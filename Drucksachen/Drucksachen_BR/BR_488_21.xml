<document>
    <id>255270</id>
    <drucksachetyp>Unterrichtung</drucksachetyp>
    <dokumentart>Drucksache</dokumentart>
    <autoren_anzahl>0</autoren_anzahl>
    <typ>Dokument</typ>
    <vorgangsbezug_anzahl>1</vorgangsbezug_anzahl>
    <dokumentnummer>488/21</dokumentnummer>
    <wahlperiode>19</wahlperiode>
    <herausgeber>BR</herausgeber>
    <pdf_hash>dc81ca9dbbf6b9b11d3ef1564c27ad41</pdf_hash>
    <aktualisiert>2022-07-26T19:57:15+02:00</aktualisiert>
    <vorgangsbezug>
      <id>279055</id>
      <titel>Vorschlag f&#252;r eine Verordnung des Europ&#228;ischen Parlaments und des Rates zur Festlegung harmonisierter Vorschriften f&#252;r k&#252;nstliche Intelligenz (Gesetz &#252;ber k&#252;nstliche Intelligenz) und zur &#196;nderung bestimmter Rechtsakte der Union
KOM(2021) 206 endg.; Ratsdok. 8115/21</titel>
      <vorgangstyp>EU-Vorlage</vorgangstyp>
    </vorgangsbezug>
    <urheber>
      <einbringer>false</einbringer>
      <bezeichnung>EU-Kommission</bezeichnung>
      <titel>Europ&#228;ische Kommission</titel>
    </urheber>
    <fundstelle>
      <pdf_url>https://dserver.bundestag.de/brd/2021/0488-21.pdf</pdf_url>
      <id>255270</id>
      <dokumentnummer>488/21</dokumentnummer>
      <datum>2021-06-07</datum>
      <dokumentart>Drucksache</dokumentart>
      <drucksachetyp>Unterrichtung</drucksachetyp>
      <herausgeber>BR</herausgeber>
      <urheber>Europ&#228;ische Kommission</urheber>
    </fundstelle>
    <text>[Vertrieb: Bundesanzeiger Verlag GmbH, Postfach 10 05 34, 50445 K&#246;ln 
Telefon (02 21) 97 66 83 40, Fax (02 21) 97 66 83 44, www.betrifft-gesetze.de 
ISSN 0720-2946
Bundesrat Drucksache 488/21
07.06.21 
EU - AIS - G - In - K - R - Wi
Unterrichtung 
durch die Europ&#228;ische Kommission
Vorschlag f&#252;r eine Verordnung des Europ&#228;ischen Parlaments und des Rates zur Festlegung 
harmonisierter Vorschriften f&#252;r k&#252;nstliche Intelligenz (Gesetz &#252;ber k&#252;nstliche Intelligenz) und 
zur &#196;nderung bestimmter Rechtsakte der Union 
COM(2021) 206 final
Der Bundesrat wird &#252;ber die Vorlage gem&#228;&#223; &#167; 2 EUZBLG auch durch die Bundesregierung 
unterrichtet. 
Der Europ&#228;ische Wirtschafts- und Sozialausschuss und der Ausschuss der Regionen werden 
an den Beratungen beteiligt.
Hinweis: Drucksache 29/99 = AE-Nr. 990150;  
Drucksache 165/19 = AE-Nr. 190330;  
Drucksache 95/20 = AE-Nr. 200110;  
Drucksache 96/20 = AE-Nr. 200111;  
Drucksache 97/20 = AE-Nr. 200112;  
Drucksache 627/20 = AE-Nr. 200862;  
Drucksache 727/20 = AE-Nr. 200996;  
Drucksache 96/21 = AE-Nr. 210064;  
Drucksache 238/21 = AE-Nr. 210227;  
Drucksache 484/21 = AE-Nr. 210424
DE DE
EUROP&#196;ISCHE
KOMMISSION
Br&#252;ssel, den 21.4.2021  
COM(2021) 206 final
2021/0106 (COD)
Vorschlag f&#252;r eine
VERORDNUNG DES EUROP&#196;ISCHEN PARLAMENTS UND DES RATES 
ZUR FESTLEGUNG HARMONISIERTER VORSCHRIFTEN F&#220;R K&#220;NSTLICHE 
INTELLIGENZ (GESETZ &#220;BER K&#220;NSTLICHE INTELLIGENZ) UND ZUR 
&#196;NDERUNG BESTIMMTER RECHTSAKTE DER UNION
{SEC(2021) 167 final} - {SWD(2021) 84 final} - {SWD(2021) 85 final}
1. KONTEXT DES VORSCHLAGS
1.1. Gr&#252;nde und Ziele des Vorschlags 
Diese Begr&#252;ndung ist dem Vorschlag f&#252;r eine Verordnung beigef&#252;gt, mit der harmonisierte 
Vorschriften f&#252;r k&#252;nstliche Intelligenz festgelegt werden (Gesetz &#252;ber k&#252;nstliche Intelligenz). 
K&#252;nstliche Intelligenz (KI) bezeichnet eine Reihe von Technologien, die sich rasant 
entwickeln und einen vielf&#228;ltigen Nutzen f&#252;r Wirtschaft und Gesellschaft &#252;ber das gesamte 
Spektrum industrieller und gesellschaftlicher Aktivit&#228;ten hinweg hervorbringen k&#246;nnen. Der 
Einsatz k&#252;nstlicher Intelligenz zur Verbesserung von Prognosen, zur Optimierung von 
Abl&#228;ufen und der Ressourcenzuweisung sowie zur Personalisierung der Diensteerbringung 
kann f&#252;r die Gesellschaft und die Umwelt von Nutzen sein und Unternehmen sowie der 
europ&#228;ischen Wirtschaft Wettbewerbsvorteile verschaffen. Bedarf besteht insbesondere in 
Sektoren, von denen eine gro&#223;e Wirkung ausgeht, wie Klimaschutz, Umwelt und Gesundheit, 
&#246;ffentlicher Sektor, Finanzen, Mobilit&#228;t, Inneres und Landwirtschaft. Dieselben Faktoren und 
Techniken, die f&#252;r den sozio&#246;konomischen Nutzen der KI sorgen, k&#246;nnen aber auch neue 
Risiken oder Nachteile f&#252;r den Einzelnen oder die Gesellschaft hervorbringen. Vor dem 
Hintergrund des rasanten technologischen Wandels und m&#246;glicher Herausforderungen ist die 
EU entschlossen, einen ausgewogenen Ansatz zu erreichen. Es liegt im Interesse der Union, 
die technische F&#252;hrungsrolle der EU auszubauen und daf&#252;r zu sorgen, dass die Europ&#228;erinnen 
und Europ&#228;er von den im Einklang mit den Werten, Grundrechten und Prinzipien der Union 
entwickelten und funktionierenden neuen Technologien profitieren k&#246;nnen. 
Dieser Vorschlag geht auf das politische Engagement von Pr&#228;sidentin von der Leyen zur&#252;ck, 
die in ihren politischen Leitlinien f&#252;r die Kommission (2019-2024) &#8211; &#8222;Eine Union, die mehr 
erreichen will&#8220;1 &#8211; ank&#252;ndigte, dass die Kommission einen Legislativvorschlag f&#252;r ein 
koordiniertes europ&#228;isches Konzept f&#252;r die menschlichen und ethischen Aspekte der KI 
vorlegen wird. Im Nachgang zu dieser Ank&#252;ndigung ver&#246;ffentlichte die Kommission am 
19. Februar 2020 ihr Wei&#223;buch zur KI &#8211; Ein europ&#228;isches Konzept f&#252;r Exzellenz und 
Vertrauen2. In dem Wei&#223;buch legt sie die politischen Optionen dar, wie die Nutzung von KI 
gef&#246;rdert und gleichzeitig die mit bestimmten Anwendungen dieser Technologie verbundenen 
Risiken einged&#228;mmt werden k&#246;nnen. Dieser Vorschlag zielt darauf ab, einen Rechtsrahmen 
f&#252;r eine vertrauensw&#252;rdige KI zu schaffen, damit das zweite Ziel f&#252;r den Aufbau eines 
&#214;kosystems f&#252;r Vertrauen umgesetzt werden kann. Der Vorschlag beruht auf den Werten und 
Grundrechten der EU und will erreichen, dass Privatpersonen und andere Nutzer KI-
gest&#252;tzten L&#246;sungen vertrauen und gleichzeitig Unternehmen Anreize erhalten, diese zu 
entwickeln. KI sollte ein Instrument sein, das als positive Kraft f&#252;r die Gesellschaft im Dienst 
der Menschen steht und das letztlich zu einem gr&#246;&#223;eren Wohlbefinden der Menschen beitr&#228;gt. 
Vorschriften f&#252;r KI, die auf dem Unionsmarkt verf&#252;gbar ist oder anderweitig Menschen in der 
Union beeinflusst, sollten daher auf den Menschen ausgerichtet sein, damit Menschen darauf 
vertrauen k&#246;nnen, dass die Technik sicher angewandt wird und den Gesetzen, auch den 
Grundrechten, gen&#252;gt. Nach Ver&#246;ffentlichung des Wei&#223;buchs leitete die Kommission eine 
breit angelegte Konsultation der Interessentr&#228;ger ein, die reges Interesse zeigten und sich in 
gro&#223;er Zahl beteiligten und die weitestgehend regulatorische Ma&#223;nahmen zur Bew&#228;ltigung 
_
BEGR&#220;NDUNG
1 https://ec.europa.eu/commission/sites/beta-political/files/political-guidelines-next-commission de.pdf
2 Wei&#223;buch zur k&#252;nstlichen Intelligenz &#8211; Ein europ&#228;isches Konzept f&#252;r Exzellenz und Vertrauen, 
COM(2020) 65 final, 2020.
der Herausforderungen und Bedenken, die der zunehmende Einsatz von KI mit sich bringt, 
bef&#252;rworteten.
Der Vorschlag ist zudem eine Reaktion auf die vom Europ&#228;ischen Parlament und dem 
Europ&#228;ischen Rat ausdr&#252;cklich und wiederholt erhobenen Forderungen nach legislativen 
Ma&#223;nahmen zur Gew&#228;hrleistung eines reibungslos funktionierenden Binnenmarkts f&#252;r 
Systeme der k&#252;nstlichen Intelligenz (KI-Systeme), mit denen sowohl der Nutzen als auch die 
Risiken der KI auf Unionsebene angemessen geregelt werden. Er unterst&#252;tzt das vom 
Europ&#228;ischen Rat3 formulierte Ziel der Union, bei der Entwicklung einer sicheren, 
vertrauensw&#252;rdigen und ethisch vertretbaren k&#252;nstlichen Intelligenz weltweit eine 
F&#252;hrungsrolle einzunehmen, und sorgt f&#252;r den vom Europ&#228;ischen Parlament4 ausdr&#252;cklich 
geforderten Schutz von Ethikgrunds&#228;tzen.
2017 forderte der Europ&#228;ische Rat &#8222;ein Bewusstsein f&#252;r die Dringlichkeit der 
Auseinandersetzung mit neuen Trends&#8220;, auch f&#252;r &#8222;Themen wie k&#252;nstliche Intelligenz....&#8220;, 
&#8222;wobei zugleich ein hohes Niveau in Bezug auf Datenschutz, digitale Rechte und ethische 
Standards gewahrt werden muss&#8220;5. In seinen Schlussfolgerungen von 2019 zu dem 
koordinierten Plan f&#252;r k&#252;nstliche Intelligenz &#8222;Made in Europe&#8220;6 betont der Rat ferner, wie 
wichtig es ist, die uneingeschr&#228;nkte Achtung der Rechte der europ&#228;ischen B&#252;rgerinnen und 
B&#252;rger zu gew&#228;hrleisten, und ruft dazu auf, die ma&#223;geblichen geltenden Rechtsvorschriften 
zu &#252;berpr&#252;fen, um sicherzustellen, dass sie im Hinblick auf die neuen Chancen und 
Herausforderungen, die sich durch k&#252;nstliche Intelligenz ergeben, zweckdienlich sind. Der 
Europ&#228;ische Rat forderte zudem eine klare Festlegung von KI-Anwendungen, die als 
hochriskant eingestuft werden sollten7. 
In seinen j&#252;ngsten Schlussfolgerungen vom 21. Oktober 2020 forderte der Rat zudem, dass 
Probleme wie Undurchsichtigkeit, Komplexit&#228;t, der sogenannte &#8222;Bias&#8220;, ein gewisses Ma&#223; an 
Unberechenbarkeit und teilweise autonomes Verhalten einiger KI-Systeme angegangen 
werden m&#252;ssen, um deren Vereinbarkeit mit den Grundrechten sicherzustellen und die 
Durchsetzung der Rechtsvorschriften zu erleichtern8. 
Auch das Europ&#228;ische Parlament hat sich intensiv mit dem Thema der KI befasst. Im Oktober 
2020 nahm es eine Reihe von Entschlie&#223;ungen zur KI an, u. a. zur Ethik9, zivilrechtlichen 
Haftung10 und zum Urheberrecht11. 2021 folgten weitere Entschlie&#223;ungen zur KI im
3 Europ&#228;ischer Rat, Au&#223;erordentliche Tagung des Europ&#228;ischen Rates (1. und 2. Oktober 2020) &#8211; 
Schlussfolgerungen, EUCO 13/20, 2020, S. 6. 
4 Entschlie&#223;ung des Europ&#228;ischen Parlaments vom 20. Oktober 2020 mit Empfehlungen an die 
Kommission zu dem Rahmen f&#252;r die ethischen Aspekte von k&#252;nstlicher Intelligenz, Robotik und damit 
zusammenh&#228;ngenden Technologien, 2020/2012 (INL). 
5 Europ&#228;ischer Rat, Tagung des Europ&#228;ischen Rates (19. Oktober 2017) &#8211; Schlussfolgerung, 
EUCO 14/17, 2017, S. 7. 
6 Rat der Europ&#228;ischen Union, K&#252;nstliche Intelligenz b) Schlussfolgerungen zu dem koordinierten Plan 
f&#252;r k&#252;nstliche Intelligenz &#8211; Annahme, 6177/19, 2019. 
7 Europ&#228;ischer Rat, Au&#223;erordentliche Tagung des Europ&#228;ischen Rates (1. und 2. Oktober 2020) &#8211; 
Schlussfolgerungen, EUCO 13/20, 2020. 
8 Rat der Europ&#228;ischen Union, Schlussfolgerungen des Vorsitzes &#8211; Die Charta der Grundrechte im 
Zusammenhang mit k&#252;nstlicher Intelligenz und dem digitalen Wandel, 11481/20, 2020. 
9 Entschlie&#223;ung des Europ&#228;ischen Parlaments vom 20. Oktober 2020 mit Empfehlungen an die 
Kommission zu dem Rahmen f&#252;r die ethischen Aspekte von k&#252;nstlicher Intelligenz, Robotik und damit 
zusammenh&#228;ngenden Technologien, 2020/2012 (INL). 
10 Entschlie&#223;ung des Europ&#228;ischen Parlaments vom 20. Oktober 2020 mit Empfehlungen an die 
Kommission f&#252;r eine Regelung der zivilrechtlichen Haftung beim Einsatz k&#252;nstlicher Intelligenz, 
2020/2014(INL).
Strafrecht12 sowie in der Bildung, der Kultur und im audiovisuellen Bereich13. In seiner 
Entschlie&#223;ung zu dem Rahmen f&#252;r die ethischen Aspekte von k&#252;nstlicher Intelligenz, Robotik 
und damit zusammenh&#228;ngenden Technologien empfiehlt das Europ&#228;ische Parlament der 
Kommission insbesondere legislative Ma&#223;nahmen vorzuschlagen, um so die Chancen und den 
Nutzen k&#252;nstlicher Intelligenz auszusch&#246;pfen, aber auch daf&#252;r zu sorgen, dass Ethik-
Grunds&#228;tze gesch&#252;tzt werden. Die Entschlie&#223;ung enth&#228;lt den Legislativvorschlag f&#252;r eine 
Verordnung &#252;ber Ethik-Grunds&#228;tze f&#252;r die Entwicklung, den Einsatz und die Nutzung von 
k&#252;nstlicher Intelligenz, Robotik und damit zusammenh&#228;ngenden Technologien im Wortlaut. 
Dieser Vorschlag ber&#252;cksichtigt die vorstehende Entschlie&#223;ung des Europ&#228;ischen Parlaments 
unter uneingeschr&#228;nkter Wahrung der Grunds&#228;tze der Verh&#228;ltnism&#228;&#223;igkeit, Subsidiarit&#228;t und 
besseren Rechtsetzung und steht damit in Einklang mit den von Pr&#228;sidentin von der Leyen in 
ihren politischen Leitlinien gemachten politischen Zusagen hinsichtlich der Behandlung der 
vom Europ&#228;ischen Parlament angenommenen Entschlie&#223;ungen nach Artikel 225 AEUV. 
Vor diesem politischen Hintergrund legt die Kommission ihren Vorschlag f&#252;r einen 
Rechtsrahmen zur K&#252;nstlichen Intelligenz vor, mit dem konkret die folgenden Ziele
angestrebt werden: 
&#61623; Es muss gew&#228;hrleistet sein, dass die auf dem Unionsmarkt in Verkehr gebrachten und 
verwendeten KI-Systeme sicher sind und die bestehenden Grundrechte und die Werte der 
Union wahren.
&#61623; Zur F&#246;rderung von Investitionen in KI und innovativen KI muss Rechtssicherheit 
gew&#228;hrleistet sein. 
&#61623; Governance und die wirksame Durchsetzung des geltenden Rechts zur Wahrung der 
Grundrechte sowie die Sicherheitsanforderungen an KI-Systeme m&#252;ssen gest&#228;rkt werden. 
&#61623; Die Entwicklung eines Binnenmarkts f&#252;r rechtskonforme, sichere und vertrauensw&#252;rdige 
KI-Anwendungen muss erleichtert werden und es gilt, eine Marktfragmentierung zu 
verhindern.
Mit Blick auf diese Ziele enth&#228;lt dieser Vorschlag einen ausgewogenen horizontalen 
Regulierungsansatz f&#252;r KI, der die Verh&#228;ltnism&#228;&#223;igkeit wahrt und auf die 
Mindestanforderungen beschr&#228;nkt ist, die zur Bew&#228;ltigung der in Verbindung mit KI 
auftretenden Risiken und Probleme notwendig ist, ohne die technologische Entwicklung 
&#252;berm&#228;&#223;ig einzuschr&#228;nken oder zu behindern oder anderweitig die Kosten f&#252;r das 
Inverkehrbringen von KI-L&#246;sungen unverh&#228;ltnism&#228;&#223;ig in die H&#246;he zu treiben. Der Vorschlag 
zielt auf einen robusten und flexiblen Rechtsrahmen ab. Einerseits ist der Vorschlag in seinen 
grundlegenden Regulierungsentscheidungen umfassend und zukunftsorientiert. Dies gilt auch 
f&#252;r die von den KI-Systemen zu erf&#252;llenden und auf Grunds&#228;tzen beruhenden Anforderungen. 
Andererseits wird ein Regulierungssystem geschaffen, das die Verh&#228;ltnism&#228;&#223;igkeit wahrt und 
auf genau definierte Risiken ausgerichtet ist. Dieser Regulierungsansatz schafft keine 
unn&#246;tigen Handelsbeschr&#228;nkungen und der Gesetzgeber schreitet nur in solchen konkreten 
11 Entschlie&#223;ung des Europ&#228;ischen Parlaments vom 20. Oktober 2020 zu den Rechten des geistigen 
Eigentums bei der Entwicklung von KI-Technologien, 2020/2015(INI). 
12 Europ&#228;isches Parlament &#8211; Berichtsentwurf &#252;ber k&#252;nstliche Intelligenz im Strafrecht und ihre 
Verwendung durch die Polizei und Justizbeh&#246;rden in Strafsachen, 2020/2016(INI). 
13 Europ&#228;isches Parlament &#8211; Entwurf eines Berichts &#252;ber k&#252;nstliche Intelligenz in der Bildung, der Kultur 
und dem audiovisuellen Bereich, 2020/2017(INI). So hat die Kommission den Aktionsplan f&#252;r digitale 
Bildung 2021-2027 angenommen: &#8222;Neuaufstellung des Bildungswesens f&#252;r das digitale Zeitalter&#8220;. Der 
Aktionsplan sieht die Entwicklung von Ethik-Leitlinien f&#252;r die Nutzung von KI und Daten im 
Bildungswesen vor &#8211; Mitteilung der Kommission, COM(2020) 624 final.
Situationen ein, in denen ein berechtigter Anlass f&#252;r Bedenken besteht oder in denen 
vern&#252;nftigerweise davon ausgegangen werden kann, dass solche Bedenken in naher Zukunft 
auftreten werden. Gleichzeitig enth&#228;lt der Rechtsrahmen Mechanismen, mit denen er flexibel 
und dynamisch an die technologische Entwicklung und neue bedenkliche Situationen 
angepasst werden kann. 
Der Vorschlag enth&#228;lt harmonisierte Vorschriften f&#252;r die Entwicklung, das Inverkehrbringen 
und die Verwendung von KI-Systemen in der Union, die im Verh&#228;ltnis zu den Risiken stehen. 
Die vorgeschlagene Begriffsbestimmung f&#252;r KI ist zukunftstauglich. W&#228;hrend einige 
besonders sch&#228;dliche KI-Praktiken, die gegen die Werte der Union versto&#223;en, verboten sind, 
werden f&#252;r die Zwecke der Strafverfolgung f&#252;r bestimmte Anwendungen biometrischer 
Fernidentifizierungssysteme konkrete Beschr&#228;nkungen und Sicherheitsma&#223;nahmen 
vorgeschlagen. Der Vorschlag enth&#228;lt eine solide Risiko-Methodik zur Einstufung von 
Hochrisiko-KI-Systemen, d. h. solchen Systemen, die erhebliche Risiken f&#252;r die Gesundheit 
und Sicherheit oder die Grundrechte von Personen bergen. Solche KI-Systeme m&#252;ssen 
horizontalen Auflagen f&#252;r vertrauensw&#252;rdige KI gen&#252;gen und 
Konformit&#228;tsbewertungsverfahren unterzogen werden, bevor sie in der Union in Verkehr 
gebracht werden d&#252;rfen. Damit die Sicherheit und die Einhaltung bestehender 
Rechtsvorschriften zum Schutz der Grundrechte &#252;ber den gesamten Lebenszyklus von KI-
Systemen hinweg gewahrt bleiben, werden Anbietern und Nutzern dieser Systeme 
berechenbare, verh&#228;ltnism&#228;&#223;ige und klare Pflichten auferlegt. F&#252;r einige KI-Systeme werden 
nur minimale Transparenzpflichten vorgeschlagen, insbesondere f&#252;r den Einsatz von Chatbots 
oder &#8222;Deepfakes&#8220;. 
Die vorgeschlagenen Vorschriften werden von den Mitgliedstaaten mittels einer 
Leitungsstruktur durchgesetzt, die auf bereits vorhandenen Strukturen aufbaut, sowie mittels 
eines Kooperationsmechanismus auf Unionsebene, auf der ein Europ&#228;ischer Ausschuss f&#252;r 
k&#252;nstliche Intelligenz eingesetzt wird. Zus&#228;tzliche Ma&#223;nahmen werden zur Unterst&#252;tzung von 
Innovation, vor allem in Form von KI-Reallaboren, sowie zur Verringerung des 
Verwaltungsaufwands und zur F&#246;rderung von kleinen und mittleren Unternehmen (KMU) 
und Startups vorgeschlagen. 
1.2. Koh&#228;renz mit den bestehenden Vorschriften in diesem Politikbereich
Die horizontale Ausrichtung des Vorschlags erfordert die uneingeschr&#228;nkte Koh&#228;renz mit 
dem bestehenden Unionsrecht, das auf Sektoren Anwendung findet, in denen Hoch-Risiko-
KI-Systeme bereits jetzt oder wahrscheinlich in naher Zukunft eingesetzt werden. 
Auch mit der EU-Grundrechtecharta und dem geltenden Sekund&#228;rrecht der Union zum Daten-
und Verbraucherschutz, zur Nichtdiskriminierung und zur Gleichstellung der Geschlechter ist 
die Koh&#228;renz gew&#228;hrleistet. Die Datenschutz-Grundverordnung (Verordnung (EU) 2016/679) 
und die Strafverfolgungsrichtlinie (Richtlinie (EU) 2016/680) bleiben von dem Vorschlag 
unber&#252;hrt und werden durch harmonisierte Vorschriften f&#252;r Entwurf, Entwicklung und 
Verwendung bestimmter Hochrisiko-KI-Systeme sowie durch Beschr&#228;nkungen f&#252;r bestimmte 
Anwendungen biometrischer Fernidentifizierungssysteme erg&#228;nzt. Dar&#252;ber hinaus erg&#228;nzt der 
Vorschlag geltendes Unionsrecht zur Nichtdiskriminierung, indem konkrete Anforderungen 
zur Minimierung des Risikos der Diskriminierung durch Algorithmen, vor allem in Bezug auf 
Entwurf und Qualit&#228;t von f&#252;r die Entwicklung von KI-Systemen verwendeten Datens&#228;tzen, 
aufgenommen wurden, und Tests, Risikomanagement, Dokumentation und menschliche 
Aufsicht &#252;ber die gesamte Lebensdauer von KI-Systemen hinweg verbindlich vorgeschrieben 
werden. Der Vorschlag l&#228;sst die Anwendung des Wettbewerbsrechts der Union unber&#252;hrt. 
Im Hinblick auf Hochrisiko-KI-Systeme, bei denen es sich um Sicherheitskomponenten von 
Produkten handelt, wird dieser Vorschlag zur Wahrung der Koh&#228;renz, zur Vermeidung von
&#220;berschneidungen und zur Verringerung des Verwaltungsaufwands in die bereits 
vorhandenen sektorspezifischen Sicherheitsvorschriften eingebunden. So werden die in 
diesem Vorschlag enthaltenen Anforderungen an KI-Systeme im Falle von Hochrisiko-KI-
Systemen, die mit unter den Neuen Rechtsrahmen (New Legislative Framework, NLF) 
fallenden Produkten (z. B. Maschinen, medizinische Ger&#228;te, Spielzeug) in Verbindung stehen, 
im Rahmen der bestehenden Konformit&#228;tsbewertungsverfahren nach dem einschl&#228;gigen NLF-
Recht gepr&#252;ft. F&#252;r das Zusammenspiel der Anforderung gilt, dass die von den jeweiligen KI-
Systemen abh&#228;ngigen Sicherheitsrisiken den Anforderungen dieses Vorschlags unterliegen, 
w&#228;hrend mit dem NLF-Recht die Sicherheit des Endprodukts insgesamt gew&#228;hrleistet werden 
soll, weshalb diese Vorschriften konkrete Anforderungen an die sichere Integration von KI-
Systemen in das Endprodukt enthalten k&#246;nnen. Dieser Ansatz l&#228;sst sich auch gut daran 
erkennen, dass der Vorschlag f&#252;r eine Maschinenverordnung am selben Tag wie dieser 
Vorschlag angenommen werden soll. F&#252;r Hochrisiko-KI-Systeme in Verbindung mit 
Produkten, die unter die einschl&#228;gigen Vorschriften des Alten Konzepts fallen (z. B. 
Luftfahrt, Fahrzeuge) w&#252;rde dieser Vorschlag nicht unmittelbar gelten. Allerdings m&#252;ssen die 
in diesem Vorschlag festgelegten und vorab zu erf&#252;llenden wesentlichen Anforderungen an 
Hochrisiko-KI-Systeme bei der Annahme einschl&#228;giger Durchf&#252;hrungsrechtsakte oder 
delegierter Rechtsakte in diesen Rechtsakten ber&#252;cksichtigt werden. 
Bei KI-Systemen, die von regulierten Kreditinstituten bereitgestellt oder verwendet werden, 
sollten die f&#252;r die Aufsicht &#252;ber die Rechtsvorschriften der Union im Bereich der 
Finanzdienstleistungen zust&#228;ndigen Beh&#246;rden auch als die zust&#228;ndigen Beh&#246;rden f&#252;r die 
Aufsicht &#252;ber die Anforderungen dieses Vorschlags benannt werden, um eine koh&#228;rente 
Durchsetzung der sich aus diesem Vorschlag ergebenden Pflichten und der Rechtsvorschriften 
der Union im Bereich der Finanzdienstleistungen zu gew&#228;hrleisten, in denen die KI-Systeme 
zu einem gewissen Grad implizit in Verbindung mit dem internen 
Unternehmensf&#252;hrungssystem der Kreditinstitute reguliert sind. Im Sinne einer noch gr&#246;&#223;eren 
Koh&#228;renz werden die in diesem Vorschlag vorgesehenen Konformit&#228;tsbewertungen und 
einige verfahrenstechnische Pflichten der Anbieter in die Verfahren eingebunden, die nach 
der Richtlinie 2013/36/EU &#252;ber den Zugang zur T&#228;tigkeit von Kreditinstituten und die 
Beaufsichtigung von Kreditinstituten und Wertpapierfirmen14 einzuhalten sind. 
Zudem steht der Vorschlag in Einklang mit dem geltenden EU-Dienstleistungsrecht, unter das 
auch die in der E-Commerce-Richtlinie 2000/31/EG15 regulierten Vermittlungsdienste und der 
j&#252;ngste Kommissionsvorschlag f&#252;r das Gesetz &#252;ber digitale Dienste16 fallen. 
Der Vorschlag gilt nicht f&#252;r die KI-Systeme, die als Komponenten von IT-Gro&#223;systemen in 
dem von der Agentur der Europ&#228;ischen Union f&#252;r das Betriebsmanagement von IT-
Gro&#223;systemen (eu-LISA) verwalteten Raum der Freiheit, der Sicherheit und des Rechts vor 
Ablauf eines Jahres ab dem Zeitpunkt der Anwendung dieser Verordnung in Verkehr gebracht 
oder in Betrieb genommen wurden, sofern der Ersatz oder die &#196;nderung der entsprechenden 
14 Richtlinie 2013/36/EU des Europ&#228;ischen Parlaments und des Rates vom 26. Juni 2013 &#252;ber den Zugang 
zur T&#228;tigkeit von Kreditinstituten und die Beaufsichtigung von Kreditinstituten und Wertpapierfirmen, 
zur &#196;nderung der Richtlinie 2002/87/EG und zur Aufhebung der Richtlinien 2006/48/EG und 
2006/49/EG (ABl. L 176 vom 27.6.2013, S. 338). 
15 Richtlinie 2000/31/EG des Europ&#228;ischen Parlaments und des Rates vom 8. Juni 2000 &#252;ber bestimmte 
rechtliche Aspekte der Dienste der Informationsgesellschaft, insbesondere des elektronischen 
Gesch&#228;ftsverkehrs, im Binnenmarkt (&#8222;Richtlinie &#252;ber den elektronischen Gesch&#228;ftsverkehr&#8220;) (ABl. 
L 178 vom 17.7.2000, S. 1). 
16 Siehe Vorschlag f&#252;r eine Verordnung des Europ&#228;ischen Parlaments und des Rates &#252;ber einen 
Binnenmarkt f&#252;r digitale Dienste (Gesetz &#252;ber digitale Dienste) und zur &#196;nderung der 
Richtlinie 2000/31/EG, COM(2020) 825 final.
Rechtsakte die Konzeption oder die Zweckbestimmung der betreffenden KI-Systeme 
erheblich &#228;ndert.
1.3. Koh&#228;renz mit der Politik der Union in anderen Bereichen
Der Vorschlag ist Teil eines umfassenderen Pakets von Ma&#223;nahmen, mit denen die im 
Wei&#223;buch zur KI untersuchten Probleme, die sich bei der Entwicklung und der Verwendung 
von KI stellen, angegangen werden sollen. Daher werden Koh&#228;renz und Komplementarit&#228;t 
mit anderen laufenden oder geplanten Initiativen der Kommission, die sich ebenfalls mit 
diesen Problemen befassen, gew&#228;hrleistet. Hierunter fallen die &#220;berarbeitung der 
sektorspezifischen Produktvorschriften (z. B. die Maschinenrichtlinie, die Richtlinie &#252;ber die 
allgemeine Produktsicherheit) sowie Initiativen, die sich mit Haftungsfragen im 
Zusammenhang mit den neuen Technologien, auch KI-Systemen, befassen. Die Initiativen 
werden auf diesem Vorschlag aufbauen und ihn erg&#228;nzen und so f&#252;r Rechtsklarheit sorgen 
und die Entwicklung eines &#214;kosystems f&#252;r Vertrauen in die KI in Europa f&#246;rdern. 
Der Vorschlag steht zudem in Einklang mit der von der Kommission insgesamt verfolgten 
Digitalstrategie, indem er dazu beitr&#228;gt, eine Technologie zu f&#246;rdern, die den Menschen 
zugutekommt &#8211; eines der drei Hauptziele, die in der Mitteilung zur &#8222;Gestaltung der digitalen 
Zukunft Europas&#8220; genannt werden17. Es wird ein koh&#228;renter, wirksamer und angemessener 
Rahmen geschaffen, mit dem sichergestellt wird, dass KI so entwickelt wird, dass die Rechte 
der Menschen geachtet werden und sie ihr Vertrauen verdient &#8211; damit ist Europa f&#252;r das 
digitale Zeitalter gewappnet und die n&#228;chsten zehn Jahre werden zur digitalen Dekade18. 
Dar&#252;ber hinaus ist die F&#246;rderung der auf KI beruhenden Innovation eng mit dem Daten-
Governance-Gesetz19, der Richtlinie &#252;ber offene Daten20 und anderen Initiativen im 
Rahmen der EU-Strategie f&#252;r Daten21 verkn&#252;pft, mit denen vertrauensw&#252;rdige 
Mechanismen und Dienste f&#252;r die Weiterverwendung, das Teilen und die Zusammenf&#252;hrung 
von Daten festgelegt werden, die f&#252;r die Entwicklung hochwertiger datengesteuerter KI-
Modelle entscheidend sind. 
Mit dem Vorschlag wird zudem die Position der Union bei der Formulierung weltweiter 
Normen und Standards sowie der F&#246;rderung vertrauensw&#252;rdiger KI, die mit den Werten und 
Interessen der Union in Einklang stehen, erheblich gest&#228;rkt. Er bietet der Union eine solide 
Grundlage f&#252;r ihre weiteren Gespr&#228;che zur Fragen der KI mit ihren externen Partnern, auch 
Drittl&#228;ndern, und in internationalen Gremien.
2. RECHTSGRUNDLAGE, SUBSIDIARIT&#196;T UND VERH&#196;LTNISM&#196;&#7838;IGKEIT 
2.1. Rechtsgrundlage 
Rechtsgrundlage f&#252;r den Vorschlag ist zun&#228;chst Artikel 114 des Vertrags &#252;ber die 
Arbeitsweise der Europ&#228;ischen Union (AEUV), der die Annahme von Ma&#223;nahmen f&#252;r die 
Errichtung und das Funktionieren des Binnenmarkts vorsieht.
17 Mitteilung der Kommission &#8222;Gestaltung der digitalen Zukunft Europas&#8220;, COM(2020) 67. 
18 Digitaler Kompass 2030:der europ&#228;ische Weg in die digitale Dekade. 
19 Vorschlag f&#252;r eine Verordnung &#252;ber europ&#228;ische Daten-Governance (Data-Governance-Gesetz), 
COM(2020) 767. 
20 Richtlinie (EU) 2019/1024 des Europ&#228;ischen Parlaments und des Rates vom 20. Juni 2019 &#252;ber offene 
Daten und die Weiterverwendung von Informationen des &#246;ffentlichen Sektors (PE/28/2019/REV/1, 
ABl. L 172 vom 26.6.2019, S. 56). 
21 Mitteilung der Kommission &#8222;Eine europ&#228;ische Datenstrategie&#8220;, COM(2020) 66 final.
Dieser Vorschlag bildet ein Kernelement der EU-Strategie f&#252;r den digitalen Binnenmarkt. 
Hauptziel dieses Vorschlags ist, durch die Festlegung harmonisierter Vorschriften, 
insbesondere in Bezug auf die Entwicklung, das Inverkehrbringen und den Einsatz von 
Produkten und Diensten, die KI-Techniken anwenden, oder von eigenst&#228;ndigen KI-Systemen, 
f&#252;r ein reibungsloses Funktionieren des Binnenmarkts zu sorgen. Einige Mitgliedstaaten 
ziehen bereits nationale Vorschriften in Erw&#228;gung, damit sichergestellt ist, dass KI sicher ist 
und unter Einhaltung der Grundrechte entwickelt und verwendet wird. Daraus d&#252;rften sich vor 
allem die beiden folgende Probleme ergeben: i) eine Fragmentierung des Binnenmarkts in 
wesentlichen Fragen, insbesondere mit Blick auf die Anforderungen an KI-Produkte und -
Dienste, deren Vermarktung und Verwendung sowie auf die Haftung und die Aufsicht durch 
&#246;ffentliche Beh&#246;rden, und ii) die erheblich geringere Rechtssicherheit sowohl f&#252;r Anbieter als 
auch Nutzer von KI-Systemen im Hinblick darauf, wie bestehende und neue Vorschriften auf 
solche Systeme in der Union angewandt werden. Angesichts des gro&#223;en Umfangs des 
grenz&#252;berschreitenden Waren- und Dienstleistungsverkehrs lassen sich diese beiden Probleme 
am besten durch unionsweit harmonisierte Rechtsvorschriften l&#246;sen.
So werden in dem Vorschlag die gemeinsamen Anforderungen an Konzeption und 
Entwicklung bestimmter KI-Systeme festgelegt, die zwingend eingehalten werden m&#252;ssen, 
bevor diese Systeme in Verkehr gebracht werden d&#252;rfen, und die weiter durch harmonisierte 
technische Normen konkretisiert werden. Der Vorschlag befasst sich auch mit der Situation 
nach dem Inverkehrbringen von KI-Systemen, indem eine abgestimmte Vorgehensweise f&#252;r 
nachtr&#228;gliche Kontrollen vorgesehen wird. 
Da dieser Vorschlag konkrete Vorschriften zum Schutz von Privatpersonen im Hinblick auf 
die Verarbeitung personenbezogener Daten enth&#228;lt, mit denen vor allem die Verwendung von 
KI-Systemen zur biometrischen Fernidentifizierung in Echtzeit in &#246;ffentlich zug&#228;nglichen 
R&#228;umen f&#252;r die Zwecke der Strafverfolgung eingeschr&#228;nkt wird, sollte sich diese Verordnung 
in Bezug auf diese konkreten Vorschriften auch auf Artikel 16 AEUV st&#252;tzen. 
2.2. Subsidiarit&#228;t (bei nicht ausschlie&#223;licher Zust&#228;ndigkeit) 
Es liegt in der Natur der KI, die h&#228;ufig auf gro&#223;en und vielf&#228;ltigen Datens&#228;tzen beruht und die 
in alle im Binnenmarkt in Verkehr gebrachte Produkte oder Dienste eingebettet sein kann, 
dass die Ziele dieses Vorschlags von den Mitgliedstaaten nicht allein effizient erreicht werden 
k&#246;nnen. Zudem wird der reibungslose unionsweite Waren- und Dienstleistungsverkehr im 
Zusammenhang mit KI-Systemen durch das Entstehen eines Flickenteppichs potenziell 
abweichender nationaler Vorschriften behindert, die zudem die Sicherheit und den Schutz der 
Grundrechte sowie die Einhaltung der Werte der Union l&#228;nder&#252;bergreifend nur unzureichend 
gew&#228;hrleisten k&#246;nnen. Einzelstaatliche Konzepte zur L&#246;sung der Probleme werden nur zu 
mehr Rechtsunsicherheit und zu Hemmnissen sowie zu einer langsameren Markteinf&#252;hrung 
von KI f&#252;hren.
Die Ziele dieses Vorschlags k&#246;nnen besser auf Unionsebene erreicht werden, denn nur so 
l&#228;sst sich eine weitere Fragmentierung des Binnenmarkts verhindern, die dazu f&#252;hren w&#252;rde, 
dass potenziell widerspr&#252;chliche nationale Bestimmungen den freien Waren- und 
Dienstleistungsverkehr von Produkten, in die KI eingebettet ist, unm&#246;glich machen. Ein 
solider europ&#228;ischer Rechtsrahmen f&#252;r eine vertrauensw&#252;rdige KI wird auch f&#252;r gleiche 
Wettbewerbsbedingungen sorgen und alle Menschen sch&#252;tzen, gleichzeitig jedoch die 
Wettbewerbsf&#228;higkeit Europas und die Industriebasis im KI-Bereich st&#228;rken. Nur durch 
gemeinsames Handeln auf Unionsebene kann die Union ihre Souver&#228;nit&#228;t im digitalen 
Bereich sch&#252;tzen und ihre Instrumente und Regelungsbefugnisse zur Gestaltung globaler 
Regeln und Standards einsetzen.
2.3. Verh&#228;ltnism&#228;&#223;igkeit 
Der Vorschlag baut auf dem bestehenden Rechtsrahmen auf, ist verh&#228;ltnism&#228;&#223;ig und zur 
Erreichung seiner Ziele notwendig, da mit ihm ein risikobasierter Ansatz verfolgt wird und 
regulatorische Belastungen nur dann entstehen, wenn davon auszugehen ist, dass ein KI-
System hohe Risiken f&#252;r die Grundrechte und die Sicherheit darstellt. F&#252;r andere, KI-
Systeme, die kein hohes Risiko darstellen, werden nur sehr wenige Transparenzpflichten 
auferlegt, etwa dahingehend, dass bei der Interaktion mit Menschen der Einsatz von KI-
Systemen angezeigt werden muss. Im Falle von Hochrisiko-KI-Systemen sind die 
Anforderungen an hohe Datenqualit&#228;t, Dokumentation und R&#252;ckverfolgbarkeit, Transparenz, 
menschliche Aufsicht, Pr&#228;zision und Robustheit unerl&#228;sslich, um die Risiken f&#252;r die 
Grundrechte und die Sicherheit abzumildern, die mit diesen KI verbunden sind und die nicht 
durch andere bestehende Rechtsvorschriften abgedeckt werden. Anbieter und Nutzer werden 
bei der Einhaltung der in dem Vorschlag festgelegten Anforderungen durch harmonisierte 
Standards, Orientierungshilfen und Instrumente zur Einhaltung der Vorschriften unterst&#252;tzt, 
die auch ihre Kosten gering halten. Die den Akteuren entstehenden Kosten stehen im 
Verh&#228;ltnis zu den erreichten Zielen, dem wirtschaftlichen Nutzen sowie dem guten Ruf, die 
die Akteure von der vorgeschlagenen Regelung erwarten k&#246;nnen.
2.4. Wahl des Instruments
Die Wahl einer Verordnung als Rechtsinstrument ist durch die Notwendigkeit einer 
einheitlichen Anwendung der neuen Vorschriften gerechtfertigt, beispielsweise im Hinblick 
auf die Begriffsbestimmung f&#252;r KI, das Verbot bestimmter sch&#228;dlicher Praktiken, die durch 
KI erm&#246;glicht werden, und die Einstufung bestimmter KI-Systeme. Die unmittelbare 
Anwendbarkeit einer Verordnung nach Artikel 288 AEUV verringert die 
Rechtsfragmentierung und erleichtert die Entwicklung eines Binnenmarkts f&#252;r rechtm&#228;&#223;ige, 
sichere und vertrauensw&#252;rdige KI-Systeme. Hierzu wird insbesondere ein B&#252;ndel 
harmonisierter zentraler Anforderungen an als hochriskant eingestufte KI-Systeme eingef&#252;hrt. 
Dar&#252;ber hinaus werden Pflichten f&#252;r Anbieter und Nutzer dieser Systeme festgelegt, um den 
Schutz der Grundrechte und die Rechtssicherheit sowohl f&#252;r Akteure als auch Nutzer zu 
verbessern.
Dar&#252;ber hinaus sind die Bestimmungen der Verordnung nicht &#252;berm&#228;&#223;ig pr&#228;skriptiv und 
lassen den Mitgliedstaaten auf verschiedenen Ebenen Raum f&#252;r Ma&#223;nahmen in Bezug auf 
Elemente, die den Zielen der Initiative nicht zuwiderlaufen, insbesondere im Hinblick auf die 
interne Organisation des Markt&#252;berwachungssystems und die Einf&#252;hrung 
innovationsf&#246;rdernder Ma&#223;nahmen.
3. ERGEBNISSE DER EX-POST-BEWERTUNG, DER KONSULTATION DER
INTERESSENTR&#196;GER UND DER FOLGENABSCH&#196;TZUNG
3.1. Konsultation der Interessentr&#228;ger 
Dieser Vorschlag ist das Ergebnis einer umfangreichen Konsultation aller wichtigen 
Interessentr&#228;ger, bei der die allgemeinen Grunds&#228;tze und Mindeststandards f&#252;r die 
Konsultation von Interessentr&#228;gern durch die Kommission angewandt wurden. 
Gleichzeitig mit der Ver&#246;ffentlichung des Wei&#223;buchs zur K&#252;nstlichen Intelligenz am 
19. Februar 2020 wurde eine &#246;ffentliche Online-Konsultation gestartet, die bis zum 14. Juni 
2020 lief. Ziel der Konsultation war die Einholung von Ansichten und Stellungnahmen zum 
Wei&#223;buch. Sie richtete sich an alle Interessentr&#228;ger des &#246;ffentlichen und privaten Sektors, 
auch an Regierungen, lokale Beh&#246;rden, gewerbliche und nichtgewerbliche Organisationen, 
Sozialpartner, Sachverst&#228;ndige und Hochschulen sowie an B&#252;rgerinnen und B&#252;rger. Nach
Auswertung der eingegangenen Antworten ver&#246;ffentlichte die Kommission auf ihrer 
Website22 eine Zusammenfassung der Ergebnisse sowie die einzelnen Antworten. 
Insgesamt gingen 1215 Beitr&#228;ge ein, davon 352 von Unternehmen oder 
Unternehmensorganisationen/-verb&#228;nden, 406 von Einzelpersonen (92 % Personen aus der 
EU), 152 von Hochschul-/Forschungsinstituten und 73 von &#246;ffentlichen Stellen. 160 
Antworten gingen von Vertretern der Zivilgesellschaft ein (darunter 
9 Verbraucherorganisationen, 129 NRO und 22 Gewerkschaften), 72 Antworten von 
&#8222;Sonstigen&#8220;. Unter den 352 Unternehmens- und Industrievertretern waren 222 Vertreter von 
Unternehmen, bei denen es sich zu 41,5 % um Vertreter von Kleinstunternehmen sowie 
kleinen und mittleren Unternehmen handelte. Bei den &#252;brigen handelte es sich um 
Unternehmensverb&#228;nde. Insgesamt kamen 84 % der Antworten der Unternehmens- und 
Industrievertreter aus der EU-27. Je nach Frage nutzten 81 bis 598 Teilnehmer die 
M&#246;glichkeit, Kommentare frei zu formulieren. &#220;ber 450 Positionspapiere wurden mittels der 
EU-Survey-Website eingereicht, entweder als Anlage zu den Antworten auf den Fragebogen 
(&#252;ber 400) oder als eigenst&#228;ndige Beitr&#228;ge (&#252;ber 50). 
Insgesamt besteht unter den Interessentr&#228;gern Einvernehmen &#252;ber den Handlungsbedarf. Eine 
gro&#223;e Mehrheit der Interessentr&#228;ger stimmt der Auffassung zu, dass Regelungsl&#252;cken 
bestehen oder neue Vorschriften ben&#246;tigt werden. Allerdings weisen mehrere Interessentr&#228;ger 
die Kommission darauf hin, dass &#220;berschneidungen, widerspr&#252;chliche Auflagen oder eine 
&#220;berregulierung vermieden werden sollten. Viele Kommentare unterstrichen die Bedeutung 
der Technologieneutralit&#228;t und eines die Verh&#228;ltnism&#228;&#223;igkeit wahrenden Rechtsrahmens. 
Die Interessentr&#228;ger forderten mehrheitlich eine enge, klare und genaue Begriffsbestimmung 
k&#252;nstlicher Intelligenz. Neben einer Kl&#228;rung des Begriffs der KI unterstrichen sie auch die 
Notwendigkeit, die Begriffe &#8222;Risiko&#8220;, &#8222;hohes Risiko&#8220;, &#8222;niedriges Risiko&#8220;, &#8222;biometrische 
Fernidentifizierung&#8220; und &#8222;Schaden&#8220; zu definieren. 
Die meisten Teilnehmer bef&#252;rworten ausdr&#252;cklich den risikobasierten Ansatz. Ein Ansatz, der 
sich auf die Risiken st&#252;tzt, wurde im Vergleich zu einer undifferenzierten Regulierung aller 
KI-Systeme als die bessere Option betrachtet. Die Festlegung der Art der Risiken und 
Gefahren sollte von den jeweiligen Sektoren und vom Einzelfall abh&#228;ngig gemacht werden 
Bei der Bewertung der Risiken sollte auch deren rechtliche und sicherheitsrelevante 
Auswirkung ber&#252;cksichtigt werden. 
Reallabore k&#246;nnten zur F&#246;rderung von KI sehr n&#252;tzlich sein und werden von einigen 
Interessentr&#228;gern, vor allem Unternehmensverb&#228;nden, begr&#252;&#223;t. 
&#220;ber die H&#228;lfte der Teilnehmer, die zu den Durchsetzungsmodellen Stellung genommen 
haben, insbesondere Unternehmensverb&#228;nde, begr&#252;&#223;en im Falle von Hochrisiko-KI-Systemen 
eine Kombination aus einer Vorab-Selbstbewertung des Risikos und einer Ex-post-
Durchsetzung. 
3.2. Einholung und Nutzung von Expertenwissen 
Der Vorschlag beruht auf in einem Zeitraum von zwei Jahren durchgef&#252;hrten Analysen und 
der engen Einbeziehung von Interessentr&#228;gern, auch von Hochschulen, Unternehmen, 
Sozialpartnern, Nichtregierungsorganisationen, Mitgliedstaaten, B&#252;rgerinnen und B&#252;rgern. 
2018 begannen die vorbereitenden Arbeiten mit der Einsetzung einer hochrangigen 
Expertengruppe f&#252;r KI, die sich aus 52 renommierten Sachverst&#228;ndigen zusammensetzte, 
die ein breites Spektrum abdeckten und deren Aufgabe es war, die Kommission bei der
22 Alle Ergebnisse der Konsultation finden Sie hier.
Umsetzung der Strategie f&#252;r K&#252;nstliche Intelligenz zu beraten. Im April 2019 unterst&#252;tzte die 
Kommission23 die zentralen Anforderungen, die die hochrangige Expertengruppe in ihre 
Ethik-Leitlinien f&#252;r vertrauensw&#252;rdige KI24 aufgenommen hatte und die &#252;berarbeitet worden 
waren, um die &#252;ber 500 Beitr&#228;ge von Interessentr&#228;gern zu ber&#252;cksichtigen. Die zentralen 
Anforderungen sind Ausdruck eines breit gefassten und gemeinsamen Ansatzes, der 
angesichts der F&#252;lle der von vielen privaten und &#246;ffentlichen Organisationen in Europa und 
weltweit entwickelten Ethik-Codes und Ethik-Grunds&#228;tzen darauf hinausl&#228;uft, dass 
Entwicklung und Verwendung von KI von bestimmten wesentlichen werteorientierten 
Grunds&#228;tzen geleitet sein sollten. F&#252;r die praktische Umsetzung dieser Anforderungen im 
Rahmen eines Pilotverfahrens mit &#252;ber 350 Organisationen wurde eine Bewertungsliste f&#252;r 
vertrauensw&#252;rdige k&#252;nstliche Intelligenz (Assessment List for Trustworthy Artificial 
Intelligence, ALTAI)25 erstellt. 
Zudem wurde eine KI-Allianz26 ins Leben gerufen, die etwa 4000 Interessentr&#228;gern die 
M&#246;glichkeit gibt, &#252;ber eine Plattform technologische und gesellschaftliche Aspekte der KI zu 
diskutieren und j&#228;hrlich in einer KI-Versammlung zusammen zu kommen. 
Dieser inklusive Ansatz wurde mit dem Wei&#223;buch zur KI weiterentwickelt, auf das 
Kommentare, darunter &#252;ber 450 Positionspapiere, von &#252;ber 1250 Interessentr&#228;gern eingingen. 
Daraufhin ver&#246;ffentlichte die Kommission eine erste Folgenabsch&#228;tzung, auf die wiederum 
&#252;ber 130 Kommentare eingingen27. Zudem wurden weitere Workshops und 
Veranstaltungen f&#252;r Interessentr&#228;ger organisiert, deren Ergebnisse die Analysen der 
Folgenabsch&#228;tzung und die in diesem Vorschlag getroffene Wahl der politischen Optionen 
unterst&#252;tzen28. Dar&#252;ber hinaus flossen die Ergebnisse einer in Auftrag gegebenen externen 
Studie mit in die Folgenabsch&#228;tzung ein. 
3.3. Folgenabsch&#228;tzung 
Entsprechend ihrer Strategie f&#252;r eine bessere Rechtsetzung f&#252;hrte die Kommission eine 
Folgenabsch&#228;tzung f&#252;r diesen Vorschlag durch, die vom Ausschuss f&#252;r Regulierungskontrolle 
der Kommission gepr&#252;ft wurde. Am 16. Dezember 2020 fand eine Sitzung mit dem 
Ausschuss f&#252;r Regulierungskontrolle statt, der eine ablehnende Stellungnahme abgab. 
Nachdem die Folgenabsch&#228;tzung unter Ber&#252;cksichtigung der Kommentare gr&#252;ndlich 
&#252;berarbeitet und erneut vorgelegt wurde, gab der Ausschuss f&#252;r Regulierungskontrolle am 
21. M&#228;rz 2021 eine bef&#252;rwortende Stellungnahme ab. Die Stellungnahmen des Ausschusses 
f&#252;r Regulierungskontrolle, die Empfehlungen und eine Erl&#228;uterung dazu, inwiefern diese 
Ber&#252;cksichtigung gefunden haben, sind Anhang 1 der Folgenabsch&#228;tzung zu entnehmen. 
Die Kommission pr&#252;fte verschiedene politische Optionen daraufhin, inwieweit sich mit ihnen 
das &#252;bergeordnete Ziel des Vorschlags erreichen l&#228;sst, n&#228;mlich durch Schaffung der 
Voraussetzungen f&#252;r die Entwicklung und Verwendung vertrauensw&#252;rdiger KI in der Union, 
das reibungslose Funktionieren des Binnenmarkts zu gew&#228;hrleisten. 
23 Europ&#228;ische Kommission, Schaffung von Vertrauen in eine auf den Menschen ausgerichtete k&#252;nstliche 
Intelligenz, COM(2019) 168. 
24 HLEG, Ethics Guidelines for Trustworthy AI, 2019. 
25 HLEG, Assessment List for Trustworthy Artificial Intelligence (ALTAI) for self-assessment, 2020.
26 Die KI-Allianz, ein Forum unterschiedlichster Interessentr&#228;ger, wurde 2018 gegr&#252;ndet: 
https://ec.europa.eu/digital-single-market/en/european-ai-alliance. 
27 Europ&#228;ische Kommission, Inception Impact Assessment For a Proposal for a legal act of the European 
Parliament and the Council laying down requirements for Artificial Intelligence.
28 Einzelheiten aller durchgef&#252;hrten Konsultationen sind Anhang 2 der Folgenabsch&#228;tzung zu entnehmen.
Hierzu wurden vier politische Optionen gepr&#252;ft, die regulatorische Ma&#223;nahmen in 
unterschiedlichem Ausma&#223; vorsehen:
&#61623; Option 1: EU-Rechtsetzungsinstrument zur Einrichtung eines Systems zur freiwilligen 
Kennzeichnung; 
&#61623; Option 2: ein sektorspezifischer &#8222;Ad-hoc&#8220;-Ansatz; 
&#61623; Option 3: ein horizontales EU-Rechtsetzungsinstrument gest&#252;tzt auf Verh&#228;ltnism&#228;&#223;igkeit 
und einen risikobasierten Ansatz; 
&#61623; Option 3+: ein horizontales EU-Rechtsetzungsinstrument gest&#252;tzt auf Verh&#228;ltnism&#228;&#223;igkeit 
und einen risikobasierten Ansatz, erg&#228;nzt durch einen Verhaltenskodex f&#252;r KI-Systeme, 
die kein hohes Risiko darstellen; 
&#61623; Option 4: ein horizontales EU-Rechtsetzungsinstrument, mit dem obligatorische 
Anforderungen an alle KI-Systeme, unabh&#228;ngig von dem mit diesen verbundenen Risiko, 
festgelegt werden. 
Nach bew&#228;hrter Methodik der Kommission wurde jede politische Option im Hinblick auf ihre 
wirtschaftlichen und gesellschaftlichen Auswirkungen mit besonderem Augenmerk auf die 
Auswirkungen auf die Grundrechte gepr&#252;ft. Bevorzugt wird die Option 3+, d. h. ein 
Rechtsrahmen ausschlie&#223;lich f&#252;r Hochrisiko-KI-Systeme und die M&#246;glichkeit f&#252;r alle 
Anbieter von KI-Systemen, die kein hohes Risiko darstellen, sich an einen Verhaltenskodex 
zu halten. Die f&#252;r Hochrisiko-KI-Systeme geltenden Anforderungen werden sich auf Daten, 
Dokumentation und R&#252;ckverfolgbarkeit, Bereitstellung von Informationen und Transparenz, 
menschliche Aufsicht sowie Robustheit und Genauigkeit beziehen. Unternehmen k&#246;nnen 
freiwillig Verhaltenskodizes f&#252;r andere KI-Systeme einf&#252;hren. 
Die bevorzugte Option wurde als geeignet erachtet, die Ziele dieses Vorschlags in 
effizientester Weise zu erreichen. Indem KI-Entwickler und KI-Nutzer verpflichtet werden, 
ein begrenztes, aber wirkungsvolles B&#252;ndel von Ma&#223;nahmen zu ergreifen, werden mit der 
bevorzugten Option, bei der gezielte Anforderungen nur f&#252;r solche Systeme gelten, bei denen 
ein hohes Risiko besteht, dass Grundrechte verletzt werden und die Sicherheit von Menschen 
gef&#228;hrdet wird, das Risiko solcher Verst&#246;&#223;e einged&#228;mmt und zudem eine effiziente Aufsicht 
und Durchsetzung unterst&#252;tzt. Die dadurch bei dieser Option minimierten 
Rechtsbefolgungskosten f&#252;hren dazu, dass die Einf&#252;hrung nicht aufgrund h&#246;herer Preise und 
Rechtsbefolgungskosten unn&#246;tigerweise hinausgez&#246;gert wird. Um etwaige Nachteile f&#252;r 
KMU zu vermeiden, umfasst diese Option mehrere Bestimmungen, mit denen KMU nicht nur 
bei der Rechtsbefolgung und Kostenreduzierung, sondern auch bei der Einrichtung von 
Reallaboren unterst&#252;tzt werden, sowie die Pflicht, bei der Festsetzung der Geb&#252;hren f&#252;r die 
Konformit&#228;tsbewertung die Interessen von KMU zu ber&#252;cksichtigen. 
Mit der bevorzugten Option l&#228;sst sich das Vertrauen der Menschen in KI erh&#246;hen, 
Unternehmen haben Rechtssicherheit und die Mitgliedstaaten sehen sich nicht mehr 
veranlasst, einseitig Ma&#223;nahmen zu ergreifen, die zu einer Fragmentierung des Binnenmarkts 
f&#252;hren w&#252;rden. Die mit dem gr&#246;&#223;eren Vertrauen steigende Nachfrage und das infolge der 
Rechtssicherheit gr&#246;&#223;ere Angebot sowie der ungehinderte grenz&#252;berschreitende 
Warenverkehr von KI-Systemen d&#252;rften zu einem florierenden Binnenmarkt f&#252;r KI f&#252;hren. 
Die Europ&#228;ische Union wird die Entwicklung eines schnell wachsenden KI-&#214;kosystems 
innovativer Dienste und Produkte, in die KI-Technologie eingebettet ist, oder eigenst&#228;ndiger 
KI-Systeme weiter vorantreiben, um so die digitale Autonomie zu vergr&#246;&#223;ern. 
Unternehmen oder &#246;ffentliche Stellen, die KI-Anwendungen entwickeln oder verwenden, die 
ein hohes Risiko f&#252;r die Sicherheit oder Grundrechte von B&#252;rgerinnen und B&#252;rgern darstellen,
sind verpflichtet, bestimmte Anforderungen und Verpflichtungen einzuhalten. F&#252;r die 
Einhaltung dieser Anforderungen entstehen bis 2025 f&#252;r die Lieferung eines 
durchschnittlichen Hochrisiko-KI-Systems im Wert von etwa 170 000 EUR Kosten von etwa 
6000 EUR bis 7000 EUR. Abh&#228;ngig von der jeweiligen Anwendung fallen f&#252;r KI-Nutzer 
gegebenenfalls zudem die j&#228;hrlichen Kosten f&#252;r die Zeit an, die f&#252;r die menschliche Aufsicht 
aufgewandt werden muss. Diese wurden mit etwa 5000 EUR bis 8000 EUR pro Jahr 
veranschlagt. F&#252;r Lieferanten von Hochrisiko-KI k&#246;nnten zudem &#220;berpr&#252;fungskosten in 
H&#246;he von 3000 EUR bis 7500 EUR anfallen. Unternehmen oder &#246;ffentliche Stellen, die nicht 
als hochriskant eingestufte KI-Anwendungen entwickeln oder nutzen, h&#228;tten nur eine 
minimale Informationspflicht. Sie k&#246;nnten sich jedoch entscheiden, mit anderen gemeinsam 
einen Verhaltenskodex &#252;ber die Einhaltung geeigneter Anforderungen festzulegen und daf&#252;r 
zu sorgen, dass ihre KI-Systeme vertrauensw&#252;rdig sind. In diesem Fall w&#252;rden sich die 
Kosten h&#246;chstens auf dem Niveau f&#252;r Hochrisiko-KI-Systeme bewegen, wahrscheinlich 
jedoch darunter. 
Welche Auswirkungen die politischen Optionen auf die verschiedenen Kategorien von 
Interessentr&#228;gern haben (Wirtschaftsakteure/Unternehmen, Konformit&#228;tsbewertungsstellen, 
Normungsgremien und sonstige &#246;ffentliche Gremien, Privatpersonen/B&#252;rgerinnen und 
B&#252;rger, Forschung), wird im Einzelnen in Anhang 3 der Folgenabsch&#228;tzung in der Anlage zu 
diesem Vorschlag erl&#228;utert. 
3.4. Effizienz der Rechtsetzung und Vereinfachung 
Dieser Vorschlag enth&#228;lt die Pflichten f&#252;r Anbieter und Nutzer von Hochrisiko-KI-Systemen. 
Anbieter, die solche Systeme entwickeln und in der Union in Verkehr bringen, erhalten 
Rechtssicherheit und die Gewissheit, dass bei der grenz&#252;berschreitenden Bereitstellung von 
Diensten und Produkten im Zusammenhang mit KI keine Hindernisse auftauchen. Kunden 
werden gr&#246;&#223;eres Vertrauen in die von Unternehmen eingesetzte KI haben. Nationale 
&#246;ffentliche Verwaltungen werden vom gestiegenen Vertrauen der &#214;ffentlichkeit in die 
Verwendung von KI und den gest&#228;rkten Durchsetzungsmechanismen profitieren (durch die 
Einf&#252;hrung eines europ&#228;ischen Koordinierungsmechanismus, die Bereitstellung angemessener 
Kapazit&#228;ten und die Erleichterung von Audits der KI-Systeme durch neue Anforderungen an 
die Dokumentation, R&#252;ckverfolgbarkeit und Transparenz). Dar&#252;ber hinaus zielt der 
Rechtsrahmen auf innovationsspezifische Ma&#223;nahmen, beispielsweise Reallabore und 
konkrete Ma&#223;nahmen ab, mit denen Kleinnutzer und Kleinanbieter von Hochrisiko-KI-
Systemen darin unterst&#252;tzt werden, die neuen Vorschriften einzuhalten. 
Der Vorschlag zielt zudem speziell auf die St&#228;rkung der europ&#228;ischen Wettbewerbsf&#228;higkeit 
und Industriebasis im Bereich der KI ab. Die Koh&#228;renz mit bestehenden sektorspezifischen 
Unionsvorschriften f&#252;r KI-Systeme (z. B. f&#252;r Produkte und Dienste) ist gew&#228;hrleistet, was zu 
gr&#246;&#223;erer Klarheit f&#252;hrt und die Durchsetzung der neuen Vorschriften erleichtert. 
3.5. Grundrechte
Durch ihre besonderen Merkmale (z. B. Undurchsichtigkeit, Komplexit&#228;t, Datenabh&#228;ngigkeit, 
autonomes Verhalten) kann die Verwendung von KI dazu f&#252;hren, dass einige der in der EU-
Grundrechtecharta (im Folgenden die &#8222;Charta&#8220;) verankerten Grundrechte verletzt werden. 
Der Vorschlag zielt darauf ab, diese Grundrechte in hohem Ma&#223;e zu sch&#252;tzen und durch einen 
klar festgelegten risikobasierten Ansatz verschiedene Ursachen f&#252;r Risiken anzugehen. Alle 
an der Wertsch&#246;pfungskette Beteiligten unterliegen einer Reihe von Anforderungen an 
vertrauensw&#252;rdige KI und verh&#228;ltnism&#228;&#223;igen Pflichten, damit die durch die Charta 
gesch&#252;tzten Rechte noch st&#228;rker gesch&#252;tzt werden: die W&#252;rde des Menschen (Artikel 1), die 
Achtung des Privatlebens und der Schutz personenbezogener Daten (Artikel 7 und 8), die 
Nichtdiskriminierung (Artikel 21) und die Gleichheit von Frauen und M&#228;nnern (Artikel 23).
Mit dem Vorschlag soll verhindert werden, dass Menschen davor zur&#252;ckschrecken, ihr Recht 
auf Meinungsfreiheit (Artikel 11) und auf Versammlungs- und Vereinigungsfreiheit 
(Artikel 12) auszu&#252;ben, und sichergestellt werden, dass das Recht auf einen wirksamen 
Rechtsbehelf und ein unparteiisches Gericht und die Unschuldsvermutung und 
Verteidigungsrechte (Artikel 47 und 48) sowie der allgemeine Grundsatz guter Verwaltung 
gewahrt werden. Zudem wird sich der Vorschlag in bestimmten Bereichen positiv auf einige 
gruppenspezifische Rechte auswirken, beispielsweise auf das Recht der Arbeitnehmer auf 
gerechte und angemessene Arbeitsbedingungen (Artikel 31), den Verbraucherschutz 
(Artikel 28), die Rechte des Kindes (Artikel 24) und die Integration von Menschen mit 
Behinderung (Artikel 26). Dar&#252;ber hinaus geht es um das Recht auf ein hohes 
Umweltschutzniveau und die Verbesserung der Umweltqualit&#228;t (Artikel 37), auch in Bezug 
auf die Gesundheit und Sicherheit von Menschen. Die Verpflichtung zu Vorabtests, 
Risikomanagement und menschlicher Aufsicht werden die Achtung auch anderer Grundrechte 
erleichtern, da sich so das Risiko, in kritischen Bereichen wie Bildung, Ausbildung, 
Besch&#228;ftigung, wichtige Dienste, Strafverfolgung und Justiz mithilfe der KI falsche oder 
verzerrte Entscheidungen zu treffen, verringern l&#228;sst. Sollten Grundrechte trotzdem noch 
verletzt werden, werden die betroffenen Personen die M&#246;glichkeit haben, wirksame 
Rechtsmittel einzulegen, da f&#252;r Transparenz und R&#252;ckverfolgbarkeit der KI-Systeme im 
Verbund mit starken Ex-post-Kontrollen gesorgt ist. 
Mit dem Vorschlag werden der unternehmerischen Freiheit (Artikel 16) und der Freiheit der 
Kunst und der Wissenschaft (Artikel 13) einige Beschr&#228;nkungen auferlegt, um Koh&#228;renz mit 
der &#252;bergeordneten Begr&#252;ndung des &#246;ffentlichen Interesses herzustellen. Hierunter fallen 
beispielsweise Gesundheit, Sicherheit, Verbraucherschutz und der Schutz anderer 
Grundrechte (&#8222;verantwortungsvolle Innovation&#8220;) bei der Entwicklung und Verwendung von 
Hochrisiko-KI-Technik. Diese Beschr&#228;nkungen sind verh&#228;ltnism&#228;&#223;ig und auf das notwendige 
Minimum beschr&#228;nkt, um schwerwiegende Sicherheitsrisiken und m&#246;gliche Verletzungen der 
Grundrechte zu verhindern und abzumildern. 
Auch die Pflicht zu gr&#246;&#223;erer Transparenz wird das Recht auf Schutz des geistigen Eigentums 
(Artikel 17 Absatz 2) nicht unverh&#228;ltnism&#228;&#223;ig beeintr&#228;chtigen, da sie auf die 
Mindestinformationen beschr&#228;nkt ist, die eine Person ben&#246;tigt, um ihr Recht auf einen 
wirksamen Rechtsbehelf auszu&#252;ben, sowie auf die Transparenz, die Aufsichts- und 
Durchsetzungsbeh&#246;rden im Rahmen ihrer Aufgaben ben&#246;tigen. Jede Offenlegung von 
Informationen erfolgt unter Einhaltung der einschl&#228;gigen Rechtsvorschriften, auch der 
Richtlinie (EU) 2016/943 &#252;ber den Schutz vertraulichen Know-hows und vertraulicher 
Gesch&#228;ftsinformationen (Gesch&#228;ftsgeheimnisse) vor rechtswidrigem Erwerb sowie 
rechtswidriger Nutzung und Offenlegung. Ben&#246;tigen &#246;ffentliche und notifizierte Stellen f&#252;r 
die Pr&#252;fung der Einhaltung der wesentlichen Pflichten Zugang zu vertraulichen Informationen 
oder zu Quellcodes, sind sie zur Wahrung der Vertraulichkeit verpflichtet.
4. AUSWIRKUNGEN AUF DEN HAUSHALT
Die Mitgliedstaaten m&#252;ssen die f&#252;r die Durchf&#252;hrung der rechtlichen Anforderungen 
zust&#228;ndigen Aufsichtsbeh&#246;rden benennen. Deren Aufsichtsfunktion k&#246;nnte sich auf 
bestehende Vereinbarungen st&#252;tzen, beispielsweise in Bezug auf die 
Konformit&#228;tsbewertungsstellen oder die Markt&#252;berwachung, was jedoch ausreichende 
technische Kenntnisse sowie personelle und finanzielle Ressourcen erforderlich macht. 
Abh&#228;ngig von der in jedem Mitgliedstaat bereits vorhandenen Struktur kann sich dies auf 1 
bis 25 Vollzeit&#228;quivalente je Mitgliedstaat belaufen.
Ein detaillierter &#220;berblick &#252;ber die anfallenden Kosten ist dem Finanzbogen im Anhang zu 
diesem Vorschlag zu entnehmen.
5. WEITERE ANGABEN 
5.1. Durchf&#252;hrungspl&#228;ne sowie &#220;berwachungs-, Bewertungs- und 
Berichterstattungsmodalit&#228;ten 
Damit mit dem Vorschlag dessen konkrete Ziele auch wirksam erreicht werden k&#246;nnen, 
kommt es auf einen robusten Beobachtungs- und Bewertungsmechanismus an. Der 
Kommission obliegt die Beobachtung der Auswirkungen der vorgeschlagenen 
Bestimmungen. Sie wird ein System aufbauen, das es erm&#246;glicht, eigenst&#228;ndige Hochrisiko-
KI-Anwendungen in einer &#246;ffentlichen, unionsweiten Datenbank zu registrieren. Anhand 
dieser Registrierung werden zust&#228;ndige Beh&#246;rden, Nutzer und sonstige Interessierte 
&#252;berpr&#252;fen k&#246;nnen, ob ein betreffendes Hochrisiko-KI-System die in dem Vorschlag 
festgelegten Anforderungen erf&#252;llt, und f&#252;r solche KI-Systeme, die ein hohes Risiko f&#252;r die 
Einhaltung der Grundrechte darstellen, kann eine verst&#228;rkte Aufsicht ausge&#252;bt werden. KI-
Anbieter werden verpflichtet sein, bei ihren Eingaben in diese Datenbank aussagekr&#228;ftige 
Angaben zu ihren Systemen und zur f&#252;r diese Systeme durchgef&#252;hrten 
Konformit&#228;tsbewertung zu machen. 
Zudem werden KI-Anbieter verpflichtet, die nationalen zust&#228;ndigen Beh&#246;rden zu informieren, 
sobald sie Kenntnis &#252;ber schwerwiegende Vorf&#228;lle oder Fehlfunktionen erlangen, die eine 
Verletzung der Pflicht zur Wahrung der Grundrechte darstellen, sowie &#252;ber jeden R&#252;ckruf 
oder jede R&#252;cknahme von KI-Systemen vom Markt. Es ist dann Aufgabe der nationalen 
Beh&#246;rden, den Vorfall oder die Fehlfunktion zu untersuchen, alle notwendigen Informationen 
zu sammeln und der Kommission zusammen mit den geeigneten Metadaten zu &#252;bermitteln. 
Die Kommission wird die Informationen zu den Vorf&#228;llen durch eine umfassende Analyse 
des KI-Markts insgesamt erg&#228;nzen. 
F&#252;nf Jahre nach dem Zeitpunkt, nach dem der vorgeschlagene KI-Rechtsrahmen anwendbar 
wird, wird die Kommission einen Bericht ver&#246;ffentlichen, in dem sie den vorgeschlagenen 
KI-Rechtsrahmen bewertet und &#252;berpr&#252;ft. 
5.2. Ausf&#252;hrliche Erl&#228;uterung einzelner Bestimmungen des Vorschlags 
5.2.1. ANWENDUNGSBEREICH UND BEGRIFFSBESTIMMUNGEN (TITEL I) 
Titel I enth&#228;lt den Gegenstand der Verordnung und den Anwendungsbereich der neuen 
Vorschriften f&#252;r das Inverkehrbringen, die Inbetriebnahme und die Verwendung von KI-
Systemen. Er enth&#228;lt auch die Begriffsbestimmungen, die in diesem Rechtsinstrument 
durchweg verwendet werden. Ziel der in diesem Rechtsrahmen festgelegten 
Begriffsbestimmung f&#252;r KI-Systeme ist es, so technologieneutral und zukunftstauglich wie 
m&#246;glich zu sein und den rasanten Entwicklungen in der KI-Technologie und auf dem KI-
Markt Rechnung zu tragen. Damit die notwendige Rechtssicherheit gegeben ist, wird Titel I 
durch Anhang I erg&#228;nzt, in dem Konzepte und Techniken f&#252;r die KI-Entwicklung detailliert 
aufgef&#252;hrt sind und von der Kommission in dem Umfang angepasst werden, wie sich neue 
technologische Entwicklungen ergeben. Im Sinne gleicher Wettbewerbsbedingungen werden 
auch die wichtigsten Beteiligten &#252;ber die gesamte KI-Wertsch&#246;pfungskette hinweg klar 
benannt, wie beispielsweise die Anbieter und Nutzer von KI-Systemen, bei denen es sich 
sowohl um &#246;ffentliche als auch um private Akteure handeln kann.
5.2.2. VERBOTENE PRAKTIKEN IM BEREICH DER K&#220;NSTLICHEN INTELLIGENZ 
(TITEL II) 
Titel II enth&#228;lt eine Liste verbotener KI-Praktiken. Die Verordnung verfolgt einen 
risikobasierten Ansatz, bei dem zwischen Anwendungen von KI unterschieden wird, die ein i) 
unannehmbares Risiko, ii) ein hohes Risiko und iii) ein geringes oder minimales Risiko 
darstellen. Die Aufstellung der verbotenen Praktiken in Titel II umfasst alle KI-Systeme, die 
als unannehmbar gelten, weil sie Werte der Union, beispielsweise Grundrechte, verletzen. Die 
Verbote gelten f&#252;r Praktiken, die ein erhebliches Potenzial haben, Personen zu manipulieren, 
indem sie auf Techniken zur unterschwelligen Beeinflussung zur&#252;ckgreifen, die von diesen 
Personen nicht bewusst wahrgenommen werden, oder die die Schw&#228;chen bestimmter 
schutzbed&#252;rftiger Gruppen wie Kinder oder Personen mit Behinderungen ausnutzen, um 
deren Verhalten massiv so zu beeinflussen, dass sie selbst oder eine andere Person psychisch 
oder physisch gesch&#228;digt werden k&#246;nnten. Andere manipulative oder ausbeuterische 
Praktiken, die Erwachsene betreffen und m&#246;glicherweise durch KI-Systeme erleichtert 
werden, k&#246;nnten unter die bestehenden Rechtsvorschriften f&#252;r den Datenschutz, 
Verbraucherschutz und digitale Dienste fallen, auf deren Grundlage nat&#252;rliche Personen 
Anspruch auf angemessene Informationen haben und es ihnen freisteht, Profiling- oder andere 
Praktiken, die Einfluss auf ihr Verhalten haben k&#246;nnten, abzulehnen. Der Vorschlag sieht 
auch vor, die Bewertung des sozialen Verhaltens f&#252;r allgemeine Zwecke mithilfe von KI 
durch &#246;ffentliche Beh&#246;rden (&#8222;Social Scoring&#8220;) zu verbieten. Schlie&#223;lich soll der Einsatz von 
biometrischen Echtzeit-Fernidentifizierungssystemen in &#246;ffentlich zug&#228;nglichen R&#228;umen f&#252;r 
die Zwecke der Strafverfolgung bis auf wenige Ausnahmen verboten werden. 
5.2.3. HOCHRISIKO-KI-SYSTEME (TITEL III) 
Titel III enth&#228;lt spezifische Vorschriften f&#252;r KI-Systeme, die ein hohes Risiko f&#252;r die 
Gesundheit und Sicherheit oder f&#252;r die Grundrechte nat&#252;rlicher Personen darstellen. 
Entsprechend dem risikobasierten Ansatz sind solche Hochrisiko-KI-Systeme auf dem 
europ&#228;ischen Markt zugelassen, sofern sie bestimmten zwingend vorgeschriebenen 
Anforderungen gen&#252;gen und vorab eine Konformit&#228;tsbewertung durchgef&#252;hrt wird. Die 
Einstufung als Hochrisiko-KI-System beruht auf der Zweckbestimmung des KI-Systems 
entsprechend den bestehenden EU-Produktsicherheitsvorschriften. Damit h&#228;ngt die 
Einstufung als Hochrisiko-KI-System nicht nur von der Funktion dieses Systems ab, sondern 
auch von seinem konkreten Zweck und seinen Anwendungsmodalit&#228;ten. 
In Titel III Kapitel 1 sind die Einstufungsregeln angegeben und zwei Hauptkategorien f&#252;r 
Hochrisiko-KI-Systeme festgelegt: 
&#61623; KI-Systeme, die als Sicherheitskomponenten von Produkten, die einer Vorab-
Konformit&#228;tsbewertung durch Dritte unterliegen, verwendet werden sollen; 
&#61623; sonstige eigenst&#228;ndige KI-Systeme, die ausdr&#252;cklich in Anhang III genannt werden und 
sich vor allem auf die Grundrechte auswirken.
Die in Anhang III aufgef&#252;hrte Liste der Hochrisiko-KI-Systeme enth&#228;lt einige KI-Systeme, 
bei denen sich bereits gezeigt hat oder bei denen absehbar ist, dass die Risiken tats&#228;chlich 
eintreten. Damit die Verordnung an neue Verwendungszwecke und Anwendungen von KI 
angepasst werden kann, hat die Kommission die M&#246;glichkeit, die Liste der Hochrisiko-KI-
Systeme, die in bestimmten festgelegten Bereichen verwendet werden, mithilfe einer Reihe 
von Kriterien und einer Methodik f&#252;r die Risikoabsch&#228;tzung auszuweiten. 
In Kapitel 2 ist festgelegt, welche rechtlichen Anforderungen Hochrisiko-KI-Systeme in 
Bezug auf Daten, Daten-Governance, Dokumentation und das F&#252;hren von Aufzeichnungen, 
Transparenz und Bereitstellung von Informationen f&#252;r die Nutzer, menschliche Aufsicht,
Robustheit, Genauigkeit und Sicherheit erf&#252;llen m&#252;ssen. Die vorgeschlagenen 
Mindestanforderungen, die sich aus den von &#252;ber 350 Organisationen29 erprobten Ethik-
Leitlinien der HEG30 ableiten, sind bereits g&#228;ngige Praxis f&#252;r viele gewissenhaften Akteure 
und das Ergebnis der Vorarbeiten der letzten zwei Jahre. Sie stimmen auch weitestgehend mit 
anderen internationalen Empfehlungen und Grunds&#228;tzen &#252;berein, wodurch sichergestellt wird, 
dass der vorgeschlagene KI-Rahmen mit den Vorgaben &#252;bereinstimmt, die von den 
internationalen Handelspartnern der EU festgelegt wurden. Es liegt im Ermessen des 
Anbieters des jeweiligen KI-Systems, mit welchen technischen L&#246;sungen er die Einhaltung 
dieser Anforderungen konkret erreicht &#8211; sei es durch Normen oder sonstige technische 
Spezifikationen oder durch andere Entwicklungen entsprechend dem allgemeinen 
wissenschaftlich-technischen Know-how. Diese Flexibilit&#228;t ist besonders wichtig, denn sie 
erm&#246;glicht es den Anbietern von KI-Systemen, unter Ber&#252;cksichtigung des Stands der 
Technik und des wissenschaftlich-technischen Fortschritts auf dem Gebiet selbst zu 
entscheiden, wie sie die f&#252;r sie geltenden Anforderungen zu erf&#252;llen beabsichtigen. 
Kapitel 3 enth&#228;lt eine Reihe klarer horizontaler Pflichten f&#252;r Anbieter von Hochrisiko-KI-
Systemen. Auch f&#252;r Nutzer und andere Beteiligte entlang der KI-Wertsch&#246;pfungskette (z. B. 
Einf&#252;hrer, H&#228;ndler, Bevollm&#228;chtigte) gelten verh&#228;ltnism&#228;&#223;ige Pflichten. 
Kapitel 4 bildet den Rahmen f&#252;r die Einbeziehung notifizierter Stellen als unabh&#228;ngige Dritte 
in die Konformit&#228;tsbewertungsverfahren, w&#228;hrend in Kapitel 5 die je nach Art des 
Hochrisiko-KI-Systems einzuhaltenden Konformit&#228;tsbewertungsverfahren im Einzelnen 
erl&#228;utert werden. Mit dem Konzept der Konformit&#228;tsbewertung sollen die Belastungen f&#252;r die 
Wirtschaftsakteure und notifizierten Stellen, deren Kapazit&#228;t mit der Zeit schrittweise 
hochgefahren werden muss, m&#246;glichst gering gehalten werden. KI-Systeme, die als 
Sicherheitskomponenten von Produkten eingesetzt werden sollen, die unter die einschl&#228;gigen 
Rechtsvorschriften des neuen Rechtsrahmens fallen (z. B. Maschinen, Spielzeug, 
medizinische Ger&#228;te), unterliegen denselben Ex-ante- und Ex-post-Mechanismen f&#252;r die 
Rechtsbefolgung und Durchsetzung wie das Produkt, dessen Komponente sie sind. Der 
wesentliche Unterschied liegt darin, dass die Ex-ante- und Ex-post-Mechanismen nicht nur 
die Einhaltung der durch sektorspezifische Vorschriften vorgegebenen Anforderungen 
gew&#228;hrleisten, sondern auch die Einhaltung der in dieser Verordnung festgelegten 
Anforderungen. 
F&#252;r die eigenst&#228;ndigen Hochrisiko-KI-Systeme, auf die in Anhang III verwiesen wird, wird 
ein neues Rechtsbefolgungs- und Durchsetzungssystem festgelegt. Dies entspricht dem 
Muster des neuen Rechtsrahmens, bei dem die einschl&#228;gigen Rechtsvorschriften durch interne 
Kontrollpr&#252;fungen des Anbieters umgesetzt werden. Ausgenommen hiervon sind die 
biometrischen Fernidentifizierungssysteme, die einer Konformit&#228;tsbewertung durch Dritte 
unterliegen. Eine umfassende Ex-ante-Konformit&#228;tsbewertung mittels interner Pr&#252;fungen 
k&#246;nnte in Kombination mit einer soliden Ex-post-Durchsetzung eine wirksame und sinnvolle 
L&#246;sung f&#252;r solche Systeme darstellen, zumal sich die Regulierung noch in der Anfangsphase 
befindet und in dem &#228;u&#223;erst innovativen KI-Sektor Auditing-Erfahrungen erst jetzt gesammelt 
werden. Damit eigenst&#228;ndige Hochrisiko-KI-Systeme mittels interner Pr&#252;fungen bewertet 
werden k&#246;nnen, muss die Einhaltung aller Anforderungen der Verordnung vorab vollst&#228;ndig, 
wirkungsvoll und sorgf&#228;ltig dokumentiert werden, ferner gilt es, robuste Qualit&#228;ts- und 
Risikomanagementsysteme zu befolgen und eine Beobachtung nach dem Inverkehrbringen zu
29 Sie wurden auch von der Kommission in ihrer Mitteilung aus dem Jahr 2019 zu einem auf den 
Menschen ausgerichteten Ansatz f&#252;r KI gebilligt. 
30 Hochrangige Expertengruppe f&#252;r k&#252;nstliche Intelligenz, Ethics Guidelines for Trustworthy AI (Ethik-
Leitlinien f&#252;r eine vertrauensw&#252;rdige KI), 2019.
gew&#228;hrleisten. Sobald ein Anbieter die jeweilige Konformit&#228;tsbewertung durchgef&#252;hrt hat, 
sollte er diese eigenst&#228;ndigen Hochrisiko-KI-Systeme in eine von der Kommission verwaltete 
EU-Datenbank eintragen, um so die Transparenz gegen&#252;ber der &#214;ffentlichkeit zu erh&#246;hen und 
die Aufsicht sowie die Ex-post-&#220;berwachung durch die zust&#228;ndigen Beh&#246;rden zu st&#228;rken. 
Aus Gr&#252;nden der Koh&#228;renz mit den bestehenden Produktsicherheitsvorschriften wird bei KI-
Systemen, bei denen es sich um Sicherheitskomponenten von Produkten handelt, hingegen 
das System der Konformit&#228;tsbewertungsverfahren durch Dritte verfolgt, das sich bereits im 
Rahmen der einschl&#228;gigen sektorspezifischen Produktsicherheitsvorschriften bew&#228;hrt hat. Bei 
wesentlichen &#196;nderungen der KI-Systeme (vor allem bei &#196;nderungen, die &#252;ber die 
Festlegungen des Anbieters in seiner technischen Dokumentation sowie &#252;ber das 
hinausgehen, was zum Zeitpunkt der Ex-ante-Konformit&#228;tsbewertung gepr&#252;ft wurde), muss 
vorab eine erneute Konformit&#228;tsbewertung durchgef&#252;hrt werden. 
5.2.4. TRANSPARENZPFLICHTEN F&#220;R BESTIMMTE KI-SYSTEME (TITEL VI) 
Titel IV befasst sich mit spezifischen Manipulationsrisiken bestimmter KI-Systeme. 
Transparenzpflichten gelten f&#252;r Systeme, die i) mit Menschen interagieren, ii) zur Erkennung 
von Emotionen oder zur Assoziierung (gesellschaftlicher) Kategorien anhand biometrischer 
Daten eingesetzt werden oder iii) Inhalte erzeugen oder manipulieren (&#8222;Deepfakes&#8220;). 
Interagieren Personen mit KI-Systemen oder werden deren Emotionen oder Merkmale durch 
automatisierte Mittel erkannt, m&#252;ssen die Menschen hier&#252;ber informiert werden. Wird ein KI-
System eingesetzt, um Bild-, Audio- oder Video-Inhalte zu erzeugen oder zu manipulieren, 
sodass sie von authentischen Inhalten kaum zu unterscheiden sind, sollte, abgesehen von 
legitimen Zwecken (wie Strafverfolgung, Meinungsfreiheit), die Pflicht zur Offenlegung der 
Tatsache vorgeschrieben werden, dass der Inhalt durch automatisierte Mittel erzeugt wurde. 
So k&#246;nnen bewusste Entscheidungen getroffen oder bestimmte Situationen vermieden 
werden. 
5.2.5. MA&#7838;NAHMEN ZUR INNOVATIONSF&#214;RDERUNG (TITEL V) 
Titel V wurde im Hinblick auf das Ziel aufgenommen, einen innovationsfreundlichen, 
zukunftstauglichen und widerstandsf&#228;higen Rechtsrahmen zu schaffen. Hierzu werden die 
nationalen zust&#228;ndigen Beh&#246;rden aufgefordert, Reallabore einzurichten und die 
grundlegenden Bedingungen f&#252;r die Leitung, Aufsicht und Haftung festzulegen. KI-
Reallabore bieten, auf der Grundlage eines mit den zust&#228;ndigen Beh&#246;rden vereinbarten 
Testplans, f&#252;r eine begrenzte Zeit kontrollierte Testumgebungen f&#252;r innovative Technologien. 
Titel V enth&#228;lt zudem Ma&#223;nahmen zur Reduzierung des Verwaltungsaufwands f&#252;r KMU und 
Start-ups. 
5.2.6. LEITUNG UND DURCHF&#220;HRUNG (TITEL VI, VII UND VII) 
Titel VI enth&#228;lt Vorgaben f&#252;r die Leitungsstrukturen auf Unionsebene und nationaler Ebene. 
Der Vorschlag sieht die Einrichtung eines Europ&#228;ischen Ausschusses f&#252;r k&#252;nstliche 
Intelligenz (im Folgenden der &#8222;Ausschuss&#8220;) auf Unionsebene vor, der sich aus Vertretern der 
Mitgliedstaaten und der Kommission zusammensetzt. Der Ausschuss soll zu einer wirksamen 
Zusammenarbeit der nationalen Aufsichtsbeh&#246;rden und der Kommission beitragen und so 
eine reibungslose, wirksame und harmonisierte Durchf&#252;hrung dieser Verordnung erleichtern 
und dar&#252;ber hinaus die Kommission fachlich beraten. Ferner soll der Ausschuss bew&#228;hrte 
Verfahrensweise aus den Mitgliedstaaten sammeln und weitergeben. 
Auf nationaler Ebene werden die Mitgliedstaaten eine oder mehrere nationale zust&#228;ndige 
Beh&#246;rden (darunter die nationale Aufsichtsbeh&#246;rde) benennen m&#252;ssen, die die Anwendung 
und Durchf&#252;hrung der Verordnung &#252;berwachen. Der Europ&#228;ische Datenschutzbeauftragte gilt
als zust&#228;ndige Beh&#246;rde f&#252;r die Aufsicht &#252;ber die Organe, Einrichtungen und sonstigen Stellen 
der Union, die in den Anwendungsbereich dieser Verordnung fallen. 
Titel VII soll durch die Einrichtung einer unionsweiten Datenbank f&#252;r eigenst&#228;ndige 
Hochrisiko-KI-Systeme, die sich vor allem auf die Grundrechte auswirken, der Kommission 
und den nationalen Beh&#246;rden die Beobachtungsaufgaben erleichtern. Die Datenbank wird von 
der Kommission betrieben. Gespeist wird sie durch die Anbieter der KI-Systeme, die ihre 
Systeme registrieren m&#252;ssen, bevor sie sie in Verkehr bringen oder anderweitig in Betrieb 
nehmen k&#246;nnen.
Titel VIII enth&#228;lt die Beobachtungs- und Meldepflichten f&#252;r die Anbieter von KI-Systemen 
im Hinblick auf die Beobachtung nach dem Inverkehrbringen sowie die Meldung und 
Untersuchung von Vorf&#228;llen und Fehlfunktionen im KI-Zusammenhang. Auch die 
Markt&#252;berwachungsbeh&#246;rden werden den Markt kontrollieren und die Einhaltung der mit 
allen bereits in Verkehr gebrachten Hochrisiko-KI-Systemen verbundenen Pflichten und 
Anforderungen pr&#252;fen. Die Markt&#252;berwachungsbeh&#246;rden werden mit allen in der Verordnung 
(EU) 2019/1020 &#252;ber die Markt&#252;berwachung festgelegten Befugnissen ausgestattet. Die
Expost-Durchsetzung soll sicherstellen, dass &#246;ffentliche Beh&#246;rden &#252;ber die Befugnisse und 
Ressourcen verf&#252;gen, damit sie, eingreifen k&#246;nnen, sollten sich bei bereits in Verkehr 
gebrachten KI-Systemen unerwartete Risiken ergeben, die ein rasches Handeln erfordern. 
Dar&#252;ber hinaus werden sie darauf achten, dass die Akteure ihren in der Verordnung 
festgelegten Pflichten nachkommen. Der Vorschlag sieht nicht die automatische Schaffung 
weiterer Gremien oder Beh&#246;rden auf Ebene der Mitgliedstaaten vor. Die Mitgliedstaaten 
k&#246;nnen sich daher auf bereits vorhandene sektorspezifische Beh&#246;rden und deren 
Fachkenntnisse st&#252;tzen, denen die Befugnisse zur Beobachtung und Durchsetzung der 
Bestimmungen dieser Verordnung &#252;bertragen werden. 
All dies geschieht unbeschadet der in den Mitgliedstaaten bereits vorhandenen Systeme und 
Zuweisung von Befugnissen f&#252;r die Ex-post-Durchsetzung der Pflichten in Bezug auf die 
Grundrechte. Sofern dies f&#252;r die Wahrnehmung ihrer Aufgaben notwendig ist, werden die 
bestehenden Aufsichts- und Durchsetzungsbeh&#246;rden auch befugt sein, Unterlagen, die auf der 
Grundlage dieser Verordnung aufbewahrt werden, anzufordern oder Zugang zu diesen 
Unterlagen zu erhalten, sowie gegebenenfalls Markt&#252;berwachungsbeh&#246;rden aufzufordern, das 
Hochrisiko-KI-System mit technischen Mitteln zu pr&#252;fen. 
5.2.7. VERHALTENSKODIZES (TITEL IX) 
Titel IX enth&#228;lt die Grundlagen zur Schaffung von Verhaltenskodizes, die Anbietern von KI-
Systemen, die kein hohes Risiko darstellen, Anreize geben sollen, die zwingend 
vorgeschriebenen Anforderungen an Hochrisiko-KI-Systeme (nach Titel III) freiwillig 
anzuwenden. Anbieter von KI-Systemen, die kein hohes Risiko darstellen, k&#246;nnen selbst 
Verhaltenskodizes festlegen und umsetzen. Diese Kodizes k&#246;nnen auch freiwillige 
Verpflichtungen beispielsweise im Hinblick auf die &#246;kologische Nachhaltigkeit, den Zugang 
f&#252;r Personen mit Behinderungen, die Beteiligung von Interessentr&#228;gern an Entwurf und 
Entwicklung von KI-Systemen sowie die Diversit&#228;t des Entwicklungsteams enthalten. 
5.2.8. SCHLUSSBESTIMMUNGEN (TITEL X, XI UND XII) 
Titel X unterstreicht, dass alle Parteien verpflichtet sind, die Vertraulichkeit der 
Informationen und Daten zu wahren, und enth&#228;lt Vorschriften f&#252;r den Austausch von w&#228;hrend 
der Durchf&#252;hrung der Verordnung erworbenen Informationen. Titel X enth&#228;lt auch 
Ma&#223;nahmen, mit denen durch wirksame, verh&#228;ltnism&#228;&#223;ige und abschreckende Strafen bei 
Verst&#246;&#223;en gegen die Bestimmungen eine effiziente Durchf&#252;hrung der Verordnung 
gew&#228;hrleistet werden soll.
Titel XI enth&#228;lt die Regeln f&#252;r die Aus&#252;bung der Befugnis&#252;bertragung und der 
Durchf&#252;hrungsbefugnisse. Der Vorschlag sieht vor, dass der Kommission die Befugnis 
&#252;bertragen wird, zur Gew&#228;hrleistung einer einheitlichen Anwendung der Verordnung 
gegebenenfalls Durchf&#252;hrungsrechtsakte oder zur Aktualisierung oder Erg&#228;nzung der Listen 
in den Anh&#228;ngen I bis VII delegierte Rechtsakte zu erlassen. 
Titel XII enth&#228;lt die Pflicht der Kommission, regelm&#228;&#223;ig zu bewerten, ob Anhang III 
aktualisiert werden muss, und regelm&#228;&#223;ig Berichte &#252;ber die Bewertung und &#220;berpr&#252;fung der 
Verordnung vorzulegen. Der Titel enth&#228;lt zudem die Schlussbestimmungen, einschlie&#223;lich 
einer differenzierten &#220;bergangsfrist mit Blick auf das Datum, ab dem die Verordnung 
Anwendung findet, um allen Parteien eine reibungslose Durchf&#252;hrung zu erleichtern.
2021/0106 (COD) 
Vorschlag f&#252;r eine 
VERORDNUNG DES EUROP&#196;ISCHEN PARLAMENTS UND DES RATES
ZUR FESTLEGUNG HARMONISIERTER VORSCHRIFTEN F&#220;R K&#220;NSTLICHE 
INTELLIGENZ (GESETZ &#220;BER K&#220;NSTLICHE INTELLIGENZ) UND ZUR 
&#196;NDERUNG BESTIMMTER RECHTSAKTE DER UNION
DAS EUROP&#196;ISCHE PARLAMENT UND DER RAT DER EUROP&#196;ISCHEN UNION - 
gest&#252;tzt auf den Vertrag &#252;ber die Arbeitsweise der Europ&#228;ischen Union, insbesondere auf die 
Artikel 16 und 114, 
auf Vorschlag der Europ&#228;ischen Kommission, 
nach Zuleitung des Entwurfs des Gesetzgebungsakts an die nationalen Parlamente, 
nach Stellungnahme des Europ&#228;ischen Wirtschafts- und Sozialausschusses31, 
nach Stellungnahme des Ausschusses der Regionen32, 
gem&#228;&#223; dem ordentlichen Gesetzgebungsverfahren, 
in Erw&#228;gung nachstehender Gr&#252;nde: 
(1) Zweck dieser Verordnung ist es, das Funktionieren des Binnenmarkts zu verbessern, 
indem ein einheitlicher Rechtsrahmen insbesondere f&#252;r die Entwicklung, Vermarktung 
und Verwendung k&#252;nstlicher Intelligenz im Einklang mit den Werten der Union 
festgelegt wird. Diese Verordnung beruht auf einer Reihe von zwingenden Gr&#252;nden 
des Allgemeininteresses, wie einem hohen Schutz der Gesundheit, der Sicherheit und 
der Grundrechte, und gew&#228;hrleistet den grenz&#252;berschreitenden freien Verkehr KI-
gest&#252;tzter Waren und Dienstleistungen, wodurch verhindert wird, dass die 
Mitgliedstaaten die Entwicklung, Vermarktung und Verwendung von KI-Systemen 
beschr&#228;nken, sofern dies nicht ausdr&#252;cklich durch diese Verordnung erlaubt wird. 
(2) Systeme der k&#252;nstlichen Intelligenz (KI-Systeme) k&#246;nnen problemlos in 
verschiedenen Bereichen der Wirtschaft und Gesellschaft, auch grenz&#252;berschreitend, 
eingesetzt werden und in der gesamten Union verkehren. Einige Mitgliedstaaten haben 
bereits die Verabschiedung nationaler Vorschriften in Erw&#228;gung gezogen, damit 
k&#252;nstliche Intelligenz sicher ist und unter Einhaltung der Grundrechte entwickelt und 
verwendet wird. Unterschiedliche nationale Vorschriften k&#246;nnen zu einer 
Fragmentierung des Binnenmarkts f&#252;hren und w&#252;rden die Rechtssicherheit f&#252;r 
Akteure, die KI-Systeme entwickeln oder verwenden, beeintr&#228;chtigen. Daher sollte in 
der gesamten Union ein einheitlich hohes Schutzniveau sichergestellt werden, wobei 
Unterschiede, die den freien Verkehr von KI-Systemen und damit 
zusammenh&#228;ngenden Produkten und Dienstleistungen im Binnenmarkt behindern, 
vermieden werden sollten, indem den Akteuren einheitliche Verpflichtungen auferlegt 
werden und der gleiche Schutz der zwingenden Gr&#252;nde des Allgemeininteresses und 
31 ABl. C [&#8230;] vom [&#8230;], S. [&#8230;]. 
32 ABl. C [&#8230;] vom [&#8230;], S. [&#8230;].
der Rechte von Personen im gesamten Binnenmarkt auf der Grundlage des 
Artikels 114 des Vertrags &#252;ber die Arbeitsweise der Europ&#228;ischen Union (AEUV) 
gew&#228;hrleistet wird. Soweit diese Verordnung konkrete Vorschriften zum Schutz von 
Privatpersonen im Hinblick auf die Verarbeitung personenbezogener Daten enth&#228;lt, 
mit denen vor allem die Verwendung von KI-Systemen zur biometrischen Echtzeit-
Fernidentifizierung in &#246;ffentlich zug&#228;nglichen R&#228;umen zu Strafverfolgungszwecken 
eingeschr&#228;nkt wird, sollte sich diese Verordnung in Bezug auf diese konkreten 
Vorschriften auch auf Artikel 16 AEUV st&#252;tzen. Angesichts dieser konkreten 
Vorschriften und des R&#252;ckgriffs auf Artikel 16 AEUV ist es angezeigt, den 
Europ&#228;ischen Datenschutzausschuss zu konsultieren. 
(3) K&#252;nstliche Intelligenz bezeichnet eine Reihe von Technologien, die sich rasant 
entwickeln und zu vielf&#228;ltigem Nutzen f&#252;r Wirtschaft und Gesellschaft &#252;ber das 
gesamte Spektrum industrieller und gesellschaftlicher Aktivit&#228;ten hinweg beitragen 
k&#246;nnen. Durch die Verbesserung der Vorhersage, Optimierung der Abl&#228;ufe, 
Ressourcenzuweisung und Personalisierung digitaler L&#246;sungen, die Einzelpersonen 
und Organisationen zur Verf&#252;gung stehen, kann die Verwendung k&#252;nstlicher 
Intelligenz den Unternehmen wesentliche Wettbewerbsvorteile verschaffen und zu 
guten Ergebnissen f&#252;r Gesellschaft und Umwelt f&#252;hren, beispielsweise in den 
Bereichen Gesundheitsversorgung, Landwirtschaft, allgemeine und berufliche 
Bildung, Infrastrukturmanagement, Energie, Verkehr und Logistik, &#246;ffentliche 
Dienstleistungen, Sicherheit, Justiz, Ressourcen- und Energieeffizienz sowie 
Klimaschutz und Anpassung an den Klimawandel. 
(4) Gleichzeitig kann k&#252;nstliche Intelligenz je nach den Umst&#228;nden ihrer konkreten 
Anwendung und Nutzung Risiken mit sich bringen und &#246;ffentliche Interessen und 
Rechte sch&#228;digen, die durch das Unionsrecht gesch&#252;tzt sind. Ein solcher Schaden kann 
materieller oder immaterieller Art sein.
(5) Daher ist ein Rechtsrahmen der Union mit harmonisierten Vorschriften f&#252;r k&#252;nstliche 
Intelligenz erforderlich, um die Entwicklung, Verwendung und Verbreitung 
k&#252;nstlicher Intelligenz im Binnenmarkt zu f&#246;rdern und gleichzeitig einen hohen 
Schutz &#246;ffentlicher Interessen wie Gesundheit und Sicherheit und den Schutz der 
durch das Unionsrecht anerkannten und gesch&#252;tzten Grundrechte zu gew&#228;hrleisten. 
Zur Umsetzung dieses Ziels sollten Vorschriften f&#252;r das Inverkehrbringen und die 
Inbetriebnahme bestimmter KI-Systeme festgelegt werden, um das reibungslose 
Funktionieren des Binnenmarkts zu gew&#228;hrleisten, sodass diesen Systemen der 
Grundsatz des freien Waren- und Dienstleistungsverkehrs zugutekommen kann. Durch 
die Festlegung dieser Vorschriften unterst&#252;tzt die Verordnung das vom Europ&#228;ischen 
Rat33 formulierte Ziel der Union, bei der Entwicklung einer sicheren, 
vertrauensw&#252;rdigen und ethisch vertretbaren k&#252;nstlichen Intelligenz weltweit eine 
F&#252;hrungsrolle einzunehmen, und sorgt f&#252;r den vom Europ&#228;ischen Parlament34
ausdr&#252;cklich geforderten Schutz von Ethikgrunds&#228;tzen. 
(6) Der Begriff &#8222;KI-System&#8220; sollte klar definiert werden, um Rechtssicherheit zu 
gew&#228;hrleisten und gleichzeitig gen&#252;gend Flexibilit&#228;t zu bieten, um k&#252;nftigen 
technologischen Entwicklungen Rechnung zu tragen. Die Begriffsbestimmung sollte
33 Europ&#228;ischer Rat, Au&#223;erordentliche Tagung des Europ&#228;ischen Rates (1. und 2. Oktober 2020) &#8211; 
Schlussfolgerungen, EUCO 13/20, 2020, S. 6. 
34 Entschlie&#223;ung des Europ&#228;ischen Parlaments vom 20. Oktober 2020 mit Empfehlungen an die 
Kommission zu dem Rahmen f&#252;r die ethischen Aspekte von k&#252;nstlicher Intelligenz, Robotik und damit 
zusammenh&#228;ngenden Technologien, 2020/2012 (INL).
auf den wesentlichen funktionalen Merkmalen der Software beruhen, insbesondere 
darauf, dass sie im Hinblick auf eine Reihe von Zielen, die vom Menschen festgelegt 
werden, Ergebnisse wie Inhalte, Vorhersagen, Empfehlungen oder Entscheidungen 
hervorbringen kann, die das Umfeld beeinflussen, mit dem sie interagieren, sei es 
physisch oder digital. KI-Systeme k&#246;nnen so konzipiert sein, dass sie mit 
verschiedenen Graden der Autonomie arbeiten und eigenst&#228;ndig oder als Bestandteil 
eines Produkts verwendet werden k&#246;nnen, unabh&#228;ngig davon, ob das System physisch 
in das Produkt integriert ist (eingebettet) oder der Funktion des Produkts dient, ohne 
darin integriert zu sein (nicht eingebettet). Die Bestimmung des Begriffs &#8222;KI-System&#8220; 
sollte durch eine Liste spezifischer Techniken und Konzepte f&#252;r seine Entwicklung 
erg&#228;nzt werden, die im Lichte der Marktentwicklungen und der technischen 
Entwicklungen auf dem neuesten Stand gehalten werden sollte, indem die 
Kommission delegierte Rechtsakte zur &#196;nderung dieser Liste erl&#228;sst. 
(7) Der in dieser Verordnung verwendete Begriff &#8222;biometrische Daten&#8220; steht im Einklang 
mit dem Begriff &#8222;biometrische Daten&#8220; im Sinne von Artikel 4 Nummer 14 der 
Verordnung (EU) 2016/679 des Europ&#228;ischen Parlaments und des Rates35, Artikel 3 
Nummer 18 der Verordnung (EU) 2018/1725 des Europ&#228;ischen Parlaments und des 
Rates36 und Artikel 3 Nummer 13 der Richtlinie (EU) 2016/680 des Europ&#228;ischen 
Parlaments und des Rates37 und sollte im Einklang damit ausgelegt werden. 
(8) Der in dieser Verordnung verwendete Begriff &#8222;biometrisches 
Fernidentifizierungssystem&#8220; sollte funktional definiert werden als KI-System, das dem 
Zweck dient, nat&#252;rliche Personen aus der Ferne durch Abgleich der biometrischen 
Daten einer Person mit den in einer Referenzdatenbank gespeicherten biometrischen 
Daten zu identifizieren, ohne dass der Nutzer des KI-Systems vorher wei&#223;, ob die 
Person anwesend sein wird und identifiziert werden kann, und unabh&#228;ngig davon, 
welche Technik, Verfahren oder Arten biometrischer Daten dazu verwendet werden. 
Angesichts ihrer unterschiedlichen Merkmale und Einsatzformen sowie der 
unterschiedlichen Risiken, die mit ihnen verbunden sind, sollte zwischen 
biometrischen Echtzeit-Fernidentifizierungssystemen und Systemen zur 
nachtr&#228;glichen biometrischen Fernidentifizierung unterschieden werden. Bei 
&#8222;Echtzeit-Systemen&#8220; erfolgen die Erfassung der biometrischen Daten, der Abgleich 
und die Identifizierung unverz&#252;glich, zeitnah oder auf jeden Fall ohne erhebliche 
Verz&#246;gerung. In diesem Zusammenhang sollte es keinen Spielraum f&#252;r eine 
Umgehung der Bestimmungen dieser Verordnung &#252;ber die &#8222;Echtzeit-Nutzung&#8220; der 
betreffenden KI-Systeme geben, indem kleinere Verz&#246;gerungen vorgesehen werden.
35 Verordnung (EU) 2016/679 des Europ&#228;ischen Parlaments und des Rates vom 27. April 2016 zum 
Schutz nat&#252;rlicher Personen bei der Verarbeitung personenbezogener Daten, zum freien Datenverkehr 
und zur Aufhebung der Richtlinie 95/46/EG (Datenschutz-Grundverordnung) (ABl. L 119 vom 
4.5.2016, S. 1). 
36 Verordnung (EU) 2018/1725 des Europ&#228;ischen Parlaments und des Rates vom 23. Oktober 2018 zum 
Schutz nat&#252;rlicher Personen bei der Verarbeitung personenbezogener Daten durch die Organe, 
Einrichtungen und sonstigen Stellen der Union, zum freien Datenverkehr und zur Aufhebung der 
Verordnung (EG) Nr. 45/2001 und des Beschlusses Nr. 1247/2002/EG (ABl. L 295 vom 21.11.2018, 
S. 39). 
37 Richtlinie (EU) 2016/680 des Europ&#228;ischen Parlaments und des Rates vom 27. April 2016 zum Schutz 
nat&#252;rlicher Personen bei der Verarbeitung personenbezogener Daten durch die zust&#228;ndigen Beh&#246;rden 
zum Zwecke der Verh&#252;tung, Ermittlung, Aufdeckung oder Verfolgung von Straftaten oder der 
Strafvollstreckung sowie zum freien Datenverkehr und zur Aufhebung des 
Rahmenbeschlusses 2008/977/JI des Rates (Richtlinie zum Datenschutz bei der Strafverfolgung) (ABl. 
L 119 vom 4.5.2016, S. 89).
&#8222;Echtzeit-Systeme&#8220; umfassen die Verwendung von &#8222;Live-Material&#8220; oder &#8222;Near-live-
Material&#8220; wie Videoaufnahmen, die von einer Kamera oder einem anderen Ger&#228;t mit 
&#228;hnlicher Funktion erzeugt werden. Bei Systemen zur nachtr&#228;glichen Identifizierung 
hingegen wurden die biometrischen Daten schon zuvor erfasst und der Abgleich und 
die Identifizierung erfolgen erst mit erheblicher Verz&#246;gerung. Dabei handelt es sich 
um Material wie Bild- oder Videoaufnahmen, die von Video-&#220;berwachungssystemen 
oder privaten Ger&#228;ten vor der Anwendung des KI-Systems auf die betroffenen 
nat&#252;rlichen Personen erzeugt wurden. 
(9) F&#252;r die Zwecke dieser Verordnung sollte der Begriff &#8222;&#246;ffentlich zug&#228;nglicher Raum&#8220; 
so verstanden werden, dass er sich auf einen der &#214;ffentlichkeit zug&#228;nglichen 
physischen Ort bezieht, unabh&#228;ngig davon, ob sich der betreffende Ort in privatem 
oder &#246;ffentlichem Eigentum befindet. Daher erfasst der Begriff keine privaten Orte, 
wie Privath&#228;user, private Clubs, B&#252;ros, Lager und Fabriken, die normalerweise f&#252;r 
Dritte, einschlie&#223;lich Strafverfolgungsbeh&#246;rden, nicht frei zug&#228;nglich sind, es sei 
denn, diese wurden ausdr&#252;cklich eingeladen oder ihr Zugang ausdr&#252;cklich erlaubt. 
Auch Online-R&#228;ume werden nicht erfasst, da es sich nicht um physische R&#228;ume 
handelt. Die blo&#223;e Tatsache, dass bestimmte Bedingungen f&#252;r den Zugang zu einem 
bestimmten Raum gelten k&#246;nnen, wie Eintrittskarten oder Altersbeschr&#228;nkungen, 
bedeutet jedoch nicht, dass der Raum im Sinne dieser Verordnung nicht &#246;ffentlich 
zug&#228;nglich ist. Folglich sind neben &#246;ffentlichen R&#228;umen wie Stra&#223;en, relevanten 
Teilen von Regierungsgeb&#228;uden und den meisten Verkehrsinfrastrukturen auch 
Bereiche wie Kinos, Theater, Gesch&#228;fte und Einkaufszentren in der Regel &#246;ffentlich 
zug&#228;nglich. Ob ein bestimmter Raum &#246;ffentlich zug&#228;nglich ist, sollte jedoch von Fall 
zu Fall unter Ber&#252;cksichtigung der Besonderheiten der jeweiligen individuellen 
Situation entschieden werden.
(10) Um gleiche Wettbewerbsbedingungen und einen wirksamen Schutz der Rechte und 
Freiheiten nat&#252;rlicher Personen in der gesamten Union zu gew&#228;hrleisten, sollten die in 
dieser Verordnung festgelegten Vorschriften in nichtdiskriminierender Weise f&#252;r 
Anbieter von KI-Systemen &#8211; unabh&#228;ngig davon, ob sie in der Union oder in einem 
Drittland niedergelassen sind &#8211; und f&#252;r Nutzer von KI-Systemen, die in der Union 
ans&#228;ssig oder niedergelassen sind, gelten. 
(11) Angesichts ihres digitalen Charakters sollten bestimmte KI-Systeme in den 
Anwendungsbereich dieser Verordnung fallen, selbst wenn sie in der Union weder in 
Verkehr gebracht noch in Betrieb genommen oder verwendet werden. Dies ist 
beispielsweise der Fall, wenn ein in der Union ans&#228;ssiger oder niedergelassener 
Akteur bestimmte Dienstleistungen an einen au&#223;erhalb der Union ans&#228;ssigen oder 
niedergelassenen Akteur im Zusammenhang mit einer T&#228;tigkeit vergibt, die von einem 
KI-System ausge&#252;bt werden soll, das als hochriskant einzustufen w&#228;re und sich auf in 
der Union ans&#228;ssige nat&#252;rliche Personen auswirken w&#252;rde. Unter diesen Umst&#228;nden 
k&#246;nnte das von dem Akteur au&#223;erhalb der Union betriebene KI-System Daten 
verarbeiten, die rechtm&#228;&#223;ig in der Union erhoben und aus der Union &#252;bertragen 
wurden, und sodann dem vertraglichen Akteur in der Union die aus dieser 
Verarbeitung resultierenden Ergebnisse dieses KI-Systems liefern, ohne dass dieses 
KI-System dabei in der Union in Verkehr gebracht, in Betrieb genommen oder 
verwendet wird. Um die Umgehung dieser Verordnung zu verhindern und einen 
wirksamen Schutz in der Union ans&#228;ssiger nat&#252;rlicher Personen zu gew&#228;hrleisten, 
sollte diese Verordnung auch f&#252;r Anbieter und Nutzer von KI-Systemen gelten, die in 
einem Drittland ans&#228;ssig oder niedergelassen sind, soweit die von diesen Systemen 
erzeugten Ergebnisse in der Union verwendet werden. Um jedoch bestehenden
Vereinbarungen und besonderen Erfordernissen f&#252;r die Zusammenarbeit mit 
ausl&#228;ndischen Partnern, mit denen Informationen und Beweismittel ausgetauscht 
werden, Rechnung zu tragen, sollte diese Verordnung nicht f&#252;r Beh&#246;rden eines 
Drittlands und internationale Organisationen gelten, wenn sie im Rahmen 
internationaler &#220;bereink&#252;nfte t&#228;tig werden, die auf nationaler oder europ&#228;ischer Ebene 
f&#252;r die Zusammenarbeit mit der Union oder ihren Mitgliedstaaten im Bereich der 
Strafverfolgung und der justiziellen Zusammenarbeit geschlossen wurden. Solche 
&#220;bereink&#252;nfte wurden bilateral zwischen Mitgliedstaaten und Drittstaaten oder 
zwischen der Europ&#228;ischen Union, Europol und anderen EU-Agenturen einerseits und 
Drittstaaten und internationalen Organisationen andererseits geschlossen. 
(12) Diese Verordnung sollte auch f&#252;r Organe, Einrichtungen und sonstige Stellen der 
Union gelten, wenn sie als Anbieter oder Nutzer eines KI-Systems auftreten. KI-
Systeme, die ausschlie&#223;lich f&#252;r milit&#228;rische Zwecke entwickelt oder verwendet 
werden, sollten vom Anwendungsbereich dieser Verordnung ausgenommen werden, 
wenn diese Verwendung in den ausschlie&#223;lichen Zust&#228;ndigkeitsbereich der 
Gemeinsamen Au&#223;en- und Sicherheitspolitik f&#228;llt, der in Titel V des Vertrags &#252;ber die 
Europ&#228;ische Union (EUV) geregelt ist. Diese Verordnung sollte die Bestimmungen 
&#252;ber die Verantwortlichkeit der Vermittler in der Richtlinie 2000/31/EG des 
Europ&#228;ischen Parlaments und des Rates [in der durch das Gesetz &#252;ber digitale Dienste 
ge&#228;nderten Fassung] unber&#252;hrt lassen. 
(13) Um einen einheitlichen und hohen Schutz &#246;ffentlicher Interessen im Hinblick auf die 
Gesundheit und Sicherheit sowie die Grundrechte zu gew&#228;hrleisten, werden f&#252;r alle 
Hochrisiko-KI-Systeme gemeinsame Normen vorgeschlagen. Diese Normen sollten 
mit der Charta der Grundrechte der Europ&#228;ischen Union (im Folgenden die &#8222;Charta&#8220;) 
im Einklang stehen, nichtdiskriminierend sein und mit den internationalen 
Handelsverpflichtungen der Union vereinbar sein. 
(14) Um ein verh&#228;ltnism&#228;&#223;iges und wirksames verbindliches Regelwerk f&#252;r KI-Systeme 
einzuf&#252;hren, sollte ein klar definierter risikobasierter Ansatz verfolgt werden. Bei 
diesem Ansatz sollten Art und Inhalt solcher Vorschriften auf die Intensit&#228;t und den 
Umfang der Risiken zugeschnitten werden, die von KI-Systemen ausgehen k&#246;nnen. Es 
ist daher notwendig, bestimmte Praktiken im Bereich der k&#252;nstlichen Intelligenz zu 
verbieten und Anforderungen an Hochrisiko-KI-Systeme und Verpflichtungen f&#252;r die 
betreffenden Akteure sowie Transparenzpflichten f&#252;r bestimmte KI-Systeme 
festzulegen. 
(15) Abgesehen von den zahlreichen nutzbringenden Verwendungsm&#246;glichkeiten 
k&#252;nstlicher Intelligenz kann diese Technik auch missbraucht werden und neue und 
wirkungsvolle Instrumente f&#252;r manipulative, ausbeuterische und soziale 
Kontrollpraktiken bieten. Solche Praktiken sind besonders sch&#228;dlich und sollten 
verboten werden, weil sie im Widerspruch zu den Werten der Union stehen, n&#228;mlich 
der Achtung der Menschenw&#252;rde, Freiheit, Gleichheit, Demokratie und 
Rechtsstaatlichkeit sowie der Grundrechte in der Union, einschlie&#223;lich des Rechts auf 
Nichtdiskriminierung, Datenschutz und Privatsph&#228;re sowie der Rechte des Kindes. 
(16) Das Inverkehrbringen, die Inbetriebnahme oder die Verwendung bestimmter KI-
Systeme, die dazu bestimmt sind, menschliches Verhalten nachteilig zu beeinflussen, 
und die zu physischen oder psychischen Sch&#228;den f&#252;hren d&#252;rften, sollte verboten 
werden. Solche KI-Systeme setzen auf eine vom Einzelnen nicht zu erkennende 
unterschwellige Beeinflussung oder sollen die Schutzbed&#252;rftigkeit von Kindern und 
anderen aufgrund ihres Alters oder ihrer k&#246;rperlichen oder geistigen Behinderung
beeintr&#228;chtigten Personen ausnutzen. Dies geschieht mit der Absicht, das Verhalten 
einer Person wesentlich zu beeinflussen, und zwar in einer Weise, die dieser oder einer 
anderen Person Schaden zuf&#252;gt oder zuf&#252;gen kann. Diese Absicht kann nicht vermutet 
werden, wenn die nachteilige Beeinflussung des menschlichen Verhaltens auf 
Faktoren zur&#252;ckzuf&#252;hren ist, die nicht Teil des KI-Systems sind und au&#223;erhalb der 
Kontrolle des Anbieters oder Nutzers liegen. Forschung zu legitimen Zwecken im 
Zusammenhang mit solchen KI-Systemen sollte durch das Verbot nicht unterdr&#252;ckt 
werden, wenn diese Forschung nicht auf eine Verwendung des KI-Systems in 
Beziehungen zwischen Mensch und Maschine hinausl&#228;uft, durch die nat&#252;rliche 
Personen gesch&#228;digt werden, und wenn diese Forschung im Einklang mit anerkannten 
ethischen Standards f&#252;r die wissenschaftliche Forschung durchgef&#252;hrt wird. 
(17) KI-Systeme, die von Beh&#246;rden oder in deren Auftrag das soziale Verhalten nat&#252;rlicher 
Personen f&#252;r allgemeine Zwecke bewerten, k&#246;nnen zu diskriminierenden Ergebnissen 
und zur Ausgrenzung bestimmter Gruppen f&#252;hren. Sie k&#246;nnen die Menschenw&#252;rde 
und das Recht auf Nichtdiskriminierung sowie die Werte der Gleichheit und 
Gerechtigkeit verletzen. Solche KI-Systeme bewerten oder klassifizieren die 
Vertrauensw&#252;rdigkeit nat&#252;rlicher Personen auf der Grundlage ihres sozialen 
Verhaltens in verschiedenen Zusammenh&#228;ngen oder aufgrund bekannter oder 
vorhergesagter pers&#246;nlicher Eigenschaften oder Pers&#246;nlichkeitsmerkmale. Die aus 
solchen KI-Systemen erzielte soziale Bewertung kann zu einer Schlechterstellung oder 
Benachteiligung bestimmter nat&#252;rlicher Personen oder ganzer Gruppen nat&#252;rlicher 
Personen in sozialen Zusammenh&#228;ngen, die in keinem Zusammenhang zu den 
Umst&#228;nden stehen, unter denen die Daten urspr&#252;nglich erzeugt oder erfasst wurden, 
oder zu einer Schlechterstellung in einer Weise f&#252;hren, die im Hinblick auf ihr soziales 
Verhalten oder dessen Tragweite ungerechtfertigt oder unverh&#228;ltnism&#228;&#223;ig ist. Solche 
KI-Systeme sollten daher verboten werden. 
(18) Die Verwendung von KI-Systemen zur biometrischen Echtzeit-Fernidentifizierung 
nat&#252;rlicher Personen in &#246;ffentlich zug&#228;nglichen R&#228;umen zu Strafverfolgungszwecken 
gilt als besonders in die Rechte und Freiheiten der betroffenen Personen eingreifend, 
da sie die Privatsph&#228;re eines gro&#223;en Teils der Bev&#246;lkerung beeintr&#228;chtigt, ein Gef&#252;hl 
der st&#228;ndigen &#220;berwachung weckt und indirekt von der Aus&#252;bung der 
Versammlungsfreiheit und anderer Grundrechte abhalten kann. Dar&#252;ber hinaus bergen 
die Unmittelbarkeit der Auswirkungen und die begrenzten M&#246;glichkeiten weiterer 
Kontrollen oder Korrekturen im Zusammenhang mit der Verwendung solcher in 
Echtzeit betriebener Systeme erh&#246;hte Risiken f&#252;r die Rechte und Freiheiten der 
Personen, die von Strafverfolgungsma&#223;nahmen betroffen sind. 
(19) Die Verwendung solcher Systeme zu Strafverfolgungszwecken sollte daher untersagt 
werden, au&#223;er in drei ersch&#246;pfend aufgef&#252;hrten und eng abgegrenzten F&#228;llen, in denen 
die Verwendung unbedingt erforderlich ist, um einem erheblichen &#246;ffentlichen 
Interesse zu dienen, dessen Bedeutung die Risiken &#252;berwiegt. Zu diesen F&#228;llen geh&#246;rt 
die Suche nach potenziellen Opfern von Straftaten, einschlie&#223;lich vermisster Kinder, 
bestimmte Gefahren f&#252;r das Leben oder die k&#246;rperliche Unversehrtheit nat&#252;rlicher 
Personen oder die Gefahr eines Terroranschlags sowie das Erkennen, Aufsp&#252;ren, 
Identifizieren oder Verfolgen von T&#228;tern oder Verd&#228;chtigen von Straftaten im Sinne 
des Rahmenbeschlusses 2002/584/JI des Rates38, sofern diese Straftaten in dem 
betreffenden Mitgliedstaat nach dessen Recht mit einer Freiheitsstrafe oder einer
38 Rahmenbeschluss 2002/584/JI des Rates vom 13. Juni 2002 &#252;ber den Europ&#228;ischen Haftbefehl und die 
&#220;bergabeverfahren zwischen den Mitgliedstaaten (ABl. L 190 vom 18.7.2002, S. 1).
freiheitsentziehenden Ma&#223;regel der Sicherung im H&#246;chstma&#223; von mindestens drei 
Jahren bedroht sind. Eine solche Schwelle f&#252;r eine Freiheitsstrafe oder eine 
freiheitsentziehende Ma&#223;regel der Sicherung nach nationalem Recht tr&#228;gt dazu bei 
sicherzustellen, dass die Straftat schwerwiegend genug ist, um den Einsatz 
biometrischer Echtzeit-Fernidentifizierungssysteme zu rechtfertigen. Dar&#252;ber hinaus 
sind einige der 32 im Rahmenbeschluss 2002/584/JI des Rates aufgef&#252;hrten Straftaten 
in der Praxis eher relevant als andere, da der R&#252;ckgriff auf die biometrische Echtzeit-
Fernidentifizierung f&#252;r die konkrete Erkennung, Aufsp&#252;rung, Identifizierung oder 
Verfolgung eines T&#228;ters oder Verd&#228;chtigen einer der verschiedenen aufgef&#252;hrten 
Straftaten voraussichtlich in &#228;u&#223;erst unterschiedlichem Ma&#223;e erforderlich und 
verh&#228;ltnism&#228;&#223;ig sein wird und da dabei die wahrscheinlichen Unterschiede in 
Schwere, Wahrscheinlichkeit und Ausma&#223; des Schadens oder m&#246;glicher negativer 
Folgen zu ber&#252;cksichtigen sind. 
(20) Um sicherzustellen, dass diese Systeme verantwortungsvoll und verh&#228;ltnism&#228;&#223;ig 
genutzt werden, ist es auch wichtig, festzulegen, dass in jedem dieser drei ersch&#246;pfend 
aufgef&#252;hrten und eng abgegrenzten F&#228;lle bestimmte Elemente ber&#252;cksichtigt werden 
sollten, insbesondere in Bezug auf die Art des dem Antrag zugrunde liegenden Falls 
und die Auswirkungen der Verwendung auf die Rechte und Freiheiten aller 
betroffenen Personen sowie auf die f&#252;r die Verwendung geltenden 
Schutzvorkehrungen und Bedingungen. Dar&#252;ber hinaus sollte die Verwendung 
biometrischer Echtzeit-Fernidentifizierungssysteme in &#246;ffentlich zug&#228;nglichen 
R&#228;umen f&#252;r die Zwecke der Strafverfolgung angemessenen zeitlichen und r&#228;umlichen 
Beschr&#228;nkungen unterliegen, wobei insbesondere den Beweisen oder Hinweisen in 
Bezug auf die Bedrohungen, die Opfer oder den T&#228;ter Rechnung zu tragen ist. Die 
Personenreferenzdatenbank sollte f&#252;r jeden Anwendungsfall in jeder der drei oben 
genannten Situationen geeignet sein. 
(21) Jede Verwendung biometrischer Echtzeit-Fernidentifizierungssysteme in &#246;ffentlich 
zug&#228;nglichen R&#228;umen zu Strafverfolgungszwecken sollte einer ausdr&#252;cklichen 
spezifischen Genehmigung durch eine Justizbeh&#246;rde oder eine unabh&#228;ngige 
Verwaltungsbeh&#246;rde eines Mitgliedstaats unterliegen. Eine solche Genehmigung sollte 
grunds&#228;tzlich vor der Verwendung eingeholt werden, au&#223;er in hinreichend 
begr&#252;ndeten dringenden F&#228;llen, d. h. in Situationen, in denen es wegen der 
Notwendigkeit der Verwendung der betreffenden Systeme tats&#228;chlich und objektiv 
unm&#246;glich ist, vor dem Beginn der Verwendung eine Genehmigung einzuholen. In 
solchen dringenden F&#228;llen sollte die Verwendung auf das absolut notwendige 
Mindestma&#223; beschr&#228;nkt werden und angemessenen Schutzvorkehrungen und 
Bedingungen unterliegen, die im nationalen Recht festgelegt sind und im 
Zusammenhang mit jedem einzelnen dringenden Anwendungsfall von der 
Strafverfolgungsbeh&#246;rde selbst pr&#228;zisiert werden. Dar&#252;ber hinaus sollte die 
Strafverfolgungsbeh&#246;rde in solchen Situationen versuchen, so bald wie m&#246;glich eine 
Genehmigung einzuholen, wobei sie begr&#252;nden sollte, warum sie diese nicht fr&#252;her 
beantragen konnte. 
(22) Dar&#252;ber hinaus sollte innerhalb des durch diese Verordnung vorgegebenen 
ersch&#246;pfenden Rahmens festgelegt werden, dass eine solche Verwendung im 
Hoheitsgebiet eines Mitgliedstaats im Einklang mit dieser Verordnung nur m&#246;glich 
sein sollte, sofern der betreffende Mitgliedstaat in seinen detaillierten nationalen 
Rechtsvorschriften ausdr&#252;cklich vorgesehen hat, dass eine solche Verwendung 
genehmigt werden kann. Folglich steht es den Mitgliedstaaten im Rahmen dieser 
Verordnung frei, eine solche M&#246;glichkeit generell oder nur in Bezug auf einige der in
dieser Verordnung genannten Ziele, f&#252;r die eine genehmigte Verwendung 
gerechtfertigt sein kann, vorzusehen. 
(23) Die Verwendung von KI-Systemen zur biometrischen Echtzeit-Fernidentifizierung 
nat&#252;rlicher Personen in &#246;ffentlich zug&#228;nglichen R&#228;umen zu Strafverfolgungszwecken 
erfordert zwangsl&#228;ufig die Verarbeitung biometrischer Daten. Die Vorschriften dieser 
Verordnung, die vorbehaltlich bestimmter Ausnahmen eine solche Verwendung auf 
der Grundlage von Artikel 16 AEUV verbieten, sollten als Lex specialis in Bezug auf 
die in Artikel 10 der Richtlinie (EU) 2016/680 enthaltenen Vorschriften &#252;ber die 
Verarbeitung biometrischer Daten gelten und somit die Verwendung und Verarbeitung 
der betreffenden biometrischen Daten umfassend regeln. Eine solche Verwendung und 
Verarbeitung sollte daher nur m&#246;glich sein, soweit sie mit dem in dieser Verordnung 
festgelegten Rahmen vereinbar ist, ohne dass es den zust&#228;ndigen Beh&#246;rden bei ihren 
T&#228;tigkeiten zu Strafverfolgungszwecken Raum l&#228;sst, au&#223;erhalb dieses Rahmens solche 
Systeme zu verwenden und die damit verbundenen Daten aus den in Artikel 10 der 
Richtlinie (EU) 2016/680 aufgef&#252;hrten Gr&#252;nden zu verarbeiten. In diesem 
Zusammenhang soll diese Verordnung nicht als Rechtsgrundlage f&#252;r die Verarbeitung 
personenbezogener Daten gem&#228;&#223; Artikel 8 der Richtlinie (EU) 2016/680 dienen. Die 
Verwendung biometrischer Echtzeit-Fernidentifizierungssysteme in &#246;ffentlich 
zug&#228;nglichen R&#228;umen zu anderen Zwecken als der Strafverfolgung, auch durch 
zust&#228;ndige Beh&#246;rden, sollte jedoch nicht unter den in dieser Verordnung festgelegten 
spezifischen Rahmen f&#252;r diese Verwendung zu Strafverfolgungszwecken fallen. Eine 
solche Verwendung zu anderen Zwecken als der Strafverfolgung sollte daher nicht der 
Genehmigungspflicht gem&#228;&#223; dieser Verordnung und der zu ihrer Durchf&#252;hrung 
anwendbaren detaillierten nationalen Rechtsvorschriften unterliegen. 
(24) Jede Verarbeitung biometrischer Daten und anderer personenbezogener Daten im 
Zusammenhang mit der Verwendung von KI-Systemen f&#252;r die biometrische 
Identifizierung, ausgenommen im Zusammenhang mit der Verwendung biometrischer 
Echtzeit-Fernidentifizierungssysteme in &#246;ffentlich zug&#228;nglichen R&#228;umen zu 
Strafverfolgungszwecken im Sinne dieser Verordnung, einschlie&#223;lich der F&#228;lle, in 
denen diese Systeme von den zust&#228;ndigen Beh&#246;rden in &#246;ffentlich zug&#228;nglichen 
R&#228;umen zu anderen Zwecken als der Strafverfolgung genutzt werden, sollte weiterhin 
allen Anforderungen gen&#252;gen, die sich gegebenenfalls aus Artikel 9 Absatz 1 der 
Verordnung (EU) 2016/679, Artikel 10 Absatz 1 der Verordnung (EU) 2018/1725 und 
Artikel 10 der Richtlinie (EU) 2016/680 ergeben. 
(25) Nach Artikel 6a des dem EUV und dem AEUV beigef&#252;gten Protokolls Nr. 21 &#252;ber die 
Position des Vereinigten K&#246;nigreichs und Irlands hinsichtlich des Raums der Freiheit, 
der Sicherheit und des Rechts sind die auf der Grundlage des Artikels 16 AEUV 
festgelegten Vorschriften in Artikel 5 Absatz 1 Buchstabe d und Artikel 5 Abs&#228;tze 2 
und 3 dieser Verordnung in Bezug auf die Verarbeitung personenbezogener Daten 
durch die Mitgliedstaaten im Rahmen der Aus&#252;bung von T&#228;tigkeiten, die in den 
Anwendungsbereich des Dritten Teils Titel V Kapitel 4 und 5 AEUV fallen, f&#252;r Irland 
nicht bindend, wenn Irland nicht durch die Vorschriften gebunden ist, die die Formen 
der justiziellen Zusammenarbeit in Strafsachen oder der polizeilichen Zusammenarbeit 
regeln, in deren Rahmen die auf der Grundlage des Artikels 16 AEUV festgelegten 
Vorschriften eingehalten werden m&#252;ssen. 
(26) Nach den Artikeln 2 und 2a des dem EUV und dem AEUV beigef&#252;gten Protokolls 
Nr. 22 &#252;ber die Position D&#228;nemarks ist D&#228;nemark durch die auf der Grundlage des 
Artikels 16 AEUV festgelegten Vorschriften in Artikel 5 Absatz 1 Buchstabe d und 
Artikel 5 Abs&#228;tze 2 und 3 dieser Verordnung in Bezug auf die Verarbeitung
personenbezogener Daten durch die Mitgliedstaaten im Rahmen der Aus&#252;bung von 
T&#228;tigkeiten, die in den Anwendungsbereich des Dritten Teils Titel V Kapitel 4 und 5 
AEUV fallen, weder gebunden noch zu ihrer Anwendung verpflichtet. 
(27) Hochrisiko-KI-Systeme sollten nur dann auf dem Unionsmarkt in Verkehr gebracht 
oder in Betrieb genommen werden, wenn sie bestimmte verbindliche Anforderungen 
erf&#252;llen. Mit diesen Anforderungen sollte sichergestellt werden, dass Hochrisiko-KI-
Systeme, die in der Union verf&#252;gbar sind oder deren Ergebnisse anderweitig in der 
Union verwendet werden, keine unannehmbaren Risiken f&#252;r wichtige &#246;ffentliche 
Interessen der Union bergen, wie sie im Unionsrecht anerkannt und gesch&#252;tzt sind. Als 
hochriskant sollten nur solche KI-Systeme eingestuft werden, die erhebliche 
sch&#228;dliche Auswirkungen auf die Gesundheit, die Sicherheit und die Grundrechte von 
Personen in der Union haben; etwaige m&#246;gliche Beschr&#228;nkungen des internationalen 
Handels, die sich daraus ergeben, sollten so gering wie m&#246;glich bleiben. 
(28) KI-Systeme k&#246;nnten negative Auswirkungen auf die Gesundheit und Sicherheit von 
Personen haben, insbesondere wenn solche Systeme als Komponenten von Produkten 
zum Einsatz kommen. Im Einklang mit den Zielen der 
Harmonisierungsrechtsvorschriften der Union, die den freien Verkehr von Produkten 
im Binnenmarkt erleichtern und gew&#228;hrleisten sollen, dass nur sichere und 
anderweitig konforme Produkte auf den Markt gelangen, ist es wichtig, dass die 
Sicherheitsrisiken, die ein Produkt als Ganzes aufgrund seiner digitalen Komponenten, 
einschlie&#223;lich KI-Systeme, mit sich bringen kann, angemessen vermieden und 
gemindert werden. So sollten beispielsweise zunehmend autonome Roboter &#8211; sei es in 
der Fertigung oder in der pers&#246;nlichen Assistenz und Pflege &#8211; in der Lage sein, sicher 
zu arbeiten und ihre Funktionen in komplexen Umgebungen zu erf&#252;llen. Desgleichen 
sollten die immer ausgefeilteren Diagnosesysteme und Systeme zur Unterst&#252;tzung 
menschlicher Entscheidungen im Gesundheitssektor, in dem die Risiken f&#252;r Leib und 
Leben besonders hoch sind, zuverl&#228;ssig und genau sein. Das Ausma&#223; der negativen 
Auswirkungen des KI-Systems auf die durch die Charta gesch&#252;tzten Grundrechte ist 
bei der Einstufung eines KI-Systems als hochriskant von besonderer Bedeutung. Zu 
diesen Rechten geh&#246;ren die W&#252;rde des Menschen, die Achtung des Privat- und 
Familienlebens, der Schutz personenbezogener Daten, die Freiheit der 
Meinungs&#228;u&#223;erung und die Informationsfreiheit, die Versammlungs- und 
Vereinigungsfreiheit, die Nichtdiskriminierung, der Verbraucherschutz, die 
Arbeitnehmerrechte, die Rechte von Menschen mit Behinderungen, das Recht auf 
einen wirksamen Rechtsbehelf und ein unparteiisches Gericht, die 
Unschuldsvermutung und das Verteidigungsrecht sowie das Recht auf eine gute 
Verwaltung. Es muss betont werden, dass Kinder &#8211; zus&#228;tzlich zu diesen Rechten &#8211; 
&#252;ber spezifische Rechte verf&#252;gen, wie sie in Artikel 24 der EU-Charta und im 
&#220;bereinkommen der Vereinten Nationen &#252;ber die Rechte des Kindes (UNCRC) (im 
Hinblick auf das digitale Umfeld weiter ausgef&#252;hrt in der Allgemeinen Bemerkung 
Nr. 25 des UNCRC) verankert sind; in beiden wird die Ber&#252;cksichtigung der 
Schutzbed&#252;rftigkeit der Kinder gefordert und ihr Anspruch auf den Schutz und die 
F&#252;rsorge festgelegt, die f&#252;r ihr Wohlergehen notwendig sind. Dar&#252;ber hinaus sollte 
dem Grundrecht auf ein hohes Umweltschutzniveau, das in der Charta verankert ist 
und mit der Unionspolitik umgesetzt wird, bei der Bewertung der Schwere des 
Schadens, den ein KI-System u. a. in Bezug auf die Gesundheit und Sicherheit von 
Menschen verursachen kann, ebenfalls Rechnung getragen werden. 
(29) In Bezug auf Hochrisiko-KI-Systeme, bei denen es sich um Sicherheitskomponenten 
von Produkten oder Systemen oder selbst um Produkte oder Systeme handelt, die in
den Anwendungsbereich der Verordnung (EG) Nr. 300/2008 des Europ&#228;ischen 
Parlaments und des Rates39, der Verordnung (EU) Nr. 167/2013 des Europ&#228;ischen 
Parlaments und des Rates40, der Verordnung (EU) Nr. 168/2013 des Europ&#228;ischen 
Parlaments und des Rates41, der Richtlinie 2014/90/EU des Europ&#228;ischen Parlaments 
und des Rates42, der Richtlinie (EU) 2016/797 des Europ&#228;ischen Parlaments und des 
Rates43, der Verordnung (EU) 2018/858 des Europ&#228;ischen Parlaments und des Rates44, 
der Verordnung (EU) 2018/1139 des Europ&#228;ischen Parlaments und des Rates45 und 
der Verordnung (EU) 2019/2144 des Europ&#228;ischen Parlaments und des Rates46 fallen, 
ist es angezeigt, diese Rechtsakte zu &#228;ndern, damit die Kommission &#8211; aufbauend auf 
den technischen und regulatorischen Besonderheiten des jeweiligen Sektors und ohne 
Beeintr&#228;chtigung bestehender Governance-, Konformit&#228;tsbewertungs- und 
Durchsetzungsmechanismen sowie der darin eingerichteten Beh&#246;rden &#8211; beim Erlass 
von etwaigen k&#252;nftigen delegierten Rechtsakten oder Durchf&#252;hrungsrechtsakten auf 
der Grundlage der genannten Rechtsakte die in der vorliegenden Verordnung 
festgelegten verbindlichen Anforderungen an Hochrisiko-KI-Systeme ber&#252;cksichtigt. 
(30) In Bezug auf KI-Systeme, bei denen es sich um Sicherheitskomponenten von 
Produkten oder selbst um Produkte handelt, die unter bestimmte
39 Verordnung (EG) Nr. 300/2008 des Europ&#228;ischen Parlaments und des Rates vom 11. M&#228;rz 2008 &#252;ber 
gemeinsame Vorschriften f&#252;r die Sicherheit in der Zivilluftfahrt und zur Aufhebung der Verordnung 
(EG) Nr. 2320/2002 (ABl. L 97 vom 9.4.2008, S. 72). 
40 Verordnung (EU) Nr. 167/2013 des Europ&#228;ischen Parlaments und des Rates vom 5. Februar 2013 &#252;ber 
die Genehmigung und Markt&#252;berwachung von land- und forstwirtschaftlichen Fahrzeugen (ABl. L 60 
vom 2.3.2013, S. 1). 
41 Verordnung (EU) Nr. 168/2013 des Europ&#228;ischen Parlaments und des Rates vom 15. Januar 2013 &#252;ber 
die Genehmigung und Markt&#252;berwachung von zwei- oder dreir&#228;drigen und vierr&#228;drigen Fahrzeugen 
(ABl. L 60 vom 2.3.2013, S. 52). 
42 Richtlinie 2014/90/EU des Europ&#228;ischen Parlaments und des Rates vom 23. Juli 2014 &#252;ber 
Schiffsausr&#252;stung und zur Aufhebung der Richtlinie 96/98/EG des Rates (ABl. L 257 vom 28.8.2014, 
S. 146). 
43 Richtlinie (EU) 2016/797 des Europ&#228;ischen Parlaments und des Rates vom 11. Mai 2016 &#252;ber die 
Interoperabilit&#228;t des Eisenbahnsystems in der Europ&#228;ischen Union (ABl. L 138 vom 26.5.2016, S. 44). 
44 Verordnung (EU) 2018/858 des Europ&#228;ischen Parlaments und des Rates vom 30. Mai 2018 &#252;ber die 
Genehmigung und die Markt&#252;berwachung von Kraftfahrzeugen und Kraftfahrzeuganh&#228;ngern sowie von 
Systemen, Bauteilen und selbstst&#228;ndigen technischen Einheiten f&#252;r diese Fahrzeuge, zur &#196;nderung der 
Verordnungen (EG) Nr. 715/2007 und (EG) Nr. 595/2009 und zur Aufhebung der 
Richtlinie 2007/46/EG (ABl. L 151 vom 14.6.2018, S. 1). 
45 Verordnung (EU) 2018/1139 des Europ&#228;ischen Parlaments und des Rates vom 4. Juli 2018 zur 
Festlegung gemeinsamer Vorschriften f&#252;r die Zivilluftfahrt und zur Errichtung einer Agentur der 
Europ&#228;ischen Union f&#252;r Flugsicherheit sowie zur &#196;nderung der Verordnungen (EG) Nr. 2111/2005, 
(EG) Nr. 1008/2008, (EU) Nr. 996/2010, (EU) Nr. 376/2014 und der Richtlinien 2014/30/EU 
und 2014/53/EU des Europ&#228;ischen Parlaments und des Rates, und zur Aufhebung der Verordnungen 
(EG) Nr. 552/2004 und (EG) Nr. 216/2008 des Europ&#228;ischen Parlaments und des Rates und der 
Verordnung (EWG) Nr. 3922/91 des Rates (ABl. L 212 vom 22.8.2018, S. 1). 
46 Verordnung (EU) 2019/2144 des Europ&#228;ischen Parlaments und des Rates vom 27. November 2019 &#252;ber 
die Typgenehmigung von Kraftfahrzeugen und Kraftfahrzeuganh&#228;ngern sowie von Systemen, Bauteilen 
und selbstst&#228;ndigen technischen Einheiten f&#252;r diese Fahrzeuge im Hinblick auf ihre allgemeine 
Sicherheit und den Schutz der Fahrzeuginsassen und von ungesch&#252;tzten Verkehrsteilnehmern, zur 
&#196;nderung der Verordnung (EU) 2018/858 des Europ&#228;ischen Parlaments und des Rates und zur 
Aufhebung der Verordnungen (EG) Nr. 78/2009, (EG) Nr. 79/2009 und (EG) Nr. 661/2009 des 
Europ&#228;ischen Parlaments und des Rates sowie der Verordnungen (EG) Nr. 631/2009, (EU) 
Nr. 406/2010, (EU) Nr. 672/2010, (EU) Nr. 1003/2010, (EU) Nr. 1005/2010, (EU) Nr. 1008/2010, (EU) 
Nr. 1009/2010, (EU) Nr. 19/2011, (EU) Nr. 109/2011, (EU) Nr. 458/2011, (EU) Nr. 65/2012, (EU) 
Nr. 130/2012, (EU) Nr. 347/2012, (EU) Nr. 351/2012, (EU) Nr. 1230/2012 und (EU) 2015/166 der 
Kommission (ABl. L 325 vom 16.12.2019, S. 1).
Harmonisierungsrechtsvorschriften der Union fallen, ist es angezeigt, sie im Rahmen 
dieser Verordnung als hochriskant einzustufen, wenn das betreffende Produkt gem&#228;&#223; 
den einschl&#228;gigen Harmonisierungsrechtsvorschriften der Union dem 
Konformit&#228;tsbewertungsverfahren durch eine als unabh&#228;ngige Dritte auftretende 
Konformit&#228;tsbewertungsstelle unterzogen wird. Dabei handelt es sich insbesondere 
um Produkte wie Maschinen, Spielzeuge, Aufz&#252;ge, Ger&#228;te und Schutzsysteme zur 
bestimmungsgem&#228;&#223;en Verwendung in explosionsgef&#228;hrdeten Bereichen, 
Funkanlagen, Druckger&#228;te, Sportbootausr&#252;stung, Seilbahnen, Ger&#228;te zur Verbrennung 
gasf&#246;rmiger Brennstoffe, Medizinprodukte und In-vitro-Diagnostika. 
(31) Die Einstufung eines KI-Systems als hochriskant gem&#228;&#223; dieser Verordnung sollte 
nicht zwangsl&#228;ufig bedeuten, dass von dem Produkt, dessen Sicherheitskomponente 
das KI-System ist, oder dem KI-System als Produkt selbst nach den Kriterien der 
einschl&#228;gigen Harmonisierungsrechtsvorschriften der Union f&#252;r das betreffende 
Produkt ein hohes Risiko ausgeht. Dies betrifft insbesondere die Verordnung 
(EU) 2017/745 des Europ&#228;ischen Parlaments und des Rates47 und die Verordnung 
(EU) 2017/746 des Europ&#228;ischen Parlaments und des Rates48, in denen f&#252;r Produkte, 
die ein mittleres und hohes Risiko bergen, eine Konformit&#228;tsbewertung durch Dritte 
vorgesehen ist. 
(32) Bei eigenst&#228;ndigen KI-Systemen, d. h. Hochrisiko-KI-Systemen, bei denen es sich um 
andere Systeme als Sicherheitskomponenten von Produkten handelt oder die selbst 
Produkte sind, ist es angezeigt, sie als hochriskant einzustufen, wenn sie aufgrund 
ihrer Zweckbestimmung ein hohes Risiko bergen, die Gesundheit und Sicherheit oder 
die Grundrechte von Personen zu sch&#228;digen, wobei sowohl die Schwere des 
m&#246;glichen Schadens als auch die Wahrscheinlichkeit seines Auftretens zu 
ber&#252;cksichtigen sind, und sofern sie in einer Reihe von Bereichen verwendet werden, 
die in der Verordnung ausdr&#252;cklich festgelegt sind. Die Bestimmung dieser Systeme 
erfolgt nach derselben Methode und denselben Kriterien, die auch f&#252;r k&#252;nftige 
&#196;nderungen der Liste der Hochrisiko-KI-Systeme vorgesehen sind. 
(33) Technische Ungenauigkeiten von KI-Systemen, die f&#252;r die biometrische 
Fernidentifizierung nat&#252;rlicher Personen bestimmt sind, k&#246;nnen zu verzerrten 
Ergebnissen f&#252;hren und eine diskriminierende Wirkung haben. Dies ist von besonderer 
Bedeutung, wenn es um das Alter, die ethnische Herkunft, das Geschlecht oder 
Behinderungen geht. Daher sollten biometrische Echtzeit-Fernidentifizierungssysteme 
und Systeme zur nachtr&#228;glichen biometrischen Fernidentifizierung als hochriskant 
eingestuft werden. Angesichts der mit ihnen verbundenen Risiken sollten f&#252;r beide 
Arten von biometrischen Fernidentifizierungssystemen besondere Anforderungen im 
Hinblick auf die Protokollierungsfunktionen und die menschliche Aufsicht gelten. 
(34) Was die Verwaltung und den Betrieb kritischer Infrastrukturen anbelangt, so sollten 
KI-Systeme, die als Sicherheitskomponenten f&#252;r das Management und den Betrieb des 
Stra&#223;enverkehrs sowie f&#252;r die Wasser-, Gas-, W&#228;rme- und Stromversorgung 
verwendet werden sollen, als hochriskant eingestuft werden, da ihr Ausfall oder ihre
47 Verordnung (EU) 2017/745 des Europ&#228;ischen Parlaments und des Rates vom 5. April 2017 &#252;ber 
Medizinprodukte, zur &#196;nderung der Richtlinie 2001/83/EG, der Verordnung (EG) Nr. 178/2002 und der 
Verordnung (EG) Nr. 1223/2009 und zur Aufhebung der Richtlinien 90/385/EWG und 93/42/EWG des 
Rates (ABl. L 117 vom 5.5.2017, S. 1). 
48 Verordnung (EU) 2017/746 des Europ&#228;ischen Parlaments und des Rates vom 5. April 2017 &#252;ber
Invitro-Diagnostika und zur Aufhebung der Richtlinie 98/79/EG und des Beschlusses 2010/227/EU der 
Kommission (ABl. L 117 vom 5.5.2017, S. 176).
St&#246;rung in gro&#223;em Umfang das Leben und die Gesundheit von Menschen gef&#228;hrden 
und zu erheblichen St&#246;rungen bei der normalen Durchf&#252;hrung sozialer und 
wirtschaftlicher T&#228;tigkeiten f&#252;hren kann. 
(35) KI-Systeme, die in der allgemeinen oder beruflichen Bildung eingesetzt werden, 
insbesondere um den Zugang von Personen zu Bildungs- und 
Berufsbildungseinrichtungen oder ihrer Zuordnung dazu zu bestimmen oder um 
Personen im Rahmen von Pr&#252;fungen als Teil ihrer Ausbildung oder als Voraussetzung 
daf&#252;r zu bewerten, sollten als hochriskant angesehen werden, da sie &#252;ber den Verlauf 
der Bildung und des Berufslebens einer Person entscheiden und daher ihre F&#228;higkeit 
beeintr&#228;chtigen k&#246;nnen, ihren Lebensunterhalt zu sichern. Bei unsachgem&#228;&#223;er 
Konzeption und Verwendung k&#246;nnen solche Systeme das Recht auf allgemeine und 
berufliche Bildung sowie das Recht auf Nichtdiskriminierung verletzen und 
historische Diskriminierungsmuster fortschreiben. 
(36) KI-Systeme, die in den Bereichen Besch&#228;ftigung, Personalmanagement und Zugang 
zur Selbstst&#228;ndigkeit eingesetzt werden, insbesondere f&#252;r die Einstellung und Auswahl 
von Personen, f&#252;r Entscheidungen &#252;ber Bef&#246;rderung und K&#252;ndigung sowie f&#252;r die 
Zuweisung, &#220;berwachung oder Bewertung von Personen in 
Arbeitsvertragsverh&#228;ltnissen, sollten ebenfalls als hochriskant eingestuft werden, da 
diese Systeme die k&#252;nftigen Karriereaussichten und die Lebensgrundlagen dieser 
Personen sp&#252;rbar beeinflussen k&#246;nnen. Einschl&#228;gige Arbeitsvertragsverh&#228;ltnisse 
sollten Besch&#228;ftigte und Personen erfassen, die Dienstleistungen &#252;ber Plattformen 
erbringen, auf die im Arbeitsprogramm der Kommission f&#252;r 2021 Bezug genommen 
wird. Solche Personen sollten grunds&#228;tzlich nicht als Nutzer im Sinne dieser 
Verordnung gelten. Solche Systeme k&#246;nnen w&#228;hrend des gesamten 
Einstellungsverfahrens und bei der Bewertung, Bef&#246;rderung oder Nichtbef&#246;rderung 
von Personen in Arbeitsvertragsverh&#228;ltnissen historische Diskriminierungsmuster 
fortschreiben, beispielsweise gegen&#252;ber Frauen, bestimmten Altersgruppen und 
Menschen mit Behinderungen oder Personen mit einer bestimmten rassischen oder 
ethnischen Herkunft oder sexuellen Ausrichtung. KI-Systeme zur &#220;berwachung der 
Leistung und des Verhaltens dieser Personen k&#246;nnen sich auch auf ihre Rechte auf 
Datenschutz und Privatsph&#228;re auswirken. 
(37) Ein weiterer Bereich, in dem der Einsatz von KI-Systemen besondere Aufmerksamkeit 
verdient, ist der Zugang zu und die Nutzung von bestimmten grundlegenden privaten 
und &#246;ffentlichen Diensten und Leistungen, die erforderlich sind, damit die Menschen 
uneingeschr&#228;nkt an der Gesellschaft teilhaben oder ihren Lebensstandard verbessern 
k&#246;nnen. Insbesondere KI-Systeme, die zur Kreditpunktebewertung oder zur 
Bewertung der Kreditw&#252;rdigkeit nat&#252;rlicher Personen verwendet werden, sollten als 
Hochrisiko-KI-Systeme eingestuft werden, da sie den Zugang dieser Personen zu 
Finanzmitteln oder wesentlichen Dienstleistungen wie Wohnraum, Elektrizit&#228;t und 
Telekommunikationsdienstleistungen bestimmen. KI-Systeme, die zu diesem Zweck 
eingesetzt werden, k&#246;nnen zur Diskriminierung von Personen oder Gruppen f&#252;hren 
und historische Diskriminierungsmuster, beispielsweise aufgrund der rassischen oder 
ethnischen Herkunft, einer Behinderung, des Alters oder der sexuellen Ausrichtung, 
fortschreiben oder neue Formen von Diskriminierung mit sich bringen. Angesichts des 
sehr begrenzten Auswirkungen und der auf dem Markt verf&#252;gbaren Alternativen ist es 
angezeigt, KI-Systeme zur Kreditw&#252;rdigkeitspr&#252;fung und Kreditpunktebewertung 
auszunehmen, wenn sie von kleinen Anbietern f&#252;r den Eigenbedarf in Betrieb 
genommen werden. Nat&#252;rliche Personen, die staatliche Unterst&#252;tzungsleistungen 
und -dienste von Beh&#246;rden beantragen oder erhalten, sind in der Regel von diesen
Leistungen und Diensten abh&#228;ngig und befinden sich gegen&#252;ber den zust&#228;ndigen 
Beh&#246;rden in einer prek&#228;ren Lage. Wenn KI-Systeme eingesetzt werden, um zu 
bestimmen, ob solche Leistungen und Dienste von den Beh&#246;rden verweigert, gek&#252;rzt, 
widerrufen oder zur&#252;ckgefordert werden sollten, k&#246;nnen sie erhebliche Auswirkungen 
auf die Existenzgrundlage der Menschen haben und ihre Grundrechte wie das Recht 
auf sozialen Schutz, Nichtdiskriminierung, Menschenw&#252;rde oder einen wirksamen 
Rechtsbehelf verletzen. Solche Systeme sollten daher als hochriskant eingestuft 
werden. Dennoch sollte diese Verordnung die Entwicklung und Anwendung 
innovativer Ans&#228;tze in der &#246;ffentlichen Verwaltung nicht behindern, die von einer 
breiteren Verwendung konformer und sicherer KI-Systeme profitieren w&#252;rde, sofern 
diese Systeme kein hohes Risiko f&#252;r juristische und nat&#252;rliche Personen bergen. 
Schlie&#223;lich sollten KI-Systeme, die bei der Entsendung oder der Priorisierung der 
Entsendung von Rettungsdiensten eingesetzt werden, ebenfalls als hochriskant 
eingestuft werden, da sie in f&#252;r das Leben und die Gesundheit von Personen und f&#252;r 
ihr Eigentum sehr kritischen Situationen Entscheidungen treffen. 
(38) Ma&#223;nahmen von Strafverfolgungsbeh&#246;rden im Zusammenhang mit bestimmten 
Verwendungen von KI-Systemen sind durch ein erhebliches Machtungleichgewicht 
gekennzeichnet und k&#246;nnen zur &#220;berwachung, Festnahme oder zum Entzug der 
Freiheit einer nat&#252;rlichen Person sowie zu anderen nachteiligen Auswirkungen auf die 
in der Charta verankerten Grundrechte f&#252;hren. Insbesondere wenn das KI-System 
nicht mit hochwertigen Daten trainiert wird, die Anforderungen an seine Genauigkeit 
oder Robustheit nicht erf&#252;llt werden oder das System nicht ordnungsgem&#228;&#223; konzipiert 
und getestet wird, bevor es in Verkehr gebracht oder in anderer Weise in Betrieb 
genommen wird, kann es Personen in diskriminierender oder anderweitig falscher oder 
ungerechter Weise ausgrenzen. Dar&#252;ber hinaus k&#246;nnte die Aus&#252;bung wichtiger 
verfahrensrechtlicher Grundrechte wie des Rechts auf einen wirksamen Rechtsbehelf 
und ein unparteiisches Gericht sowie die Unschuldsvermutung und 
Verteidigungsrechte behindert werden, insbesondere wenn solche KI-Systeme nicht 
hinreichend transparent, erkl&#228;rbar und dokumentiert sind. Daher ist es angezeigt, eine 
Reihe von KI-Systemen, die im Rahmen der Strafverfolgung eingesetzt werden sollen 
und bei denen Genauigkeit, Zuverl&#228;ssigkeit und Transparenz besonders wichtig sind, 
als hochriskant einzustufen, um nachteilige Auswirkungen zu vermeiden, das 
Vertrauen der &#214;ffentlichkeit zu erhalten und die Rechenschaftspflicht und einen 
wirksamen Rechtsschutz zu gew&#228;hrleisten. Angesichts der Art der betreffenden 
T&#228;tigkeiten und der damit verbundenen Risiken sollten diese Hochrisiko-KI-Systeme 
insbesondere KI-Systeme umfassen, die von Strafverfolgungsbeh&#246;rden f&#252;r 
individuelle Risikobewertungen, als L&#252;gendetektoren und &#228;hnliche Instrumente oder 
zur Ermittlung des emotionalen Zustands nat&#252;rlicher Personen, zur Aufdeckung von 
&#8222;Deepfakes&#8220;, zur Bewertung der Zuverl&#228;ssigkeit von Beweismitteln in Strafverfahren, 
zur Vorhersage des Auftretens oder erneuten Auftretens einer tats&#228;chlichen oder 
potenziellen Straftat auf der Grundlage des Profils nat&#252;rlicher Personen oder zur 
Bewertung von Pers&#246;nlichkeitsmerkmalen und Eigenschaften oder vergangenen 
kriminellen Verhaltens von nat&#252;rlichen Personen oder Gruppen, zur Erstellung eines 
Profils w&#228;hrend der Aufdeckung, Untersuchung oder strafrechtlichen Verfolgung einer 
Straftat sowie zur Kriminalanalyse in Bezug auf nat&#252;rliche Personen eingesetzt 
werden. KI-Systeme, die speziell f&#252;r Verwaltungsverfahren in Steuer- und 
Zollbeh&#246;rden bestimmt sind, sollten nicht als Hochrisiko-KI-Systeme gelten, die von 
Strafverfolgungsbeh&#246;rden zum Zwecke der Verh&#252;tung, Aufdeckung, Untersuchung 
und strafrechtlichen Verfolgung von Straftaten eingesetzt werden.
(39) KI-Systeme, die in den Bereichen Migration, Asyl und Grenzkontrolle eingesetzt 
werden, betreffen Menschen, die sich h&#228;ufig in einer besonders prek&#228;ren Lage 
befinden und vom Ergebnis der Ma&#223;nahmen der zust&#228;ndigen Beh&#246;rden abh&#228;ngig sind. 
Die Genauigkeit, der nichtdiskriminierende Charakter und die Transparenz der KI-
Systeme, die in solchen Zusammenh&#228;ngen eingesetzt werden, sind daher besonders 
wichtig, um die Achtung der Grundrechte der betroffenen Personen, insbesondere 
ihrer Rechte auf Freiz&#252;gigkeit, Nichtdiskriminierung, den Schutz des Privatlebens und 
personenbezogener Daten, den internationalen Schutz und die gute Verwaltung, zu 
gew&#228;hrleisten. Daher ist es angezeigt, KI-Systeme als hochriskant einzustufen, die von 
den zust&#228;ndigen mit Aufgaben in den Bereichen Migration, Asyl und Grenzkontrolle 
betrauten Beh&#246;rden f&#252;r Folgendes eingesetzt werden: als L&#252;gendetektoren und 
&#228;hnliche Instrumente oder zur Ermittlung des emotionalen Zustand einer nat&#252;rlichen 
Person; zur Bewertung bestimmter Risiken, die von nat&#252;rlichen Personen ausgehen, 
die in das Hoheitsgebiet eines Mitgliedstaats einreisen oder ein Visum oder Asyl 
beantragen; zur &#220;berpr&#252;fung der Echtheit der einschl&#228;gigen Dokumente nat&#252;rlicher 
Personen; zur Unterst&#252;tzung der zust&#228;ndigen Beh&#246;rden bei der Pr&#252;fung von Asyl- und 
Visumantr&#228;gen sowie Aufenthaltstiteln und damit verbundenen Beschwerden im 
Hinblick darauf, die Berechtigung der den Antrag stellenden nat&#252;rlichen Personen 
festzustellen. KI-Systeme im Bereich Migration, Asyl und Grenzkontrolle, die unter 
diese Verordnung fallen, sollten den einschl&#228;gigen Verfahrensvorschriften der 
Richtlinie 2013/32/EU des Europ&#228;ischen Parlaments und des Rates49, der Verordnung 
(EG) Nr. 810/2009 des Europ&#228;ischen Parlaments und des Rates50 und anderen 
einschl&#228;gigen Rechtsvorschriften entsprechen. 
(40) Bestimmte KI-Systeme, die f&#252;r die Rechtspflege und demokratische Prozesse 
bestimmt sind, sollten angesichts ihrer m&#246;glichen erheblichen Auswirkungen auf die 
Demokratie, die Rechtsstaatlichkeit, die individuellen Freiheiten sowie das Recht auf 
einen wirksamen Rechtsbehelf und ein unparteiisches Gericht als hochriskant 
eingestuft werden. Um insbesondere den Risiken m&#246;glicher Verzerrungen, Fehler und 
Undurchsichtigkeiten zu begegnen, sollten KI-Systeme, die Justizbeh&#246;rden dabei 
helfen sollen, Sachverhalte und Rechtsvorschriften zu ermitteln und auszulegen und 
das Recht auf konkrete Sachverhalte anzuwenden, als hochriskant eingestuft werden. 
Diese Einstufung sollte sich jedoch nicht auf KI-Systeme erstrecken, die f&#252;r rein 
begleitende Verwaltungst&#228;tigkeiten bestimmt sind, die die tats&#228;chliche Rechtspflege in 
Einzelf&#228;llen nicht beeintr&#228;chtigen, wie die Anonymisierung oder Pseudonymisierung 
gerichtlicher Urteile, Dokumente oder Daten, die Kommunikation zwischen dem 
Personal, Verwaltungsaufgaben oder die Zuweisung von Ressourcen. 
(41) Die Tatsache, dass ein KI-System gem&#228;&#223; dieser Verordnung als hochriskant eingestuft 
wird, sollte nicht dahingehend ausgelegt werden, dass die Verwendung des Systems 
nach anderen Rechtsakten der Union oder nach nationalen Rechtsvorschriften, die mit 
dem Unionsrecht vereinbar sind, zwangsl&#228;ufig rechtm&#228;&#223;ig ist, beispielsweise in Bezug 
auf den Schutz personenbezogener Daten, die Verwendung von L&#252;gendetektoren und 
&#228;hnlichen Instrumenten oder anderen Systemen zur Ermittlung des emotionalen 
Zustand einer nat&#252;rlichen Person. Eine solche Verwendung sollte weiterhin 
49 Richtlinie 2013/32/EU des Europ&#228;ischen Parlaments und des Rates vom 26. Juni 2013 zu gemeinsamen 
Verfahren f&#252;r die Zuerkennung und Aberkennung des internationalen Schutzes (ABl. L 180 vom 
29.6.2013, S. 60). 
50 Verordnung (EG) Nr. 810/2009 des Europ&#228;ischen Parlaments und des Rates vom 13. Juli 2009 &#252;ber 
einen Visakodex der Gemeinschaft (Visakodex) (ABl. L 243 vom 15.9.2009, S. 1).
ausschlie&#223;lich im Einklang mit den geltenden Anforderungen erfolgen, die sich aus 
der Charta, dem anwendbaren Sekund&#228;rrecht der Union und nationalen Recht ergeben. 
Diese Verordnung sollte nicht so verstanden werden, dass sie eine Rechtsgrundlage f&#252;r 
die Verarbeitung personenbezogener Daten bildet, auch nicht f&#252;r besondere 
Kategorien personenbezogener Daten. 
(42) Zur Minderung der Risiken f&#252;r Nutzer und betroffene Personen, die von auf dem 
Unionsmarkt in Verkehr gebrachten oder anderweitig in Betrieb genommenen 
Hochrisiko-KI-Systemen ausgehen, sollten bestimmte verbindliche Anforderungen 
gelten, wobei der Zweckbestimmung des Systems und dem vom Anbieter 
einzurichtenden Risikomanagementsystem Rechnung zu tragen ist. 
(43) Die Anforderungen sollten f&#252;r Hochrisiko-KI-Systeme im Hinblick auf die Qualit&#228;t 
der verwendeten Datens&#228;tze, die technische Dokumentation und die 
Aufzeichnungspflichten, die Transparenz und die Bereitstellung von Informationen f&#252;r 
die Nutzer, die menschliche Aufsicht sowie die Robustheit, Genauigkeit und 
Cybersicherheit gelten. Diese Anforderungen sind erforderlich, um die Risiken f&#252;r die 
Gesundheit, die Sicherheit und die Grundrechte entsprechend der Zweckbestimmung 
des Systems wirksam zu mindern, und es stehen keine anderen weniger 
handelsbeschr&#228;nkenden Ma&#223;nahmen zur Verf&#252;gung, sodass ungerechtfertigte 
Handelsbeschr&#228;nkungen vermieden werden. 
(44) Eine hohe Datenqualit&#228;t ist f&#252;r die Leistung vieler KI-Systeme von wesentlicher 
Bedeutung, insbesondere wenn Techniken eingesetzt werden, bei denen Modelle mit 
Daten trainiert werden, um sicherzustellen, dass das Hochrisiko-KI-System 
bestimmungsgem&#228;&#223; und sicher funktioniert und nicht zur Ursache f&#252;r Diskriminierung 
wird, die nach dem Unionsrecht verboten ist. F&#252;r hochwertige Trainings-, 
Validierungs- und Testdatens&#228;tze m&#252;ssen geeignete Daten-Governance- und 
Datenverwaltungsverfahren umgesetzt werden. Die Trainings-, Validierungs- und 
Testdatens&#228;tze sollten im Hinblick auf die Zweckbestimmung des Systems 
hinreichend relevant, repr&#228;sentativ, fehlerfrei und vollst&#228;ndig sein. Ferner sollten sie 
die geeigneten statistischen Merkmale haben, auch bez&#252;glich der Personen oder 
Personengruppen, auf die das Hochrisiko-KI-System bestimmungsgem&#228;&#223; angewandt 
werden soll. Insbesondere sollten die Trainings-, Validierungs- und Testdatens&#228;tze, 
soweit dies angesichts der Zweckbestimmung erforderlich ist, den Eigenschaften, 
Merkmalen oder Elementen entsprechen, die f&#252;r die besonderen geografischen, 
verhaltensbezogenen oder funktionalen Rahmenbedingungen oder den 
Zusammenh&#228;ngen, in denen das KI-System bestimmungsgem&#228;&#223; verwendet werden 
soll, typisch sind. Um das Recht anderer auf Schutz vor Diskriminierung, die sich aus 
Verzerrungen in KI-Systemen ergeben k&#246;nnte, zu wahren, sollten die Anbieter 
angesichts des erheblichen &#246;ffentlichen Interesses auch besondere Kategorien 
personenbezogener Daten verarbeiten d&#252;rfen, um Verzerrungen in Hochrisiko-KI-
Systemen zu beobachten, zu erkennen und zu korrigieren. 
(45) F&#252;r die Entwicklung von Hochrisiko-KI-Systemen sollten bestimmte Akteure wie 
Anbieter, notifizierte Stellen und andere einschl&#228;gige Stellen wie Zentren f&#252;r digitale 
Innovation, Erprobungs- und Versuchseinrichtungen und Forscher in der Lage sein, in 
ihren jeweiligen T&#228;tigkeitsbereichen, die mit dieser Verordnung in Zusammenhang 
stehen, auf hochwertige Datens&#228;tze zuzugreifen und diese zu nutzen. Die von der 
Kommission eingerichteten gemeinsamen europ&#228;ischen Datenr&#228;ume und die 
Erleichterung des Datenaustauschs im &#246;ffentlichen Interesse zwischen Unternehmen 
und mit Beh&#246;rden werden entscheidend dazu beitragen, einen vertrauensvollen, 
rechenschaftspflichtigen und diskriminierungsfreien Zugang zu hochwertigen Daten
f&#252;r das Training, die Validierung und das Testen von KI-Systemen zu gew&#228;hrleisten. 
Im Gesundheitsbereich beispielsweise wird der europ&#228;ische Raum f&#252;r 
Gesundheitsdaten den diskriminierungsfreien Zugang zu Gesundheitsdaten und das 
Training von KI-Algorithmen mithilfe dieser Datens&#228;tze erleichtern, und zwar unter 
Wahrung der Privatsph&#228;re, auf sichere, zeitnahe, transparente und vertrauensw&#252;rdige 
Weise und unter angemessener institutioneller Leitung. Die einschl&#228;gigen zust&#228;ndigen 
Beh&#246;rden, einschlie&#223;lich sektoraler Beh&#246;rden, die den Zugang zu Daten bereitstellen 
oder unterst&#252;tzen, k&#246;nnen auch die Bereitstellung hochwertiger Daten f&#252;r das 
Training, die Validierung und das Testen von KI-Systemen unterst&#252;tzen. 
(46) Informationen dar&#252;ber, wie Hochrisiko-KI-Systeme entwickelt wurden und wie sie 
w&#228;hrend ihres gesamten Lebenszyklus funktionieren, sind unerl&#228;sslich, um die 
Einhaltung der Anforderungen dieser Verordnung &#252;berpr&#252;fen zu k&#246;nnen. Dies 
erfordert die F&#252;hrung von Aufzeichnungen und die Verf&#252;gbarkeit einer technischen 
Dokumentation, die alle erforderlichen Informationen enth&#228;lt, um die Einhaltung der 
einschl&#228;gigen Anforderungen durch das KI-System zu beurteilen. Diese Informationen 
sollten die allgemeinen Merkmale, F&#228;higkeiten und Grenzen des Systems, die 
verwendeten Algorithmen, Daten, Trainings-, Test- und Validierungsverfahren sowie 
die Dokumentation des einschl&#228;gigen Risikomanagementsystems umfassen. Die 
technische Dokumentation sollte stets auf dem neuesten Stand gehalten werden. 
(47) Um der Undurchsichtigkeit entgegenzuwirken, die bestimmte KI-Systeme f&#252;r 
nat&#252;rliche Personen unverst&#228;ndlich oder zu komplex erscheinen l&#228;sst, sollte f&#252;r 
Hochrisiko-KI-Systeme ein gewisses Ma&#223; an Transparenz vorgeschrieben werden. Die 
Nutzer sollten in der Lage sein, die Ergebnisse des Systems zu interpretieren und es 
angemessen zu verwenden. Hochrisiko-KI-Systemen sollte daher die einschl&#228;gige 
Dokumentation und Gebrauchsanweisungen beigef&#252;gt sein und diese sollten pr&#228;zise 
und eindeutige Informationen enthalten, gegebenenfalls auch in Bezug auf m&#246;gliche 
Risiken in Bezug auf die Grundrechte und Diskriminierung. 
(48) Hochrisiko-KI-Systeme sollten so konzipiert und entwickelt werden, dass nat&#252;rliche 
Personen ihre Funktionsweise &#252;berwachen k&#246;nnen. Zu diesem Zweck sollte der 
Anbieter des Systems vor dem Inverkehrbringen oder der Inbetriebnahme geeignete 
Ma&#223;nahmen zur Gew&#228;hrleistung der menschlichen Aufsicht festlegen. Insbesondere 
sollten solche Ma&#223;nahmen gegebenenfalls gew&#228;hrleisten, dass das System integrierten 
Betriebseinschr&#228;nkungen unterliegt, &#252;ber die sich das System selbst nicht 
hinwegsetzen kann, dass es auf den menschlichen Bediener reagiert und dass die 
nat&#252;rlichen Personen, denen die menschliche Aufsicht &#252;bertragen wurde, &#252;ber die 
erforderliche Kompetenz, Ausbildung und Befugnis verf&#252;gen, um diese Aufgabe 
wahrzunehmen.
(49) Hochrisiko-KI-Systeme sollten w&#228;hrend ihres gesamten Lebenszyklus best&#228;ndig 
funktionieren und ein angemessenes Ma&#223; an Genauigkeit, Robustheit und 
Cybersicherheit entsprechend dem allgemein anerkannten Stand der Technik 
aufweisen. Der Genauigkeitsgrad und die Genauigkeitskennzahlen sollte den Nutzern 
mitgeteilt werden. 
(50) Die technische Robustheit ist eine wesentliche Voraussetzung f&#252;r Hochrisiko-KI-
Systeme. Sie sollten widerstandf&#228;hig gegen&#252;ber Risiken im Zusammenhang mit den 
Grenzen des Systems (z. B. Fehler, St&#246;rungen, Unstimmigkeiten, unerwartete 
Situationen) sowie gegen&#252;ber b&#246;swilligen Eingriffen sein, die die Sicherheit des KI-
Systems gef&#228;hrden und zu sch&#228;dlichen oder anderweitig unerw&#252;nschtem Verhalten 
f&#252;hren k&#246;nnen. Ein fehlender Schutz vor diesen Risiken k&#246;nnte die Sicherheit
beeintr&#228;chtigen oder sich negativ auf die Grundrechte auswirken, wenn das KI-System 
beispielsweise falsche Entscheidungen trifft oder falsche oder verzerrte Ergebnisse 
hervorbringt. 
(51) Die Cybersicherheit spielt eine entscheidende Rolle, wenn es darum geht 
sicherzustellen, dass KI-Systeme widerstandsf&#228;hig gegen&#252;ber Versuchen b&#246;swilliger 
Dritter sind, unter Ausnutzung der Schwachstellen der Systeme deren Verwendung, 
Verhalten, Leistung oder Sicherheitsmerkmale zu ver&#228;ndern. Cyberangriffe auf KI-
Systeme k&#246;nnen KI-spezifische Ressourcen wie Trainingsdatens&#228;tze (z. B. 
Datenvergiftung) oder trainierte Modelle (z. B. feindliche Angriffe) nutzen oder 
Schwachstellen in den digitalen Ressourcen des KI-Systems oder der zugrunde 
liegenden IKT-Infrastruktur ausnutzen. Um ein den Risiken angemessenes 
Cybersicherheitsniveau zu gew&#228;hrleisten, sollten die Anbieter von Hochrisiko-KI-
Systemen daher geeignete Ma&#223;nahmen ergreifen, wobei gegebenenfalls auch die 
zugrunde liegende IKT-Infrastruktur zu ber&#252;cksichtigen ist. 
(52) Als Teil der Harmonisierungsrechtsvorschriften der Union sollten Vorschriften f&#252;r das 
Inverkehrbringen, die Inbetriebnahme und die Verwendung von Hochrisiko-KI-
Systemen im Einklang mit der Verordnung (EG) Nr. 765/2008 des Europ&#228;ischen 
Parlaments und des Rates51 &#252;ber die Vorschriften f&#252;r die Akkreditierung und 
&#220;berwachung von Produkten, dem Beschluss Nr. 768/2008/EG des Europ&#228;ischen 
Parlaments und des Rates52 &#252;ber einen gemeinsamen Rechtsrahmen f&#252;r die 
Vermarktung von Produkten und der Verordnung (EU) 2019/1020 des Europ&#228;ischen 
Parlaments und des Rates53 &#252;ber Markt&#252;berwachung und die Konformit&#228;t von 
Produkten (&#8222;neuer Rechtsrahmen f&#252;r die Vermarktung von Produkten&#8220;) festgelegt 
werden.
(53) Es ist angemessen, dass eine bestimmte als Anbieter definierte nat&#252;rliche oder 
juristische Person die Verantwortung f&#252;r das Inverkehrbringen oder die 
Inbetriebnahme eines Hochrisiko-KI-Systems &#252;bernimmt, unabh&#228;ngig davon, ob es 
sich bei dieser nat&#252;rlichen oder juristischen Person um die Person handelt, die das 
System konzipiert oder entwickelt hat. 
(54) Der Anbieter sollte ein solides Qualit&#228;tsmanagementsystem einrichten, die 
Durchf&#252;hrung des vorgeschriebenen Konformit&#228;tsbewertungsverfahrens sicherstellen, 
die einschl&#228;gige Dokumentation erstellen und ein robustes System zur Beobachtung 
nach dem Inverkehrbringen einrichten. Beh&#246;rden, die Hochrisiko-KI-Systeme f&#252;r den 
Eigengebrauch in Betrieb nehmen, k&#246;nnen unter Ber&#252;cksichtigung der Besonderheiten 
des Bereichs sowie der Zust&#228;ndigkeiten und der Organisation der betreffenden 
Beh&#246;rde die Vorschriften f&#252;r das Qualit&#228;tsmanagementsystem als Teil des auf 
nationaler oder regionaler Ebene eingesetzten Qualit&#228;tsmanagementsystems annehmen 
und umsetzen. 
51 Verordnung (EG) Nr. 765/2008 des Europ&#228;ischen Parlaments und des Rates vom 9. Juli 2008 &#252;ber die 
Vorschriften f&#252;r die Akkreditierung und Markt&#252;berwachung im Zusammenhang mit der Vermarktung 
von Produkten und zur Aufhebung der Verordnung (EWG) Nr. 339/93 des Rates (ABl. L 218 vom 
13.8.2008, S. 30). 
52 Beschluss Nr. 768/2008/EG des Europ&#228;ischen Parlaments und des Rates vom 9. Juli 2008 &#252;ber einen 
gemeinsamen Rechtsrahmen f&#252;r die Vermarktung von Produkten und Aufhebung des 
Beschlusses 93/465/EWG des Rates (ABl. L 218 vom 13.8.2008, S. 82). 
53 Verordnung (EU) 2019/1020 des Europ&#228;ischen Parlaments und des Rates vom 20. Juni 2019 &#252;ber 
Markt&#252;berwachung und die Konformit&#228;t von Produkten sowie zur &#196;nderung der Richtlinie 2004/42/EG 
und der Verordnungen (EG) Nr. 765/2008 und (EU) Nr. 305/2011 (ABl. L 169 vom 25.6.2019, S. 1).
(55) Wird ein Hochrisiko-KI-System, bei dem es sich um eine Sicherheitskomponente 
eines Produkts handelt, das unter einschl&#228;gige sektorale Rechtsvorschriften des neuen 
Rechtsrahmen f&#228;llt, nicht unabh&#228;ngig von dem Produkt in Verkehr gebracht oder in 
Betrieb genommen, so sollte der Hersteller des Endprodukts im Sinne der 
einschl&#228;gigen Rechtsvorschriften des neuen Rechtsrahmens die in dieser Verordnung 
festgelegten Anbieterpflichten erf&#252;llen und insbesondere sicherstellen, dass das in das 
Endprodukt eingebettete KI-System den Anforderungen dieser Verordnung entspricht. 
(56) Um die Durchsetzung dieser Verordnung zu erm&#246;glichen und gleiche 
Wettbewerbsbedingungen f&#252;r die Akteure zu schaffen, muss unter Ber&#252;cksichtigung 
der verschiedenen Formen der Bereitstellung digitaler Produkte sichergestellt sein, 
dass unter allen Umst&#228;nden eine in der Union ans&#228;ssige oder niedergelassene Person 
den Beh&#246;rden alle erforderlichen Informationen &#252;ber die Konformit&#228;t eines KI-
Systems zur Verf&#252;gung stellen kann. Daher benennen Anbieter, die au&#223;erhalb der 
Union niedergelassen sind, vor der Bereitstellung ihrer KI-Systeme in der Union 
schriftlich einen in der Union niedergelassenen Bevollm&#228;chtigten f&#252;r den Fall, dass 
kein Einf&#252;hrer ermittelt werden kann.
(57) Im Einklang mit den Grunds&#228;tzen des neuen Rechtsrahmens sollten besondere 
Verpflichtungen f&#252;r einschl&#228;gige Wirtschaftsakteure, wie Einf&#252;hrer und H&#228;ndler, 
festgelegt werden, um die Rechtssicherheit zu gew&#228;hrleisten und die Einhaltung der 
Rechtsvorschriften durch die betreffenden Wirtschaftsakteure zu erleichtern. 
(58) Angesichts des Charakters von KI-Systemen und der Risiken f&#252;r die Sicherheit und 
die Grundrechte, die mit ihrer Verwendung verbunden sein k&#246;nnen, ist es angebracht, 
besondere Zust&#228;ndigkeiten f&#252;r die Nutzer festzulegen, auch im Hinblick darauf, dass 
eine angemessene &#220;berwachung der Leistung eines KI-Systems unter realen 
Bedingungen sichergestellt werden muss. Die Nutzer sollten insbesondere Hochrisiko-
KI-Systeme gem&#228;&#223; der Gebrauchsanweisung verwenden, und es sollten bestimmte 
andere Pflichten in Bezug auf die &#220;berwachung der Funktionsweise der KI-Systeme 
und gegebenenfalls auch Aufzeichnungspflichten festgelegt werden. 
(59) Es ist angemessen, davon auszugehen, dass der Nutzer des KI-Systems eine nat&#252;rliche 
oder juristische Person oder eine Beh&#246;rde, Einrichtung oder sonstige Stelle ist, die f&#252;r 
den Betrieb eines KI-Systems verantwortlich ist, es sei denn, das KI-System wird im 
Rahmen einer pers&#246;nlichen nicht beruflichen T&#228;tigkeit verwendet. 
(60) Angesichts der Komplexit&#228;t der Wertsch&#246;pfungskette im Bereich der k&#252;nstlichen 
Intelligenz sollten einschl&#228;gige Dritte, insbesondere diejenigen, die am Verkauf und 
der Bereitstellung von Software, Software-Tools und Komponenten, vortrainierten 
Modellen und Daten beteiligt sind, oder Netzdienstbetreiber gegebenenfalls mit 
Anbietern und Nutzern, denen die Einhaltung der Verpflichtungen aus dieser 
Verordnung erm&#246;glicht werden soll, und mit den gem&#228;&#223; dieser Verordnung 
eingerichteten zust&#228;ndigen Beh&#246;rden zusammenarbeiten. 
(61) Die Normung sollte eine Schl&#252;sselrolle dabei spielen, den Anbietern technische 
L&#246;sungen zur Verf&#252;gung zu stellen, um die Einhaltung dieser Verordnung zu 
gew&#228;hrleisten. Die Einhaltung harmonisierter Normen gem&#228;&#223; der Verordnung (EU) 
Nr. 1025/2012 des Europ&#228;ischen Parlaments und des Rates54 sollte den Anbietern den
54 Verordnung (EU) Nr. 1025/2012 des Europ&#228;ischen Parlaments und des Rates vom 25. Oktober 2012 
zur europ&#228;ischen Normung, zur &#196;nderung der Richtlinien 89/686/EWG und 93/15/EWG des Rates 
sowie der Richtlinien 94/9/EG, 94/25/EG, 95/16/EG, 97/23/EG, 98/34/EG, 2004/22/EG, 2007/23/EG, 
2009/23/EG und 2009/105/EG des Europ&#228;ischen Parlaments und des Rates und zur Aufhebung des
Nachweis der Konformit&#228;t mit den Anforderungen dieser Verordnung erm&#246;glichen. 
Die Kommission k&#246;nnte jedoch gemeinsame technische Spezifikationen in Bereichen 
annehmen, in denen es keine harmonisierten Normen gibt oder diese unzureichend 
sind. 
(62) Um ein hohes Ma&#223; an Vertrauensw&#252;rdigkeit von Hochrisiko-KI-Systemen zu 
gew&#228;hrleisten, sollten diese Systeme einer Konformit&#228;tsbewertung unterzogen 
werden, bevor sie in Verkehr gebracht oder in Betrieb genommen werden. 
(63) Damit f&#252;r die Betreiber m&#246;glichst wenig Aufwand entsteht und etwaige Doppelarbeit 
vermieden wird, sollte bei Hochrisiko-KI-Systemen im Zusammenhang mit 
Produkten, die nach dem neuen Rechtsrahmen unter bestehende 
Harmonisierungsrechtsvorschriften der Union fallen, im Rahmen der bereits in diesen 
Rechtsvorschriften vorgesehenen Konformit&#228;tsbewertung bewertet werden, ob diese 
KI-Systeme den Anforderungen dieser Verordnung gen&#252;gen. Die Anwendbarkeit der 
Anforderungen dieser Verordnung sollte daher die besondere Logik, die Methodik 
oder die allgemeine Struktur der Konformit&#228;tsbewertung gem&#228;&#223; den einschl&#228;gigen 
spezifischen Rechtsvorschriften des neuen Rechtsrahmens unber&#252;hrt lassen. Dieser 
Ansatz spiegelt sich voll und ganz in der Wechselwirkung zwischen dieser 
Verordnung und der [Maschinenverordnung] wider. Bei den Anforderungen in dieser 
Verordnung geht es um die Sicherheitsrisiken, die von KI-Systemen ausgehen, die 
Sicherheitsfunktionen in Maschinen steuern, wogegen bestimmte spezifische 
Anforderungen der [Maschinenverordnung] gew&#228;hrleisten werden, dass ein KI-System 
auf sichere Weise in die gesamte Maschine integriert wird, damit die Sicherheit der 
Maschine insgesamt nicht beeintr&#228;chtigt wird. In der [Maschinenverordnung] wird der 
Begriff &#8222;KI-System&#8220; genauso wie in dieser Verordnung definiert. 
(64) Angesichts der umfassenderen Erfahrung professioneller dem Inverkehrbringen 
vorgeschalteter Zertifizierer im Bereich der Produktsicherheit und der 
unterschiedlichen Art der damit verbundenen Risiken empfiehlt es sich, zumindest 
w&#228;hrend der anf&#228;nglichen Anwendung dieser Verordnung f&#252;r Hochrisiko-KI-Systeme, 
die nicht mit Produkten in Verbindung stehen, den Anwendungsbereich der 
Konformit&#228;tsbewertung durch Dritte einzuschr&#228;nken. Daher sollte die 
Konformit&#228;tsbewertung solcher Systeme in der Regel vom Anbieter in eigener 
Verantwortung durchgef&#252;hrt werden, mit Ausnahme von KI-Systemen, die zur 
biometrischen Fernidentifizierung von Personen verwendet werden sollen, bei denen 
die Beteiligung einer notifizierten Stelle an der Konformit&#228;tsbewertung vorgesehen 
werden sollte, soweit diese Systeme nicht ganz verboten sind. 
(65) Damit KI-Systeme, die zur biometrischen Fernidentifizierung von Personen verwendet 
werden sollen, einer Konformit&#228;tsbewertung durch Dritte unterzogen werden k&#246;nnen, 
sollten die notifizierten Stellen gem&#228;&#223; dieser Verordnung von den zust&#228;ndigen 
nationalen Beh&#246;rden benannt werden, sofern sie eine Reihe von Anforderungen 
erf&#252;llen, insbesondere in Bezug auf Unabh&#228;ngigkeit, Kompetenz und Nichtvorliegen 
von Interessenkonflikten. 
(66) Im Einklang mit dem allgemein anerkannten Begriff der wesentlichen &#196;nderung von 
Produkten, f&#252;r die Harmonisierungsrechtsvorschriften der Union gelten, ist es 
angebracht, dass ein KI-System einer neuen Konformit&#228;tsbewertung unterzogen wird, 
wenn eine &#196;nderung eintritt, die die Einhaltung dieser Verordnung durch das System
Beschlusses 87/95/EWG des Rates und des Beschlusses Nr. 1673/2006/EG des Europ&#228;ischen 
Parlaments und des Rates (ABl. L 316 vom 14.11.2012, S. 12).
beeintr&#228;chtigen k&#246;nnte, oder wenn sich die Zweckbestimmung des Systems &#228;ndert. 
Dar&#252;ber hinaus m&#252;ssen in Bezug auf KI-Systeme, die nach dem Inverkehrbringen oder 
der Inbetriebnahme weiterhin dazulernen (d. h. sie passen automatisch an, wie die 
Funktionen ausgef&#252;hrt werden), Vorschriften festgelegt werden, nach denen 
&#196;nderungen des Algorithmus und seiner Leistung, die vom Anbieter vorab festgelegt 
und zum Zeitpunkt der Konformit&#228;tsbewertung bewertet wurden, keine wesentliche 
&#196;nderung darstellen sollten. 
(67) Hochrisiko-KI-Systeme sollten grunds&#228;tzlich mit der CE-Kennzeichnung versehen 
sein, aus der ihre Konformit&#228;t mit dieser Verordnung hervorgeht, sodass sie frei im 
Binnenmarkt verkehren k&#246;nnen. Die Mitgliedstaaten sollten keine ungerechtfertigten 
Hindernisse f&#252;r das Inverkehrbringen oder die Inbetriebnahme von Hochrisiko-KI-
Systemen schaffen, die die in dieser Verordnung festgelegten Anforderungen erf&#252;llen 
und mit der CE-Kennzeichnung versehen sind. 
(68) Unter bestimmten Bedingungen kann die rasche Verf&#252;gbarkeit innovativer Technik f&#252;r 
die Gesundheit und Sicherheit von Menschen und f&#252;r die Gesellschaft insgesamt von 
entscheidender Bedeutung sein. Es ist daher angebracht, dass die Mitgliedstaaten aus 
au&#223;ergew&#246;hnlichen Gr&#252;nden der &#246;ffentlichen Sicherheit, des Schutzes des Lebens und 
der Gesundheit nat&#252;rlicher Personen und des Schutzes des gewerblichen und 
kommerziellen Eigentums das Inverkehrbringen oder die Inbetriebnahme von KI-
Systemen, die keiner Konformit&#228;tsbewertung unterzogen wurden, genehmigen 
k&#246;nnten. 
(69) Um die Arbeit der Kommission und der Mitgliedstaaten im Bereich der k&#252;nstlichen 
Intelligenz zu erleichtern und die Transparenz gegen&#252;ber der &#214;ffentlichkeit zu 
erh&#246;hen, sollten Anbieter von Hochrisiko-KI-Systemen, die nicht mit Produkten in 
Verbindung stehen, die unter die einschl&#228;gigen Harmonisierungsrechtsvorschriften der 
Union fallen, dazu verpflichtet werden, ihr Hochrisiko-KI-System in einer von der 
Kommission einzurichtenden und zu verwaltenden EU-Datenbank zu registrieren. Die 
Kommission sollte im Einklang mit der Verordnung (EU) 2018/1725 des 
Europ&#228;ischen Parlaments und des Rates55 als f&#252;r die Datenbank verantwortliche Stelle 
gelten. Um die volle Funktionsf&#228;higkeit der Datenbank zu gew&#228;hrleisten, sollte das 
Verfahren f&#252;r die Einrichtung der Datenbank auch die Ausarbeitung von funktionalen 
Spezifikationen durch die Kommission und einen unabh&#228;ngigen Pr&#252;fbericht umfassen. 
(70) Bestimmte KI-Systeme, die mit nat&#252;rlichen Personen interagieren oder Inhalte 
erzeugen sollen, k&#246;nnen unabh&#228;ngig davon, ob sie als hochriskant eingestuft werden, 
ein besonderes Risiko in Bezug auf Identit&#228;tsbetrug oder T&#228;uschung bergen. Unter 
bestimmten Umst&#228;nden sollte die Verwendung solcher Systeme daher &#8211; unbeschadet 
der Anforderungen an und Verpflichtungen f&#252;r Hochrisiko-KI-Systeme &#8211; besonderen 
Transparenzpflichten unterliegen. Insbesondere sollte nat&#252;rlichen Personen mitgeteilt 
werden, dass sie es mit einem KI-System zu tun haben, es sei denn, dies ist aufgrund 
der Umst&#228;nde und des Kontexts der Nutzung offensichtlich. Dar&#252;ber hinaus sollten 
nat&#252;rliche Personen informiert werden, wenn sie einem Emotionserkennungssystem 
oder einem System zur biometrischen Kategorisierung ausgesetzt sind. Diese 
Informationen und Mitteilungen sollten f&#252;r Menschen mit Behinderungen in 
55 Verordnung (EU) 2016/679 des Europ&#228;ischen Parlaments und des Rates vom 27. April 2016 zum 
Schutz nat&#252;rlicher Personen bei der Verarbeitung personenbezogener Daten, zum freien Datenverkehr 
und zur Aufhebung der Richtlinie 95/46/EG (Datenschutz-Grundverordnung) (ABl. L 119 vom 
4.5.2016, S. 1).
entsprechend barrierefrei zug&#228;nglicher Form bereitgestellt werden. Dar&#252;ber hinaus 
sollten Nutzer, die ein KI-System zum Erzeugen oder Manipulieren von Bild-,
Tonoder Videoinhalten verwenden, die wirklichen Personen, Orten oder Ereignissen 
merklich &#228;hneln und einer Person f&#228;lschlicherweise echt erscheinen w&#252;rden, 
offenlegen, dass die Inhalte k&#252;nstlich erzeugt oder manipuliert wurden, indem sie die 
Ergebnisse k&#252;nstlicher Intelligenz entsprechend kennzeichnen und auf ihren 
k&#252;nstlichen Ursprung hinweisen. 
(71) K&#252;nstliche Intelligenz bezeichnet eine Reihe sich rasch entwickelnder Technologien, 
die neuartige Formen der Regulierungsaufsicht und einen sicheren Raum f&#252;r die 
Erprobung erfordern, wobei gleichzeitig eine verantwortungsvolle Innovation und die 
Integration geeigneter Schutzvorkehrungen und Risikominderungsma&#223;nahmen 
gew&#228;hrleistet werden m&#252;ssen. Um einen innovationsfreundlichen, zukunftssicheren 
und gegen&#252;ber St&#246;rungen widerstandsf&#228;higen Rechtsrahmen sicherzustellen, sollten 
die zust&#228;ndigen nationalen Beh&#246;rden eines oder mehrerer Mitgliedstaaten angehalten 
werden, Reallabore f&#252;r k&#252;nstliche Intelligenz einzurichten, um die Entwicklung und 
Erprobung innovativer KI-Systeme vor deren Inverkehrbringen oder anderweitiger 
Inbetriebnahme unter strenger Regulierungsaufsicht zu erleichtern. 
(72) Die Ziele der Reallabore sollten darin bestehen, Innovationen im Bereich KI zu 
f&#246;rdern, indem eine kontrollierte Versuchs- und Erprobungsumgebung f&#252;r die 
Entwicklungsphase und die dem Inverkehrbringen vorgelagerte Phase geschaffen 
wird, um sicherzustellen, dass die innovativen KI-Systeme mit dieser Verordnung und 
anderen einschl&#228;gigen Rechtsvorschriften der Union und der Mitgliedstaaten in 
Einklang stehen. Dar&#252;ber hinaus sollen sie die Rechtssicherheit f&#252;r Innovatoren sowie 
die Aufsicht und das Verst&#228;ndnis der zust&#228;ndigen Beh&#246;rden in Bezug auf die 
M&#246;glichkeiten, neu auftretenden Risiken und der Auswirkungen der KI-Nutzung 
verbessern und den Marktzugang beschleunigen, unter anderem indem Hindernisse f&#252;r 
kleine und mittlere Unternehmen (KMU) und Start-up-Unternehmen abgebaut werden. 
Im Interesse einer unionsweit einheitlichen Umsetzung und der Erzielung von 
Gr&#246;&#223;envorteilen sollten gemeinsame Vorschriften f&#252;r die Umsetzung von Reallaboren 
und ein Rahmen f&#252;r die Zusammenarbeit zwischen den an der Beaufsichtigung der 
Reallabore beteiligten Beh&#246;rden festgelegt werden. Die vorliegende Verordnung sollte 
im Einklang mit Artikel 6 Absatz 4 der Verordnung (EU) 2016/679 und Artikel 6 der 
Verordnung (EU) 2018/1725 sowie unbeschadet des Artikels 4 Absatz 2 der Richtlinie 
(EU) 2016/680 die Rechtsgrundlage f&#252;r die Verwendung personenbezogener Daten, 
die f&#252;r andere Zwecke erhoben werden, zur Entwicklung bestimmter KI-Systeme im 
&#246;ffentlichen Interesse innerhalb der KI-Reallabore bilden. Die am Reallabor 
Beteiligten sollten angemessene Schutzvorkehrungen treffen und mit den zust&#228;ndigen 
Beh&#246;rden zusammenarbeiten, unter anderem indem sie deren Anweisungen befolgen 
und z&#252;gig und nach Treu und Glauben handeln, um etwaige hohe Risiken f&#252;r die 
Sicherheit und die Grundrechte, die bei der Entwicklung und Erprobung im Reallabor 
auftreten k&#246;nnen, zu mindern. Das Verhalten der am Reallabor Beteiligten sollte 
ber&#252;cksichtigt werden, wenn die zust&#228;ndigen Beh&#246;rden entscheiden, ob sie eine 
Geldbu&#223;e gem&#228;&#223; Artikel 83 Absatz 2 der Verordnung (EU) 2016/679 und Artikel 57 
der Richtlinie (EU) 2016/680 verh&#228;ngen. 
(73) Um Innovationen zu f&#246;rdern und zu sch&#252;tzen, ist es wichtig, die Interessen kleiner 
Anbieter und Nutzer von KI-Systemen besonders zu ber&#252;cksichtigen. Zu diesem 
Zweck sollten die Mitgliedstaaten Initiativen ergreifen, die sich an diese Akteure 
richten, darunter auch Sensibilisierungs- und Informationsma&#223;nahmen. Dar&#252;ber 
hinaus sind die besonderen Interessen und Bed&#252;rfnisse kleinerer Anbieter bei der
Festlegung der Geb&#252;hren f&#252;r die Konformit&#228;tsbewertung durch die notifizierten 
Stellen zu ber&#252;cksichtigen. &#220;bersetzungen im Zusammenhang mit der verpflichtenden 
Dokumentation und Kommunikation mit Beh&#246;rden k&#246;nnen f&#252;r Anbieter und andere 
Akteure, insbesondere den kleineren unter ihnen, erhebliche Kosten verursachen. Die 
Mitgliedstaaten sollten m&#246;glichst daf&#252;r sorgen, dass eine der Sprachen, die sie f&#252;r die 
einschl&#228;gige Dokumentation der Anbieter und f&#252;r die Kommunikation mit den 
Akteuren bestimmen und akzeptieren, eine Sprache ist, die von der gr&#246;&#223;tm&#246;glichen 
Zahl grenz&#252;berschreitender Nutzer weitgehend verstanden wird. 
(74) Um die Risiken bei der Durchf&#252;hrung, die sich aus mangelndem Wissen und 
fehlenden Fachkenntnissen auf dem Markt ergeben, zu minimieren und den Anbietern 
und notifizierten Stellen die Einhaltung ihrer Verpflichtungen aus dieser Verordnung 
zu erleichtern, sollten die KI-Abruf-Plattform, die europ&#228;ischen Zentren f&#252;r digitale 
Innovation und die Erprobungs- und Versuchseinrichtungen, die von der Kommission 
und den Mitgliedstaaten auf nationaler oder EU-Ebene eingerichtet wurden/werden, 
m&#246;glichst zur Durchf&#252;hrung dieser Verordnung beitragen. Sie k&#246;nnen Anbieter und 
notifizierte Stellen im Rahmen ihres jeweiligen Auftrags und ihrer jeweiligen 
Kompetenzbereiche insbesondere technisch und wissenschaftlich unterst&#252;tzen. 
(75) Es ist angezeigt, dass die Kommission den Stellen, Gruppen oder Laboratorien, die 
gem&#228;&#223; den einschl&#228;gigen Harmonisierungsrechtsvorschriften der Union eingerichtet 
oder akkreditiert sind und Aufgaben im Zusammenhang mit der 
Konformit&#228;tsbewertung von Produkten oder Ger&#228;ten wahrnehmen, die unter diese 
Harmonisierungsrechtsvorschriften der Union fallen, soweit wie m&#246;glich den Zugang 
zu Erprobungs- und Versuchseinrichtungen erleichtert. Dies gilt insbesondere f&#252;r 
Expertengremien, Fachlaboratorien und Referenzlaboratorien im Bereich 
Medizinprodukte gem&#228;&#223; der Verordnung (EU) 2017/745 und der Verordnung 
(EU) 2017/746. 
(76) Um eine reibungslose, wirksame und harmonisierte Umsetzung dieser Verordnung zu 
erleichtern, sollte ein Europ&#228;ischer Ausschuss f&#252;r k&#252;nstliche Intelligenz eingerichtet 
werden. Der Ausschuss sollte f&#252;r eine Reihe von Beratungsaufgaben zust&#228;ndig sein 
und Stellungnahmen, Empfehlungen, Ratschl&#228;gen oder Leitlinien zu Fragen im 
Zusammenhang mit der Umsetzung dieser Verordnung abgeben, darunter zu 
technischen Spezifikationen oder bestehenden Normen in Bezug auf die in dieser 
Verordnung festgelegten Anforderungen; au&#223;erdem sollte er die Kommission in 
spezifischen Fragen im Zusammenhang mit k&#252;nstlicher Intelligenz beraten und 
unterst&#252;tzen. 
(77) Den Mitgliedstaaten kommt bei der Anwendung und Durchsetzung dieser Verordnung 
eine Schl&#252;sselrolle zu. Dazu sollte jeder Mitgliedstaat eine oder mehrere zust&#228;ndige 
nationale Beh&#246;rden benennen, die die Anwendung und Umsetzung dieser Verordnung 
beaufsichtigen. Um die Effizienz der Organisation aufseiten der Mitgliedstaaten zu 
steigern und eine offizielle Kontaktstelle gegen&#252;ber der &#214;ffentlichkeit und anderen 
Ansprechpartnern auf Ebene der Mitgliedstaaten und der Union einzurichten, sollte in 
jedem Mitgliedstaat eine nationale Beh&#246;rde als nationale Aufsichtsbeh&#246;rde benannt 
werden.
(78) Damit Anbieter von Hochrisiko-KI-Systemen die Erfahrungen mit der Verwendung 
von Hochrisiko-KI-Systemen bei der Verbesserung ihrer Systeme und im 
Konzeptions- und Entwicklungsprozess ber&#252;cksichtigen oder rechtzeitig etwaige 
Korrekturma&#223;nahmen ergreifen k&#246;nnen, sollten alle Anbieter &#252;ber ein System zur 
Beobachtung nach dem Inverkehrbringen verf&#252;gen. Dieses System ist auch wichtig,
damit den m&#246;glichen Risiken, die von KI-Systemen ausgehen, die nach dem 
Inverkehrbringen oder der Inbetriebnahme dazulernen, wirksamer und zeitnah 
begegnet werden kann. In diesem Zusammenhang sollten die Anbieter auch 
verpflichtet sein, ein System einzurichten, um den zust&#228;ndigen Beh&#246;rden 
schwerwiegende Vorf&#228;lle oder Verst&#246;&#223;e gegen nationales Recht und Unionsrecht zum 
Schutz der Grundrechte zu melden, die sich aus der Verwendung ihrer KI-Systeme 
ergeben. 
(79) Zur Gew&#228;hrleistung einer angemessenen und wirksamen Durchsetzung der 
Anforderungen und Verpflichtungen gem&#228;&#223; dieser Verordnung, bei der es sich eine 
Harmonisierungsrechtsvorschrift der Union handelt, sollte das mit der Verordnung 
(EU) 2019/1020 eingef&#252;hrte System der Markt&#252;berwachung und der Konformit&#228;t von 
Produkten in vollem Umfang gelten. Sofern dies f&#252;r die Erf&#252;llung ihres Auftrags 
erforderlich ist, sollten auch nationale Beh&#246;rden oder Stellen, die die Anwendung des 
Unionsrechts zum Schutz der Grundrechte &#252;berwachen, einschlie&#223;lich 
Gleichstellungsstellen, Zugang zu der gesamten im Rahmen dieser Verordnung 
erstellten Dokumentation haben.
(80) Die Rechtsvorschriften der Union &#252;ber Finanzdienstleistungen enthalten Vorschriften 
und Anforderungen f&#252;r die interne Unternehmensf&#252;hrung und das Risikomanagement, 
die f&#252;r regulierte Finanzinstitute bei der Erbringung solcher Dienstleistungen gelten, 
auch wenn sie KI-Systeme verwenden. Um eine koh&#228;rente Anwendung und 
Durchsetzung der Verpflichtungen aus dieser Verordnung sowie der einschl&#228;gigen 
Vorschriften und Anforderungen der Rechtsvorschriften der Union f&#252;r 
Finanzdienstleistungen zu gew&#228;hrleisten, sollten die f&#252;r die Beaufsichtigung und 
Durchsetzung der Rechtsvorschriften im Bereich der Finanzdienstleistungen 
zust&#228;ndigen Beh&#246;rden, gegebenenfalls einschlie&#223;lich der Europ&#228;ischen Zentralbank, 
auch als zust&#228;ndige Beh&#246;rden f&#252;r die &#220;berwachung der Durchf&#252;hrung dieser 
Verordnung, einschlie&#223;lich der Markt&#252;berwachungst&#228;tigkeiten, in Bezug auf von 
regulierten und beaufsichtigten Finanzinstituten bereitgestellte oder verwendete KI-
Systeme benannt werden. Um die Koh&#228;renz zwischen dieser Verordnung und den 
Vorschriften f&#252;r Kreditinstitute, die unter die Richtlinie 2013/36/EU des Europ&#228;ischen 
Parlaments und des Rates56 fallen, weiter zu verbessern, ist es ferner angezeigt, das 
Konformit&#228;tsbewertungsverfahren und einige verfahrenstechnische Anbieterpflichten 
in Bezug auf das Risikomanagement, die Beobachtung nach dem Inverkehrbringen 
und die Dokumentation in die bestehenden Verpflichtungen und Verfahren gem&#228;&#223; der 
Richtlinie 2013/36/EU aufzunehmen. Zur Vermeidung von &#220;berschneidungen sollten 
auch begrenzte Ausnahmen in Bezug auf das Qualit&#228;tsmanagementsystem der 
Anbieter und die Beobachtungspflichten der Nutzer von Hochrisiko-KI-Systemen in 
Betracht gezogen werden, soweit diese Kreditinstitute betreffen, die unter die 
Richtlinie 2013/36/EU fallen. 
(81) Die Entwicklung anderer KI-Systeme als Hochrisiko-KI-Systeme im Einklang mit den 
Anforderungen dieser Verordnung kann zu einer st&#228;rkeren Verbreitung 
vertrauensw&#252;rdiger k&#252;nstlicher Intelligenz in der Union f&#252;hren. Anbieter von KI-
Systemen, die kein hohes Risiko bergen, sollten angehalten werden, Verhaltenskodizes 
zu erstellen, um eine freiwillige Anwendung der f&#252;r Hochrisiko-KI-Systeme
56 Richtlinie 2013/36/EU des Europ&#228;ischen Parlaments und des Rates vom 26. Juni 2013 &#252;ber den Zugang 
zur T&#228;tigkeit von Kreditinstituten und die Beaufsichtigung von Kreditinstituten und Wertpapierfirmen, 
zur &#196;nderung der Richtlinie 2002/87/EG und zur Aufhebung der Richtlinien 2006/48/EG 
und 2006/49/EG (ABl. L 176 vom 27.6.2013, S. 338).
verbindlichen Anforderungen zu f&#246;rdern. Dar&#252;ber hinaus sollten die Anbieter auch 
ermutigt werden, freiwillig zus&#228;tzliche Anforderungen anzuwenden, z. B. in Bezug auf 
die &#246;kologische Nachhaltigkeit, die barrierefreie Zug&#228;nglichkeit f&#252;r Menschen mit 
Behinderungen, die Beteiligung der Interessentr&#228;ger an der Konzeption und 
Entwicklung von KI-Systemen und die Vielfalt der Entwicklungsteams. Die 
Kommission kann Initiativen, auch sektoraler Art, ergreifen, um den Abbau 
technischer Hindernisse zu erleichtern, die den grenz&#252;berschreitenden Datenaustausch 
im Zusammenhang mit der KI-Entwicklung behindern, unter anderem in Bezug auf 
die Infrastruktur f&#252;r den Datenzugang und die semantische und technische 
Interoperabilit&#228;t verschiedener Arten von Daten. 
(82) Es ist wichtig, dass KI-Systeme im Zusammenhang mit Produkten, die gem&#228;&#223; dieser 
Verordnung kein hohes Risiko bergen und daher nicht die in dieser Verordnung 
festgelegten Anforderungen erf&#252;llen m&#252;ssen, dennoch sicher sind, wenn sie in Verkehr 
gebracht oder in Betrieb genommen werden. Um zu diesem Ziel beizutragen, w&#252;rde 
die Richtlinie 2001/95/EG des Europ&#228;ischen Parlaments und des Rates57 als 
Sicherheitsnetz dienen.
(83) Zur Gew&#228;hrleistung einer vertrauensvollen und konstruktiven Zusammenarbeit der 
zust&#228;ndigen Beh&#246;rden auf Ebene der Union und der Mitgliedstaaten, sollten alle an der 
Anwendung dieser Verordnung beteiligten Parteien die Vertraulichkeit der im Rahmen 
der Durchf&#252;hrung ihrer T&#228;tigkeiten erlangten Informationen und Daten wahren. 
(84) Die Mitgliedstaaten sollten alle erforderlichen Ma&#223;nahmen ergreifen, um 
sicherzustellen, dass die Bestimmungen dieser Verordnung eingehalten werden, und 
dazu u. a. wirksame, verh&#228;ltnism&#228;&#223;ige und abschreckende Sanktionen f&#252;r Verst&#246;&#223;e 
festlegen. Bei bestimmten Verst&#246;&#223;en sollten die Mitgliedstaaten die in dieser 
Verordnung festgelegten Spielr&#228;ume und Kriterien ber&#252;cksichtigen. Der Europ&#228;ische 
Datenschutzbeauftragte sollte befugt sein, gegen Organe, Einrichtungen und sonstige 
Stellen der Union, die in den Anwendungsbereich dieser Verordnung fallen, 
Geldbu&#223;en zu verh&#228;ngen. 
(85) Damit der Rechtsrahmen erforderlichenfalls angepasst werden kann, sollte der 
Kommission die Befugnis &#252;bertragen werden, gem&#228;&#223; Artikel 290 AEUV Rechtsakte 
zur &#196;nderung der in Anhang I genannten Techniken und Konzepte f&#252;r die Einstufung 
von KI-Systemen, der in Anhang II aufgef&#252;hrten Harmonisierungsrechtsvorschriften 
der Union, der in Anhang III aufgef&#252;hrten Hochrisiko-KI-Systeme, der Bestimmungen 
&#252;ber die technische Dokumentation in Anhang IV, des Inhalts der EU-
Konformit&#228;tserkl&#228;rung in Anhang V, der Bestimmungen &#252;ber die 
Konformit&#228;tsbewertungsverfahren in den Anh&#228;ngen VI und VII und der 
Bestimmungen zur Festlegung der Hochrisiko-KI-Systeme zu erlassen, f&#252;r die das 
Konformit&#228;tsbewertungsverfahren auf der Grundlage der Bewertung des 
Qualit&#228;tsmanagementsystems und der technischen Dokumentation gelten sollte. Es ist 
von besonderer Bedeutung, dass die Kommission im Zuge ihrer Vorbereitungsarbeit 
angemessene Konsultationen, auch auf der Ebene von Sachverst&#228;ndigen, durchf&#252;hrt, 
die mit den Grunds&#228;tzen in Einklang stehen, die in der Interinstitutionellen 
Vereinbarung vom 13. April 2016 &#252;ber bessere Rechtsetzung58 niedergelegt wurden. 
Um insbesondere f&#252;r eine gleichberechtigte Beteiligung an der Vorbereitung 
57 Richtlinie 2001/95/EG des Europ&#228;ischen Parlaments und des Rates vom 3. Dezember 2001 &#252;ber die 
allgemeine Produktsicherheit (ABl. L 11 vom 15.1.2002, S. 4). 
58 ABl. L 123 vom 12.5.2016, S. 1.
delegierter Rechtsakte zu sorgen, erhalten das Europ&#228;ische Parlament und der Rat alle 
Dokumente zur gleichen Zeit wie die Sachverst&#228;ndigen der Mitgliedstaaten, und ihre 
Sachverst&#228;ndigen haben systematisch Zugang zu den Sitzungen der 
Sachverst&#228;ndigengruppen der Kommission, die mit der Vorbereitung der delegierten 
Rechtsakte befasst sind. 
(86) Zur Gew&#228;hrleistung einheitlicher Bedingungen f&#252;r die Durchf&#252;hrung dieser 
Verordnung sollten der Kommission Durchf&#252;hrungsbefugnisse &#252;bertragen werden. 
Diese Befugnisse sollten im Einklang mit der Verordnung (EU) Nr. 182/2011 des 
Europ&#228;ischen Parlaments und des Rates59 ausge&#252;bt werden. 
(87) Da das Ziel dieser Verordnung von den Mitgliedstaaten nicht ausreichend verwirklicht 
werden kann, sondern vielmehr wegen des Umfangs oder der Wirkung der Ma&#223;nahme 
auf Unionsebene besser zu verwirklichen ist, kann die Union im Einklang mit dem in 
Artikel 5 EUV verankerten Subsidiarit&#228;tsprinzip t&#228;tig werden. Entsprechend dem in 
demselben Artikel genannten Grundsatz der Verh&#228;ltnism&#228;&#223;igkeit geht diese 
Verordnung nicht &#252;ber das f&#252;r die Verwirklichung dieses Ziels erforderliche Ma&#223; 
hinaus.
(88) Diese Verordnung sollte ab dem &#8230; [Amt f&#252;r Ver&#246;ffentlichungen &#8211; bitte das in 
Artikel 85 festgelegte Datum einf&#252;gen] gelten. Die Infrastruktur f&#252;r die Leitung und 
das Konformit&#228;tsbewertungssystem sollte jedoch schon vorher einsatzbereit sein, 
weshalb die Bestimmungen &#252;ber notifizierte Stellen und die Leitungsstruktur ab dem... 
[Amt f&#252;r Ver&#246;ffentlichungen &#8211; bitte Datum einf&#252;gen &#8211; drei Monate nach Inkrafttreten 
dieser Verordnung] gelten sollten. Dar&#252;ber hinaus sollten die Mitgliedstaaten 
Vorschriften &#252;ber Sanktionen, einschlie&#223;lich Geldbu&#223;en, festlegen und der 
Kommission mitteilen sowie daf&#252;r sorgen, dass diese bis zum Geltungsbeginn dieser 
Verordnung ordnungsgem&#228;&#223; und wirksam umgesetzt werden. Daher sollten die 
Bestimmungen &#252;ber Sanktionen ab dem [Amt f&#252;r Ver&#246;ffentlichungen &#8211; bitte Datum 
einf&#252;gen &#8211; zw&#246;lf Monate nach Inkrafttreten dieser Verordnung] gelten. 
(89) Der Europ&#228;ische Datenschutzbeauftragte und der Europ&#228;ische Datenschutzausschuss 
wurden gem&#228;&#223; Artikel 42 Absatz 2 der Verordnung (EU) 2018/1725 angeh&#246;rt und 
haben am [...] eine Stellungnahme abgegeben &#8212;
HABEN FOLGENDE VERORDNUNG ERLASSEN:
TITEL I
ALLGEMEINE BESTIMMUNGEN
Artikel 1 
Gegenstand 
In dieser Verordnung wird Folgendes festgelegt: 
a) harmonisierte Vorschriften f&#252;r das Inverkehrbringen, die Inbetriebnahme und die 
Verwendung von Systemen der k&#252;nstlichen Intelligenz (im Folgenden &#8222;KI-
Systeme&#8220;) in der Union;
59 Verordnung (EU) Nr. 182/2011 des Europ&#228;ischen Parlaments und des Rates vom 16. Februar 2011 zur 
Festlegung der allgemeinen Regeln und Grunds&#228;tze, nach denen die Mitgliedstaaten die Wahrnehmung 
der Durchf&#252;hrungsbefugnisse durch die Kommission kontrollieren (ABl. L 55 vom 28.2.2011, S. 13).
b) Verbote bestimmter Praktiken im Bereich der k&#252;nstlichen Intelligenz; 
c) besondere Anforderungen an Hochrisiko-KI-Systeme und Verpflichtungen f&#252;r 
Betreiber solcher Systeme; 
d) harmonisierte Transparenzvorschriften f&#252;r KI-Systeme, die mit nat&#252;rlichen Personen 
interagieren sollen, f&#252;r KI-Systeme zur Emotionserkennung und zur biometrischen 
Kategorisierung sowie f&#252;r KI-Systeme, die zum Erzeugen oder Manipulieren von 
Bild-, Ton- oder Videoinhalten verwendet werden; 
e) Vorschriften f&#252;r die Marktbeobachtung und Markt&#252;berwachung.
Artikel 2 
Anwendungsbereich
(1) Diese Verordnung gilt f&#252;r: 
a) Anbieter, die KI-Systeme in der Union in Verkehr bringen oder in Betrieb 
nehmen, unabh&#228;ngig davon, ob diese Anbieter in der Union oder in einem 
Drittland niedergelassen sind; 
b) Nutzer von KI-Systemen, die sich in der Union befinden; 
c) Anbieter und Nutzer von KI-Systemen, die in einem Drittland niedergelassen 
oder ans&#228;ssig sind, wenn das vom System hervorgebrachte Ergebnis in der 
Union verwendet wird.
(2) F&#252;r Hochrisiko-KI-Systeme, die Sicherheitskomponenten von Produkten oder 
Systemen oder selbst Produkte oder Systeme sind, die in den Anwendungsbereich 
der folgenden Rechtsakte fallen, gilt nur Artikel 84 dieser Verordnung: 
a) Verordnung (EG) Nr. 300/2008, 
b) Verordnung (EU) Nr. 167/2013, 
c) Verordnung (EU) Nr. 168/2013, 
d) Richtlinie 2014/90/EU, 
e) Richtlinie (EU) 2016/797, 
f) Verordnung (EU) 2018/858, 
g) Verordnung (EU) 2018/1139, 
h) Verordnung (EU) 2019/2144. 
(3) Diese Verordnung gilt nicht f&#252;r KI-Systeme, die ausschlie&#223;lich f&#252;r milit&#228;rische 
Zwecke entwickelt oder verwendet werden.
(4) Diese Verordnung gilt weder f&#252;r Beh&#246;rden in Drittl&#228;ndern noch f&#252;r internationale 
Organisationen, die gem&#228;&#223; Absatz 1 in den Anwendungsbereich dieser Verordnung 
fallen, soweit diese Beh&#246;rden oder Organisationen KI-Systeme im Rahmen 
internationaler &#220;bereink&#252;nfte im Bereich der Strafverfolgung und justiziellen 
Zusammenarbeit mit der Union oder mit einem oder mehreren Mitgliedstaaten 
verwenden.
(5) Die Anwendung der Bestimmungen &#252;ber die Verantwortlichkeit der Vermittler in 
Kapitel II Abschnitt 4 der Richtlinie 2000/31/EG des Europ&#228;ischen Parlaments und
des Rates60 [die durch die entsprechenden Bestimmungen des Gesetzes &#252;ber digitale 
Dienste ersetzt werden sollen] bleibt von dieser Verordnung unber&#252;hrt.
Artikel 3 
Begriffsbestimmungen 
F&#252;r die Zwecke dieser Verordnung bezeichnet der Ausdruck 
1. &#8222;System der k&#252;nstlichen Intelligenz&#8220; (KI-System) eine Software, die mit einer oder 
mehreren der in Anhang I aufgef&#252;hrten Techniken und Konzepte entwickelt worden 
ist und im Hinblick auf eine Reihe von Zielen, die vom Menschen festgelegt werden, 
Ergebnisse wie Inhalte, Vorhersagen, Empfehlungen oder Entscheidungen 
hervorbringen kann, die das Umfeld beeinflussen, mit dem sie interagieren; 
2. &#8222;Anbieter&#8220; eine nat&#252;rliche oder juristische Person, Beh&#246;rde, Einrichtung oder 
sonstige Stelle, die ein KI-System entwickelt oder entwickeln l&#228;sst, um es unter 
ihrem eigenen Namen oder ihrer eigenen Marke &#8211; entgeltlich oder unentgeltlich &#8211; in 
Verkehr zu bringen oder in Betrieb zu nehmen; 
3. &#8222;Kleinanbieter&#8220; einen Anbieter, bei dem es sich um ein Kleinst- oder 
Kleinunternehmen im Sinne der Empfehlung 2003/361/EG der Kommission61
handelt; 
4. &#8222;Nutzer&#8220; eine nat&#252;rliche oder juristische Person, Beh&#246;rde, Einrichtung oder sonstige 
Stelle, die ein KI-System in eigener Verantwortung verwendet, es sei denn, das KI-
System wird im Rahmen einer pers&#246;nlichen und nicht beruflichen T&#228;tigkeit 
verwendet; 
5. &#8222;Bevollm&#228;chtigter&#8220; eine in der Union ans&#228;ssige oder niedergelassene nat&#252;rliche oder 
juristische Person, die vom Anbieter eines KI-Systems schriftlich dazu 
bevollm&#228;chtigt wurde, in seinem Namen die in dieser Verordnung festgelegten 
Pflichten zu erf&#252;llen bzw. Verfahren durchzuf&#252;hren; 
6. &#8222;Einf&#252;hrer&#8220; eine in der Union ans&#228;ssige oder niedergelassene nat&#252;rliche oder 
juristische Person, die ein KI-System, das den Namen oder die Marke einer 
au&#223;erhalb der Union ans&#228;ssigen oder niedergelassenen nat&#252;rlichen oder juristischen 
Person tr&#228;gt, in der Union in Verkehr bringt oder in Betrieb nimmt; 
7. &#8222;H&#228;ndler&#8220; eine nat&#252;rliche oder juristische Person in der Lieferkette, die ein KI-
System ohne &#196;nderung seiner Merkmale auf dem Unionsmarkt bereitstellt, mit 
Ausnahme des Herstellers oder des Einf&#252;hrers; 
8. &#8222;Akteur&#8220; den Anbieter, den Nutzer, den Bevollm&#228;chtigten, den Einf&#252;hrer und den 
H&#228;ndler; 
9. &#8222;Inverkehrbringen&#8220; die erstmalige Bereitstellung eines KI-Systems auf dem 
Unionsmarkt;
60 Richtlinie 2000/31/EG des Europ&#228;ischen Parlaments und des Rates vom 8. Juni 2000 &#252;ber bestimmte 
rechtliche Aspekte der Dienste der Informationsgesellschaft, insbesondere des elektronischen 
Gesch&#228;ftsverkehrs, im Binnenmarkt (&#8222;Richtlinie &#252;ber den elektronischen Gesch&#228;ftsverkehr&#8220;) (ABl. 
L 178 vom 17.7.2000, S. 1). 
61 Empfehlung der Kommission vom 6. Mai 2003 betreffend die Definition der Kleinstunternehmen sowie 
der kleinen und mittleren Unternehmen (ABl. L 124 vom 20.5.2003, S. 36).
10. &#8222;Bereitstellung auf dem Markt&#8220; jede entgeltliche oder unentgeltliche Abgabe eines 
KI-Systems zum Vertrieb oder zur Verwendung auf dem Unionsmarkt im Rahmen 
einer Gesch&#228;ftst&#228;tigkeit; 
11. &#8222;Inbetriebnahme&#8220; die Bereitstellung eines KI-Systems auf dem Unionsmarkt zum 
Erstgebrauch direkt an den Nutzer oder zum Eigengebrauch entsprechend seiner 
Zweckbestimmung; 
12. &#8222;Zweckbestimmung&#8220; die Verwendung, f&#252;r die ein KI-System laut Anbieter bestimmt 
ist, einschlie&#223;lich der besonderen Nutzungsumst&#228;nde und Nutzungsbedingungen 
entsprechend den Angaben des Anbieters in der Gebrauchsanweisung, im
Werbeoder Verkaufsmaterial und in diesbez&#252;glichen Erkl&#228;rungen sowie in der technischen 
Dokumentation; 
13. &#8222;vern&#252;nftigerweise vorhersehbare Fehlanwendung&#8220; die Verwendung eines KI-
Systems in einer Weise, die nicht seiner Zweckbestimmung entspricht, die sich aber 
aus einem vern&#252;nftigerweise vorhersehbaren menschlichen Verhalten oder einer 
vern&#252;nftigerweise vorhersehbaren Interaktion mit anderen Systemen ergeben kann; 
14. &#8222;Sicherheitskomponente eines Produkts oder Systems&#8220; einen Bestandteil eines 
Produkts oder Systems, der eine Sicherheitsfunktion f&#252;r dieses Produkt oder System 
erf&#252;llt oder dessen Ausfall oder St&#246;rung die Gesundheit und Sicherheit von Personen 
oder Sachen gef&#228;hrdet; 
15. &#8222;Gebrauchsanweisung&#8220; die Informationen, die der Anbieter bereitstellt, um den 
Nutzer insbesondere &#252;ber die Zweckbestimmung und die ordnungsgem&#228;&#223;e 
Verwendung eines KI-Systems zu informieren, einschlie&#223;lich der besonderen 
geografischen, verhaltensbezogenen oder funktionalen Rahmenbedingungen, unter 
denen ein Hochrisiko-KI-System bestimmungsgem&#228;&#223; verwendet werden soll; 
16. &#8222;R&#252;ckruf eines KI-Systems&#8220; jede Ma&#223;nahme, die auf die R&#252;ckgabe eines den 
Nutzern bereits zur Verf&#252;gung gestellten KI-Systems an den Anbieter abzielt; 
17. &#8222;R&#252;cknahme eines KI-Systems&#8220; jede Ma&#223;nahme, mit der verhindert werden soll, das 
ein KI-System vertrieben, ausgestellt oder angeboten wird; 
18. &#8222;Leistung eines KI-Systems&#8220; die F&#228;higkeit eines KI-Systems, seine 
Zweckbestimmung zu erf&#252;llen; 
19. &#8222;notifizierende Beh&#246;rde&#8220; die nationale Beh&#246;rde, die f&#252;r die Einrichtung und 
Durchf&#252;hrung der erforderlichen Verfahren f&#252;r die Bewertung, Benennung und 
Notifizierung von Konformit&#228;tsbewertungsstellen und f&#252;r deren &#220;berwachung 
zust&#228;ndig ist; 
20. &#8222;Konformit&#228;tsbewertung&#8220; das Verfahren zur &#220;berpr&#252;fung, ob die in Titel III 
Kapitel 2 dieser Verordnung festgelegten Anforderungen an ein KI-System erf&#252;llt 
worden sind; 
21. &#8222;Konformit&#228;tsbewertungsstelle&#8220; eine Stelle, die Konformit&#228;tsbewertungst&#228;tigkeiten 
einschlie&#223;lich Pr&#252;fungen, Zertifizierungen und Kontrollen durchf&#252;hrt und dabei als 
unabh&#228;ngige Dritte auftritt; 
22. &#8222;notifizierte Stelle&#8220; eine Konformit&#228;tsbewertungsstelle, die gem&#228;&#223; dieser 
Verordnung und anderen einschl&#228;gigen Harmonisierungsvorschriften der Union 
benannt wurde; 
23. &#8222;wesentliche &#196;nderung&#8220; eine &#196;nderung des KI-Systems nach dessen 
Inverkehrbringen oder Inbetriebnahme, die sich auf die Konformit&#228;t des KI-Systems
mit den Anforderungen in Titel III Kapitel 2 dieser Verordnung auswirkt oder zu 
einer &#196;nderung der Zweckbestimmung f&#252;hrt, f&#252;r die das KI-System gepr&#252;ft wurde; 
24. &#8222;CE-Konformit&#228;tskennzeichnung&#8220; (CE-Kennzeichnung) eine Kennzeichnung, durch 
die ein Anbieter erkl&#228;rt, dass ein KI-System die Anforderungen erf&#252;llt, die in Titel III 
Kapitel 2 dieser Verordnung und in anderen einschl&#228;gigen Rechtsvorschriften der 
Union zur Harmonisierung der Bedingungen f&#252;r die Vermarktung von Produkten 
(&#8222;Harmonisierungsrechtsvorschriften der Union&#8220;), die die Anbringung dieser 
Kennzeichnung vorsehen, festgelegt sind; 
25. &#8222;Beobachtung nach dem Inverkehrbringen&#8220; alle T&#228;tigkeiten, die Anbieter von KI-
Systemen zur proaktiven Sammlung und &#220;berpr&#252;fung von Erfahrungen mit der 
Nutzung der von ihnen in Verkehr gebrachten oder in Betrieb genommenen KI-
Systeme durchf&#252;hren, um festzustellen, ob unverz&#252;glich n&#246;tige Korrektur- oder 
Pr&#228;ventivma&#223;nahmen zu ergreifen sind; 
26. &#8222;Markt&#252;berwachungsbeh&#246;rde&#8220; die nationale Beh&#246;rde, die die T&#228;tigkeiten durchf&#252;hrt 
und die Ma&#223;nahmen ergreift, die in der Verordnung (EU) 2019/1020 vorgesehen 
sind; 
27. &#8222;harmonisierte Norm&#8220; eine harmonisierte europ&#228;ische Norm im Sinne des Artikels 2 
Absatz 1 Buchstabe c der Verordnung (EU) Nr. 1025/2012; 
28. &#8222;gemeinsame Spezifikationen&#8220; ein Dokument, das keine Norm ist und das technische 
L&#246;sungen enth&#228;lt, deren Befolgung es erm&#246;glicht, bestimmte Anforderungen und 
Verpflichtungen dieser Verordnung zu erf&#252;llen; 
29. &#8222;Trainingsdaten&#8220; Daten, die zum Trainieren eines KI-Systems verwendet werden, 
wobei dessen lernbare Parameter und die Gewichte eines neuronalen Netzes 
angepasst werden; 
30. &#8222;Validierungsdaten&#8220; Daten, die zum Bewerten des trainierten KI-Systems und zum 
Abstimmen seiner nicht lernbaren Parameter und seines Lernprozesses verwendet 
werden, um unter anderem eine &#220;beranpassung zu vermeiden; der 
Validierungsdatensatz kann ein separater Datensatz oder Teil des 
Trainingsdatensatzes mit fester oder variabler Aufteilung sein; 
31. &#8222;Testdaten&#8220; Daten, die f&#252;r eine unabh&#228;ngige Bewertung des trainierten und 
validierten KI-Systems verwendet werden, um die erwartete Leistung dieses Systems 
vor dessen Inverkehrbringen oder Inbetriebnahme zu best&#228;tigen; 
32. &#8222;Eingabedaten&#8220; die in ein KI-System eingespeisten oder von diesem direkt erfassten 
Daten, auf deren Grundlage das System ein Ergebnis (Ausgabe) hervorbringt; 
33. &#8222;biometrische Daten&#8220; mit speziellen technischen Verfahren gewonnene 
personenbezogene Daten zu den physischen, physiologischen oder 
verhaltenstypischen Merkmalen einer nat&#252;rlichen Person, die die eindeutige 
Identifizierung dieser nat&#252;rlichen Person erm&#246;glichen oder best&#228;tigen, wie 
Gesichtsbilder oder daktyloskopische Daten; 
34. &#8222;Emotionserkennungssystem&#8220; ein KI-System, das dem Zweck dient, Emotionen oder 
Absichten nat&#252;rlicher Personen auf der Grundlage ihrer biometrischen Daten 
festzustellen oder daraus abzuleiten; 
35. &#8222;System zur biometrischen Kategorisierung&#8220; ein KI-System, das dem Zweck dient, 
nat&#252;rliche Personen auf der Grundlage ihrer biometrischen Daten bestimmten
Kategorien wie Geschlecht, Alter, Haarfarbe, Augenfarbe, T&#228;towierung, ethnische 
Herkunft oder sexuelle oder politische Ausrichtung zuzuordnen; 
36. &#8222;biometrisches Fernidentifizierungssystem&#8220; ein KI-System, das dem Zweck dient, 
nat&#252;rliche Personen aus der Ferne durch Abgleich der biometrischen Daten einer 
Person mit den in einer Referenzdatenbank gespeicherten biometrischen Daten zu 
identifizieren, ohne dass der Nutzer des KI-Systems vorher wei&#223;, ob die Person 
anwesend sein wird und identifiziert werden kann; 
37. &#8222;biometrisches Echtzeit-Fernidentifizierungssystem&#8220; ein biometrisches 
Fernidentifizierungssystem, bei dem die Erfassung biometrischer Daten, der 
Abgleich und die Identifizierung ohne erhebliche Verz&#246;gerung erfolgen; zur 
Vermeidung einer Umgehung der Vorschriften umfasst dies nicht nur die sofortige 
Identifizierung, sondern auch eine Identifizierung mit begrenzten kurzen 
Verz&#246;gerungen; 
38. &#8222;System zur nachtr&#228;glichen biometrischen Fernidentifizierung&#8220; ein biometrisches 
Fernidentifizierungssystem, das kein biometrisches Echtzeit-
Fernidentifizierungssystem ist; 
39. &#8222;&#246;ffentlich zug&#228;nglicher Raum&#8220; einen der &#214;ffentlichkeit zug&#228;nglichen physischen 
Ort, unabh&#228;ngig davon, ob daf&#252;r bestimmte Zugangsbedingungen gelten; 
40. &#8222;Strafverfolgungsbeh&#246;rde&#8220;: 
a) eine staatliche Stelle, die f&#252;r die Verh&#252;tung, Ermittlung, Aufdeckung oder 
Verfolgung von Straftaten oder die Strafvollstreckung, einschlie&#223;lich des 
Schutzes vor und der Abwehr von Gefahren f&#252;r die &#246;ffentliche Sicherheit, 
zust&#228;ndig ist, oder 
b) eine andere Stelle oder Einrichtung, der durch das Recht der Mitgliedstaaten 
die Aus&#252;bung &#246;ffentlicher Gewalt und hoheitlicher Befugnisse zur Verh&#252;tung, 
Ermittlung, Aufdeckung oder Verfolgung von Straftaten oder zur 
Strafvollstreckung, einschlie&#223;lich des Schutzes vor und der Abwehr von 
Gefahren f&#252;r die &#246;ffentliche Sicherheit, &#252;bertragen wurde;
41. &#8222;Strafverfolgung&#8220; T&#228;tigkeiten der Strafverfolgungsbeh&#246;rden zur Verh&#252;tung, 
Ermittlung, Aufdeckung oder Verfolgung von Straftaten oder zur Strafvollstreckung, 
einschlie&#223;lich des Schutzes vor und der Abwehr von Gefahren f&#252;r die &#246;ffentliche 
Sicherheit; 
42. &#8222;nationale Aufsichtsbeh&#246;rde&#8220; die Beh&#246;rde, der ein Mitgliedstaat die Verantwortung 
f&#252;r die Durchf&#252;hrung und Anwendung dieser Verordnung, die Koordinierung der 
diesem Mitgliedstaat &#252;bertragenen T&#228;tigkeiten, die Wahrnehmung der Funktion der 
zentralen Kontaktstelle f&#252;r die Kommission und die Vertretung des Mitgliedstaats im 
Europ&#228;ischen Ausschuss f&#252;r k&#252;nstliche Intelligenz &#252;bertr&#228;gt; 
43. &#8222;zust&#228;ndige nationale Beh&#246;rde&#8220; die nationale Aufsichtsbeh&#246;rde, die notifizierende 
Beh&#246;rde und die Markt&#252;berwachungsbeh&#246;rde; 
44. &#8222;schwerwiegender Vorfall&#8220; ein Vorkommnis, das direkt oder indirekt eine der 
nachstehenden Folgen hat, h&#228;tte haben k&#246;nnen oder haben k&#246;nnte: 
a) den Tod oder die schwere gesundheitliche Sch&#228;digung einer Person, schwere 
Sach- oder Umweltsch&#228;den, 
b) eine schwere und unumkehrbare St&#246;rung der Verwaltung und des Betriebs 
kritischer Infrastrukturen.
Artikel 4 
&#196;nderungen des Anhangs I 
Der Kommission wird die Befugnis &#252;bertragen, gem&#228;&#223; Artikel 73 delegierte Rechtsakte zur 
&#196;nderung der Liste der Techniken und Konzepte in Anhang I zu erlassen, um diese Liste auf 
der Grundlage von Merkmalen, die den dort aufgef&#252;hrten Techniken und Konzepten &#228;hnlich 
sind, an Marktentwicklungen und technische Entwicklungen anzupassen.
TITEL II
VERBOTENE PRAKTIKEN IM BEREICH DER K&#220;NSTLICHEN
INTELLIGENZ
Artikel 5 
(1) Folgende Praktiken im Bereich der k&#252;nstlichen Intelligenz sind verboten: 
a) das Inverkehrbringen, die Inbetriebnahme oder die Verwendung eines KI-
Systems, das Techniken der unterschwelligen Beeinflussung au&#223;erhalb des 
Bewusstseins einer Person einsetzt, um das Verhalten einer Person in einer 
Weise wesentlich zu beeinflussen, die dieser Person oder einer anderen Person 
einen physischen oder psychischen Schaden zuf&#252;gt oder zuf&#252;gen kann; 
b) das Inverkehrbringen, die Inbetriebnahme oder die Verwendung eines KI-
Systems, das eine Schw&#228;che oder Schutzbed&#252;rftigkeit einer bestimmten 
Gruppe von Personen aufgrund ihres Alters oder ihrer k&#246;rperlichen oder 
geistigen Behinderung ausnutzt, um das Verhalten einer dieser Gruppe 
angeh&#246;renden Person in einer Weise wesentlich zu beeinflussen, die dieser 
Person oder einer anderen Person einen physischen oder psychischen Schaden 
zuf&#252;gt oder zuf&#252;gen kann; 
c) das Inverkehrbringen, die Inbetriebnahme oder die Verwendung von KI-
Systemen durch Beh&#246;rden oder in deren Auftrag zur Bewertung oder 
Klassifizierung der Vertrauensw&#252;rdigkeit nat&#252;rlicher Personen &#252;ber einen 
bestimmten Zeitraum auf der Grundlage ihres sozialen Verhaltens oder 
bekannter oder vorhergesagter pers&#246;nlicher Eigenschaften oder 
Pers&#246;nlichkeitsmerkmale, wobei die soziale Bewertung zu einem oder beiden 
der folgenden Ergebnisse f&#252;hrt: 
i) Schlechterstellung oder Benachteiligung bestimmter nat&#252;rlicher Personen 
oder ganzer Gruppen nat&#252;rlicher Personen in sozialen Zusammenh&#228;ngen, 
die in keinem Zusammenhang zu den Umst&#228;nden stehen, unter denen die 
Daten urspr&#252;nglich erzeugt oder erfasst wurden; 
ii) Schlechterstellung oder Benachteiligung bestimmter nat&#252;rlicher Personen 
oder ganzer Gruppen nat&#252;rlicher Personen, in einer Weise, die im 
Hinblick auf ihr soziales Verhalten oder dessen Tragweite 
ungerechtfertigt oder unverh&#228;ltnism&#228;&#223;ig ist; 
d) die Verwendung biometrischer Echtzeit-Fernidentifizierungssysteme in 
&#246;ffentlich zug&#228;nglichen R&#228;umen zu Strafverfolgungszwecken, au&#223;er wenn und 
insoweit dies im Hinblick auf eines der folgenden Ziele unbedingt erforderlich 
ist:
i) gezielte Suche nach bestimmten potenziellen Opfern von Straftaten oder 
nach vermissten Kindern; 
ii) Abwenden einer konkreten, erheblichen und unmittelbaren Gefahr f&#252;r 
das Leben oder die k&#246;rperliche Unversehrtheit nat&#252;rlicher Personen oder 
eines Terroranschlags; 
iii) Erkennen, Aufsp&#252;ren, Identifizieren oder Verfolgen eines T&#228;ters oder 
Verd&#228;chtigen einer Straftat im Sinne des Artikels 2 Absatz 2 des 
Rahmenbeschlusses 2002/584/JI des Rates62, der in dem betreffenden 
Mitgliedstaat nach dessen Recht mit einer Freiheitsstrafe oder einer 
freiheitsentziehenden Ma&#223;regel der Sicherung im H&#246;chstma&#223; von 
mindestens drei Jahren bedroht ist. 
(2) Bei der Verwendung biometrischer Echtzeit-Fernidentifizierungssysteme in 
&#246;ffentlich zug&#228;nglichen R&#228;umen zu Strafverfolgungszwecken im Hinblick auf die in 
Absatz 1 Buchstabe d genannten Ziele werden folgende Elemente ber&#252;cksichtigt: 
a) die Art der Situation, die der m&#246;glichen Verwendung zugrunde liegt, 
insbesondere die Schwere, die Wahrscheinlichkeit und das Ausma&#223; des 
Schadens, der entstehen w&#252;rde, wenn das System nicht eingesetzt w&#252;rde; 
b) die Folgen der Verwendung des Systems f&#252;r die Rechte und Freiheiten aller 
betroffenen Personen, insbesondere die Schwere, die Wahrscheinlichkeit und 
das Ausma&#223; solcher Folgen. 
Dar&#252;ber hinaus sind bei der Verwendung biometrischer Echtzeit-
Fernidentifizierungssysteme in &#246;ffentlich zug&#228;nglichen R&#228;umen zu 
Strafverfolgungszwecken im Hinblick auf die in Absatz 1 Buchstabe d genannten 
Ziele notwendige und verh&#228;ltnism&#228;&#223;ige Schutzvorkehrungen und Bedingungen f&#252;r 
die Verwendung einzuhalten, insbesondere in Bezug auf die zeitlichen, 
geografischen und personenbezogenen Beschr&#228;nkungen. 
(3) Im Hinblick auf Absatz 1 Buchstabe d und Absatz 2 ist f&#252;r jede einzelne 
Verwendung eines biometrischen Echtzeit-Fernidentifizierungssystems in &#246;ffentlich 
zug&#228;nglichen R&#228;umen zu Strafverfolgungszwecken eine vorherige Genehmigung 
erforderlich, die von einer Justizbeh&#246;rde oder einer unabh&#228;ngigen 
Verwaltungsbeh&#246;rde des Mitgliedstaats, in dem die Verwendung erfolgen soll, auf 
begr&#252;ndeten Antrag und im Einklang mit den in Absatz 4 genannten detaillierten 
Vorschriften des nationalen Rechts erteilt wird. In hinreichend begr&#252;ndeten 
dringenden F&#228;llen kann jedoch mit der Verwendung des Systems zun&#228;chst ohne 
Genehmigung begonnen und die Genehmigung erst w&#228;hrend oder nach der Nutzung 
beantragt werden. 
Die zust&#228;ndige Justiz- oder Verwaltungsbeh&#246;rde erteilt die Genehmigung nur dann, 
wenn sie auf der Grundlage objektiver Nachweise oder eindeutiger Hinweise, die ihr 
vorgelegt werden, davon &#252;berzeugt ist, dass die Verwendung des betreffenden 
biometrischen Echtzeit-Fernidentifizierungssystems f&#252;r das Erreichen eines der in 
Absatz 1 Buchstabe d genannten Ziele &#8211; wie im Antrag angegeben &#8211; notwendig und 
verh&#228;ltnism&#228;&#223;ig ist. Bei ihrer Entscheidung &#252;ber den Antrag ber&#252;cksichtigt die 
zust&#228;ndige Justiz- oder Verwaltungsbeh&#246;rde die in Absatz 2 genannten Elemente. 
62 Rahmenbeschluss 2002/584/JI des Rates vom 13. Juni 2002 &#252;ber den Europ&#228;ischen Haftbefehl und die 
&#220;bergabeverfahren zwischen den Mitgliedstaaten (ABl. L 190 vom 18.7.2002, S. 1).
(4) Ein Mitgliedstaat kann die M&#246;glichkeit einer vollst&#228;ndigen oder teilweisen 
Genehmigung der Verwendung biometrischer Echtzeit-Identifizierungssysteme in 
&#246;ffentlich zug&#228;nglichen R&#228;umen zu Strafverfolgungszwecken innerhalb der in 
Absatz 1 Buchstabe d, Absatz 2 und Absatz 3 aufgef&#252;hrten Grenzen und unter den 
dort genannten Bedingungen vorsehen. Dieser Mitgliedstaat legt in seinem 
nationalen Recht die erforderlichen detaillierten Vorschriften f&#252;r die Beantragung, 
Erteilung und Aus&#252;bung der in Absatz 3 genannten Genehmigungen sowie f&#252;r die 
entsprechende Beaufsichtigung fest. In diesen Vorschriften wird auch festgelegt, im 
Hinblick auf welche der in Absatz 1 Buchstabe d genannten Ziele und welche der 
unter Ziffer iii genannten Straftaten die zust&#228;ndigen Beh&#246;rden erm&#228;chtigt werden 
k&#246;nnen, diese Systeme zu Strafverfolgungszwecken zu verwenden.
TITEL III
HOCHRISIKO-KI-SYSTEME 
KAPITEL 1 
KLASSIFIZIERUNG VON KI-SYSTEMEN ALS HOCHRISIKO-
SYSTEME 
Artikel 6 
Klassifizierungsvorschriften f&#252;r Hochrisiko-KI-Systeme 
(1) Ungeachtet dessen, ob ein KI-System unabh&#228;ngig von den unter den Buchstaben a 
und b genannten Produkten in Verkehr gebracht oder in Betrieb genommen wird, gilt 
es als Hochrisiko-KI-System, wenn die beiden folgenden Bedingungen erf&#252;llt sind: 
a) das KI-System soll als Sicherheitskomponente eines unter die in Anhang II 
aufgef&#252;hrten Harmonisierungsrechtsvorschriften der Union fallenden Produkts 
verwendet werden oder ist selbst ein solches Produkt; 
b) das Produkt, dessen Sicherheitskomponente das KI-System ist, oder das KI-
System selbst als Produkt muss einer Konformit&#228;tsbewertung durch Dritte im 
Hinblick auf das Inverkehrbringen oder die Inbetriebnahme dieses Produkts 
gem&#228;&#223; den in Anhang II aufgef&#252;hrten Harmonisierungsrechtsvorschriften der 
Union unterzogen werden. 
(2) Zus&#228;tzlich zu den in Absatz 1 genannten Hochrisiko-KI-Systemen gelten die in 
Anhang III genannten KI-Systeme ebenfalls als hochriskant.
Artikel 7 
&#196;nderungen des Anhangs III 
(1) Der Kommission wird die Befugnis &#252;bertragen, gem&#228;&#223; Artikel 73 delegierte 
Rechtsakte zur &#196;nderung der Liste in Anhang III zu erlassen, um Hochrisiko-KI-
Systeme hinzuzuf&#252;gen, die beide folgenden Bedingungen erf&#252;llen: 
a) die KI-Systeme sollen in einem der in Anhang III Nummern 1 bis 8 
aufgef&#252;hrten Bereiche eingesetzt werden; 
b) die KI-Systeme bergen ein Risiko der Sch&#228;digung der Gesundheit oder der 
Beeintr&#228;chtigung der Sicherheit oder nachteiliger Auswirkungen auf die
Grundrechte, das im Hinblick auf die Schwere und die Wahrscheinlichkeit des 
Eintretens dem Risiko der Sch&#228;digung, Beeintr&#228;chtigung oder negativer 
Auswirkungen gleicht, das von den in Anhang III bereits aufgef&#252;hrten 
Hochrisiko-KI-Systemen ausgeht, oder dieses &#252;bersteigt. 
(2) Bei der Bewertung f&#252;r die Zwecke des Absatzes 1, ob ein KI-System ein Risiko der 
Sch&#228;digung der Gesundheit oder der Beeintr&#228;chtigung der Sicherheit oder ein Risiko 
nachteiliger Auswirkungen auf die Grundrechte birgt, das dem Risiko der 
Sch&#228;digung oder Beeintr&#228;chtigung gleicht, das von den in Anhang III bereits 
aufgef&#252;hrten Hochrisiko-KI-Systemen ausgeht, oder dieses &#252;bersteigt, ber&#252;cksichtigt 
die Kommission folgende Kriterien: 
a) die Zweckbestimmung des KI-Systems; 
b) das Ausma&#223;, in dem ein KI-System verwendet wird oder voraussichtlich 
verwendet werden wird; 
c) das Ausma&#223;, in dem durch die Verwendung eines KI-Systems schon die 
Gesundheit gesch&#228;digt, die Sicherheit beeintr&#228;chtigt oder negative 
Auswirkungen auf die Grundrechte verursacht worden sind oder nach 
Berichten oder dokumentierten Behauptungen, die den zust&#228;ndigen nationalen 
Beh&#246;rden &#252;bermittelt werden, Anlass zu erheblichen Bedenken hinsichtlich des 
Eintretens solcher Sch&#228;den, Beeintr&#228;chtigungen oder nachteiligen 
Auswirkungen besteht; 
d) das potenzielle Ausma&#223; solcher Sch&#228;den, Beeintr&#228;chtigungen oder nachteiligen 
Auswirkungen, insbesondere hinsichtlich ihrer Intensit&#228;t und ihrer Eignung, 
eine Vielzahl von Personen zu beeintr&#228;chtigen; 
e) das Ausma&#223;, in dem potenziell gesch&#228;digte oder beeintr&#228;chtigte Personen von 
dem von einem KI-System hervorgebrachten Ergebnis abh&#228;ngen, weil es 
insbesondere aus praktischen oder rechtlichen Gr&#252;nden nach vern&#252;nftigem 
Ermessen unm&#246;glich ist, sich diesem Ergebnis zu entziehen; 
f) das Ausma&#223;, in dem potenziell gesch&#228;digte oder beeintr&#228;chtigte Personen 
gegen&#252;ber dem Nutzer eines KI-Systems schutzbed&#252;rftig sind, insbesondere 
aufgrund eines Ungleichgewichts in Bezug auf Machtposition, Wissen, 
wirtschaftliche oder soziale Umst&#228;nde oder Alter; 
g) das Ausma&#223;, in dem das mit einem KI-System hervorgebrachte Ergebnis leicht 
r&#252;ckg&#228;ngig zu machen ist, wobei Ergebnisse, die sich auf die Gesundheit oder 
Sicherheit von Personen auswirken, nicht als leicht r&#252;ckg&#228;ngig zu machen 
gelten; 
h) das Ausma&#223;, in dem bestehende Rechtsvorschriften der Union Folgendes 
vorsehen:
i) wirksame Abhilfema&#223;nahmen in Bezug auf die Risiken, die von einem 
KI-System ausgehen, mit Ausnahme von Schadenersatzanspr&#252;chen, 
ii) wirksame Ma&#223;nahmen zur Vermeidung oder wesentlichen Verringerung 
dieser Risiken.
KAPITEL 2
ANFORDERUNGEN AN HOCHRISIKO-KI-SYSTEME
Artikel 8 
Einhaltung der Anforderungen 
(1) Hochrisiko-KI-Systeme m&#252;ssen die in diesem Kapitel festgelegten Anforderungen 
erf&#252;llen.
(2) Bei der Gew&#228;hrleistung der Einhaltung dieser Anforderungen wird der 
Zweckbestimmung des Hochrisiko-KI-Systems und dem in Artikel 9 genannten 
Risikomanagementsystem Rechnung getragen.
Artikel 9 
Risikomanagementsystem 
(1) F&#252;r Hochrisiko-KI-Systeme wird ein Risikomanagementsystem eingerichtet, 
angewandt, dokumentiert und aufrechterhalten. 
(2) Das Risikomanagementsystem versteht sich als ein kontinuierlicher iterativer Prozess 
w&#228;hrend des gesamten Lebenszyklus eines KI-Systems, der eine regelm&#228;&#223;ige 
systematische Aktualisierung erfordert. Es umfasst folgende Schritte: 
a) Ermittlung und Analyse der bekannten und vorhersehbaren Risiken, die von 
jedem Hochrisiko-KI-System ausgehen; 
b) Absch&#228;tzung und Bewertung der Risiken, die entstehen k&#246;nnen, wenn das 
Hochrisiko-KI-System entsprechend seiner Zweckbestimmung oder im 
Rahmen einer vern&#252;nftigerweise vorhersehbaren Fehlanwendung verwendet 
wird; 
c) Bewertung anderer m&#246;glicherweise auftretender Risiken auf der Grundlage der 
Auswertung der Daten aus dem in Artikel 61 genannten System zur 
Beobachtung nach dem Inverkehrbringen; 
d) Ergreifung geeigneter Risikomanagementma&#223;nahmen gem&#228;&#223; den 
Bestimmungen der folgenden Abs&#228;tze. 
(3) Bei den in Absatz 2 Buchstabe d genannten Risikomanagementma&#223;nahmen werden 
die Auswirkungen und m&#246;glichen Wechselwirkungen, die sich aus der kombinierten 
Anwendung der Anforderungen dieses Kapitels 2 ergeben, geb&#252;hrend ber&#252;cksichtigt. 
Diese Ma&#223;nahmen tragen dem allgemein anerkannten Stand der Technik Rechnung, 
wie er auch in einschl&#228;gigen harmonisierten Normen oder gemeinsamen 
Spezifikationen zum Ausdruck kommt. 
(4) Die in Absatz 2 Buchstabe d genannten Risikomanagementma&#223;nahmen werden so 
gestaltet, dass jedes mit einer bestimmten Gefahr verbundene Restrisiko sowie das 
Gesamtrestrisiko der Hochrisiko-KI-Systeme als vertretbar beurteilt werden kann, 
sofern das Hochrisiko-KI-System entsprechend seiner Zweckbestimmung oder im 
Rahmen einer vern&#252;nftigerweise vorhersehbaren Fehlanwendung verwendet wird. 
Diese Restrisiken m&#252;ssen den Nutzern mitgeteilt werden. 
Bei der Festlegung der am besten geeigneten Risikomanagementma&#223;nahmen ist 
Folgendes sicherzustellen:
a) weitestm&#246;gliche Beseitigung oder Verringerung der Risiken durch eine 
geeignete Konzeption und Entwicklung, 
b) gegebenenfalls Anwendung angemessener Minderungs- und 
Kontrollma&#223;nahmen im Hinblick auf nicht auszuschlie&#223;ende Risiken; 
c) Bereitstellung angemessener Informationen gem&#228;&#223; Artikel 13, insbesondere 
bez&#252;glich der in Absatz 2 Buchstabe b des vorliegenden Artikels genannten 
Risiken, und gegebenenfalls entsprechende Schulung der Nutzer. 
Bei der Beseitigung oder Verringerung der Risiken im Zusammenhang mit der 
Verwendung des Hochrisiko-KI-Systems werden die technischen Kenntnisse, die 
Erfahrungen und der Bildungsstand, die vom Nutzer erwarten werden k&#246;nnen, sowie 
das Umfeld, in dem das System eingesetzt werden soll, geb&#252;hrend ber&#252;cksichtigt. 
(5) Hochrisiko-KI-Systeme m&#252;ssen getestet werden, um die am besten geeigneten 
Risikomanagementma&#223;nahmen zu ermitteln. Durch das Testen wird sichergestellt, 
dass Hochrisiko-KI-Systeme stets bestimmungsgem&#228;&#223; funktionieren und die 
Anforderungen dieses Kapitels erf&#252;llen. 
(6) Die Testverfahren m&#252;ssen geeignet sein, die Zweckbestimmung des KI-Systems zu 
erf&#252;llen, und brauchen nicht &#252;ber das hierf&#252;r erforderliche Ma&#223; hinauszugehen. 
(7) Das Testen von Hochrisiko-KI-Systemen erfolgt zu jedem geeigneten Zeitpunkt 
w&#228;hrend des gesamten Entwicklungsprozesses und in jedem Fall vor dem 
Inverkehrbringen oder der Inbetriebnahme. Das Testen erfolgt anhand vorab 
festgelegter Parameter und probabilistischer Schwellenwerte, die f&#252;r die 
Zweckbestimmung des Hochrisiko-KI-Systems geeignet sind. 
(8) Bei der Umsetzung des in den Abs&#228;tzen 1 bis 7 beschriebenen 
Risikomanagementsystems ist insbesondere zu ber&#252;cksichtigen, ob das Hochrisiko-
KI-System wahrscheinlich f&#252;r Kinder zug&#228;nglich ist oder Auswirkungen auf Kinder 
hat. 
(9) Bei Kreditinstituten, die unter die Richtlinie 2013/36/EU fallen, sind die in den 
Abs&#228;tzen 1 bis 8 beschriebenen Aspekte Bestandteil der von diesen Instituten gem&#228;&#223; 
Artikel 74 der Richtlinie festgelegten Risikomanagementverfahren.
Artikel 10 
Daten und Daten-Governance
(1) Hochrisiko-KI-Systeme, in denen Techniken eingesetzt werden, bei denen Modelle 
mit Daten trainiert werden, m&#252;ssen mit Trainings-, Validierungs- und 
Testdatens&#228;tzen entwickelt werden, die den in den Abs&#228;tzen 2 bis 5 genannten 
Qualit&#228;tskriterien entsprechen. 
(2) F&#252;r Trainings-, Validierungs- und Testdatens&#228;tze gelten geeignete Daten-
Governance- und Datenverwaltungsverfahren. Diese Verfahren betreffen 
insbesondere
a) die einschl&#228;gigen konzeptionellen Entscheidungen, 
b) die Datenerfassung, 
c) relevante Datenaufbereitungsvorg&#228;nge wie Kommentierung, Kennzeichnung, 
Bereinigung, Anreicherung und Aggregierung,
d) die Aufstellung relevanter Annahmen, insbesondere in Bezug auf die 
Informationen, die mit den Daten erfasst und dargestellt werden sollen, 
e) eine vorherige Bewertung der Verf&#252;gbarkeit, Menge und Eignung der 
ben&#246;tigten Datens&#228;tze, 
f) eine Untersuchung im Hinblick auf m&#246;gliche Verzerrungen (Bias); 
g) die Ermittlung m&#246;glicher Datenl&#252;cken oder M&#228;ngel und wie diese L&#252;cken und 
M&#228;ngel behoben werden k&#246;nnen. 
(3) Die Trainings-, Validierungs- und Testdatens&#228;tze m&#252;ssen relevant, repr&#228;sentativ, 
fehlerfrei und vollst&#228;ndig sein. Sie haben die geeigneten statistischen Merkmale, 
gegebenenfalls auch bez&#252;glich der Personen oder Personengruppen, auf die das 
Hochrisiko-KI-System bestimmungsgem&#228;&#223; angewandt werden soll. Diese Merkmale 
der Datens&#228;tze k&#246;nnen durch einzelne Datens&#228;tze oder eine Kombination solcher 
Datens&#228;tze erf&#252;llt werden. 
(4) Die Trainings-, Validierungs- und Testdatens&#228;tze m&#252;ssen, soweit dies f&#252;r die 
Zweckbestimmung erforderlich ist, den Merkmalen oder Elementen entsprechen, die 
f&#252;r die besonderen geografischen, verhaltensbezogenen oder funktionalen 
Rahmenbedingungen, unter denen das Hochrisiko-KI-System bestimmungsgem&#228;&#223; 
verwendet werden soll, typisch sind. 
(5) Soweit dies f&#252;r die Beobachtung, Erkennung und Korrektur von Verzerrungen im 
Zusammenhang mit Hochrisiko-KI-Systemen unbedingt erforderlich ist, d&#252;rfen die 
Anbieter solcher Systeme besondere Kategorien personenbezogener Daten gem&#228;&#223; 
Artikel 9 Absatz 1 der Verordnung (EU) 2016/679, Artikel 10 der Richtlinie 
(EU) 2016/680 und Artikel 10 Absatz 1 der Verordnung (EU) 2018/1725 
verarbeiten, wobei sie angemessene Vorkehrungen f&#252;r den Schutz der Grundrechte 
und Grundfreiheiten nat&#252;rlicher Personen treffen m&#252;ssen, wozu auch technische 
Beschr&#228;nkungen einer Weiterverwendung und modernste Sicherheits- und 
Datenschutzma&#223;nahmen wie Pseudonymisierung oder Verschl&#252;sselung geh&#246;ren, 
wenn der verfolgte Zweck durch eine Anonymisierung erheblich beeintr&#228;chtigt 
w&#252;rde.
(6) Bei der Entwicklung von Hochrisiko-KI-Systemen, in denen keine Techniken 
eingesetzt werden, bei denen Modelle mit Daten trainiert werden, m&#252;ssen 
angemessene Daten-Governance und Datenverwaltungsverfahren angewandt werden, 
um sicherzustellen, dass solche Hochrisiko-KI-Systeme den Vorgaben in Absatz 2 
entsprechen.
Artikel 11 
Technische Dokumentation 
(1) Die technische Dokumentation eines Hochrisiko-KI-Systems wird erstellt, bevor 
dieses System in Verkehr gebracht oder in Betrieb genommen wird, und ist stets auf 
dem neuesten Stand zu halten. 
Die technische Dokumentation wird so erstellt, dass aus ihr der Nachweis 
hervorgeht, wie das Hochrisiko-KI-System die Anforderungen dieses Kapitels 
erf&#252;llt, und dass den zust&#228;ndigen nationalen Beh&#246;rden und den notifizierten Stellen 
alle Informationen zur Verf&#252;gung stehen, die erforderlich sind, um zu beurteilen, ob 
das KI-System diese Anforderungen erf&#252;llt. Sie enth&#228;lt zumindest die in Anhang IV 
genannten Angaben.
(2) Wird ein Hochrisiko-KI-System, das mit einem Produkt verbunden ist, das unter die 
in Anhang II Abschnitt A aufgef&#252;hrten Rechtsakte f&#228;llt, in Verkehr gebracht oder in 
Betrieb genommen, so wird eine einzige technische Dokumentation erstellt, die alle 
in Anhang IV genannten Informationen sowie die nach diesen Rechtsakten 
erforderlichen Informationen enth&#228;lt.
(3) Der Kommission wird die Befugnis &#252;bertragen, gem&#228;&#223; Artikel 73 delegierte 
Rechtsakte zur &#196;nderung des Anhangs IV zu erlassen, wenn dies n&#246;tig ist, damit die 
technische Dokumentation in Anbetracht des technischen Fortschritts stets alle 
Informationen enth&#228;lt, die erforderlich sind, um zu beurteilen, ob das System die 
Anforderungen dieses Kapitels erf&#252;llt. 
Artikel 12 
Aufzeichnungspflichten 
(1) Hochrisiko-KI-Systeme werden mit Funktionsmerkmalen konzipiert und entwickelt, 
die eine automatische Aufzeichnung von Vorg&#228;ngen und Ereignissen 
(&#8222;Protokollierung&#8220;) w&#228;hrend des Betriebs der Hochrisiko-KI-Systeme erm&#246;glichen. 
Diese Protokollierung muss anerkannten Normen oder gemeinsamen Spezifikationen 
entsprechen. 
(2) Die Protokollierung gew&#228;hrleistet, dass das Funktionieren des KI-Systems w&#228;hrend 
seines gesamten Lebenszyklus in einem der Zweckbestimmung des Systems 
angemessenen Ma&#223;e r&#252;ckverfolgbar ist. 
(3) Die Protokollierung erm&#246;glicht insbesondere die &#220;berwachung des Betriebs des 
Hochrisiko-KI-Systems im Hinblick auf das Auftreten von Situationen, die dazu 
f&#252;hren k&#246;nnen, dass das KI-System ein Risiko im Sinne des Artikels 65 Absatz 1 
birgt, oder die zu einer wesentlichen &#196;nderung f&#252;hren, und erleichtert so die 
Beobachtung nach dem Inverkehrbringen gem&#228;&#223; Artikel 61. 
(4) Die Protokollierungsfunktionen der in Anhang III Absatz 1 Buchstabe a genannten 
Hochrisiko-KI-Systeme m&#252;ssen zumindest Folgendes umfassen: 
a) Aufzeichnung jedes Zeitraums der Verwendung des Systems (Datum und 
Uhrzeit des Beginns und des Endes jeder Verwendung); 
b) die Referenzdatenbank, mit der das System die Eingabedaten abgleicht; 
c) die Eingabedaten, mit denen die Abfrage zu einer &#220;bereinstimmung gef&#252;hrt 
hat; 
d) die Identit&#228;t der gem&#228;&#223; Artikel 14 Absatz 5 an der &#220;berpr&#252;fung der Ergebnisse 
beteiligten nat&#252;rlichen Personen.
Artikel 13 
Transparenz und Bereitstellung von Informationen f&#252;r die Nutzer 
(1) Hochrisiko-KI-Systeme werden so konzipiert und entwickelt, dass ihr Betrieb 
hinreichend transparent ist, damit die Nutzer die Ergebnisse des Systems angemessen 
interpretieren und verwenden k&#246;nnen. Die Transparenz wird auf eine geeignete Art 
und in einem angemessenen Ma&#223; gew&#228;hrleistet, damit die Nutzer und Anbieter ihre 
in Kapitel 3 dieses Titels festgelegten einschl&#228;gigen Pflichten erf&#252;llen k&#246;nnen. 
(2) Hochrisiko-KI-Systeme werden mit Gebrauchsanweisungen in einem geeigneten 
digitalen Format bereitgestellt oder auf andere Weise mit Gebrauchsanweisungen
versehen, die pr&#228;zise, vollst&#228;ndige, korrekte und eindeutige Informationen in einer 
f&#252;r die Nutzer relevanten, barrierefrei zug&#228;nglichen und verst&#228;ndlichen Form 
enthalten.
(3) Die in Absatz 2 genannten Informationen umfassen: 
a) den Namen und die Kontaktangaben des Anbieters sowie gegebenenfalls seines 
Bevollm&#228;chtigten; 
b) die Merkmale, F&#228;higkeiten und Leistungsgrenzen des Hochrisiko-KI-Systems, 
einschlie&#223;lich 
i) seiner Zweckbestimmung, 
ii) des Ma&#223;es an Genauigkeit, Robustheit und Cybersicherheit gem&#228;&#223; 
Artikel 15, f&#252;r das das Hochrisiko-KI-System getestet und validiert 
wurde und das zu erwarten ist, sowie alle bekannten und vorhersehbaren 
Umst&#228;nde, die sich auf das erwartete Ma&#223; an Genauigkeit, Robustheit 
und Cybersicherheit auswirken k&#246;nnen, 
iii) aller bekannten oder vorhersehbaren Umst&#228;nde im Zusammenhang mit 
der bestimmungsgem&#228;&#223;en Verwendung des Hochrisiko-KI-Systems oder 
einer vern&#252;nftigerweise vorhersehbaren Fehlanwendung, die zu Risiken 
f&#252;r die Gesundheit und Sicherheit oder die Grundrechte f&#252;hren k&#246;nnen, 
iv) seiner Leistung bez&#252;glich der Personen oder Personengruppen, auf die 
das System bestimmungsgem&#228;&#223; angewandt werden soll, 
v) gegebenenfalls der Spezifikationen f&#252;r die Eingabedaten oder sonstiger 
relevanter Informationen &#252;ber die verwendeten Trainings-, Validierungs-
und Testdatens&#228;tze unter Ber&#252;cksichtigung der Zweckbestimmung des 
KI-Systems; 
c) etwaige &#196;nderungen des Hochrisiko-KI-Systems und seiner Leistung, die der 
Anbieter zum Zeitpunkt der ersten Konformit&#228;tsbewertung vorab bestimmt hat; 
d) die in Artikel 14 genannten Ma&#223;nahmen zur Gew&#228;hrleistung der menschlichen 
Aufsicht, einschlie&#223;lich der technischen Ma&#223;nahmen, die getroffen wurden, 
um den Nutzern die Interpretation der Ergebnisse von KI-Systemen zu 
erleichtern; 
e) die erwartete Lebensdauer des Hochrisiko-KI-Systems und alle erforderlichen 
Wartungs- und Pflegema&#223;nahmen zur Gew&#228;hrleistung des ordnungsgem&#228;&#223;en 
Funktionierens dieses KI-Systems, auch in Bezug auf Software-Updates.
Artikel 14 
Menschliche Aufsicht 
(1) Hochrisiko-KI-Systeme werden so konzipiert und entwickelt, dass sie w&#228;hrend der 
Dauer der Verwendung des KI-Systems &#8211; auch mit geeigneten Werkzeugen einer 
Mensch-Maschine-Schnittstelle &#8211; von nat&#252;rlichen Personen wirksam beaufsichtigt 
werden k&#246;nnen.
(2) Die menschliche Aufsicht dient der Verhinderung oder Minimierung der Risiken f&#252;r 
die Gesundheit, die Sicherheit oder die Grundrechte, die entstehen k&#246;nnen, wenn ein 
Hochrisiko-KI-System bestimmungsgem&#228;&#223; oder unter im Rahmen einer 
vern&#252;nftigerweise vorhersehbaren Fehlanwendung verwendet wird, insbesondere
wenn solche Risiken trotz der Einhaltung anderer Anforderungen dieses Kapitels 
fortbestehen.
(3) Die menschliche Aufsicht wird durch eine oder alle der folgenden Vorkehrungen 
gew&#228;hrleistet: 
a) sie wird vor dem Inverkehrbringen oder der Inbetriebnahme vom Anbieter 
bestimmt und, sofern technisch machbar, in das Hochrisiko-KI-System 
eingebaut; 
b) sie wird vor dem Inverkehrbringen oder der Inbetriebnahme des Hochrisiko-
KI-Systems vom Anbieter bestimmt und ist dazu geeignet, vom Nutzer 
umgesetzt zu werden. 
(4) Die in Absatz 3 genannten Ma&#223;nahmen m&#252;ssen den Personen, denen die 
menschliche Aufsicht &#252;bertragen wurde, je nach den Umst&#228;nden Folgendes 
erm&#246;glichen: 
a) die F&#228;higkeiten und Grenzen des Hochrisiko-KI-Systems vollst&#228;ndig zu 
verstehen und seinen Betrieb ordnungsgem&#228;&#223; zu &#252;berwachen, damit Anzeichen 
von Anomalien, Fehlfunktionen und unerwarteter Leistung so bald wie 
m&#246;glich erkannt und behoben werden k&#246;nnen; 
b) sich einer m&#246;glichen Neigung zu einem automatischen oder &#252;berm&#228;&#223;igen 
Vertrauen in das von einem Hochrisiko-KI-System hervorgebrachte Ergebnis 
(&#8222;Automatisierungsbias&#8220;) bewusst zu bleiben, insbesondere wenn Hochrisiko-
KI-Systeme Informationen oder Empfehlungen ausgeben, auf deren Grundlage 
nat&#252;rliche Personen Entscheidungen treffen; 
c) die Ergebnisse des Hochrisiko-KI-Systems richtig zu interpretieren, wobei 
insbesondere die Merkmale des Systems und die vorhandenen 
Interpretationswerkzeuge und -methoden zu ber&#252;cksichtigen sind; 
d) in einer bestimmten Situation zu beschlie&#223;en, das Hochrisiko-KI-System nicht 
zu verwenden oder das Ergebnis des Hochrisiko-KI-Systems anderweitig au&#223;er 
Acht zu lassen, au&#223;er Kraft zu setzen oder r&#252;ckg&#228;ngig zu machen; 
e) in den Betrieb des Hochrisiko-KI-Systems einzugreifen oder den 
Systembetrieb mit einer &#8222;Stopptaste&#8220; oder einem &#228;hnlichen Verfahren zu 
unterbrechen.
(5) Bei den in Anhang III Nummer 1 Buchstabe a genannten Hochrisiko-KI-Systemen 
m&#252;ssen die in Absatz 3 genannten Vorkehrungen so gestaltet sein, dass au&#223;erdem der 
Nutzer keine Ma&#223;nahmen oder Entscheidungen allein aufgrund des vom System 
hervorgebrachten Identifizierungsergebnisses trifft, solange dies nicht von 
mindestens zwei nat&#252;rlichen Personen &#252;berpr&#252;ft und best&#228;tigt wurde.
Artikel 15 
Genauigkeit, Robustheit und Cybersicherheit 
(1) Hochrisiko-KI-Systeme werden so konzipiert und entwickelt, dass sie im Hinblick 
auf ihre Zweckbestimmung ein angemessenes Ma&#223; an Genauigkeit, Robustheit und 
Cybersicherheit erreichen und in dieser Hinsicht w&#228;hrend ihres gesamten 
Lebenszyklus best&#228;ndig funktionieren. 
(2) Die Genauigkeitsgrade und die relevanten Genauigkeitskennzahlen von Hochrisiko-
KI-Systemen werden in der ihnen beigef&#252;gten Gebrauchsanweisung angegeben.
(3) Hochrisiko-KI-Systeme m&#252;ssen widerstandsf&#228;hig gegen&#252;ber Fehlern, St&#246;rungen oder 
Unstimmigkeiten sein, die innerhalb des Systems oder der Umgebung, in der das 
System betrieben wird, insbesondere wegen seiner Interaktion mit nat&#252;rlichen 
Personen oder anderen Systemen auftreten k&#246;nnen. 
Die Robustheit von Hochrisiko-KI-Systemen kann durch technische Redundanz 
erreicht werden, was auch Sicherungs- oder St&#246;rungssicherheitspl&#228;ne umfassen kann. 
Hochrisiko-KI-Systeme, die nach dem Inverkehrbringen oder der Inbetriebnahme 
weiterhin dazulernen, sind so zu entwickeln, dass auf m&#246;glicherweise verzerrte 
Ergebnisse, die durch eine Verwendung vorheriger Ergebnisse als Eingabedaten f&#252;r 
den k&#252;nftigen Betrieb entstehen (&#8222;R&#252;ckkopplungsschleifen&#8220;), angemessen mit 
geeigneten Risikominderungsma&#223;nahmen eingegangen wird. 
(4) Hochrisiko-KI-Systeme m&#252;ssen widerstandf&#228;hig gegen Versuche unbefugter Dritter 
sein, ihre Verwendung oder Leistung durch Ausnutzung von Systemschwachstellen 
zu ver&#228;ndern.
Die technischen L&#246;sungen zur Gew&#228;hrleistung der Cybersicherheit von Hochrisiko-
KI-Systemen m&#252;ssen den jeweiligen Umst&#228;nden und Risiken angemessen sein. 
Die technischen L&#246;sungen f&#252;r den Umgang mit KI-spezifischen Schwachstellen 
umfassen gegebenenfalls Ma&#223;nahmen zur Verh&#252;tung und Kontrolle von Angriffen, 
mit denen versucht wird, den Trainingsdatensatz zu manipulieren 
(&#8222;Datenvergiftung&#8220;), von Eingabedaten, die das Modell zu Fehlern verleiten sollen 
(&#8222;feindliche Beispiele&#8220;), oder von Modellm&#228;ngeln. 
KAPITEL 3
PFLICHTEN DER ANBIETER UND NUTZER VON HOCHRISIKO-KI-SYSTEMEN 
UND ANDERER BETEILIGTER
Artikel 16 
Pflichten der Anbieter von Hochrisiko-KI-Systemen 
Anbieter von Hochrisiko-KI-Systemen m&#252;ssen 
a) sicherstellen, dass ihre Hochrisiko-KI-Systeme die Anforderungen in Kapitel 2 
dieses Titels erf&#252;llen; 
b) &#252;ber ein Qualit&#228;tsmanagementsystem verf&#252;gen, das dem Artikel 17 entspricht; 
c) die technische Dokumentation des Hochrisiko-KI-Systems erstellen; 
d) die von ihren Hochrisiko-KI-Systemen automatisch erzeugten Protokolle 
aufbewahren, wenn dies ihrer Kontrolle unterliegt; 
e) sicherstellen, dass das Hochrisiko-KI-System dem betreffenden 
Konformit&#228;tsbewertungsverfahren unterzogen wird, bevor es in Verkehr gebracht 
oder in Betrieb genommen wird;
f) den in Artikel 51 genannten Registrierungspflichten nachkommen; 
g) die erforderlichen Korrekturma&#223;nahmen ergreifen, wenn das Hochrisiko-KI-System
die Anforderungen in Kapitel 2 dieses Titels nicht erf&#252;llt; 
h) die zust&#228;ndigen nationalen Beh&#246;rden der Mitgliedstaaten, in denen sie das System 
bereitgestellt oder in Betrieb genommen haben, und gegebenenfalls die notifizierte
Stelle &#252;ber die Nichtkonformit&#228;t und bereits ergriffene Korrekturma&#223;nahmen 
informieren; 
i) die CE-Kennzeichnung an ihren Hochrisiko-KI-Systemen anbringen, um die 
Konformit&#228;t mit dieser Verordnung gem&#228;&#223; Artikel 49 anzuzeigen;
j) auf Anfrage einer zust&#228;ndigen nationalen Beh&#246;rde nachweisen, dass das Hochrisiko-
KI-System die Anforderungen in Kapitel 2 dieses Titels erf&#252;llt. 
Artikel 17 
Qualit&#228;tsmanagementsystem 
(1) Anbieter von Hochrisiko-KI-Systemen richten ein Qualit&#228;tsmanagementsystem ein, 
das die Einhaltung dieser Verordnung gew&#228;hrleistet. Dieses System wird 
systematisch und ordnungsgem&#228;&#223; in Form schriftlicher Regeln, Verfahren und 
Anweisungen dokumentiert und umfasst mindestens folgende Aspekte: 
a) ein Konzept zur Einhaltung der Regulierungsvorschriften, was die Einhaltung 
der Konformit&#228;tsbewertungsverfahren und der Verfahren f&#252;r das Management 
von &#196;nderungen an den Hochrisiko-KI-Systemen miteinschlie&#223;t; 
b) Techniken, Verfahren und systematische Ma&#223;nahmen f&#252;r den Entwurf, die 
Entwurfskontrolle und die Entwurfspr&#252;fung des Hochrisiko-KI-Systems; 
c) Techniken, Verfahren und systematische Ma&#223;nahmen f&#252;r die Entwicklung, 
Qualit&#228;tskontrolle und Qualit&#228;tssicherung des Hochrisiko-KI-Systems; 
d) Untersuchungs-, Test- und Validierungsverfahren, die vor, w&#228;hrend und nach 
der Entwicklung des Hochrisiko-KI-Systems durchzuf&#252;hren sind, und die 
H&#228;ufigkeit der Durchf&#252;hrung; 
e) die technischen Spezifikationen und Normen, die anzuwenden sind, falls die 
einschl&#228;gigen harmonisierten Normen nicht vollst&#228;ndig angewandt werden, 
sowie die Mittel, mit denen gew&#228;hrleistet werden soll, dass das Hochrisiko-KI-
System die Anforderungen in Kapitel 2 dieses Titels erf&#252;llt; 
f) Systeme und Verfahren f&#252;r das Datenmanagement, einschlie&#223;lich 
Datenerfassung, Datenanalyse, Datenkennzeichnung, Datenspeicherung, 
Datenfilterung, Datenauswertung, Datenaggregation, Vorratsdatenspeicherung 
und sonstiger Vorg&#228;nge in Bezug auf die Daten, die im Vorfeld und f&#252;r die 
Zwecke des Inverkehrbringens oder der Inbetriebnahme von Hochrisiko-KI-
Systemen durchgef&#252;hrt werden; 
g) das in Artikel 9 genannte Risikomanagementsystem; 
h) Einrichtung, Anwendung und Aufrechterhaltung eines Systems zur 
Beobachtung nach dem Inverkehrbringen gem&#228;&#223; Artikel 61; 
i) Verfahren zur Meldung schwerwiegender Vorf&#228;lle und Fehlfunktionen gem&#228;&#223; 
Artikel 62; 
j) Kommunikation mit zust&#228;ndigen nationalen Beh&#246;rden, zust&#228;ndigen Beh&#246;rden, 
auch sektoralen Beh&#246;rden, die den Zugang zu Daten gew&#228;hren oder erleichtern, 
sowie mit notifizierten Stellen, anderen Akteuren, Kunden oder sonstigen 
interessierten Kreisen; 
k) Systeme und Verfahren f&#252;r die Aufzeichnung aller einschl&#228;gigen Unterlagen 
und Informationen;
l) Ressourcenmanagement, einschlie&#223;lich Ma&#223;nahmen im Hinblick auf die 
Versorgungssicherheit; 
m) einen Rechenschaftsrahmen, der die Verantwortlichkeiten der Leitung und des 
sonstigen Personals in Bezug auf alle in diesem Absatz aufgef&#252;hrten Aspekte 
regelt. 
(2) Die Umsetzung der in Absatz 1 genannten Aspekte erfolgt in einem angemessenen 
Verh&#228;ltnis zur Gr&#246;&#223;e der Organisation des Anbieters. 
(3) Bei Anbietern, die Kreditinstitute im Sinne der Richtlinie 2013/36/EU sind, gilt die 
Verpflichtung zur Einrichtung eines Qualit&#228;tsmanagementsystems als erf&#252;llt, wenn 
die Vorschriften &#252;ber Regelungen, Verfahren und Mechanismen der internen 
Unternehmensf&#252;hrung gem&#228;&#223; Artikel 74 der genannten Richtlinie eingehalten 
werden. Dabei werden die in Artikel 40 dieser Verordnung genannten harmonisierten 
Normen ber&#252;cksichtigt.
Artikel 18 
Pflicht zur Erstellung der technischen Dokumentation 
(1) Anbieter von Hochrisiko-KI-Systemen erstellen die in Artikel 11 genannte 
technische Dokumentation gem&#228;&#223; Anhang IV. 
(2) Anbieter, die Kreditinstitute im Sinne der Richtlinie 2013/36/EU sind, pflegen die 
technische Dokumentation als Teil ihrer Dokumentation &#252;ber die Regelungen, 
Verfahren und Mechanismen der internen Unternehmensf&#252;hrung gem&#228;&#223; Artikel 74 
der genannten Richtlinie. 
Artikel 19 
Konformit&#228;tsbewertung 
(1) Die Anbieter von Hochrisiko-KI-Systemen stellen sicher, dass ihre Systeme vor dem 
Inverkehrbringen oder der Inbetriebnahme dem betreffenden 
Konformit&#228;tsbewertungsverfahren gem&#228;&#223; Artikel 43 unterzogen werden. Wurde 
infolge dieser Konformit&#228;tsbewertung nachgewiesen, dass die KI-Systeme die 
Anforderungen in Kapitel 2 dieses Titels erf&#252;llen, erstellen die Anbieter eine EU-
Konformit&#228;tserkl&#228;rung gem&#228;&#223; Artikel 48 und bringen die CE-
Konformit&#228;tskennzeichnung gem&#228;&#223; Artikel 49 an. 
(2) Bei den in Anhang III Nummer 5 Buchstabe b genannten Hochrisiko-KI-Systemen, 
die von Anbietern in Verkehr gebracht oder in Betrieb genommen werden, die 
Kreditinstitute im Sinne der Richtlinie 2013/36/EU sind, erfolgt die 
Konformit&#228;tsbewertung im Rahmen des in den Artikeln 97 bis 101 der Richtlinie 
genannten Verfahrens.
Artikel 20 
Automatisch erzeugte Protokolle 
(1) Anbieter von Hochrisiko-KI-Systemen bewahren die von ihren Hochrisiko-KI-
Systemen automatisch erzeugten Protokolle auf, soweit diese Protokolle aufgrund 
einer vertraglichen Vereinbarung mit dem Nutzer oder auf gesetzlicher Grundlage 
ihrer Kontrolle unterliegen. Die Protokolle werden f&#252;r einen Zeitraum aufbewahrt, 
der der Zweckbestimmung des Hochrisiko-KI-Systems und den geltenden
rechtlichen Verpflichtungen nach Unionsrecht oder nationalem Recht angemessen 
ist.
(2) Anbieter, die Kreditinstitute im Sinne der Richtlinie 2013/36/EU sind, bewahren die 
von ihren Hochrisiko-KI-Systemen automatisch erzeugten Protokolle als Teil der 
Dokumentation gem&#228;&#223; Artikel 74 der Richtlinie auf. 
Artikel 21 
Korrekturma&#223;nahmen 
Anbieter von Hochrisiko-KI-Systemen, die der Auffassung sind oder Grund zu der Annahme 
haben, dass ein von ihnen in Verkehr gebrachtes oder in Betrieb genommenes Hochrisiko-KI-
System nicht dieser Verordnung entspricht, ergreifen unverz&#252;glich die erforderlichen 
Korrekturma&#223;nahmen, um die Konformit&#228;t dieses Systems herzustellen oder es 
gegebenenfalls zur&#252;ckzunehmen oder zur&#252;ckzurufen. Sie setzen die H&#228;ndler des betreffenden 
Hochrisiko-KI-Systems und gegebenenfalls den Bevollm&#228;chtigten und die Einf&#252;hrer davon in 
Kenntnis.
Artikel 22 
Informationspflicht 
Birgt das Hochrisiko-KI-System ein Risiko im Sinne des Artikels 65 Absatz 1 und ist dem 
Anbieter des Systems dieses Risiko bekannt, so informiert dieser Anbieter unverz&#252;glich die 
zust&#228;ndigen nationalen Beh&#246;rden der Mitgliedstaaten, in denen er das System bereitgestellt 
hat, und gegebenenfalls die notifizierte Stelle, die eine Bescheinigung f&#252;r das Hochrisiko-KI-
System ausgestellt hat, und macht dabei ausf&#252;hrliche Angaben, insbesondere zur 
Nichtkonformit&#228;t und zu bereits ergriffenen Korrekturma&#223;nahmen.
Artikel 23 
Zusammenarbeit mit den zust&#228;ndigen Beh&#246;rden 
Anbieter von Hochrisiko-KI-Systemen &#252;bermitteln einer zust&#228;ndigen nationalen Beh&#246;rde auf 
deren Verlangen alle Informationen und Unterlagen, die erforderlich sind, um die Konformit&#228;t 
des Hochrisiko-KI-Systems mit den Anforderungen in Kapitel 2 dieses Titels nachzuweisen, 
in einer von dem betreffenden Mitgliedstaat festgelegten Amtssprache der Union. Auf 
begr&#252;ndetes Verlangen einer zust&#228;ndigen nationalen Beh&#246;rde gew&#228;hren die Anbieter dieser 
Beh&#246;rde auch Zugang zu den von ihrem Hochrisiko-KI-System automatisch erzeugten 
Protokollen, soweit diese Protokolle aufgrund einer vertraglichen Vereinbarung mit dem 
Nutzer oder auf gesetzlicher Grundlage ihrer Kontrolle unterliegen.
Artikel 24 
Pflichten der Produkthersteller 
Wird ein Hochrisiko-KI-System f&#252;r Produkte, die unter die in Anhang II Abschnitt A 
aufgef&#252;hrten Rechtsakte fallen, zusammen mit dem gem&#228;&#223; diesen Rechtsvorschriften 
hergestellten Produkt unter dem Namen des Produktherstellers in Verkehr gebracht oder in 
Betrieb genommen, so &#252;bernimmt der Hersteller des Produkts die Verantwortung f&#252;r die 
Konformit&#228;t des KI-Systems mit dieser Verordnung und hat in Bezug auf das KI-System 
dieselben Pflichten, die dem Anbieter durch diese Verordnung auferlegt werden.
Artikel 25 
Bevollm&#228;chtigte 
(1) Anbieter, die au&#223;erhalb der Union niedergelassen sind, benennen vor der 
Bereitstellung ihrer Systeme in der Union schriftlich einen in der Union 
niedergelassenen Bevollm&#228;chtigten, wenn kein Einf&#252;hrer festgestellt werden kann. 
(2) Der Bevollm&#228;chtigte nimmt die Aufgaben wahr, die in seinem vom Anbieter 
erhaltenen Auftrag festgelegt sind. Der Auftrag erm&#228;chtigt den Bevollm&#228;chtigten 
zumindest zur Wahrnehmung folgender Aufgaben: 
a) Bereithaltung eines Exemplars der EU-Konformit&#228;tserkl&#228;rung und der 
technischen Dokumentation f&#252;r die zust&#228;ndigen nationalen Beh&#246;rden und die 
in Artikel 63 Absatz 7 genannten nationalen Beh&#246;rden; 
b) &#220;bermittlung aller Informationen und Unterlagen, die erforderlich sind, um die 
Konformit&#228;t eines Hochrisiko-KI-Systems mit den Anforderungen in Kapitel 2 
dieses Titels nachzuweisen, an eine zust&#228;ndige nationale Beh&#246;rde auf deren 
begr&#252;ndetes Verlangen, einschlie&#223;lich der Gew&#228;hrung des Zugangs zu den 
vom Hochrisiko-KI-System automatisch erzeugten Protokollen, soweit diese 
Protokolle aufgrund einer vertraglichen Vereinbarung mit dem Nutzer oder auf 
gesetzlicher Grundlage der Kontrolle des Anbieters unterliegen; 
c) Zusammenarbeit mit den zust&#228;ndigen nationalen Beh&#246;rden auf deren 
begr&#252;ndetes Verlangen bei allen Ma&#223;nahmen, die Letztere im Zusammenhang 
mit dem Hochrisiko-KI-System ergreifen.
Artikel 26 
Pflichten der Einf&#252;hrer 
(1) Bevor sie ein Hochrisiko-KI-System in Verkehr bringen, stellen die Einf&#252;hrer 
solcher Systeme sicher, dass 
a) der Anbieter des KI-Systems das betreffende 
Konformit&#228;tsbewertungsverfahren durchgef&#252;hrt hat; 
b) der Anbieter die technische Dokumentation gem&#228;&#223; Anhang IV erstellt hat; 
c) das System mit der erforderlichen Konformit&#228;tskennzeichnung versehen ist 
und ihm die erforderlichen Unterlagen und Gebrauchsanweisungen beigef&#252;gt 
sind. 
(2) Ist ein Einf&#252;hrer der Auffassung oder hat er Grund zu der Annahme, dass ein 
Hochrisiko-KI-System nicht dieser Verordnung entspricht, so bringt er dieses 
Hochrisiko-KI-System erst in Verkehr, nachdem die Konformit&#228;t dieses Systems 
hergestellt worden ist. Birgt das Hochrisiko-KI-System ein Risiko im Sinne des 
Artikels 65 Absatz 1, so setzt der Einf&#252;hrer den Anbieter des KI-Systems und die 
Markt&#252;berwachungsbeh&#246;rden davon in Kenntnis. 
(3) Die Einf&#252;hrer geben ihren Namen, ihren eingetragenen Handelsnamen oder ihre 
eingetragene Handelsmarke und ihre Kontaktanschrift auf dem Hochrisiko-KI-
System selbst oder, wenn dies nicht m&#246;glich ist, auf der Verpackung oder in der 
beigef&#252;gten Dokumentation an. 
(4) Solange sich ein Hochrisiko-KI-System in ihrer Verantwortung befindet, 
gew&#228;hrleisten die Einf&#252;hrer, dass &#8211; soweit zutreffend &#8211; die Lagerungs- oder
Transportbedingungen dessen Konformit&#228;t mit den Anforderungen in Kapitel 2 
dieses Titels nicht beeintr&#228;chtigen. 
(5) Die Einf&#252;hrer &#252;bermitteln den zust&#228;ndigen nationalen Beh&#246;rden auf deren 
begr&#252;ndetes Verlangen alle Informationen und Unterlagen zum Nachweis der 
Konformit&#228;t eines Hochrisiko-KI-Systems mit den Anforderungen in Kapitel 2 
dieses Titels in einer Sprache, die f&#252;r die betreffende zust&#228;ndige nationale Beh&#246;rde 
leicht verst&#228;ndlich ist, und gew&#228;hren ihr Zugang zu den vom Hochrisiko-KI-System 
automatisch erzeugten Protokollen, soweit diese Protokolle aufgrund einer 
vertraglichen Vereinbarung mit dem Nutzer oder auf gesetzlicher Grundlage der 
Kontrolle des Anbieters unterliegen. Sie arbeiten au&#223;erdem mit diesen Beh&#246;rden bei 
allen Ma&#223;nahmen zusammen, die eine zust&#228;ndige nationale Beh&#246;rde im 
Zusammenhang mit diesem System ergreift.
Artikel 27 
Pflichten der H&#228;ndler 
(1) Bevor H&#228;ndler ein Hochrisiko-KI-System auf dem Markt bereitstellen, &#252;berpr&#252;fen 
sie, ob das Hochrisiko-KI-System mit der erforderlichen CE-
Konformit&#228;tskennzeichnung versehen ist, ob ihm die erforderliche Dokumentation 
und Gebrauchsanweisung beigef&#252;gt sind und ob der Anbieter bzw. gegebenenfalls 
der Einf&#252;hrer des Systems die in dieser Verordnung festgelegten Pflichten erf&#252;llt hat. 
(2) Ist ein H&#228;ndler der Auffassung oder hat er Grund zu der Annahme, dass ein 
Hochrisiko-KI-System nicht den Anforderungen in Kapitel 2 dieses Titels entspricht, 
so stellt er das Hochrisiko-KI-System erst auf dem Markt bereit, nachdem die 
Konformit&#228;t mit den Anforderungen hergestellt worden ist. Birgt das System zudem 
ein Risiko im Sinne des Artikels 65 Absatz 1, so setzt der H&#228;ndler den Anbieter bzw. 
den Einf&#252;hrer des Systems davon in Kenntnis. 
(3) Solange sich ein Hochrisiko-KI-System in ihrer Verantwortung befindet, 
gew&#228;hrleisten die H&#228;ndler, dass &#8211; soweit zutreffend &#8211; die Lagerungs- oder 
Transportbedingungen die Konformit&#228;t des Systems mit den Anforderungen in 
Kapitel 2 dieses Titels nicht beeintr&#228;chtigen. 
(4) Ein H&#228;ndler, der der Auffassung ist oder Grund zu der Annahme hat, dass ein von 
ihm auf dem Markt bereitgestelltes Hochrisiko-KI-System nicht den Anforderungen 
in Kapitel 2 dieses Titels entspricht, ergreift die erforderlichen 
Korrekturma&#223;nahmen, um die Konformit&#228;t dieses Systems mit diesen 
Anforderungen herzustellen, es zur&#252;ckzunehmen oder zur&#252;ckzurufen, oder er stellt 
sicher, dass der Anbieter, der Einf&#252;hrer oder gegebenenfalls jeder relevante Akteur 
diese Korrekturma&#223;nahmen ergreift. Birgt das Hochrisiko-KI-System ein Risiko im 
Sinne des Artikels 65 Absatz 1, so informiert der H&#228;ndler unverz&#252;glich die 
zust&#228;ndigen nationalen Beh&#246;rden der Mitgliedstaaten, in denen er das System 
bereitgestellt hat, und macht dabei ausf&#252;hrliche Angaben, insbesondere zur 
Nichtkonformit&#228;t und zu bereits ergriffenen Korrekturma&#223;nahmen. 
(5) Auf begr&#252;ndetes Verlangen einer zust&#228;ndigen nationalen Beh&#246;rde &#252;bermitteln die 
H&#228;ndler von Hochrisiko-KI-Systemen dieser Beh&#246;rde alle Informationen und 
Unterlagen, die erforderlich sind, um die Konformit&#228;t eines Hochrisiko-KI-Systems 
mit den Anforderungen in Kapitel 2 dieses Titels nachzuweisen. Die H&#228;ndler 
arbeiten au&#223;erdem mit dieser zust&#228;ndigen nationalen Beh&#246;rde bei allen von dieser 
Beh&#246;rde ergriffenen Ma&#223;nahmen zusammen.
Artikel 28 
Pflichten der H&#228;ndler, Einf&#252;hrer, Nutzer oder sonstiger Dritter 
(1) In den folgenden F&#228;llen gelten H&#228;ndler, Einf&#252;hrer, Nutzer oder sonstige Dritte als 
Anbieter f&#252;r die Zwecke dieser Verordnung und unterliegen den Anbieterpflichten 
gem&#228;&#223; Artikel 16: 
a) wenn sie ein Hochrisiko-KI-System unter ihrem Namen oder ihrer Marke in 
Verkehr bringen oder in Betrieb nehmen; 
b) wenn sie die Zweckbestimmung eines bereits im Verkehr befindlichen oder in 
Betrieb genommenen Hochrisiko-KI-Systems ver&#228;ndern; 
c) wenn sie eine wesentliche &#196;nderung an dem Hochrisiko-KI-System 
vornehmen.
(2) Unter den in Absatz 1 Buchstabe b oder c genannten Umst&#228;nden gilt der Anbieter, 
der das Hochrisiko-KI-System urspr&#252;nglich in Verkehr gebracht oder in Betrieb 
genommen hatte, nicht mehr als Anbieter f&#252;r die Zwecke dieser Verordnung.
Artikel 29 
Pflichten der Nutzer von Hochrisiko-KI-Systemen 
(1) Die Nutzer von Hochrisiko-KI-Systemen verwenden solche Systeme entsprechend 
der den Systemen beigef&#252;gten Gebrauchsanweisung und gem&#228;&#223; den Abs&#228;tzen 2 
und 5. 
(2) Die Pflichten nach Absatz 1 lassen sonstige Pflichten der Nutzer nach Unionsrecht 
oder nationalem Recht sowie das Ermessen der Nutzer bei der Organisation ihrer 
eigenen Ressourcen und T&#228;tigkeiten zur Wahrnehmung der vom Anbieter 
angegebenen Ma&#223;nahmen der menschlichen Aufsicht unber&#252;hrt. 
(3) Unbeschadet des Absatzes 1 und soweit die Eingabedaten seiner Kontrolle 
unterliegen, sorgen die Nutzer daf&#252;r, dass die Eingabedaten der Zweckbestimmung 
des Hochrisiko-KI-Systems entsprechen. 
(4) Die Nutzer &#252;berwachen den Betrieb des Hochrisiko-KI-Systems anhand der 
Gebrauchsanweisung. Haben sie Grund zu der Annahme, dass die Verwendung 
gem&#228;&#223; der Gebrauchsanweisung dazu f&#252;hren kann, dass das Hochrisiko-KI-System 
ein Risiko im Sinne des Artikels 65 Absatz 1 birgt, so informieren sie den Anbieter 
oder H&#228;ndler und setzen die Verwendung des Systems aus. Sie informieren den 
Anbieter oder H&#228;ndler auch, wenn sie einen schwerwiegenden Vorfall oder eine 
Fehlfunktion im Sinne des Artikels 62 festgestellt haben, und unterbrechen die 
Verwendung des KI-Systems. Kann der Nutzer den Anbieter nicht erreichen, so gilt 
Artikel 62 entsprechend. 
Bei Nutzern, die Kreditinstitute im Sinne der Richtlinie 2013/36/EU sind, gilt die in 
Unterabsatz 1 vorgesehene &#220;berwachungspflicht als erf&#252;llt, wenn die Vorschriften 
&#252;ber Regelungen, Verfahren und Mechanismen der internen Unternehmensf&#252;hrung 
gem&#228;&#223; Artikel 74 der genannten Richtlinie eingehalten werden. 
(5) Nutzer von Hochrisiko-KI-Systemen bewahren die von ihrem Hochrisiko-KI-System 
automatisch erzeugten Protokolle auf, soweit diese Protokolle ihrer Kontrolle 
unterliegen. Die Protokolle werden f&#252;r einen Zeitraum aufbewahrt, der der 
Zweckbestimmung des Hochrisiko-KI-Systems und den geltenden rechtlichen 
Verpflichtungen nach Unionsrecht oder nationalem Recht angemessen ist.
Nutzer, die Kreditinstitute im Sinne der Richtlinie 2013/36/EU sind, bewahren die 
Protokolle als Teil ihrer Dokumentation &#252;ber die Regelungen, Verfahren und 
Mechanismen der internen Unternehmensf&#252;hrung gem&#228;&#223; Artikel 74 der genannten 
Richtlinie auf. 
(6) Die Nutzer von Hochrisiko-KI-Systemen verwenden die gem&#228;&#223; Artikel 13 
bereitgestellten Informationen, um gegebenenfalls ihrer Verpflichtung zur 
Durchf&#252;hrung einer Datenschutz-Folgenabsch&#228;tzung gem&#228;&#223; Artikel 35 der 
Verordnung (EU) 2016/679 oder Artikel 27 der Richtlinie (EU) 2016/680 
nachzukommen. 
KAPITEL 4
NOTIFIZIERENDE BEH&#214;RDEN UND NOTIFIZIERTE STELLEN
Artikel 30 
Notifizierende Beh&#246;rden 
(1) Jeder Mitgliedstaat sorgt f&#252;r die Benennung oder Schaffung einer notifizierenden 
Beh&#246;rde, die f&#252;r die Einrichtung und Durchf&#252;hrung der erforderlichen Verfahren zur 
Bewertung, Benennung und Notifizierung von Konformit&#228;tsbewertungsstellen und 
f&#252;r deren &#220;berwachung zust&#228;ndig ist. 
(2) Die Mitgliedstaaten k&#246;nnen eine nationale Akkreditierungsstelle im Sinne der 
Verordnung (EG) Nr. 765/2008 als notifizierende Beh&#246;rde benennen. 
(3) Notifizierende Beh&#246;rden werden so eingerichtet, strukturiert und in ihren 
Arbeitsabl&#228;ufen organisiert, dass jegliche Interessenkonflikte mit 
Konformit&#228;tsbewertungsstellen vermieden werden und die Objektivit&#228;t und die 
Unparteilichkeit ihrer T&#228;tigkeiten gew&#228;hrleistet sind. 
(4) Notifizierende Beh&#246;rden werden so strukturiert, dass Entscheidungen &#252;ber die 
Notifizierung von Konformit&#228;tsbewertungsstellen von kompetenten Personen 
getroffen werden, die nicht mit den Personen identisch sind, die die Bewertung 
dieser Stellen durchgef&#252;hrt haben. 
(5) Notifizierende Beh&#246;rden d&#252;rfen weder T&#228;tigkeiten, die 
Konformit&#228;tsbewertungsstellen durchf&#252;hren, noch Beratungsleistungen auf einer 
gewerblichen oder wettbewerblichen Basis anbieten oder erbringen. 
(6) Notifizierende Beh&#246;rden gew&#228;hrleisten die Vertraulichkeit der von ihnen erlangten 
Informationen.
(7) Notifizierende Beh&#246;rden verf&#252;gen &#252;ber kompetente Mitarbeiter in ausreichender 
Zahl, sodass sie ihre Aufgaben ordnungsgem&#228;&#223; wahrnehmen k&#246;nnen. 
(8) Notifizierende Beh&#246;rden gew&#228;hrleisten, dass Konformit&#228;tsbewertungen in 
angemessener Art und Weise und ohne unn&#246;tige Belastungen f&#252;r die Anbieter 
durchgef&#252;hrt werden und dass die notifizierten Stellen bei ihren T&#228;tigkeiten die 
Gr&#246;&#223;e eines Unternehmens, die Branche, in der es t&#228;tig ist, seine Struktur und die 
Komplexit&#228;t des betreffenden KI-Systems geb&#252;hrend ber&#252;cksichtigen.
Artikel 31 
Antrag einer Konformit&#228;tsbewertungsstelle auf Notifizierung 
(1) Konformit&#228;tsbewertungsstellen beantragen ihre Notifizierung bei der notifizierenden 
Beh&#246;rde des Mitgliedstaats, in dem sie ans&#228;ssig sind. 
(2) Dem Antrag auf Notifizierung legen sie eine Beschreibung der 
Konformit&#228;tsbewertungst&#228;tigkeiten, des/der Konformit&#228;tsbewertungsverfahren(s) 
und der Technologien der k&#252;nstlichen Intelligenz, f&#252;r die diese 
Konformit&#228;tsbewertungsstelle Kompetenz beansprucht, sowie, falls vorhanden, eine 
Akkreditierungsurkunde bei, die von einer nationalen Akkreditierungsstelle 
ausgestellt wurde und in der bescheinigt wird, dass die Konformit&#228;tsbewertungsstelle 
die Anforderungen des Artikels 33 erf&#252;llt. Sonstige g&#252;ltige Dokumente in Bezug auf 
bestehende Benennungen der antragstellenden notifizierten Stelle im Rahmen 
anderer Harmonisierungsrechtsvorschriften der Union sind ebenfalls beizuf&#252;gen. 
(3) Kann die Konformit&#228;tsbewertungsstelle keine Akkreditierungsurkunde vorweisen, so 
legt sie der notifizierenden Beh&#246;rde als Nachweis alle Unterlagen vor, die 
erforderlich sind, um zu &#252;berpr&#252;fen, festzustellen und regelm&#228;&#223;ig zu &#252;berwachen, ob 
sie die Anforderungen des Artikels 33 erf&#252;llt. Bei notifizierten Stellen, die im 
Rahmen anderer Harmonisierungsrechtsvorschriften der Union benannt wurden, 
k&#246;nnen alle Unterlagen und Bescheinigungen im Zusammenhang mit solchen 
Benennungen zur Unterst&#252;tzung ihres Benennungsverfahrens nach dieser 
Verordnung verwendet werden.
Artikel 32 
Notifizierungsverfahren 
(1) Die notifizierenden Beh&#246;rden d&#252;rfen nur Konformit&#228;tsbewertungsstellen notifizieren, 
die die Anforderungen des Artikels 33 erf&#252;llen. 
(2) Die notifizierenden Beh&#246;rden unterrichten die Kommission und die &#252;brigen 
Mitgliedstaaten mithilfe des elektronischen Notifizierungsinstruments, das von der 
Kommission entwickelt und verwaltet wird.
(3) Eine Notifizierung enth&#228;lt vollst&#228;ndige Angaben zu den 
Konformit&#228;tsbewertungst&#228;tigkeiten, dem/den betreffenden 
Konformit&#228;tsbewertungsmodul(en) und den betreffenden Technologien der 
k&#252;nstlichen Intelligenz.
(4) Die betreffende Konformit&#228;tsbewertungsstelle darf die Aufgaben einer notifizierten 
Stelle nur dann wahrnehmen, wenn weder die Kommission noch die &#252;brigen 
Mitgliedstaaten innerhalb von einem Monat nach der Notifizierung Einw&#228;nde 
erhoben haben.
(5) Die notifizierenden Beh&#246;rden melden der Kommission und den &#252;brigen 
Mitgliedstaaten jede sp&#228;ter eintretende &#196;nderung der Notifizierung.
Artikel 33 
Notifizierte Stellen 
(1) Die notifizierten Stellen &#252;berpr&#252;fen die Konformit&#228;t von Hochrisiko-KI-Systemen 
nach den in Artikel 43 genannten Konformit&#228;tsbewertungsverfahren.
(2) Die notifizierten Stellen m&#252;ssen die Anforderungen an die Organisation, das 
Qualit&#228;tsmanagement, die Ressourcenausstattung und die Verfahren erf&#252;llen, die zur 
Wahrnehmung ihrer Aufgaben erforderlich sind. 
(3) Die Organisationsstruktur, die Zuweisung der Zust&#228;ndigkeiten, die Berichtslinien 
und die Funktionsweise der notifizierten Stellen sind so gestaltet, dass sie die 
Zuverl&#228;ssigkeit der Leistung der notifizierten Stelle und das Vertrauen in die 
Ergebnisse der von ihr durchgef&#252;hrten Konformit&#228;tsbewertungst&#228;tigkeiten 
gew&#228;hrleisten. 
(4) Die notifizierten Stellen sind von dem Anbieter eines Hochrisiko-KI-Systems, zu 
dem sie Konformit&#228;tsbewertungst&#228;tigkeiten durchf&#252;hren, unabh&#228;ngig. Au&#223;erdem 
sind die notifizierten Stellen von allen anderen Akteuren, die ein wirtschaftliches 
Interesse an dem bewerteten Hochrisiko-KI-System haben, und von allen 
Wettbewerbern des Anbieters unabh&#228;ngig. 
(5) Die notifizierten Stellen gew&#228;hrleisten durch ihre Organisation und Arbeitsweise, 
dass bei der Aus&#252;bung ihrer T&#228;tigkeit Unabh&#228;ngigkeit, Objektivit&#228;t und 
Unparteilichkeit gewahrt sind. Von den notifizierten Stellen werden eine Struktur 
und Verfahren dokumentiert und umgesetzt, die ihre Unparteilichkeit gew&#228;hrleisten 
und sicherstellen, dass die Grunds&#228;tze der Unparteilichkeit in ihrer gesamten 
Organisation und von allen Mitarbeitern und bei allen Bewertungst&#228;tigkeiten 
gef&#246;rdert und angewandt werden. 
(6) Die notifizierten Stellen gew&#228;hrleisten durch dokumentierte Verfahren, dass ihre 
Mitarbeiter, Aussch&#252;sse, Zweigstellen, Unterauftragnehmer sowie alle zugeordneten 
Stellen oder Mitarbeiter externer Einrichtungen die Vertraulichkeit der 
Informationen, die bei der Durchf&#252;hrung der Konformit&#228;tsbewertungst&#228;tigkeiten in 
ihren Besitz gelangen, wahren, au&#223;er wenn die Offenlegung gesetzlich 
vorgeschrieben ist. Informationen, von denen Mitarbeiter der notifizierten Stellen bei 
der Durchf&#252;hrung ihrer Aufgaben gem&#228;&#223; dieser Verordnung Kenntnis erlangen, 
unterliegen der beruflichen Schweigepflicht, au&#223;er gegen&#252;ber den notifizierenden 
Beh&#246;rden des Mitgliedstaats, in dem sie ihre T&#228;tigkeiten aus&#252;ben. 
(7) Die notifizierten Stellen verf&#252;gen &#252;ber Verfahren zur Durchf&#252;hrung ihrer T&#228;tigkeiten 
unter geb&#252;hrender Ber&#252;cksichtigung der Gr&#246;&#223;e eines Unternehmens, der Branche, in 
der es t&#228;tig ist, seiner Struktur sowie der Komplexit&#228;t des betreffenden KI-Systems. 
(8) Die notifizierten Stellen schlie&#223;en eine angemessene Haftpflichtversicherung f&#252;r ihre 
Konformit&#228;tsbewertungst&#228;tigkeiten ab, es sei denn, diese Haftpflicht wird aufgrund 
nationalen Rechts von dem betreffenden Mitgliedstaat gedeckt oder dieser 
Mitgliedstaat ist unmittelbar f&#252;r die Durchf&#252;hrung der Konformit&#228;tsbewertung 
zust&#228;ndig. 
(9) Die notifizierten Stellen sind in der Lage, die ihnen durch diese Verordnung 
zufallenden Aufgaben mit h&#246;chster beruflicher Integrit&#228;t und der erforderlichen 
Fachkompetenz in dem betreffenden Bereich auszuf&#252;hren, gleichg&#252;ltig, ob diese 
Aufgaben von den notifizierten Stellen selbst oder in ihrem Auftrag und in ihrer 
Verantwortung erf&#252;llt werden. 
(10) Die notifizierten Stellen verf&#252;gen &#252;ber ausreichende interne Kompetenzen, um die 
von externen Stellen in ihrem Namen wahrgenommen Aufgaben wirksam beurteilen 
zu k&#246;nnen. Dazu m&#252;ssen die notifizierten Stellen jederzeit f&#252;r jedes 
Konformit&#228;tsbewertungsverfahren und f&#252;r jede Art von Hochrisiko-KI-Systemen, f&#252;r 
die sie benannt wurden, st&#228;ndig &#252;ber ausreichendes administratives, technisches und
wissenschaftliches Personal verf&#252;gen, das die entsprechenden Erfahrungen und 
Kenntnisse in Bezug auf einschl&#228;gige KI-Technik, Daten und Datenverarbeitung 
sowie die Anforderungen in Kapitel 2 dieses Titels besitzt. 
(11) Die notifizierten Stellen wirken an den in Artikel 38 genannten 
Koordinierungst&#228;tigkeiten mit. Sie wirken au&#223;erdem unmittelbar oder mittelbar an 
der Arbeit der europ&#228;ischen Normungsorganisationen mit oder stellen sicher, dass sie 
stets &#252;ber den Stand der einschl&#228;gigen Normen unterrichtet sind. 
(12) Die notifizierten Stellen machen der in Artikel 30 genannten notifizierenden Beh&#246;rde 
alle einschl&#228;gigen Unterlagen, einschlie&#223;lich der Unterlagen des Anbieters, 
zug&#228;nglich bzw. &#252;bermitteln diese auf Anfrage, damit diese ihre Bewertungs-, 
Benennungs-, Notifizierungs-, &#220;berwachungs- und Kontrollaufgaben wahrnehmen 
kann und die Bewertung gem&#228;&#223; diesem Kapitel erleichtert wird.
Artikel 34 
Zweigstellen notifizierter Stellen und Vergabe von Unterauftr&#228;gen durch notifizierte Stellen 
(1) Vergibt die notifizierte Stelle bestimmte mit der Konformit&#228;tsbewertung verbundene 
Aufgaben an Unterauftragnehmer oder &#252;bertr&#228;gt sie diese einer Zweigstelle, so stellt 
sie sicher, dass der Unterauftragnehmer oder die Zweigstelle die Anforderungen des 
Artikels 33 erf&#252;llt, und setzt die notifizierende Beh&#246;rde davon in Kenntnis. 
(2) Die notifizierten Stellen tragen die volle Verantwortung f&#252;r die Arbeiten, die von 
Unterauftragnehmern oder Zweigstellen ausgef&#252;hrt werden, unabh&#228;ngig davon, wo 
diese niedergelassen sind. 
(3) Arbeiten d&#252;rfen nur mit Zustimmung des Anbieters an einen Unterauftragnehmer 
vergeben oder einer Zweigstelle &#252;bertragen werden. 
(4) Die notifizierten Stellen halten f&#252;r die notifizierende Beh&#246;rde die einschl&#228;gigen 
Unterlagen &#252;ber die Bewertung der Qualifikation des Unterauftragnehmers oder der 
Zweigstelle und die von ihnen gem&#228;&#223; dieser Verordnung ausgef&#252;hrten Arbeiten 
bereit.
Artikel 35 
Kennnummern und Verzeichnisse der nach dieser Verordnung benannten notifizierten Stellen 
(1) Die Kommission weist den notifizierten Stelle jeweils eine Kennnummer zu. Selbst 
wenn eine Stelle nach mehreren Rechtsakten der Union notifiziert worden ist, erh&#228;lt 
sie nur eine einzige Kennnummer. 
(2) Die Kommission ver&#246;ffentlicht das Verzeichnis der nach dieser Verordnung 
notifizierten Stellen samt den ihnen zugewiesenen Kennnummern und den 
T&#228;tigkeiten, f&#252;r die sie notifiziert wurden. Die Kommission h&#228;lt das Verzeichnis stets 
auf dem neuesten Stand.
Artikel 36 
&#196;nderungen der Notifizierungen 
(1) Falls eine notifizierende Beh&#246;rde vermutet oder dar&#252;ber unterrichtet wird, dass eine 
notifizierte Stelle die in Artikel 33 festgelegten Anforderungen nicht mehr erf&#252;llt 
oder dass sie ihren Verpflichtungen nicht nachkommt, so untersucht die den 
Sachverhalt unverz&#252;glich und mit &#228;u&#223;erster Sorgfalt. In diesem Zusammenhang teilt 
sie der betreffenden notifizierten Stelle die erhobenen Einw&#228;nde mit und gibt ihr die
M&#246;glichkeit, dazu Stellung zu nehmen. Kommt die notifizierende Beh&#246;rde zu dem 
Schluss, dass die &#252;berpr&#252;fte notifizierte Stelle die in Artikel 33 festgelegten 
Anforderungen nicht mehr erf&#252;llt oder dass sie ihren Verpflichtungen nicht 
nachkommt, schr&#228;nkt sie die Notifizierung gegebenenfalls ein, setzt sie aus oder 
widerruft sie, wobei sie das Ausma&#223; der Nichterf&#252;llung oder Pflichtverletzung 
ber&#252;cksichtigt. Sie setzt zudem die Kommission und die &#252;brigen Mitgliedstaaten 
unverz&#252;glich davon in Kenntnis. 
(2) Wird die Notifizierung widerrufen, eingeschr&#228;nkt oder ausgesetzt oder stellt die 
notifizierte Stelle ihre T&#228;tigkeit ein, so ergreift die notifizierende Beh&#246;rde geeignete 
Ma&#223;nahmen, um sicherzustellen, dass die Akten dieser notifizierten Stelle von einer 
anderen notifizierten Stelle &#252;bernommen bzw. f&#252;r die zust&#228;ndigen notifizierenden 
Beh&#246;rden auf deren Verlangen bereitgehalten werden. 
Artikel 37 
Anfechtungen der Kompetenz notifizierter Stellen 
(1) Die Kommission untersucht erforderlichenfalls alle F&#228;lle, in denen begr&#252;ndete 
Zweifel daran bestehen, dass eine notifizierte Stelle die in Artikel 33 festgelegten 
Anforderungen erf&#252;llt. 
(2) Die notifizierende Beh&#246;rde stellt der Kommission auf Anfrage alle Informationen 
&#252;ber die Notifizierung der betreffenden notifizierten Stelle zur Verf&#252;gung. 
(3) Die Kommission stellt sicher, dass alle im Verlauf ihrer Untersuchungen gem&#228;&#223; 
diesem Artikel erlangten vertraulichen Informationen vertraulich behandelt werden. 
(4) Stellt die Kommission fest, dass eine notifizierte Stelle die in Artikel 33 festgelegten 
Anforderungen nicht oder nicht mehr erf&#252;llt, so erl&#228;sst sie einen begr&#252;ndeten 
Beschluss, in dem der notifizierende Mitgliedstaat aufgefordert wird, die 
erforderlichen Abhilfema&#223;nahmen zu treffen, einschlie&#223;lich eines Widerrufs der 
Notifizierung, sofern dies n&#246;tig ist. Dieser Durchf&#252;hrungsrechtsakt wird gem&#228;&#223; dem 
in Artikel 74 Absatz 2 genannten Pr&#252;fverfahren erlassen. 
Artikel 38 
Koordinierung der notifizierten Stellen 
(1) Die Kommission sorgt daf&#252;r, dass in den von dieser Verordnung erfassten Bereichen 
eine zweckm&#228;&#223;ige Koordinierung und Zusammenarbeit zwischen den an den 
Konformit&#228;tsbewertungsverfahren f&#252;r KI-Systeme im Rahmen dieser Verordnung 
beteiligten notifizierten Stellen in Form einer sektoralen Gruppe notifizierter Stellen 
eingerichtet und ordnungsgem&#228;&#223; weitergef&#252;hrt wird. 
(2) Die Mitgliedstaaten sorgen daf&#252;r, dass sich die von ihnen notifizierten Stellen direkt 
oder &#252;ber benannte Vertreter an der Arbeit dieser Gruppe beteiligen.
Artikel 39 
Konformit&#228;tsbewertungsstellen in Drittl&#228;ndern 
Konformit&#228;tsbewertungsstellen, die nach dem Recht eines Drittlandes errichtet wurden, mit 
dem die Union ein Abkommen geschlossen hat, k&#246;nnen erm&#228;chtigt werden, die T&#228;tigkeiten 
notifizierter Stellen gem&#228;&#223; dieser Verordnung durchzuf&#252;hren.
KAPITEL 5
NORMEN, KONFORMIT&#196;TSBEWERTUNG, BESCHEINIGUNGEN,
REGISTRIERUNG
Artikel 40 
Harmonisierte Normen
Bei Hochrisiko-KI-Systemen, die mit harmonisierten Normen oder Teilen davon, deren 
Fundstellen im Amtsblatt der Europ&#228;ischen Union ver&#246;ffentlicht wurden, &#252;bereinstimmen, 
wird eine Konformit&#228;t mit den Anforderungen in Kapitel 2 dieses Artikels vermutet, soweit 
diese Anforderungen von den Normen abgedeckt sind. 
Artikel 41 
Gemeinsame Spezifikationen 
(1) Gibt es keine harmonisierten Normen gem&#228;&#223; Artikel 40 oder ist die Kommission der 
Auffassung, dass die einschl&#228;gigen harmonisierten Normen unzureichend sind oder 
dass bestimmte Bedenken hinsichtlich der Sicherheit oder der Grundrechte 
ausger&#228;umt werden m&#252;ssen, so kann die Kommission im Wege von 
Durchf&#252;hrungsrechtsakten gemeinsame Spezifikationen f&#252;r die Anforderungen in 
Kapitel 2 dieses Titels festlegen. Diese Durchf&#252;hrungsrechtsakte werden gem&#228;&#223; dem 
in Artikel 74 Absatz 2 genannten Pr&#252;fverfahren erlassen. 
(2) Bei der Ausarbeitung der in Absatz 1 genannten gemeinsamen Spezifikationen holt 
die Kommission die Stellungnahmen der einschl&#228;gigen Stellen oder 
Expertengruppen ein, die nach den jeweiligen sektorspezifischen Rechtsvorschriften 
der Union eingerichtet wurden. 
(3) Bei Hochrisiko-KI-Systemen, die mit den in Absatz 1 genannten gemeinsamen 
Spezifikationen &#252;bereinstimmen, wird eine Konformit&#228;t mit den Anforderungen in 
Kapitel 2 dieses Artikels vermutet, soweit diese Anforderungen von den 
gemeinsamen Spezifikationen abgedeckt sind. 
(4) Wenn Anbieter die in Absatz 1 genannten gemeinsamen Spezifikationen nicht 
befolgen, m&#252;ssen sie hinreichend nachweisen, dass sie technische L&#246;sungen 
verwenden, die den gemeinsamen Spezifikationen zumindest gleichwertig sind. 
Artikel 42 
Vermutung der Konformit&#228;t mit gewissen Anforderungen 
(1) Unter Ber&#252;cksichtigung der Zweckbestimmung gilt f&#252;r Hochrisiko-KI-Systeme, die 
mit Daten zu den besonderen geografischen, verhaltensbezogenen und funktionalen 
Rahmenbedingungen, unter denen sie bestimmungsgem&#228;&#223; verwendet werden sollen, 
trainiert und getestet wurden, die Vermutung, dass sie die in Artikel 10 Absatz 4
festgelegte Anforderung erf&#252;llen. 
(2) F&#252;r Hochrisiko-KI-Systeme, die im Rahmen eines der
Cybersicherheitszertifizierungssysteme gem&#228;&#223; der Verordnung (EU) 2019/881 des
Europ&#228;ischen Parlaments und des Rates63, deren Fundstellen im Amtsblatt der 
Europ&#228;ischen Union ver&#246;ffentlicht wurden, zertifiziert wurden oder f&#252;r die eine 
solche Konformit&#228;tserkl&#228;rung erstellt wurde, gilt die Vermutung, dass sie die in 
Artikel 15 der vorliegenden Verordnung festgelegten Cybersicherheitsanforderungen 
erf&#252;llen, sofern diese Anforderungen von der Cybersicherheitszertifizierung oder der 
Konformit&#228;tserkl&#228;rung oder Teilen davon abdeckt sind. 
Artikel 43 
Konformit&#228;tsbewertung 
(1) Hat ein Anbieter zum Nachweis, dass sein in Anhang III Nummer 1 aufgef&#252;hrtes 
Hochrisiko-KI-System die Anforderungen in Kapitel 2 dieses Titels erf&#252;llt, 
harmonisierte Normen gem&#228;&#223; Artikel 40 oder gegebenenfalls gemeinsame 
Spezifikationen gem&#228;&#223; Artikel 41 angewandt, so befolgt er eines der folgenden 
Verfahren:
(a) das Konformit&#228;tsbewertungsverfahren auf der Grundlage einer internen 
Kontrolle gem&#228;&#223; Anhang VI; 
(b) das Konformit&#228;tsbewertungsverfahren auf der Grundlage der Bewertung des 
Qualit&#228;tsmanagementsystems und der Bewertung der technischen 
Dokumentation unter Beteiligung einer notifizierten Stelle gem&#228;&#223; Anhang VII. 
Hat ein Anbieter zum Nachweis, dass sein Hochrisiko-KI-System die Anforderungen 
in Kapitel 2 dieses Titels erf&#252;llt, die harmonisierten Normen gem&#228;&#223; Artikel 40 nicht 
oder nur teilweise angewandt oder gibt es solche harmonisierten Normen nicht und 
liegen keine gemeinsamen Spezifikationen gem&#228;&#223; Artikel 41 vor, so befolgt er das 
Konformit&#228;tsbewertungsverfahren gem&#228;&#223; Anhang VII. 
F&#252;r die Zwecke des Konformit&#228;tsbewertungsverfahrens gem&#228;&#223; Anhang VII kann der 
Anbieter eine der notifizierten Stellen ausw&#228;hlen. Soll das System jedoch von 
Strafverfolgungs-, Einwanderungs- oder Asylbeh&#246;rden oder von Organen, 
Einrichtungen oder sonstigen Stellen der EU in Betrieb genommen werden, so 
&#252;bernimmt die in Artikel 63 Absatz 5 oder 6 genannte Markt&#252;berwachungsbeh&#246;rde 
die Funktion der notifizierten Stelle. 
(2) Bei den in Anhang III Nummern 2 bis 8 aufgef&#252;hrten Hochrisiko-KI-Systemen 
befolgen die Anbieter das Konformit&#228;tsbewertungsverfahren auf der Grundlage einer 
internen Kontrolle gem&#228;&#223; Anhang VI, das keine Beteiligung einer notifizierten Stelle 
vorsieht. Bei den in Anhang III Nummer 5 Buchstabe b genannten Hochrisiko-KI-
Systemen, die von Kreditinstituten im Sinne der Richtlinie 2013/36/EU in Verkehr 
gebracht oder in Betrieb genommen werden, erfolgt die Konformit&#228;tsbewertung im 
Rahmen des in den Artikeln 97 bis 101 der Richtlinie genannten Verfahrens. 
(3) Bei den Hochrisiko-KI-Systemen, die unter die in Anhang II Abschnitt A 
aufgef&#252;hrten Rechtsakte fallen, befolgt der Anbieter die einschl&#228;gigen 
Konformit&#228;tsbewertungsverfahren, die nach diesen Rechtsakten erforderlich sind. 
Die Anforderungen in Kapitel 2 dieses Titels gelten f&#252;r diese Hochrisiko-KI-Systeme
63 Verordnung (EU) 2019/881 des Europ&#228;ischen Parlaments und des Rates vom 17. April 2019 &#252;ber die 
ENISA (Agentur der Europ&#228;ischen Union f&#252;r Cybersicherheit) und &#252;ber die Zertifizierung der 
Cybersicherheit von Informations- und Kommunikationstechnik und zur Aufhebung der Verordnung 
(EU) Nr. 526/2013 (Rechtsakt zur Cybersicherheit) (ABl. L 151 vom 7.6.2019, S. 15).
und werden in diese Bewertung einbezogen. Anhang VII Nummern 4.3, 4.4, 4.5 und 
Nummer 4.6 Absatz 5 finden ebenfalls Anwendung. 
F&#252;r die Zwecke dieser Bewertung sind die notifizierten Stellen, die gem&#228;&#223; diesen 
Rechtsakten benannt wurden, auch berechtigt, die Konformit&#228;t der Hochrisiko-KI-
Systeme mit den Anforderungen in Kapitel 2 dieses Titels zu kontrollieren, sofern im 
Rahmen des gem&#228;&#223; diesen Rechtsakten durchgef&#252;hrten Notifizierungsverfahrens 
gepr&#252;ft wurde, dass diese notifizierten Stellen die in Artikel 33 Abs&#228;tze 4, 9 und 10 
festgelegten Anforderungen erf&#252;llen. 
Wenn die in Anhang II Abschnitt A aufgef&#252;hrten Rechtsakte es dem Hersteller des 
Produkts erm&#246;glichen, auf eine Konformit&#228;tsbewertung durch Dritte zu verzichten, 
sofern dieser Hersteller alle harmonisierten Normen, die alle einschl&#228;gigen 
Anforderungen abdecken, angewandt hat, so darf dieser Hersteller nur dann von 
dieser M&#246;glichkeit Gebrauch machen, wenn er auch harmonisierte Normen oder 
gegebenenfalls gemeinsame Spezifikationen gem&#228;&#223; Artikel 41, die die 
Anforderungen in Kapitel 2 dieses Titels abdecken, angewandt hat. 
(4) Hochrisiko-KI-Systeme werden einem neuen Konformit&#228;tsbewertungsverfahren 
unterzogen, wenn sie wesentlich ge&#228;ndert werden, unabh&#228;ngig davon, ob das 
ge&#228;nderte System noch weiter in Verkehr gebracht oder vom derzeitigen Nutzer 
weitergenutzt werden soll. 
Bei Hochrisiko-KI-Systemen, die nach dem Inverkehrbringen oder der 
Inbetriebnahme weiterhin dazulernen, gelten &#196;nderungen des Hochrisiko-KI-
Systems und seiner Leistung, die vom Anbieter zum Zeitpunkt der urspr&#252;nglichen 
Konformit&#228;tsbewertung vorab festgelegt wurden und in den Informationen der 
technischen Dokumentation gem&#228;&#223; Anhang IV Nummer 2 Buchstabe f enthalten 
sind, nicht als wesentliche &#196;nderung. 
(5) Der Kommission wird die Befugnis &#252;bertragen, gem&#228;&#223; Artikel 73 delegierte 
Rechtsakte zur Aktualisierung der Anh&#228;nge VI und VII zu erlassen, um Elemente der 
Konformit&#228;tsbewertungsverfahren einzuf&#252;hren, die angesichts des technischen 
Fortschritts erforderlich werden. 
(6) Der Kommission wird die Befugnis &#252;bertragen, delegierte Rechtsakte zur &#196;nderung 
der Abs&#228;tze 1 und 2 zu erlassen, um die in Anhang III Nummern 2 bis 8 genannten 
Hochrisiko-KI-Systeme dem Konformit&#228;tsbewertungsverfahren gem&#228;&#223; Anhang VII 
oder Teilen davon zu unterwerfen. Die Kommission erl&#228;sst solche delegierten 
Rechtsakte unter Ber&#252;cksichtigung der Wirksamkeit des 
Konformit&#228;tsbewertungsverfahrens auf der Grundlage einer internen Kontrolle 
gem&#228;&#223; Anhang VI hinsichtlich der Vermeidung oder Minimierung der von solchen 
Systemen ausgehenden Risiken f&#252;r die Gesundheit und Sicherheit und den Schutz 
der Grundrechte sowie hinsichtlich der Verf&#252;gbarkeit angemessener Kapazit&#228;ten und 
Ressourcen in den notifizierten Stellen. 
Artikel 44 
Bescheinigungen 
(1) Die von notifizierten Stellen gem&#228;&#223; Anhang VII erteilten Bescheinigungen werden in 
einer Amtssprache der Union ausgefertigt, die der Mitgliedstaat, in dem die 
notifizierte Stelle niedergelassen ist, festlegt, oder in einer anderen Amtssprache der 
Union, mit der die notifizierte Stelle einverstanden ist.
(2) Die Bescheinigungen sind f&#252;r die darin genannte Dauer g&#252;ltig, die maximal f&#252;nf 
Jahre betr&#228;gt. Auf Antrag des Anbieters kann die G&#252;ltigkeit einer Bescheinigung auf 
der Grundlage einer Neubewertung gem&#228;&#223; den geltenden 
Konformit&#228;tsbewertungsverfahren um weitere Zeitr&#228;ume von jeweils h&#246;chstens f&#252;nf 
Jahren verl&#228;ngert werden. 
(3) Stellt eine notifizierte Stelle fest, dass ein KI-System die Anforderungen in Kapitel 2 
dieses Titels nicht mehr erf&#252;llt, setzt sie die erteilte Bescheinigung aus oder widerruft 
diese oder schr&#228;nkt sie ein, jeweils unter Ber&#252;cksichtigung des 
Verh&#228;ltnism&#228;&#223;igkeitsgrundsatzes, sofern die Einhaltung der Anforderungen nicht 
durch geeignete Korrekturma&#223;nahmen des Anbieters des Systems innerhalb einer 
von der notifizierten Stelle gesetzten angemessenen Frist wiederhergestellt wird. Die 
notifizierte Stelle begr&#252;ndet ihre Entscheidung.
Artikel 45 
Einspruch gegen Entscheidungen notifizierter Stellen 
Die Mitgliedstaaten stellen sicher, dass ein Einspruchsverfahren gegen die Entscheidungen 
der notifizierten Stelle f&#252;r Beteiligte vorgesehen ist, die ein berechtigtes Interesse an einer 
solchen Entscheidung haben. 
Artikel 46 
Meldepflichten der notifizierten Stellen 
(1) Die notifizierten Stellen melden der notifizierenden Beh&#246;rde 
a) alle Unionsbescheinigungen &#252;ber die Bewertung der technischen 
Dokumentation, etwaige Erg&#228;nzungen dieser Bescheinigungen und alle 
Genehmigungen von Qualit&#228;tsmanagementsystemen, die gem&#228;&#223; den 
Anforderungen des Anhangs VII erteilt wurden; 
b) alle Verweigerungen, Einschr&#228;nkungen, Aussetzungen oder R&#252;cknahmen von 
Unionsbescheinigungen &#252;ber die Bewertung der technischen Dokumentation 
oder Genehmigungen von Qualit&#228;tsmanagementsystemen, die gem&#228;&#223; den 
Anforderungen des Anhangs VII erteilt wurden; 
c) alle Umst&#228;nde, die Folgen f&#252;r den Anwendungsbereich oder die Bedingungen 
der Notifizierung haben; 
d) alle Auskunftsersuchen &#252;ber Konformit&#228;tsbewertungst&#228;tigkeiten, die sie von 
den Markt&#252;berwachungsbeh&#246;rden erhalten haben; 
e) auf Anfrage, die Konformit&#228;tsbewertungst&#228;tigkeiten, denen sie im 
Anwendungsbereich ihrer Notifizierung nachgegangen sind, und sonstige 
T&#228;tigkeiten, einschlie&#223;lich grenz&#252;berschreitender T&#228;tigkeiten und Vergabe von 
Unterauftr&#228;gen, die sie durchgef&#252;hrt haben. 
(2) Jede notifizierte Stelle unterrichtet die anderen notifizierten Stellen &#252;ber 
a) die Genehmigungen von Qualit&#228;tsmanagementsystemen, die sie verweigert, 
ausgesetzt oder zur&#252;ckgenommen hat, und auf Anfrage die Genehmigungen 
von Qualit&#228;tsmanagementsystemen, die sie erteilt hat; 
b) die EU-Bescheinigungen &#252;ber die Bewertung der technischen Dokumentation 
und deren etwaige Erg&#228;nzungen, die sie verweigert, ausgesetzt oder
zur&#252;ckgenommen oder anderweitig eingeschr&#228;nkt hat, und auf Anfrage die 
Bescheinigungen und/oder deren Erg&#228;nzungen, die sie ausgestellt hat. 
(3) Jede notifizierte Stelle &#252;bermittelt den anderen notifizierten Stellen, die &#228;hnlichen 
Konformit&#228;tsbewertungst&#228;tigkeiten f&#252;r die gleiche KI-Technik nachgehen, ihre 
einschl&#228;gigen Informationen &#252;ber negative und auf Anfrage auch &#252;ber positive 
Konformit&#228;tsbewertungsergebnisse.
Artikel 47 
Ausnahme vom Konformit&#228;tsbewertungsverfahren 
(1) Abweichend von Artikel 43 kann eine Markt&#252;berwachungsbeh&#246;rde das 
Inverkehrbringen oder die Inbetriebnahme bestimmter Hochrisiko-KI-Systeme im 
Hoheitsgebiet des betreffenden Mitgliedstaats aus au&#223;ergew&#246;hnlichen Gr&#252;nden der 
&#246;ffentlichen Sicherheit, des Schutzes des Lebens und der Gesundheit von Personen, 
des Umweltschutzes und des Schutzes wichtiger Industrie- und Infrastrukturanlagen 
genehmigen. Diese Genehmigung wird auf die Dauer der erforderlichen 
Konformit&#228;tsbewertungsverfahren befristet und l&#228;uft mit dem Abschluss dieser 
Verfahren aus. Der Abschluss dieser Verfahren erfolgt unverz&#252;glich. 
(2) Die in Absatz 1 genannte Genehmigung wird nur erteilt, wenn die 
Markt&#252;berwachungsbeh&#246;rde zu dem Schluss gelangt, dass das Hochrisiko-KI-
System die Anforderungen in Kapitel 2 dieses Titels erf&#252;llt. Die 
Markt&#252;berwachungsbeh&#246;rde unterrichtet die Kommission und die anderen 
Mitgliedstaaten &#252;ber alle von ihr gem&#228;&#223; Absatz 1 erteilten Genehmigungen. 
(3) Erhebt weder ein Mitgliedstaat noch die Kommission innerhalb von 
15 Kalendertagen nach Erhalt der in Absatz 2 genannten Mitteilung Einw&#228;nde gegen 
die von einer Markt&#252;berwachungsbeh&#246;rde eines Mitgliedstaats gem&#228;&#223; Absatz 1 
erteilte Genehmigung, so gilt diese Genehmigung als gerechtfertigt. 
(4) Erhebt innerhalb von 15 Kalendertagen nach Erhalt der in Absatz 2 genannten 
Mitteilung ein Mitgliedstaat Einw&#228;nde gegen eine von einer 
Markt&#252;berwachungsbeh&#246;rde eines anderen Mitgliedstaats erteilte Genehmigung oder 
ist die Kommission der Auffassung, dass die Genehmigung mit dem Unionsrecht 
unvereinbar ist oder dass die Schlussfolgerung der Mitgliedstaaten in Bezug auf die 
Konformit&#228;t des in Absatz 2 genannten Systems unbegr&#252;ndet ist, so nimmt die 
Kommission unverz&#252;glich Konsultationen mit dem betreffenden Mitgliedstaat auf; 
der bzw. die betroffenen Akteur(e) werden konsultiert und erhalten Gelegenheit, 
dazu Stellung zu nehmen. In Anbetracht dessen entscheidet die Kommission, ob die 
Genehmigung gerechtfertigt ist oder nicht. Die Kommission richtet ihren Beschluss 
an die betroffenen Mitgliedstaaten und an den/die betroffenen Akteur(e). 
(5) Wird die Genehmigung als ungerechtfertigt erachtet, so muss sie von der 
Markt&#252;berwachungsbeh&#246;rde des betreffenden Mitgliedstaats zur&#252;ckgenommen 
werden.
(6) Abweichend von den Abs&#228;tzen 1 bis 5 gelten f&#252;r Hochrisiko-KI-Systeme, die 
bestimmungsgem&#228;&#223; als Sicherheitskomponenten von Produkten verwendet werden 
sollen, die unter die Verordnung (EU) 2017/745 und die Verordnung (EU) 2017/746 
fallen, oder die selbst solche Produkte sind, die Ausnahmen gem&#228;&#223; Artikel 59 der 
Verordnung (EU) 2017/745 und Artikel 54 der Verordnung (EU) 2017/746 auch f&#252;r 
die Konformit&#228;tsbewertung hinsichtlich der Erf&#252;llung der Anforderungen in 
Kapitel 2 dieses Titels.
Artikel 48 
EU-Konformit&#228;tserkl&#228;rung 
(1) Der Anbieter stellt f&#252;r jedes KI-System eine schriftliche EU-Konformit&#228;tserkl&#228;rung 
aus und h&#228;lt sie f&#252;r einen Zeitraum von 10 Jahren ab dem Inverkehrbringen oder der 
Inbetriebnahme des KI-Systems f&#252;r die zust&#228;ndigen nationalen Beh&#246;rden bereit. Aus 
der EU-Konformit&#228;tserkl&#228;rung geht hervor, f&#252;r welches KI-System sie ausgestellt 
wurde. Ein Exemplar der EU-Konformit&#228;tserkl&#228;rung wird den zust&#228;ndigen 
nationalen Beh&#246;rden auf Anfrage zur Verf&#252;gung gestellt. 
(2) Die EU-Konformit&#228;tserkl&#228;rung besagt, dass das betreffende Hochrisiko-KI-System 
die Anforderungen in Kapitel 2 dieses Titels erf&#252;llt. Die EU-Konformit&#228;tserkl&#228;rung 
enth&#228;lt die in Anhang V aufgef&#252;hrten Angaben und wird in eine oder mehrere 
Amtssprachen der Union &#252;bersetzt, die von dem/den Mitgliedstaat(en) 
vorgeschrieben wird/werden, in dem/denen das Hochrisiko-KI-System bereitgestellt 
wird. 
(3) Unterliegen Hochrisiko-KI-Systeme noch anderen 
Harmonisierungsrechtsvorschriften der Union, die ebenfalls eine EU-
Konformit&#228;tserkl&#228;rung vorschreiben, so wird eine einzige EU-Konformit&#228;tserkl&#228;rung 
ausgestellt, die sich auf alle f&#252;r das Hochrisiko-KI-System geltenden 
Rechtsvorschriften der Union bezieht. Die Erkl&#228;rung enth&#228;lt alle erforderlichen 
Angaben zur Feststellung der Harmonisierungsrechtsvorschriften der Union, auf die 
sich die Erkl&#228;rung bezieht. 
(4) Mit der Ausstellung der EU-Konformit&#228;tserkl&#228;rung &#252;bernimmt der Anbieter die 
Verantwortung f&#252;r die Erf&#252;llung der Anforderungen in Kapitel 2 dieses Titels. Der 
Anbieter h&#228;lt die EU-Konformit&#228;tserkl&#228;rung gegebenenfalls auf dem neuesten Stand. 
(5) Der Kommission wird die Befugnis &#252;bertragen, gem&#228;&#223; Artikel 73 delegierte 
Rechtsakte zur &#196;nderung des in Anhang V festgelegten Inhalts der EU-
Konformit&#228;tserkl&#228;rung zu erlassen, um Elemente einzuf&#252;hren, die angesichts des 
technischen Fortschritts erforderlich werden.
Artikel 49 
CE-Konformit&#228;tskennzeichnung 
(1) Die CE-Kennzeichnung wird gut sichtbar, leserlich und dauerhaft an Hochrisiko-KI-
Systemen angebracht. Falls die Art des Hochrisiko-KI-Systems dies nicht zul&#228;sst 
oder nicht rechtfertigt, wird sie auf der Verpackung oder gegebenenfalls den 
Begleitunterlagen angebracht. 
(2) F&#252;r die in Absatz 1 dieses Artikels genannte CE-Kennzeichnung gelten die 
allgemeinen Grunds&#228;tze des Artikels 30 der Verordnung (EG) Nr. 765/2008. 
(3) Wo erforderlich, wird der CE-Kennzeichnung die Kennnummer der f&#252;r die 
Konformit&#228;tsbewertungsverfahren gem&#228;&#223; Artikel 43 zust&#228;ndigen notifizierten Stelle 
hinzugef&#252;gt. Diese Kennnummer wird auch auf jeglichem Werbematerial angegeben, 
in dem darauf hingewiesen wird, dass das Hochrisiko-KI-System die Anforderungen 
f&#252;r die CE-Kennzeichnung erf&#252;llt.
Artikel 50 
Aufbewahrung von Unterlagen 
Der Anbieter h&#228;lt f&#252;r einen Zeitraum von zehn Jahren ab dem Inverkehrbringen oder der 
Inbetriebnahme des Hochrisiko-KI-Systems folgende Unterlagen f&#252;r die zust&#228;ndigen 
nationalen Beh&#246;rden bereit:
a) die in Artikel 11 genannte technische Dokumentation, 
b) die Unterlagen zu dem in Artikel 17 genannten Qualit&#228;tsmanagementsystem, 
c) die Unterlagen &#252;ber etwaige von notifizierten Stellen genehmigte &#196;nderungen, 
d) die Entscheidungen und etwaigen sonstigen Dokumente der notifizierten Stellen, 
e) die in Artikel 48 genannte EU-Konformit&#228;tserkl&#228;rung.
Artikel 51 
Registrierung 
Vor dem Inverkehrbringen oder der Inbetriebnahme eines in Artikel 6 Absatz 2 genannten 
Hochrisiko-KI-Systems registriert der Anbieter oder gegebenenfalls sein Bevollm&#228;chtigter 
dieses System in der in Artikel 60 genannten EU-Datenbank. 
TITEL IV 
TRANSPARENZPFLICHTEN F&#220;R BESTIMMTE KI-SYSTEME 
Artikel 52 
Transparenzpflichten f&#252;r bestimmte KI-Systeme 
(1) Die Anbieter stellen sicher, dass KI-Systeme, die f&#252;r die Interaktion mit nat&#252;rlichen 
Personen bestimmt sind, so konzipiert und entwickelt werden, dass nat&#252;rlichen 
Personen mitgeteilt wird, dass sie es mit einem KI-System zu tun haben, es sei denn, 
dies ist aufgrund der Umst&#228;nde und des Kontexts der Nutzung offensichtlich. Diese 
Vorgabe gilt nicht f&#252;r gesetzlich zur Aufdeckung, Verh&#252;tung, Ermittlung und 
Verfolgung von Straftaten zugelassene KI-Systeme, es sei denn, diese Systeme 
stehen der &#214;ffentlichkeit zur Anzeige einer Straftat zur Verf&#252;gung. 
(2) Die Verwender eines Emotionserkennungssystems oder eines Systems zur 
biometrischen Kategorisierung informieren die davon betroffenen nat&#252;rlichen 
Personen &#252;ber den Betrieb des Systems. Diese Vorgabe gilt nicht f&#252;r gesetzlich zur 
Aufdeckung, Verh&#252;tung, Ermittlung und Verfolgung von Straftaten zugelassene KI-
Systeme, die zur biometrischen Kategorisierung verwendet werden. 
(3) Nutzer eines KI-Systems, das Bild-, Ton- oder Videoinhalte erzeugt oder 
manipuliert, die wirklichen Personen, Gegenst&#228;nden, Orten oder anderen 
Einrichtungen oder Ereignissen merklich &#228;hneln und einer Person f&#228;lschlicherweise 
als echt oder wahrhaftig erscheinen w&#252;rden (&#8222;Deepfake&#8220;), m&#252;ssen offenlegen, dass 
die Inhalte k&#252;nstlich erzeugt oder manipuliert wurden. 
Unterabsatz 1 gilt jedoch nicht, wenn die Verwendung zur Aufdeckung, Verh&#252;tung, 
Ermittlung und Verfolgung von Straftaten gesetzlich zugelassen oder f&#252;r die 
Aus&#252;bung der durch die Charta der Grundrechte der Europ&#228;ischen Union 
garantierten Rechte auf freie Meinungs&#228;u&#223;erung und auf Freiheit der Kunst und
Wissenschaft erforderlich ist und geeignete Schutzvorkehrungen f&#252;r die Rechte und 
Freiheiten Dritter bestehen. 
(4) Die Abs&#228;tze 1, 2 und 3 lassen die in Titel III dieser Verordnung festgelegten 
Anforderungen und Pflichten unber&#252;hrt. 
TITEL V
MA&#7838;NAHMEN ZUR INNOVATIONSF&#214;RDERUNG
Artikel 53 
KI-Reallabore
(1) KI-Reallabore, die von den zust&#228;ndigen Beh&#246;rden eines oder mehrerer 
Mitgliedstaaten oder vom Europ&#228;ischen Datenschutzbeauftragten eingerichtet 
werden, bieten eine kontrollierte Umgebung, um die Entwicklung, Erprobung und 
Validierung innovativer KI-Systeme f&#252;r einen begrenzten Zeitraum vor ihrem 
Inverkehrbringen oder ihrer Inbetriebnahme nach einem spezifischen Plan zu 
erleichtern. Dies geschieht unter direkter Aufsicht und Anleitung der zust&#228;ndigen 
Beh&#246;rden, um die Einhaltung der Anforderungen dieser Verordnung und 
gegebenenfalls anderer Rechtsvorschriften der Union und der Mitgliedstaaten, die 
innerhalb des Reallabors beaufsichtigt wird, sicherzustellen. 
(2) Soweit die innovativen KI-Systeme personenbezogene Daten verarbeiten oder 
anderweitig der Aufsicht anderer nationaler Beh&#246;rden oder zust&#228;ndiger Beh&#246;rden 
unterstehen, die den Zugang zu Daten gew&#228;hren oder unterst&#252;tzen, sorgen die 
Mitgliedstaaten daf&#252;r, dass die nationalen Datenschutzbeh&#246;rden und diese anderen 
nationalen Beh&#246;rden in den Betrieb des KI-Reallabors einbezogen werden. 
(3) Die KI-Reallabore lassen die Aufsichts- und Abhilfebefugnisse der zust&#228;ndigen 
Beh&#246;rden unber&#252;hrt. Alle erheblichen Risiken f&#252;r die Gesundheit und Sicherheit und 
die Grundrechte, die bei der Entwicklung und Erprobung solcher Systeme festgestellt 
werden, f&#252;hren zur sofortigen Risikominderung oder, falls dies nicht m&#246;glich ist, zur 
Aussetzung des Entwicklungs- und Erprobungsprozesses bis eine solche 
Risikominderung erfolgt ist. 
(4) Die am KI-Reallabor Beteiligten bleiben nach geltendem Recht der Union und der 
Mitgliedstaaten f&#252;r Sch&#228;den haftbar, die Dritten infolge der Erprobung im Reallabor 
entstehen.
(5) Die zust&#228;ndigen Beh&#246;rden der Mitgliedstaaten, die KI-Reallabore eingerichtet haben, 
koordinieren ihre T&#228;tigkeiten und arbeiten im Rahmen des Europ&#228;ischen 
Ausschusses f&#252;r k&#252;nstliche Intelligenz zusammen. Sie &#252;bermitteln dem Ausschuss 
und der Kommission j&#228;hrliche Berichte &#252;ber die Ergebnisse der Umsetzung dieser 
Systeme, einschlie&#223;lich bew&#228;hrter Verfahren, gewonnener Erkenntnisse und 
Empfehlungen zu deren Aufbau, sowie gegebenenfalls &#252;ber die Anwendung dieser 
Verordnung und anderer Rechtsvorschriften der Union, die innerhalb des Reallabors 
kontrolliert werden.
(6) Die Modalit&#228;ten und Bedingungen f&#252;r den Betrieb der KI-Reallabore, einschlie&#223;lich 
Genehmigungskriterien und Verfahren f&#252;r die Beantragung, Auswahl, Beteiligung 
und f&#252;r den Ausstieg aus dem Reallabor, sowie die Rechte und Pflichten der 
Beteiligten werden in Durchf&#252;hrungsrechtsakten festgelegt. Diese
Durchf&#252;hrungsrechtsakte werden gem&#228;&#223; dem in Artikel 74 Absatz 2 genannten 
Pr&#252;fverfahren erlassen.
Artikel 54 
Weiterverarbeitung personenbezogener Daten zur Entwicklung bestimmter KI-Systeme im 
&#246;ffentlichen Interesse im KI-Reallabor 
(1) Im KI-Reallabor d&#252;rfen personenbezogene Daten, die rechtm&#228;&#223;ig f&#252;r andere Zwecke 
erhoben wurden, zur Entwicklung und Erprobung bestimmter innovativer KI-
Systeme im Reallabor unter folgenden Bedingungen verarbeitet werden: 
a) die innovativen KI-Systeme werden entwickelt, um ein erhebliches &#246;ffentliches 
Interesse in einem oder mehreren der folgenden Bereiche zu wahren: 
i) Verh&#252;tung, Ermittlung, Aufdeckung oder Verfolgung von Straftaten oder 
Strafvollstreckung, einschlie&#223;lich des Schutzes vor und der Abwehr von 
Gefahren f&#252;r die &#246;ffentliche Sicherheit unter der Kontrolle und 
Verantwortung der zust&#228;ndigen Beh&#246;rden, wobei die Verarbeitung auf 
der Grundlage des Rechts der Mitgliedstaaten oder des Unionsrechts 
erfolgt, 
ii) &#246;ffentliche Sicherheit und &#246;ffentliche Gesundheit, einschlie&#223;lich 
Verh&#252;tung, Bek&#228;mpfung und Behandlung von Krankheiten, 
iii) hohes Umweltschutzniveau und Verbesserung der Umweltqualit&#228;t; 
b) die verarbeiteten Daten sind f&#252;r die Erf&#252;llung einer oder mehrerer der in 
Titel III Kapitel 2 genannten Anforderungen erforderlich, soweit diese 
Anforderungen durch die Verarbeitung anonymisierter, synthetischer oder 
sonstiger nicht personenbezogener Daten nicht wirksam erf&#252;llt werden k&#246;nnen; 
c) es bestehen wirksame &#220;berwachungsmechanismen, um festzustellen, ob 
w&#228;hrend der Erprobung im Reallabor hohe Risiken f&#252;r die Grundrechte der 
betroffenen Personen auftreten k&#246;nnen, sowie Reaktionsmechanismen, um 
diese Risiken umgehend zu mindern und erforderlichenfalls die Verarbeitung 
zu beenden; 
d) personenbezogene Daten, die im Rahmen des Reallabors verarbeitet werden 
sollen, befinden sich in einer funktional getrennten, isolierten und gesch&#252;tzten 
Datenverarbeitungsumgebung unter der Kontrolle der Beteiligten, und nur 
befugte Personen haben Zugriff auf diese Daten; 
e) es erfolgt keine &#220;bermittlung oder &#220;bertragung verarbeiteter 
personenbezogener Daten an Dritte und auch kein anderweitiger Zugriff Dritter 
auf diese Daten; 
f) eine Verarbeitung personenbezogener Daten im Rahmen des Reallabors f&#252;hrt 
zu keinen Ma&#223;nahmen oder Entscheidungen, die Auswirkungen auf die 
betroffenen Personen haben; 
g) personenbezogene Daten, die im Rahmen des Reallabors verarbeitet wurden, 
werden gel&#246;scht, sobald die Beteiligung an dem Reallabor beendet wird oder 
das Ende der Speicherfrist f&#252;r die personenbezogenen Daten erreicht ist; 
h) die Protokolle der Verarbeitung personenbezogener Daten im Rahmen des 
Reallabors werden f&#252;r die Dauer der Beteiligung am Reallabor und noch 1 Jahr 
nach deren Beendigung ausschlie&#223;lich zu dem Zweck und nur so lange
aufbewahrt, wie dies zur Erf&#252;llung der Rechenschafts- und 
Dokumentationspflichten nach diesem Artikel oder anderen anwendbaren 
Rechtsvorschriften der Union oder der Mitgliedstaaten erforderlich ist; 
i) eine vollst&#228;ndige und detaillierte Beschreibung des Prozesses und der Gr&#252;nde 
f&#252;r das Trainieren, Testen und Validieren des KI-Systems wird zusammen mit 
den Testergebnissen als Teil der technischen Dokumentation gem&#228;&#223; 
Anhang IV aufbewahrt; 
j) eine kurze Zusammenfassung des im KI-Reallabor entwickelten KI-Projekts, 
seiner Ziele und erwarteten Ergebnisse wird auf der Website der zust&#228;ndigen 
Beh&#246;rden ver&#246;ffentlicht. 
(2) Absatz 1 l&#228;sst die Rechtsvorschriften der Union oder der Mitgliedstaaten, die eine 
Verarbeitung f&#252;r andere als die in diesen Rechtsvorschriften ausdr&#252;cklich genannten 
Zwecke ausschlie&#223;en, unber&#252;hrt.
Artikel 55 
Ma&#223;nahmen f&#252;r Kleinanbieter und Kleinnutzer 
(1) Die Mitgliedstaaten ergreifen folgende Ma&#223;nahmen: 
a) Gew&#228;hrung eines vorrangigen Zugangs zu den KI-Reallaboren f&#252;r 
Kleinanbieter und Start-up-Unternehmen, soweit sie die entsprechenden 
Voraussetzungen erf&#252;llen; 
b) Durchf&#252;hrung besonderer Sensibilisierungsma&#223;nahmen f&#252;r die Anwendung 
dieser Verordnung, die auf die Bed&#252;rfnisse der Kleinanbieter und Kleinnutzer 
ausgerichtet sind; 
c) gegebenenfalls Einrichtung eines eigenen Kanals f&#252;r die Kommunikation mit 
Kleinanbietern, Kleinnutzern und anderen Innovatoren, um Orientierungen zu 
geben und Fragen zur Durchf&#252;hrung dieser Verordnung zu beantworten. 
(2) Bei der Festsetzung der Geb&#252;hren f&#252;r die Konformit&#228;tsbewertung gem&#228;&#223; Artikel 43 
werden die besonderen Interessen und Bed&#252;rfnisse von Kleinanbietern 
ber&#252;cksichtigt, indem diese Geb&#252;hren proportional zu ihrer Gr&#246;&#223;e und der Gr&#246;&#223;e 
ihres Marktes gesenkt werden.
TITEL VI 
LEITUNGSSTRUKTUR 
KAPITEL 1 
EUROP&#196;ISCHER AUSSCHUSS F&#220;R K&#220;NSTLICHE INTELLIGENZ
Artikel 56 
Einrichtung des Europ&#228;ischen Ausschusses f&#252;r k&#252;nstliche Intelligenz 
(1) Ein &#8222;Europ&#228;ischer Ausschuss f&#252;r k&#252;nstliche Intelligenz&#8220; (im Folgenden 
&#8222;Ausschuss&#8220;) wird eingerichtet. 
(2) Der Ausschuss ber&#228;t und unterst&#252;tzt die Kommission zu folgenden Zwecken:
a) Leisten eines Beitrags zur wirksamen Zusammenarbeit der nationalen 
Aufsichtsbeh&#246;rden und der Kommission in Angelegenheiten, die unter diese 
Verordnung fallen; 
b) Koordinierung und Mitwirkung an Leitlinien und Analysen der Kommission, 
der nationalen Aufsichtsbeh&#246;rden und anderer zust&#228;ndiger Beh&#246;rden zu neu 
auftretenden Fragen in Bezug auf Angelegenheiten, die unter diese Verordnung 
fallen, im gesamten Binnenmarkt; 
c) Unterst&#252;tzung der nationalen Aufsichtsbeh&#246;rden und der Kommission bei der 
Gew&#228;hrleistung der einheitlichen Anwendung dieser Verordnung.
Artikel 57 
Struktur des Ausschusses
(1) Der Ausschuss besteht aus den nationalen Aufsichtsbeh&#246;rden, vertreten durch ihren 
Leiter oder einen gleichwertigen hochrangigen Beamten der Beh&#246;rde, und dem 
Europ&#228;ischen Datenschutzbeauftragten. Weitere nationale Beh&#246;rden k&#246;nnen zu den 
Sitzungen eingeladen werden, wenn die er&#246;rterten Fragen f&#252;r sie von Belang sind. 
(2) Der Ausschuss gibt sich mit einfacher Mehrheit seiner Mitglieder und nach 
Zustimmung der Kommission eine Gesch&#228;ftsordnung. Die Gesch&#228;ftsordnung regelt 
auch die operativen Aspekte der Wahrnehmung der in Artikel 58 aufgef&#252;hrten 
Aufgaben des Ausschusses. Der Ausschuss kann gegebenenfalls Untergruppen zur 
Pr&#252;fung besonderer Fragen einsetzen. 
(3) Den Vorsitz im Ausschuss f&#252;hrt die Kommission. Die Kommission beruft die 
Sitzungen ein und bereitet die Tagesordnung im Einklang mit den Aufgaben des 
Ausschusses gem&#228;&#223; dieser Verordnung und seiner Gesch&#228;ftsordnung vor. Die 
Kommission leistet administrative und analytische Unterst&#252;tzung f&#252;r die T&#228;tigkeiten 
des Ausschusses gem&#228;&#223; dieser Verordnung. 
(4) Der Ausschuss kann externe Sachverst&#228;ndige und Beobachter zu seinen Sitzungen 
einladen und einen Meinungsaustausch mit interessierten Dritten f&#252;hren, um diesen 
in angemessenem Umfang in seine T&#228;tigkeiten einflie&#223;en zu lassen. Dazu kann die 
Kommission den Austausch zwischen dem Verwaltungsrat und anderen 
Einrichtungen, &#196;mtern, Agenturen und Beratungsgruppen der Union f&#246;rdern.
Artikel 58 
Aufgaben des Ausschusses 
Bei der Beratung und Unterst&#252;tzung der Kommission im Zusammenhang mit Artikel 56 
Absatz 2 hat der Ausschuss insbesondere folgende Aufgaben: 
a) Sammlung von Fachwissen und bew&#228;hrten Verfahren und deren Austausch zwischen 
den Mitgliedstaaten; 
b) Leisten eines Beitrags zu einer einheitlichen Verwaltungspraxis in den 
Mitgliedstaaten, auch bez&#252;glich der Funktionsweise der in Artikel 53 genannten KI-
Reallabore; 
c) Abgabe von Stellungnahmen, Empfehlungen oder schriftlichen Beitr&#228;gen zu Fragen 
im Zusammenhang mit der Durchf&#252;hrung dieser Verordnung, insbesondere 
i) &#252;ber technische Spezifikationen oder bestehende Normen in Bezug auf die in 
Titel III Kapitel 2 festgelegten Anforderungen,
ii) &#252;ber die Anwendung der in Artikel 40 genannten harmonisierten Normen oder 
der in Artikel 41 genannten gemeinsamen Spezifikationen, 
iii) &#252;ber die Ausarbeitung von Leitf&#228;den, einschlie&#223;lich der Leitlinien f&#252;r die 
Festsetzung von Geldbu&#223;en gem&#228;&#223; Artikel 71.
KAPITEL 2
ZUST&#196;NDIGE NATIONALE BEH&#214;RDEN
Artikel 59 
Benennung der zust&#228;ndigen nationalen Beh&#246;rden 
(1) Um die Anwendung und Durchf&#252;hrung dieser Verordnung sicherzustellen, werden 
von jedem Mitgliedstaat zust&#228;ndige nationale Beh&#246;rden eingerichtet oder benannt. 
Die notifizierenden Beh&#246;rden werden so organisiert, dass bei der Aus&#252;bung ihrer 
T&#228;tigkeiten und der Wahrnehmung ihrer Aufgaben Objektivit&#228;t und Unparteilichkeit 
gewahrt sind. 
(2) Jeder Mitgliedstaat benennt aus der Reihe der zust&#228;ndigen nationalen Beh&#246;rden eine 
nationale Aufsichtsbeh&#246;rde. Die nationale Aufsichtsbeh&#246;rde fungiert als 
notifizierende Beh&#246;rde und als Markt&#252;berwachungsbeh&#246;rde, es sei denn, der 
Mitgliedstaat hat organisatorische und administrative Gr&#252;nde, um mehr als eine 
Beh&#246;rde zu benennen.
(3) Die Mitgliedstaaten teilen der Kommission ihre Benennung oder Benennungen sowie 
gegebenenfalls ihre Gr&#252;nde f&#252;r die Benennung von mehr als einer Beh&#246;rde mit. 
(4) Die Mitgliedstaaten sorgen daf&#252;r, dass die zust&#228;ndigen nationalen Beh&#246;rden mit 
angemessenen finanziellen und personellen Ressourcen ausgestattet werden, damit 
sie ihre Aufgaben im Rahmen dieser Verordnung wahrnehmen k&#246;nnen. Insbesondere 
m&#252;ssen die zust&#228;ndigen nationalen Beh&#246;rden st&#228;ndig &#252;ber eine ausreichende Zahl 
von Mitarbeitern verf&#252;gen, deren Kompetenzen und Sachkenntnis ein tiefes 
Verst&#228;ndnis der Technologien der k&#252;nstlichen Intelligenz, der Daten und 
Datenverarbeitung, der Grundrechte, der Gesundheits- und Sicherheitsrisiken sowie 
die Kenntnis der bestehenden Normen und rechtlichen Anforderungen einschlie&#223;en. 
(5) Die Mitgliedstaaten &#252;bermitteln der Kommission j&#228;hrlich einen Bericht &#252;ber den 
Stand der finanziellen und personellen Ressourcen der zust&#228;ndigen nationalen 
Beh&#246;rden, in dem sie auch deren Angemessenheit bewerten. Die Kommission leitet 
diese Informationen an den Ausschuss zur Er&#246;rterung und etwaigen Abgabe von 
Empfehlungen weiter. 
(6) Die Kommission f&#246;rdert den Erfahrungsaustausch zwischen den zust&#228;ndigen 
nationalen Beh&#246;rden.
(7) Die zust&#228;ndigen nationalen Beh&#246;rden k&#246;nnen insbesondere auch Kleinanbietern mit 
Orientierung und Rat bei der Anwendung dieser Verordnung zur Seite stehen. Wenn 
zust&#228;ndige nationale Beh&#246;rden beabsichtigen, Orientierung und Rat in Bezug auf KI-
Systeme in Bereichen zu geben, die unter andere Rechtsvorschriften der Union 
fallen, so sind gegebenenfalls die nach jenen Unionsvorschriften daf&#252;r zust&#228;ndigen 
nationalen Beh&#246;rden zu konsultieren. Mitgliedstaaten k&#246;nnen auch eine zentrale 
Kontaktstelle f&#252;r die Kommunikation mit den Akteuren einrichten.
(8) Soweit Organe, Einrichtungen und sonstige Stellen der Union in den 
Anwendungsbereich dieser Verordnung fallen, &#252;bernimmt der Europ&#228;ische 
Datenschutzbeauftragte die Funktion der f&#252;r ihre Beaufsichtigung zust&#228;ndigen 
Beh&#246;rde.
TITEL VII
EU-DATENBANK F&#220;R EIGENST&#196;NDIGE HOCHRISIKO-KI-
SYSTEME 
Artikel 60 
EU-Datenbank f&#252;r eigenst&#228;ndige Hochrisiko-KI-Systeme 
(1) Die Kommission errichtet und pflegt in Zusammenarbeit mit den Mitgliedstaaten 
eine EU-Datenbank mit den in Absatz 2 genannten Informationen &#252;ber Hochrisiko-
KI-Systeme nach Artikel 6 Absatz 2, die gem&#228;&#223; Artikel 51 registriert werden. 
(2) Die in Anhang VIII aufgef&#252;hrten Daten werden von den Anbietern in die EU-
Datenbank eingegeben. Die Kommission leistet ihnen dabei technische und 
administrative Unterst&#252;tzung. 
(3) Die in der EU-Datenbank gespeicherten Daten sind &#246;ffentlich zug&#228;nglich. 
(4) Die EU-Datenbank enth&#228;lt personenbezogene Daten nur, soweit dies f&#252;r die 
Erfassung und Verarbeitung von Informationen gem&#228;&#223; dieser Verordnung 
erforderlich ist. Zu diesen Informationen geh&#246;ren die Namen und Kontaktdaten der 
nat&#252;rlichen Personen, die f&#252;r die Registrierung des Systems verantwortlich sind und 
die rechtlich befugt sind, den Anbieter zu vertreten. 
(5) Die Kommission gilt bez&#252;glich der EU-Datenbank als die f&#252;r die Verarbeitung 
verantwortliche Stelle. Sie sorgt auch f&#252;r eine angemessene technische und 
administrative Unterst&#252;tzung der Anbieter.
TITEL VIII
BEOBACHTUNG NACH DEM INVERKEHRBRINGEN,
INFORMATIONSAUSTAUSCH, MARKT&#220;BERWACHUNG 
KAPITEL 1
BEOBACHTUNG NACH DEM INVERKEHRBRINGEN
Artikel 61 
Beobachtung nach dem Inverkehrbringen durch die Anbieter und Plan f&#252;r die Beobachtung 
nach dem Inverkehrbringen f&#252;r Hochrisiko-KI-Systeme 
(1) Anbieter m&#252;ssen ein System zur Beobachtung nach dem Inverkehrbringen einrichten 
und dokumentieren, das im Verh&#228;ltnis zur Art der KI-Technik und zu den Risiken 
des Hochrisiko-KI-Systems steht. 
(2) Mit dem System zur Beobachtung nach dem Inverkehrbringen m&#252;ssen sich die 
einschl&#228;gigen von den Nutzern bereitgestellten oder aus anderen Quellen
gesammelten Daten zur Leistung der Hochrisiko-KI-Systeme &#252;ber deren gesamte 
Lebensdauer hinweg aktiv und systematisch erfassen, dokumentieren und analysieren 
lassen, und der Anbieter muss damit die fortdauernde Einhaltung der in Titel III 
Kapitel 2 genannten Anforderungen an die KI-Systeme bewerten k&#246;nnen. 
(3) Das System zur Beobachtung nach dem Inverkehrbringen muss auf einem 
entsprechenden Plan beruhen. Der Plan f&#252;r die Beobachtung nach dem 
Inverkehrbringen ist Teil der in Anhang IV genannten technischen Dokumentation. 
Die Kommission erl&#228;sst einen Durchf&#252;hrungsrechtsakt, in dem sie die 
Bestimmungen f&#252;r die Erstellung eines Musters des Plans f&#252;r die Beobachtung nach 
dem Inverkehrbringen sowie die Liste der in den Plan aufzunehmenden Elemente 
detailliert festlegt. 
(4) Bei Hochrisiko-KI-Systemen, die unter die in Anhang II genannten Rechtsakte fallen 
und f&#252;r die auf der Grundlage dieser Rechtsakte bereits ein System zur Beobachtung 
nach dem Inverkehrbringen sowie ein entsprechender Plan festgelegt wurden, 
m&#252;ssen die in den Abs&#228;tzen 1, 2 und 3 genannten Elemente gegebenenfalls in dieses 
System bzw. in diesen Plan aufgenommen werden. 
Unterabsatz 1 gilt auch f&#252;r Hochrisiko-KI-Systeme nach Anhang III Nummer 5 
Buchstabe b, die von Kreditinstituten im Sinne der Richtlinie 2013/36/EU in Verkehr 
gebracht oder in Betrieb genommen wurden.
KAPITEL 2
AUSTAUSCH VON INFORMATIONEN &#220;BER VORF&#196;LLE UND FEHLFUNKTIONEN
Artikel 62 
Meldung schwerwiegender Vorf&#228;lle und Fehlfunktionen 
(1) Anbieter von in der Union in Verkehr gebrachten Hochrisiko-KI-Systemen, melden 
schwerwiegende Vorf&#228;lle oder Fehlfunktionen dieser Systeme, die einen Versto&#223; 
gegen die Bestimmungen des Unionsrechts zum Schutz der Grundrechte darstellen, 
den Markt&#252;berwachungsbeh&#246;rden des Mitgliedstaats, in dem der Vorfall oder der 
Versto&#223; stattgefunden hat. 
Diese Meldung erfolgt unmittelbar, nachdem der Anbieter den kausalen 
Zusammenhang zwischen dem KI-System und dem Vorfall bzw. der Fehlfunktion 
oder die naheliegende Wahrscheinlichkeit eines solchen Zusammenhangs festgestellt 
hat, oder auf jeden Fall sp&#228;testens 15 Tage, nachdem der Anbieter Kenntnis von 
diesem schwerwiegenden Vorfall oder der Fehlfunktion erlangt hat. 
(2) Sobald die Markt&#252;berwachungsbeh&#246;rde eine Meldung &#252;ber einen Versto&#223; gegen die 
Bestimmungen des Unionsrechts zum Schutz der Grundrechte erh&#228;lt, unterrichtet sie 
die in Artikel 64 Absatz 3 genannten nationalen Beh&#246;rden oder &#246;ffentlichen Stellen. 
Zur leichteren Einhaltung der Pflichten nach Absatz 1 arbeitet die Kommission 
entsprechende Leitlinien aus. Diese Leitlinien werden sp&#228;testens 12 Monate nach 
dem Inkrafttreten dieser Verordnung ver&#246;ffentlicht. 
(3) Bei Hochrisiko-KI-Systemen nach Anhang III Nummer 5 Buchstabe b, die von 
Kreditinstituten im Sinne der Richtlinie 2013/36/EU in Verkehr gebracht oder in 
Betrieb genommen wurden, sowie bei Hochrisiko-KI-Systemen, bei denen es sich 
um Sicherheitskomponenten von Produkten handelt, die unter die Verordnung 
(EU) 2017/745 und die Verordnung (EU) 2017/746 fallen, oder die selbst solche
Produkte sind, m&#252;ssen nur jene schwerwiegenden Vorf&#228;lle oder Fehlfunktionen 
gemeldet werden, die einen Versto&#223; gegen die Bestimmungen des Unionsrechts zum 
Schutz der Grundrechte darstellen.
KAPITEL 3
DURCHSETZUNG
Artikel 63 
Markt&#252;berwachung und Kontrolle von KI-Systemen auf dem Unionsmarkt 
(1) Die Verordnung (EU) 2019/1020 gilt f&#252;r KI-Systeme, die unter diese Verordnung 
fallen. F&#252;r die Zwecke einer wirksamen Durchsetzung dieser Verordnung gilt jedoch 
Folgendes: 
a) Jede Bezugnahme auf einen Wirtschaftsakteur nach der Verordnung 
(EU) 2019/1020 gilt auch als Bezugnahme auf alle Akteure, die in Titel III 
Kapitel 3 dieser Verordnung genannt werden. 
b) Jede Bezugnahme auf ein Produkt nach der Verordnung (EU) 2019/1020 gilt 
auch als Bezugnahme auf alle KI-Systeme, die unter diese Verordnung fallen. 
(2) Die nationale Aufsichtsbeh&#246;rde erstattet der Kommission regelm&#228;&#223;ig &#252;ber die 
Ergebnisse ihrer jeweiligen Markt&#252;berwachungst&#228;tigkeiten Bericht. Die nationale 
Aufsichtsbeh&#246;rde meldet der Kommission und den einschl&#228;gigen nationalen 
Wettbewerbsbeh&#246;rden unverz&#252;glich alle Informationen, die sie im Verlauf ihrer 
Markt&#252;berwachungst&#228;tigkeiten erlangt hat und die f&#252;r die Anwendung von 
Unionsrecht auf Wettbewerbsregeln von Interesse sein k&#246;nnten. 
(3) Bei Hochrisiko-KI-Systemen und damit in Zusammenhang stehenden Produkten, auf 
die die in Anhang II Abschnitt A aufgef&#252;hrten Rechtsakte Anwendung finden, gilt 
als Markt&#252;berwachungsbeh&#246;rde f&#252;r die Zwecke dieser Verordnung die in jenen 
Rechtsakten f&#252;r die Markt&#252;berwachung benannte Beh&#246;rde. 
(4) Bei KI-Systemen, die von auf der Grundlage des Finanzdienstleistungsrechts der 
Union regulierten Finanzinstituten in Verkehr gebracht, in Betrieb genommen oder 
eingesetzt werden, gilt als Markt&#252;berwachungsbeh&#246;rde f&#252;r die Zwecke dieser 
Verordnung die in jenen Rechtsvorschriften f&#252;r die Finanzaufsicht &#252;ber diese 
Institute benannte Beh&#246;rde. 
(5) F&#252;r die in Absatz 1 Buchstabe a genannten KI-Systeme, sofern diese Systeme f&#252;r 
Strafverfolgungszwecke nach Anhang III Nummern 6 und 7 eingesetzt werden, 
benennen die Mitgliedstaaten f&#252;r die Zwecke dieser Verordnung als 
Markt&#252;berwachungsbeh&#246;rden entweder die f&#252;r den Datenschutz nach der Richtlinie 
(EU) 2016/680 oder der Verordnung (EU) 2016/679 zust&#228;ndigen Aufsichtsbeh&#246;rden 
oder die zust&#228;ndigen nationalen Beh&#246;rden, die die T&#228;tigkeiten der Beh&#246;rden im 
Bereich der Strafverfolgung, Einwanderung oder Asyl, die solche Systeme in 
Verkehr bringen oder einsetzen, beaufsichtigen. 
(6) Soweit Organe, Einrichtungen und sonstige Stellen der Union in den 
Anwendungsbereich dieser Verordnung fallen, &#252;bernimmt der Europ&#228;ische 
Datenschutzbeauftragte die Funktion der f&#252;r sie zust&#228;ndigen 
Markt&#252;berwachungsbeh&#246;rde.
(7) Die Mitgliedstaaten erleichtern die Koordinierung zwischen den auf der Grundlage 
dieser Verordnung benannten Markt&#252;berwachungsbeh&#246;rden und anderen 
einschl&#228;gigen nationalen Beh&#246;rden oder Stellen, die die Anwendung der in 
Anhang II aufgef&#252;hrten Harmonisierungsrechtsvorschriften der Union oder sonstigen 
Unionsrechts &#252;berwachen, das f&#252;r die in Anhang III aufgef&#252;hrten Hochrisiko-KI-
Systeme relevant sein k&#246;nnte. 
Artikel 64 
Zugang zu Daten und zur Dokumentation 
(1) Im Zusammenhang mit ihren T&#228;tigkeiten erhalten die Markt&#252;berwachungsbeh&#246;rden 
uneingeschr&#228;nkten Zugang zu den von den Anbietern genutzten Trainings-, 
Validierungs- und Testdatens&#228;tzen, auch &#252;ber 
Anwendungsprogrammierschnittstellen (API) oder sonstige f&#252;r den Fernzugriff 
geeignete technische Mittel und Instrumente. 
(2) Sofern dies f&#252;r die Bewertung der Konformit&#228;t der Hochrisiko-KI-Systeme mit den 
in Titel III Kapitel 2 festgelegten Anforderungen notwendig ist, wird der 
Markt&#252;berwachungsbeh&#246;rde auf deren begr&#252;ndetes Verlangen Zugang zum 
Quellcode des KI-Systems gew&#228;hrt. 
(3) Nationale Beh&#246;rden oder &#246;ffentliche Stellen, die die Einhaltung des Unionsrechts 
zum Schutz der Grundrechte in Bezug auf den Einsatz der in Anhang III 
aufgef&#252;hrten Hochrisiko-KI-Systeme &#252;berwachen oder durchsetzen, sind befugt, alle 
auf der Grundlage dieser Verordnung erstellten oder gef&#252;hrten Unterlagen 
anzufordern und einzusehen, sofern der Zugang zu diesen Unterlagen f&#252;r die 
Aus&#252;bung ihres Auftrags im Rahmen ihrer Befugnisse notwendig ist. Die jeweilige 
Beh&#246;rde oder &#246;ffentliche Stelle unterrichtet die Markt&#252;berwachungsbeh&#246;rde des 
betreffenden Mitgliedstaats von jedem diesbez&#252;glichen Verlangen. 
(4) Bis drei Monate nach dem Inkrafttreten dieser Verordnung muss jeder Mitgliedstaat 
die in Absatz 3 genannten Beh&#246;rden oder &#246;ffentlichen Stellen benannt haben und 
deren Liste auf einer &#246;ffentlich zug&#228;nglichen Website der nationalen 
Aufsichtsbeh&#246;rde ver&#246;ffentlichen. Die Mitgliedstaaten &#252;bermitteln die Liste der 
Kommission und allen anderen Mitgliedstaaten und sorgen daf&#252;r, dass die Liste stets 
aktuell bleibt. 
(5) Sollte die in Absatz 3 genannte Dokumentation nicht ausreichen, um feststellen zu 
k&#246;nnen, ob ein Versto&#223; gegen das Unionsrecht zum Schutz der Grundrechte vorliegt, 
kann die in Absatz 3 genannte Beh&#246;rde oder &#246;ffentliche Stelle bei der 
Markt&#252;berwachungsbeh&#246;rde einen begr&#252;ndeten Antrag auf Durchf&#252;hrung 
technischer Tests des Hochrisiko-KI-Systems stellen. Die 
Markt&#252;berwachungsbeh&#246;rde f&#252;hrt den Test unter enger Einbeziehung der 
beantragenden Beh&#246;rde oder &#246;ffentlichen Stelle innerhalb eines angemessenen 
Zeitraums nach Eingang des Antrags durch. 
(6) Alle Informationen und Unterlagen, in deren Besitz eine in Absatz 3 genannte 
nationale Beh&#246;rde oder &#246;ffentliche Stelle auf der Grundlage dieses Artikels gelangt, 
werden im Einklang mit den in Artikel 70 festgelegten Vertraulichkeitspflichten 
behandelt.
Artikel 65 
Verfahren f&#252;r den Umgang mit KI-Systemen, die ein Risiko auf nationaler Ebene bergen 
(1) Als KI-Systeme, die ein Risiko bergen, gelten Produkte, mit denen ein Risiko im 
Sinne des Artikels 3 Nummer 19 der Verordnung (EU) 2019/1020 verbunden ist, 
sofern es sich dabei um Risiken f&#252;r die Gesundheit oder Sicherheit oder den Schutz 
der Grundrechte von Personen handelt.
(2) Hat die Markt&#252;berwachungsbeh&#246;rde eines Mitgliedstaats hinreichende Gr&#252;nde zu der 
Annahme, dass ein KI-System ein Risiko im Sinne des Absatzes 1 birgt, pr&#252;ft sie das 
betreffende KI-System im Hinblick auf die Erf&#252;llung aller in dieser Verordnung 
festgelegten Anforderungen und Pflichten. Bestehen Risiken f&#252;r den Schutz von 
Grundrechten, unterrichtet die Markt&#252;berwachungsbeh&#246;rde auch die in Artikel 64 
Absatz 3 genannten einschl&#228;gigen nationalen Beh&#246;rden oder &#246;ffentlichen Stellen. 
Die betreffenden Akteure m&#252;ssen im notwendigen Umfang mit den 
Markt&#252;berwachungsbeh&#246;rden und den in Artikel 64 Absatz 3 genannten anderen 
Beh&#246;rden oder &#246;ffentlichen Stellen zusammenarbeiten. 
Stellt die Markt&#252;berwachungsbeh&#246;rde im Verlauf dieser Pr&#252;fung fest, dass das KI-
System die in dieser Verordnung festgelegten Anforderungen und Pflichten nicht 
erf&#252;llt, fordert sie den betreffenden Akteur unverz&#252;glich auf, alle von ihr 
m&#246;glicherweise vorgegebenen Korrekturma&#223;nahmen zu ergreifen, die geeignet sind, 
die Konformit&#228;t des KI-Systems wiederherzustellen, das KI-System vom Markt zu 
nehmen oder es innerhalb einer der Art des Risikos angemessenen Frist 
zur&#252;ckzurufen. 
Die Markt&#252;berwachungsbeh&#246;rde unterrichtet die betreffende notifizierte Stelle 
entsprechend. Artikel 18 der Verordnung (EU) 2019/1020 gilt f&#252;r die in 
Unterabsatz 2 genannten Ma&#223;nahmen. 
(3) Gelangt die Markt&#252;berwachungsbeh&#246;rde zu der Auffassung, dass die 
Nichtkonformit&#228;t nicht auf ihr nationales Hoheitsgebiet beschr&#228;nkt ist, unterrichtet 
sie die Kommission und die anderen Mitgliedstaaten &#252;ber die Ergebnisse der Pr&#252;fung 
und &#252;ber die Ma&#223;nahmen, zu denen sie den Akteur aufgefordert hat. 
(4) Der Akteur sorgt daf&#252;r, dass alle geeigneten Korrekturma&#223;nahmen in Bezug auf die 
betreffenden KI-Systeme, die er in der Union in Verkehr gebracht hat, getroffen 
werden.
(5) Ergreift der Akteur in Bezug auf sein KI-System keine geeigneten 
Korrekturma&#223;nahmen innerhalb der in Absatz 2 genannten Frist, trifft die 
Markt&#252;berwachungsbeh&#246;rde alle geeigneten vorl&#228;ufigen Ma&#223;nahmen, um die 
Bereitstellung des KI-Systems auf ihrem nationalen Markt zu verbieten oder 
einzuschr&#228;nken, das Produkt von diesem Markt zu nehmen oder es zur&#252;ckzurufen. 
Diese Beh&#246;rde unterrichtet die Kommission und die anderen Mitgliedstaaten 
unverz&#252;glich &#252;ber diese Ma&#223;nahmen. 
(6) Die Unterrichtung nach Absatz 5 enth&#228;lt alle vorliegenden Angaben, insbesondere 
die f&#252;r die Identifizierung des nicht konformen Systems notwendigen Daten, den 
Ursprung des KI-Systems, die Art der vermuteten Nichtkonformit&#228;t und das sich 
daraus ergebende Risiko, die Art und Dauer der ergriffenen nationalen Ma&#223;nahmen 
und die von dem betreffenden Akteur vorgebrachten Argumente. Die 
Markt&#252;berwachungsbeh&#246;rden geben insbesondere an, ob die Nichtkonformit&#228;t eine 
oder mehrere der folgenden Ursachen hat:
a) Nichterf&#252;llung der in Titel III Kapitel 2 aufgef&#252;hrten Anforderungen durch das 
KI-System; 
b) M&#228;ngel in den in den Artikeln 40 und 41 genannten harmonisierten Normen 
oder gemeinsamen Spezifikationen, die eine Konformit&#228;tsvermutung 
begr&#252;nden. 
(7) Die anderen Markt&#252;berwachungsbeh&#246;rden, die kein Verfahren eingeleitet haben, 
unterrichten unverz&#252;glich die Kommission und die anderen Mitgliedstaaten von 
jeglichen Ma&#223;nahmen und etwaigen ihnen vorliegenden zus&#228;tzlichen Erkenntnissen 
&#252;ber die Nichtkonformit&#228;t des betreffenden KI-Systems sowie &#252;ber ihre Einw&#228;nde, 
falls sie die ihnen mitgeteilt nationale Ma&#223;nahme ablehnen. 
(8) Erhebt weder ein Mitgliedstaat noch die Kommission innerhalb von drei Monaten 
nach Eingang der in Absatz 5 genannten Unterrichtung Einw&#228;nde gegen die von 
einem Mitgliedstaat erlassene vorl&#228;ufige Ma&#223;nahme, so gilt diese Ma&#223;nahme als 
gerechtfertigt. Die Verfahrensrechte des betreffenden Akteurs nach Artikel 18 der 
Verordnung (EU) 2019/1020 bleiben hiervon unber&#252;hrt. 
(9) Die Markt&#252;berwachungsbeh&#246;rden aller Mitgliedstaaten tragen daf&#252;r Sorge, dass 
geeignete einschr&#228;nkende Ma&#223;nahmen in Bezug auf das betreffende Produkt 
ergriffen werden, indem sie beispielsweise das Produkt unverz&#252;glich von ihrem 
Markt nehmen.
Artikel 66 
Schutzklauselverfahren der Union 
(1) Erhebt ein Mitgliedstaat innerhalb von drei Monaten nach Eingang der in Artikel 65 
Absatz 5 genannten Unterrichtung Einw&#228;nde gegen eine von einem anderen 
Mitgliedstaat getroffene Ma&#223;nahme oder ist die Kommission der Ansicht, dass die 
Ma&#223;nahme mit dem Unionsrecht unvereinbar ist, so nimmt die Kommission 
unverz&#252;glich Konsultationen mit dem betreffenden Mitgliedstaat oder Akteur auf 
und pr&#252;ft die nationale Ma&#223;nahme. Anhand der Ergebnisse dieser Pr&#252;fung 
entscheidet die Kommission innerhalb von neun Monaten nach Eingang der in 
Artikel 65 Absatz 5 genannten Unterrichtung, ob die nationale Ma&#223;nahme 
gerechtfertigt ist oder nicht und teilt dem betreffenden Mitgliedstaat ihre 
Entscheidung mit. 
(2) Gilt die nationale Ma&#223;nahme als gerechtfertigt, so ergreifen alle Mitgliedstaaten die 
erforderlichen Ma&#223;nahmen, damit das nichtkonforme KI-System von ihrem Markt 
genommen wird, und unterrichten die Kommission dar&#252;ber. Gilt die nationale 
Ma&#223;nahme als nicht gerechtfertigt, nimmt der betreffende Mitgliedstaat die 
Ma&#223;nahme zur&#252;ck.
(3) Gilt die nationale Ma&#223;nahme als gerechtfertigt und wird die Nichtkonformit&#228;t des 
KI-Systems auf M&#228;ngel in den in den Artikeln 40 und 41 dieser Verordnung 
genannten harmonisierten Normen oder gemeinsamen Spezifikationen 
zur&#252;ckgef&#252;hrt, so leitet die Kommission das in Artikel 11 der Verordnung (EU) 
Nr. 1025/2012 festgelegte Verfahren ein.
Artikel 67 
Konforme KI-Systeme, die ein Risiko bergen 
(1) Stellt die Markt&#252;berwachungsbeh&#246;rde nach der gem&#228;&#223; Artikel 65 durchgef&#252;hrten 
Pr&#252;fung fest, dass ein KI-System dieser Verordnung entspricht, jedoch trotzdem ein 
Risiko f&#252;r die Gesundheit oder Sicherheit von Personen, f&#252;r die Einhaltung der 
Pflichten aus dem Unionsrecht oder dem nationalen Recht zum Schutz der 
Grundrechte oder f&#252;r andere Aspekte des Schutzes &#246;ffentlicher Interessen darstellt, 
fordert sie den betreffenden Akteur auf, alle geeigneten und von ihr m&#246;glicherweise 
vorgegebenen Ma&#223;nahmen zu treffen, damit das betreffende KI-System zum 
Zeitpunkt des Inverkehrbringens oder der Inbetriebnahme dieses Risiko nicht mehr 
birgt, oder das KI-System vom Markt zu nehmen oder es innerhalb einer der Art des 
Risikos angemessenen Frist zur&#252;ckzurufen. 
(2) Der Anbieter oder andere einschl&#228;gige Akteure m&#252;ssen daf&#252;r sorgen, dass in Bezug 
auf alle betroffenen KI-Systeme, die sie in der Union in Verkehr gebracht haben, 
innerhalb der Frist, die von der Markt&#252;berwachungsbeh&#246;rde des in Absatz 1 
genannten Mitgliedstaats vorgegeben wurde, Korrekturma&#223;nahmen ergriffen werden. 
(3) Der Mitgliedstaat unterrichtet die Kommission und die &#252;brigen Mitgliedstaaten 
unverz&#252;glich davon. Diese Unterrichtung enth&#228;lt alle vorliegenden Angaben, 
insbesondere die f&#252;r die Identifizierung des betreffenden KI-Systems notwendigen 
Daten, den Ursprung und die Lieferkette des KI-Systems, die Art des sich daraus 
ergebenden Risikos sowie die Art und Dauer der ergriffenen nationalen Ma&#223;nahmen. 
(4) Die Kommission nimmt unverz&#252;glich mit den Mitgliedstaaten und den betreffenden 
Akteuren Konsultationen auf und pr&#252;ft die ergriffenen nationalen Ma&#223;nahmen. 
Anhand der Ergebnisse dieser Pr&#252;fung entscheidet die Kommission, ob die 
Ma&#223;nahme gerechtfertigt ist oder nicht, und schl&#228;gt, falls erforderlich, geeignete 
Ma&#223;nahmen vor.
(5) Die Kommission richtet diese Entscheidung an die Mitgliedstaaten.
Artikel 68 
Formale Nichtkonformit&#228;t 
(1) Gelangt die Markt&#252;berwachungsbeh&#246;rde eines Mitgliedstaats zu einer der folgenden 
Feststellungen, fordert sie den jeweiligen Anbieter auf, die betreffende 
Nichtkonformit&#228;t zu beheben:
a) die Konformit&#228;tskennzeichnung wurde nicht nach Artikel 49 angebracht; 
b) die Konformit&#228;tskennzeichnung wurde nicht angebracht; 
c) die EU-Konformit&#228;tserkl&#228;rung wurde nicht ausgestellt; 
d) die EU-Konformit&#228;tserkl&#228;rung wurde nicht ordnungsgem&#228;&#223; ausgestellt; 
e) die Kennnummer der gegebenenfalls am Konformit&#228;tsbewertungsverfahren 
beteiligten notifizierten Stelle wurde nicht angebracht. 
(2) Besteht die Nichtkonformit&#228;t nach Absatz 1 weiter, so ergreift der betreffende 
Mitgliedstaat alle geeigneten Ma&#223;nahmen, um die Bereitstellung des Hochrisiko-KI-
Systems auf dem Markt zu beschr&#228;nken oder zu untersagen oder um daf&#252;r zu sorgen, 
dass es zur&#252;ckgerufen oder vom Markt genommen wird.
TITEL IX
VERHALTENSKODIZES
Artikel 69 
Verhaltenskodizes
(1) Die Kommission und die Mitgliedstaaten f&#246;rdern und erleichtern die Aufstellung von 
Verhaltenskodizes, mit denen erreicht werden soll, dass die in Titel III Kapitel 2 
genannten Anforderungen auf KI-Systeme Anwendung finden, die kein hohes Risiko 
bergen, und zwar auf der Grundlage technischer Spezifikationen und L&#246;sungen, die 
geeignet sind, die Einhaltung dieser Anforderungen mit Blick auf die 
Zweckbestimmung der Systeme zu gew&#228;hrleisten. 
(2) Die Kommission und der Ausschuss f&#246;rdern und erleichtern die Aufstellung von 
Verhaltenskodizes, mit denen erreicht werden soll, dass KI-Systeme freiwillig 
weitere Anforderungen erf&#252;llen, die sich beispielsweise auf die &#246;kologische 
Nachhaltigkeit, die barrierefreie Zug&#228;nglichkeit f&#252;r Personen mit Behinderungen, die 
Beteiligung von Interessentr&#228;gern an der Konzeption und Entwicklung von KI-
Systemen und die Vielfalt der Entwicklungsteams beziehen, wobei die Erreichung 
dieser Ziele anhand klarer Vorgaben und wesentlicher Leistungsindikatoren 
gemessen wird. 
(3) Verhaltenskodizes k&#246;nnen von einzelnen KI-System-Anbietern oder von 
Interessenvertretungen dieser Anbieter oder von beiden aufgestellt werden, auch 
unter Einbeziehung von Nutzern und Interessentr&#228;gern sowie deren 
Interessenvertretungen. Verhaltenskodizes k&#246;nnen sich auf mehrere KI-Systeme 
erstrecken, um &#228;hnlichen Zweckbestimmungen der jeweiligen Systeme Rechnung zu 
tragen. 
(4) Die Kommission und der Ausschuss ber&#252;cksichtigen die besonderen Interessen und 
Bed&#252;rfnisse von Kleinanbietern und Startups bei der F&#246;rderung und Erleichterung 
der Aufstellung von Verhaltenskodizes.
TITEL X
VETRAULICHKEIT UND SANKTIONEN
Artikel 70 
Vertraulichkeit
(1) Die an der Anwendung dieser Verordnung beteiligten zust&#228;ndigen nationalen 
Beh&#246;rden und notifizierten Stellen wahren die Vertraulichkeit der Informationen und 
Daten, von denen sie in Aus&#252;bung ihrer Aufgaben und T&#228;tigkeiten Kenntnis erlangen 
und dabei insbesondere Folgendes sch&#252;tzen: 
a) Rechte des geistigen Eigentums, vertrauliche Gesch&#228;ftsinformationen oder 
Gesch&#228;ftsgeheimnisse nat&#252;rlicher oder juristischer Personen, auch Quellcodes, 
mit Ausnahme der in Artikel 5 der Richtlinie 2016/943 &#252;ber den Schutz 
vertraulichen Know-hows und vertraulicher Gesch&#228;ftsinformationen 
(Gesch&#228;ftsgeheimnisse) vor rechtswidrigem Erwerb sowie rechtswidriger 
Nutzung und Offenlegung genannten F&#228;lle;
b) die wirksame Durchf&#252;hrung dieser Verordnung, insbesondere f&#252;r die Zwecke 
von Inspektionen, Untersuchungen oder Audits, 
c) &#246;ffentliche und nationale Sicherheitsinteressen; 
d) die Integrit&#228;t von Straf- oder Verwaltungsverfahren. 
(2) Unbeschadet des Absatzes 1 darf der Austausch vertraulicher Informationen 
zwischen den zust&#228;ndigen nationalen Beh&#246;rden untereinander sowie zwischen den 
zust&#228;ndigen nationalen Beh&#246;rden und der Kommission nicht ohne vorherige 
R&#252;cksprache mit der zust&#228;ndigen nationalen Beh&#246;rde und dem Nutzer, von denen die 
Informationen stammen, offengelegt werden, sofern die Hochrisiko-KI-Systeme nach 
Anhang III Nummern 1, 6 und 7 von Strafverfolgungs-, Einwanderungs- oder 
Asylbeh&#246;rden verwendet werden und eine solche Offenlegung die &#246;ffentlichen und 
nationalen Sicherheitsinteressen gef&#228;hrden k&#246;nnte. 
Handeln Strafverfolgungs-, Einwanderungs- oder Asylbeh&#246;rden als Anbieter von 
Hochrisiko-KI-Systemen, wie sie in Anhang III Nummern 1, 6 und 7 aufgef&#252;hrt sind, 
verbleibt die technische Dokumentation nach Anhang IV in den R&#228;umlichkeiten 
dieser Beh&#246;rden. Diese Beh&#246;rden m&#252;ssen daf&#252;r sorgen, dass die Artikel 63 Abs&#228;tze 5 
bzw. 6 genannten Markt&#252;berwachungsbeh&#246;rden auf Verlangen unverz&#252;glich Zugang 
zu dieser Dokumentation oder eine Kopie davon erhalten. Zugang zu dieser 
Dokumentation oder zu einer Kopie davon darf nur das Personal der 
Markt&#252;berwachungsbeh&#246;rde erhalten, das &#252;ber eine entsprechende 
Sicherheitsfreigabe verf&#252;gt. 
(3) Die Abs&#228;tze 1 und 2 d&#252;rfen sich weder auf die Rechte und Pflichten der 
Kommission, der Mitgliedstaaten und notifizierten Stellen in Bezug auf den 
Informationsaustausch und die Weitergabe von Warnungen noch auf die Pflichten 
der betreffenden Parteien auswirken, Informationen auf der Grundlage des 
Strafrechts der Mitgliedstaaten bereitzustellen. 
(4) Die Kommission und die Mitgliedstaaten k&#246;nnen mit Regulierungsbeh&#246;rden von 
Drittstaaten, mit denen sie bilaterale oder multilaterale
Vertraulichkeitsvereinbarungen getroffen haben und die ein angemessenes Niveau an 
Vertraulichkeit gew&#228;hrleisten, erforderlichenfalls vertrauliche Informationen 
austauschen.
Artikel 71 
Sanktionen 
(1) Entsprechend den Vorgaben dieser Verordnung erlassen die Mitgliedstaaten 
Vorschriften f&#252;r Sanktionen, beispielsweise in Form von Geldbu&#223;en, die bei 
Verst&#246;&#223;en gegen diese Verordnung Anwendung finden, und ergreifen alle 
Ma&#223;nahmen, die f&#252;r deren ordnungsgem&#228;&#223;e und wirksame Durchsetzung notwendig 
sind. Die vorgesehenen Sanktionen m&#252;ssen wirksam, verh&#228;ltnism&#228;&#223;ig und 
abschreckend sein. Sie ber&#252;cksichtigen insbesondere die Interessen von 
Kleinanbietern und Startups sowie deren wirtschaftliches &#220;berleben. 
(2) Die Mitgliedstaaten teilen der Kommission diese Vorschriften und Ma&#223;nahmen mit 
und melden ihr unverz&#252;glich alle diesbez&#252;glichen &#196;nderungen.
(3) Bei folgenden Verst&#246;&#223;en werden Geldbu&#223;en von bis zu 30 000 000 EUR oder &#8211; im 
Falle von Unternehmen &#8211; von bis zu 6 % des gesamten weltweiten Jahresumsatzes
des vorangegangenen Gesch&#228;ftsjahres verh&#228;ngt, je nachdem, welcher Betrag h&#246;her 
ist:
a) Missachtung des Verbots der in Artikel 5 genannten KI-Praktiken; 
b) Nichtkonformit&#228;t des KI-Systems mit den in Artikel 10 festgelegten 
Anforderungen. 
(4) Versto&#223;en KI-Systeme gegen die in dieser Verordnung festgelegten Anforderungen 
oder Pflichten, mit Ausnahme der in den Artikeln 5 und 10 genannten, werden 
Geldbu&#223;en von bis zu 20 000 000 EUR oder &#8211; im Falle von Unternehmen &#8211; von bis 
zu 4 % des gesamten weltweiten Jahresumsatzes des vorangegangenen 
Gesch&#228;ftsjahres verh&#228;ngt, je nachdem, welcher Betrag h&#246;her ist. 
(5) Werden gegen&#252;ber notifizierten Stellen und zust&#228;ndigen nationalen Beh&#246;rden auf 
deren Auskunftsverlangen hin falsche, unvollst&#228;ndige oder irref&#252;hrende Angaben 
gemacht, werden Geldbu&#223;en von bis zu 10 000 000 EUR oder &#8211; im Falle von 
Unternehmen &#8211; von bis zu 2 % des gesamten weltweiten Jahresumsatzes des 
vorangegangenen Gesch&#228;ftsjahres verh&#228;ngt, je nachdem, welcher Betrag h&#246;her ist. 
(6) Bei der Festsetzung der Geldbu&#223;e werden in jedem Einzelfall alle relevanten 
Umst&#228;nde der konkreten Situation sowie Folgendes geb&#252;hrend ber&#252;cksichtigt: 
a) Art, Schwere und Dauer des Versto&#223;es und dessen Folgen; 
b) ob bereits andere Markt&#252;berwachungsbeh&#246;rden demselben Akteur f&#252;r 
denselben Versto&#223; Geldbu&#223;en auferlegt haben; 
c) Gr&#246;&#223;e und Marktanteil des Akteurs, der den Versto&#223; begangen hat. 
(7) Jeder Mitgliedstaat erl&#228;sst Vorschriften dar&#252;ber, ob und in welchem Umfang gegen 
Beh&#246;rden und &#246;ffentliche Stellen, die in dem betreffenden Mitgliedstaat 
niedergelassen sind, Geldbu&#223;en verh&#228;ngt werden k&#246;nnen. 
(8) In Abh&#228;ngigkeit vom Rechtssystem des betreffenden Mitgliedstaats k&#246;nnen die 
Vorschriften &#252;ber Geldbu&#223;en je nach den dort geltenden Regeln so angewandt 
werden, dass die Geldbu&#223;en von den zust&#228;ndigen nationalen Gerichten oder von 
sonstigen Stellen verh&#228;ngt werden. Die Anwendung dieser Vorschriften in diesen 
Mitgliedstaaten muss eine gleichwertige Wirkung haben.
Artikel 72 
Verh&#228;ngung von Geldbu&#223;en gegen Organe, Einrichtungen und sonstige Stellen der Union 
(1) Der Europ&#228;ische Datenschutzbeauftragte kann gegen Organe, Einrichtungen und 
sonstige Stellen der Union, die in den Anwendungsbereich dieser Verordnung fallen, 
Geldbu&#223;en verh&#228;ngen. Bei der Entscheidung, ob eine Geldbu&#223;e verh&#228;ngt wird, und 
bei der Festsetzung der Geldbu&#223;e werden in jedem Einzelfall alle relevanten 
Umst&#228;nde der konkreten Situation sowie Folgendes geb&#252;hrend ber&#252;cksichtigt: 
a) Art, Schwere und Dauer des Versto&#223;es und dessen Folgen; 
b) die Zusammenarbeit mit dem Europ&#228;ischen Datenschutzbeauftragten bei der 
Behebung des Versto&#223;es und der Minderung seiner m&#246;glichen Auswirkungen, 
einschlie&#223;lich der Befolgung von Ma&#223;nahmen, die der Europ&#228;ische 
Datenschutzbeauftragte dem Organ, der der Einrichtung oder der sonstigen 
Stelle der Union im Hinblick auf denselben Gegenstand zuvor bereits auferlegt 
hatte;
c) &#228;hnliche fr&#252;here Verst&#246;&#223;e des Organs, der Einrichtung oder der sonstigen 
Stelle der Union. 
(2) Bei folgenden Verst&#246;&#223;en werden Geldbu&#223;en von bis zu 500 000 EUR verh&#228;ngt: 
a) Missachtung des Verbots der in Artikel 5 genannten KI-Praktiken; 
b) Nichtkonformit&#228;t des KI-Systems mit den in Artikel 10 festgelegten 
Anforderungen. 
(3) Versto&#223;en KI-Systeme gegen die in dieser Verordnung festgelegten Anforderungen 
oder Pflichten, mit Ausnahme der in den Artikeln 5 und 10 genannten, werden 
Geldbu&#223;en von bis zu 250 000 EUR verh&#228;ngt. 
(4) Bevor der Europ&#228;ische Datenschutzbeauftragte Entscheidungen nach diesem Artikel 
trifft, gibt er dem Organ, der Einrichtung oder der sonstigen Stelle der Union, gegen 
das/die sich das von ihm gef&#252;hrte Verfahren richtet, Gelegenheit, sich zum Vorwurf 
des Versto&#223;es zu &#228;u&#223;ern. Der Europ&#228;ische Datenschutzbeauftragte st&#252;tzt seine 
Entscheidungen nur auf die Elemente und Umst&#228;nde, zu denen sich die betreffenden 
Parteien &#228;u&#223;ern k&#246;nnen. Beschwerdef&#252;hrer, soweit vorhanden, m&#252;ssen in das 
Verfahren eng einbezogen werden. 
(5) Die Verteidigungsrechte der betroffenen Parteien werden w&#228;hrend des Verfahrens in 
vollem Umfang gewahrt. Vorbehaltlich der legitimen Interessen von Einzelpersonen 
oder Unternehmen im Hinblick auf den Schutz ihrer personenbezogenen Daten oder 
Gesch&#228;ftsgeheimnisse haben sie Anspruch auf Einsicht in die Unterlagen des 
Europ&#228;ischen Datenschutzbeauftragten. 
(6) Das Aufkommen aus den nach diesem Artikel verh&#228;ngten Geldbu&#223;en z&#228;hlt zu den 
Einnahmen des Gesamthaushalts der Union.
TITEL XI
BEFUGNIS&#220;BERTRAGUNG UND AUSSCHUSSVERFAHREN
Artikel 73 
Aus&#252;bung der Befugnis&#252;bertragung 
(1) Die Befugnis zum Erlass delegierter Rechtsakte wird der Kommission unter den in 
diesem Artikel festgelegten Bedingungen &#252;bertragen. 
(2) Die Befugnis zum Erlass delegierter Rechtsakte nach Artikel 4, Artikel 7 Absatz 1, 
Artikel 11 Absatz 3, Artikel 43 Absatz 5 und 6 und Artikel 48 Absatz 5 wird der 
Kommission auf unbestimmte Zeit ab dem [Datum des Inkrafttretens dieser 
Verordnung] &#252;bertragen. 
(3) Die Befugnis zum Erlass delegierter Rechtsakte nach Artikel 4, Artikel 7 Absatz 1, 
Artikel 11 Absatz 3, Artikel 43 Absatz 5 und 6 und Artikel 48 Absatz 5 kann vom 
Europ&#228;ischen Parlament oder vom Rat jederzeit widerrufen werden. Der Beschluss 
&#252;ber den Widerruf beendet die &#220;bertragung der in diesem Beschluss angegebenen 
Befugnis. Er wird am Tag nach seiner Ver&#246;ffentlichung im Amtsblatt der 
Europ&#228;ischen Union oder zu einem darin angegebenen sp&#228;teren Zeitpunkt wirksam. 
Die G&#252;ltigkeit von delegierten Rechtsakten, die bereits in Kraft sind, wird von dem 
Beschluss &#252;ber den Widerruf nicht ber&#252;hrt.
DE
__________ 
95 DE
(4) Sobald die Kommission einen delegierten Rechtsakt erl&#228;sst, &#252;bermittelt sie ihn 
gleichzeitig dem Europ&#228;ischen Parlament und dem Rat. 
__________ 
(5) Ein delegierter Rechtsakt, der nach Artikel 4, Artikel 7 Absatz 1, Artikel 11 
Absatz 3, Artikel 43 Absatz 5 und 6 und Artikel 48 Absatz 5 erlassen wurde, tritt nur 
in Kraft, wenn weder das Europ&#228;ische Parlament noch der Rat innerhalb einer Frist 
von drei Monaten nach &#220;bermittlung dieses Rechtsakts an das Europ&#228;ische 
Parlament und den Rat Einw&#228;nde erhoben haben oder wenn vor Ablauf dieser Frist 
das Europ&#228;ische Parlament und der Rat beide der Kommission mitgeteilt haben, dass 
sie keine Einw&#228;nde erheben werden. Auf Initiative des Europ&#228;ischen Parlaments 
oder des Rates wird diese Frist um drei Monate verl&#228;ngert.
Artikel 74 
Ausschussverfahren 
(1) Die Kommission wird von einem Ausschuss unterst&#252;tzt. Dieser Ausschuss ist ein 
Ausschuss im Sinne der Verordnung (EU) Nr. 182/2011. 
(2) Wird auf diesen Absatz Bezug genommen, gilt Artikel 5 der Verordnung (EU) 
Nr. 182/2011. 
TITEL XII 
SCHLUSSBESTIMMUNGEN 
Artikel 75 
&#196;nderung der Verordnung (EU) Nr. 300/2008 
In Artikel 4 Absatz 3 der Verordnung (EG) Nr. 300/2008 wird folgender Unterabsatz 
angef&#252;gt: 
&#8222;Beim Erlass detaillierter Ma&#223;nahmen, die technische Spezifikationen und Verfahren f&#252;r die 
Genehmigung und den Einsatz von Sicherheitsausr&#252;stung betreffen, bei der auch Systeme der 
k&#252;nstlichen Intelligenz im Sinne der Verordnung (EU) YYY/XX [&#252;ber K&#252;nstliche Intelligenz] 
des Europ&#228;ischen Parlaments und des Rates* zum Einsatz kommen, werden die in Titel III 
Kapitel 2 jener Verordnung festgelegten Anforderungen ber&#252;cksichtigt.
* Verordnung (EU) YYY/XX [&#252;ber K&#252;nstliche Intelligenz] (ABl...)&#8220;
Artikel 76 
&#196;nderung der Verordnung (EU) Nr. 167/2013 
In Artikel 17 Absatz 5 der Verordnung (EG) Nr. 167/2013 wird folgender Unterabsatz 
angef&#252;gt: 
&#8222;Beim Erlass delegierter Rechtsakte nach Unterabsatz 1, die sich auf Systeme der k&#252;nstlichen 
Intelligenz beziehen, bei denen es sich um Sicherheitskomponenten im Sinne der Verordnung 
(EU) YYY/XX [&#252;ber K&#252;nstliche Intelligenz] des Europ&#228;ischen Parlaments und des Rates* 
handelt, werden die in Titel III Kapitel 2 jener Verordnung festgelegten Anforderungen 
ber&#252;cksichtigt.
* Verordnung (EU) YYY/XX [&#252;ber K&#252;nstliche Intelligenz] (ABl...)&#8220;
DE
__________ 
96 DE
Artikel 77 
&#196;nderung der Verordnung (EU) Nr. 168/2013 
In Artikel 22 Absatz 5 der Verordnung (EG) Nr. 168/2013 wird folgender Unterabsatz 
__________ 
__________ 
angef&#252;gt: 
&#8222;Beim Erlass delegierter Rechtsakte nach Unterabsatz 1, die sich auf Systeme der k&#252;nstlichen 
Intelligenz beziehen, bei denen es sich um Sicherheitskomponenten im Sinne der Verordnung 
(EU) YYY/XX [&#252;ber K&#252;nstliche Intelligenz] des Europ&#228;ischen Parlaments und des Rates* 
handelt, werden die in Titel III Kapitel 2 jener Verordnung festgelegten Anforderungen 
ber&#252;cksichtigt.
* Verordnung (EU) YYY/XX [&#252;ber K&#252;nstliche Intelligenz] (ABl...)&#8220;
Artikel 78 
&#196;nderung der Richtlinie 2014/90/EU 
In Artikel 8 der Richtlinie 2014/90/EU wird folgender Absatz angef&#252;gt: 
&#8222;(4) Bei Systemen der k&#252;nstlichen Intelligenz, bei denen es sich um Sicherheitskomponenten 
im Sinne der Verordnung (EU) YYY/XX [&#252;ber K&#252;nstliche Intelligenz] des Europ&#228;ischen 
Parlaments und des Rates* handelt, ber&#252;cksichtigt die Kommission bei der Aus&#252;bung ihrer 
T&#228;tigkeiten nach Absatz 1 und bei Erlass technischer Spezifikationen und Pr&#252;fnormen nach 
den Abs&#228;tzen 2 und 3 die in Titel III Kapitel 2 jener Verordnung festgelegten Anforderungen.
* Verordnung (EU) YYY/XX [&#252;ber K&#252;nstliche Intelligenz] (ABl...)&#8220;.
Artikel 79 
&#196;nderung der Richtlinie (EU) 2016/797 
In Artikel 5 der Richtlinie (EU) 2016/797 wird folgender Absatz angef&#252;gt: 
&#8222;(12) &#8222;Beim Erlass von delegierten Rechtsakten nach Unterabsatz 1 und von 
Durchf&#252;hrungsrechtsakten nach Absatz 11, die sich auf Systeme der k&#252;nstlichen Intelligenz 
beziehen, bei denen es sich um Sicherheitskomponenten im Sinne der Verordnung 
(EU) YYY/XX [&#252;ber K&#252;nstliche Intelligenz] des Europ&#228;ischen Parlaments und des Rates* 
handelt, werden die in Titel III Kapitel 2 jener Verordnung festgelegten Anforderungen 
ber&#252;cksichtigt.
* Verordnung (EU) YYY/XX [&#252;ber K&#252;nstliche Intelligenz] (ABl...)&#8220;.
Artikel 80 
&#196;nderung der Verordnung (EU) Nr. 2018/858 
In Artikel 5 der Verordnung (EU) 2018/858 wird folgender Absatz angef&#252;gt: 
&#8222;(4) &#8222;Beim Erlass delegierter Rechtsakte nach Absatz 3, die sich auf Systeme der k&#252;nstlichen 
Intelligenz beziehen, bei denen es sich um Sicherheitskomponenten im Sinne der Verordnung 
(EU) YYY/XX [&#252;ber K&#252;nstliche Intelligenz] des Europ&#228;ischen Parlaments und des Rates* 
handelt, werden die in Titel III Kapitel 2 jener Verordnung festgelegten Anforderungen 
ber&#252;cksichtigt.
DE
__________ 
97 DE
__________ 
* Verordnung (EU) YYY/XX [&#252;ber K&#252;nstliche Intelligenz] (ABl...)&#8220;.
Artikel 81 
&#196;nderung der Verordnung (EU) 2018/1139 
Die Verordnung (EU) 2018/1139 wird wie folgt ge&#228;ndert: 
1. In Artikel 17 wird folgender Absatz angef&#252;gt: 
&#8222;(3) &#8222;Unbeschadet des Absatzes 2 werden beim Erlass von Durchf&#252;hrungsrechtakten nach 
Absatz 1, die sich auf Systeme der k&#252;nstlichen Intelligenz beziehen, bei denen es sich um 
Sicherheitskomponenten im Sinne der Verordnung (EU) YYY/XX [&#252;ber K&#252;nstliche 
Intelligenz] des Europ&#228;ischen Parlaments und des Rates* handelt, die in Titel III Kapitel 2 
jener Verordnung festgelegten Anforderungen ber&#252;cksichtigt.
* Verordnung (EU) YYY/XX [&#252;ber K&#252;nstliche Intelligenz] (ABl...)&#8220; 
2. In Artikel 19 wird folgender Absatz angef&#252;gt: 
&#8222;(4) &#8222;Beim Erlass delegierter Rechtsakte nach den Abs&#228;tzen 1 und 2, die sich auf Systeme der 
k&#252;nstlichen Intelligenz beziehen, bei denen es sich um Sicherheitskomponenten im Sinne der 
Verordnung (EU) YYY/XX [&#252;ber K&#252;nstliche Intelligenz] des Europ&#228;ischen Parlaments und 
des Rates* handelt, werden die in Titel III Kapitel 2 jener Verordnung festgelegten 
Anforderungen ber&#252;cksichtigt.&#8220; 
3. In Artikel 43 wird folgender Absatz angef&#252;gt: 
&#8222;(4) &#8222;Beim Erlass von Durchf&#252;hrungsrechtsakten nach Absatz 1, die sich auf Systeme der 
k&#252;nstlichen Intelligenz beziehen, bei denen es sich um Sicherheitskomponenten im Sinne der 
Verordnung (EU) YYY/XX [&#252;ber K&#252;nstliche Intelligenz] des Europ&#228;ischen Parlaments und 
des Rates* handelt, werden die in Titel III Kapitel 2 jener Verordnung festgelegten 
Anforderungen ber&#252;cksichtigt.&#8220; 
4. In Artikel 47 wird folgender Absatz angef&#252;gt: 
&#8222;(3) &#8222;Beim Erlass delegierter Rechtsakte nach den Abs&#228;tzen 1 und 2, die sich auf Systeme der 
k&#252;nstlichen Intelligenz beziehen, bei denen es sich um Sicherheitskomponenten im Sinne der 
Verordnung (EU) YYY/XX [&#252;ber K&#252;nstliche Intelligenz] des Europ&#228;ischen Parlaments und 
des Rates* handelt, werden die in Titel III Kapitel 2 jener Verordnung festgelegten 
Anforderungen ber&#252;cksichtigt.&#8220; 
5. In Artikel 57 wird folgender Absatz angef&#252;gt: 
&#8222;Beim Erlass solcher Durchf&#252;hrungsrechtsakte, die sich auf Systeme der k&#252;nstlichen 
Intelligenz beziehen, bei denen es sich um Sicherheitskomponenten im Sinne der Verordnung 
(EU) YYY/XX [&#252;ber K&#252;nstliche Intelligenz] des Europ&#228;ischen Parlaments und des Rates* 
handelt, werden die in Titel III Kapitel 2 jener Verordnung festgelegten Anforderungen 
ber&#252;cksichtigt.&#8220; 
6. In Artikel 58 wird folgender Absatz angef&#252;gt: 
&#8222;(3) Beim Erlass delegierter Rechtsakte nach den Abs&#228;tzen 1 und 2, die sich auf Systeme der 
k&#252;nstlichen Intelligenz beziehen, bei denen es sich um Sicherheitskomponenten im Sinne der 
Verordnung (EU) YYY/XX [&#252;ber K&#252;nstliche Intelligenz] des Europ&#228;ischen Parlaments und
DE
__________ 
98 DE
des Rates* handelt, werden die in Titel III Kapitel 2 jener Verordnung festgelegten 
Anforderungen ber&#252;cksichtigt.&#8220;
Artikel 82 
&#196;nderung der Verordnung (EU) Nr. 2019/2144 
In Artikel 11 der Verordnung (EU) 2019/2144 wird folgender Absatz angef&#252;gt: 
&#8222;(3) Beim Erlass von Durchf&#252;hrungsrechtsakten nach Absatz 2, die sich auf Systeme der 
k&#252;nstlichen Intelligenz beziehen, bei denen es sich um Sicherheitskomponenten im Sinne der 
Verordnung (EU) YYY/XX [&#252;ber K&#252;nstliche Intelligenz] des Europ&#228;ischen Parlaments und 
des Rates* handelt, werden die in Titel III Kapitel 2 jener Verordnung festgelegten 
Anforderungen ber&#252;cksichtigt. 
* Verordnung (EU) YYY/XX [&#252;ber K&#252;nstliche Intelligenz] (ABl...)&#8220;.
Artikel 83 
Bereits in Verkehr gebrachte oder in Betrieb genommene KI-Systeme 
(1) Diese Verordnung gilt nicht f&#252;r KI-Systeme, bei denen es sich um Komponenten von 
IT-Gro&#223;systemen handelt, die mit den in Anhang IX genannten Rechtsakten 
festgelegt wurden und vor dem [Datum 12 Monate nach dem Datum der Anwendung 
dieser Verordnung nach Artikel 85 Absatz 2] in Verkehr gebracht oder in Betrieb 
genommen wurden, sofern der Ersatz oder die &#196;nderung jener Rechtsakte nicht zu 
einer wesentlichen &#196;nderung der Konzeption oder Zweckbestimmung des 
betreffenden KI-Systems f&#252;hrt. 
Die in dieser Verordnung festgelegten Anforderungen werden gegebenenfalls bei der 
Bewertung jedes IT-Gro&#223;systems, das auf der Grundlage der in Anhang IX 
aufgef&#252;hrten Rechtsakte eingerichtet wurde, ber&#252;cksichtigt, wobei die Bewertung 
entsprechend den Vorgaben der jeweiligen Rechtsakte erfolgt. 
(2) Diese Verordnung gilt &#8211; mit Ausnahme der in Absatz 1 genannten Systeme &#8211; f&#252;r 
Hochrisiko-KI-Systeme, die vor dem [Datum der Anwendung dieser Verordnung 
nach Artikel 85 Absatz 2] in Verkehr gebracht oder in Betrieb genommen wurden, 
nur dann, wenn diese Systeme danach in ihrer Konzeption oder Zweckbestimmung 
wesentlich ge&#228;ndert wurden. 
Artikel 84 
Bewertung und &#220;berarbeitung 
(1) Die Kommission pr&#252;ft nach dem Inkrafttreten dieser Verordnung einmal j&#228;hrlich, ob 
eine &#196;nderung der Liste in Anhang III erforderlich ist. 
(2) Bis zum [Datum drei Jahre nach dem Datum der Anwendung dieser Verordnung 
nach Artikel 85 Absatz 2] und danach alle vier Jahre legt die Kommission dem 
Europ&#228;ischen Parlament und dem Rat einen Bericht &#252;ber die Bewertung und 
&#220;berpr&#252;fung dieser Verordnung vor. Die Berichte werden ver&#246;ffentlicht. 
(3) In den in Absatz 2 genannten Berichten wird insbesondere auf folgende Aspekte 
eingegangen:
a) Stand der finanziellen und personellen Ressourcen der zust&#228;ndigen nationalen 
Beh&#246;rden im Hinblick auf deren F&#228;higkeit, die ihnen auf der Grundlage dieser 
Verordnung &#252;bertragenen Aufgaben wirksam zu erf&#252;llen; 
b) Stand der Sanktionen, insbesondere der Bu&#223;gelder nach Artikel 71 Absatz 1, 
die Mitgliedstaaten bei Verst&#246;&#223;en gegen diese Verordnung verh&#228;ngt haben. 
(4) Innerhalb von [drei Jahren nach dem Datum der Anwendung dieser Verordnung 
nach Artikel 85 Absatz 2] und danach alle vier Jahre f&#252;hrt die Kommission eine 
Bewertung der Folgen und Wirksamkeit der Verhaltenskodizes durch, mit denen die 
Anwendung der Anforderungen in Titel III Kapitel 2 und m&#246;glicherweise auch 
zus&#228;tzlicher Anforderungen an andere KI-Systeme als Hochrisiko-KI-Systeme 
gef&#246;rdert werden soll. 
(5) F&#252;r die Zwecke der Abs&#228;tze 1 bis 4 &#252;bermitteln der Ausschuss, die Mitgliedstaaten 
und die zust&#228;ndigen nationalen Beh&#246;rden der Kommission auf Anfrage die 
gew&#252;nschten Informationen. 
(6) Bei den in den Abs&#228;tzen 1 und 4 genannten Bewertungen und &#220;berpr&#252;fungen 
ber&#252;cksichtigt die Kommission die Standpunkte und Feststellungen des Ausschusses, 
des Europ&#228;ischen Parlaments, des Rates und anderer einschl&#228;giger Stellen oder 
Quellen. 
(7) Die Kommission legt erforderlichenfalls geeignete Vorschl&#228;ge zur &#196;nderung dieser 
Verordnung vor und ber&#252;cksichtigt dabei insbesondere die technischen 
Entwicklungen und die Fortschritte in der Informationsgesellschaft.
Artikel 85 
Inkrafttreten und Geltungsbeginn 
(1) Diese Verordnung tritt am zwanzigsten Tag nach ihrer Ver&#246;ffentlichung im 
Amtsblatt der Europ&#228;ischen Union in Kraft. 
(2) Diese Verordnung gilt ab dem [24 Monate nach Inkrafttreten der Verordnung]. 
(3) Abweichend von Absatz 2 gilt Folgendes: 
a) Titel III Kapitel 4 und Titel VI gelten ab dem [drei Monate nach Inkrafttreten 
der Verordnung]; 
b) Artikel 71 gilt ab dem [12 Monate nach Inkrafttreten der Verordnung]. 
Diese Verordnung ist in allen ihren Teilen verbindlich und gilt unmittelbar in jedem 
Mitgliedstaat. 
Geschehen zu Br&#252;ssel am [&#8230;]
Im Namen des Europ&#228;ischen Parlaments Im Namen des Rates 
Der Pr&#228;sident Der Pr&#228;sident
FINANZBOGEN ZU RECHTSAKTEN
1. RAHMEN DES VORSCHLAGS/DER INITIATIVE
1.1. Bezeichnung des Vorschlags/der Initiative 
1.2. Politikbereich(e) 
1.3. Der Vorschlag/Die Initiative betrifft 
1.4. Ziel(e) 
1.4.1. Allgemeine(s) Ziel(e) 
1.4.2. Einzelziel(e) 
1.4.3. Erwartete Ergebnisse und Auswirkungen 
1.4.4. Leistungsindikatoren
1.5. Begr&#252;ndung des Vorschlags/der Initiative 
1.5.1. Kurz- oder langfristig zu deckender Bedarf, einschlie&#223;lich einer detaillierten 
Zeitleiste f&#252;r die Durchf&#252;hrung der Initiative 
1.5.2. Mehrwert aufgrund des T&#228;tigwerdens der Union (kann sich aus 
unterschiedlichen Faktoren ergeben, z. B. Vorteile durch Koordinierung, 
Rechtssicherheit, gr&#246;&#223;erer Wirksamkeit oder Komplementarit&#228;t). F&#252;r die Zwecke 
dieser Nummer bezeichnet der Ausdruck &#8222;Mehrwert aufgrund des T&#228;tigwerdens der 
Union&#8220; den Wert, der sich aus dem T&#228;tigwerden der Union ergibt und den Wert 
erg&#228;nzt, der andernfalls allein von den Mitgliedstaaten geschaffen worden w&#228;re. 
1.5.3. Aus fr&#252;heren &#228;hnlichen Ma&#223;nahmen gewonnene Erkenntnisse 
1.5.4. Vereinbarkeit mit dem Mehrj&#228;hrigen Finanzrahmen sowie m&#246;gliche 
Synergieeffekte mit anderen geeigneten Instrumenten 
1.5.5 Bewertung der verschiedenen verf&#252;gbaren Finanzierungsoptionen, 
einschlie&#223;lich der M&#246;glichkeiten f&#252;r eine Umschichtung 
1.6. Laufzeit und finanzielle Auswirkungen des Vorschlags/der Initiative 
1.7. Vorgeschlagene Methode(n) der Mittelverwaltung 
2. VERWALTUNGSMA&#7838;NAHMEN 
2.1. &#220;berwachung und Berichterstattung 
2.2. Verwaltungs- und Kontrollsystem 
2.2.1. Begr&#252;ndung der Methode(n) der Mittelverwaltung, des 
Durchf&#252;hrungsmechanismus/der Durchf&#252;hrungsmechanismen f&#252;r die Finanzierung, 
der Zahlungsmodalit&#228;ten und der Kontrollstrategie, wie vorgeschlagen 
2.2.2. Angaben zu den ermittelten Risiken und dem/den zu deren Eind&#228;mmung 
eingerichteten System(en) der internen Kontrolle 
2.2.3. Sch&#228;tzung und Begr&#252;ndung der Kosteneffizienz der Kontrollen (Verh&#228;ltnis 
zwischen den Kontrollkosten und dem Wert der betreffenden verwalteten Mittel) 
sowie Bewertung des erwarteten Ausma&#223;es des Fehlerrisikos (bei Zahlung und beim 
Abschluss)
2.3. Pr&#228;vention von Betrug und Unregelm&#228;&#223;igkeiten
3. GESCH&#196;TZTE FINANZIELLE AUSWIRKUNGEN DES
VORSCHLAGS/DER INITIATIVE 
3.1. Betroffene Rubrik(en) des Mehrj&#228;hrigen Finanzrahmens und Ausgabenlinie(n) 
im Haushaltsplan 
3.2. Gesch&#228;tzte finanzielle Auswirkungen des Vorschlags auf die Mittel
3.2.1. &#220;bersicht &#252;ber die gesch&#228;tzten Auswirkungen auf die operativen Mittel 
3.2.2. Gesch&#228;tzte Ergebnisse, die mit operativen Mitteln finanziert werden 
3.2.3. &#220;bersicht &#252;ber die gesch&#228;tzten Auswirkungen auf die Verwaltungsmittel 
3.2.4. Vereinbarkeit mit dem Mehrj&#228;hrigen Finanzrahmen 
3.2.5. Finanzierungsbeteiligung Dritter 
3.3. Gesch&#228;tzte Auswirkungen auf die Einnahmen
FINANZBOGEN ZU RECHTSAKTEN
1. RAHMEN DES VORSCHLAGS/DER INITIATIVE
1.1. Bezeichnung des Vorschlags/der Initiative
Verordnung des Europ&#228;ischen Parlaments und des Rates zur Festlegung 
harmonisierter Vorschriften f&#252;r k&#252;nstliche Intelligenz (Gesetz &#252;ber k&#252;nstliche 
Intelligenz) und zur &#196;nderung bestimmter Rechtsakte der Union
1.2. Politikbereich(e)
Kommunikationsnetze, Inhalte und Technologien; 
Binnenmarkt, Industrie, Unternehmertum und KMU; 
Die finanziellen Auswirkungen betreffen die neuen Aufgaben, mit denen die 
Kommission betraut wird, einschlie&#223;lich der Unterst&#252;tzung des KI-Ausschusses der 
EU; 
T&#228;tigkeit: Gestaltung der digitalen Zukunft Europas.
1.3. Der Vorschlag/Die Initiative betrifft 
X eine neue Ma&#223;nahme
&#61608; eine neue Ma&#223;nahme im Anschluss an ein Pilotprojekt/eine vorbereitende 
Ma&#223;nahme64
&#61608; die Verl&#228;ngerung einer bestehenden Ma&#223;nahme
&#61608; eine neu ausgerichtete Ma&#223;nahme
1.4. Ziel(e) 
1.4.1. Allgemeine(s) Ziel(e)
&#220;bergeordnetes Ziel der Ma&#223;nahme ist die Gew&#228;hrleistung des reibungslosen 
Funktionierens des Binnenmarkts, indem die Voraussetzungen f&#252;r die Entwicklung 
und Verwendung vertrauensw&#252;rdiger k&#252;nstlicher Intelligenz in der Union geschaffen 
werden.
1.4.2. Einzelziel(e)
Einzelziel Nr. 1 
Festlegung konkreter Anforderungen an und Pflichten f&#252;r alle an der 
Wertsch&#246;pfungskette Beteiligten, um zu gew&#228;hrleisten, dass die auf dem Markt in 
Verkehr gebrachten und verwendeten KI-Systeme sicher sind und die bestehenden 
Grundrechte und die Werte der Union wahren.
Einzelziel Nr. 2 
Gew&#228;hrleistung von Rechtssicherheit, um Investitionen und Innovationen im Bereich 
KI zu f&#246;rdern, indem klargestellt wird, welchen grundlegenden Anforderungen und 
Pflichten nachgekommen werden muss sowie welche Konformit&#228;ts- und 
Einhaltungsverfahren befolgt werden m&#252;ssen, um ein KI-System auf dem 
Unionsmarkt in Verkehr zu bringen oder zu verwenden. 
64 Im Sinne des Artikels 54 Absatz 2 Buchstabe a oder b der Haushaltsordnung.
Einzelziel Nr. 3 
St&#228;rkung der Leitungsstruktur und der wirksamen Durchsetzung des geltenden 
Rechts zur Wahrung der Grundrechte sowie der Sicherheitsanforderungen f&#252;r KI-
Systeme durch Erteilung neuer Befugnisse sowie Bereitstellung von Ressourcen und 
klaren Regeln f&#252;r die zust&#228;ndigen Beh&#246;rden in Bezug auf 
Konformit&#228;tsbewertungsverfahren und nachtr&#228;gliche Beobachtungsverfahren sowie 
die Aufteilung der Leitungs- und &#220;berwachungsaufgaben zwischen der nationalen 
und der EU-Ebene.
Einzelziel Nr. 4 
Erleichterung der Entwicklung eines Binnenmarkts f&#252;r rechtskonforme, sichere und 
vertrauensw&#252;rdige KI-Anwendungen und Verhinderung einer Marktfragmentierung, 
indem die EU Ma&#223;nahmen ergreift, um Mindestanforderungen f&#252;r KI-Systeme 
festzulegen, die im Einklang mit den bestehenden Grundrechten und 
Sicherheitsvorschriften auf dem Unionsmarkt in Verkehr gebracht und verwendet 
werden sollen.
1.4.3. Erwartete Ergebnisse und Auswirkungen 
Bitte geben Sie an, wie sich der Vorschlag/die Initiative auf die Beg&#252;nstigten/Zielgruppen auswirken 
d&#252;rfte.
Minimale, aber klare Anforderungen sollten sich positiv auf KI-Lieferanten 
auswirken, indem sie Rechtssicherheit schaffen und den Zugang zum gesamten 
Binnenmarkt gew&#228;hrleisten. 
KI-Nutzern sollte die Rechtssicherheit zugutekommen, dass die von ihnen 
erworbenen Hochrisiko-KI-Systeme mit den europ&#228;ischen Rechtsvorschriften und 
Werten im Einklang stehen. 
Die Verbraucherinnen und Verbraucher sollten davon profitieren, dass das Risiko 
von Verletzungen ihrer Sicherheit oder ihrer Grundrechte einged&#228;mmt wird. 
1.4.4. Leistungsindikatoren 
Bitte geben Sie an, anhand welcher Indikatoren sich die Realisierung des Vorschlags/der Initiative 
verfolgen l&#228;sst.
Indikator 1 
Zahl der schwerwiegenden Vorf&#228;lle oder KI-Leistungen, die einen schwerwiegenden 
Vorfall oder eine Verletzung der Pflicht zur Wahrung der Grundrechte darstellen, 
(halbj&#228;hrlich) nach Anwendungsbereichen und berechnet a) in absoluten Zahlen, b) 
als Anteil der eingesetzten Anwendungen und c) Anteil der betroffenen B&#252;rger. 
Indikator 2 
a) Gesamtinvestitionen in KI in der EU (pro Jahr) 
b) Gesamtinvestitionen in KI nach Mitgliedstaat (pro Jahr) 
c) Anteil von Unternehmen, die KI nutzen (pro Jahr) 
d) Anteil von KMU, die KI nutzen (pro Jahr) 
Buchstaben a und b werden auf der Grundlage amtlicher Quellen berechnet und mit 
Sch&#228;tzungen des privaten Sektors verglichen. 
Buchstaben c und d werden durch regelm&#228;&#223;ige Unternehmenserhebungen erfasst.
1.5. Begr&#252;ndung des Vorschlags/der Initiative 
1.5.1. Kurz- oder langfristig zu deckender Bedarf, einschlie&#223;lich einer detaillierten 
Zeitleiste f&#252;r die Durchf&#252;hrung der Initiative
Die Verordnung sollte eineinhalb Jahre nach ihrer Annahme uneingeschr&#228;nkt 
anwendbar sein. Die Elemente der Leitungsstruktur sollten jedoch bereits vor diesem 
Zeitpunkt eingerichtet sein. Insbesondere m&#252;ssen die Mitgliedstaaten bereits 
bestehende Beh&#246;rden benannt und/oder neue Beh&#246;rden eingerichtet haben, die die in 
den Rechtsvorschriften festgelegten Aufgaben bereits fr&#252;her wahrnehmen, und der 
KI-Ausschuss der EU sollte eingerichtet und arbeitsbereit sein. Zum Zeitpunkt der 
Anwendbarkeit sollte die europ&#228;ische Datenbank der KI-Systeme voll funktionsf&#228;hig 
sein. Parallel zum Annahmeverfahren ist daher die Datenbank zu entwickeln, damit 
ihre Entwicklung zum Zeitpunkt des Inkrafttretens der Verordnung abgeschlossen 
ist.
1.5.2. Mehrwert aufgrund des T&#228;tigwerdens der Union (kann sich aus unterschiedlichen 
Faktoren ergeben, z. B. Vorteile durch Koordinierung, Rechtssicherheit, gr&#246;&#223;erer
Wirksamkeit oder Komplementarit&#228;t). F&#252;r die Zwecke dieser Nummer bezeichnet der 
Ausdruck &#8222;Mehrwert aufgrund des T&#228;tigwerdens der Union&#8220; den Wert, der sich aus 
dem T&#228;tigwerden der Union ergibt und den Wert erg&#228;nzt, der andernfalls allein von 
den Mitgliedstaaten geschaffen worden w&#228;re. 
Die reibungslose unionsweite Bereitstellung von KI-Systemen wird durch das 
Entstehen eines Flickenteppichs potenziell abweichender nationaler Vorschriften 
behindert, die zudem die Sicherheit und den Schutz der Grundrechte sowie die 
Einhaltung der Werte der Union l&#228;nder&#252;bergreifend nur unzureichend gew&#228;hrleisten. 
Eine gemeinsame Legislativma&#223;nahme der EU im KI-Bereich k&#246;nnte den 
Binnenmarkt ankurbeln und verf&#252;gt &#252;ber gro&#223;es Potenzial, der europ&#228;ischen 
Industrie auf der Weltb&#252;hne einen Wettbewerbsvorteil und Gr&#246;&#223;envorteile zu 
verschaffen, die von einzelnen Mitgliedstaaten allein nicht erzielt werden k&#246;nnen. 
1.5.3. Aus fr&#252;heren &#228;hnlichen Ma&#223;nahmen gewonnene Erkenntnisse
Die Richtlinie &#252;ber den elektronischen Gesch&#228;ftsverkehr (2000/31/EG) setzt den 
&#252;bergeordneten Rahmen f&#252;r das Funktionieren des Binnenmarktes und die Aufsicht 
&#252;ber digitale Dienste und legt die Grundstruktur f&#252;r ein System der Zusammenarbeit 
zwischen den Mitgliedstaaten. Sie deckt im Prinzip alle Anforderungen an digitale 
Dienste ab. Die Bewertung der Richtlinie brachte mehrere M&#228;ngel in diesem System 
der Zusammenarbeit zu Tage, darunter wichtige Verfahrensaspekte, wie fehlende 
klare Fristen f&#252;r Antworten aus den Mitgliedstaaten, gepaart mit einer allgemeinen 
mangelnden Bereitschaft zur Beantwortung von Anfragen. Dies hat im Laufe der 
Jahre zu einem Mangel an Vertrauen zwischen den Mitgliedstaaten gef&#252;hrt, wenn es 
darum geht, Bedenken in Bezug auf grenz&#252;berschreitender Anbieter digitaler Dienste 
auszur&#228;umen. Die Bewertung der Richtlinie hat gezeigt, dass auf europ&#228;ischer Ebene 
differenzierte Regeln und Anforderungen festgelegt werden m&#252;ssen. Aus diesem 
Grund w&#252;rde die Umsetzung der in dieser Verordnung festgelegten besonderen 
Verpflichtungen einen spezifischen Kooperationsmechanismus auf EU-Ebene mit 
einer Leitungsstruktur erfordern, die die Koordinierung der jeweils zust&#228;ndigen 
Stellen auf EU-Ebene gew&#228;hrleistet.
1.5.4. Vereinbarkeit mit dem Mehrj&#228;hrigen Finanzrahmen sowie m&#246;gliche Synergieeffekte 
mit anderen geeigneten Instrumenten 
In der Verordnung zur Festlegung harmonisierter Vorschriften f&#252;r k&#252;nstliche 
Intelligenz und zur &#196;nderung bestimmter Rechtsakte der Union wird ein neuer 
gemeinsamer Rahmen von Anforderungen f&#252;r KI-Systeme eingef&#252;hrt, der weit &#252;ber 
den Rahmen der bestehenden Rechtsvorschriften hinausgeht. Aus diesem Grund 
muss mit diesem Vorschlag eine neue nationale und europ&#228;ische Regulierungs- und 
Koordinierungsfunktion geschaffen werden. 
Was m&#246;gliche Synergien mit anderen geeigneten Instrumenten anbelangt, so kann 
die Rolle der notifizierenden Beh&#246;rden auf nationaler Ebene von nationalen 
Beh&#246;rden wahrgenommen werden, die &#228;hnliche Aufgaben im Rahmen anderer EU-
Verordnungen wahrnehmen. 
Durch die St&#228;rkung des Vertrauens in KI und damit die F&#246;rderung von Investitionen 
in die Entwicklung und Einf&#252;hrung von KI erg&#228;nzt sie dar&#252;ber hinaus das Programm 
&#8222;Digitales Europa&#8220;, zu dessen f&#252;nf Priorit&#228;ten die F&#246;rderung der Verbreitung der KI 
geh&#246;rt.
1.5.5. Bewertung der verschiedenen verf&#252;gbaren Finanzierungsoptionen, einschlie&#223;lich der 
M&#246;glichkeiten f&#252;r eine Umschichtung
Personal wird umgesetzt. Die &#252;brigen Kosten werden aus dem Finanzrahmen des 
Programms &#8222;Digitales Europa&#8220; finanziert, da das Ziel dieser Verordnung &#8211; 
Gew&#228;hrleistung einer vertrauensw&#252;rdigen KI &#8211; unmittelbar zu einem Kernziel des 
Programms &#8222;Digitales Europa&#8220; beitr&#228;gt, n&#228;mlich der Beschleunigung der 
Entwicklung und Einf&#252;hrung von KI in Europa.
1.6. Laufzeit und finanzielle Auswirkungen des Vorschlags/der Initiative 
&#61608; befristete Laufzeit 
&#8211; &#61608; Laufzeit: [TT.MM.]JJJJ bis [TT.MM.]JJJJ 
&#8211; &#61608; Finanzielle Auswirkungen auf die Mittel f&#252;r Verpflichtungen von JJJJ bis JJJJ 
und auf die Mittel f&#252;r Zahlungen von JJJJ bis JJJJ 
X unbefristete Laufzeit
&#8211; Anlaufphase von ein/zwei Jahren (zu best&#228;tigen), 
&#8211; anschlie&#223;end regul&#228;re Umsetzung. 
_
1.7. Vorgeschlagene Methode(n) der Mittelverwaltung65
X Direkte Mittelverwaltung durch die Kommission 
&#8211; &#61608; durch ihre Dienststellen, einschlie&#223;lich ihres Personals in den Delegationen der 
Union 
&#8211; &#61608; durch Exekutivagenturen 
&#61608; Geteilte Mittelverwaltung mit Mitgliedstaaten 
&#61608; Indirekte Mittelverwaltung durch &#220;bertragung von Haushaltsvollzugsaufgaben 
an:
&#8211; &#61608; Drittl&#228;nder oder die von ihnen benannten Einrichtungen 
&#8211; &#61608; internationale Einrichtungen und deren Agenturen (bitte angeben) 
&#8211; &#61608; die EIB und den Europ&#228;ischen Investitionsfonds 
&#8211; &#61608; Einrichtungen im Sinne der Artikel 70 und 71 der Haushaltsordnung 
&#8211; &#61608; &#246;ffentlich-rechtliche K&#246;rperschaften 
&#8211; &#61608; privatrechtliche Einrichtungen, die im &#246;ffentlichen Auftrag t&#228;tig werden, sofern 
sie ausreichende finanzielle Garantien bieten
&#8211; &#61608; privatrechtliche Einrichtungen eines Mitgliedstaats, die mit der Einrichtung 
einer &#246;ffentlich-privaten Partnerschaft betraut werden und die ausreichende 
finanzielle Garantien bieten 
&#8211; &#61608; Personen, die mit der Durchf&#252;hrung bestimmter Ma&#223;nahmen im Bereich der 
GASP im Rahmen des Titels V EUV betraut und in dem ma&#223;geblichen 
Basisrechtsakt benannt sind 
&#8211; Falls mehrere Methoden der Mittelverwaltung angegeben werden, ist dies unter &#8222;Bemerkungen&#8220; n&#228;her zu 
erl&#228;utern.
Bemerkungen
65 Erl&#228;uterungen zu den Methoden der Mittelverwaltung und Verweise auf die Haushaltsordnung enth&#228;lt 
die Website BudgWeb (in franz&#246;sischer und englischer Sprache): 
http://www.cc.cec/budg/man/budgmanag/budgmanag en.html.
2. VERWALTUNGSMA&#7838;NAHMEN 
2.1. &#220;berwachung und Berichterstattung 
Bitte geben Sie an, wie oft und unter welchen Bedingungen diese T&#228;tigkeiten erfolgen.
Die Verordnung wird f&#252;nf Jahre nach ihrem Inkrafttreten &#252;berpr&#252;ft und bewertet. Die 
Kommission wird dem Europ&#228;ischen Parlament, dem Rat sowie dem Europ&#228;ischen 
Wirtschafts- und Sozialausschuss &#252;ber die Ergebnisse der Bewertung Bericht 
erstatten.
2.2. Verwaltungs- und Kontrollsystem(e) 
2.2.1. Begr&#252;ndung der Methode(n) der Mittelverwaltung, des 
Durchf&#252;hrungsmechanismus/der Durchf&#252;hrungsmechanismen f&#252;r die Finanzierung, 
der Zahlungsmodalit&#228;ten und der Kontrollstrategie, wie vorgeschlagen
Mit der Verordnung wird eine neue Politik in Bezug auf harmonisierte Vorschriften 
f&#252;r die Bereitstellung von Systemen der k&#252;nstlichen Intelligenz im Binnenmarkt 
unter Wahrung der Sicherheit und der Grundrechte festgelegt. Diese neuen 
Vorschriften erfordern ein Koh&#228;renzverfahren f&#252;r die grenz&#252;berschreitende 
Anwendung der Verpflichtungen aus dieser Verordnung in Form einer neuen 
Beratergruppe, die die T&#228;tigkeiten der nationalen Beh&#246;rden koordiniert. 
Um diesen neuen Aufgaben gerecht zu werden, m&#252;ssen die Dienststellen der 
Kommission angemessen mit Ressourcen ausgestattet werden. Die Durchsetzung der 
neuen Verordnung erfordert sch&#228;tzungsweise 10 VZ&#196; (5 VZ&#196; f&#252;r die Unterst&#252;tzung 
der T&#228;tigkeiten des Ausschusses und 5 VZ&#196; f&#252;r den Europ&#228;ischen 
Datenschutzbeauftragten, der als notifizierende Stelle f&#252;r KI-Systeme fungiert, die 
von einer Einrichtung der Europ&#228;ischen Union eingesetzt werden).
2.2.2. Angaben zu den ermittelten Risiken und dem/den zu deren Eind&#228;mmung 
eingerichteten System(en) der internen Kontrolle
Um sicherzustellen, dass die Mitglieder des Ausschusses auf der Grundlage von 
Fakten fundierte Analysen durchf&#252;hren k&#246;nnen, ist vorgesehen, dass der Ausschuss 
durch die Verwaltungsstruktur der Kommission unterst&#252;tzt wird und dass eine 
Expertengruppe eingesetzt wird, die erforderlichenfalls zus&#228;tzliches Fachwissen zur 
Verf&#252;gung stellt.
2.2.3. Sch&#228;tzung und Begr&#252;ndung der Kosteneffizienz der Kontrollen (Verh&#228;ltnis zwischen 
den Kontrollkosten und dem Wert der betreffenden verwalteten Mittel) sowie 
Bewertung des erwarteten Ausma&#223;es des Fehlerrisikos (bei Zahlung und beim 
Abschluss)
F&#252;r die Sitzungskosten erscheinen angesichts des geringen Werts pro Transaktion 
(z. B. Erstattung der Reisekosten eines Delegierten f&#252;r eine Sitzung) die &#252;blichen 
Kontrollverfahren ausreichend. In Bezug auf die Entwicklung der Datenbank verf&#252;gt 
die GD CNECT durch zentrale Vergabet&#228;tigkeiten bei der &#246;ffentlichen 
Auftragsvergabe &#252;ber ein starkes internes Kontrollsystem.
2.3. Pr&#228;vention von Betrug und Unregelm&#228;&#223;igkeiten 
Bitte geben Sie an, welche Pr&#228;ventions- und Schutzma&#223;nahmen, z. B. im Rahmen der 
Betrugsbek&#228;mpfungsstrategie, bereits bestehen oder angedacht sind.
Die f&#252;r die Kommission geltenden Betrugsbek&#228;mpfungsma&#223;nahmen gelten auch f&#252;r 
die zus&#228;tzlichen Mittel, die f&#252;r diese Verordnung erforderlich werden.
D
E
0 
D
E
3.
 
G
E
S
C
H
&#196;
T
Z
T
E
F
IN
A
N
Z
IE
L
L
E
A
U
S
W
IR
K
U
N
G
E
N
D
E
S
V
O
R
S
C
H
L
A
G
S
/D
E
R
IN
IT
IA
T
IV
E
 
3.
1.
 
B
et
ro
ff
en
e 
R
u
b
ri
k
(e
n
) 
d
es
 M
eh
rj
&#228;h
ri
ge
n
 F
in
an
zr
ah
m
en
s 
u
n
d
 A
u
sg
a
b
en
li
n
ie
(n
) 
im
 H
au
sh
al
ts
p
la
n
 
&#61623;
B
es
te
h
en
de
 H
au
sh
al
ts
li
ni
en
 
In
 d
er
 R
ei
he
n
fo
lg
e 
de
r 
R
ub
ri
ke
n 
de
s 
M
eh
rj
&#228;h
ri
ge
n 
F
in
an
zr
ah
m
en
s 
un
d 
de
r 
H
au
sh
al
ts
li
ni
en
. 
R
u
b
ri
k 
d
es
 
M
eh
rj
&#228;h
ri
g
en
 
F
in
an
zr
ah
m
en
s
H
au
sh
al
ts
li
ni
e
A
rt
 d
er
 
A
u
sg
ab
e
F
in
an
zi
er
u
n
gs
b
ei
tr
&#228;g
e
N
u
m
m
er
G
M
/N
G
M
6
vo
n
 
E
F
T
A
-
L
&#228;n
d
er
n
7
vo
n
 
K
an
d
id
at
en
l&#228;
n
d
er
n6
vo
n
 
D
ri
tt
l&#228;
n
d
e
rn
n
ac
h
 A
rt
ik
el
1 
A
b
sa
tz
B
uc
h
st
ab
e 
b 
d
er
 
H
au
sh
al
ts
or
dn
u
n
g
20
2
 V
er
w
al
tu
ng
sa
us
ga
b
en
N
G
M
N
E
IN
N
E
IN
N
E
IN
N
E
IN
02
4
 K
&#252;n
st
li
ch
e 
In
te
ll
ig
en
z
G
M
JA
N
E
IN
N
E
IN
N
E
IN
02
1
 0
U
nt
er
st
&#252;t
zu
ng
sa
us
ga
be
n
 
f&#252;
r 
da
s 
P
ro
gr
am
m
 &#8222;
D
ig
it
al
es
 E
ur
op
a&#8220;
N
G
M
JA
N
E
IN
N
E
IN
N
E
IN
3.
2.
 
G
es
ch
&#228;t
zt
e 
fi
n
an
zi
el
le
 A
u
sw
ir
k
u
n
ge
n
 d
es
 V
or
sc
h
la
gs
 a
u
f 
d
ie
 M
it
te
l 
3.
2.
1.
 
&#220;
be
rs
ic
ht
 &#252;
b
er
 d
ie
 g
es
ch
&#228;t
zt
en
 A
us
w
ir
ku
ng
en
 a
uf
 d
ie
 A
us
ga
be
n 
f&#252;
r 
op
er
a
ti
ve
 M
it
te
l 
&#8211;
&#61608;
 F
&#252;r
 d
en
 V
or
sc
hl
ag
/d
ie
 I
n
it
ia
ti
ve
 w
er
de
n
 k
ei
n
e 
op
er
at
iv
en
 M
it
te
l 
be
n&#246;
ti
gt
. 
&#8211;
X
 
F
&#252;r
 d
en
 V
or
sc
hl
ag
/d
ie
 I
n
it
ia
ti
ve
 w
er
de
n 
di
e 
fo
lg
en
de
n 
op
er
at
iv
en
 M
it
te
l 
b
en
&#246;t
ig
t:
in
 M
io
. 
E
U
R
 (
 D
ez
im
al
st
el
le
n)
G
M
 =
 G
et
re
nn
te
 M
it
te
l/
N
G
M
 =
 N
ic
ht
ge
tr
en
nt
e 
M
it
te
l.
E
F
T
A
: 
E
ur
o
p
&#228;i
sc
he
 F
re
ih
an
d
el
sa
ss
o
zi
at
io
n.
K
an
d
id
at
en
l&#228;
nd
er
 u
nd
 g
eg
eb
en
en
fa
ll
s 
p
o
te
nz
ie
ll
e 
K
an
d
id
at
en
 d
es
 W
es
tb
al
ka
ns
.
D
ru
ck
sa
ch
e
8/
- 1
 -
D
E
1 
D
E
R
u
b
ri
k
 d
es
 M
eh
rj
&#228;h
ri
ge
n
 F
in
an
zr
ah
m
en
s
G
D
: 
C
N
E
C
T
Ja
hr
0
2
Ja
hr
0
3
Ja
hr
0
4
Ja
hr
0
5
Ja
hr
0
6
Ja
hr
0
76
IN
S
G
E
S
A
M
T
&#61599; 
O
pe
ra
ti
ve
 M
it
te
l
H
au
sh
al
ts
li
ni
e7
 0
 0
 0
V
er
p
fl
ic
h
tu
n
ge
n
(1
a)
1,
0
,0
0
Z
ah
lu
n
ge
n
(2
a)
0,
0
0,
0
0,
0
0,
0
0,
0
,0
0
H
au
sh
al
ts
li
ni
e
V
er
p
fl
ic
h
tu
n
ge
n
(1
b)
Z
ah
lu
n
ge
n
(2
b)
A
us
 
de
r 
D
ot
at
io
n 
be
st
im
m
te
r 
sp
ez
if
is
ch
er
P
ro
gr
am
m
e 
fi
na
nz
ie
rt
e
V
er
w
al
tu
ng
sa
us
ga
be
n7
H
au
sh
al
ts
li
ni
e
2
1
0
1
(3
)
,2
0
,2
0
,2
0
,2
0
,2
0
,2
0
M
it
te
l 
IN
S
G
E
S
A
M
T
 f
&#252;
r 
d
ie
 G
D
 C
N
E
C
T
V
er
p
fl
ic
h
tu
n
ge
n
=
1a
+
1b
 +
1
,2
0
,2
0
,2
0
,2
0
,2
0
Z
ah
lu
n
ge
n
=
2a
+
2b
 
+
0
,8
0
,3
0
,3
0
,3
0
,3
0
,2
0
&#61599;O
pe
ra
ti
ve
 M
it
te
l 
IN
S
G
E
S
A
M
T
V
er
p
fl
ic
h
tu
n
ge
n
(4
)
,0
0
,0
0
Z
ah
lu
n
ge
n
(5
)
,6
0
,1
0
,1
0
,1
0
,1
0
,0
0
&#61599;A
us
 
de
r 
D
ot
at
io
n 
b
es
ti
m
m
te
r 
sp
ez
if
is
ch
er
 
P
ro
gr
am
m
e 
fi
n
an
zi
er
te
 
V
er
w
al
tu
ng
sa
us
ga
be
n 
IN
S
G
E
S
A
M
T
(6
)
,2
0
,2
0
,2
0
,2
0
,2
0
,2
0
V
o
rl
&#228;u
fi
g 
un
d
 a
b
h&#228;
ng
ig
 v
o
n 
d
er
 V
er
f&#252;
gb
ar
ke
it
 v
o
n 
H
au
sh
al
ts
m
it
te
ln
.
G
em
&#228;&#223;
 d
em
 o
ff
iz
ie
ll
en
 E
in
g
li
ed
er
un
g
sp
la
n.
T
ec
hn
is
ch
e 
u
nd
/o
d
er
 a
d
m
in
is
tr
at
iv
e 
H
il
fe
 u
nd
 A
us
ga
b
en
 z
u
r 
U
nt
er
st
&#252;t
zu
n
g 
d
er
 D
ur
ch
f&#252;
h
ru
n
g 
vo
n 
P
ro
gr
am
m
en
 b
zw
. 
M
a&#223;
na
h
m
en
 d
er
 E
U
 (
vo
rm
al
ig
e 
B
A
-L
in
ie
n)
, 
in
d
ir
ek
te
 F
o
rs
ch
un
g,
 d
ir
ek
te
 F
o
rs
ch
u
n
g.
D
ru
ck
sa
ch
e
8/
- 1
 -
D
E
2 
D
E
M
it
te
l 
IN
S
G
E
S
A
M
T
 u
n
te
r 
R
U
B
R
IK
 d
es
 m
eh
rj
&#228;h
ri
ge
n
F
in
an
zr
ah
m
en
s
V
er
p
fl
ic
h
tu
n
ge
n
=
4+
1
,2
0
,2
0
,2
0
,2
0
,2
0
,2
0
Z
ah
lu
n
ge
n
=
5+
0
,8
0
,3
0
,3
0
,3
0
,3
0
,2
0
W
en
n
 d
er
 V
or
sc
h
la
g/
d
ie
 I
n
it
ia
ti
ve
 m
eh
re
re
 R
u
b
ri
k
en
 b
et
ri
ff
t,
 i
st
 d
er
 v
or
st
eh
en
d
e 
A
b
sc
h
n
it
t 
zu
 w
ie
d
er
h
o
le
n
:
&#61599;O
pe
ra
ti
ve
 
M
it
te
l 
IN
S
G
E
S
A
M
T
 
(a
ll
e 
op
er
at
iv
en
 R
ub
ri
ke
n
)
V
er
p
fl
ic
h
tu
n
ge
n
(4
)
Z
ah
lu
n
ge
n
(5
)
&#61599; 
A
us
 
de
r 
D
ot
at
io
n 
be
st
im
m
te
r 
sp
ez
if
is
ch
er
 
P
ro
g
ra
m
m
e 
fi
n
an
zi
er
te
 
V
er
w
al
tu
ng
sa
us
ga
be
n 
IN
S
G
E
S
A
M
T
 
(a
ll
e 
op
er
at
iv
en
 R
ub
ri
ke
n
)
(6
)
M
it
te
l 
IN
S
G
E
S
A
M
T
 u
n
te
r 
R
U
B
R
IK
E
N
 b
is
 d
es
 m
eh
rj
&#228;h
ri
ge
n 
F
in
an
zr
ah
m
en
s
(R
ef
er
en
zb
et
ra
g)
V
er
p
fl
ic
h
tu
n
ge
n
=
4+
Z
ah
lu
n
ge
n
=
5+
D
ru
ck
sa
ch
e
8/
- 1
 -
D
E
3 
D
E
R
u
b
ri
k
 d
es
 M
eh
rj
&#228;h
ri
ge
n
 F
in
an
zr
ah
m
en
s
V
er
w
al
tu
ng
sa
us
ga
be
n
Z
um
 A
us
f&#252;
ll
en
 d
ie
se
s 
T
ei
ls
 i
st
 d
ie
 &#8222;
T
ab
el
le
 f
&#252;r
 V
er
w
al
tu
ng
sa
us
ga
b
en
&#8220; 
zu
 v
er
w
en
d
en
, d
ie
 z
u
er
st
 i
n 
de
n 
A
nh
an
g 
de
s 
F
in
an
zb
o
ge
ns
 z
u 
R
ec
ht
sa
kt
en
 (
A
nh
an
g 
V
 d
er
 I
nt
er
n
en
 V
or
sc
hr
if
te
n
),
 d
er
 f
&#252;
r 
di
e 
di
en
st
st
el
le
n&#252;
be
rg
re
if
en
de
 K
on
su
lt
at
io
n 
in
 D
E
C
ID
E
 h
o
ch
ge
la
de
n 
w
ir
d,
 
au
fg
en
om
m
en
 w
ir
d.
in
 M
io
. 
E
U
R
 (
 D
ez
im
al
st
el
le
n)
Ja
hr
0
3
Ja
hr
0
4
Ja
hr
0
5
Ja
hr
0
6
Ja
h
r
0
N
ac
h
0
7
IN
S
G
E
S
A
M
T
G
D
: 
C
N
E
C
T
&#61599; 
P
er
so
na
l
,7
0
,7
0
,7
0
,7
0
,7
0
,7
0
,8
0
&#61599; 
S
o
ns
ti
ge
 V
er
w
al
tu
ng
sa
us
ga
be
n
,0
0
,0
0
,0
0
,0
0
,0
0
,0
0
,0
0
G
D
 C
N
E
C
T
 I
N
S
G
E
S
A
M
T
M
it
te
l
,7
0
,7
0
,7
0
,7
0
,7
0
,7
0
,8
0
E
ur
op
&#228;i
sc
he
r 
D
at
en
sc
hu
tz
be
au
ft
ra
gt
er
&#61599; 
P
er
so
na
l
,7
0
,7
0
,7
0
,7
0
,7
0
,7
0
,8
0
&#61599; 
S
o
ns
ti
ge
 V
er
w
al
tu
ng
sa
us
ga
be
n 
G
E
S
A
M
T
 E
D
S
B
M
it
te
l
0,
0
,7
0
,7
0
0,
0
,7
0
,7
0
,8
0
M
it
te
l 
IN
S
G
E
S
A
M
T
u
n
te
r 
d
er
 R
U
B
R
IK
d
es
 M
eh
rj
&#228;h
ri
ge
n 
F
in
an
zr
ah
m
en
s
(V
er
p
fl
ic
h
tu
n
ge
n
 i
n
sg
es
. 
=
 Z
ah
lu
n
ge
n
 i
n
sg
es
.)
,5
0
,5
0
,5
0
,5
0
,5
0
,5
0
,6
0
in
 M
io
. 
E
U
R
 (
 D
ez
im
al
st
el
le
n)
Ja
hr
0
2
Ja
hr
0
3
Ja
hr
0
4
Ja
hr
0
5
Ja
h
r
0
Ja
h
r
0
IN
S
G
E
S
A
M
T
A
ll
e 
Z
ah
le
n 
in
 d
ie
se
r 
S
p
al
te
 s
in
d
 v
o
rl
&#228;u
fi
g 
u
nd
 v
o
n 
d
er
 F
o
rt
f&#252;
hr
un
g 
d
er
 P
ro
gr
am
m
e 
un
d
 d
er
 V
er
f&#252;
gb
ar
ke
it
 v
o
n 
M
it
te
ln
 a
b
h&#228;
n
gi
g.
D
ru
ck
sa
ch
e
8/
- 1
 -
D
E
4 
D
E
M
it
te
l 
IN
S
G
E
S
A
M
T
 u
n
te
r
R
U
B
R
IK
E
N
 b
is
 d
es
 m
eh
rj
&#228;h
ri
ge
n 
F
in
an
zr
ah
m
en
s
V
er
p
fl
ic
h
tu
n
ge
n
,7
0
,7
0
,7
0
,7
0
,7
0
,8
0
Z
ah
lu
n
ge
n
,3
0
,8
0
,8
0
,8
0
,8
0
,8
0
D
ru
ck
sa
ch
e
8/
- 1
 -
D
E
5 
D
E
3.
2.
2.
 
G
es
ch
&#228;t
zt
e 
E
rg
eb
ni
ss
e,
 d
ie
 m
it
 o
pe
ra
ti
ve
n 
M
it
te
ln
 f
in
an
zi
er
t 
w
er
d
en
 
M
it
te
l 
f&#252;
r 
V
er
p
fl
ic
ht
un
ge
n 
in
 M
io
. 
E
U
R
 (
 D
ez
im
al
st
el
le
n)
Z
ie
le
 u
n
d
 
E
rg
eb
n
is
se
 a
n
g
eb
en
 
&#61682;
Ja
h
r
0
Ja
h
r
0
Ja
h
r
0
Ja
h
r
0
Ja
h
r
0
Ja
h
r
0
N
ac
h
0
7
IN
S
G
E
S
A
M
T
E
R
G
E
B
N
IS
S
E
A
rt
D
u
rc
h
sc
h
n
it
ts
ko
st
e
n
Anzahl
K
o
st
e
n
Anzahl
K
o
st
e
n
Anzahl
K
o
st
en
Anzahl
K
o
st
e
n
Anzahl
K
o
st
e
n
Anzahl
K
o
st
e
n
Anzahl
K
o
st
e
n
G
es
am
tz
ah
l
G
es
am
tk
o
st
en
E
IN
Z
E
L
Z
IE
L
 N
r.
7
&#8230;
 
D
at
en
b
an
k
1
,0
0
1
1
0
,1
0
1
,0
0
S
it
zu
n
gs
er
ge
b
n
is
se
0
,2
0
0
,2
0
0
,2
0
0
,2
0
0
,2
0
0
,2
0
0
,0
0
K
o
m
m
u
n
ik
at
io
n
sm
a&#223;
n
ah
m
en
0
,0
0
0
,0
0
0
,0
0
0
,0
0
0
,0
0
0
,0
0
0
,0
0
Z
w
is
ch
en
su
m
m
e 
f&#252;
r 
E
in
ze
lz
ie
l 
N
r.
E
IN
Z
E
L
Z
IE
L
 N
r.
 .
..
- 
E
rg
eb
n
is
Z
w
is
ch
en
su
m
m
e 
f&#252;
r 
E
in
ze
lz
ie
l 
N
r.
IN
S
G
E
S
A
M
T
3
,2
0
3
,2
0
3
,2
0
3
,2
0
3
,2
0
3
,1
0
5
,2
0
A
ll
e 
Z
ah
le
n 
in
 d
ie
se
r 
S
p
al
te
 s
in
d
 v
o
rl
&#228;u
fi
g 
u
nd
 v
o
n 
d
er
 F
o
rt
f&#252;
hr
un
g 
d
er
 P
ro
gr
am
m
e 
un
d
 d
er
 V
er
f&#252;
gb
ar
ke
it
 v
o
n 
M
it
te
ln
 a
b
h&#228;
n
gi
g.
W
ie
 u
nt
er
.4
.2
. 
(&#8222;
E
in
ze
lz
ie
l(
e)
&#8230;
&#8220;)
 b
es
ch
ri
eb
en
.
D
ru
ck
sa
ch
e
8/
- 1
 -
DE 116 DE
3.2.3. &#220;bersicht &#252;ber die gesch&#228;tzten Auswirkungen auf die Verwaltungsmittel 
&#8211; &#61608; F&#252;r den Vorschlag/die Initiative werden keine Verwaltungsmittel ben&#246;tigt. 
&#8211; X F&#252;r den Vorschlag/die Initiative werden die folgenden Verwaltungsmittel 
ben&#246;tigt:
in Mio. EUR (3 Dezimalstellen)
Jahr
Jahr
Jahr
Jahr
Jahr
Jahr
J&#228;hrlich 
nach 
202775
INSGESAMT
RUBRIK 7 des 
mehrj&#228;hrigen 
Finanzrahmens
Personal 1,520 1,520 1,520 1,520 1,520 1,520 7,600
Sonstige 
Verwaltungsausgaben
0,010 0,010 0,010 0,010 0,010 0,010 0,050
Zwischensumme 
RUBRIK 7 des 
Mehrj&#228;hrigen 
Finanzrahmens
1,530 1,530 1,530 1,530 1,530 1,530 7,650
Au&#223;erhalb der 
RUBRIK 776des 
mehrj&#228;hrigen 
Finanzrahmens
Personal
Sonstige 
Verwaltungsausgaben
0,240 0,240 0,240 0,240 0,240 0,240 1,20
Zwischensumme 
au&#223;erhalb der 
RUBRIK 7 des 
mehrj&#228;hrigen 
Finanzrahmens
0,240 0,240 0,240 0,240 0,240 0,240 1,20
INSGESAMT 1,770 1,770 1,770 1,770 1,770 1,770 8,850
Der Mittelbedarf f&#252;r Personal- und sonstige Verwaltungsausgaben wird durch der Verwaltung der Ma&#223;nahme zugeordnete 
Mittel der GD oder GD-interne Personalumschichtung gedeckt. Hinzu kommen etwaige zus&#228;tzliche Mittel, die der f&#252;r die 
Verwaltung der Ma&#223;nahme zust&#228;ndigen GD nach Ma&#223;gabe der verf&#252;gbaren Mittel im Rahmen der j&#228;hrlichen 
Mittelzuweisung zugeteilt werden.
75 Alle Zahlen in dieser Spalte sind vorl&#228;ufig und von der Fortf&#252;hrung der Programme und der Verf&#252;gbarkeit von 
Mitteln abh&#228;ngig.
76 Technische und/oder administrative Hilfe und Ausgaben zur Unterst&#252;tzung der Durchf&#252;hrung von 
Programmen bzw. Ma&#223;nahmen der EU (vormalige BA-Linien), indirekte Forschung, direkte 
Forschung.
3.2.3.1. Gesch&#228;tzter Personalbedarf 
&#8211; &#61608; F&#252;r den Vorschlag/die Initiative wird kein Personal ben&#246;tigt. 
&#8211; X F&#252;r den Vorschlag/die Initiative wird folgendes Personal ben&#246;tigt: 
Sch&#228;tzung in Vollzeit&#228;quivalenten
Jahr
Jahr
Jahr
2026 2027
Nach 
202777
&#61599; Im Stellenplan vorgesehene Planstellen (Beamte und Bedienstete auf Zeit)
20 01 02 01 (am Sitz und in den Vertretungen der Kommission) 10 10 10 10 10 10
20 01 02 03 (in den Delegationen)
01 01 01 01 (indirekte Forschung)
01 01 01 11 (direkte Forschung)
Sonstige Haushaltslinien (bitte angeben)
&#61599; Externes Personal (in Vollzeit&#228;quivalenten &#8211; VZ&#196;)
20 02 01 (VB, ANS und LAK der Globaldotation)
20 02 03 (VB, &#214;B, ANS, LAK und JFD in den Delegationen)
XX 01 xx yy zz
- am Sitz
- in den Delegationen
01 01 01 02 (VB, ANS und LAK &#8211; indirekte Forschung)
01 01 01 12 (VB, ANS und LAK &#8211; direkte Forschung)
Sonstige Haushaltslinien (bitte angeben)
INSGESAMT 10 10 10 10 10 10
XX steht f&#252;r den jeweiligen Politikbereich bzw. Haushaltstitel. 
Der Personalbedarf wird durch der Verwaltung der Ma&#223;nahme zugeordnetes Personal der GD oder GD-interne 
Personalumschichtung gedeckt. Hinzu kommen etwaige zus&#228;tzliche Mittel, die der f&#252;r die Verwaltung der 
Ma&#223;nahme zust&#228;ndigen GD nach Ma&#223;gabe der verf&#252;gbaren Mittel im Rahmen der j&#228;hrlichen Mittelzuweisung 
zugeteilt werden.
Der EDSB wird voraussichtlich die H&#228;lfte der erforderlichen Ressourcen bereitstellen.
Beschreibung der auszuf&#252;hrenden Aufgaben:
Beamte und Zeitbedienstete Zur Vorbereitung von insgesamt 13&#8211;16 Sitzungen, zum Entwurf von Berichten, zur
Fortsetzung der politischen Arbeit, z. B. in Bezug auf k&#252;nftige &#196;nderungen der Liste 
der Hochrisiko-KI-Anwendungen, und zur Pflege der Beziehungen zu den Beh&#246;rden 
der Mitgliedstaaten werden vier AD VZ&#196; und ein AST VZ&#196; erforderlich sein.
F&#252;r KI-Systeme, die von den EU-Organen entwickelt werden, ist der Europ&#228;ische
Datenschutzbeauftragte zust&#228;ndig. Auf der Grundlage der bisherigen Erfahrungen 
kann davon ausgegangen werden, dass f&#252;r die Wahrnehmung der Aufgaben des EDSB 
im Rahmen des Gesetzesentwurfs f&#252;nf AD VZ&#196; ben&#246;tigt werden.
Externes Personal
77 Alle Zahlen in dieser Spalte sind vorl&#228;ufig und von der Fortf&#252;hrung der Programme und der 
Verf&#252;gbarkeit von Mitteln abh&#228;ngig. 
78 VB = Vertragsbedienstete, &#214;B = &#246;rtliche Bedienstete, ANS = abgeordnete nationale Sachverst&#228;ndige, 
LAK = Leiharbeitskr&#228;fte, JFD = Juniorfachkr&#228;fte in Delegationen. 
79 Teilobergrenze f&#252;r aus operativen Mitteln finanziertes externes Personal (vormalige BA-Linien).
3.2.4. Vereinbarkeit mit dem Mehrj&#228;hrigen Finanzrahmen 
Der Vorschlag/Die Initiative 
&#8211; X kann durch Umschichtungen innerhalb der entsprechenden Rubrik des 
Mehrj&#228;hrigen Finanzrahmens (MFR) in voller H&#246;he finanziert werden.
Keine Anpassung erforderlich.
&#8211; &#61608; erfordert die Inanspruchnahme des verbleibenden Spielraums unter der 
einschl&#228;gigen Rubrik des MFR und/oder den Einsatz der besonderen Instrumente 
im Sinne der MFR-Verordnung.
Bitte erl&#228;utern Sie den Bedarf unter Angabe der betreffenden Rubriken und Haushaltslinien, der 
entsprechenden Betr&#228;ge und der vorgeschlagenen einzusetzenden Instrumente.
&#8211; &#61608; erfordert eine Revision des MFR.
Bitte erl&#228;utern Sie den Bedarf unter Angabe der betreffenden Rubriken und Haushaltslinien sowie der 
entsprechenden Betr&#228;ge.
3.2.5. Finanzierungsbeteiligung Dritter 
Der Vorschlag/Die Initiative 
&#8211; X sieht keine Kofinanzierung durch Dritte vor. 
&#8211; &#61608; sieht folgende Kofinanzierung durch Dritte vor:
Mittel in Mio. EUR (3 Dezimalstellen)
Jahr
N80
Jahr
N+1
Jahr
N+2
Jahr
N+3
Bei l&#228;nger andauernden 
Auswirkungen (siehe 1.6.) bitte 
weitere Spalten einf&#252;gen
Insgesamt
Kofinanzierende 
Einrichtung
Kofinanzierung 
INSGESAMT
80 Das Jahr N ist das Jahr, in dem mit der Umsetzung des Vorschlags/der Initiative begonnen wird. Bitte 
ersetzen Sie &#8222;N&#8220; durch das voraussichtlich erste Jahr der Umsetzung (z. B. 2021). Dasselbe gilt f&#252;r die 
folgenden Jahre.
3.3. Gesch&#228;tzte Auswirkungen auf die Einnahmen 
&#8211; &#61608; Der Vorschlag/Die Initiative wirkt sich auf die Einnahmen aus, und zwar: 
&#8211; &#61608; Der Vorschlag/Die Initiative wirkt sich auf die Einnahmen aus, und zwar: 
&#8211; &#61608; auf die &#252;brigen Einnahmen 
&#8211; &#61608; auf die &#252;brigen Einnahmen 
&#8211; Bitte geben Sie an, ob die Einnahmen bestimmten Ausgabenlinien 
zugewiesen sind. &#61608;
in Mio. EUR (3 Dezimalstellen)
Einnahmenlinie: 
F&#252;r das 
laufende 
Haushaltsjahr 
zur Verf&#252;gung 
stehende 
Mittel
Auswirkungen des Vorschlags/der Initiative
Jahr
N
Jahr
N+1
Jahr
N+2
Jahr
N+3
Bei l&#228;nger andauernden Auswirkungen 
(siehe 1.6.) bitte weitere Spalten 
einf&#252;gen.
Artikel &#8230;.
Bitte geben Sie f&#252;r die zweckgebundenen Einnahmen die betreffende(n) Ausgabenlinie(n) im 
Haushaltsplan an.
Sonstige Anmerkungen (bei der Ermittlung der Auswirkungen auf die Einnahmen verwendete 
Methode/Formel oder weitere Informationen).
81 Bei den traditionellen Eigenmitteln (Z&#246;lle, Zuckerabgaben) sind die Betr&#228;ge netto, d. h. abz&#252;glich 20 % 
f&#252;r Erhebungskosten, anzugeben.
DE DE
EUROP&#196;ISCHE
KOMMISSION
Br&#252;ssel, den 21.4.2021  
COM(2021) 206 final
ANNEXES 1 to 9
ANH&#196;NGE
des
Vorschlags f&#252;r eine Verordnung des Europ&#228;ischen Parlaments und des Rates
ZUR FESTLEGUNG HARMONISIERTER VORSCHRIFTEN F&#220;R K&#220;NSTLICHE 
INTELLIGENZ (GESETZ &#220;BER K&#220;NSTLICHE INTELLIGENZ) UND ZUR 
&#196;NDERUNG BESTIMMTER RECHTSAKTE DER UNION  
{SEC(2021) 167 final} - {SWD(2021) 84 final} - {SWD(2021) 85 final}
ANHANG I 
TECHNIKEN UND KONZEPTE DER K&#220;NSTLICHEN INTELLIZENZ 
gem&#228;&#223; Artikel 3 Absatz 1 
a) Konzepte des maschinellen Lernens, mit beaufsichtigtem, unbeaufsichtigtem und 
best&#228;rkendem Lernen unter Verwendung einer breiten Palette von Methoden, 
einschlie&#223;lich des tiefen Lernens (Deep Learning); 
b) Logik- und wissensgest&#252;tzte Konzepte, einschlie&#223;lich Wissensrepr&#228;sentation, 
induktiver (logischer) Programmierung, Wissensgrundlagen, Inferenz- und 
Deduktionsmaschinen, (symbolischer) Schlussfolgerungs- und Expertensysteme; 
c) Statistische Ans&#228;tze, Bayessche Sch&#228;tz-, Such- und Optimierungsmethoden.
ANHANG II 
LISTE DER HARMONISIERUNGSRECHTSVORSCHRIFTEN DER UNION 
Abschnitt A &#8211; Liste der Harmonisierungsrechtsvorschriften der Union auf der 
Grundlage des neuen Rechtsrahmens 
1. Richtlinie 2006/42/EG des Europ&#228;ischen Parlaments und des Rates vom 17. Mai 
2006 &#252;ber Maschinen und zur &#196;nderung der Richtlinie 95/16/EG (ABl. L 157 vom 
9.6.2006, S. 24) [aufgehoben durch die Maschinenverordnung]; 
2. Richtlinie 2009/48/EG des Europ&#228;ischen Parlaments und des Rates vom 18. Juni 
2009 &#252;ber die Sicherheit von Spielzeug (ABl. L 170 vom 30.6.2009, S. 1); 
3. Richtlinie 2013/53/EU des Europ&#228;ischen Parlaments und des Rates vom 
20. November 2013 &#252;ber Sportboote und Wassermotorr&#228;der und zur Aufhebung der 
Richtlinie 94/25/EG (ABl. L 354 vom 28.12.2013, S. 90); 
4. Richtlinie 2014/33/EU des Europ&#228;ischen Parlaments und des Rates vom 26. Februar 
2014 zur Angleichung der Rechtsvorschriften der Mitgliedstaaten &#252;ber Aufz&#252;ge und 
Sicherheitsbauteile f&#252;r Aufz&#252;ge (ABl. L 96 vom 29.3.2014, S. 251); 
5. Richtlinie 2014/34/EU des Europ&#228;ischen Parlaments und des Rates vom 26. Februar 
2014 zur Harmonisierung der Rechtsvorschriften der Mitgliedstaaten f&#252;r Ger&#228;te und 
Schutzsysteme zur bestimmungsgem&#228;&#223;en Verwendung in explosionsgef&#228;hrdeten 
Bereichen (ABl. L 96 vom 29.3.2014, S. 309); 
6. Richtlinie 2014/53/EU des Europ&#228;ischen Parlaments und des Rates vom 16. April 
2014 &#252;ber die Harmonisierung der Rechtsvorschriften der Mitgliedstaaten &#252;ber die 
Bereitstellung von Funkanlagen auf dem Markt und zur Aufhebung der 
Richtlinie 1999/5/EG (ABl. L 153 vom 22.5.2014, S. 62); 
7. Richtlinie 2014/68/EU des Europ&#228;ischen Parlaments und des Rates vom 15. Mai 
2014 zur Harmonisierung der Rechtsvorschriften der Mitgliedstaaten &#252;ber die 
Bereitstellung von Druckger&#228;ten auf dem Markt (ABl. L 189 vom 27.6.2014, 
S. 164); 
8. Verordnung (EU) 2016/424 des Europ&#228;ischen Parlaments und des Rates vom 
9. M&#228;rz 2016 &#252;ber Seilbahnen und zur Aufhebung der Richtlinie 2000/9/EG (ABl. 
L 81 vom 31.3.2016, S. 1); 
9. Verordnung (EU) 2016/425 des Europ&#228;ischen Parlaments und des Rates vom 
9. M&#228;rz 2016 &#252;ber pers&#246;nliche Schutzausr&#252;stungen und zur Aufhebung der 
Richtlinie 89/686/EWG des Rates (ABl. L 81 vom 31.3.2016, S. 51); 
10. Verordnung (EU) 2016/426 des Europ&#228;ischen Parlaments und des Rates vom 
9. M&#228;rz 2016 &#252;ber Ger&#228;te zur Verbrennung gasf&#246;rmiger Brennstoffe und zur 
Aufhebung der Richtlinie 2009/142/EG (ABl. L 81 vom 31.3.2016, S. 99); 
11. Verordnung (EU) 2017/745 des Europ&#228;ischen Parlaments und des Rates vom 
5. April 2017 &#252;ber Medizinprodukte, zur &#196;nderung der Richtlinie 2001/83/EG, der 
Verordnung (EG) Nr. 178/2002 und der Verordnung (EG) Nr. 1223/2009 und zur 
Aufhebung der Richtlinien 90/385/EWG und 93/42/EWG des Rates (ABl. L 117 
vom 5.5.2017, S. 1); 
12. Verordnung (EU) 2017/746 des Europ&#228;ischen Parlaments und des Rates vom 
5. April 2017 &#252;ber In-vitro-Diagnostika und zur Aufhebung der Richtlinie 98/79/EG 
und des Beschlusses 2010/227/EU der Kommission (ABl. L 117 vom 5.5.2017, 
S. 176).
Abschnitt B &#8211; Liste der Harmonisierungsrechtsvorschriften der Union 
1. Verordnung (EG) Nr. 300/2008 des Europ&#228;ischen Parlaments und des Rates vom 
11. M&#228;rz 2008 &#252;ber gemeinsame Vorschriften f&#252;r die Sicherheit in der Zivilluftfahrt 
und zur Aufhebung der Verordnung (EG) Nr. 2320/2002 (ABl. L 97 vom 9.4.2008, 
S. 72); 
2. Verordnung (EU) Nr. 168/2013 des Europ&#228;ischen Parlaments und des Rates vom 
15. Januar 2013 &#252;ber die Genehmigung und Markt&#252;berwachung von zwei- oder 
dreir&#228;drigen und vierr&#228;drigen Fahrzeugen (ABl. L 60 vom 2.3.2013, S. 52); 
3. Verordnung (EU) Nr. 167/2013 des Europ&#228;ischen Parlaments und des Rates vom 
5. Februar 2013 &#252;ber die Genehmigung und Markt&#252;berwachung von land- und 
forstwirtschaftlichen Fahrzeugen (ABl. L 60 vom 2.3.2013, S. 1); 
4. Richtlinie 2014/90/EU des Europ&#228;ischen Parlaments und des Rates vom 23. Juli 
2014 &#252;ber Schiffsausr&#252;stung und zur Aufhebung der Richtlinie 96/98/EG des Rates 
(ABl. L 257 vom 28.8.2014, S. 146); 
5. Richtlinie (EU) 2016/797 des Europ&#228;ischen Parlaments und des Rates vom 11. Mai 
2016 &#252;ber die Interoperabilit&#228;t des Eisenbahnsystems in der Europ&#228;ischen Union 
(ABl. L 138 vom 26.5.2016, S. 44); 
6. Verordnung (EU) 2018/858 des Europ&#228;ischen Parlaments und des Rates vom 
30. Mai 2018 &#252;ber die Genehmigung und die Markt&#252;berwachung von 
Kraftfahrzeugen und Kraftfahrzeuganh&#228;ngern sowie von Systemen, Bauteilen und 
selbstst&#228;ndigen technischen Einheiten f&#252;r diese Fahrzeuge, zur &#196;nderung der 
Verordnungen (EG) Nr. 715/2007 und (EG) Nr. 595/2009 und zur Aufhebung der 
Richtlinie 2007/46/EG (ABl. L 151 vom 14.6.2018, S. 1); 3. Verordnung 
(EU) 2019/2144 des Europ&#228;ischen Parlaments und des Rates vom 27. November 
2019 &#252;ber die Typgenehmigung von Kraftfahrzeugen und Kraftfahrzeuganh&#228;ngern 
sowie von Systemen, Bauteilen und selbstst&#228;ndigen technischen Einheiten f&#252;r diese 
Fahrzeuge im Hinblick auf ihre allgemeine Sicherheit und den Schutz der 
Fahrzeuginsassen und von ungesch&#252;tzten Verkehrsteilnehmern, zur &#196;nderung der 
Verordnung (EU) 2018/858 des Europ&#228;ischen Parlaments und des Rates und zur 
Aufhebung der Verordnungen (EG) Nr. 78/2009, (EG) Nr. 79/2009 und (EG) 
Nr. 661/2009 des Europ&#228;ischen Parlaments und des Rates sowie der Verordnungen 
(EG) Nr. 631/2009, (EU) Nr. 406/2010, (EU) Nr. 672/2010, (EU) Nr. 1003/2010, 
(EU) Nr. 1005/2010, (EU) Nr. 1008/2010, (EU) Nr. 1009/2010, (EU) Nr. 19/2011, 
(EU) Nr. 109/2011, (EU) Nr. 458/2011, (EU) Nr. 65/2012, (EU) Nr. 130/2012, (EU) 
Nr. 347/2012, (EU) Nr. 351/2012, (EU) Nr. 1230/2012 und (EU) 2015/166 der 
Kommission (ABl. L 325 vom 16.12.2019, S. 1); 
7. Verordnung (EU) 2018/1139 des Europ&#228;ischen Parlaments und des Rates vom 4. Juli 
2018 zur Festlegung gemeinsamer Vorschriften f&#252;r die Zivilluftfahrt und zur 
Errichtung einer Agentur der Europ&#228;ischen Union f&#252;r Flugsicherheit sowie zur 
&#196;nderung der Verordnungen (EG) Nr. 2111/2005, (EG) Nr. 1008/2008, (EU) 
Nr. 996/2010, (EU) Nr. 376/2014 und der Richtlinien 2014/30/EU und 2014/53/EU 
des Europ&#228;ischen Parlaments und des Rates, und zur Aufhebung der Verordnungen 
(EG) Nr. 552/2004 und (EG) Nr. 216/2008 des Europ&#228;ischen Parlaments und des 
Rates und der Verordnung (EWG) Nr. 3922/91 des Rates (ABl. L 212 vom 
22.8.2018, S. 1), insoweit die Konstruktion, Herstellung und Vermarktung von 
Luftfahrzeugen gem&#228;&#223; Artikel 2 Absatz 1 Buchstaben a und b in Bezug auf
unbemannte Luftfahrzeuge sowie deren Motoren, Propeller, Teile und Ausr&#252;stung 
zur Fernsteuerung betroffen sind.
ANHANG III 
HOCHRISIKO-KI-SYSTEME GEM&#196;&#7838; ARTIKEL 6 ABSATZ 2 
Als Hochrisiko-KI-Systeme gem&#228;&#223; Artikel 6 Absatz 2 gelten die in folgenden Bereichen 
aufgef&#252;hrten KI-Systeme: 
1. Biometrische Identifizierung und Kategorisierung nat&#252;rlicher Personen: 
a) KI-Systeme, die bestimmungsgem&#228;&#223; f&#252;r die biometrische Echtzeit-
Fernidentifizierung und nachtr&#228;gliche biometrische Fernidentifizierung 
nat&#252;rlicher Personen verwendet werden sollen; 
2. Verwaltung und Betrieb kritischer Infrastrukturen: 
a) KI-Systeme, die bestimmungsgem&#228;&#223; als Sicherheitskomponenten in der 
Verwaltung und im Betrieb des Stra&#223;enverkehrs sowie in der Wasser-, Gas-, 
W&#228;rme- und Stromversorgung verwendet werden sollen; 
3. Allgemeine und berufliche Bildung: 
a) KI-Systeme, die bestimmungsgem&#228;&#223; f&#252;r Entscheidungen &#252;ber den Zugang oder 
die Zuweisung nat&#252;rlicher Personen zu Einrichtungen der allgemeinen und 
beruflichen Bildung verwendet werden sollen; 
b) KI-Systeme, die bestimmungsgem&#228;&#223; f&#252;r die Bewertung von Sch&#252;lern in 
Einrichtungen der allgemeinen und beruflichen Bildung und f&#252;r die Bewertung 
der Teilnehmer an &#252;blicherweise f&#252;r die Zulassung zu Bildungseinrichtungen 
erforderlichen Tests verwendet werden sollen; 
4. Besch&#228;ftigung, Personalmanagement und Zugang zur Selbstst&#228;ndigkeit: 
a) KI-Systeme, die bestimmungsgem&#228;&#223; f&#252;r die Einstellung oder Auswahl 
nat&#252;rlicher Personen verwendet werden sollen, insbesondere f&#252;r die 
Bekanntmachung freier Stellen, das Sichten oder Filtern von Bewerbungen und 
das Bewerten von Bewerbern in Vorstellungsgespr&#228;chen oder Tests; 
b) KI-Systeme, die bestimmungsgem&#228;&#223; f&#252;r Entscheidungen &#252;ber Bef&#246;rderungen 
und &#252;ber K&#252;ndigungen von Arbeitsvertragsverh&#228;ltnissen, f&#252;r die 
Aufgabenzuweisung sowie f&#252;r die &#220;berwachung und Bewertung der Leistung 
und des Verhaltens von Personen in solchen Besch&#228;ftigungsverh&#228;ltnissen 
verwendet werden sollen; 
5. Zug&#228;nglichkeit und Inanspruchnahme grundlegender privater und &#246;ffentlicher 
Dienste und Leistungen: 
a) KI-Systeme, die bestimmungsgem&#228;&#223; von Beh&#246;rden oder im Namen von 
Beh&#246;rden verwendet werden sollen, um zu beurteilen, ob nat&#252;rliche Personen 
Anspruch auf &#246;ffentliche Unterst&#252;tzungsleistungen und -dienste haben und ob 
solche Leistungen und Dienste zu gew&#228;hren, einzuschr&#228;nken, zu widerrufen 
oder zur&#252;ckzufordern sind; 
b) KI-Systeme, die bestimmungsgem&#228;&#223; f&#252;r die Kreditw&#252;rdigkeitspr&#252;fung und 
Kreditpunktebewertung nat&#252;rlicher Personen verwendet werden sollen, mit 
Ausnahme von KI-Systemen, die von Kleinanbietern f&#252;r den Eigengebrauch in 
Betrieb genommen werden; 
c) KI-Systeme, die bestimmungsgem&#228;&#223; f&#252;r die Entsendung oder Priorisierung des 
Einsatzes von Not- und Rettungsdiensten, einschlie&#223;lich Feuerwehr und 
medizinischer Nothilfe, verwendet werden sollen;
6. Strafverfolgung: 
a) KI-Systeme, die bestimmungsgem&#228;&#223; von Strafverfolgungsbeh&#246;rden f&#252;r 
individuelle Risikobewertungen nat&#252;rlicher Personen verwendet werden sollen, 
um das Risiko abzusch&#228;tzen, dass eine nat&#252;rliche Person Straftaten begeht oder 
erneut begeht oder dass eine Person zum Opfer m&#246;glicher Straftaten wird; 
b) KI-Systeme, die bestimmungsgem&#228;&#223; von Strafverfolgungsbeh&#246;rden als 
L&#252;gendetektoren und &#228;hnliche Instrumente oder zur Ermittlung des 
emotionalen Zustands einer nat&#252;rlichen Person verwendet werden sollen; 
c) KI-Systeme, die bestimmungsgem&#228;&#223; von Strafverfolgungsbeh&#246;rden zur 
Aufdeckung von Deepfakes gem&#228;&#223; Artikel 52 Absatz 3 verwendet werden 
sollen; 
d) KI-Systeme, die bestimmungsgem&#228;&#223; von Strafverfolgungsbeh&#246;rden zur 
Bewertung der Verl&#228;sslichkeit von Beweismitteln im Zuge der Ermittlung oder 
Verfolgung von Straftaten verwendet werden sollen; 
e) KI-Systeme, die bestimmungsgem&#228;&#223; von Strafverfolgungsbeh&#246;rden zur 
Vorhersage des Auftretens oder erneuten Auftretens einer tats&#228;chlichen oder 
potenziellen Straftat auf der Grundlage des Profils nat&#252;rlicher Personen gem&#228;&#223; 
Artikel 3 Absatz 4 der Richtlinie (EU) 2016/680 oder zur Bewertung von 
Pers&#246;nlichkeitsmerkmalen und Eigenschaften oder vergangenen kriminellen 
Verhaltens nat&#252;rlicher Personen oder von Gruppen verwendet werden sollen; 
f) KI-Systeme, die bestimmungsgem&#228;&#223; von Strafverfolgungsbeh&#246;rden zur 
Erstellung von Profilen nat&#252;rlicher Personen gem&#228;&#223; Artikel 3 Absatz 4 der 
Richtlinie (EU) 2016/680 im Zuge der Aufdeckung, Ermittlung oder 
Verfolgung von Straftaten verwendet werden sollen; 
g) KI-Systeme, die bestimmungsgem&#228;&#223; zur Kriminalanalyse nat&#252;rlicher Personen 
eingesetzt werden sollen und es den Strafverfolgungsbeh&#246;rden erm&#246;glichen, 
gro&#223;e komplexe verkn&#252;pfte und unverkn&#252;pfte Datens&#228;tze aus verschiedenen 
Datenquellen oder in verschiedenen Datenformaten zu durchsuchen, um 
unbekannte Muster zu erkennen oder verdeckte Beziehungen in den Daten 
aufzudecken; 
7. Migration, Asyl und Grenzkontrolle: 
a) KI-Systeme, die bestimmungsgem&#228;&#223; von zust&#228;ndigen Beh&#246;rden als 
L&#252;gendetektoren und &#228;hnliche Instrumente oder zur Ermittlung des 
emotionalen Zustands einer nat&#252;rlichen Person verwendet werden sollen; 
b) KI-Systeme, die bestimmungsgem&#228;&#223; von zust&#228;ndigen Beh&#246;rden zur Bewertung 
eines Risikos verwendet werden sollen, einschlie&#223;lich eines Sicherheitsrisikos, 
eines Risikos der irregul&#228;ren Einwanderung oder eines Gesundheitsrisikos, das 
von einer nat&#252;rlichen Person ausgeht, die in das Hoheitsgebiet eines 
Mitgliedstaats einzureisen beabsichtigt oder eingereist ist; 
c) KI-Systeme, die bestimmungsgem&#228;&#223; von zust&#228;ndigen Beh&#246;rden zur 
&#220;berpr&#252;fung der Echtheit von Reisedokumenten und Nachweisunterlagen 
nat&#252;rlicher Personen und zur Erkennung unechter Dokumente durch Pr&#252;fung 
ihrer Sicherheitsmerkmale verwendet werden sollen; 
d) KI-Systeme, die bestimmungsgem&#228;&#223; zust&#228;ndige Beh&#246;rden bei der Pr&#252;fung von 
Asyl- und Visumantr&#228;gen sowie Aufenthaltstiteln und damit verbundenen
Beschwerden im Hinblick auf die Feststellung der Berechtigung der den 
Antrag stellenden nat&#252;rlichen Personen unterst&#252;tzen sollen; 
8. Rechtspflege und demokratische Prozesse: 
a) KI-Systeme, die bestimmungsgem&#228;&#223; Justizbeh&#246;rden bei der Ermittlung und 
Auslegung von Sachverhalten und Rechtsvorschriften und bei der Anwendung 
des Rechts auf konkrete Sachverhalte unterst&#252;tzen sollen.
ANHANG IV 
TECHNISCHE DOKUMENTATION GEM&#196;&#7838; ARTIKEL 11 ABSATZ 1 
Die in Artikel 11 Absatz 1 genannte technische Dokumentation muss mindestens die 
folgenden Informationen enthalten, soweit sie f&#252;r das betreffende KI-System von Belang sind: 
1. Allgemeine Beschreibung des KI-Systems einschlie&#223;lich: 
a) Zweckbestimmung, das System entwickelnde Person(en), Datum und Version 
des Systems; 
b) gegebenenfalls Interaktion oder Verwendung des KI-Systems mit Hardware 
oder Software, die nicht Teil des KI-Systems selbst sind; 
c) Versionen der betreffenden Software oder Firmware und etwaige 
Anforderungen in Bezug auf die Aktualisierung der Versionen; 
d) Beschreibung aller Formen, in denen das KI-System in Verkehr gebracht oder 
in Betrieb genommen wird; 
e) Beschreibung der Hardware, auf der das KI-System betrieben werden soll; 
f) falls das KI-System Bestandteil von Produkten ist: Fotografien oder 
Abbildungen, die &#228;u&#223;ere Merkmale, Kennzeichnungen und den inneren Aufbau 
dieser Produkte zeigen; 
g) Gebrauchsanweisungen f&#252;r die Nutzer und gegebenenfalls Aufbau- oder 
Installationsanweisungen; 
2. Detaillierte Beschreibung der Bestandteile des KI-Systems und seines 
Entwicklungsprozesses einschlie&#223;lich: 
a) Methoden und Schritte zur Entwicklung des KI-Systems, gegebenenfalls 
einschlie&#223;lich des Einsatzes von Dritten bereitgestellter vortrainierter Systeme 
oder Werkzeuge, und wie diese vom Anbieter benutzt, integriert oder ver&#228;ndert 
wurden; 
b) Entwurfsspezifikationen des Systems, insbesondere die allgemeine Logik des 
KI-Systems und der Algorithmen; wichtigste Entwurfsentscheidungen mit den 
Gr&#252;nden und Annahmen, auch in Bezug auf Personen oder Personengruppen, 
auf die das System angewandt werden soll; haupts&#228;chliche 
Klassifizierungsentscheidungen; was das System optimieren soll und welche 
Bedeutung den verschiedenen Parametern dabei zukommt; Entscheidungen 
&#252;ber m&#246;gliche Kompromisse in Bezug auf die technischen L&#246;sungen, mit 
denen die Anforderungen in Titel III Kapitel 2 erf&#252;llt werden sollen; 
c) Beschreibung der Systemarchitektur, aus der hervorgeht, wie 
Softwarekomponenten aufeinander aufbauen oder einander zuarbeiten und in 
die Gesamtverarbeitung integriert sind; zum Entwickeln, Trainieren, Testen 
und Validieren des KI-Systems verwendete Rechenressourcen; 
d) gegebenenfalls Datenanforderungen in Form von Datenbl&#228;ttern, in denen die 
Trainingsmethoden und -techniken und die verwendeten Trainingsdatens&#228;tze 
beschrieben werden, mit Angaben zu Herkunft, Umfang und Hauptmerkmalen 
dieser Datens&#228;tze; Angaben zur Beschaffung und Auswahl der Daten; 
Kennzeichnungsverfahren (z. B. f&#252;r &#252;berwachtes Lernen), 
Datenbereinigungsmethoden (z. B. Erkennung von Ausrei&#223;ern);
e) Bewertung der nach Artikel 14 erforderlichen Ma&#223;nahmen der menschlichen 
Aufsicht, mit einer Bewertung der technischen Ma&#223;nahmen, die erforderlich 
sind, um den Nutzern gem&#228;&#223; Artikel 13 Absatz 3 Buchstabe d die 
Interpretation der Ergebnisse von KI-Systemen zu erleichtern; 
f) gegebenenfalls detaillierte Beschreibung der vorab bestimmten &#196;nderungen an 
dem KI-System und seiner Leistung mit allen einschl&#228;gigen Angaben zu den 
technischen L&#246;sungen, mit denen sichergestellt wird, dass das KI-System die 
einschl&#228;gigen Anforderungen nach Titel III Kapitel 2 weiterhin dauerhaft 
erf&#252;llt; 
g) verwendete Validierungs- und Testverfahren, mit Angaben zu den verwendeten 
Validierungs- und Testdaten und deren Hauptmerkmalen; Parameter, die zur 
Messung der Genauigkeit, Robustheit, Cybersicherheit und der Erf&#252;llung 
anderer einschl&#228;giger Anforderungen nach Titel III Kapitel 2 sowie potenziell 
diskriminierender Auswirkungen verwendet werden; Testprotokolle und alle 
von den verantwortlichen Personen datierten und unterzeichneten Testberichte, 
auch in Bezug auf die in Buchstabe f genannten vorab bestimmten 
&#196;nderungen. 
3. Detaillierte Informationen &#252;ber die &#220;berwachung, Funktionsweise und Kontrolle des 
KI-Systems, insbesondere in Bezug auf: seine F&#228;higkeiten und Leistungsgrenzen, mit 
dem Genauigkeitsgrad f&#252;r bestimmte Personen oder Personengruppen, auf die das 
System angewandt werden soll, und dem insgesamt erwarteten Genauigkeitsgrad in 
Bezug auf seine Zweckbestimmung; vorhersehbare unbeabsichtigte Ergebnisse und 
Risikoquellen f&#252;r die Gesundheit und Sicherheit, die Grundrechte und eine etwaige 
Diskriminierung angesichts der Zweckbestimmung des KI-Systems; die nach 
Artikel 14 erforderlichen Ma&#223;nahmen der menschlichen Aufsicht, einschlie&#223;lich der 
technischen Ma&#223;nahmen, die getroffen wurden, um den Nutzern die Interpretation 
der Ergebnisse von KI-Systemen zu erleichtern; gegebenenfalls Spezifikationen f&#252;r 
die Eingabedaten; 
4. Detaillierte Beschreibung des Risikomanagementsystems gem&#228;&#223; Artikel 9; 
5. Beschreibung aller an dem System w&#228;hrend seines Lebenszyklus vorgenommenen 
&#196;nderungen; 
6. Aufstellung der vollst&#228;ndig oder teilweise angewandten harmonisierten Normen, 
deren Fundstellen im Amtsblatt der Europ&#228;ischen Union ver&#246;ffentlicht worden sind; 
falls keine solchen harmonisierten Normen angewandt werden, eine detaillierte 
Beschreibung der L&#246;sungen, mit denen die Anforderungen in Titel III Kapitel 2 
erf&#252;llt werden sollen, mit einer Aufstellung anderer einschl&#228;giger Normen und 
technischer Spezifikationen; 
7. Kopie der EU-Konformit&#228;tserkl&#228;rung; 
8. Detaillierte Beschreibung des Systems zur Bewertung der Leistung des KI-Systems 
in der Phase nach dem Inverkehrbringen gem&#228;&#223; Artikel 61, mit dem in Artikel 61 
Absatz 3 genannten Plan f&#252;r die Beobachtung nach dem Inverkehrbringen.
ANHANG V 
EU-KONFORMIT&#196;TSERKL&#196;RUNG 
Die EU-Konformit&#228;tserkl&#228;rung gem&#228;&#223; Artikel 48 enth&#228;lt alle folgenden Angaben: 
1. Name und Art des KI-Systems und etwaige zus&#228;tzliche eindeutige Angaben, die die 
Identifizierung und R&#252;ckverfolgbarkeit des KI-Systems erm&#246;glichen; 
2. Name und Anschrift des Anbieters und gegebenenfalls seines Bevollm&#228;chtigten: 
3. Erkl&#228;rung dar&#252;ber, dass der Anbieter die alleinige Verantwortung f&#252;r die Ausstellung 
der EU-Konformit&#228;tserkl&#228;rung tr&#228;gt; 
4. Versicherung, dass das betreffende KI-System der vorliegenden Verordnung sowie 
gegebenenfalls weiteren einschl&#228;gigen Rechtsvorschriften der Union, in denen die 
Ausstellung einer EU-Konformit&#228;tserkl&#228;rung vorgesehen ist, entspricht; 
5. Verweise auf die verwendeten einschl&#228;gigen harmonisierten Normen oder sonstigen 
gemeinsamen Spezifikationen, f&#252;r die die Konformit&#228;t erkl&#228;rt wird; 
6. gegebenenfalls Name und Kennnummer der notifizierten Stelle, Beschreibung des 
durchgef&#252;hrten Konformit&#228;tsbewertungsverfahrens und Kennnummer der 
ausgestellten Bescheinigung; 
7. Ort und Datum der Ausstellung der Erkl&#228;rung, Name und Funktion des 
Unterzeichners sowie Angabe, f&#252;r wen und in wessen Namen diese Person 
unterzeichnet hat, Unterschrift.
ANHANG VI 
KONFORMIT&#196;TSBEWERTUNGSVERFAHREN AUF DER GRUNDLAGE EINER 
INTERNEN KONTROLLE
1. Das Konformit&#228;tsbewertungsverfahren auf der Grundlage einer internen Kontrolle ist 
das Konformit&#228;tsbewertungsverfahren gem&#228;&#223; den Nummern 2 bis 4. 
2. Der Anbieter &#252;berpr&#252;ft, ob das bestehende Qualit&#228;tsmanagementsystem den 
Anforderungen des Artikels 17 entspricht. 
3. Der Anbieter pr&#252;ft die in der technischen Dokumentation enthaltenen Informationen, 
um zu beurteilen. ob das KI-System den einschl&#228;gigen grundlegenden 
Anforderungen in Titel III Kapitel 2 entspricht. 
4. Der Anbieter &#252;berpr&#252;ft ferner, ob der Entwurfs- und Entwicklungsprozess des KI-
Systems und seine Beobachtung nach dem Inverkehrbringen gem&#228;&#223; Artikel 61 mit 
der technischen Dokumentation im Einklang stehen.
ANHANG VII 
KONFORMIT&#196;T AUF DER GRUNDLAGE DER BEWERTUNG DES 
QUALIT&#196;TSMANAGEMENTSYSTEMS UND DER BEWERTUNG DER 
TECHNISCHEN DOKUMENTATION
1. Einleitung 
Das Konformit&#228;tsbewertungsverfahren auf der Grundlage der Bewertung des 
Qualit&#228;tsmanagementsystems und der Bewertung der technischen Dokumentation ist 
das Konformit&#228;tsbewertungsverfahren gem&#228;&#223; den Nummern 2 bis 5. 
2. &#220;berblick 
Das genehmigte Qualit&#228;tsmanagementsystem f&#252;r die Konzeption, die Entwicklung 
und das Testen von KI-Systemen nach Artikel 17 wird gem&#228;&#223; Nummer 3 gepr&#252;ft und 
unterliegt der &#220;berwachung gem&#228;&#223; Nummer 5. Die technische Dokumentation des 
KI-Systems wird gem&#228;&#223; Nummer 4 gepr&#252;ft. 
3. Qualit&#228;tsmanagementsystem 
3.1. Der Antrag des Anbieters muss Folgendes enthalten: 
a) den Namen und die Anschrift des Anbieters sowie, wenn der Antrag vom 
Bevollm&#228;chtigten eingereicht wird, auch dessen Namen und Anschrift; 
b) die Liste der unter dasselbe Qualit&#228;tsmanagementsystem fallenden KI-
Systeme; 
c) die technische Dokumentation f&#252;r jedes unter dasselbe 
Qualit&#228;tsmanagementsystem fallende KI-System; 
d) die Dokumentation &#252;ber das Qualit&#228;tsmanagementsystem mit allen in 
Artikel 17 aufgef&#252;hrten Aspekten; 
e) eine Beschreibung der bestehenden Verfahren, mit denen sichergestellt wird, 
dass das Qualit&#228;tsmanagementsystem geeignet und wirksam bleibt; 
f) eine schriftliche Erkl&#228;rung, dass derselbe Antrag bei keiner anderen 
notifizierten Stelle eingereicht worden ist. 
3.2. Das Qualit&#228;tssicherungssystem wird von der notifizierten Stelle bewertet, um 
festzustellen, ob es die in Artikel 17 genannten Anforderungen erf&#252;llt. 
Die Entscheidung wird dem Anbieter oder dessen Bevollm&#228;chtigten mitgeteilt. 
Die Mitteilung enth&#228;lt die Ergebnisse der Bewertung des 
Qualit&#228;tsmanagementsystems und die begr&#252;ndete Bewertungsentscheidung. 
3.3. Das genehmigte Qualit&#228;tsmanagementsystem wird vom Anbieter weiter angewandt 
und gepflegt, damit es stets sachgem&#228;&#223; und effizient funktioniert. 
3.4. Der Anbieter unterrichtet die notifizierte Stelle &#252;ber jede beabsichtigte &#196;nderung des 
genehmigten Qualit&#228;tsmanagementsystems oder der Liste der unter dieses System 
fallenden KI-Systeme. 
Die notifizierte Stelle pr&#252;ft die vorgeschlagenen &#196;nderungen und entscheidet, ob das 
ge&#228;nderte Qualit&#228;tsmanagementsystem die in Nummer 3.2 genannten Anforderungen 
weiterhin erf&#252;llt oder ob eine erneute Bewertung erforderlich ist.
Die notifizierte Stelle teilt dem Anbieter ihre Entscheidung mit. Die Mitteilung 
enth&#228;lt die Ergebnisse der Pr&#252;fung der &#196;nderungen und die begr&#252;ndete 
Bewertungsentscheidung. 
4. Kontrolle der technischen Dokumentation 
4.1. Zus&#228;tzlich zu dem in Nummer 3 genannten Antrag stellt der Anbieter bei der 
notifizierten Stelle seiner Wahl einen Antrag auf Bewertung der technischen 
Dokumentation f&#252;r das KI-System, das er in Verkehr zu bringen oder in Betrieb zu 
nehmen beabsichtigt und das unter das in Nummer 3 genannte 
Qualit&#228;tsmanagementsystem f&#228;llt. 
4.2. Der Antrag enth&#228;lt: 
a) den Namen und die Anschrift des Anbieters, 
b) eine schriftliche Erkl&#228;rung, dass derselbe Antrag bei keiner anderen 
notifizierten Stelle eingereicht worden ist, 
c) die in Anhang IV genannte technische Dokumentation. 
4.3. Die technische Dokumentation wird von der notifizierten Stelle gepr&#252;ft. Dazu erh&#228;lt 
die notifizierte Stelle uneingeschr&#228;nkten Zugang zu den vom Anbieter verwendeten 
Trainings- und Testdatens&#228;tzen, auch &#252;ber Anwendungsprogrammierschnittstellen 
(API) oder sonstige f&#252;r den Fernzugriff geeignete Mittel und Instrumente. 
4.4. Bei der Pr&#252;fung der technischen Dokumentation kann die notifizierte Stelle vom 
Anbieter weitere Nachweise verlangen oder weitere Tests durchf&#252;hren, um eine 
ordnungsgem&#228;&#223;e Bewertung der Konformit&#228;t des KI-Systems mit den 
Anforderungen in Titel III Kapitel 2 zu erm&#246;glichen. Ist die notifizierte Stelle mit 
den vom Anbieter durchgef&#252;hrten Tests nicht zufrieden, so f&#252;hrt sie gegebenenfalls 
unmittelbar selbst angemessene Tests durch. 
4.5. Sofern dies f&#252;r die Bewertung der Konformit&#228;t des Hochrisiko-KI-Systems mit den 
in Titel III Kapitel 2 festgelegten Anforderungen notwendig ist, wird der notifizierten 
Stelle auf begr&#252;ndeten Antrag Zugang zum Quellcode des KI-Systems gew&#228;hrt. 
4.6. Die Entscheidung wird dem Anbieter oder dessen Bevollm&#228;chtigten mitgeteilt. Die 
Mitteilung enth&#228;lt die Ergebnisse der Bewertung der technischen Dokumentation und 
die begr&#252;ndete Bewertungsentscheidung. 
Erf&#252;llt das KI-System die Anforderungen in Titel III Kapitel 2, so stellt die 
notifizierte Stelle eine EU-Bescheinigung &#252;ber die Bewertung der technischen 
Dokumentation aus. Diese Bescheinigung enth&#228;lt den Namen und die Anschrift des 
Anbieters, die Ergebnisse der Pr&#252;fung, etwaige Bedingungen f&#252;r ihre G&#252;ltigkeit und 
die f&#252;r die Identifizierung des KI-Systems notwendigen Daten. 
Die Bescheinigung und ihre Anh&#228;nge enthalten alle zweckdienlichen Angaben f&#252;r 
die Beurteilung der Konformit&#228;t des KI-Systems und gegebenenfalls f&#252;r die 
Kontrolle des KI-Systems w&#228;hrend seiner Verwendung. 
Entspricht das KI-System nicht den Anforderungen in Titel III Kapitel 2, so 
verweigert die notifizierte Stelle die Ausstellung einer EU-Bescheinigung &#252;ber die 
Bewertung der technischen Dokumentation und unterrichtet den Antragsteller 
dar&#252;ber, wobei sie ihre Weigerung ausf&#252;hrlich begr&#252;ndet. 
Erf&#252;llt das KI-System nicht die Anforderung in Bezug auf seine verwendeten 
Trainingsdaten, so muss das KI-System vor der Beantragung einer neuen
Konformit&#228;tsbewertung erneut trainiert werden. In diesem Fall enth&#228;lt die 
begr&#252;ndete Bewertungsentscheidung der notifizierten Stelle, mit der die Ausstellung 
der EU-Bescheinigung &#252;ber die Bewertung der technischen Dokumentation 
verweigert wird, besondere Erl&#228;uterungen zu den zum Trainieren des KI-Systems 
verwendeten Qualit&#228;tsdaten und insbesondere zu den Gr&#252;nden f&#252;r die 
Nichtkonformit&#228;t. 
4.7. Jede &#196;nderung des KI-Systems, die sich auf die Konformit&#228;t des KI-Systems mit den 
Anforderungen oder auf seine Zweckbestimmung auswirken k&#246;nnte, bedarf der 
Genehmigung der notifizierten Stelle, die die EU-Bescheinigung &#252;ber die Bewertung 
der technischen Dokumentation ausgestellt hat. Der Anbieter unterrichtet die 
notifizierte Stelle &#252;ber seine Absicht, die oben genannten &#196;nderungen vorzunehmen, 
oder wenn er auf andere Weise Kenntnis vom Eintreten solcher &#196;nderungen erh&#228;lt. 
Die notifizierte Stelle bewertet die beabsichtigten &#196;nderungen und entscheidet, ob 
diese &#196;nderungen eine neue Konformit&#228;tsbewertung gem&#228;&#223; Artikel 43 Absatz 4 
erforderlich machen oder ob ein Nachtrag zu der EU-Bescheinigung &#252;ber die 
Bewertung der technischen Dokumentation ausgestellt werden k&#246;nnte. In letzterem 
Fall bewertet die notifizierte Stelle die beabsichtigten &#196;nderungen, teilt dem 
Anbieter ihre Entscheidung mit und stellt ihm, sofern die &#196;nderungen genehmigt 
wurden, einen Nachtrag zu der EU-Bescheinigung &#252;ber die Bewertung der 
technischen Dokumentation aus.
5. &#220;berwachung des genehmigten Qualit&#228;tsmanagementsystems 
5.1. Mit der in Nummer 3 genannten &#220;berwachung durch die notifizierte Stelle soll 
sichergestellt werden, dass der Anbieter die Anforderungen und Bedingungen des 
genehmigten Qualit&#228;tsmanagementsystems ordnungsgem&#228;&#223; einh&#228;lt. 
5.2. Zu Bewertungszwecken gew&#228;hrt der Anbieter der notifizierten Stelle Zugang zu den 
R&#228;umlichkeiten, in denen die Konzeption, die Entwicklung und das Testen der KI-
Systeme stattfindet. Au&#223;erdem &#252;bermittelt der Anbieter der notifizierten Stelle alle 
erforderlichen Informationen. 
5.3. Die notifizierte Stelle f&#252;hrt regelm&#228;&#223;ig Audits durch, um sicherzustellen, dass der 
Anbieter das Qualit&#228;tsmanagementsystem pflegt und anwendet, und &#252;bermittelt ihm 
einen entsprechenden Pr&#252;fbericht. Im Rahmen dieser Audits kann die notifizierte 
Stelle die KI-Systeme, f&#252;r die eine EU-Bescheinigung &#252;ber die Bewertung der 
technischen Dokumentation ausgestellt wurde, zus&#228;tzlichen Tests unterziehen.
ANHANG VIII 
BEI DER REGISTRIERUNG DES HOCHRISIKO-KI-SYSTEMS GEM&#196;&#7838; 
ARTIKEL 51 BEREITZUSTELLENDE INFORMATIONEN 
F&#252;r Hochrisiko-KI-Systeme, die gem&#228;&#223; Artikel 51 zu registrieren sind, werden folgende 
Informationen bereitgestellt und danach auf dem neuesten Stand gehalten:
1. Name, Anschrift und Kontaktdaten des Anbieters;
2. bei Vorlage von Informationen durch eine andere Person im Namen des Anbieters: 
Name, Anschrift und Kontaktdaten dieser Person; 
3. Name, Anschrift und Kontaktdaten des Bevollm&#228;chtigten, falls zutreffend; 
4. Handelsname des KI-Systems und etwaige zus&#228;tzliche eindeutige Angaben, die die 
Identifizierung und R&#252;ckverfolgbarkeit des KI-Systems erm&#246;glichen; 
5. Beschreibung der Zweckbestimmung des KI-Systems; 
6. Status des KI-Systems (in Verkehr/in Betrieb; nicht mehr in Verkehr/in Betrieb, 
zur&#252;ckgerufen); 
7. Art, Nummer und Ablaufdatum der von der notifizierten Stelle ausgestellten 
Bescheinigung und gegebenenfalls Name oder Kennnummer dieser notifizierten 
Stelle; 
8. gegebenenfalls eine gescannte Kopie der in Nummer 7 genannten Bescheinigung; 
9. Mitgliedstaaten, in denen das KI-System in der Union in Verkehr gebracht, in 
Betrieb genommen oder bereitgestellt wird/wurde; 
10. eine Kopie der in Artikel 48 genannten EU-Konformit&#228;tserkl&#228;rung; 
11. elektronische Gebrauchsanweisungen; dies gilt nicht f&#252;r Hochrisiko-KI-Systeme in 
den Bereichen Strafverfolgung und Migration, Asyl und Grenzkontrolle gem&#228;&#223; 
Anhang III Nummern 1, 6 und 7; 
12. URL-Adresse f&#252;r zus&#228;tzliche Informationen (fakultativ).
ANHANG IX 
RECHTSVORSCHRIFTEN DER UNION &#220;BER IT-GRO&#7838;SYSTEME IM RAUM 
DER FREIHEIT, DER SICHERHEIT UND DES RECHTS 
1. Schengener Informationssystem 
a) Verordnung (EU) 2018/1860 des Europ&#228;ischen Parlaments und des Rates vom 
28. November 2018 &#252;ber die Nutzung des Schengener Informationssystems f&#252;r 
die R&#252;ckkehr illegal aufh&#228;ltiger Drittstaatsangeh&#246;riger (ABl. L 312 vom 
7.12.2018, S. 1); 
b) Verordnung (EU) 2018/1861 des Europ&#228;ischen Parlaments und des Rates vom 
28. November 2018 &#252;ber die Einrichtung, den Betrieb und die Nutzung des 
Schengener Informationssystems (SIS) im Bereich der Grenzkontrollen, zur 
&#196;nderung des &#220;bereinkommens zur Durchf&#252;hrung des &#220;bereinkommens von 
Schengen und zur &#196;nderung und Aufhebung der Verordnung (EG) 
Nr. 1987/2006 (ABl. L 312 vom 7.12.2018, S. 14); 
c) Verordnung (EU) 2018/1862 des Europ&#228;ischen Parlaments und des Rates vom 
28. November 2018 &#252;ber die Einrichtung, den Betrieb und die Nutzung des 
Schengener Informationssystems (SIS) im Bereich der polizeilichen 
Zusammenarbeit und der justiziellen Zusammenarbeit in Strafsachen, zur 
&#196;nderung und Aufhebung des Beschlusses 2007/533/JI des Rates und zur 
Aufhebung der Verordnung (EG) Nr. 1986/2006 des Europ&#228;ischen Parlaments 
und des Rates und des Beschlusses 2010/261/EU der Kommission (ABl. L 312 
vom 7.12.2018, S. 56). 
2. Visa-Informationssystem 
a) Vorschlag f&#252;r eine VERORDNUNG DES EUROP&#196;ISCHEN PARLAMENTS 
UND DES RATES zur &#196;nderung der Verordnung (EG) Nr. 767/2008, der 
Verordnung (EG) Nr. 810/2009, der Verordnung (EU) 2017/2226, der 
Verordnung (EU) 2016/399, der Verordnung (EU) 2018/XX 
[Interoperabilit&#228;ts-Verordnung] und der Entscheidung 2004/512/EG sowie zur 
Aufhebung des Beschlusses 2008/633/JI des Rates, COM(2018) 302 final; zu 
aktualisieren, sobald die Verordnung von den beiden gesetzgebenden Organen 
erlassen wurde (April/Mai 2021). 
3. Eurodac 
a) Ge&#228;nderter Vorschlag f&#252;r eine VERORDNUNG DES EUROP&#196;ISCHEN 
PARLAMENTS UND DES RATES &#252;ber die Einrichtung von Eurodac f&#252;r den 
Abgleich biometrischer Daten zum Zwecke der effektiven Anwendung der 
Verordnung (EU) XXX/XXX [Verordnung &#252;ber Asyl- und 
Migrationsmanagement] und der Verordnung (EU) XXX/XXX 
[Neuansiedlungsverordnung], f&#252;r die Feststellung der Identit&#228;t illegal 
aufh&#228;ltiger Drittstaatsangeh&#246;riger oder Staatenloser und &#252;ber der 
Gefahrenabwehr und Strafverfolgung dienende Antr&#228;ge der Gefahrenabwehr-
und Strafverfolgungsbeh&#246;rden der Mitgliedstaaten und Europols auf den 
Abgleich mit Eurodac-Daten sowie zur &#196;nderung der Verordnungen 
(EU) 2018/1240 und (EU) 2019/818, COM(2020) 614 final. 
4. Einreise-/Ausreisesystem 
a) Verordnung (EU) 2017/2226 des Europ&#228;ischen Parlaments und des Rates vom 
30. November 2017 &#252;ber ein Einreise-/Ausreisesystem (EES) zur Erfassung der
Ein- und Ausreisedaten sowie der Einreiseverweigerungsdaten von 
Drittstaatsangeh&#246;rigen an den Au&#223;engrenzen der Mitgliedstaaten und zur 
Festlegung der Bedingungen f&#252;r den Zugang zum EES zu Gefahrenabwehr-
und Strafverfolgungszwecken und zur &#196;nderung des &#220;bereinkommens von 
Schengen sowie der Verordnungen (EG) Nr. 767/2008 und (EU) 
Nr. 1077/2011 (ABl. L 327 vom 9.12.2017, S. 20). 
5. Europ&#228;isches Reiseinformations- und -genehmigungssystem 
a) Verordnung (EU) 2018/1240 des Europ&#228;ischen Parlaments und des Rates vom 
12. September 2018 &#252;ber die Einrichtung eines Europ&#228;ischen 
Reiseinformations- und -genehmigungssystems (ETIAS) und zur &#196;nderung der 
Verordnungen (EU) Nr. 1077/2011, (EU) Nr. 515/2014, (EU) 2016/399, 
(EU) 2016/1624 und (EU) 2017/2226 (ABl. L 236 vom 19.9.2018, S. 1); 
b) Verordnung (EU) 2018/1241 des Europ&#228;ischen Parlaments und des Rates vom 
12. September 2018 zur &#196;nderung der Verordnung (EU) 2016/794 f&#252;r die 
Zwecke der Einrichtung eines Europ&#228;ischen Reiseinformations-
und -genehmigungssystems (ETIAS) (ABl. L 236 vom 19.9.2018, S. 72). 
6. Europ&#228;isches Strafregisterinformationssystem &#252;ber Drittstaatsangeh&#246;rige und 
Staatenlose
a) Verordnung (EU) 2019/816 des Europ&#228;ischen Parlaments und des Rates vom 
17. April 2019 zur Einrichtung eines zentralisierten Systems f&#252;r die Ermittlung 
der Mitgliedstaaten, in denen Informationen zu Verurteilungen von 
Drittstaatsangeh&#246;rigen und Staatenlosen (ECRIS-TCN) vorliegen, zur 
Erg&#228;nzung des Europ&#228;ischen Strafregisterinformationssystems und zur 
&#196;nderung der Verordnung (EU) 2018/1726 (ABl. L 135 vom 22.5.2019, S. 1). 
7. Interoperabilit&#228;t 
a) Verordnung (EU) 2019/817 des Europ&#228;ischen Parlaments und des Rates vom 
20. Mai 2019 zur Errichtung eines Rahmens f&#252;r die Interoperabilit&#228;t zwischen 
EU-Informationssystemen in den Bereichen Grenzen und Visa und zur 
&#196;nderung der Verordnungen (EG) Nr. 767/2008, (EU) 2016/399, 
(EU) 2017/2226, (EU) 2018/1240, (EU) 2018/1726 und (EU) 2018/1861 des 
Europ&#228;ischen Parlaments und des Rates, der Entscheidung 2004/512/EG des 
Rates und des Beschlusses 2008/633/JI des Rates (ABl. L 135 vom 22.5.2019, 
S. 27); 
b) Verordnung (EU) 2019/818 des Europ&#228;ischen Parlaments und des Rates vom 
20. Mai 2019 zur Errichtung eines Rahmens f&#252;r die Interoperabilit&#228;t zwischen 
EU-Informationssystemen (polizeiliche und justizielle Zusammenarbeit, Asyl 
und Migration) und zur &#196;nderung der Verordnungen (EU) 2018/1726, 
(EU) 2018/1862 und (EU) 2019/816 (ABl. L 135 vom 22.5.2019, S. 85). 
Drucksache 488/21 - 138 -]</text>
    <titel>Vorschlag f&#252;r eine Verordnung des Europ&#228;ischen Parlaments und des Rates zur Festlegung harmonisierter Vorschriften f&#252;r k&#252;nstliche Intelligenz (Gesetz &#252;ber k&#252;nstliche Intelligenz) und zur &#196;nderung bestimmter Rechtsakte der Union</titel>
    <datum>2021-06-07</datum>
  </document>
  