<document>
    <id>228064</id>
    <drucksachetyp>Unterrichtung</drucksachetyp>
    <dokumentart>Drucksache</dokumentart>
    <autoren_anzahl>0</autoren_anzahl>
    <typ>Dokument</typ>
    <vorgangsbezug_anzahl>1</vorgangsbezug_anzahl>
    <dokumentnummer>165/19</dokumentnummer>
    <wahlperiode>19</wahlperiode>
    <herausgeber>BR</herausgeber>
    <pdf_hash>889efa65319971216f6547bff1052f9d</pdf_hash>
    <aktualisiert>2022-07-26T19:57:15+02:00</aktualisiert>
    <vorgangsbezug>
      <id>246116</id>
      <titel>Mitteilung der Kommission an das Europ&#228;ische Parlament, den Rat, den Europ&#228;ischen Wirtschafts- und Sozialausschuss und den Ausschuss der Regionen
Schaffung von Vertrauen in eine auf den Menschen ausgerichtete k&#252;nstliche Intelligenz 
KOM(2019) 168 endg.; Ratsdok. 8396/19</titel>
      <vorgangstyp>EU-Vorlage</vorgangstyp>
    </vorgangsbezug>
    <urheber>
      <einbringer>false</einbringer>
      <bezeichnung>EU-Kommission</bezeichnung>
      <titel>Europ&#228;ische Kommission</titel>
    </urheber>
    <fundstelle>
      <pdf_url>https://dserver.bundestag.de/brd/2019/0165-19.pdf</pdf_url>
      <id>228064</id>
      <dokumentnummer>165/19</dokumentnummer>
      <datum>2019-04-08</datum>
      <dokumentart>Drucksache</dokumentart>
      <drucksachetyp>Unterrichtung</drucksachetyp>
      <herausgeber>BR</herausgeber>
      <urheber>Europ&#228;ische Kommission</urheber>
    </fundstelle>
    <text>[Vertrieb: Bundesanzeiger Verlag GmbH, Postfach 10 05 34, 50445 K&#246;ln 
Telefon (02 21) 97 66 83 40, Fax (02 21) 97 66 83 44, www.betrifft-gesetze.de 
ISSN 0720-2946
Bundesrat Drucksache 165/19
08.04.19 
EU  -  In - K - R - Wi
Unterrichtung 
durch die Europ&#228;ische Kommission
Mitteilung der Kommission an das Europ&#228;ische Parlament, den Rat, den Europ&#228;ischen 
Wirtschafts- und Sozialausschuss und den Ausschuss der Regionen: 
Schaffung von Vertrauen in eine auf den Menschen ausgerichtete k&#252;nstliche Intelligenz 
COM(2019) 168 final
Der Bundesrat wird &#252;ber die Vorlage gem&#228;&#223; &#167; 2 EUZBLG auch durch die Bundesregierung 
unterrichtet.
Hinweis: vgl. Drucksache 158/18 = AE-Nr. 180370 und 
Drucksache 631/18 = AE-Nr. 181166
DE DE
EUROP&#196;ISCHE
KOMMISSION
Br&#252;ssel, den 8.4.2019 
COM(2019) 168 final
MITTEILUNG DER KOMMISSION AN DAS EUROP&#196;ISCHE PARLAMENT, DEN 
RAT, DEN EUROP&#196;ISCHEN WIRTSCHAFTS- UND SOZIALAUSSCHUSS UND 
DEN AUSSCHUSS DER REGIONEN
Schaffung von Vertrauen in eine auf den Menschen ausgerichtete k&#252;nstliche Intelligenz
1. EINLEITUNG &#8211; DIE EUROP&#196;ISCHE KI-STRATEGIE
Die k&#252;nstliche Intelligenz (KI) hat das Potenzial, unsere Welt zum Besseren zu ver&#228;ndern: Sie 
kann die Gesundheitsversorgung verbessern, den Energieverbrauch senken, Autos sicherer 
machen und erm&#246;glicht Landwirten eine effizientere Nutzung von Wasser und 
Naturressourcen. KI kann eingesetzt werden, um Umwelt- und Klimaver&#228;nderungen 
vorherzusagen, das Management finanzieller Risiken zu verbessern und die Werkzeuge zu 
schaffen, die wir brauchen, um genau auf unsere Bed&#252;rfnisse zugeschnittene Produkte mit 
weniger Abf&#228;llen herzustellen. Sie kann auch helfen, Betrug und Bedrohungen der 
Cybersicherheit zu erkennen, und versetzt die Strafverfolgungsbeh&#246;rden in die Lage, 
Kriminalit&#228;t wirksamer zu bek&#228;mpfen. 
KI kann f&#252;r die Gesellschaft und Wirtschaft als Ganzes von gro&#223;em Nutzen sein. Es handelt 
sich um eine strategische Technologie, die sich derzeit in der ganzen Welt rasch 
weiterentwickelt und verbreitet. Allerdings bringt die KI auch neue Herausforderungen f&#252;r die 
Zukunft der Arbeit mit sich und wirft rechtliche und ethische Fragen auf. 
Um diese Herausforderungen zu meistern und die von der KI er&#246;ffneten Chancen 
bestm&#246;glich zu nutzen, hat die Kommission im April 2018 eine europ&#228;ische Strategie1
ver&#246;ffentlicht. Diese Strategie r&#252;ckt die Menschen in den Mittelpunkt der KI-Entwicklung &#8211; 
es geht um eine auf den Menschen ausgerichtete, menschenzentrierte KI. Dabei wird ein 
dreiteiliger Ansatz verfolgt: F&#246;rderung der technologischen und industriellen 
Leistungsf&#228;higkeit der EU sowie der weiteren KI-Verbreitung in der gesamten Wirtschaft, 
Vorbereitung auf die mit KI verbundenen sozio&#246;konomischen Ver&#228;nderungen und 
Gew&#228;hrleistung eines geeigneten ethischen und rechtlichen Rahmens. 
Zur Umsetzung der KI-Strategie hat die Kommission gemeinsam mit den Mitgliedstaaten 
einen koordinierten Plan f&#252;r die KI2 ausgearbeitet, den sie im Dezember 2018 vorgestellt 
hat&#8218; um Synergien zu schaffen, Daten &#8211; den Rohstoff f&#252;r zahlreiche KI-Anwendungen &#8211; 
zusammenzuf&#252;hren und verst&#228;rkt gemeinsame Investitionen zu f&#246;rdern. Ziel ist es, die 
grenz&#252;berschreitende Zusammenarbeit zu f&#246;rdern und alle Akteure zu mobilisieren, damit die 
&#246;ffentlichen und privaten Investitionen in den n&#228;chsten zehn Jahren auf mindestens 
20 Mrd. EUR j&#228;hrlich steigen3. Die Kommission hat ihre im Rahmenprogramm 
Horizont 2020 vorgesehenen Investitionsmittel f&#252;r KI verdoppelt und plant zudem, 
1 Mrd. EUR j&#228;hrlich aus den Programmen &#8222;Horizont Europa&#8220; und &#8222;Digitales Europa&#8220; zu 
investieren, um insbesondere gemeinsame Datenr&#228;ume auf Gebieten wie Gesundheit, Verkehr 
und Fertigung, gro&#223;e Versuchseinrichtungen wie intelligente Krankenh&#228;user und 
Infrastrukturen f&#252;r automatisierte Fahrzeuge sowie eine strategische Forschungsagenda zu 
unterst&#252;tzen. 
Zur Umsetzung einer solchen gemeinsamen strategischen Forschungs-, Innovations- und 
Einf&#252;hrungsagenda hat die Kommission ihren Dialog mit allen relevanten Akteuren aus 
Industrie, Forschungsinstituten und Beh&#246;rden intensiviert. Das neue Programm 
&#8222;Digitales Europa&#8220; wird ebenfalls ma&#223;geblich dazu beitragen, dass gerade kleinen und 
mittleren Unternehmen in allen Mitgliedstaaten &#8211; mithilfe digitaler Innovationszentren &#8211; 
1 COM(2018) 237. 
2 COM(2018) 795. 
3 Um dieses Ziel zu erreichen, hat die Kommission f&#252;r den n&#228;chsten Programmplanungszeitraum 2021&#8211;2027 
vorgeschlagen, dass die Union j&#228;hrlich mindestens 1 Mrd. EUR an F&#246;rdermitteln aus den Programmen 
&#8222;Horizont Europa&#8220; und &#8222;Digitales Europa&#8220; f&#252;r Investitionen in KI bereitstellt.
verbesserte Test- und Versuchseinrichtungen, Datenr&#228;ume und Schulungsprogramme zur 
Verf&#252;gung gestellt werden k&#246;nnen.
Das ethische Herangehen Europas an die KI wird &#8211; aufbauend auf dem guten Ruf seiner 
sicheren und hochwertigen Produkte &#8211; einerseits das Vertrauen der B&#252;rger in die digitale 
Entwicklung st&#228;rken und zielt andererseits darauf ab, einen Wettbewerbsvorteil f&#252;r 
europ&#228;ische KI-Unternehmen zu erringen. Mit dieser Mitteilung soll eine umfassende 
Pilotphase unter breitestm&#246;glicher Beteiligung der Interessentr&#228;ger eingeleitet werden, um die 
praktische Umsetzung der Ethik-Leitlinien bei der Entwicklung und Nutzung der KI zu 
erproben.
2. SCHAFFUNG VON VERTRAUEN IN EINE MENSCHENZENTRIERTE KI 
Die europ&#228;ische KI-Strategie und der koordinierte Plan machen deutlich, dass Vertrauen 
eine Grundvoraussetzung f&#252;r die Verfolgung eines auf den Menschen ausgerichteten 
Ansatzes f&#252;r die KI ist: KI ist kein Selbstzweck, sondern ein Instrument, das den Menschen 
dienen muss und letztlich das Wohlergehen der Menschen steigern soll. Dabei kommt es 
entscheidend auf die Vertrauensw&#252;rdigkeit der KI an. Die unseren Gesellschaften zugrunde 
liegenden Wertvorstellungen m&#252;ssen bei der Entwicklung der KI vollst&#228;ndig zum Tragen 
kommen. 
Die Werte, auf denen die Union beruht, sind die Achtung der Menschenw&#252;rde, Freiheit, 
Demokratie, Gleichheit, Rechtsstaatlichkeit und die Wahrung der Menschenrechte
einschlie&#223;lich der Rechte der Personen, die Minderheiten angeh&#246;ren4. Diese Werte sind den 
Gesellschaften aller Mitgliedstaaten gemeinsam, die sich durch Pluralismus, 
Nichtdiskriminierung, Toleranz, Gerechtigkeit, Solidarit&#228;t und Gleichheit auszeichnen. 
&#220;berdies sind in der EU-Grundrechtecharta alle pers&#246;nlichen, b&#252;rgerlichen, politischen, 
wirtschaftlichen und sozialen Rechte der Menschen innerhalb der EU in einem einzigen Text 
zusammengefasst. 
Die EU verf&#252;gt &#252;ber einen starken Rechtsrahmen&#8218; der weltweite Standards f&#252;r eine 
menschenzentrierte KI setzen wird. Die Datenschutz-Grundverordnung gew&#228;hrleistet ein 
hohes Ma&#223; an Schutz personenbezogener Daten und schreibt verbindliche Vorkehrungen vor, 
die den &#8222;Datenschutz durch Technik&#8220; und &#8222;datenschutzfreundliche Voreinstellungen&#8220;5
einschlie&#223;en. Die Verordnung &#252;ber den freien Verkehr nicht personenbezogener Daten 
beseitigt Hindernisse, die der freien Weitergabe nicht personenbezogener Daten 
entgegenstehen, und bewirkt, dass alle Datenkategorien &#252;berall in Europa verarbeitet werden 
k&#246;nnen. Der erst k&#252;rzlich erlassene Rechtsakt zur Cybersicherheit wird dazu beitragen, das 
Vertrauen in die Online-Welt zu st&#228;rken. Die vorgeschlagene e-Datenschutz-Verordnung6
dient ebenfalls diesem Ziel. 
4 Au&#223;erdem ist die EU Vertragspartei des &#220;bereinkommens der Vereinten Nationen &#252;ber die Rechte von 
Menschen mit Behinderungen. 
5 Verordnung (EU) 2016/679. Die Datenschutz-Grundverordnung (DSGVO) gew&#228;hrleistet den freien Verkehr 
personenbezogener Daten in der Union. Sie enth&#228;lt Bestimmungen &#252;ber Entscheidungsprozesse, die 
ausschlie&#223;lich auf einer automatisierten Verarbeitung &#8211; einschlie&#223;lich Profiling &#8211; beruhen. So haben die 
betroffenen Personen das Recht, &#252;ber das Bestehen automatischer Entscheidungsprozesse informiert zu 
werden und aussagekr&#228;ftige Ausk&#252;nfte &#252;ber die Logik der automatisierten Entscheidungsfindung sowie &#252;ber 
die Bedeutung und die vorgesehenen Folgen der Verarbeitung f&#252;r sie zu erhalten. Au&#223;erdem haben sie in 
solchen F&#228;llen Anspruch auf eine menschliche &#220;berpr&#252;fung, bei der sie ihren Standpunkt darlegen und der 
Entscheidung widersprechen k&#246;nnen. 
6 COM(2017) 10.
Dennoch bringt die KI neue Herausforderungen mit sich, weil sie es Maschinen erm&#246;glicht, 
eigenst&#228;ndig &#8222;zu lernen&#8220; und ohne menschliches Zutun Entscheidungen zu treffen und 
umzusetzen. Es wird nicht mehr lange dauern, bis diese Funktionsweise bei vielen Arten von 
Waren und Dienstleistungen &#8211; von Smartphones bis hin zu automatisierten Fahrzeugen, 
Robotern und Online-Anwendungen &#8211; zum Standard wird. Entscheidungen, die von 
Algorithmen getroffen werden, k&#246;nnen jedoch aus Daten resultieren, die unvollst&#228;ndig und 
daher nicht verl&#228;sslich sind; sie k&#246;nnen durch Cyber-Angreifer manipuliert werden oder 
einfach fehlerhaft sein. Ein unbedachter Einsatz der sich entwickelnden Technik w&#252;rde daher 
problematische Ergebnisse hervorbringen und dazu f&#252;hren, dass die B&#252;rger solche Technik 
nur z&#246;gerlich akzeptieren und nutzen.
Stattdessen sollte KI-Technik so entwickelt werden, dass sie die Menschen in ihren 
Mittelpunkt r&#252;ckt und daher das Vertrauen der &#214;ffentlichkeit verdient. Das bedeutet, dass KI-
Anwendungen nicht nur rechtm&#228;&#223;ig sein m&#252;ssen, sondern auch ethische Grunds&#228;tze einhalten 
und sicherstellen sollten, dass bei ihrer Anwendung kein unbeabsichtigter Schaden entstehen 
kann. Die Vielfalt in Bezug auf Geschlecht, Rasse oder ethnische Herkunft, Religion oder 
Weltanschauung, Behinderung und Alter sollte in jeder Phase der KI-Entwicklung 
gew&#228;hrleistet sein. KI-Anwendungen sollten die m&#252;ndigen B&#252;rger st&#228;rken und deren 
Grundrechte wahren. Ihr Einsatz sollte dem Ziel dienen, die F&#228;higkeiten der Menschen zu 
verbessern, und nicht, sie zu ersetzen. Und auch Menschen mit Behinderungen sollten sich die 
M&#246;glichkeiten der KI voll zunutze machen k&#246;nnen. 
Deshalb brauchen wir Ethik-Leitlinien, die auf dem bestehenden Rechtsrahmen aufbauen 
und von KI-Entwicklern, -Anbietern und -Nutzern im Binnenmarkt gleicherma&#223;en befolgt 
werden, damit in allen Mitgliedstaaten gleiche Wettbewerbsbedingungen herrschen. Aus 
diesem Grund hat die Kommission eine hochrangige Expertengruppe f&#252;r KI7 eingesetzt, in 
der ein breites Spektrum von Interessentr&#228;gern vertreten ist. Sie hat die Gruppe mit der 
Aufstellung von Ethik-Leitlinien f&#252;r die KI und mit der Ausarbeitung von Empfehlungen f&#252;r 
eine umfassendere KI-Politik beauftragt. Gleichzeitig wurde die Europ&#228;ische KI-Allianz8 als 
eine offene Multi-Stakeholder-Plattform mit mehr als 2700 Mitgliedern eingerichtet, die einen 
auf breiterer Grundlage fu&#223;enden Beitrag zur Arbeit der hochrangigen Expertengruppe f&#252;r KI 
leisten soll. 
Die hochrangige Expertengruppe f&#252;r KI ver&#246;ffentlichte im Dezember 2018 einen ersten 
Entwurf der Ethik-Leitlinien. Nach einer Konsultation der Interessentr&#228;ger9 und nach 
Zusammenk&#252;nften mit Vertretern der Mitgliedstaaten10 legte die KI-Expertengruppe der 
Kommission im M&#228;rz 2019 eine &#252;berarbeitete Fassung der Leitlinien vor. In ihren bisherigen 
Beitr&#228;gen begr&#252;&#223;ten die Interessentr&#228;ger insgesamt den praktischen Charakter der Leitlinien 
und die konkreten Hinweise, die sie Entwicklern, Anbietern und Nutzern von KI in Bezug 
darauf geben, wie Vertrauensw&#252;rdigkeit gew&#228;hrleistet werden kann.
7 https://ec.europa.eu/digital-single-market/en/high-level-expert-group-artificial-intelligence
8 https://ec.europa.eu/digital-single-market/en/european-ai-alliance
9 Zu dieser Konsultation gingen Stellungnahmen von 511 Organisationen, Verb&#228;nden, Unternehmen, 
Forschungsinstituten, Einzelpersonen und anderen ein. Eine Zusammenfassung der Beitr&#228;ge ist abrufbar unter: 
https://ec.europa.eu/futurium/en/system/files/ged/consultation_feedback_on_draft_ai_ethics_guidelines_4.pdf. 
10 Die Arbeit der Expertengruppe wurde von den Mitgliedstaaten positiv aufgenommen. In den 
Schlussfolgerungen des Rates vom 18. Februar 2019 wurden unter anderem die bevorstehende 
Ver&#246;ffentlichung der Ethik-Leitlinien begr&#252;&#223;t und die Bem&#252;hungen der Kommission um die Etablierung eines 
Ethik-Ansatzes der EU auf weltweiter Ebene unterst&#252;tzt: https://data.consilium.europa.eu/doc/document/ST-
6177-2019-INIT/en/pdf.
2.1 Ethik-Leitlinien f&#252;r eine vertrauensw&#252;rdige KI &#8211; ausgearbeitet von der 
hochrangigen Expertengruppe f&#252;r KI
Die von der hochrangigen Expertengruppe f&#252;r KI ausgearbeiteten Ethik-Leitlinien, auf die 
sich diese Mitteilung bezieht11&#8218; beruhen insbesondere auf den Vorarbeiten der Europ&#228;ischen 
Gruppe f&#252;r Ethik der Naturwissenschaften und der neuen Technologien und der Agentur der 
Europ&#228;ischen Union f&#252;r Grundrechte. 
In den Leitlinien wird davon ausgegangen, dass zur Verwirklichung einer 
&#8222;vertrauensw&#252;rdigen KI&#8220; drei Komponenten notwendig sind: 1) sie sollte rechtm&#228;&#223;ig sein, 2) 
sie sollte ethischen Grunds&#228;tzen entsprechen und 3) sie sollte robust sein. 
Auf der Grundlage dieser drei Komponenten und der in Abschnitt 2 dargelegten europ&#228;ischen 
Werte werden in den Leitlinien sieben Kernanforderungen genannt, die von KI-Anwendungen 
zu erf&#252;llen sind, damit sie als vertrauensw&#252;rdig gelten k&#246;nnen. Dar&#252;ber hinaus enthalten die 
Leitlinien eine Bewertungsliste, mit deren Hilfe &#252;berpr&#252;ft werden kann, ob diese 
Anforderungen erf&#252;llt sind. 
Die sieben Kernanforderungen sind: 
&#8226; Vorrang menschlichen Handelns und menschlicher Aufsicht 
&#8226; Technische Robustheit und Sicherheit
&#8226; Privatsph&#228;re und Datenqualit&#228;tsmanagement 
&#8226; Transparenz 
&#8226; Vielfalt, Nichtdiskriminierung und Fairness 
&#8226; Gesellschaftliches und &#246;kologisches Wohlergehen 
&#8226; Rechenschaftspflicht 
Diese Anforderungen sollen zwar generell f&#252;r alle KI-Systeme in verschiedenen Umfeldern 
und Branchen gelten, bei ihrer konkreten und verh&#228;ltnism&#228;&#223;igen Umsetzung sind aber der 
jeweilige spezifische Anwendungskontext und die m&#246;glichen Folgen zu ber&#252;cksichtigen. So 
w&#228;re beispielsweise eine KI-Anwendung, die ein unpassendes Buch vorschl&#228;gt, weit weniger 
gef&#228;hrlich als etwa eine Anwendung, die eine falsche Krebsdiagnose stellt, und k&#246;nnte daher 
einer weniger strengen Aufsicht unterliegen. 
Die von der hochrangigen Expertengruppe f&#252;r KI ausgearbeiteten Leitlinien haben einen 
unverbindlichen Charakter und begr&#252;nden daher als solche keine neuen rechtlichen 
Verpflichtungen. Mehrere dieser Kernanforderungen finden sich bereits in vielen bestehenden 
(nutzungs- oder bereichsspezifischen) Bestimmungen des Unionsrechts, z. B. in 
Sicherheitsvorschriften und in Vorschriften zum Schutz personenbezogener Daten und zum 
Schutz der Privatsph&#228;re oder zum Umweltschutz. 
Die Kommission begr&#252;&#223;t die Arbeit der hochrangigen Expertengruppe f&#252;r KI und betrachtet 
ihre Arbeitsergebnisse als wertvollen Beitrag zu ihrer Politik. 
2.2 Kernanforderungen an eine vertrauensw&#252;rdige KI 
Die Kommission unterst&#252;tzt die folgenden Kernanforderungen an eine 
vertrauensw&#252;rdige KI&#8218; die auf europ&#228;ischen Werten beruhen. Sie ruft die Interessentr&#228;ger 
auf, diese Anforderungen umzusetzen und die Bewertungsliste, die diese praktisch anwendbar
11 https://ec.europa.eu/futurium/en/ai-alliance-consultation/guidelines#Top
macht, selbst zu testen, um so das richtige Umfeld f&#252;r die erfolgreiche Entwicklung und 
Nutzung k&#252;nstlicher Intelligenz zu schaffen. Die Kommission begr&#252;&#223;t etwaige 
R&#252;ckmeldungen der Interessentr&#228;ger, um besser einsch&#228;tzen zu k&#246;nnen, ob die in den 
Leitlinien enthaltene Bewertungsliste weiter angepasst werden muss.
I. Vorrang menschlichen Handelns und menschlicher Aufsicht 
KI-Systeme sollten die einzelnen Menschen dabei unterst&#252;tzen, im Einklang mit ihren 
eigenen Zielen bessere, fundiertere Entscheidungen zu treffen. Sie sollten einer 
florierenden und gerechten Gesellschaft dienen, indem sie das menschliche Handeln und 
die Wahrung der Grundrechte unterst&#252;tzen&#8218; keinesfalls aber sollten sie die Autonomie der 
Menschen verringern, beschr&#228;nken oder fehlleiten. Die Richtschnur f&#252;r das Funktionieren 
von KI-Systemen sollte das allgemeine Wohl des Nutzers sein. 
Die menschliche Aufsicht hilft, daf&#252;r zu sorgen, dass ein KI-System die menschliche 
Autonomie nicht untergr&#228;bt oder sich sonst nachteilig auswirkt. In Abh&#228;ngigkeit vom 
konkreten KI-gest&#252;tzten System und dessen Anwendungsgebiet sollte es geeignete Stufen 
von Kontrollma&#223;nahmen geben&#8218; die auch Aspekte der Anpassbarkeit&#8218; Genauigkeit und 
Erkl&#228;rbarkeit KI-gest&#252;tzter Systeme beinhalten12. Die Aufsicht kann durch Lenkungs-
und Kontrollmechanismen wie die Gew&#228;hrleistung der interaktiven Einbindung eines 
Menschen (&#8222;Human-in-the-Loop&#8220;), der &#220;berpr&#252;fung und Kontrolle durch einen Menschen 
(&#8222;Human-on-the-Loop&#8220;) oder der Gesamtsteuerung durch einen Menschen (&#8222;Human-in-
Command&#8220;) erreicht werden13. Auf jeden Fall muss dabei aber sichergestellt werden, dass 
die Beh&#246;rden stets in der Lage sind, die Aufsicht im Einklang mit ihrem jeweiligen 
Auftrag auszu&#252;ben. F&#252;r ein ansonsten gleiches System muss gelten: je weniger Aufsicht 
ein Mensch &#252;ber ein KI-System aus&#252;ben kann, desto ausf&#252;hrlicher muss es zuvor getestet 
werden und desto strenger muss die Lenkung und Kontrolle sein. 
II. Technische Robustheit und Sicherheit 
Eine vertrauensw&#252;rdige KI setzt Algorithmen voraus, die sicher, verl&#228;sslich und robust 
genug sind, um Fehler oder Unstimmigkeiten in allen Phasen des Lebenszyklus des KI-
Systems zu bew&#228;ltigen und mit fehlerhaften Ergebnissen angemessen umzugehen. KI-
Systeme m&#252;ssen verl&#228;sslich und hinreichend sicher sein, sodass sie sowohl offenen 
Angriffen als auch subtileren Manipulationsversuchen an ihren Daten oder eigenen 
Algorithmen standhalten&#8218; und sie m&#252;ssen f&#252;r den Fall von Problemen eine 
R&#252;ckfallstrategie haben. Ihre Entscheidungen m&#252;ssen genau sein oder zumindest den 
Grad der Genauigkeit richtig angeben, und ihre Ergebnisse sollten reproduzierbar sein. 
&#220;berdies sollten KI-Systeme konzeptuell integrierte Schutz- und Sicherheitsvorkehrungen 
aufweisen, damit sie in jeder Phase nachpr&#252;fbar sicher sind, wobei es auf die k&#246;rperliche
12 Die Datenschutz-Grundverordnung gibt Personen das Recht, nicht einer ausschlie&#223;lich auf einer 
automatisierten Verarbeitung beruhenden Entscheidung unterworfen zu werden, die ihr gegen&#252;ber rechtliche 
Wirkung entfaltet oder sie in &#228;hnlicher Weise erheblich beeintr&#228;chtigt (Artikel 22 der DSGVO).
13 &#8222;Human-in-the-Loop&#8220; (HITL) bedeutet, dass in jeden Entscheidungszyklus des Systems ein Mensch 
eingebunden sein muss, was in vielen F&#228;llen weder m&#246;glich noch w&#252;nschenswert w&#228;re. &#8222;Human-on-the-
Loop&#8220; (HOTL) bedeutet die M&#246;glichkeit des Menschen, in den Entwurfszyklus des Systems einzugreifen und 
den Systembetrieb zu &#252;berwachen. &#8222;Human-in-Command&#8220; (HIC) bedeutet die M&#246;glichkeit, den 
Gesamtbetrieb des KI-Systems zu beaufsichtigen (einschlie&#223;lich seiner weiteren wirtschaftlichen, 
gesellschaftlichen, rechtlichen und ethischen Auswirkungen), sowie die F&#228;higkeit zu entscheiden, wann und 
wie das System in einer bestimmten Situation eingesetzt werden soll. Dies beinhaltet auch die 
Entscheidungsm&#246;glichkeit, ein KI-System in einer bestimmten Situation nicht einzusetzen, beim Einsatz des 
Systems ein bestimmtes Ma&#223; an menschlichem Ermessen zuzulassen oder eine vom System getroffene 
Entscheidung au&#223;er Kraft zu setzen.
und geistige Sicherheit aller Beteiligten ankommt. Dies schlie&#223;t das Minimieren und 
m&#246;glichst das R&#252;ckg&#228;ngigmachen unbeabsichtigter Folgen oder Fehler im Systembetrieb 
ein. Es sollten Verfahren zur Kl&#228;rung und Bewertung potenzieller Risiken im 
Zusammenhang mit dem Einsatz von KI-Systemen in verschiedenen 
Anwendungsbereichen eingerichtet werden.
III. Privatsph&#228;re und Datenqualit&#228;tsmanagement 
Der Schutz der Privatsph&#228;re und der Datenschutz m&#252;ssen in allen Phasen des 
Lebenszyklus eines KI-Systems gew&#228;hrleistet sein. Aus digitalen Aufzeichnungen &#252;ber 
das menschliche Verhalten k&#246;nnen KI-Systeme nicht nur auf pers&#246;nliche Vorlieben sowie 
Alter und Geschlecht einzelner Menschen, sondern auch auf die sexuelle Ausrichtung und 
religi&#246;se oder politische Ansichten schlie&#223;en. Damit die Menschen Vertrauen in die 
Datenverarbeitung haben k&#246;nnen, muss sichergestellt sein, dass sie die volle Kontrolle 
&#252;ber ihre eigenen Daten behalten und dass die sie betreffenden Daten nicht dazu 
verwendet werden, sie zu sch&#228;digen oder zu diskriminieren. 
Neben dem Schutz der Privatsph&#228;re und der personenbezogenen Daten m&#252;ssen 
hochwertige KI-Systeme weitere strenge Anforderungen erf&#252;llen. Die Qualit&#228;t der 
verwendeten Datens&#228;tze ist f&#252;r die Leistungsf&#228;higkeit von KI-Systemen von 
entscheidender Bedeutung. Bei der Erfassung der Daten kann es sozial bedingte 
Verzerrungen geben, oder die Daten k&#246;nnen Ungenauigkeiten, Fehler und andere M&#228;ngel 
aufweisen. Solche Probleme m&#252;ssen behoben werden, bevor ein KI-System mit einem 
bestimmten Datensatz ausgebildet wird. Dar&#252;ber hinaus muss die Integrit&#228;t der Daten 
gew&#228;hrleistet sein. Die verwendeten Prozesse und Datens&#228;tze m&#252;ssen in allen Schritten 
wie Planung, Ausbildung, Erprobung und Einsatz getestet und dokumentiert werden. Dies 
sollte auch f&#252;r KI-Systeme gelten, die nicht intern entwickelt, sondern von au&#223;erhalb 
erworben werden. Schlie&#223;lich muss auch der Zugang zu den Daten angemessen geregelt 
und kontrolliert werden.
IV. Transparenz 
Die R&#252;ckverfolgbarkeit der KI-Systeme muss sichergestellt werden. Dazu m&#252;ssen 
sowohl die vom System getroffenen Entscheidungen selbst als auch der gesamte Prozess, 
der zu der Entscheidung gef&#252;hrt hat, protokolliert und dokumentiert werden 
(einschlie&#223;lich Beschreibung der Datenerfassung und Datenbenennung und des 
verwendeten Algorithmus). In diesem Zusammenhang sollte &#8211; soweit dies m&#246;glich ist &#8211; 
eine f&#252;r die beteiligten Personen verst&#228;ndliche Erkl&#228;rung des algorithmischen 
Entscheidungsprozesses bereitgestellt werden. Die laufenden Forschungsarbeiten zur 
Entwicklung von Erkl&#228;rungsmechanismen sollten fortgesetzt werden. Dar&#252;ber hinaus 
sollten Erl&#228;uterungen dazu vorliegen, inwieweit ein KI-System den Entscheidungsprozess 
der Organisation beeinflusst und formt, aber auch &#252;ber Entscheidungen zum 
Systementwurf und die Gr&#252;nde f&#252;r dessen Einf&#252;hrung (sodass nicht nur die Daten- und 
Systemtransparenz, sondern auch die Transparenz des Gesch&#228;ftsmodells gew&#228;hrleistet 
wird). 
Schlie&#223;lich ist es wichtig, den verschiedenen Beteiligten die F&#228;higkeiten und 
Beschr&#228;nkungen des KI-Systems in einer Weise mitzuteilen, die f&#252;r die jeweilige 
Nutzung angemessen ist. Au&#223;erdem sollten KI-Systeme als solche erkennbar sein, damit 
die Nutzer stets wissen, dass sie es mit einem KI-System zu tun haben, und wer daf&#252;r 
verantwortlich ist.
V. Vielfalt, Nichtdiskriminierung und Fairness 
Die von KI-Systemen (sowohl zur Ausbildung als auch im Betrieb) verwendeten
Datens&#228;tze k&#246;nnen unbeabsichtigte historische Verzerrungen aufweisen, unvollst&#228;ndig 
sein und auf schlechte Lenkungs- und Kontrollmodelle zur&#252;ckgehen. Die Fortschreibung 
solcher Verzerrungen k&#246;nnte (in)direkte Diskriminierungen zur Folge haben. Schaden 
kann aber auch aus einer beabsichtigten Ausnutzung von Vorurteilen (der Verbraucher) 
oder durch unlauteren Wettbewerb entstehen. Auch die Art und Weise, wie KI-Systeme 
entwickelt werden (z. B. wie der Programmcode eines Algorithmus geschrieben wird), 
kann durch gewisse Einfl&#252;sse beeintr&#228;chtigt sein. Auf solche Bedenken sollte vom Beginn 
der Systementwicklung an eingegangen werden.
Die Bildung vielf&#228;ltig zusammengesetzter Entwurfsteams und die Einrichtung von 
Mechanismen der Beteiligung (vor allem auch der B&#252;rger) an der KI-Entwicklung k&#246;nnen 
ebenfalls dazu beitragen, solche Bedenken auszur&#228;umen. Ebenso ist es ratsam, all jene 
Beteiligten zu konsultieren, die von dem System w&#228;hrend seines gesamten Lebenszyklus 
direkt oder indirekt betroffen sein k&#246;nnen. KI-Systeme sollten dem gesamten Spektrum 
menschlicher F&#228;higkeiten, Fertigkeiten und Anforderungen Rechnung tragen und die 
Barrierefreiheit durch ein universelles Entwurfskonzept gew&#228;hrleisten, um einen 
gleichberechtigten Zugang f&#252;r Menschen mit Behinderungen zu erreichen. 
VI. Gesellschaftliches und &#246;kologisches Wohlergehen 
Damit die KI vertrauensw&#252;rdig sein kann, sollten ihre Auswirkungen auf die Umwelt und 
auf andere f&#252;hlende Wesen ber&#252;cksichtigt werden. Im Idealfall sollten alle Menschen, 
auch die k&#252;nftigen Generationen, in biologischer Vielfalt und einer bewohnbaren Umwelt 
leben k&#246;nnen. Die Nachhaltigkeit und die &#246;kologische Verantwortlichkeit von KI-
Systemen sollten daher gef&#246;rdert werden. Dasselbe gilt f&#252;r KI-L&#246;sungen, die sich mit 
Belangen von weltweiter Bedeutung befassen, wie z. B. mit den Zielen der Vereinten 
Nationen f&#252;r nachhaltige Entwicklung. 
Dar&#252;ber hinaus sollten die Auswirkungen von KI-Systemen nicht nur aus individueller, 
sondern auch aus gesamtgesellschaftlicher Sicht betrachtet werden. Der Einsatz von KI-
Systemen sollte insbesondere im Zusammenhang mit dem demokratischen Prozess &#8211; also 
in der &#246;ffentlichen Meinungsbildung, im politischen Entscheidungsprozess oder in Bezug 
auf Wahlen &#8211; sorgf&#228;ltig gepr&#252;ft werden. Au&#223;erdem sollten die sozialen Auswirkungen
der KI ber&#252;cksichtigt werden. So wie KI-Systeme zur Verbesserung sozialer 
Kompetenzen eingesetzt werden k&#246;nnen, k&#246;nnen sie auch zu ihrer Verschlechterung 
beitragen. 
VII. Rechenschaftspflicht 
Es sollten Mechanismen geschaffen werden, die die Verantwortlichkeit und 
Rechenschaftspflicht f&#252;r KI-Systeme und deren Ergebnisse vor und nach ihrer Umsetzung 
gew&#228;hrleisten. Die Nachpr&#252;fbarkeit von KI-Systemen ist in dieser Hinsicht von 
entscheidender Bedeutung, denn die Bewertung von KI-Systemen durch interne und 
externe Pr&#252;fer und das Vorliegen solcher Bewertungsberichte tr&#228;gt betr&#228;chtlich zur 
Vertrauensw&#252;rdigkeit der Technik bei. Die externe Nachpr&#252;fbarkeit sollte insbesondere 
bei Anwendungen sichergestellt sein, die sich auf Grundrechte auswirken, sowie bei 
sicherheitskritischen Anwendungen. 
M&#246;gliche negative Auswirkungen von KI-Systemen sollten ermittelt, bewertet, 
dokumentiert und minimiert werden. Folgenabsch&#228;tzungen k&#246;nnen diesen Prozess 
erleichtern. Solche Folgenabsch&#228;tzungen sollten aber in einem angemessenen Verh&#228;ltnis 
zu der H&#246;he der Risiken stehen, die von den KI-Systemen ausgehen. Kompromisse
zwischen den verschiedenen Anforderungen, die oft unvermeidbar sind, sollten rational 
und methodisch angegangen und ber&#252;cksichtigt werden. Sollte es schlie&#223;lich doch zu
ungerechten und nachteiligen Auswirkungen kommen, sollten leicht zug&#228;ngliche 
Mechanismen vorgesehen sein, die einen angemessenen Rechtsschutz gew&#228;hrleisten.
2.3 N&#228;chste Schritte: Pilotphase unter breitestm&#246;glicher Beteiligung der 
Interessentr&#228;ger 
Der Konsens &#252;ber diese Kernanforderungen an KI-Systeme ist ein erster wichtiger 
Meilenstein auf dem Weg zu Leitlinien f&#252;r eine ethisch vertretbare KI. Als n&#228;chsten Schritt 
wird die Kommission daf&#252;r sorgen, dass diese Leitlinien in der Praxis getestet und umgesetzt 
werden k&#246;nnen.
Zu diesem Zweck wird sie nun eine gezielte Pilotphase einleiten, um strukturierte 
R&#252;ckmeldungen von den Interessentr&#228;gern einzuholen. Dies wird vor allem anhand der 
Bewertungsliste geschehen, die die hochrangige Expertengruppe f&#252;r jede der 
Kernanforderungen erstellt hat. 
Diese Arbeiten werden in zwei Teile gegliedert sein: i) eine Pilotphase f&#252;r die Leitlinien unter 
Einbeziehung von Interessentr&#228;gern, die KI entwickeln oder einsetzen, einschlie&#223;lich 
&#246;ffentlicher Verwaltungen, und ii) die fortlaufende Konsultation der Interessentr&#228;ger sowie 
die Sensibilisierung in den Mitgliedstaaten und in verschiedenen Gruppen von 
Interessentr&#228;gern, einschlie&#223;lich Industrie und Dienstleistungssektor: 
i) Ab Juni 2019 werden alle Interessentr&#228;ger und Einzelpersonen aufgerufen sein, die 
Bewertungsliste zu testen und R&#252;ckmeldungen dar&#252;ber zu geben, wie sie verbessert 
werden kann. Dar&#252;ber hinaus wird die hochrangige Expertengruppe f&#252;r KI zusammen mit 
den Interessentr&#228;gern aus dem privaten und dem &#246;ffentlichen Sektor eine eingehende 
&#220;berpr&#252;fung beginnen, um detailliertere R&#252;ckmeldungen dar&#252;ber zu erhalten, wie die 
Leitlinien in einer Vielzahl von Anwendungsbereichen umgesetzt werden k&#246;nnen. Alle 
R&#252;ckmeldungen zur Praxistauglichkeit und Umsetzbarkeit der Leitlinien werden bis 
Ende 2019 bewertet.
ii) Parallel dazu wird die Kommission weitere Informationsma&#223;nahmen ergreifen und 
Vertretern der hochrangigen Expertengruppe f&#252;r KI die M&#246;glichkeit geben, die Leitlinien 
den einschl&#228;gigen Interessentr&#228;gern in den Mitgliedstaaten, auch in der Industrie und im 
Dienstleistungssektor, vorzustellen, damit diese eine zus&#228;tzliche Gelegenheit erhalten, 
sich zu den KI-Leitlinien zu &#228;u&#223;ern und einen Beitrag dazu zu leisten. 
Die Kommission wird auch die Arbeit der Expertengruppe f&#252;r Ethik beim vernetzten und 
automatisierten Fahren14 ber&#252;cksichtigen und bei der Umsetzung der Kernanforderungen mit 
den von der EU finanzierten Forschungsprojekten zum Thema KI sowie mit einschl&#228;gigen 
&#246;ffentlich-privaten Partnerschaften zusammenarbeiten15. Beispielsweise wird die Kommission 
&#8211; in Abstimmung mit den Mitgliedstaaten &#8211; den Aufbau einer gemeinsamen medizinischen 
Bilddatenbank unterst&#252;tzen, die urspr&#252;nglich f&#252;r die h&#228;ufigsten Arten von Krebserkrankungen 
bestimmt war, um Algorithmen zu entwickeln, die anhand von Symptomen mit hoher 
Pr&#228;zision Diagnosen stellen k&#246;nnen. Ebenso kann dank der Zusammenarbeit zwischen 
Kommission und Mitgliedstaaten eine wachsende Zahl grenz&#252;berschreitender Korridore f&#252;r 
die Erprobung vernetzter und automatisierter Fahrzeuge eingerichtet werden. Die Leitlinien 
sollten bei diesen Projekten angewendet und getestet werden. Die Ergebnisse werden dann in 
den Bewertungsprozess einflie&#223;en. 
14 Siehe die Mitteilung der Kommission zur automatisierten Mobilit&#228;t, COM(2018) 283. 
15 Im Rahmen des Europ&#228;ischen Verteidigungsfonds wird die Kommission ebenfalls besondere Ethik-Leitlinien 
f&#252;r die Bewertung von Projektvorschl&#228;gen im Bereich der KI f&#252;r Verteidigungszwecke ausarbeiten.
Die Pilotphase und die Konsultation der Interessentr&#228;ger werden vom Beitrag der 
Europ&#228;ischen KI-Allianz und vom Projekt AI4EU, der KI-Abruf-Plattform, profitieren. Das 
im Januar 2019 ins Leben gerufene Projekt AI4EU16 wird Algorithmen, Werkzeuge, 
Datens&#228;tze und Dienste zusammenf&#252;hren, um Organisationen, insbesondere kleine und 
mittlere Unternehmen, bei der Umsetzung von KI-L&#246;sungen zu unterst&#252;tzen. Die Europ&#228;ische 
KI-Allianz wird zusammen mit dem Projekt AI4EU weiterhin das KI-&#214;kosystem in ganz 
Europa mobilisieren, auch im Hinblick auf die Erprobung der Ethik-Leitlinien f&#252;r die KI und 
die F&#246;rderung einer auf den Menschen ausgerichteten (&#8222;menschenzentrierten&#8220;) KI. 
Aufbauend auf der Bewertung der R&#252;ckmeldungen aus der Pilotphase wird die hochrangige 
Expertengruppe f&#252;r KI Anfang 2020 die Leitlinien &#252;berpr&#252;fen und aktualisieren. Auf 
der Grundlage der &#220;berpr&#252;fung und der gewonnenen Erfahrungen wird die Kommission das 
Ergebnis bewerten und n&#228;chste Schritte vorschlagen.
Bei einer ethisch vertretbaren KI gibt es nur Gewinner. F&#252;r die Achtung der Grundwerte und 
Grundrechte zu sorgen, ist nicht nur f&#252;r sich genommen wichtig, sondern erleichtert auch die 
Akzeptanz in der &#214;ffentlichkeit und erh&#246;ht den Wettbewerbsvorteil der europ&#228;ischen KI-
Unternehmen, indem eine auf den Menschen ausgerichtete vertrauensw&#252;rdige KI mit ethisch 
vertretbaren und sicheren Produkten als Marke etabliert wird. Dies baut allgemein auf dem 
gefestigten guten Ruf europ&#228;ischer Unternehmen bei der Bereitstellung sicherer und 
hochwertiger Produkte auf. Die Pilotphase wird dazu beitragen, dass die KI-Produkte diese 
Erwartungen erf&#252;llen.
2.4 Hin zu internationalen KI-Ethik-Leitlinien
Die internationale Debatte &#252;ber die KI-Ethik hat sich intensiviert, nachdem Japan im Rahmen 
seiner G7-Pr&#228;sidentschaft das Thema im Jahr 2016 ganz oben auf die Tagesordnung gesetzt 
hatte. Angesichts der gegenseitigen internationalen Abh&#228;ngigkeiten bei der Entwicklung der 
KI bez&#252;glich der Weitergabe von Daten, der Entwicklung von Algorithmen und der 
Forschungsinvestitionen wird die Kommission ihre Bem&#252;hungen fortsetzen, den Ansatz 
der Union auch weltweit zur Geltung zu bringen und einen Konsens &#252;ber eine auf den 
Menschen ausgerichtete KI zu erzielen17. 
Dank der Arbeit der hochrangigen Expertengruppe f&#252;r KI sowie vor allem der Liste der 
Anforderungen und der Einbindung der Interessentr&#228;ger, verf&#252;gt die Kommission &#252;ber 
zus&#228;tzliche wertvolle Beitr&#228;ge als Grundlage f&#252;r die internationalen Gespr&#228;che. Die 
Europ&#228;ische Union kann bei der Ausarbeitung internationaler KI-Leitlinien und, wenn 
m&#246;glich, eines entsprechenden Bewertungsmechanismus eine F&#252;hrungsrolle &#252;bernehmen.
Die Kommission wird daher
&#8211; die Zusammenarbeit mit gleich gesinnten Partnern verst&#228;rken: 
&#8226; Untersuchung, inwieweit Konvergenz mit den Ethik-Leitlinienentw&#252;rfen von Drittl&#228;ndern 
(z. B. Japan, Kanada, Singapur) erreicht werden kann, und &#8211; aufbauend auf dieser Gruppe 
gleich gesinnter L&#228;nder &#8211; Vorbereitung einer breiteren Diskussion, unterst&#252;tzt durch 
16 https://ec.europa.eu/digital-single-market/en/news/artificial-intelligence-ai4eu-project-launches-1-january-
17 Die Hohe Vertreterin der Union f&#252;r Au&#223;en- und Sicherheitspolitik wird mit Unterst&#252;tzung der Kommission 
die Konsultationen im Rahmen der Vereinten Nationen, im Global Tech Panel (globaler Technikbeirat) und in 
anderen multilateralen Foren fortsetzen und insbesondere Vorschl&#228;ge zur Bew&#228;ltigung der betreffenden 
komplexen Sicherheitsfragen koordinieren.
Ma&#223;nahmen zur Durchf&#252;hrung des Partnerschaftsinstruments f&#252;r die Zusammenarbeit mit 
Drittstaaten18,
&#8226; Untersuchung, wie Unternehmen aus Drittl&#228;ndern und internationale Organisationen 
durch Erprobung und Validierung zur &#8222;Pilotphase&#8220; der Leitlinien beitragen k&#246;nnen; 
&#8211; weiterhin eine aktive Rolle bei internationalen Diskussionen und Initiativen spielen: 
&#8226; Beitrag zu multilateralen Foren wie der G7 und der G20, 
&#8226; Dialoge mit Drittl&#228;ndern und Ausrichtung bilateraler und multilateraler Treffen, um 
einen Konsens &#252;ber eine auf den Menschen ausgerichtete KI zu erzielen, 
&#8226; Beitrag zu einschl&#228;gigen Normungst&#228;tigkeiten in internationalen 
Normungsorganisationen zur F&#246;rderung dieser Vision und 
&#8226; St&#228;rkung der Erfassung und Verbreitung von Erkenntnissen &#252;ber staatliche Ma&#223;nahmen, 
die gemeinsam mit einschl&#228;gigen internationalen Organisationen durchgef&#252;hrt werden.
3. SCHLUSSFOLGERUNGEN
Die EU beruht auf einer Reihe von Grundwerten, auf deren Grundlage sie einen starken und 
ausgewogenen Rechtsrahmen geschaffen hat. Aufbauend auf diesem bestehenden 
Rechtsrahmen sind wegen der Neuheit der KI und der besonderen Herausforderungen, die mit 
dieser Technologie verbunden sind, Ethik-Leitlinien f&#252;r ihre Entwicklung und Nutzung 
erforderlich. Nur wenn KI unter Achtung der weitgehend gemeinsamen ethischen Werte 
entwickelt und genutzt wird, kann sie auch als vertrauensw&#252;rdig angesehen werden. 
Im Hinblick auf dieses Ziel begr&#252;&#223;t die Kommission die Beitr&#228;ge der hochrangigen 
Expertengruppe f&#252;r KI. Ausgehend von den Kernanforderungen, die eine als 
vertrauensw&#252;rdig anzusehende KI erf&#252;llen muss, wird die Kommission nun eine gezielte 
Pilotphase einleiten, um daf&#252;r zu sorgen, dass die sich daraus ergebenden KI-Ethik-Leitlinien 
f&#252;r die Entwicklung und Nutzung der KI in der Praxis angewandt werden k&#246;nnen. Die 
Kommission wird ferner darauf hinarbeiten, unter anderem mit allen Beteiligten und unseren 
internationalen Partnern einen breiten gesellschaftlichen Konsens &#252;ber eine auf den Menschen 
ausgerichtete KI zu erzielen. 
Die ethische Dimension der KI ist kein Luxus oder erg&#228;nzender Zusatz, sondern muss fester 
Bestandteil der KI-Entwicklung sein. Durch das Bem&#252;hen um eine auf den Menschen 
ausgerichtete KI, die auf Vertrauen beruht, gew&#228;hrleisten wir, dass unsere gesellschaftlichen 
Grundwerte gewahrt bleiben und Europa und seine Industrie als Vorreiter auf dem Gebiet der 
innovativen KI eine unverwechselbare Marke schaffen k&#246;nnen, die &#252;berall auf der Welt 
Vertrauen genie&#223;t.
18 Verordnung (EU) Nr. 234/2014 des Europ&#228;ischen Parlaments und des Rates vom 11. M&#228;rz 2014 zur 
Schaffung eines Partnerschaftsinstruments f&#252;r die Zusammenarbeit mit Drittstaaten (ABl. L 77 vom 
15.3.2014, S. 77). So wird beispielsweise das geplante Projekt f&#252;r ein &#8222;internationales B&#252;ndnis f&#252;r ein auf den 
Menschen ausgerichtetes Herangehen an die k&#252;nstliche Intelligenz&#8220; gemeinsame Initiativen mit gleich 
gesinnten Partnern zur F&#246;rderung von Ethik-Leitlinien und zur Festlegung gemeinsamer Grunds&#228;tze und 
operativer Schlussfolgerungen erleichtern. Im Rahmen des Projekts werden die EU und gleich gesinnte 
L&#228;nder operative Schlussfolgerungen aus den von der Expertengruppe vorgeschlagenen Ethik-Leitlinien f&#252;r 
die KI er&#246;rtern k&#246;nnen, um zu einem gemeinsamen Ansatz zu gelangen. Dar&#252;ber hinaus wird im Rahmen des 
Projekts die weltweite Einf&#252;hrung der KI-Technologie beobachtet. Schlie&#223;lich werden als Teil des Projekts 
Ma&#223;nahmen im Bereich der &#214;ffentlichkeitsarbeit bei internationalen Veranstaltungen organisiert, z. B. im 
Rahmen der G7, der G20 und der Organisation f&#252;r wirtschaftliche Zusammenarbeit und Entwicklung.
Um die ethisch vertretbare Entwicklung der KI in Europa in einem breiteren Kontext zu 
gew&#228;hrleisten, verfolgt die Kommission einen umfassenden Ansatz, der insbesondere 
folgende Ma&#223;nahmen umfasst, die bis zum dritten Quartal 2019 umgesetzt werden sollen:
&#8226; Sie wird mithilfe von &#8222;Horizont 2020&#8220; mehrere Netze von KI-Spitzenforschungszentren
einrichten. Sie wird bis zu vier Netze ausw&#228;hlen, deren Schwerpunkt auf gro&#223;en 
wissenschaftlichen oder technischen Herausforderungen liegt, wie z. B. der Erkl&#228;rbarkeit 
von KI-Systemen und der fortgeschrittenen Mensch-Maschine-Interaktion, die f&#252;r eine 
vertrauensw&#252;rdige KI von entscheidender Bedeutung sind. 
&#8226; Sie wird Netze digitaler Innovationszentren19 einrichten, die sich auf KI in der 
Fertigung und auf Big Data konzentrieren. 
&#8226; Sie wird vorbereitende Gespr&#228;che mit den Mitgliedstaaten und Interessentr&#228;gern f&#252;hren, 
um ein Modell f&#252;r eine gemeinsame Datennutzung und die bestm&#246;gliche 
Verwendung gemeinsamer Datenr&#228;ume zu entwickeln und umzusetzen, wobei der 
Schwerpunkt insbesondere auf den Bereichen Verkehr, Gesundheitswesen und industrielle 
Fertigung liegen wird20. 
Dar&#252;ber hinaus arbeitet die Kommission derzeit an einem Bericht &#252;ber die mit KI 
verbundenen Herausforderungen im Zusammenhang mit dem Sicherheits- und 
Haftungsrahmen und einem Leitfaden zur Umsetzung der Produkthaftungsrichtlinie21. 
Gleichzeitig wird im Rahmen des gemeinsamen Unternehmens f&#252;r europ&#228;isches 
Hochleistungsrechnen (EuroHPC)22 die n&#228;chste Generation von Supercomputern entwickelt, 
da Rechenkapazit&#228;ten f&#252;r die Verarbeitung von Daten und f&#252;r die Ausbildung von KI-
Anwendungen eine wesentliche Rolle spielen und Europa die gesamte digitale 
Wertsch&#246;pfungskette selbst meistern muss. Die laufende Partnerschaft mit den 
Mitgliedstaaten und der Industrie im Bereich der Mikroelektronikkomponenten und -systeme 
(ECSEL)23 sowie die Initiative f&#252;r europ&#228;ische Prozessoren24 werden zur Entwicklung von 
Niedrigenergieprozessortechnik f&#252;r vertrauensw&#252;rdiges und sicheres Hochleistungsrechnen 
und modernste Spitzencomputer beitragen. 
Ebenso wie die Arbeit an den Ethik-Leitlinien f&#252;r die KI beruhen all diese Initiativen auf einer 
engen Zusammenarbeit aller beteiligten Akteure, einschlie&#223;lich der Mitgliedstaaten, der 
Industrie, der gesellschaftlichen Kr&#228;fte und der B&#252;rger. Insgesamt zeigt das europ&#228;ische 
Konzept f&#252;r die k&#252;nstliche Intelligenz, wie die wirtschaftliche Wettbewerbsf&#228;higkeit und das 
Vertrauen der Gesellschaft auf denselben Grundwerten beruhen und sich gegenseitig 
verst&#228;rken m&#252;ssen.
19 http://s3platform.jrc.ec.europa.eu/digital-innovation-hubs
20 Die erforderlichen Mittel werden aus dem Programm &#8222;Horizont 2020&#8220; (vorgesehen sind knapp 1,5 Mrd. EUR 
f&#252;r KI im Zeitraum 2018&#8211;2020), dessen Nachfolgeprogramm &#8222;Horizont Europa&#8220;, dem digitalen Teil der 
Fazilit&#228;t &#8222;Connecting Europe&#8220; und insbesondere dem k&#252;nftigen Programm &#8222;Digitales Europa&#8220; bereitgestellt 
werden. Die Projekte werden sich auch auf Mittel aus dem Privatsektor und aus den Programmen der 
Mitgliedstaaten st&#252;tzen. 
21 Siehe die Mitteilung der Kommission zur k&#252;nstlichen Intelligenz f&#252;r Europa, COM(2018) 237. 
22 https://eurohpc-ju.europa.eu
23 www.ecsel.eu
24 www.european-processor-initiative.eu
Drucksache 165/19 - 12 -]</text>
    <titel>Mitteilung der Kommission an das Europ&#228;ische Parlament, den Rat, den Europ&#228;ischen Wirtschafts- und Sozialausschuss und den Ausschuss der Regionen:
Schaffung von Vertrauen in eine auf den Menschen ausgerichtete k&#252;nstliche Intelligenz</titel>
    <datum>2019-04-08</datum>
  </document>
  