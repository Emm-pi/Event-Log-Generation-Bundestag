<document>
    <id>257543</id>
    <drucksachetyp>Empfehlungen</drucksachetyp>
    <dokumentart>Drucksache</dokumentart>
    <autoren_anzahl>0</autoren_anzahl>
    <typ>Dokument</typ>
    <vorgangsbezug_anzahl>1</vorgangsbezug_anzahl>
    <dokumentnummer>488/1/21</dokumentnummer>
    <wahlperiode>19</wahlperiode>
    <herausgeber>BR</herausgeber>
    <pdf_hash>2f121f614ef4a1d39dec6a656b567976</pdf_hash>
    <aktualisiert>2021-09-06T00:00:00+02:00</aktualisiert>
    <vorgangsbezug>
      <id>279055</id>
      <titel>Vorschlag f&#252;r eine Verordnung des Europ&#228;ischen Parlaments und des Rates zur Festlegung harmonisierter Vorschriften f&#252;r k&#252;nstliche Intelligenz (Gesetz &#252;ber k&#252;nstliche Intelligenz) und zur &#196;nderung bestimmter Rechtsakte der Union
KOM(2021) 206 endg.; Ratsdok. 8115/21</titel>
      <vorgangstyp>EU-Vorlage</vorgangstyp>
    </vorgangsbezug>
    <fundstelle>
      <pdf_url>https://dserver.bundestag.de/brd/2021/0488-1-21.pdf</pdf_url>
      <id>257543</id>
      <dokumentnummer>488/1/21</dokumentnummer>
      <datum>2021-09-06</datum>
      <dokumentart>Drucksache</dokumentart>
      <drucksachetyp>Empfehlungen</drucksachetyp>
      <herausgeber>BR</herausgeber>
    </fundstelle>
    <text>[Bundesrat Drucksache 488/1/21
06.09.21
...
Vertrieb: Bundesanzeiger Verlag GmbH, Postfach 10 05 34, 50445 K&#246;ln 
Telefon (02 21) 97 66 83 40, Fax (02 21) 97 66 83 44, www.betrifft-gesetze.de 
ISSN 0720-2946
E m p f e h l u n g e n  
der Aussch&#252;sse
EU - AIS - AV - G - In - K - R - Vk - 
Wi
zu Punkt &#8230; der 1008. Sitzung des Bundesrates am 17. September 2021
Vorschlag f&#252;r eine Verordnung des Europ&#228;ischen Parlaments und 
des Rates zur Festlegung harmonisierter Vorschriften f&#252;r 
k&#252;nstliche Intelligenz (Gesetz &#252;ber k&#252;nstliche Intelligenz) und zur 
&#196;nderung bestimmter Rechtsakte der Union 
COM(2021) 206 final 
A 
Der Ausschuss f&#252;r Arbeit, Integration und Sozialpolitik (AIS), 
der Ausschuss f&#252;r Agrarpolitik und Verbraucherschutz (AV), 
der Ausschuss f&#252;r Innere Angelegenheiten (In), 
der Ausschuss f&#252;r Kulturfragen (K), 
der Rechtsausschuss (R), 
der Verkehrsausschuss (Vk) und 
der Wirtschaftsausschuss (Wi) 
empfehlen dem Bundesrat, zu der Vorlage gem&#228;&#223; &#167;&#167; 3 und 5 EUZBLG wie folgt 
Stellung zu nehmen:
Allgemeines
1. Der Bundesrat begr&#252;&#223;t, dass die Kommission mit dem nun vorliegenden
Verordnungsvorschlag den weltweit ersten Rechtsrahmen f&#252;r K&#252;nstliche Intelligenz 
(KI) entworfen hat und damit europaweit einheitliche Regelungen f&#252;r das sehr 
komplexe Thema KI schaffen m&#246;chte. Besonders positiv ist dabei hervorzuhe-
K 
In
... 
ben, dass davon auch Anbieter au&#223;erhalb der EU erfasst werden, sofern sie im 
europ&#228;ischen Markt aktiv sein wollen.
2. Der Bundesrat begr&#252;&#223;t das Ziel der Kommission, einen einheitlichen
Rechtsrahmen zu schaffen, der die Entwicklung und Anwendung einer sicheren,
vertrauensw&#252;rdigen und ethisch vertretbaren KI in Europa gew&#228;hrleisten und 
nachhaltig f&#246;rdern soll sowie auch die Koh&#228;renz mit der EU-Grundrechte-
Charta und dem geltenden Sekund&#228;rrecht der Union zur Nichtdiskriminierung 
und zur Gleichstellung der Geschlechter gew&#228;hrleistet.
3. Der Bundesrat stimmt der Kommission insofern zu, als dass f&#252;r den Einsatz von
KI eine europaweit einheitliche Regelung sinnvoll ist.
4. Der Bundesrat unterst&#252;tzt den Ansatz, dass Europa das globale Zentrum f&#252;r eine 
vertrauensw&#252;rdige KI werden soll. Denn KI kann nur dann ihr wirtschaftliches 
Potenzial entfalten, wenn die Menschen dieser Technologie vertrauen k&#246;nnen. 
Deshalb ist es folgerichtig, dass die Kommission in ihrem
Verordnungsvorschlag nicht nur einen klaren Fokus auf Wirtschaft und Unternehmen, sondern 
gleicherma&#223;en auf den Schutz der B&#252;rgerinnen und B&#252;rger sowie der
Demokratie auf der Basis der europ&#228;ischen Werte legt.
5. Der Bundesrat begr&#252;&#223;t das Vorhaben der Kommission, erstmalig einen
risikobasierten Rechtsrahmen f&#252;r eine vertrauensw&#252;rdige KI zu schaffen, damit sich 
KI als eine der Schl&#252;sseltechnologien der Digitalisierung und als Treiber des 
wirtschaftlichen Wachstums in der Union erfolgreich entwickeln kann. Es ist 
konsequent, dass die Union dazu einen zweigleisigen Ansatz verfolgt, indem sie 
einerseits eine menschenzentrierte und vertrauensw&#252;rdige KI sicherstellen und 
andererseits Anreize f&#252;r Unternehmen zur Weiterentwicklung der Technologie 
setzten m&#246;chte.
6. Der Bundesrat begr&#252;&#223;t das Vorhaben der Kommission, einen risikobasierten 
Rechtsrahmen f&#252;r die Entwicklung und Anwendung von KI in der Union zu 
schaffen.
7. Der Bundesrat begr&#252;&#223;t die Vorlage des Verordnungsvorschlags und unterst&#252;tzt 
grunds&#228;tzlich die Zielsetzung der Kommission, die mit KI einhergehenden 
Chancen, Potenziale und Risiken gleichberechtigt in den Blick zu nehmen. Er
Wi 
(bei
Annahme 
entf&#228;llt 
Ziffer 3)
K 
In 
K
K 
(bei
Annahme 
entf&#228;llt 
Ziffer 6)
AV 
R
Vk
...
begr&#252;&#223;t den darauf basierenden Ansatz, dass die Schaffung eines
Regulierungsrahmens mit Investitionen f&#252;r KI einhergehen soll. Der Bundesrat bekr&#228;ftigt in 
diesem Zusammenhang seine Stellungnahmen vom 15. Februar 2019 (BR-
Drucksache 631/18 (Beschluss)), vom 17. Mai 2019 (BR-Drucksache 165/19 
(Beschluss)) sowie vom 15. Mai 2020 (BR-Drucksache 95/20 (Beschluss)). 
8. Der Bundesrat begr&#252;&#223;t die Anwendung des Marktortprinzips im
Verordnungsvorschlag, um einen souver&#228;nen europ&#228;ischen Weg bei der Entwicklung und 
der Anwendung von KI zu beschreiten.
9. Der Bundesrat bef&#252;rwortet die Schaffung eines einheitlichen europ&#228;ischen KI-
Regulierungsrahmens zum Nutzen der B&#252;rgerinnen und B&#252;rger und mit dem 
Ziel der Schaffung eines reibungslos funktionierenden europ&#228;ischen
Binnenmarkts. Er betont, dass ein einheitlicher europ&#228;ischer Regulierungsrahmen zur 
Weiterentwicklung und Verbreitung von KI sowie zur St&#228;rkung der
industriellen Basis Europas im Bereich KI beitragen kann. 
10. Der Bundesrat hebt das relativ weite Verst&#228;ndnis von KI, das auch die
Bedeutung von Daten und deren Qualit&#228;t ber&#252;cksichtigt, als gewinnbringend hervor.
11. KI ist eine Schl&#252;sseltechnologie f&#252;r die L&#246;sung gro&#223;er gesellschaftlicher
Herausforderungen und f&#252;r eine nachhaltige wirtschaftliche Prosperit&#228;t Europas. 
Europa kann es sich nicht leisten, die Innovations- und
Wertsch&#246;pfungspotenziale der KI ungenutzt zu lassen. Dies erfordert die erfolgreiche Anwendung von 
KI-Technologien, aber vor allem muss Europa auch selbst ein weltweit
f&#252;hrender Standort f&#252;r die Entwicklung innovativer KI-L&#246;sungen sein.
12. Der Bundesrat h&#228;lt es f&#252;r erforderlich, dass eine Regulierung vor allem auch die 
Chancen von KI-L&#246;sungen, etwa zur Bew&#228;ltigung gesellschaftlicher
Herausforderungen wie zum Beispiel Klimaschutz, Gesundheit und Verkehrssicherheit, 
im Blick haben muss.
13. Der Einsatz von KI-Technologie ist f&#252;r die k&#252;nftige Wettbewerbsf&#228;higkeit der 
deutschen Unternehmen von zentraler Bedeutung. Der Anwendungsbereich von 
KI-Systemen erstreckt sich &#252;ber nahezu alle Wirtschaftszweige und
Gesch&#228;ftsbereiche. Vor allem f&#252;r die Industrie ist das Potenzial von KI enorm, indem sie
Vk 
Vk 
Vk 
Wi
Wi
K
... 
die Produktion durch intelligente, digital vernetzte Systeme und Prozessketten 
effizienter, flexibler und zuverl&#228;ssiger gestalten kann.
14. Damit Europa das globale Zentrum f&#252;r vertrauensw&#252;rdige KI werden kann, 
m&#252;ssen die Regelungen so pr&#228;zise und verst&#228;ndlich formuliert sein, dass 
dadurch weder neue b&#252;rokratische H&#252;rden oder regulatorische Grauzonen noch 
Forschungs- oder Innovationshemmnisse entstehen. Die Regelungen des
Verordnungsvorschlags d&#252;rfen in keinem Fall zu einem Wettbewerbsnachteil f&#252;r 
europ&#228;ische Unternehmen und Start-ups werden. Nur dort, wo es aus ethischen, 
verbraucherpolitischen oder sicherheitspolitischen Gr&#252;nden unbedingt
erforderlich ist, sollten der Anwendung von KI strikte Grenzen gesetzt werden. Die 
hierbei zu erf&#252;llenden Anforderungen m&#252;ssen sich in einem f&#252;r Nutzende und 
Anbietende zumutbaren Rahmen bewegen.
15. Der Bundesrat bittet die Bundesregierung insgesamt darauf hinzuwirken, dass 
der neue KI-Rechtsrahmen nicht in eine &#220;berregulierung m&#252;ndet und dadurch 
zu einem Innovationshemmnis f&#252;r die Entwicklung und Anwendung von KI in 
Europa wird. Dabei ist zu beachten, dass die Besonderheit von KI als
Technologie ber&#252;cksichtigt wird und vergleichbare Regularien angewandt werden wie 
f&#252;r andere Technologien. 
16. Die Anforderungen des vorgelegten Verordnungsvorschlages werden
insbesondere die kleinen und mittleren Unternehmen (KMU), die KI-Technologie in 
nach dem Verordnungsvorschlag als hochriskant bewerteten Anwendungen
einsetzen wollen, vor gro&#223;e Herausforderungen stellen. In diesem Zusammenhang 
ist darauf zu achten, dass KMU vor unangemessenen Belastungen gesch&#252;tzt 
werden.
17. Der Bundesrat weist darauf hin, dass eine &#252;berm&#228;&#223;ige Regulierung von KI-
Systemen die Entstehung und Nutzung von Innovationen in dieser
Schl&#252;sseltechnologie verlangsamen oder sogar ganz verhindern kann. Insbesondere 
k&#246;nnte eine &#252;berm&#228;&#223;ige Regulierung die Gr&#252;ndungsneigung von KI-Talenten 
reduzieren oder auch ihre Abwanderung aus Europa weiter beg&#252;nstigen. Dies 
h&#228;tte nicht nur negative Auswirkungen auf die Wettbewerbsf&#228;higkeit der
europ&#228;ischen Wirtschaft und insbesondere KMU sowie von Start-ups, sondern auch 
auf die technologische Souver&#228;nit&#228;t und die F&#228;higkeit Europas, auf europ&#228;i-
In 
K
K 
K 
Wi
...
schen Werten und den Grundrechten beruhende Regeln im Umgang mit dieser 
Technologie zu etablieren und durchzusetzen.
18. Der Bundesrat weist in diesem Zusammenhang auf die im Juni 2021
erschienene Studie &#8222;Artificial intelligence, blockchain and the future of Europe: How
disruptive technologies create opportunities for a green and digital economy&#8220; von 
Kommission und Europ&#228;ischer Investitionsbank hin. Danach besteht in Europa 
eine j&#228;hrliche Investitionsl&#252;cke bei KI-Start-ups und -KMU in H&#246;he von 4 bis 8 
Milliarden Euro im Vergleich zu den USA und China. Bei der Anzahl von KI-
Start-ups und -KMU liegen die USA mit rund 2.500 Unternehmen weit vor 
China und der EU mit jeweils rund 1.000 Unternehmen sowie dem Vereinigten 
K&#246;nigreich mit fast 400 Unternehmen. Der Bundesrat ist daher der Auffassung, 
dass die zuk&#252;nftige KI-Verordnung so ausgestaltet werden muss, dass sie zur 
Entstehung und zum nachhaltigen Wachstum innovativer KI-Start-ups und 
-KMU beitr&#228;gt. 
19. Der Bundesrat bef&#252;rwortet deshalb den Ansatz einer risikobasierten
Regulierung von KI-Systemen, die sich gezielt auf jene Anwendungen konzentriert, in 
denen die Verwendung von KI-Technologien mit hohen beziehungsweise
inakzeptablen Risiken f&#252;r die Sicherheit und Gesundheit sowie die Grundrechte von 
Personen einhergeht.
20. Der Bundesrat begr&#252;&#223;t den gew&#228;hlten Ansatz, KI-Systeme nur insoweit
Sorgfalts- und &#220;berwachungspflichten zu unterwerfen, als ein hohes Risiko f&#252;r 
Rechte und Freiheiten besteht. In Anbetracht der Gefahr unerw&#252;nschter Folgen 
(zum Beispiel diskriminierende Effekte, falsche Ergebnisse wegen schlechter 
Datenqualit&#228;t oder Manipulation von au&#223;en), sind Sicherungsma&#223;nahmen f&#252;r 
kritische Anwendungen sinnvoll.
21. Der Bundesrat bittet die Bundesregierung darum, sich im weiteren
Gesetzgebungsverfahren daf&#252;r einzusetzen, dass dieser Ansatz konsequent und f&#252;r die 
betroffenen Akteure erf&#252;llbar umgesetzt wird. Es muss sichergestellt werden, 
dass die konkreten regulatorischen Anforderungen an eine bestimmte
Anwendung sich daran bemessen, dass diese tats&#228;chlich ein erhebliches
Risikopotenzial aufweist. Dies gilt insbesondere auch f&#252;r den Fall, wenn KI-Technologien als 
Teil eines Systems beziehungsweise Produkts eingesetzt werden, welches einer 
sektorspezifischen Regulierung unterliegt.
Wi
Wi
AIS 
Vk 
Wi
Wi
... 
22. Insbesondere muss vermieden werden, dass bereits langj&#228;hrig eingesetzte
Systeme, die kein oder nur ein geringes Risikopotenzial aufweisen oder deren
funktionale Sicherheit bereits nach sektorspezifischen Vorgaben gepr&#252;ft wurde, 
durch nachtr&#228;glich unerf&#252;llbare beziehungsweise nicht wirtschaftlich
darstellbare Anforderungen vom Markt genommen werden m&#252;ssen. Der Bundesrat weist 
in diesem Zusammenhang auch darauf hin, dass die Definitionen von KI-
Systemen (insbesondere die in Anhang I des Verordnungsvorschlags
aufgef&#252;hrten Techniken und Konzepte) mit Bedacht gew&#228;hlt werden m&#252;ssen. Nach dem 
Vorschlag der Kommission w&#252;rde beispielsweise jegliche Software, die
statistische Ans&#228;tze aufweist, als KI-Anwendung reguliert, was nach Auffassung des 
Bundesrates eine sehr weitgehende Definition ist.
23. Der Bundesrat begr&#252;&#223;t den Ansatz, zur Vermeidung von Doppelstrukturen und 
zur Nutzung vorhandener sektorspezifischer Expertise die Regulierung von KI-
Systemen, die in bestimmte Maschinen oder Systeme integriert werden, in
bestehende Regelungsrahmen zu integrieren. Einheitliche Ansprechpartner
erleichtern wirtschaftlichen Akteuren das Verfahren erheblich. Der Bundesrat
bittet jedoch um Pr&#252;fung, ob die ausschlie&#223;liche Zust&#228;ndigkeit der
sektorspezifischen Aufsichtsbeh&#246;rden auch im Falle der Verarbeitung personenbezogener 
Daten beibehalten werden kann, da der Vorschlag auch auf Artikel 16 AEUV 
gest&#252;tzt wird. Aus diesem folgt, dass &#8211; soweit personenbezogene Daten
verarbeitet werden &#8211; eine den Anforderungen gen&#252;gende &#8222;unabh&#228;ngige&#8220;
Aufsichtsbeh&#246;rde erforderlich ist. Diese Unabh&#228;ngigkeit d&#252;rfte nicht bei allen
sektorspezifischen Aufsichtsbeh&#246;rden gegeben sein. Eine Aufteilung der Zust&#228;ndigkeit 
zwischen zwei Beh&#246;rden im Falle der Betroffenheit (auch) personenbezogener 
Daten sollte vermieden werden. Sofern das nicht m&#246;glich ist, muss das
Verfahren der Zusammenarbeit geregelt werden.
24. Um Doppelbelastungen von Unternehmen bei der Erf&#252;llung von
Dokumentations- und Transparenzpflichten zu ein und demselben Produkt &#8211; beispielsweise 
in der Medizintechnikbranche &#8211; zu vermeiden, wird die Bundesregierung
gebeten, darauf hinzuwirken, bestehende Strukturen zu integrieren und den
Verwaltungsmehraufwand so gering wie m&#246;glich zu halten.
25. Aus Sicht des Bundesrates sollte die vorgeschlagene Verordnung in einigen 
Punkten noch ge&#228;ndert werden. Er bittet die Bundesregierung, bei den weiteren 
Beratungen auf EU-Ebene die folgenden Aspekte zu ber&#252;cksichtigen:
Wi
AIS 
Vk 
Wi
K 
AIS 
Vk 
Wi
...
Zu einzelnen Vorschriften 
26. Der Bundesrat unterst&#252;tzt das Bestreben der Kommission, auch Anbieter und 
Nutzende von KI-Systemen, die in Drittstaaten ans&#228;ssig sind, in den
Anwendungsbereich der Verordnung einzubeziehen, wenn sie die KI-Systeme in der 
Union in Verkehr bringen oder sich die Verwendung der KI-Systeme auf die 
Menschen in der Union auswirkt. Allerdings sollte bei den weiteren
Verhandlungen gepr&#252;ft werden, den Geltungsbereich der Verordnung auch f&#252;r Anbieter 
und Nutzende in Drittstaaten zu &#246;ffnen, wenn diese Daten von B&#252;rgerinnen und 
B&#252;rgern auswerten und das vom KI-System erzeugte Ergebnis Auswirkungen 
auf die B&#252;rgerinnen und B&#252;rger in der Union haben kann. Aus Sicht des
Bundesrates birgt die in Artikel 2 Absatz 1 Buchstabe c des Verordnungsvorschlags 
gew&#228;hlte Bedingung, dass das vom KI-System hervorgebrachte Ergebnis in der 
Union verwendet werden m&#252;sse, die Gefahr von Rechtsunsicherheit und
Umgehung.
27. Der Bundesrat merkt an, dass mit der weitgehenden Herausnahme von
Kraftfahrzeugen aus dem Anwendungsbereich der Verordnung ein wesentlicher und 
praxisnaher Bereich von KI-Anwendungen unreguliert bleibt. Die Kommission 
gibt lediglich den Hinweis, dass Kraftfahrzeuge nicht dem &#8222;New Legislative 
Framework&#8220; unterliegen, begr&#252;ndet ihre Entscheidung jedoch nicht n&#228;her.
28. Der Bundesrat stellt fest, dass der Begriff &#8222;System der K&#252;nstlichen Intelligenz&#8220; 
in Artikel 3 Absatz 1 in Verbindung mit Anhang I des Verordnungsvorschlags 
sehr weit gefasst ist. Dies erscheint grunds&#228;tzlich angemessen, da diese
Definition die breite Diskussion in der Wissenschaft und Fachwelt widerspiegelt. Eine 
einheitliche Definition existiert (bisher) nicht. Da an die Bewertung als KI
allein zun&#228;chst keine Folgen gekn&#252;pft sind, ist es unproblematisch, einen weiten 
Begriff zu w&#228;hlen. 
29. Allerdings sollte die weite Definition und Beschreibung der Methoden KI auf 
&#8222;aus sich selbst heraus lernende Systeme&#8220; beschr&#228;nkt werden. Nahezu jede IT-
Anwendung verwendet einfache Sortier- und Suchalgorithmen und nutzt
demnach KI-Methoden gem&#228;&#223; der Definition in Anhang I des
Verordnungsvorschlags. In der Folge sind nahezu alle IT-Anwendungen von der Verordnung
erfasst. 
AV
AV
AIS 
Vk 
Wi
R
... 
30. Die Definition von KI-Systemen, die von der Regulierung betroffen sein sollen, 
in Anhang I des Verordnungsvorschlags &#8222;ARTIFICIAL INTELLIGENCE 
TECHNIQUES AND APPROACHES&#8220; (verwiesen von Artikel 3 Absatz 1 des 
Verordnungsvorschlags) enth&#228;lt unter Buchstabe c (&#8222;Statistical approaches, 
Bayesian estimation, search and optimization methods&#8220;) eine Reihe von
mathematischen beziehungsweise informatischen Methoden beziehungsweise
Gebieten, die zwar &#8211; nach derzeitigem Wissensstand &#8211; als umfassend betrachtet 
werden k&#246;nnen, unter die jedoch insbesondere einfache statistische
Vorgehensweisen ohne erhebliche Grundrechtsrisiken fallen, zu denen m&#246;glicherweise 
auch die Wahrscheinlichkeitsbehandlung nach Bayes zu z&#228;hlen w&#228;re. Bei einer 
derart weiten Definition k&#246;nnten streng genommen bereits die einfache
Berechnung eines Mittelwerts oder einer Standardabweichung sowie die Anwendung 
von linearer Regression oder &#196;hnlichem unter die KI-Methoden fallen, die von 
der Regulierung betroffen w&#228;ren. [Auch konventionelle Methoden der
amtlichen Statistik k&#246;nnten der Definition unterfallen.] Der Bundesrat bittet daher 
die Bunderegierung, [f&#252;r eine Streichung des ersten Teils von Anhang I
Buchstabe c des Verordnungsvorschlags (&#8222;Statistical approaches&#8220;) und im &#220;brigen 
auch] f&#252;r eine Engerfassung der Definition von KI-Methoden beziehungsweise 
einer erl&#228;uternden Klarstellung des angedachten Umfangs zu pl&#228;dieren. Sollte 
dem nicht entsprochen werden k&#246;nnen, wird die Streichung von Anhang I 
Buchstabe c des Verordnungsvorschlags empfohlen. 
31. Nach Auffassung des Bundesrates ist die Beschr&#228;nkung der Verbote in
Artikel 5 Absatz 1 Buchstaben a und b des Verordnungsvorschlags auf
manipulative KI-Systeme, die physischen oder psychischen Schaden zuf&#252;gen, aus
Gr&#252;nden des Verbraucherschutzes nicht ausreichend. Die Bundesregierung wird
gebeten, sich daf&#252;r einzusetzen, dass auch KI-Systeme, die in der Absicht
hergestellt, in Verkehr gebracht oder verwendet werden, Menschen in unlauterer 
Weise wirtschaftlich zu sch&#228;digen, in die Verbote nach Artikel 5 des
Verordnungsvorschlags aufgenommen werden.
32. Der Bundesrat sieht au&#223;erdem bei einem uneingeschr&#228;nkten Einsatz von KI-
Systemen zur Identifizierung von Personen aufgrund biometrischer Daten sowie 
von Emotionserkennungssystemen durch private Unternehmen die Gefahr, dass 
personenbezogene Daten unter Missachtung der Zweckbindung von
Unternehmen zu umfassenden Profilbildungen und zur Verfeinerung manipulativer
Methoden der Beeinflussung von Verbraucherentscheidungen verwendet werden.
In 
K
[In]
AV
AV
...
Auch besteht bei Emotionserkennungssystemen ein gro&#223;es Potenzial f&#252;r
Fehleinsch&#228;tzungen, die f&#252;r betroffene Menschen mit erheblichen nachteiligen
Folgen verbunden sein k&#246;nnen und durch blo&#223;e Informationspflichten nicht
wirksam verhindert werden. Dies gilt insbesondere beim Einsatz derartiger Systeme 
als &#8222;digitaler L&#252;gendetektor&#8220;. Der Bundesrat bittet daher die Bundesregierung, 
sich bei den weiteren Verhandlungen f&#252;r die notwendigen Einschr&#228;nkungen 
einzusetzen. 
33. Der Bundesrat bittet die Bundesregierung zu pr&#252;fen, ob der
Anwendungsbereich des Verbots des sogenannten &#8222;Social Scoring&#8220; in Artikel 5 Absatz 1 
Buchstabe c des Verordnungsvorschlags auch auf Unternehmen erstreckt
werden kann, deren Leistungen f&#252;r die B&#252;rgerinnen und B&#252;rger f&#252;r eine
gleichberechtigte Teilhabe von grundlegender Bedeutung sind. Aus Sicht des
Bundesrates kann auch bei nicht-beh&#246;rdlichem Einsatz von KI-Systemen zur Bewertung 
des sozialen Verhaltens die Gefahr von ungerechtfertigter Diskriminierung und 
einem grundrechtebeeintr&#228;chtigenden sozialen Anpassungsdruck bestehen.
34. Der Verordnungsvorschlag enth&#228;lt abgesehen von Artikel 5 keine materiellen 
Anforderungen zum Grundrechtsschutz, zum Schutz vor unerw&#252;nschten
Diskriminierungen oder zur Einhaltung von gesetzlichen Vorgaben. Sowohl die 
Konformit&#228;tsbewertungsverfahren als auch die beh&#246;rdliche Aufsicht w&#228;ren
damit auf eine &#220;berpr&#252;fung der &#252;berwiegend organisatorischen und
qualit&#228;tssichernden Schutzvorkehrungen beschr&#228;nkt. Aus Sicht des Bundesrates kann der 
notwendige pr&#228;ventive Schutz vor denkbaren Grundrechtsverletzungen und
unerw&#252;nschten Diskriminierungen durch KI-Systeme jedoch nur dann ausreichend 
gew&#228;hrleistet werden, wenn die Verordnung die Anbieter von KI-Systemen
bereits bei ihrer Konzeption und Entwicklung ausdr&#252;cklich an die Einhaltung von 
Grundrechten, Diskriminierungsverboten und sonstigen gesetzlichen Vorgaben, 
insbesondere zum Datenschutz, bindet. Der Bundesrat bittet die
Bundesregierung, sich bei den weiteren Verhandlungen f&#252;r die notwendigen Erg&#228;nzungen 
einzusetzen.
AV
AV
... 
35. Der Bundesrat begr&#252;&#223;t die Zielsetzung der Kommission, nach dem
risikobasierten Ansatz im Bereich der KI Praktiken zu verbieten, welche die Schw&#228;che oder 
Schutzbed&#252;rftigkeit einer bestimmten Gruppe von Personen aufgrund ihres
Alters oder ihrer k&#246;rperlichen oder geistigen Behinderung ausnutzen. Zur
Pr&#228;zisierung des Personenkreises der Menschen mit Behinderungen sollte in Artikel 5 
Absatz 1 Buchstabe b des Verordnungsvorschlags im Einklang mit Artikel 1 der 
VN-Behindertenrechtskonvention explizit auf Menschen abgestellt werden, die 
k&#246;rperliche, seelische, geistige oder Sinnesbeeintr&#228;chtigungen haben. Dies gilt 
speziell, wenn das Verhalten einer dieser Gruppe angeh&#246;renden Person in einer 
Weise wesentlich beeinflusst werden soll, die dazu f&#252;hrt, dass sie selbst oder
eine andere Person psychisch oder physisch gesch&#228;digt werden k&#246;nnte. Gerade 
bei Menschen mit seelischen Beeintr&#228;chtigungen wird in der Folge das Risiko 
einer psychischen Sch&#228;digung gesehen.
36. Der Bundesrat begr&#252;&#223;t den von der Kommission vorgelegten risikobasierten 
Ansatz und den damit einhergehenden Fokus auf Hochrisiko-KI-Systeme. Mit 
der risikobasierten Einteilung in KI-Systeme der Klassen 1 (unannehmbares
Risiko), 2 (hohes Risiko) und 3 (geringes oder minimales Risiko) greift die
Kommission die vom Bundesrat in seiner Stellungnahme vom 15. Mai 2020 (BR-
Drucksache 95/20 (Beschluss)) ge&#228;u&#223;erten Bedenken auf. Die vorgelegte
Einteilung in Risikoklassen wird grunds&#228;tzlich als angemessen eingesch&#228;tzt, um im 
gleichen Ma&#223;e Grundrechte und insbesondere Verbraucherrechte zu sch&#252;tzen 
sowie die europ&#228;ische Innovationsf&#228;higkeit durch die Schaffung von
Rechtssicherheit zu st&#228;rken.
37. Der Bundesrat teilt die Einsch&#228;tzung der Kommission, dass mit der Auflistung 
von Hochrisiko-KI-Systemen Rechtssicherheit erm&#246;glicht werden kann. Er
begr&#252;&#223;t, dass die Auflistung regelm&#228;&#223;ig aktualisiert werden soll. Der Bundesrat 
bittet die Kommission jedoch um kritische Pr&#252;fung, ob die im Vorschlag
aufgelisteten Hochrisikoanwendungsbereiche berechtigterweise aufgef&#252;hrt sind. Er 
regt dar&#252;ber hinaus an, Forschung und Entwicklung zu Indikatoren zu
unterst&#252;tzen und eine klare Operationalisierung aller Risikoklassen anzuwenden.
AIS
Vk 
Vk
...
38. Der Bundesrat gibt zu bedenken, dass, basierend auf diesem sehr weit gefassten 
Verst&#228;ndnis von KI-Systemen, die Bewertung als &#8222;Hochrisiko-KI-System&#8220; auch 
sehr weitreichend ist und im Einzelfall zu der unbeabsichtigten Erfassung von 
Anwendungen f&#252;hrt, die kaum als besonders risikoreich zu bewerten sind. Es 
sollte daher zus&#228;tzlich klargestellt werden, dass nur Systeme gemeint sind, von 
denen erhebliche sch&#228;dliche Auswirkungen auf die Gesundheit, die Sicherheit 
und die Grundrechte von Personen ausgehen, wie in Erw&#228;gungsgrund 27 des 
Verordnungsvorschlags erw&#228;hnt.
39. Bei Hochrisiko-KI-Systemen nach Artikel 6 des Verordnungsvorschlags
werden alle verantwortlichen Akteure umfangreichen Pflichten unterworfen. Dies 
erscheint in einigen denkbaren Konstellationen nicht gerechtfertigt. Aktuell 
werden in Anhang III des Verordnungsvorschlags die Hochrisiko-KI-Systeme 
im Stil einer fallbezogenen Darstellung definiert, die sich an Einsatzgebiet und 
-zweck orientiert. Legt man diesen Anwendungen jedoch die verwendete
Begriffsbestimmung f&#252;r KI zugrunde, so ist nahezu jeder kleinere Such- oder
Sortieralgorithmus innerhalb einer Software als Hochrisiko-KI-System zu werten, 
wenn diese f&#252;r die genannten Zwecke &#8222;bestimmt&#8220; ist. Dies birgt die Gefahr
eines erh&#246;hten b&#252;rokratischen und finanziellen Aufwands bei der Zulassung von 
Softwaresystemen f&#252;r die genannten Anwendungsgebiete, ohne dass hierzu ein 
Anlass best&#252;nde. Die Formulierung &#8222;bestimmungsgem&#228;&#223;&#8220; in den F&#228;llen des 
Anhangs III des Verordnungsvorschlags allein l&#228;sst nicht erkennen, dass zum 
Beispiel bei der Programmierung der Software diese Bestimmung vorgesehen 
worden sein muss. Eine &#8222;Bestimmung&#8220; der Zielsetzung durch Nutzende &#8211; wozu 
das System jedoch gar nicht vorgesehen ist &#8211; k&#246;nnte dem Wortlaut nach ebenso 
gen&#252;gen. Es w&#228;re zu weitgehend, jede denkbare Einsatzm&#246;glichkeit
heranzuziehen. Aus Ziffer 5.2.3 der Begr&#252;ndung des Verordnungsvorschlags geht
hervor, dass die Einstufung &#8222;auf der Zweckbestimmung des KI-Systems
entsprechend den bestehenden EU-Produktsicherheitsvorschriften&#8220; erfolgt, womit die 
Einstufung als Hochrisiko-KI-System nicht nur von der Funktion dieses
Systems abhinge, sondern auch von seinem konkreten Zweck und seinen
Anwendungsmodalit&#228;ten. Um Unklarheiten zu vermeiden, sollte daher in Anhang III 
des Verordnungsvorschlags jeweils der Begriff &#8222;bestimmungsgem&#228;&#223;&#8220; durch 
&#8222;entsprechend ihrer Zweckbestimmung&#8220; nach Artikel 3 Ziffer 12 des
Verordnungsvorschlags ersetzt werden.
AIS 
Vk 
Wi
AIS 
Vk 
Wi
... 
40. Der Bundesrat h&#228;lt zudem die Bezeichnung &#8222;Hochrisiko-KI-System&#8220; nicht in 
jedem Fall f&#252;r angemessen. Der Begriff kann auf nichttechnisch gepr&#228;gte
Menschen, die mit Technikfolgenabsch&#228;tzungen nicht vertraut sind, abschreckend 
wirken und gegebenenfalls dazu f&#252;hren, dass kein KI-System eingesetzt wird, 
um kein &#8222;hohes Risiko&#8220; einzugehen. Nachdem die Kommission wiederholt
betont hat, dass es bei der Regulierung vor allem darum gehe, dass Menschen KI 
vertrauen (k&#246;nnen), sollte eine andere Formulierung erwogen werden, zum
Beispiel &#8222;regulierte KI&#8220; oder &#8222;pr&#252;fbed&#252;rftige KI&#8220;, insbesondere wenn Systeme
gemeint sind, die gem&#228;&#223; Artikel 6 des Verordnungsvorschlags als
Sicherheitskomponente Risiken senken sollen. Der Begriff ist zudem inkonsequent, da im 
Folgenden (Artikel 65 fortfolgende des Verordnungsvorschlags) zum Beispiel 
von &#8222;konformen KI-Systemen, die ein Risiko bergen&#8220; gesprochen wird.
&#8222;Konforme KI-Systeme&#8220; sind Hochrisiko-KI-Systeme, die den f&#252;r sie aufgestellten 
Anforderungen entsprechen, aber dennoch ein (weiteres) spezifisches Risiko 
bergen. Diese Systeme sind demnach noch risikobehafteter als blo&#223;e
&#8222;Hochrisiko-KI-Systeme&#8220;, was in der Terminologie deutlich werden sollte.
41. Der Bundesrat h&#228;lt jedoch aus Gr&#252;nden des Verbraucherschutzes die Definition 
und Aufz&#228;hlung von Hochrisiko-KI-Systemen f&#252;r nicht ausreichend. So sollten 
nicht nur das &#8222;Kreditscoring&#8220;, sondern auch sonstige &#8222;KI-Scoring&#8220;-Verfahren, 
auf deren Grundlage Unternehmen &#252;ber den Zugang zu unverzichtbaren
Leistungen wie beispielsweise Krankenversicherungen,
Gesundheitsdienstleistungen und Wohnraum entscheiden, in Anhang III des Verordnungsvorschlags 
aufgenommen werden. Gleiches gilt f&#252;r &#8222;Scoring&#8220;-Verfahren, die aufgrund
ihrer Zweckbestimmung, der verwendeten Daten und der angewandten Kriterien 
ein hohes Diskriminierungspotenzial bergen. Beispielhaft genannt sind KI-
gest&#252;tzte Kundenprofile, die &#252;ber den Zugang zum Angebot von
Ferienunterk&#252;nften oder Bef&#246;rderungsdienstleistungen entscheiden.
42. Der Bundesrat verweist beispielhaft auf die Gesundheitsindustrie. Im Rahmen 
der neuen Medizinprodukte- und In-Vitro-Diagnostik-Regulierung 
(MDR/IVDR) wurden bereits umfangreiche Anforderungen an die Qualit&#228;t der 
Produkte und die Patientensicherheit vorgegeben, die auch auf KI-Systeme 
Anwendung finden. Die Umsetzung dieser Anforderungen stellt die Branche, 
die in einem starken internationalen Wettbewerb steht, vor erhebliche
Herausforderungen. Dies f&#252;hrt auch zu unerw&#252;nschten Folgen f&#252;r die
Patientenversorgung, weil dringend ben&#246;tigte Bestands- und Nischenprodukte nicht mehr her-
AIS 
Vk 
Wi
AV
Wi 
(bei
Annahme 
entf&#228;llt 
Ziffer 43)
...
gestellt werden und die Neuentwicklung von Innovationen ausgesetzt wird. Vor 
diesem Hintergrund k&#246;nnte eine pauschale Einstufung praktisch aller
softwarebasierten MDR/IVD-Produkte als Hochrisiko-KI-Anwendungen dazu f&#252;hren, 
dass KI-Innovationen im Gesundheitssektor nachhaltig und auf breiter Front 
ausbleiben und insbesondere KMU sich aus der KI-Entwicklung zur&#252;ckziehen. 
Eine Unterscheidung zwischen KI-basierten und auf konventioneller Software 
basierenden (Bestands-)Medizinprodukten sowie eine
anwendungsfallspezifische Risikoeinstufung, die beispielsweise ber&#252;cksichtigt, ob die KI Patientinnen 
und Patienten oder medizinisches Personal lediglich unterst&#252;tzt oder
menschliche Handlungen weitestgehend ersetzt, k&#246;nnten diese negativen Effekte
reduzieren beziehungsweise verhindern.
43. Aus Sicht des Bundesrates sollte auch erwogen werden, eingesetzte KI-Systeme 
bei Produkten und Dienstleistungen, die der F&#246;rderung der menschlichen
Gesundheit dienen und von denen nicht nur unerhebliche Gefahren f&#252;r die 
menschliche Gesundheit ausgehen k&#246;nnen, generell als Hochrisiko-KI-Systeme 
einzustufen und dies nicht von ihrer Eigenschaft als Sicherheitskomponente f&#252;r 
Medizinprodukte abh&#228;ngig zu machen. In jedem Fall sollte die
Bereichsbeschr&#228;nkung in Artikel 7 Absatz 1 Buchstabe a des Verordnungsvorschlags, die 
einem umfassenden Gefahrenschutz bei gesundheitsrelevanten Produkten und 
Diensten entgegenstehen k&#246;nnte, aufgehoben oder gelockert werden.
44. Der Bundesrat h&#228;lt die Aufz&#228;hlung der sch&#252;tzenswerten Belange in Artikel 7 
Absatz 1 Buchstabe b und Absatz 2 des Verordnungsvorschlags, die den
Rahmen f&#252;r die Einbeziehung weiterer Hochrisiko-KI-Systeme setzen, f&#252;r nicht 
ausreichend. Er bittet die Bundesregierung, sich daf&#252;r einzusetzen, dass darin 
auch das Risiko einer erheblichen wirtschaftlichen Sch&#228;digung einer Vielzahl 
von Verbraucherinnen und Verbrauchern aufgenommen wird.
45. Zum Schutz vor unkontrollierbaren Risiken bittet der Bundesrat zu pr&#252;fen, ob 
vor allem beim Einsatz von Hochrisiko-KI-Systemen als
Sicherheitskomponenten in Produkten die Weiterentwicklung der Systeme durch selbstlernende
Prozesse an bestimmte Regeln gebunden sein sollte, die vom KI-System nicht 
&#252;berwunden werden k&#246;nnen.
AV 
(entf&#228;llt 
bei
Annahme 
von 
Ziffer 42)
AV
AV
... 
46. Der Bundesrat sieht au&#223;erdem Verbesserungsbedarf hinsichtlich der
&#220;berpr&#252;fbarkeit von Hochrisiko-KI-Systemen und ihren Entscheidungen. Bei
Hochrisiko-KI-Systemen sollten Anstrengungen unternommen werden, nicht nur die 
Prozesse zu protokollieren, sondern auch die vom KI-System hervorgebrachten 
Ergebnisse erkl&#228;rbar und ihre Gr&#252;nde nachvollziehbar zu machen. Um zu
gew&#228;hrleisten, dass die Anwendung von KI-Systemen beim Verdacht erheblicher 
unvorhergesehener Risiken tats&#228;chlich gestoppt wird und keine Folgerisiken 
entstehen, sollten grunds&#228;tzlich die Basisfunktionen des mit der KI
verbundenen restlichen Produkts oder Systems weiterhin verf&#252;gbar sein.
47. Der Bundesrat begr&#252;&#223;t die vorgeschlagene Flexibilit&#228;t von Ex-ante-
Konformit&#228;tspr&#252;fungen von Hochrisiko-KI-Systemen sowie deren Integration 
in bereits bestehende Konformit&#228;tspr&#252;fungen, wo immer dies m&#246;glich ist. Er 
weist darauf hin, dass durch die Konformit&#228;tspr&#252;fungen KMU und Start-ups 
nicht &#252;berm&#228;&#223;ig belastet werden sollen, und regt an zu pr&#252;fen, inwieweit hier 
weitere unterst&#252;tzende Ma&#223;nahmen ergriffen werden k&#246;nnen.
48. Der Bundesrat stuft die an Hochrisiko-KI-Systeme formulierten Anforderungen 
als grunds&#228;tzlich w&#252;nschenswert ein. Er weist jedoch darauf hin, dass die
Implementierung dieser Anforderungen teilweise eine technische Herausforderung 
darstellt. Der Bundesrat sieht in diesem Zusammenhang Forschungs- und
Entwicklungsbedarf, der ein Zusammenwirken von wirtschaftlichen,
wissenschaftlichen und zivilgesellschaftlichen Akteuren erfordert.
49. Der Bundesrat begr&#252;&#223;t die &#220;berlegung der Kommission, f&#252;r die Durchf&#252;hrung 
der Konformit&#228;tsbewertung von Hochrisiko-KI-Systemen ein System von
notifizierten Stellen einzusetzen. Er sieht darin die M&#246;glichkeit, auf den
hervorragenden deutschen Pr&#252;finfrastrukturen aufzubauen. Er weist jedoch darauf hin, 
dass bei dieser dezentralen Markt&#252;berwachung ein einheitliches und
angemessenes Qualit&#228;tsniveau zu gew&#228;hrleisten ist. Er bittet die Kommission,
entsprechende Vorkehrungen der Qualit&#228;tssicherung zu treffen.
50. Der Bundesrat stellt fest, dass sich die Konformit&#228;tsbewertung bei Hochrisiko-
KI-Systemen im Sinne des Anhangs III des Verordnungsvorschlags weitgehend 
auf eine interne Kontrolle durch den Anbietenden beschr&#228;nkt. Eine externe
AV
Vk 
Vk 
Vk 
AV
...
Kontrolle durch eine notifizierte Stelle bietet jedoch gr&#246;&#223;ere Gew&#228;hr f&#252;r eine 
unabh&#228;ngige Pr&#252;fung und sollte vor allem dann, wenn die Gefahr von
erheblichen Sch&#228;den und Grundrechtsbeeintr&#228;chtigungen besteht, der Regelfall sein. 
Der Bundesrat regt daher an, unter Ber&#252;cksichtigung des
Verh&#228;ltnism&#228;&#223;igkeitsgrundsatzes eine Erweiterung der Verpflichtung zu einer externen
Konformit&#228;tsbewertung vor allem bei Hochrisiko-KI-Systemen, die zu kommerziellen 
Zwecken eingesetzt werden, zu pr&#252;fen.
51. Die Kapazit&#228;ten und Kompetenzen von Konformit&#228;tsbewertungsstellen k&#246;nnen 
aber auch ein Engpass f&#252;r die Zulassung von bestimmten
Hochrisikoanwendungen sein. Der Bundesrat verweist in diesem Zusammenhang auf die
Erfahrungen bei der Umsetzung der MDR und IVDR, wo fehlende Benannte Stellen
erhebliche negative Auswirkungen auf die betroffenen Unternehmen und die
Patientenversorgung haben. Der Bundesrat bittet die Bundesregierung deshalb,
daf&#252;r Sorge zu tragen, dass den Unternehmen die Infrastruktur, die sie zur
Erf&#252;llung von regulatorischen Anforderungen an Hochrisiko-KI-Systeme zwingend 
ben&#246;tigen, rechtzeitig und in ausreichender Kapazit&#228;t zur Verf&#252;gung steht.
52. Der Bundesrat begr&#252;&#223;t, dass f&#252;r Hochrisiko-KI-Systeme ein
Risikomanagementsystem eingerichtet und angewandt wird. Bei dessen Umsetzung ist gem&#228;&#223; 
Artikel 9 Absatz 8 des Verordnungsvorschlags insbesondere zu
ber&#252;cksichtigen, ob das Hochrisiko-KI-System wahrscheinlich f&#252;r Kinder zug&#228;nglich ist
oder Auswirkungen auf Kinder hat. Der Bundesrat spricht sich daf&#252;r aus, analog 
dem Schutzgedanken von Artikel 5 Absatz 1 Buchstabe b des
Verordnungsvorschlags auch die wahrscheinliche Betroffenheit weiterer aufgrund ihres Alters 
oder ihrer k&#246;rperlichen, seelischen, geistigen oder Sinnesbeeintr&#228;chtigungen 
schutzbed&#252;rftiger Gruppen explizit im Rahmen eines
Risikomanagementsystems zu ber&#252;cksichtigen. 
53. Der Bundesrat bittet die Kommission zu pr&#252;fen, ob die Einhaltung der in
Artikel 10 des Verordnungsvorschlages normierten Anforderungen an die genutzten 
Daten auch durch eine Best&#228;tigung von KI-Dienstleistern nachgewiesen werden 
kann. Besonders KMU sind von einer mangelnden Datenbasis betroffen. 
54. Der Vorschlag sieht au&#223;erdem besondere Transparenzpflichten f&#252;r bestimmte 
KI-Systeme, die mit nat&#252;rlichen Personen interagieren, vor. Gleiches gilt f&#252;r 
Emotionserkennungs-Systeme, Systeme zur biometrischen Kategorisierung und
Wi
AIS
K 
AIS
... 
KI-Systeme, die Bild-, Ton- oder Videoinhalte erzeugen oder manipulieren, die 
wirklichen Personen, Gegenst&#228;nden oder Orten merklich &#228;hneln und einer
Person f&#228;lschlicherweise als echt erscheinen w&#252;rden (&#8222;Deepfake&#8220;). Dass die
entsprechenden Informationen und Mitteilungen f&#252;r die Nutzenden f&#252;r Menschen 
mit Behinderungen in barrierefrei zug&#228;nglicher Form bereitgestellt werden
sollten, wird lediglich in Erw&#228;gungsgrund 70 des Verordnungsvorschlags erw&#228;hnt. 
Aus Sicht des Bundesrates ist Artikel 52 des Verordnungsvorschlags um eine 
entsprechende Ma&#223;gabe zu erg&#228;nzen, analog Artikel 13 Absatz 2 des
Verordnungsvorschlags betreffend die Gebrauchsanweisungen f&#252;r Hochrisiko-KI-
Systeme in barrierefrei zug&#228;nglicher und verst&#228;ndlicher Form.
55. Der Bundesrat begr&#252;&#223;t die von der Kommission in Artikel 53 des
Verordnungsvorschlages vorgesehenen KI-Reallabore[, in denen das Experimentieren von 
KI-Technologien erleichtert und Innovationen im Zusammenspiel mit
Regulierung praxisnah ausprobiert werden sollen].
56. Der Bundesrat empfiehlt, KI-Reallabore grunds&#228;tzlich in allen Branchen, die 
die Mitgliedstaaten als sinnvoll erachten, zu erm&#246;glichen. Er bittet die
Bundesregierung, z&#252;gig entsprechende Initiativen zu starten, um das deutsche
Innovationspotenzial, insbesondere von KMU und Start-ups, zu heben. Der Bundesrat 
erinnert daran, dass in den L&#228;ndern bereits erste Anstrengungen unternommen 
wurden, die es mit den vorgeschlagenen Ma&#223;nahmen zu st&#228;rken und aktiv
einzubeziehen gilt.
57. Der Bundesrat begr&#252;&#223;t besonders den Ansatz der Einrichtung von KI-
Reallaboren. Eine solche staatliche Investition in die Entwicklung und
Erprobung innovativer Anwendungen ist sehr positiv, insbesondere da die KI-
Reallabore zug&#228;nglich f&#252;r Unternehmen aller Gr&#246;&#223;en sein sollen. Der Ansatz 
beseitigt potenziell zu hohe Entwicklungskosten und zielt auf die Vermeidung 
der vielleicht gr&#246;&#223;ten H&#252;rde f&#252;r KMU, der Rechtsunsicherheit, ab. Der
Bundesrat bittet jedoch um Pr&#252;fung, ob die den Datenschutz betreffenden
Bestimmungen im Zusammenhang mit den KI-Reallaboren klarer gefasst werden k&#246;nnen. 
Hinsichtlich der Verarbeitung personenbezogener Daten ist nicht klar, ob
Artikel 54 des Verordnungsvorschlags als eigenst&#228;ndige Rechtsgrundlage zur 
(zweck&#228;ndernden) Verarbeitung personenbezogener Daten zu verstehen ist. Der 
Wortlaut von Artikel 54 Absatz 1 des Verordnungsvorschlags legt dies nahe, 
der Erw&#228;gungsgrund 41 und Artikel 54 Absatz 2 des Verordnungsvorschlags
K 
Vk 
[K]
Vk 
AIS 
Vk 
Wi
...
hingegen sprechen dagegen. Die zweck&#228;ndernde Verarbeitung ist in der
Datenschutzgrundverordnung (DSGVO) grunds&#228;tzlich geregelt (vergleiche Artikel 6 
Absatz 4 in Verbindung mit Artikel 23 DSGVO). Es muss klar sein, ob er
zus&#228;tzlich zu Artikel 54 des Verordnungsvorschlags zu beachten ist. Weiterhin ist 
klarzustellen, wer in der Konstellation &#8222;KI-Reallabor&#8220; datenschutzrechtlich
verantwortlich sein soll. Artikel 53 Absatz 4 des Verordnungsvorschlags spricht 
lediglich von der Schadenshaftung der &#8222;Beteiligten&#8220;. Artikel 53 Absatz 3 des 
Verordnungsvorschlags l&#228;sst zudem alle &#8222;Aufsichts- und Abhilfebefugnisse&#8220; 
der zust&#228;ndigen Beh&#246;rden unber&#252;hrt &#8211; wenigstens im europ&#228;ischen Kontext ist 
dies der Europ&#228;ische Datenschutzbeauftragte (EDPS), dessen Beh&#246;rde das KI-
Reallabor auch betreibt. Es bedarf hier einer Klarstellung der Rollen, m&#246;glichst 
nicht erst durch einen Durchf&#252;hrungsrechtsakt nach Artikel 53 Absatz 6 des 
Verordnungsvorschlags. 
58. F&#252;r den Bundesrat steht au&#223;er Frage, dass der Zugang f&#252;r Menschen mit
Behinderungen zur Nutzung von KI-Systemen trotz der gesehenen Risiken zu
gew&#228;hrleisten ist. Er h&#228;lt es daher f&#252;r erforderlich, die Sicherstellung
ausreichender Barrierefreiheit von KI-Systemen in dem Verordnungsvorschlag in
geeigneter Weise zu verankern, und bittet die Bundesregierung, sich hierf&#252;r bei den 
weiteren Verhandlungen einzusetzen. Auch sollte nach Ansicht des Bundesrates 
in Artikel 69 Absatz 2 des Verordnungsvorschlags &#8211; ebenso wie in Absatz 1 &#8211; 
darauf verzichtet werden, die in Verhaltenskodizes vorgesehene Erf&#252;llung
weiterer Anforderungen f&#252;r KI-Systeme, wie die barrierefreie Zug&#228;nglichkeit f&#252;r 
Personen mit Behinderungen, nochmals explizit als &#8222;freiwillig&#8220; zu bezeichnen, 
da Verhaltenskodizes ohnehin in Form freiwilliger Selbstverpflichtung
eingegangen werden.
Zum Einsatz von Daten in KI-Systemen
59. Der Bundesrat bittet die Bundesregierung, sich f&#252;r eine bessere Verf&#252;gbarkeit 
von qualitativ hochwertigen Daten zur Entwicklung von KI-Systemen
einzusetzen, weil dies nicht nur eine wichtige Voraussetzung f&#252;r die Entwicklung
innovativer KI-L&#246;sungen, sondern auch f&#252;r die Vermeidung bestimmter Risiken wie 
etwa unerw&#252;nschten Verzerrungen (Bias) ist.
60. Daten-Synthetisierung kann ein wichtiger Ansatz sein, um weitere Fortschritte 
bei maschinellem Lernen und KI zu erreichen. Der Bundesrat bittet die Bundes-
AIS
Wi
Wi
... 
regierung, sich auch f&#252;r eine Kl&#228;rung der wichtigsten rechtlichen und ethischen 
Fragen der Daten-Synthetisierung einzusetzen. 
61. Der medizinische Fortschritt durch KI ist ma&#223;geblich davon abh&#228;ngig, dass
Daten aus der medizinischen Versorgung und der klinischen Forschung sowie von 
Patientinnen und Patienten selbst erhobene Daten zeitnah und &#252;bergreifend
ausgewertet und die daraus gezogenen Erkenntnisse in die medizinische Praxis 
umgesetzt werden k&#246;nnen. Die Attraktivit&#228;t des Wirtschaftsstandortes
Deutschland h&#228;ngt heute stark davon ab, dass forschende Unternehmen und
Einrichtungen der &#246;ffentlichen Forschung auch im Sinne von Kooperationen einen
Rechtsrahmen vorfinden, in dem die Forschung stattfinden kann. Daher sollte eine 
praxistaugliche Umsetzung der Harmonisierung der Datenschutzgesetzgebung 
in Deutschland ebenso in der vereinbarten und gelebten Zusammenarbeit der 
L&#228;nder im Fokus bleiben wie die Weiterentwicklung eines gleichberechtigten 
Zugangs zu Forschungsdaten auf Bundes- und EU-Ebene f&#252;r die &#246;ffentliche und 
die private Forschung, etwa im Falle des Forschungsdatenzentrums nach &#167; 303d 
SGB V.
Zum Medienbereich
62. Aufgrund der zunehmenden Digitalisierung und Konvergenz der Medien sowie 
der wachsenden Bedeutung digitaler Plattformen f&#252;r die Medienlandschaft
einerseits und f&#252;r die freie demokratische Willensbildung andererseits ist der 
Umgang mit KI-Systemen auch von besonderer medienpolitischer Bedeutung.
63. Der Bundesrat sieht Transparenz als ein wichtiges Element im Umgang mit KI-
Systemen an und verweist dabei auch auf die im Medienstaatsvertrag der
L&#228;nder vorgesehene Transparenzpflicht bei der Anwendung sogenannter Social 
Bots.
64. Der Bundesrat begr&#252;&#223;t daher, dass f&#252;r bestimmte KI-Systeme, die mit
nat&#252;rlichen Personen interagieren, Transparenzpflichten bestehen. Er hebt in diesem 
Zusammenhang die besondere Bedeutung von KI im Bereich der Medien- und 
Meinungsfreiheit sowie in demokratischen Prozessen hervor. Er bittet um eine 
m&#246;glichst einheitliche und einfache Kennzeichnung.
Wi
K 
K 
Vk
...
65. Der Bundesrat betont, dass die Regelungskompetenz zur Sicherung des
Medienpluralismus nach den europ&#228;ischen Vertr&#228;gen bei den Mitgliedstaaten und als 
Ausdruck des F&#246;deralismus in Deutschland bei den L&#228;ndern liegt. Die Organe 
der EU haben den Pluralismus der Medien und die Vielfalt der verschiedenen 
nationalen Medienlandschaften in Europa bei der Aus&#252;bung ihrer jeweiligen 
Zust&#228;ndigkeiten zu achten. Diese Prinzipien werden ausdr&#252;cklich auch in den 
unter der deutschen Ratspr&#228;sidentschaft verabschiedeten Schlussfolgerungen 
des Rates zur Sicherung eines freien und pluralistischen Mediensystems 
(2020/C 422/08) bekr&#228;ftigt und ebenfalls in anderen europ&#228;ischen Regelungen 
ausdr&#252;cklich anerkannt (vergleiche zum Beispiel Artikel 1 Absatz 6 E-
Commerce-Richtlinie, Artikel 1 Absatz 3 Buchstabe b des Europ&#228;ischen
Elektronischen Kommunikationskodexes, Artikel 21 Absatz 4 der EG-
Fusionskontrollverordnung oder Artikel 85 DSGVO).
66. Der Bundesrat nimmt zur Kenntnis, dass dem Verordnungsvorschlag bei der 
Definition der erfassten KI-Systeme ein sehr weites Verst&#228;ndnis zugrunde liegt 
und dieses gerade auch die Beeinflussung des Umfeldes als gewichtiges
Kriterium einbezieht.
67. Der Bundesrat weist auf die vielf&#228;ltigen Anwendungsfelder von KI-Systemen 
hin, die allein im Medienbereich etwa die Sicherung der Qualit&#228;t
journalistischredaktioneller Inhalte, die Herstellung barrierefreier Angebote, die Moderation 
von Inhalten, die Nutzung und das Angebot von Auswahl-, Empfehlungs- und 
Personalisierungsmechanismen sowie sprachgesteuerte Assistenzsysteme
umfassen, und betont die Notwendigkeit, den Anwendungsrahmen der Verordnung 
klar zu definieren sowie Ma&#223;nahmen angemessen auszugestalten.
68. Der Bundesrat stellt fest, dass der Verordnungsvorschlag bei der Bewertung der 
von ihm erfassten KI-Anwendungen und des mit ihnen verbundenen Risikos
einen prim&#228;r IT-sicherheitstechnischen Ansatz w&#228;hlt. Er weist darauf hin, dass 
diese im Verordnungsvorschlag vorgenommene Einsch&#228;tzung von einer unter 
medienrechtlichen Gesichtspunkten vorzunehmenden Einsch&#228;tzung abweichen 
kann. Dies wird beispielsweise deutlich bei der Einstufung von sogenannten 
Deepfakes und Bots als Anwendungen mit lediglich geringem Risiko. Durch 
die Nutzung dieser Anwendungen kann der &#246;ffentliche Diskurs verdeckt mani-
K 
K 
K 
K
... 
puliert und damit ein erheblicher Einfluss auf den Prozess der individuellen und 
&#246;ffentlichen Meinungsbildung ausge&#252;bt werden. Die Einordnung dieser
Aspekte ist von besonderer Relevanz um sicherzustellen, dass Folgewirkungen auf 
demokratische Prozesse ganzheitlich ber&#252;cksichtigt werden. Dabei ist der
Eindruck zu vermeiden, dass sogenannte Deepfakes angesichts ihres potenziellen 
Einflusses auf den &#246;ffentlichen Diskurs als regul&#228;re Begleiterscheinung des 
Einsatzes von KI ohne weitergehende (bereichsspezifische) Regulierung
hinzunehmen sind. Diese durch die Mitgliedstaaten zu adressierende
medienrechtliche Dimension erfasst der Verordnungsvorschlag aufgrund der
Gesetzgebungszust&#228;ndigkeiten richtigerweise nicht.
69. Der Bundesrat fordert sicherzustellen, dass der Verordnungsvorschlag die
M&#246;glichkeiten der Mitgliedstaaten, ihrer Verpflichtung zur Sicherung von
Meinungs- und Medienpluralismus nachzukommen, nicht einschr&#228;nkt. Die in ihrer 
Kulturhoheit liegende Regulierung wie auch die Durchsetzung sind durch
entsprechende &#214;ffnungsklauseln sicherzustellen, welche zus&#228;tzliche
Verpflichtungen, Ausnahmen oder Abweichungen von der vorgeschlagenen Verordnung 
erm&#246;glichen, soweit sie zur Sicherung des Medienpluralismus im jeweiligen 
Mitgliedstaat notwendig sind.
Zum Justizbereich und zum Bereich der Sicherheitsbeh&#246;rden
70. Der Bundesrat regt an zu pr&#252;fen, ob in Artikel 5 Absatz 1 Buchstabe b des
Verordnungsvorschlags ausdr&#252;cklich klargestellt werden soll, dass die richterliche 
Entscheidung keinem KI-System &#252;bertragen werden darf und dass keine KI-
Systeme eingesetzt werden d&#252;rfen, die durch ihre Konzeption die Gefahr
bergen, dass die richterliche Entscheidungsfindung dahingehend beeinflusst wird, 
dass bei mehreren vertretbaren Rechtsauffassungen eine Vorauswahl getroffen 
und dem Ergebnis zu Grunde gelegt wird. Ein Richter muss von Dritten erstellte 
vorbereitende Arbeiten inhaltlich voll nachvollziehen, bevor er sie in seiner 
Entscheidungsbegr&#252;ndung verwenden darf. Bei einer durch KI-Systeme
getroffenen Vorauswahl besteht die Gefahr, dass hierdurch die
Entscheidungsfindung des Richters, der die Anwendung nutzen m&#246;chte, inhaltlich determiniert 
wird. Eine Auseinandersetzung mit weniger verbreiteten Rechtsauffassungen 
und eine Fortentwicklung der Rechtsprechung k&#246;nnten hierdurch unterbunden 
werden. Eine solche &#8222;Lenkungsfunktion&#8220; darf KI-Systemen nicht zukommen.
K 
R
...
71. Der Bundesrat gibt zu bedenken, dass der Verordnungsvorschlag in Artikel 5 
tats&#228;chlich kein Verbot von biometrischen Echtzeit-Fernidentifikationssystemen 
vorsieht, sondern ihren Einsatz unter bestimmten Bedingungen gestattet.
Angesichts der mit ihnen verbunden Gefahren f&#252;r die Werte der Union sollte eine
eigene Risikoklasse geschaffen werden. Bei einem zul&#228;ssigen Einsatz von
biometrischen Echtzeit-Fernidentifikationssystemen sollten die Anforderungen an 
Hochrisiko-KI-Systeme erf&#252;llt werden.
72. Die Kommission beabsichtigt mit einem horizontalen Ansatz die einheitliche 
Regulierung des Einsatzes von Methoden der KI &#252;ber unterschiedlichste
Einsatzbereiche hinweg. Diesem horizontalen Ansatz folgend finden sich in
Anhang III zu Artikel 6 Absatz 2 des Verordnungsvorschlags die Bereiche, in
denen der Einsatz von Methoden der KI von der Kommission als derart riskant 
angesehen werden, dass dort zum Einsatz kommende KI-Systeme als
Hochrisiko-KI-Systeme im Sinne der Verordnung eingestuft werden. Durch diese
Einstufung unterfallen die Systeme in diesen Bereichen insbesondere den
Vorgaben in Titel III des Verordnungsvorschlags, der Vorschriften f&#252;r KI-Systeme 
enth&#228;lt, die ein hohes Risiko f&#252;r die Gesundheit und Sicherheit oder f&#252;r die 
Grundrechte nat&#252;rlicher Personen darstellen. Auff&#228;llig ist hierbei, dass die 
Klassifizierung von Hochrisiko-KI-Systemen f&#252;r den gesamten Bereich der
Justiz, der unter Ziffer 8 des Anhangs III zu Artikel 6 Absatz 2 des
Verordnungsvorschlags erw&#228;hnt wird, noch nicht ausreichend konkret definiert ist und
hierdurch einerseits die Verordnung ihren Schutzzweck nicht hinreichend erf&#252;llen 
k&#246;nnte sowie andererseits f&#252;r eine &#220;berregulierung im unmittelbaren
justiziellen Umfeld sorgen w&#252;rde. W&#228;hrend in s&#228;mtlichen in Ziffer 8 des Anhangs III 
des Verordnungsvorschlags aufgef&#252;hrten Bereichen konkrete
Gef&#228;hrdungsvektoren, wie beispielsweise biometrische Fernidentifizierung, Zugang zu Bildung 
und Beruf oder Betrieb systemrelevanter Infrastruktur angef&#252;hrt sind, die beim 
Einsatz in spezifischen Bereichen eine Einstufung als Hochrisiko-KI-System 
bedingen, ist diese Definition von Gef&#228;hrdungsvektoren im Bereich der Justiz 
nicht gelungen. So sollen nach dem Entwurf bereits Methoden der KI als
Hochrisiko-System eingestuft werden, die &#8222;bestimmungsgem&#228;&#223; Justizbeh&#246;rden bei 
der Ermittlung und Auslegung von Sachverhalten und Rechtsvorschriften und 
bei der Anwendung des Rechts auf konkrete Sachverhalte unterst&#252;tzen sollen&#8220;. 
Diese Definition ist ungeeignet, hochriskante Einsatzgebiete in der Justiz zu
beschreiben, da sie ohne Differenzierung den gr&#246;&#223;ten Teil des gesamten
T&#228;tigkeitsbereichs der Justiz erfasst, der aus der Natur der Sache heraus aus der Er-
R 
R
... 
mittlung und Auslegung von Sachverhalten sowie der Anwendung des Rechts 
auf diese Sachverhalte besteht. Insbesondere schlie&#223;t die Definition auch solche 
T&#228;tigkeiten ein, bei denen von vorneherein kein Gef&#228;hrdungsvektor
anzunehmen ist. Schon eine blo&#223;e Unterst&#252;tzungshandlung in diesem weiten
Einsatzbereich soll f&#252;r die Einstufung als Hochrisiko-System ausreichen. Es findet damit 
eine Unterbetonung des Gef&#228;hrdungsvektors bei einer &#220;berbetonung des
Einsatzbereiches statt. Damit widerspricht die Definition zugleich der &#252;brigen
Systematik der Ziffern 1 bis 7 des Anhangs III des Verordnungsvorschlags, wo f&#252;r 
die jeweiligen Bereiche gezielt und spezifisch Gef&#228;hrdungsvektoren
beschrieben werden, um die Einsatzgebiete von Hochrisiko-KI zu definieren, bei denen 
ein hohes Risiko f&#252;r die Gesundheit und Sicherheit oder f&#252;r die Grundrechte zu 
bef&#252;rchten ist.
73. Verst&#228;rkt wird diese Problematik dadurch, dass die im Verordnungsvorschlag 
vorgesehene Definition von KI gem&#228;&#223; Artikel 3 Absatz 1 in Verbindung mit 
Anhang I des Verordnungsvorschlags derart breit gefasst ist, dass darunter auch 
Techniken zu subsumieren sind, die dem eigentlichen Sinne nach nicht als KI-
Methoden einzustufen w&#228;ren, sondern eher dem Bereich genereller
Informationstechnologie in Form spezifischer Algorithmen zuzuordnen sind. Es steht zu 
bef&#252;rchten, dass zahlreiche seit Jahren im Einsatz befindliche Anwendungen 
der Justiz nach dieser Definition bereits KI-Systeme im Sinne der Verordnung 
bilden werden. Hierdurch sind erhebliche Einschr&#228;nkungen bei der Entwicklung 
und Weiterentwicklung der einschl&#228;gigen Fachverfahren zu erwarten, die sich 
ohnehin bereits komplex darstellen. Diesen Einschr&#228;nkungen steht dabei kein 
Vorteil durch die Regulierung gegen&#252;ber, da es sich bei diesen Systemen nicht 
um solche handelt, von denen ein Risiko f&#252;r die Gesundheit und Sicherheit oder 
f&#252;r die Grundrechte ausgehen k&#246;nnte. Sie werden vom Geltungsbereich der 
vorgeschlagenen Verordnung nur deshalb umfasst, da die zu weite technische 
Definition von KI-Systemen gemeinsam mit der zu weiten Definition der
Hochrisiko-Einsatzgebiete in der Justiz ein wechselseitig ausuferndes
Zusammenspiel erzeugt. Mithin bedingt die technisch sehr weite Definition eine
Konkretisierung der Hochrisiko-Einsatzgebiete. 
74. Software, die zur reinen Unterst&#252;tzung eingesetzt wird und von der nur ein
geringes Risiko ausgeht, sollte nicht als Hochrisiko-KI-System eingestuft werden. 
Hierunter fallen Anwendungen, die im Rahmen von Assistenzt&#228;tigkeiten auf der 
Gesch&#228;ftsstelle im Einsatz sind, auch wenn in ihnen Techniken eingesetzt wer-
R 
R
...
den, bei denen Modelle mit Daten trainiert werden (zum Beispiel KI-gest&#252;tzte 
Extraktion von Metadaten in Schrifts&#228;tzen). Aus Erw&#228;gungsgrund 40 des
Verordnungsvorschlags ergibt sich, dass die Einstufung als Hochrisiko-KI-System 
sich nicht auf KI-Systeme erstrecken soll, die f&#252;r rein begleitende
Verwaltungst&#228;tigkeiten bestimmt sind, die die tats&#228;chliche Rechtspflege in Einzelf&#228;llen nicht 
beeintr&#228;chtigen, wie die Anonymisierung oder Pseudonymisierung gerichtlicher 
Urteile, Dokumente oder Daten, die Kommunikation zwischen dem Personal, 
Verwaltungsaufgaben oder die Zuweisung von Ressourcen. Sofern diese
Anwendungen nicht bereits durch eine Neugestaltung der KI-Definition oder eine 
engere Fassung von Ziffer 8 Buchstabe a in Anhang III des
Verordnungsvorschlags ausgenommen werden, sollte in Ziffer 8 Buchstabe a in Anhang III des 
Verordnungsvorschlags zumindest ausdr&#252;cklich geregelt werden, dass KI-
Systeme, die f&#252;r rein begleitende Verwaltungst&#228;tigkeiten bestimmt sind, die die 
tats&#228;chliche Rechtspflege in Einzelf&#228;llen nicht beeintr&#228;chtigen, nicht als
Hochrisiko-KI-Systeme anzusehen sind.
75. Der Bundesrat regt an, zu pr&#252;fen, ob aus Ziffer 8 Buchstabe a in Anhang III des 
Verordnungsvorschlags Anwendungen, die der Unterst&#252;tzung der Arbeit und 
Entscheidungsfindung der Richterinnen und Richter sowie Staatsanw&#228;ltinnen 
und Staatsanw&#228;lte dienen, teilweise ausgenommen werden sollen, sofern sie 
nicht bereits aufgrund einer Anpassung der KI-Definition nicht mehr erfasst 
sind. Denn es gibt Anwendungen, die nicht die in Artikel 7 Absatz 1 Buchstabe 
b des Verordnungsvorschlags f&#252;r die k&#252;nftige Entscheidung &#252;ber eine
Einstufung als Hochrisiko-KI-System aufgestellten Anforderungen erf&#252;llen und die 
die Werte der Union nicht gef&#228;hrden. Ihre Einstufung als Hochrisiko-KI-
Systeme erscheint daher nicht gerechtfertigt. 
Konkret ausgenommen werden sollten lediglich KI-Systeme, die der
Unterst&#252;tzung der Arbeit und Entscheidungsfindung der Richterinnen und Richter sowie 
Staatsanw&#228;ltinnen und Staatsanw&#228;lte dienen, sofern in ihnen keine Techniken 
eingesetzt werden, bei denen Modelle mit Daten trainiert werden, und deren 
Arbeitsergebnisse durch die Richterin beziehungsweise den Richter oder
Staatsanw&#228;ltin beziehungsweise Staatsanwalt vollumf&#228;nglich gesteuert werden
k&#246;nnen. In Bezug auf die vorgenannten Anwendungen sollte eine eigene
Risikoklasse unterhalb der Risikostufe Hochrisiko-KI-Systeme geschaffen werden, die 
verpflichtend vorgibt, dass das System dem Nutzenden die M&#246;glichkeit geben 
muss, selbst zwischen allen vertretbaren Rechtsauffassungen zu entscheiden.
R
... 
76. Der Verordnungsvorschlag f&#252;hrt in der jetzigen Fassung zu erheblichen
Mehrkosten bei der Entwicklung und dem Betrieb von IT-Anwendungen der Justiz. 
Heute genutzte Systeme wie die Fach- und Textanwendungen EUREKA, 
web.sta oder e&#178;T, die lediglich der Unterst&#252;tzung der Arbeit und
Entscheidungsfindung der Richterinnen und Richter sowie Staatsanw&#228;ltinnen und
Staatsanw&#228;lte dienen, w&#252;rden unter den Begriff einer Hochrisiko-KI zu fassen sein.
77. Zusammenfassend kann gesagt werden, dass der Verordnungsvorschlag mit 
Blick auf die Justiz zwingend &#252;berarbeitungsbed&#252;rftig ist. Zugespitzt umfasst 
der Verordnungsvorschlag unz&#228;hlige Technologien in nahezu s&#228;mtlichen
T&#228;tigkeitsbereichen der Justiz, v&#246;llig losgel&#246;st vom konkreten Gef&#228;hrdungsvektor 
und -potenzial. Der Verordnungsvorschlag w&#252;rde daher in der vorliegenden 
Fassung eine sch&#228;dliche &#220;berregulierung der Justiz verursachen.
78. Es ist daher unerl&#228;sslich, die Gef&#228;hrdungspotenziale im Bereich der Justiz zu 
identifizieren und in die Definition der Ziffer 8 des Anhangs III des
Verordnungsvorschlags aufzunehmen. In vergleichbarer Weise zu den vorherigen
Ziffern des Anhangs III des Verordnungsvorschlags sollten konkrete
Einsatzgebiete definiert werden, bei denen der Einsatz von KI-Methoden zu einer
Gef&#228;hrdung von Gesundheit, Sicherheit oder Grundrechten f&#252;hren kann.
79. Statt der pauschalen Formulierung in Ziffer 8 Buchstabe a in Anhang III des 
Verordnungsvorschlags sollte in Ziffer 8 in Anhang III des
Verordnungsvorschlags konkret herausgearbeitet werden, von welchen Einsatzszenarien in der 
Justiz ein hohes Risiko ausgeht. Die jetzige Fassung w&#252;rde dazu f&#252;hren, dass 
wahrscheinlich zahlreiche bereits jetzt in der Justiz eingesetzte
Softwareanwendungen als Hochrisiko-KI-Systeme gem&#228;&#223; Artikel 6 Absatz 2 des
Verordnungsvorschlags eingestuft werden m&#252;ssten, ohne dass das konkrete von der 
Anwendung tats&#228;chlich ausgehende Risiko Ber&#252;cksichtigung findet. Zudem 
sollte die &#220;berschrift angepasst werden, da keine Regelungen bez&#252;glich
demokratischer Prozesse getroffen werden.
80. Aufgrund von Erw&#228;gungsgrund 32 des Verordnungsvorschlags wird in der
Literatur angenommen, dass sich die Regelung in Artikel 6 Absatz 2 des
Verordnungsvorschlags in Verbindung mit Anhang III des Verordnungsvorschlags nur
R 
R 
R 
R 
R
...
auf eigenst&#228;ndige KI-Systeme bezieht. Diese Auffassung wird durch 
Ziffer 5.2.3 des Verordnungsvorschlags der ausf&#252;hrlichen Erl&#228;uterung einzelner 
Bestimmungen des Vorschlags zwar best&#228;tigt; dies sollte jedoch durch eine
eindeutigere Formulierung in Artikel 6 des Verordnungsvorschlags klargestellt 
werden.
81. Unabh&#228;ngig von den vorherigen &#220;berlegungen sollte eine neue Ziffer 8
Buchstabe b geschaffen werden, in der KI-Systeme, in denen Techniken eingesetzt 
werden, bei denen Modelle mit Daten trainiert werden, die im Rahmen der 
Rechtsberatung eingesetzt werden, ebenfalls als Hochrisiko-KI-Systeme
klassifiziert werden. Der genaue Regelungsumfang sollte sich an dem f&#252;r die Justiz 
gew&#228;hlten Umfang orientieren. Dies w&#252;rde zum einen zu einer
Waffengleichheit zwischen Justiz und Anwaltschaft beziehungsweise Legal-Tech-
Unternehmen f&#252;hren und zum anderen die Rechtsrat suchenden EU-B&#252;rgerinnen und 
-B&#252;rger sch&#252;tzen.
82. Von einer Regelung des strafverfolgungsbeh&#246;rdlichen Einsatzes von KI in der 
auf Wirtschafts- und Gesellschaftsbelange zugeschnittenen KI-Verordnung
sollte abgesehen werden. Sollte an der Einbeziehung des Bereichs der
Strafverfolgung festgehalten werden, ist eine Inkonsistenz zu pr&#252;fen, wonach die in Ziffer 
6 des Verordnungsvorschlags f&#252;r Strafverfolgungsbeh&#246;rden genannten
Methoden im Bereich von Polizei und Staatsanwaltschaft als hochriskant eingestuft 
werden, im gerichtlichen Bereich jedoch nicht, weil Strafgerichte nicht unter 
den in Ziffer 6 des Verordnungsvorschlags verwendeten Begriff der
Strafverfolgungsbeh&#246;rde zu fassen sind.
83. Die Kommission will auch den Einsatz von KI durch staatliche Stellen,
insbesondere die [Strafverfolgungs- und] Sicherheitsbeh&#246;rden, regeln. Der Einsatz 
von KI zu Strafverfolgungszwecken {beziehungsweise zu
Gefahrenabwehrzwecken} ist jedoch in den nationalen Strafverfahrensrechten {beziehungsweise
Polizeigesetzen} zu regeln. Angesichts der &#228;u&#223;erst begrenzten
Gesetzgebungskompetenz der EU in diesem Bereich sollte von einer Regelung {des Einsatzes 
zu Gefahrenabwehrzwecken und} des strafverfolgungsbeh&#246;rdlichen Einsatzes 
von KI in der auf Wirtschafts- und Gesellschaftsbelange zugeschnittenen
vorgeschlagenen KI-Verordnung abgesehen werden. {Der Bundesrat fordert daher, 
dass sich die EU auf ihre Kompetenzen beschr&#228;nkt und keine
unverh&#228;ltnism&#228;&#223;igen Versch&#228;rfungen f&#252;r den Einsatz von KI durch die Sicherheitsbeh&#246;rden
R 
R 
In 
R
[R] 
{In}
... 
einf&#252;hrt. Eine auf den Bereich der Inneren Sicherheit fokussierte
Folgenabsch&#228;tzung ist dringend anzustreben.}
84. Soweit an der Regelung des KI-Einsatzes durch Strafverfolgungsbeh&#246;rden
festgehalten wird, w&#228;re es vorzugsw&#252;rdig, wenn die Ma&#223;nahmen des pr&#228;ventiven 
und repressiven Bereichs der Strafverfolgungs- und Sicherheitsbeh&#246;rden in eine 
gesonderte Regelungslage extrahiert w&#252;rden, die die Notwendigkeit der
Erhaltung der Leistungsf&#228;higkeit und Reaktionsf&#228;higkeit der Strafverfolgungs- und 
Sicherheitsbeh&#246;rden ausreichend ber&#252;cksichtigt. 
85. Dabei weist der Bundesrat darauf hin, dass die Anforderungen der
Strafverfolgungs- und Sicherheitsbeh&#246;rden beim Einsatz von KI in der Verordnung
angemessen ber&#252;cksichtigt werden m&#252;ssen. Die Einstufung zahlreicher
Anwendungen im Bereich der Strafverfolgung als &#8222;Hochrisiko-KI&#8220; (Anhang III des 
Verordnungsvorschlags) zieht als Konsequenz die Notwendigkeit einer
Konformit&#228;tsbewertung der Anwendungen nach sich. Dabei handelt es sich unter 
anderem um Software f&#252;r die biometrische Fernidentifizierung oder Systeme, 
die zur Aufdeckung von sogenannten Deepfakes oder zur Bewertung der
Verl&#228;sslichkeit von Beweismitteln im Zuge der Ermittlung oder Verfolgung von 
Straftaten dienen. Mit diesen sowohl internen wie auch externen Bewertungen 
sind erh&#246;hte Pr&#252;f-, Aufsichts-, Transparenz- und Rechenschaftspflichten
verbunden. Der Einsatz von KI zur Auswertung und Aufbereitung gro&#223;er
Datenmengen wird somit unn&#246;tig erschwert. Auch f&#252;r den Einsatz von KI-gest&#252;tzter 
Gesichtserkennungssoftware zur Fahndung nach Straft&#228;tern oder Gef&#228;hrdern 
mittels Video&#252;berwachung werden &#252;berm&#228;&#223;ig strenge Voraussetzungen
festgeschrieben. Aufgrund der Ausgestaltung der Normen und vorhandener
Definitionsunklarheiten besteht zumindest die Gefahr, dass zukunftsorientierte Projekte 
beziehungsweise Software der Strafverfolgungsbeh&#246;rden verhindert oder
wesentlich erschwert werden. Auch bereits genutzte Software (zum Beispiel Tools 
zur Erkennung und Kategorisierung von Kinderpornographie oder Software zur 
Auswertung komplexer IT-Asservate) k&#246;nnte unter die Definition von KI fallen. 
Die im aktuellen Verordnungsvorschlag enthaltenen Restriktionen k&#246;nnten
somit einen Zeitverzug bei notwendigen Ermittlungsma&#223;nahmen hervorrufen, der 
den Erfolg und die Effizienz der polizeilichen Ma&#223;nahmen gef&#228;hrden k&#246;nnte. 
Die Anforderungen an den Einsatz von KI durch Strafverfolgungs- und
Sicherheitsbeh&#246;rden sollten daher praxisgerechter ausgestaltet und besser auf die be-
In 
R
In 
R
...
sonderen Belange der Strafverfolgung und Gefahrenabwehr zugeschnitten
werden.
86. Gem&#228;&#223; Artikel 43 Absatz 1 Unterabsatz 3 Satz 2 des Verordnungsvorschlags 
&#252;bernimmt die in Artikel 63 Absatz 5 oder 6 des Verordnungsvorschlags
genannte Markt&#252;berwachungsbeh&#246;rde die Funktion der notifizierten Stelle, wenn 
das System von Strafverfolgungs-, Einwanderungs- oder Asylbeh&#246;rden oder 
von Organen, Einrichtungen oder sonstigen Stellen der EU in Betrieb
genommen werden soll. In diese Regelung sollte auch die Justiz insgesamt
aufgenommen werden. Gr&#252;nde f&#252;r eine unterschiedliche Behandlung der Justiz insgesamt 
und der Strafverfolgungsbeh&#246;rden sind nicht ersichtlich.
87. Artikel 70 Absatz 2 des Verordnungsvorschlags enth&#228;lt besondere Vorgaben 
zum Schutz von Strafverfolgungs-, Einwanderungs- oder Asylbeh&#246;rden als
Anbieter von Hochrisiko-KI-Systemen. In diese Regelung sollte auch die Justiz 
insgesamt aufgenommen werden. Gr&#252;nde f&#252;r eine unterschiedliche Behandlung 
der Justiz insgesamt und der Strafverfolgungsbeh&#246;rden sind nicht ersichtlich.
88. In Artikel 71 des Verordnungsvorschlags ist geregelt, dass bei Verst&#246;&#223;en gegen 
die Verordnung Anbietende von KI-Systemen mit Bu&#223;geldern von bis zu 30 
Millionen Euro beziehungsweise im Falle von Unternehmen in H&#246;he von bis zu 
6 Prozent des Jahresumsatzes belegt werden k&#246;nnen. Beh&#246;rden und &#246;ffentliche 
Stellen inklusive der Justiz sollten aus dem Anwendungsbereich der Vorschrift 
ausgenommen werden. Es sollte in der Vorschrift zumindest ausdr&#252;cklich
klargestellt werden, dass von Beh&#246;rden und &#246;ffentlichen Stellen auch die Justiz
erfasst ist. 
Sonstiges
89. Der Bundesrat bittet die Bundesregierung, die m&#246;glichen Auswirkungen des 
Verordnungsvorschlags auf die Entwicklungschancen f&#252;r innovative KI-
L&#246;sungen in Europa zu pr&#252;fen. Mit Blick auf das weitere
Gesetzgebungsverfahren sollten dabei insbesondere die zugrundeliegende, sehr weitgehende
Definition von erfassten KI-Technologien, der Ma&#223;stab f&#252;r die Risikobewertung einer 
konkreten KI-Anwendung sowie das Zusammenwirken mit sektorspezifischen 
Regulierungen, unter anderem hinsichtlich m&#246;glicher Doppelregulierungen
sowie widerspr&#252;chlicher Vorgaben, ber&#252;cksichtigt werden.
R 
R 
R 
Wi
... 
90. Der Bundesrat bittet die Bundesregierung, sich im weiteren
Gesetzgebungsverfahren daf&#252;r einzusetzen, dass: 
&#8211; das zuk&#252;nftige KI-Gesetz f&#252;r Transparenz und Klarheit sorgt, welcher
Regulierungsstufe eine bestimmte Anwendung unterworfen ist und welche 
konkreten Anforderungen damit einhergehen, etwa hinsichtlich der
Anforderungen an die Qualit&#228;t der verwendeten Datens&#228;tze, so dass Unternehmen 
gr&#246;&#223;tm&#246;gliche Rechtssicherheit bei der Entwicklung und Nutzung dieser 
Anwendung erhalten, insbesondere auch durch die m&#246;glichst rasche
Etablierung von harmonisierten Normen, 
&#8211; weitere Vereinfachungen speziell f&#252;r KMU sowie Start-ups bei den
vorgesehenen regulatorischen Anforderungen vorgesehen werden und diese bei 
der Erf&#252;llung dieser Anforderungen m&#246;glichst fr&#252;hzeitig und in geeigneter 
Form unterst&#252;tzt werden, 
&#8211; der Rechtsrahmen so ausgestaltet wird, dass eine Fragmentierung des
Binnenmarktes, beispielsweise hinsichtlich der Ausgestaltung der
Markt&#252;berwachung, in der Praxis vermieden wird sowie 
&#8211; Gesch&#228;ftsgeheimnisse im Rahmen der vorgesehenen Pr&#252;f- und
Offenlegungspflichten wirksam gewahrt bleiben.
91. Der Bundesrat weist darauf hin, dass ein zuverl&#228;ssiges Haftungsregime f&#252;r die 
Etablierung eines innovationsfreundlichen Rechtsrahmens von gro&#223;er
Bedeutung ist. Dies gilt auch vor dem Hintergrund der in Artikel 14 des
Verordnungsvorschlags aufgef&#252;hrten obligatorischen menschlichen Aufsicht f&#252;r Hochrisiko-
Systeme. Der Bundesrat bittet die Bundesregierung zu pr&#252;fen, welche
Anpassungen im Produkthaftungsrecht gegebenenfalls notwendig sind, um
insbesondere im Hinblick auf den europ&#228;ischen Binnenmarkt Rechtssicherheit
herzustellen. 
Wi
Wi
...
92. Der Bundesrat bittet die Bundesregierung um Kl&#228;rung, wie in den Bereichen 
des Anhangs III des Verordnungsvorschlags, f&#252;r die derzeit keine
Aufsichtsstrukturen bestehen, eine entsprechende Zust&#228;ndigkeit geschaffen werden soll. 
Da die Regulierung von KI-Systemen sehr spezialisiertes Fachwissen erfordert, 
m&#252;ssen die Mitgliedstaaten daf&#252;r sorgen, dass die zust&#228;ndigen nationalen
Beh&#246;rden mit angemessenen finanziellen und personellen Ressourcen ausgestattet 
werden, damit sie ihre Aufgaben im Rahmen der Verordnung wahrnehmen 
k&#246;nnen. 
93. Der Bundesrat bittet die Bundesregierung, sich bei den weiteren Verhandlungen 
daf&#252;r einzusetzen, dass die Spielr&#228;ume der Mitgliedstaaten bei der Benennung 
der zust&#228;ndigen Beh&#246;rden gewahrt bleiben. Auch sollte daf&#252;r Sorge getragen 
werden, dass bei Verst&#246;&#223;en gegen die Verordnung, die die Rechte von
B&#252;rgerinnen und B&#252;rgern in mehreren Mitgliedstaaten betreffen und die in Anlehnung 
an die Begriffsbestimmung der Verordnung (EU) 2017/2394 &#252;ber die
Zusammenarbeit zwischen den f&#252;r die Durchsetzung der Verbraucherschutzgesetze 
zust&#228;ndigen nationalen Beh&#246;rden als &#8222;weitverbreitete Verst&#246;&#223;e&#8220; angesehen 
werden k&#246;nnen, geeignete Mechanismen der Kooperation und Koordinierung 
zur Verf&#252;gung stehen.
94. Der Bundesrat bittet zudem zu pr&#252;fen, ob eine Regelung zu zust&#228;ndigen
Beh&#246;rden im Falle der Betroffenheit mehrerer Mitgliedstaaten geschaffen werden 
kann.
95. Der Bundesrat sieht kritisch, dass der Verordnungsvorschlag keine
Interventionsrechte derjenigen Personen vorsieht, die durch den Einsatz von KI-Systemen 
betroffen sein k&#246;nnen. Der durch die DSGVO vermittelte Schutz bei
automatisierten Entscheidungsverfahren ist nicht ausreichend, da er bei vorgelagerten 
Entscheidungen noch nicht greift und nur die Richtigkeit der verarbeiteten
Daten, jedoch nicht die der aus ihnen und anderen Daten gezogenen
Schlussfolgerungen sch&#252;tzt. Zudem fehlt eine Verzahnung mit den Pflichten zur
menschlichen Aufsicht und den Verpflichtungen der Anbietenden und Nutzenden zur 
Beobachtung der KI-Systeme nach ihrer Inbetriebnahme. 
AIS 
Vk 
Wi
AV
AIS 
Vk 
Wi
AV
... 
96. Der Bundesrat begr&#252;&#223;t, dass der Verordnungsvorschlag die Anbietenden und 
Nutzenden zur Beobachtung der von KI-Systemen ausgehenden Risiken nach 
ihrer Inbetriebnahme verpflichtet. Allerdings l&#228;sst der Verordnungsvorschlag 
weitgehend offen, wer im Verh&#228;ltnis zwischen Hersteller, Anbieter und Nutzer 
beispielsweise f&#252;r das Risikomanagement oder die technische Dokumentation 
w&#228;hrend des Betriebs des KI-Systems verantwortlich sein soll. Mit R&#252;cksicht 
auf die Vielgestaltigkeit der KI-Systeme sollten aus Sicht des Bundesrates
zumindest vor Inverkehrbringen oder Inbetriebnahme in einem entsprechenden 
Dokument die Verantwortlichkeiten f&#252;r die Pflichten aus Titel III Kapitel 2 des 
Verordnungsvorschlags festgehalten sein.
97. Der Bundesrat begr&#252;&#223;t die &#220;berlegung der Kommission, freiwillige
Verhaltenskodizes f&#252;r KI-Systeme, die kein hohes Risiko darstellen, durch die
Kommission und die Mitgliedstaaten zu f&#246;rdern. Der Bundesrat bittet die
Bundesregierung, Aktivit&#228;ten zur F&#246;rderung entsprechender freiwilliger Verhaltenskodizes 
im Sinne einer marktwirtschaftlichen Anreizsetzung zu unterst&#252;tzen. Er erinnert 
daran, dass in den L&#228;ndern bereits erste Anstrengungen unternommen wurden, 
die es mit den vorgeschlagenen Ma&#223;nahmen zu st&#228;rken und aktiv einzubeziehen 
gilt.
98. Der Bundesrat stellt fest, dass das Verh&#228;ltnis des Verordnungsvorschlages zu 
anderen europ&#228;ischen Rechtsakten, wie etwa zur Richtlinie &#252;ber irref&#252;hrende 
und vergleichende Werbung (2006/114/EG) und insbesondere zur Richtlinie 
&#252;ber audiovisuelle Mediendienste (2010/13/EU, AVMD-Richtlinie), nicht
gekl&#228;rt wird, obwohl in den Regelwerken sich &#252;berschneidende Vorschriften
enthalten sind. Dies betrifft beispielsweise die Regelungen hinsichtlich der
Verwendung von Techniken der unterschwelligen Beeinflussung.
99. Der Bundesrat stellt fest, dass in dem Verordnungsvorschlag abweichende
Begriffsbestimmungen zur Verordnung (EU) 2019/1020 enthalten sind. Er bittet 
die Bundesregierung, darauf hinzuwirken, dass Begriffsbestimmungen der
vorgenannten Verordnung gleich und eindeutig &#252;bernommen werden, damit die 
Markt&#252;berwachungsbeh&#246;rden der L&#228;nder in &#220;bereinstimmung mit der
Verordnung (EU) 2019/1020 und dem Markt&#252;berwachungsgesetz die
Markt&#252;berwachung vollziehen k&#246;nnen. 
AV
Vk 
K 
AIS 
Vk 
Wi
100. Der Bundesrat bittet die Bundesregierung, darauf hinzuweisen, dass bereits 
bestehende gesetzliche Regelungen &#8211; etwa in der DSGVO &#8211; bei der
Regulierung von KI ber&#252;cksichtigt werden m&#252;ssen, um Doppelungen zu vermeiden 
und die Regelungen f&#252;r KI so schlank wie m&#246;glich zu halten. Der
Verordnungsvorschlag muss auf bereits bestehende Normierungen abgestimmt sein.
101. Der Bundesrat weist dar&#252;ber hinaus auf die Subsidiarit&#228;t europ&#228;ischer
Regelungen und die Kompetenzordnung hin. 
Direktzuleitung der Stellungnahme 
102. Der Bundesrat &#252;bermittelt diese Stellungnahme direkt an die Kommission.
B 
103. Der federf&#252;hrende Ausschuss f&#252;r Fragen der Europ&#228;ischen Union und
der Gesundheitsausschuss
empfehlen dem Bundesrat, von der Vorlage gem&#228;&#223; &#167;&#167; 3 und 5 EUZBLG 
Kenntnis zu nehmen.
In 
K
K 
AIS 
In 
K 
R 
Vk 
Wi]</text>
    <titel>Vorschlag f&#252;r eine Verordnung des Europ&#228;ischen Parlaments und des Rates zur Festlegung harmonisierter Vorschriften f&#252;r k&#252;nstliche Intelligenz (Gesetz &#252;ber k&#252;nstliche Intelligenz) und zur &#196;nderung bestimmter Rechtsakte der Union</titel>
    <datum>2021-09-06</datum>
  </document>
  