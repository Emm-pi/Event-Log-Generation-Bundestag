<document>
    <id>257756</id>
    <drucksachetyp>Beschluss</drucksachetyp>
    <dokumentart>Drucksache</dokumentart>
    <autoren_anzahl>0</autoren_anzahl>
    <typ>Dokument</typ>
    <vorgangsbezug_anzahl>1</vorgangsbezug_anzahl>
    <dokumentnummer>488/21(B)</dokumentnummer>
    <wahlperiode>19</wahlperiode>
    <herausgeber>BR</herausgeber>
    <pdf_hash>91d02b6ce6e932d3ff86a7b1d581a3b4</pdf_hash>
    <aktualisiert>2021-09-17T00:00:00+02:00</aktualisiert>
    <vorgangsbezug>
      <id>279055</id>
      <titel>Vorschlag f&#252;r eine Verordnung des Europ&#228;ischen Parlaments und des Rates zur Festlegung harmonisierter Vorschriften f&#252;r k&#252;nstliche Intelligenz (Gesetz &#252;ber k&#252;nstliche Intelligenz) und zur &#196;nderung bestimmter Rechtsakte der Union
KOM(2021) 206 endg.; Ratsdok. 8115/21</titel>
      <vorgangstyp>EU-Vorlage</vorgangstyp>
    </vorgangsbezug>
    <fundstelle>
      <pdf_url>https://dserver.bundestag.de/brd/2021/0488-21B.pdf</pdf_url>
      <id>257756</id>
      <dokumentnummer>488/21(B)</dokumentnummer>
      <datum>2021-09-17</datum>
      <dokumentart>Drucksache</dokumentart>
      <drucksachetyp>Beschluss</drucksachetyp>
      <herausgeber>BR</herausgeber>
    </fundstelle>
    <text>[Bundesrat Drucksache 488/21 (Beschluss)
17.09.21
Vertrieb: Bundesanzeiger Verlag GmbH, Postfach 10 05 34, 50445 K&#246;ln 
Telefon (02 21) 97 66 83 40, Fax (02 21) 97 66 83 44, www.betrifft-gesetze.de 
ISSN 0720-2946
Beschluss
des Bundesrates
Vorschlag f&#252;r eine Verordnung des Europ&#228;ischen Parlaments und 
des Rates zur Festlegung harmonisierter Vorschriften f&#252;r 
k&#252;nstliche Intelligenz (Gesetz &#252;ber k&#252;nstliche Intelligenz) und zur 
&#196;nderung bestimmter Rechtsakte der Union 
COM(2021) 206 final 
Der Bundesrat hat in seiner 1008. Sitzung am 17. September 2021 gem&#228;&#223; &#167;&#167; 3 
und 5 EUZBLG die folgende Stellungnahme beschlossen:
Allgemeines
1. Der Bundesrat begr&#252;&#223;t, dass die Kommission mit dem nun vorliegenden
Verordnungsvorschlag den weltweit ersten Rechtsrahmen f&#252;r K&#252;nstliche Intelligenz 
(KI) entworfen hat und damit europaweit einheitliche Regelungen f&#252;r das sehr 
komplexe Thema KI schaffen m&#246;chte. Besonders positiv ist dabei
hervorzuheben, dass davon auch Anbieter au&#223;erhalb der EU erfasst werden, sofern sie im 
europ&#228;ischen Markt aktiv sein wollen.
2. Er begr&#252;&#223;t ferner das Ziel der Kommission, einen einheitlichen Rechtsrahmen 
zu schaffen, der die Entwicklung und Anwendung einer sicheren,
vertrauensw&#252;rdigen und ethisch vertretbaren KI in Europa gew&#228;hrleisten und nachhaltig 
f&#246;rdern soll sowie auch die Koh&#228;renz mit der EU-Grundrechte-Charta und dem 
geltenden Sekund&#228;rrecht der Union zur Nichtdiskriminierung und zur
Gleichstellung der Geschlechter gew&#228;hrleistet.
Der Bundesrat unterst&#252;tzt den Ansatz, dass Europa das globale Zentrum f&#252;r eine 
vertrauensw&#252;rdige KI werden soll. Denn KI kann nur dann ihr wirtschaftliches 
Potenzial entfalten, wenn die Menschen dieser Technologie vertrauen k&#246;nnen. 
Deshalb ist es folgerichtig, dass die Kommission in ihrem
Verordnungsvorschlag nicht nur einen klaren Fokus auf Wirtschaft und Unternehmen, sondern 
gleicherma&#223;en auf den Schutz der B&#252;rgerinnen und B&#252;rger sowie der
Demokratie auf der Basis der europ&#228;ischen Werte legt.
3. Er begr&#252;&#223;t das Vorhaben der Kommission, erstmalig einen risikobasierten 
Rechtsrahmen f&#252;r eine vertrauensw&#252;rdige KI zu schaffen, damit sich KI als eine 
der Schl&#252;sseltechnologien der Digitalisierung und als Treiber des
wirtschaftlichen Wachstums in der Union erfolgreich entwickeln kann. Es ist konsequent, 
dass die Union dazu einen zweigleisigen Ansatz verfolgt, indem sie einerseits 
eine menschenzentrierte und vertrauensw&#252;rdige KI sicherstellen und
andererseits Anreize f&#252;r Unternehmen zur Weiterentwicklung der Technologie setzten 
m&#246;chte.
4. Der Bundesrat begr&#252;&#223;t mithin die Vorlage des Verordnungsvorschlags und
unterst&#252;tzt grunds&#228;tzlich die Zielsetzung der Kommission, die mit KI
einhergehenden Chancen, Potenziale und Risiken gleichberechtigt in den Blick zu
nehmen. Er begr&#252;&#223;t den darauf basierenden Ansatz, dass die Schaffung eines
Regulierungsrahmens mit Investitionen f&#252;r KI einhergehen soll. Der Bundesrat
bekr&#228;ftigt in diesem Zusammenhang seine Stellungnahmen vom 15. Februar 2019 
(BR-Drucksache 631/18 (Beschluss)), vom 17. Mai 2019 (BR-Drucksache 
165/19 (Beschluss)) sowie vom 15. Mai 2020 (BR-Drucksache 95/20
(Beschluss)). 
5. Er begr&#252;&#223;t au&#223;erdem die Anwendung des Marktortprinzips im
Verordnungsvorschlag, um einen souver&#228;nen europ&#228;ischen Weg bei der Entwicklung und der 
Anwendung von KI zu beschreiten.
6. Der Bundesrat bef&#252;rwortet die Schaffung eines einheitlichen europ&#228;ischen KI-
Regulierungsrahmens zum Nutzen der B&#252;rgerinnen und B&#252;rger und mit dem 
Ziel der Schaffung eines reibungslos funktionierenden europ&#228;ischen
Binnenmarkts. Er betont, dass ein einheitlicher europ&#228;ischer Regulierungsrahmen zur 
Weiterentwicklung und Verbreitung von KI sowie zur St&#228;rkung der
industriellen Basis Europas im Bereich KI beitragen kann.
7. Der Bundesrat hebt das relativ weite Verst&#228;ndnis von KI, das auch die
Bedeutung von Daten und deren Qualit&#228;t ber&#252;cksichtigt, als gewinnbringend hervor.
8. KI ist eine Schl&#252;sseltechnologie f&#252;r die L&#246;sung gro&#223;er gesellschaftlicher
Herausforderungen und f&#252;r eine nachhaltige wirtschaftliche Prosperit&#228;t Europas. 
Europa kann es sich nicht leisten, die Innovations- und
Wertsch&#246;pfungspotenziale der KI ungenutzt zu lassen. Dies erfordert die erfolgreiche Anwendung von 
KI-Technologien, aber vor allem muss Europa auch selbst ein weltweit
f&#252;hrender Standort f&#252;r die Entwicklung innovativer KI-L&#246;sungen sein. 
Der Bundesrat h&#228;lt es f&#252;r erforderlich, dass eine Regulierung vor allem auch die 
Chancen von KI-L&#246;sungen, etwa zur Bew&#228;ltigung gesellschaftlicher
Herausforderungen wie zum Beispiel Klimaschutz, Gesundheit und Verkehrssicherheit, 
im Blick haben muss.
9. Der Einsatz von KI-Technologie ist f&#252;r die k&#252;nftige Wettbewerbsf&#228;higkeit der 
deutschen Unternehmen von zentraler Bedeutung. Der Anwendungsbereich von 
KI-Systemen erstreckt sich &#252;ber nahezu alle Wirtschaftszweige und
Gesch&#228;ftsbereiche. Vor allem f&#252;r die Industrie ist das Potenzial von KI enorm, indem sie 
die Produktion durch intelligente, digital vernetzte Systeme und Prozessketten 
effizienter, flexibler und zuverl&#228;ssiger gestalten kann.
10. Damit Europa das globale Zentrum f&#252;r vertrauensw&#252;rdige KI werden kann, 
m&#252;ssen die Regelungen so pr&#228;zise und verst&#228;ndlich formuliert sein, dass 
dadurch weder neue b&#252;rokratische H&#252;rden oder regulatorische Grauzonen noch 
Forschungs- oder Innovationshemmnisse entstehen. Die Regelungen des
Verordnungsvorschlags d&#252;rfen in keinem Fall zu einem Wettbewerbsnachteil f&#252;r 
europ&#228;ische Unternehmen und Start-ups werden. Nur dort, wo es aus ethischen, 
verbraucherpolitischen oder sicherheitspolitischen Gr&#252;nden unbedingt
erforderlich ist, sollten der Anwendung von KI strikte Grenzen gesetzt werden. Die 
hierbei zu erf&#252;llenden Anforderungen m&#252;ssen sich in einem f&#252;r Nutzende und 
Anbietende zumutbaren Rahmen bewegen.
11. Der Bundesrat bittet die Bundesregierung insgesamt darauf hinzuwirken, dass 
der neue KI-Rechtsrahmen nicht in eine &#220;berregulierung m&#252;ndet und dadurch 
zu einem Innovationshemmnis f&#252;r die Entwicklung und Anwendung von KI in 
Europa wird. Dabei ist zu beachten, dass die Besonderheit von KI als
Technologie ber&#252;cksichtigt wird und vergleichbare Regularien angewandt werden wie 
f&#252;r andere Technologien. 
Die Anforderungen des vorgelegten Verordnungsvorschlages werden
insbesondere die kleinen und mittleren Unternehmen (KMU), die KI-Technologie in 
nach dem Verordnungsvorschlag als hochriskant bewerteten Anwendungen
einsetzen wollen, vor gro&#223;e Herausforderungen stellen. In diesem Zusammenhang 
ist darauf zu achten, dass KMU vor unangemessenen Belastungen gesch&#252;tzt 
werden.
Der Bundesrat weist darauf hin, dass eine &#252;berm&#228;&#223;ige Regulierung von KI-
Systemen die Entstehung und Nutzung von Innovationen in dieser
Schl&#252;sseltechnologie verlangsamen oder sogar ganz verhindern kann. Insbesondere 
k&#246;nnte eine &#252;berm&#228;&#223;ige Regulierung die Gr&#252;ndungsneigung von KI-Talenten 
reduzieren oder auch ihre Abwanderung aus Europa weiter beg&#252;nstigen. Dies 
h&#228;tte nicht nur negative Auswirkungen auf die Wettbewerbsf&#228;higkeit der
europ&#228;ischen Wirtschaft und insbesondere KMU sowie von Start-ups, sondern auch 
auf die technologische Souver&#228;nit&#228;t und die F&#228;higkeit Europas, auf
europ&#228;ischen Werten und den Grundrechten beruhende Regeln im Umgang mit dieser 
Technologie zu etablieren und durchzusetzen.
12. Er weist in diesem Zusammenhang auf die im Juni 2021 erschienene Studie 
&#8222;Artificial intelligence, blockchain and the future of Europe: How disruptive 
technologies create opportunities for a green and digital economy&#8220; von
Kommission und Europ&#228;ischer Investitionsbank hin. Danach besteht in Europa eine 
j&#228;hrliche Investitionsl&#252;cke bei KI-Start-ups und -KMU in H&#246;he von 4 bis 8
Milliarden Euro im Vergleich zu den USA und China. Bei der Anzahl von KI-
Startups und -KMU liegen die USA mit rund 2.500 Unternehmen weit vor China 
und der EU mit jeweils rund 1.000 Unternehmen sowie dem Vereinigten
K&#246;nigreich mit fast 400 Unternehmen. Der Bundesrat ist daher der Auffassung, dass 
die zuk&#252;nftige KI-Verordnung so ausgestaltet werden muss, dass sie zur
Entstehung und zum nachhaltigen Wachstum innovativer KI-Start-ups und 
-KMU beitr&#228;gt. 
13. Der Bundesrat bef&#252;rwortet deshalb den Ansatz einer risikobasierten
Regulierung von KI-Systemen, die sich gezielt auf jene Anwendungen konzentriert, in 
denen die Verwendung von KI-Technologien mit hohen beziehungsweise
inakzeptablen Risiken f&#252;r die Sicherheit und Gesundheit sowie die Grundrechte von 
Personen einhergeht. 
Er begr&#252;&#223;t den gew&#228;hlten Ansatz, KI-Systeme nur insoweit Sorgfalts- und 
&#220;berwachungspflichten zu unterwerfen, als ein hohes Risiko f&#252;r Rechte und 
Freiheiten besteht. In Anbetracht der Gefahr unerw&#252;nschter Folgen (zum
Beispiel diskriminierende Effekte, falsche Ergebnisse wegen schlechter
Datenqualit&#228;t oder Manipulation von au&#223;en) sind Sicherungsma&#223;nahmen f&#252;r kritische 
Anwendungen sinnvoll. 
Der Bundesrat bittet die Bundesregierung darum, sich im weiteren
Gesetzgebungsverfahren daf&#252;r einzusetzen, dass dieser Ansatz konsequent und f&#252;r die 
betroffenen Akteure erf&#252;llbar umgesetzt wird. Es muss sichergestellt werden, 
dass die konkreten regulatorischen Anforderungen an eine bestimmte
Anwendung sich daran bemessen, dass diese tats&#228;chlich ein erhebliches
Risikopotenzial aufweist. Dies gilt insbesondere auch f&#252;r den Fall, wenn KI-Technologien als 
Teil eines Systems beziehungsweise Produkts eingesetzt werden, welches einer 
sektorspezifischen Regulierung unterliegt. 
Insbesondere muss vermieden werden, dass bereits langj&#228;hrig eingesetzte
Systeme, die kein oder nur ein geringes Risikopotenzial aufweisen oder deren
funktionale Sicherheit bereits nach sektorspezifischen Vorgaben gepr&#252;ft wurde, 
durch nachtr&#228;glich unerf&#252;llbare beziehungsweise nicht wirtschaftlich
darstellbare Anforderungen vom Markt genommen werden m&#252;ssen. Der Bundesrat weist 
in diesem Zusammenhang auch darauf hin, dass die Definitionen von KI-
Systemen (insbesondere die in Anhang I des Verordnungsvorschlags
aufgef&#252;hrten Techniken und Konzepte) mit Bedacht gew&#228;hlt werden m&#252;ssen. Nach dem 
Vorschlag der Kommission w&#252;rde beispielsweise jegliche Software, die
statistische Ans&#228;tze aufweist, als KI-Anwendung reguliert, was nach Auffassung des 
Bundesrates eine sehr weitgehende Definition ist.
14. Der Bundesrat begr&#252;&#223;t den Ansatz, zur Vermeidung von Doppelstrukturen und 
zur Nutzung vorhandener sektorspezifischer Expertise die Regulierung von KI-
Systemen, die in bestimmte Maschinen oder Systeme integriert werden, in
bestehende Regelungsrahmen zu integrieren. Einheitliche Ansprechpartner
erleichtern wirtschaftlichen Akteuren das Verfahren erheblich. Der Bundesrat
bittet jedoch um Pr&#252;fung, ob die ausschlie&#223;liche Zust&#228;ndigkeit der
sektorspezifischen Aufsichtsbeh&#246;rden auch im Falle der Verarbeitung personenbezogener 
Daten beibehalten werden kann, da der Vorschlag auch auf Artikel 16 AEUV
gest&#252;tzt wird. Aus diesem folgt, dass &#8211; soweit personenbezogene Daten
verarbeitet werden &#8211; eine den Anforderungen gen&#252;gende &#8222;unabh&#228;ngige&#8220;
Aufsichtsbeh&#246;rde erforderlich ist. Diese Unabh&#228;ngigkeit d&#252;rfte nicht bei allen
sektorspezifischen Aufsichtsbeh&#246;rden gegeben sein. Eine Aufteilung der Zust&#228;ndigkeit 
zwischen zwei Beh&#246;rden im Falle der Betroffenheit (auch) personenbezogener 
Daten sollte vermieden werden. Sofern das nicht m&#246;glich ist, muss das
Verfahren der Zusammenarbeit geregelt werden.
15. Um Doppelbelastungen von Unternehmen bei der Erf&#252;llung von
Dokumentations- und Transparenzpflichten zu ein und demselben Produkt &#8211; beispielsweise 
in der Medizintechnikbranche &#8211; zu vermeiden, wird die Bundesregierung
gebeten, darauf hinzuwirken, bestehende Strukturen zu integrieren und den
Verwaltungsmehraufwand so gering wie m&#246;glich zu halten.
16. Aus Sicht des Bundesrates sollte die vorgeschlagene Verordnung in einigen 
Punkten noch ge&#228;ndert werden. Er bittet die Bundesregierung, bei den weiteren 
Beratungen auf EU-Ebene die folgenden Aspekte zu ber&#252;cksichtigen:
Zu einzelnen Vorschriften
17. Der Bundesrat unterst&#252;tzt das Bestreben der Kommission, auch Anbieter und 
Nutzende von KI-Systemen, die in Drittstaaten ans&#228;ssig sind, in den
Anwendungsbereich der Verordnung einzubeziehen, wenn sie die KI-Systeme in der 
Union in Verkehr bringen oder sich die Verwendung der KI-Systeme auf die 
Menschen in der Union auswirkt. Allerdings sollte bei den weiteren
Verhandlungen gepr&#252;ft werden, den Geltungsbereich der Verordnung auch f&#252;r Anbieter 
und Nutzende in Drittstaaten zu &#246;ffnen, wenn diese Daten von B&#252;rgerinnen und 
B&#252;rgern auswerten und das vom KI-System erzeugte Ergebnis Auswirkungen 
auf die B&#252;rgerinnen und B&#252;rger in der Union haben kann. Aus Sicht des
Bundesrates birgt die in Artikel 2 Absatz 1 Buchstabe c des Verordnungsvorschlags 
gew&#228;hlte Bedingung, dass das vom KI-System hervorgebrachte Ergebnis in der 
Union verwendet werden m&#252;sse, die Gefahr von Rechtsunsicherheit und
Umgehung.
18. Der Bundesrat merkt an, dass mit der weitgehenden Herausnahme von
Kraftfahrzeugen aus dem Anwendungsbereich der Verordnung ein wesentlicher und 
praxisnaher Bereich von KI-Anwendungen unreguliert bleibt. Die Kommission 
gibt lediglich den Hinweis, dass Kraftfahrzeuge nicht dem &#8222;New Legislative 
Framework&#8220; unterliegen, begr&#252;ndet ihre Entscheidung jedoch nicht n&#228;her.
19. Er stellt fest, dass der Begriff &#8222;System der K&#252;nstlichen Intelligenz&#8220; in Artikel 3 
Absatz 1 in Verbindung mit Anhang I des Verordnungsvorschlags sehr weit
gefasst ist. Dies erscheint grunds&#228;tzlich angemessen, da diese Definition die breite 
Diskussion in der Wissenschaft und Fachwelt widerspiegelt. Eine einheitliche 
Definition existiert (bisher) nicht. Da an die Bewertung als KI allein zun&#228;chst 
keine Folgen gekn&#252;pft sind, ist es unproblematisch, einen weiten Begriff zu 
w&#228;hlen.
Allerdings sollte die weite Definition und Beschreibung der Methoden KI auf 
&#8222;aus sich selbst heraus lernende Systeme&#8220; beschr&#228;nkt werden. Nahezu jede IT-
Anwendung verwendet einfache Sortier- und Suchalgorithmen und nutzt
demnach KI-Methoden gem&#228;&#223; der Definition in Anhang I des
Verordnungsvorschlags. In der Folge sind nahezu alle IT-Anwendungen von der Verordnung
erfasst.
Die Definition von KI-Systemen, die von der Regulierung betroffen sein sollen, 
in Anhang I des Verordnungsvorschlags &#8222;ARTIFICIAL INTELLIGENCE 
TECHNIQUES AND APPROACHES&#8220; (verwiesen von Artikel 3 Absatz 1 des 
Verordnungsvorschlags) enth&#228;lt unter Buchstabe c (&#8222;Statistical approaches, 
Bayesian estimation, search and optimization methods&#8220;) eine Reihe von
mathematischen beziehungsweise informatischen Methoden beziehungsweise
Gebieten, die zwar &#8211; nach derzeitigem Wissensstand &#8211; als umfassend betrachtet 
werden k&#246;nnen, unter die jedoch insbesondere einfache statistische
Vorgehensweisen ohne erhebliche Grundrechtsrisiken fallen, zu denen m&#246;glicherweise 
auch die Wahrscheinlichkeitsbehandlung nach Bayes zu z&#228;hlen w&#228;re. Bei einer 
derart weiten Definition k&#246;nnten streng genommen bereits die einfache
Berechnung eines Mittelwerts oder einer Standardabweichung sowie die Anwendung 
von linearer Regression oder &#196;hnlichem unter die KI-Methoden fallen, die von 
der Regulierung betroffen w&#228;ren. Auch konventionelle Methoden der amtlichen 
Statistik k&#246;nnten der Definition unterfallen. Der Bundesrat bittet daher die 
Bunderegierung, f&#252;r eine Streichung des ersten Teils von Anhang I Buchstabe c 
des Verordnungsvorschlags (&#8222;Statistical approaches&#8220;) und im &#220;brigen auch f&#252;r
eine Engerfassung der Definition von KI-Methoden beziehungsweise einer
erl&#228;uternden Klarstellung des angedachten Umfangs zu pl&#228;dieren. Sollte dem 
nicht entsprochen werden k&#246;nnen, wird die Streichung von Anhang I Buchstabe 
c des Verordnungsvorschlags empfohlen.
20. Nach Auffassung des Bundesrates ist die Beschr&#228;nkung der Verbote in
Artikel 5 Absatz 1 Buchstaben a und b des Verordnungsvorschlags auf
manipulative KI-Systeme, die physischen oder psychischen Schaden zuf&#252;gen, aus
Gr&#252;nden des Verbraucherschutzes nicht ausreichend. Die Bundesregierung wird
gebeten, sich daf&#252;r einzusetzen, dass auch KI-Systeme, die in der Absicht
hergestellt, in Verkehr gebracht oder verwendet werden, Menschen in unlauterer 
Weise wirtschaftlich zu sch&#228;digen, in die Verbote nach Artikel 5 des
Verordnungsvorschlags aufgenommen werden.
21. Der Bundesrat sieht au&#223;erdem bei einem uneingeschr&#228;nkten Einsatz von KI-
Systemen zur Identifizierung von Personen aufgrund biometrischer Daten sowie 
von Emotionserkennungssystemen durch private Unternehmen die Gefahr, dass 
personenbezogene Daten unter Missachtung der Zweckbindung von
Unternehmen zu umfassenden Profilbildungen und zur Verfeinerung manipulativer
Methoden der Beeinflussung von Verbraucherentscheidungen verwendet werden. 
Auch besteht bei Emotionserkennungssystemen ein gro&#223;es Potenzial f&#252;r
Fehleinsch&#228;tzungen, die f&#252;r betroffene Menschen mit erheblichen nachteiligen
Folgen verbunden sein k&#246;nnen und durch blo&#223;e Informationspflichten nicht
wirksam verhindert werden. Dies gilt insbesondere beim Einsatz derartiger Systeme 
als &#8222;digitaler L&#252;gendetektor&#8220;. Der Bundesrat bittet daher die Bundesregierung, 
sich bei den weiteren Verhandlungen f&#252;r die notwendigen Einschr&#228;nkungen 
einzusetzen. 
22. Er bittet die Bundesregierung ferner zu pr&#252;fen, ob der Anwendungsbereich des 
Verbots des sogenannten &#8222;Social Scoring&#8220; in Artikel 5 Absatz 1 Buchstabe c 
des Verordnungsvorschlags auch auf Unternehmen erstreckt werden kann,
deren Leistungen f&#252;r die B&#252;rgerinnen und B&#252;rger f&#252;r eine gleichberechtigte
Teilhabe von grundlegender Bedeutung sind. Aus Sicht des Bundesrates kann auch 
bei nicht beh&#246;rdlichem Einsatz von KI-Systemen zur Bewertung des sozialen 
Verhaltens die Gefahr von ungerechtfertigter Diskriminierung und einem 
grundrechtebeeintr&#228;chtigenden sozialen Anpassungsdruck bestehen.
23. Der Verordnungsvorschlag enth&#228;lt abgesehen von Artikel 5 keine materiellen 
Anforderungen zum Grundrechtsschutz, zum Schutz vor unerw&#252;nschten
Diskriminierungen oder zur Einhaltung von gesetzlichen Vorgaben. Sowohl die 
Konformit&#228;tsbewertungsverfahren als auch die beh&#246;rdliche Aufsicht w&#228;ren
damit auf eine &#220;berpr&#252;fung der &#252;berwiegend organisatorischen und
qualit&#228;tssichernden Schutzvorkehrungen beschr&#228;nkt. Aus Sicht des Bundesrates kann der 
notwendige pr&#228;ventive Schutz vor denkbaren Grundrechtsverletzungen und
unerw&#252;nschten Diskriminierungen durch KI-Systeme jedoch nur dann ausreichend 
gew&#228;hrleistet werden, wenn die Verordnung die Anbieter von KI-Systemen
bereits bei ihrer Konzeption und Entwicklung ausdr&#252;cklich an die Einhaltung von 
Grundrechten, Diskriminierungsverboten und sonstigen gesetzlichen Vorgaben, 
insbesondere zum Datenschutz, bindet. Der Bundesrat bittet die
Bundesregierung, sich bei den weiteren Verhandlungen f&#252;r die notwendigen Erg&#228;nzungen 
einzusetzen.
24. Er begr&#252;&#223;t die Zielsetzung der Kommission, nach dem risikobasierten Ansatz 
im Bereich der KI Praktiken zu verbieten, welche die Schw&#228;che oder
Schutzbed&#252;rftigkeit einer bestimmten Gruppe von Personen aufgrund ihres Alters oder 
ihrer k&#246;rperlichen oder geistigen Behinderung ausnutzen. Zur Pr&#228;zisierung des 
Personenkreises der Menschen mit Behinderungen sollte in Artikel 5 Absatz 1 
Buchstabe b des Verordnungsvorschlags im Einklang mit Artikel 1 der VN-
Behindertenrechtskonvention explizit auf Menschen abgestellt werden, die
k&#246;rperliche, seelische, geistige oder Sinnesbeeintr&#228;chtigungen haben. Dies gilt
speziell, wenn das Verhalten einer dieser Gruppe angeh&#246;renden Person in einer 
Weise wesentlich beeinflusst werden soll, die dazu f&#252;hrt, dass sie selbst oder
eine andere Person psychisch oder physisch gesch&#228;digt werden k&#246;nnte. Gerade 
bei Menschen mit seelischen Beeintr&#228;chtigungen wird in der Folge das Risiko 
einer psychischen Sch&#228;digung gesehen.
25. Der Bundesrat begr&#252;&#223;t ferner den von der Kommission vorgelegten
risikobasierten Ansatz und den damit einhergehenden Fokus auf Hochrisiko-KI-
Systeme. Mit der risikobasierten Einteilung in KI-Systeme der Klassen 1
(unannehmbares Risiko), 2 (hohes Risiko) und 3 (geringes oder minimales Risiko) 
greift die Kommission die vom Bundesrat in seiner Stellungnahme vom 
15. Mai 2020 (BR-Drucksache 95/20 (Beschluss)) ge&#228;u&#223;erten Bedenken auf. 
Die vorgelegte Einteilung in Risikoklassen wird grunds&#228;tzlich als angemessen 
eingesch&#228;tzt, um im gleichen Ma&#223;e Grundrechte und insbesondere
Verbraucherrechte zu sch&#252;tzen sowie die europ&#228;ische Innovationsf&#228;higkeit durch die 
Schaffung von Rechtssicherheit zu st&#228;rken.
26. Der Bundesrat teilt die Einsch&#228;tzung der Kommission, dass mit der Auflistung 
von Hochrisiko-KI-Systemen Rechtssicherheit erm&#246;glicht werden kann. Er
begr&#252;&#223;t, dass die Auflistung regelm&#228;&#223;ig aktualisiert werden soll. Der Bundesrat 
bittet die Kommission jedoch um kritische Pr&#252;fung, ob die im Vorschlag
aufgelisteten Hochrisikoanwendungsbereiche berechtigterweise aufgef&#252;hrt sind. Er 
regt dar&#252;ber hinaus an, Forschung und Entwicklung zu Indikatoren zu
unterst&#252;tzen und eine klare Operationalisierung aller Risikoklassen anzuwenden. 
Der Bundesrat gibt zu bedenken, dass, basierend auf diesem sehr weit gefassten 
Verst&#228;ndnis von KI-Systemen, die Bewertung als &#8222;Hochrisiko-KI-System&#8220; auch 
sehr weitreichend ist und im Einzelfall zu der unbeabsichtigten Erfassung von 
Anwendungen f&#252;hrt, die kaum als besonders risikoreich zu bewerten sind. Es 
sollte daher zus&#228;tzlich klargestellt werden, dass nur Systeme gemeint sind, von 
denen erhebliche sch&#228;dliche Auswirkungen auf die Gesundheit, die Sicherheit 
und die Grundrechte von Personen ausgehen, wie in Erw&#228;gungsgrund 27 des 
Verordnungsvorschlags erw&#228;hnt.
27. Bei Hochrisiko-KI-Systemen nach Artikel 6 des Verordnungsvorschlags
werden alle verantwortlichen Akteure umfangreichen Pflichten unterworfen. Dies 
erscheint in einigen denkbaren Konstellationen nicht gerechtfertigt. Aktuell 
werden in Anhang III des Verordnungsvorschlags die Hochrisiko-KI-Systeme 
im Stil einer fallbezogenen Darstellung definiert, die sich an Einsatzgebiet und 
-zweck orientiert. Legt man diesen Anwendungen jedoch die verwendete
Begriffsbestimmung f&#252;r KI zugrunde, so ist nahezu jeder kleinere Such- oder
Sortieralgorithmus innerhalb einer Software als Hochrisiko-KI-System zu werten, 
wenn diese f&#252;r die genannten Zwecke &#8222;bestimmt&#8220; ist. Dies birgt die Gefahr
eines erh&#246;hten b&#252;rokratischen und finanziellen Aufwands bei der Zulassung von 
Softwaresystemen f&#252;r die genannten Anwendungsgebiete, ohne dass hierzu ein 
Anlass best&#252;nde. Die Formulierung &#8222;bestimmungsgem&#228;&#223;&#8220; in den F&#228;llen des 
Anhangs III des Verordnungsvorschlags allein l&#228;sst nicht erkennen, dass zum 
Beispiel bei der Programmierung der Software diese Bestimmung vorgesehen 
worden sein muss. Eine &#8222;Bestimmung&#8220; der Zielsetzung durch Nutzende &#8211; wozu 
das System jedoch gar nicht vorgesehen ist &#8211; k&#246;nnte dem Wortlaut nach ebenso 
gen&#252;gen. Es w&#228;re zu weitgehend, jede denkbare Einsatzm&#246;glichkeit
heranzuziehen. Aus Ziffer 5.2.3 der Begr&#252;ndung des Verordnungsvorschlags geht
hervor, dass die Einstufung &#8222;auf der Zweckbestimmung des KI-Systems
entsprechend den bestehenden EU-Produktsicherheitsvorschriften&#8220; erfolgt, womit die 
Einstufung als Hochrisiko-KI-System nicht nur von der Funktion dieses
Systems abhinge, sondern auch von seinem konkreten Zweck und seinen
Anwendungsmodalit&#228;ten. Um Unklarheiten zu vermeiden, sollte daher in Anhang III 
des Verordnungsvorschlags jeweils der Begriff &#8222;bestimmungsgem&#228;&#223;&#8220; durch 
&#8222;entsprechend ihrer Zweckbestimmung&#8220; nach Artikel 3 Ziffer 12 des
Verordnungsvorschlags ersetzt werden.
28. Der Bundesrat h&#228;lt zudem die Bezeichnung &#8222;Hochrisiko-KI-System&#8220; nicht in 
jedem Fall f&#252;r angemessen. Der Begriff kann auf nichttechnisch gepr&#228;gte
Menschen, die mit Technikfolgenabsch&#228;tzungen nicht vertraut sind, abschreckend 
wirken und gegebenenfalls dazu f&#252;hren, dass kein KI-System eingesetzt wird, 
um kein &#8222;hohes Risiko&#8220; einzugehen. Nachdem die Kommission wiederholt
betont hat, dass es bei der Regulierung vor allem darum gehe, dass Menschen KI 
vertrauen (k&#246;nnen), sollte eine andere Formulierung erwogen werden, zum
Beispiel &#8222;regulierte KI&#8220; oder &#8222;pr&#252;fbed&#252;rftige KI&#8220;, insbesondere wenn Systeme
gemeint sind, die gem&#228;&#223; Artikel 6 des Verordnungsvorschlags als
Sicherheitskomponente Risiken senken sollen. Der Begriff ist zudem inkonsequent, da im 
Folgenden (Artikel 65 fortfolgende des Verordnungsvorschlags) zum Beispiel 
von &#8222;konformen KI-Systemen, die ein Risiko bergen&#8220; gesprochen wird.
&#8222;Konforme KI-Systeme&#8220; sind Hochrisiko-KI-Systeme, die den f&#252;r sie aufgestellten 
Anforderungen entsprechen, aber dennoch ein (weiteres) spezifisches Risiko 
bergen. Diese Systeme sind demnach noch risikobehafteter als blo&#223;e
&#8222;Hochrisiko-KI-Systeme&#8220;, was in der Terminologie deutlich werden sollte.
29. Er h&#228;lt jedoch aus Gr&#252;nden des Verbraucherschutzes die Definition und
Aufz&#228;hlung von Hochrisiko-KI-Systemen f&#252;r nicht ausreichend. So sollten nicht 
nur das &#8222;Kreditscoring&#8220;, sondern auch sonstige &#8222;KI-Scoring&#8220;-Verfahren, auf 
deren Grundlage Unternehmen &#252;ber den Zugang zu unverzichtbaren Leistungen 
wie beispielsweise Krankenversicherungen, Gesundheitsdienstleistungen und 
Wohnraum entscheiden, in Anhang III des Verordnungsvorschlags
aufgenommen werden. Gleiches gilt f&#252;r &#8222;Scoring&#8220;-Verfahren, die aufgrund ihrer
Zweckbestimmung, der verwendeten Daten und der angewandten Kriterien ein hohes 
Diskriminierungspotenzial bergen. Beispielhaft genannt sind KI-gest&#252;tzte
Kundenprofile, die &#252;ber den Zugang zum Angebot von Ferienunterk&#252;nften oder
Bef&#246;rderungsdienstleistungen entscheiden.
30. Der Bundesrat verweist beispielhaft auf die Gesundheitsindustrie. Im Rahmen 
der neuen Medizinprodukte- und In-Vitro-Diagnostik-Regulierung 
(MDR/IVDR) wurden bereits umfangreiche Anforderungen an die Qualit&#228;t der 
Produkte und die Patientensicherheit vorgegeben, die auch auf KI-Systeme 
Anwendung finden. Die Umsetzung dieser Anforderungen stellt die Branche, 
die in einem starken internationalen Wettbewerb steht, vor erhebliche
Herausforderungen. Dies f&#252;hrt auch zu unerw&#252;nschten Folgen f&#252;r die
Patientenversorgung, weil dringend ben&#246;tigte Bestands- und Nischenprodukte nicht mehr
hergestellt werden und die Neuentwicklung von Innovationen ausgesetzt wird. Vor 
diesem Hintergrund k&#246;nnte eine pauschale Einstufung praktisch aller
softwarebasierten MDR/IVD-Produkte als Hochrisiko-KI-Anwendungen dazu f&#252;hren, 
dass KI-Innovationen im Gesundheitssektor nachhaltig und auf breiter Front 
ausbleiben und insbesondere KMU sich aus der KI-Entwicklung zur&#252;ckziehen. 
Eine Unterscheidung zwischen KI-basierten und auf konventioneller Software 
basierenden (Bestands-)Medizinprodukten sowie eine
anwendungsfallspezifische Risikoeinstufung, die beispielsweise ber&#252;cksichtigt, ob die KI Patientinnen 
und Patienten oder medizinisches Personal lediglich unterst&#252;tzt oder
menschliche Handlungen weitestgehend ersetzt, k&#246;nnten diese negativen Effekte
reduzieren beziehungsweise verhindern.
31. Der Bundesrat h&#228;lt die Aufz&#228;hlung der sch&#252;tzenswerten Belange in Artikel 7 
Absatz 1 Buchstabe b und Absatz 2 des Verordnungsvorschlags, die den
Rahmen f&#252;r die Einbeziehung weiterer Hochrisiko-KI-Systeme setzen, f&#252;r nicht 
ausreichend. Er bittet die Bundesregierung, sich daf&#252;r einzusetzen, dass darin 
auch das Risiko einer erheblichen wirtschaftlichen Sch&#228;digung einer Vielzahl 
von Verbraucherinnen und Verbrauchern aufgenommen wird.
32. Zum Schutz vor unkontrollierbaren Risiken bittet der Bundesrat zu pr&#252;fen, ob 
vor allem beim Einsatz von Hochrisiko-KI-Systemen als
Sicherheitskomponenten in Produkten die Weiterentwicklung der Systeme durch selbstlernende
Prozesse an bestimmte Regeln gebunden sein sollte, die vom KI-System nicht 
&#252;berwunden werden k&#246;nnen.
33. Der Bundesrat sieht au&#223;erdem Verbesserungsbedarf hinsichtlich der
&#220;berpr&#252;fbarkeit von Hochrisiko-KI-Systemen und ihren Entscheidungen. Bei
Hochrisiko-KI-Systemen sollten Anstrengungen unternommen werden, nicht nur die 
Prozesse zu protokollieren, sondern auch die vom KI-System hervorgebrachten 
Ergebnisse erkl&#228;rbar und ihre Gr&#252;nde nachvollziehbar zu machen. Um zu
gew&#228;hrleisten, dass die Anwendung von KI-Systemen beim Verdacht erheblicher 
unvorhergesehener Risiken tats&#228;chlich gestoppt wird und keine Folgerisiken 
entstehen, sollten grunds&#228;tzlich die Basisfunktionen des mit der KI
verbundenen restlichen Produkts oder Systems weiterhin verf&#252;gbar sein.
34. Er begr&#252;&#223;t die vorgeschlagene Flexibilit&#228;t von Ex-ante-Konformit&#228;tspr&#252;fungen 
von Hochrisiko-KI-Systemen sowie deren Integration in bereits bestehende 
Konformit&#228;tspr&#252;fungen, wo immer dies m&#246;glich ist. Er weist darauf hin, dass 
durch die Konformit&#228;tspr&#252;fungen KMU und Start-ups nicht &#252;berm&#228;&#223;ig belastet 
werden sollen, und regt an zu pr&#252;fen, inwieweit hier weitere unterst&#252;tzende 
Ma&#223;nahmen ergriffen werden k&#246;nnen.
35. Der Bundesrat stuft die an Hochrisiko-KI-Systeme formulierten Anforderungen 
als grunds&#228;tzlich w&#252;nschenswert ein. Er weist jedoch darauf hin, dass die
Implementierung dieser Anforderungen teilweise eine technische Herausforderung 
darstellt. Der Bundesrat sieht in diesem Zusammenhang Forschungs- und
Entwicklungsbedarf, der ein Zusammenwirken von wirtschaftlichen,
wissenschaftlichen und zivilgesellschaftlichen Akteuren erfordert.
36. Der Bundesrat begr&#252;&#223;t die &#220;berlegung der Kommission, f&#252;r die Durchf&#252;hrung 
der Konformit&#228;tsbewertung von Hochrisiko-KI-Systemen ein System von
notifizierten Stellen einzusetzen. Er sieht darin die M&#246;glichkeit, auf den
hervorragenden deutschen Pr&#252;finfrastrukturen aufzubauen. Er weist jedoch darauf hin, 
dass bei dieser dezentralen Markt&#252;berwachung ein einheitliches und
angemessenes Qualit&#228;tsniveau zu gew&#228;hrleisten ist. Er bittet die Kommission,
entsprechende Vorkehrungen der Qualit&#228;tssicherung zu treffen.
37. Der Bundesrat stellt fest, dass sich die Konformit&#228;tsbewertung bei Hochrisiko-
KI-Systemen im Sinne des Anhangs III des Verordnungsvorschlags weitgehend 
auf eine interne Kontrolle durch den Anbietenden beschr&#228;nkt. Eine externe 
Kontrolle durch eine notifizierte Stelle bietet jedoch gr&#246;&#223;ere Gew&#228;hr f&#252;r eine 
unabh&#228;ngige Pr&#252;fung und sollte vor allem dann, wenn die Gefahr von
erheblichen Sch&#228;den und Grundrechtsbeeintr&#228;chtigungen besteht, der Regelfall sein. 
Der Bundesrat regt daher an, unter Ber&#252;cksichtigung des
Verh&#228;ltnism&#228;&#223;igkeitsgrundsatzes eine Erweiterung der Verpflichtung zu einer externen
Konformit&#228;tsbewertung vor allem bei Hochrisiko-KI-Systemen, die zu kommerziellen 
Zwecken eingesetzt werden, zu pr&#252;fen.
38. Die Kapazit&#228;ten und Kompetenzen von Konformit&#228;tsbewertungsstellen k&#246;nnen 
aber auch ein Engpass f&#252;r die Zulassung von bestimmten
Hochrisikoanwendungen sein. Der Bundesrat verweist in diesem Zusammenhang auf die
Erfahrungen bei der Umsetzung der MDR und IVDR, wo fehlende Benannte Stellen
erhebliche negative Auswirkungen auf die betroffenen Unternehmen und die
Patientenversorgung haben. Der Bundesrat bittet die Bundesregierung deshalb,
daf&#252;r Sorge zu tragen, dass den Unternehmen die Infrastruktur, die sie zur
Erf&#252;llung von regulatorischen Anforderungen an Hochrisiko-KI-Systeme zwingend 
ben&#246;tigen, rechtzeitig und in ausreichender Kapazit&#228;t zur Verf&#252;gung steht.
39. Der Bundesrat begr&#252;&#223;t, dass f&#252;r Hochrisiko-KI-Systeme ein
Risikomanagementsystem eingerichtet und angewandt wird. Bei dessen Umsetzung ist gem&#228;&#223; 
Artikel 9 Absatz 8 des Verordnungsvorschlags insbesondere zu
ber&#252;cksichtigen, ob das Hochrisiko-KI-System wahrscheinlich f&#252;r Kinder zug&#228;nglich ist
oder Auswirkungen auf Kinder hat. Der Bundesrat spricht sich daf&#252;r aus, analog 
dem Schutzgedanken von Artikel 5 Absatz 1 Buchstabe b des
Verordnungsvorschlags auch die wahrscheinliche Betroffenheit weiterer aufgrund ihres Alters 
oder ihrer k&#246;rperlichen, seelischen, geistigen oder Sinnesbeeintr&#228;chtigungen 
schutzbed&#252;rftiger Gruppen explizit im Rahmen eines
Risikomanagementsystems zu ber&#252;cksichtigen. 
40. Er bittet die Kommission zu pr&#252;fen, ob die Einhaltung der in Artikel 10 des 
Verordnungsvorschlages normierten Anforderungen an die genutzten Daten 
auch durch eine Best&#228;tigung von KI-Dienstleistern nachgewiesen werden kann. 
Besonders KMU sind von einer mangelnden Datenbasis betroffen.
41. Der Vorschlag sieht au&#223;erdem besondere Transparenzpflichten f&#252;r bestimmte 
KI-Systeme, die mit nat&#252;rlichen Personen interagieren, vor. Gleiches gilt f&#252;r 
Emotionserkennungs-Systeme, Systeme zur biometrischen Kategorisierung und 
KI-Systeme, die Bild-, Ton- oder Videoinhalte erzeugen oder manipulieren, die 
wirklichen Personen, Gegenst&#228;nden oder Orten merklich &#228;hneln und einer
Person f&#228;lschlicherweise als echt erscheinen w&#252;rden (&#8222;Deepfake&#8220;). Dass die
entsprechenden Informationen und Mitteilungen f&#252;r die Nutzenden f&#252;r Menschen 
mit Behinderungen in barrierefrei zug&#228;nglicher Form bereitgestellt werden
sollten, wird lediglich in Erw&#228;gungsgrund 70 des Verordnungsvorschlags erw&#228;hnt. 
Aus Sicht des Bundesrates ist Artikel 52 des Verordnungsvorschlags um eine 
entsprechende Ma&#223;gabe zu erg&#228;nzen, analog Artikel 13 Absatz 2 des
Verordnungsvorschlags betreffend die Gebrauchsanweisungen f&#252;r Hochrisiko-KI-
Systeme in barrierefrei zug&#228;nglicher und verst&#228;ndlicher Form.
42. Er begr&#252;&#223;t die von der Kommission in Artikel 53 des Verordnungsvorschlages 
vorgesehenen KI-Reallabore, in denen das Experimentieren von KI-
Technologien erleichtert und Innovationen im Zusammenspiel mit Regulierung 
praxisnah ausprobiert werden sollen. 
Der Bundesrat empfiehlt, KI-Reallabore grunds&#228;tzlich in allen Branchen, die 
die Mitgliedstaaten als sinnvoll erachten, zu erm&#246;glichen. Er bittet die
Bundesregierung, z&#252;gig entsprechende Initiativen zu starten, um das deutsche
Innovationspotenzial, insbesondere von KMU und Start-ups, zu heben. Der Bundesrat 
erinnert daran, dass in den L&#228;ndern bereits erste Anstrengungen unternommen 
wurden, die es mit den vorgeschlagenen Ma&#223;nahmen zu st&#228;rken und aktiv
einzubeziehen gilt. 
Er begr&#252;&#223;t besonders den Ansatz der Einrichtung von KI-Reallaboren. Eine
solche staatliche Investition in die Entwicklung und Erprobung innovativer
Anwendungen ist sehr positiv, insbesondere da die KI-Reallabore zug&#228;nglich f&#252;r 
Unternehmen aller Gr&#246;&#223;en sein sollen. Der Ansatz beseitigt potenziell zu hohe 
Entwicklungskosten und zielt auf die Vermeidung der vielleicht gr&#246;&#223;ten H&#252;rde 
f&#252;r KMU, der Rechtsunsicherheit, ab. Der Bundesrat bittet jedoch um Pr&#252;fung, 
ob die den Datenschutz betreffenden Bestimmungen im Zusammenhang mit 
den KI-Reallaboren klarer gefasst werden k&#246;nnen. Hinsichtlich der
Verarbeitung personenbezogener Daten ist nicht klar, ob Artikel 54 des
Verordnungsvorschlags als eigenst&#228;ndige Rechtsgrundlage zur (zweck&#228;ndernden)
Verarbeitung personenbezogener Daten zu verstehen ist. Der Wortlaut von Artikel 54 
Absatz 1 des Verordnungsvorschlags legt dies nahe, der Erw&#228;gungsgrund 41 
und Artikel 54 Absatz 2 des Verordnungsvorschlags hingegen sprechen
dagegen. Die zweck&#228;ndernde Verarbeitung ist in der Datenschutzgrundverordnung 
(DSGVO) grunds&#228;tzlich geregelt (vergleiche Artikel 6 Absatz 4 in Verbindung 
mit Artikel 23 DSGVO). Es muss klar sein, ob er zus&#228;tzlich zu Artikel 54 des
Verordnungsvorschlags zu beachten ist. Weiterhin ist klarzustellen, wer in der 
Konstellation &#8222;KI-Reallabor&#8220; datenschutzrechtlich verantwortlich sein soll.
Artikel 53 Absatz 4 des Verordnungsvorschlags spricht lediglich von der
Schadenshaftung der &#8222;Beteiligten&#8220;. Artikel 53 Absatz 3 des Verordnungsvorschlags 
l&#228;sst zudem alle &#8222;Aufsichts- und Abhilfebefugnisse&#8220; der zust&#228;ndigen Beh&#246;rden 
unber&#252;hrt &#8211; wenigstens im europ&#228;ischen Kontext ist dies der Europ&#228;ische
Datenschutzbeauftragte (EDPS), dessen Beh&#246;rde das KI-Reallabor auch betreibt. 
Es bedarf hier einer Klarstellung der Rollen, m&#246;glichst nicht erst durch einen 
Durchf&#252;hrungsrechtsakt nach Artikel 53 Absatz 6 des Verordnungsvorschlags.
43. F&#252;r den Bundesrat steht au&#223;er Frage, dass der Zugang f&#252;r Menschen mit
Behinderungen zur Nutzung von KI-Systemen trotz der gesehenen Risiken zu
gew&#228;hrleisten ist. Er h&#228;lt es daher f&#252;r erforderlich, die Sicherstellung
ausreichender Barrierefreiheit von KI-Systemen in dem Verordnungsvorschlag in
geeigneter Weise zu verankern, und bittet die Bundesregierung, sich hierf&#252;r bei den 
weiteren Verhandlungen einzusetzen. Auch sollte nach Ansicht des Bundesrates 
in Artikel 69 Absatz 2 des Verordnungsvorschlags &#8211; ebenso wie in Absatz 1 &#8211; 
darauf verzichtet werden, die in Verhaltenskodizes vorgesehene Erf&#252;llung
weiterer Anforderungen f&#252;r KI-Systeme, wie die barrierefreie Zug&#228;nglichkeit f&#252;r 
Personen mit Behinderungen, nochmals explizit als &#8222;freiwillig&#8220; zu bezeichnen, 
da Verhaltenskodizes ohnehin in Form freiwilliger Selbstverpflichtung
eingegangen werden.
Zum Einsatz von Daten in KI-Systemen
44. Der Bundesrat bittet die Bundesregierung, sich f&#252;r eine bessere Verf&#252;gbarkeit 
von qualitativ hochwertigen Daten zur Entwicklung von KI-Systemen
einzusetzen, weil dies nicht nur eine wichtige Voraussetzung f&#252;r die Entwicklung
innovativer KI-L&#246;sungen, sondern auch f&#252;r die Vermeidung bestimmter Risiken wie 
etwa unerw&#252;nschten Verzerrungen (Bias) ist.
45. Daten-Synthetisierung kann ein wichtiger Ansatz sein, um weitere Fortschritte 
bei maschinellem Lernen und KI zu erreichen. Der Bundesrat bittet die
Bundesregierung, sich auch f&#252;r eine Kl&#228;rung der wichtigsten rechtlichen und ethischen 
Fragen der Daten-Synthetisierung einzusetzen.
46. Der medizinische Fortschritt durch KI ist ma&#223;geblich davon abh&#228;ngig, dass
Daten aus der medizinischen Versorgung und der klinischen Forschung sowie von 
Patientinnen und Patienten selbst erhobene Daten zeitnah und &#252;bergreifend
ausgewertet und die daraus gezogenen Erkenntnisse in die medizinische Praxis 
umgesetzt werden k&#246;nnen. Die Attraktivit&#228;t des Wirtschaftsstandortes
Deutschland h&#228;ngt heute stark davon ab, dass forschende Unternehmen und
Einrichtungen der &#246;ffentlichen Forschung auch im Sinne von Kooperationen einen
Rechtsrahmen vorfinden, in dem die Forschung stattfinden kann. Daher sollte eine 
praxistaugliche Umsetzung der Harmonisierung der Datenschutzgesetzgebung 
in Deutschland ebenso in der vereinbarten und gelebten Zusammenarbeit der 
L&#228;nder im Fokus bleiben wie die Weiterentwicklung eines gleichberechtigten 
Zugangs zu Forschungsdaten auf Bundes- und EU-Ebene f&#252;r die &#246;ffentliche und 
die private Forschung, etwa im Falle des Forschungsdatenzentrums nach &#167; 303d 
SGB V.
Zum Medienbereich
47. Aufgrund der zunehmenden Digitalisierung und Konvergenz der Medien sowie 
der wachsenden Bedeutung digitaler Plattformen f&#252;r die Medienlandschaft
einerseits und f&#252;r die freie demokratische Willensbildung andererseits ist der 
Umgang mit KI-Systemen auch von besonderer medienpolitischer Bedeutung.
48. Der Bundesrat sieht Transparenz als ein wichtiges Element im Umgang mit KI-
Systemen an und verweist dabei auch auf die im Medienstaatsvertrag der
L&#228;nder vorgesehene Transparenzpflicht bei der Anwendung sogenannter Social 
Bots.
Der Bundesrat begr&#252;&#223;t daher, dass f&#252;r bestimmte KI-Systeme, die mit
nat&#252;rlichen Personen interagieren, Transparenzpflichten bestehen. Er hebt in diesem 
Zusammenhang die besondere Bedeutung von KI im Bereich der Medien- und 
Meinungsfreiheit sowie in demokratischen Prozessen hervor. Er bittet um eine 
m&#246;glichst einheitliche und einfache Kennzeichnung.
49. Der Bundesrat betont, dass die Regelungskompetenz zur Sicherung des
Medienpluralismus nach den europ&#228;ischen Vertr&#228;gen bei den Mitgliedstaaten und als
Ausdruck des F&#246;deralismus in Deutschland bei den L&#228;ndern liegt. Die Organe 
der EU haben den Pluralismus der Medien und die Vielfalt der verschiedenen 
nationalen Medienlandschaften in Europa bei der Aus&#252;bung ihrer jeweiligen 
Zust&#228;ndigkeiten zu achten. Diese Prinzipien werden ausdr&#252;cklich auch in den 
unter der deutschen Ratspr&#228;sidentschaft verabschiedeten Schlussfolgerungen 
des Rates zur Sicherung eines freien und pluralistischen Mediensystems 
(2020/C 422/08) bekr&#228;ftigt und ebenfalls in anderen europ&#228;ischen Regelungen 
ausdr&#252;cklich anerkannt (vergleiche zum Beispiel Artikel 1 Absatz 6 E-
Commerce-Richtlinie, Artikel 1 Absatz 3 Buchstabe b des Europ&#228;ischen
Elektronischen Kommunikationskodexes, Artikel 21 Absatz 4 der EG-
Fusionskontrollverordnung oder Artikel 85 DSGVO).
50. Der Bundesrat nimmt zur Kenntnis, dass dem Verordnungsvorschlag bei der 
Definition der erfassten KI-Systeme ein sehr weites Verst&#228;ndnis zugrunde liegt 
und dieses gerade auch die Beeinflussung des Umfeldes als gewichtiges
Kriterium einbezieht.
51. Er weist auf die vielf&#228;ltigen Anwendungsfelder von KI-Systemen hin, die allein 
im Medienbereich etwa die Sicherung der Qualit&#228;t journalistisch-redaktioneller 
Inhalte, die Herstellung barrierefreier Angebote, die Moderation von Inhalten, 
die Nutzung und das Angebot von Auswahl-, Empfehlungs- und
Personalisierungsmechanismen sowie sprachgesteuerte Assistenzsysteme umfassen, und
betont die Notwendigkeit, den Anwendungsrahmen der Verordnung klar zu
definieren sowie Ma&#223;nahmen angemessen auszugestalten.
52. Der Bundesrat stellt fest, dass der Verordnungsvorschlag bei der Bewertung der 
von ihm erfassten KI-Anwendungen und des mit ihnen verbundenen Risikos
einen prim&#228;r IT-sicherheitstechnischen Ansatz w&#228;hlt. Er weist darauf hin, dass 
diese im Verordnungsvorschlag vorgenommene Einsch&#228;tzung von einer unter 
medienrechtlichen Gesichtspunkten vorzunehmenden Einsch&#228;tzung abweichen 
kann. Dies wird beispielsweise deutlich bei der Einstufung von sogenannten 
Deepfakes und Bots als Anwendungen mit lediglich geringem Risiko. Durch 
die Nutzung dieser Anwendungen kann der &#246;ffentliche Diskurs verdeckt
manipuliert und damit ein erheblicher Einfluss auf den Prozess der individuellen und 
&#246;ffentlichen Meinungsbildung ausge&#252;bt werden. Die Einordnung dieser
Aspekte ist von besonderer Relevanz um sicherzustellen, dass Folgewirkungen auf 
demokratische Prozesse ganzheitlich ber&#252;cksichtigt werden. Dabei ist der
Eindruck zu vermeiden, dass sogenannte Deepfakes angesichts ihres potenziellen 
Einflusses auf den &#246;ffentlichen Diskurs als regul&#228;re Begleiterscheinung des 
Einsatzes von KI ohne weitergehende (bereichsspezifische) Regulierung
hinzunehmen sind. Diese durch die Mitgliedstaaten zu adressierende
medienrechtliche Dimension erfasst der Verordnungsvorschlag aufgrund der
Gesetzgebungszust&#228;ndigkeiten richtigerweise nicht.
53. Der Bundesrat fordert sicherzustellen, dass der Verordnungsvorschlag die
M&#246;glichkeiten der Mitgliedstaaten, ihrer Verpflichtung zur Sicherung von
Meinungs- und Medienpluralismus nachzukommen, nicht einschr&#228;nkt. Die in ihrer 
Kulturhoheit liegende Regulierung wie auch die Durchsetzung sind durch
entsprechende &#214;ffnungsklauseln sicherzustellen, welche zus&#228;tzliche
Verpflichtungen, Ausnahmen oder Abweichungen von der vorgeschlagenen Verordnung 
erm&#246;glichen, soweit sie zur Sicherung des Medienpluralismus im jeweiligen 
Mitgliedstaat notwendig sind.
Zum Justizbereich und zum Bereich der Sicherheitsbeh&#246;rden
54. Der Bundesrat regt an zu pr&#252;fen, ob in Artikel 5 Absatz 1 Buchstabe b des
Verordnungsvorschlags ausdr&#252;cklich klargestellt werden soll, dass die richterliche 
Entscheidung keinem KI-System &#252;bertragen werden darf und dass keine KI-
Systeme eingesetzt werden d&#252;rfen, die durch ihre Konzeption die Gefahr
bergen, dass die richterliche Entscheidungsfindung dahingehend beeinflusst wird, 
dass bei mehreren vertretbaren Rechtsauffassungen eine Vorauswahl getroffen 
und dem Ergebnis zu Grunde gelegt wird. Ein Richter muss von Dritten erstellte 
vorbereitende Arbeiten inhaltlich voll nachvollziehen, bevor er sie in seiner 
Entscheidungsbegr&#252;ndung verwenden darf. Bei einer durch KI-Systeme
getroffenen Vorauswahl besteht die Gefahr, dass hierdurch die
Entscheidungsfindung des Richters, der die Anwendung nutzen m&#246;chte, inhaltlich determiniert 
wird. Eine Auseinandersetzung mit weniger verbreiteten Rechtsauffassungen 
und eine Fortentwicklung der Rechtsprechung k&#246;nnten hierdurch unterbunden 
werden. Eine solche &#8222;Lenkungsfunktion&#8220; darf KI-Systemen nicht zukommen.
55. Er gibt zu bedenken, dass der Verordnungsvorschlag in Artikel 5 tats&#228;chlich 
kein Verbot von biometrischen Echtzeit-Fernidentifikationssystemen vorsieht, 
sondern ihren Einsatz unter bestimmten Bedingungen gestattet. Angesichts der 
mit ihnen verbunden Gefahren f&#252;r die Werte der Union sollte eine eigene
Risikoklasse geschaffen werden. Bei einem zul&#228;ssigen Einsatz von bio-metrischen 
Echtzeit-Fernidentifikationssystemen sollten die Anforderungen an Hochrisiko-
KI-Systeme erf&#252;llt werden.
56. Die Kommission beabsichtigt mit einem horizontalen Ansatz die einheitliche 
Regulierung des Einsatzes von Methoden der KI &#252;ber unterschiedlichste
Einsatzbereiche hinweg. Diesem horizontalen Ansatz folgend finden sich in
Anhang III zu Artikel 6 Absatz 2 des Verordnungsvorschlags die Bereiche, in
denen der Einsatz von Methoden der KI von der Kommission als derart riskant 
angesehen werden, dass dort zum Einsatz kommende KI-Systeme als
Hochrisiko-KI-Systeme im Sinne der Verordnung eingestuft werden. Durch diese
Einstufung unterfallen die Systeme in diesen Bereichen insbesondere den
Vorgaben in Titel III des Verordnungsvorschlags, der Vorschriften f&#252;r KI-Systeme 
enth&#228;lt, die ein hohes Risiko f&#252;r die Gesundheit und Sicherheit oder f&#252;r die 
Grundrechte nat&#252;rlicher Personen darstellen. Auff&#228;llig ist hierbei, dass die 
Klassifizierung von Hochrisiko-KI-Systemen f&#252;r den gesamten Bereich der
Justiz, der unter Ziffer 8 des Anhangs III zu Artikel 6 Absatz 2 des
Verordnungsvorschlags erw&#228;hnt wird, noch nicht ausreichend konkret definiert ist und
hierdurch einerseits die Verordnung ihren Schutzzweck nicht hinreichend erf&#252;llen 
k&#246;nnte sowie andererseits f&#252;r eine &#220;berregulierung im unmittelbaren
justiziellen Umfeld sorgen w&#252;rde. W&#228;hrend in s&#228;mtlichen in Ziffer 8 des Anhangs III 
des Verordnungsvorschlags aufgef&#252;hrten Bereichen konkrete
Gef&#228;hrdungsvektoren, wie beispielsweise biometrische Fernidentifizierung, Zugang zu Bildung 
und Beruf oder Betrieb systemrelevanter Infrastruktur angef&#252;hrt sind, die beim 
Einsatz in spezifischen Bereichen eine Einstufung als Hochrisiko-KI-System 
bedingen, ist diese Definition von Gef&#228;hrdungsvektoren im Bereich der Justiz 
nicht gelungen. So sollen nach dem Entwurf bereits Methoden der KI als
Hochrisiko-System eingestuft werden, die &#8222;bestimmungsgem&#228;&#223; Justizbeh&#246;rden bei 
der Ermittlung und Auslegung von Sachverhalten und Rechtsvorschriften und 
bei der Anwendung des Rechts auf konkrete Sachverhalte unterst&#252;tzen sollen&#8220;. 
Diese Definition ist ungeeignet, hochriskante Einsatzgebiete in der Justiz zu
beschreiben, da sie ohne Differenzierung den gr&#246;&#223;ten Teil des gesamten
T&#228;tigkeitsbereichs der Justiz erfasst, der aus der Natur der Sache heraus aus der
Ermittlung und Auslegung von Sachverhalten sowie der Anwendung des Rechts 
auf diese Sachverhalte besteht. Insbesondere schlie&#223;t die Definition auch solche 
T&#228;tigkeiten ein, bei denen von vorneherein kein Gef&#228;hrdungsvektor
anzunehmen ist. Schon eine blo&#223;e Unterst&#252;tzungshandlung in diesem weiten
Einsatzbereich soll f&#252;r die Einstufung als Hochrisiko-System ausreichen. Es findet damit 
eine Unterbetonung des Gef&#228;hrdungsvektors bei einer &#220;berbetonung des
Einsatzbereiches statt. Damit widerspricht die Definition zugleich der &#252;brigen
Systematik der Ziffern 1 bis 7 des Anhangs III des Verordnungsvorschlags, wo f&#252;r 
die jeweiligen Bereiche gezielt und spezifisch Gef&#228;hrdungsvektoren
beschrieben werden, um die Einsatzgebiete von Hochrisiko-KI zu definieren, bei denen 
ein hohes Risiko f&#252;r die Gesundheit und Sicherheit oder f&#252;r die Grundrechte zu 
bef&#252;rchten ist.
57. Verst&#228;rkt wird diese Problematik dadurch, dass die im Verordnungsvorschlag 
vorgesehene Definition von KI gem&#228;&#223; Artikel 3 Absatz 1 in Verbindung mit 
Anhang I des Verordnungsvorschlags derart breit gefasst ist, dass darunter auch 
Techniken zu subsumieren sind, die dem eigentlichen Sinne nach nicht als KI-
Methoden einzustufen w&#228;ren, sondern eher dem Bereich genereller
Informationstechnologie in Form spezifischer Algorithmen zuzuordnen sind. Es steht zu 
bef&#252;rchten, dass zahlreiche seit Jahren im Einsatz befindliche Anwendungen 
der Justiz nach dieser Definition bereits KI-Systeme im Sinne der Verordnung 
bilden werden. Hierdurch sind erhebliche Einschr&#228;nkungen bei der Entwicklung 
und Weiterentwicklung der einschl&#228;gigen Fachverfahren zu erwarten, die sich 
ohnehin bereits komplex darstellen. Diesen Einschr&#228;nkungen steht dabei kein 
Vorteil durch die Regulierung gegen&#252;ber, da es sich bei diesen Systemen nicht 
um solche handelt, von denen ein Risiko f&#252;r die Gesundheit und Sicherheit oder 
f&#252;r die Grundrechte ausgehen k&#246;nnte. Sie werden vom Geltungsbereich der 
vorgeschlagenen Verordnung nur deshalb umfasst, da die zu weite technische 
Definition von KI-Systemen gemeinsam mit der zu weiten Definition der
Hochrisiko-Einsatzgebiete in der Justiz ein wechselseitig ausuferndes
Zusammenspiel erzeugt. Mithin bedingt die technisch sehr weite Definition eine
Konkretisierung der Hochrisiko-Einsatzgebiete. 
58. Software, die zur reinen Unterst&#252;tzung eingesetzt wird und von der nur ein
geringes Risiko ausgeht, sollte nicht als Hochrisiko-KI-System eingestuft werden. 
Hierunter fallen Anwendungen, die im Rahmen von Assistenzt&#228;tigkeiten auf der 
Gesch&#228;ftsstelle im Einsatz sind, auch wenn in ihnen Techniken eingesetzt
werden, bei denen Modelle mit Daten trainiert werden (zum Beispiel KI-gest&#252;tzte 
Extraktion von Metadaten in Schrifts&#228;tzen). Aus Erw&#228;gungsgrund 40 des
Verordnungsvorschlags ergibt sich, dass die Einstufung als Hochrisiko-KI-System 
sich nicht auf KI-Systeme erstrecken soll, die f&#252;r rein begleitende
Verwaltungst&#228;tigkeiten bestimmt sind, die die tats&#228;chliche Rechtspflege in Einzelf&#228;llen nicht 
beeintr&#228;chtigen, wie die Anonymisierung oder Pseudonymisierung gerichtlicher 
Urteile, Dokumente oder Daten, die Kommunikation zwischen dem Personal, 
Verwaltungsaufgaben oder die Zuweisung von Ressourcen. Sofern diese
Anwendungen nicht bereits durch eine Neugestaltung der KI-Definition oder eine 
engere Fassung von Ziffer 8 Buchstabe a in Anhang III des
Verordnungsvorschlags ausgenommen werden, sollte in Ziffer 8 Buchstabe a in Anhang III des 
Verordnungsvorschlags zumindest ausdr&#252;cklich geregelt werden, dass KI-
Systeme, die f&#252;r rein begleitende Verwaltungst&#228;tigkeiten bestimmt sind, die die 
tats&#228;chliche Rechtspflege in Einzelf&#228;llen nicht beeintr&#228;chtigen, nicht als
Hochrisiko-KI-Systeme anzusehen sind.
59. Der Bundesrat regt an, zu pr&#252;fen, ob aus Ziffer 8 Buchstabe a in Anhang III des 
Verordnungsvorschlags Anwendungen, die der Unterst&#252;tzung der Arbeit und 
Entscheidungsfindung der Richterinnen und Richter sowie Staatsanw&#228;ltinnen 
und Staatsanw&#228;lte dienen, teilweise ausgenommen werden sollen, sofern sie 
nicht bereits aufgrund einer Anpassung der KI-Definition nicht mehr erfasst 
sind. Denn es gibt Anwendungen, die nicht die in Artikel 7 Absatz 1 Buchstabe 
b des Verordnungsvorschlags f&#252;r die k&#252;nftige Entscheidung &#252;ber eine
Einstufung als Hochrisiko-KI-System aufgestellten Anforderungen erf&#252;llen und die 
die Werte der Union nicht gef&#228;hrden. Ihre Einstufung als Hochrisiko-KI-
Systeme erscheint daher nicht gerechtfertigt. 
Konkret ausgenommen werden sollten lediglich KI-Systeme, die der
Unterst&#252;tzung der Arbeit und Entscheidungsfindung der Richterinnen und Richter sowie 
Staatsanw&#228;ltinnen und Staatsanw&#228;lte dienen, sofern in ihnen keine Techniken 
eingesetzt werden, bei denen Modelle mit Daten trainiert werden, und deren 
Arbeitsergebnisse durch die Richterin beziehungsweise den Richter oder
Staatsanw&#228;ltin beziehungsweise Staatsanwalt vollumf&#228;nglich gesteuert werden
k&#246;nnen. In Bezug auf die vorgenannten Anwendungen sollte eine eigene
Risikoklasse unterhalb der Risikostufe Hochrisiko-KI-Systeme geschaffen werden, die 
verpflichtend vorgibt, dass das System dem Nutzenden die M&#246;glichkeit geben 
muss, selbst zwischen allen vertretbaren Rechtsauffassungen zu entscheiden.
60. Der Verordnungsvorschlag f&#252;hrt in der jetzigen Fassung zu erheblichen
Mehrkosten bei der Entwicklung und dem Betrieb von IT-Anwendungen der Justiz. 
Heute genutzte Systeme wie die Fach- und Textanwendungen EUREKA,
web.sta oder e&#178;T, die lediglich der Unterst&#252;tzung der Arbeit und
Entscheidungsfindung der Richterinnen und Richter sowie Staatsanw&#228;ltinnen und
Staatsanw&#228;lte dienen, w&#252;rden unter den Begriff einer Hochrisiko-KI zu fassen sein.
61. Zusammenfassend kann gesagt werden, dass der Verordnungsvorschlag mit 
Blick auf die Justiz zwingend &#252;berarbeitungsbed&#252;rftig ist. Zugespitzt umfasst 
der Verordnungsvorschlag unz&#228;hlige Technologien in nahezu s&#228;mtlichen
T&#228;tigkeitsbereichen der Justiz, v&#246;llig losgel&#246;st vom konkreten Gef&#228;hrdungsvektor 
und -potenzial. Der Verordnungsvorschlag w&#252;rde daher in der vorliegenden 
Fassung eine sch&#228;dliche &#220;berregulierung der Justiz verursachen.
62. Es ist daher unerl&#228;sslich, die Gef&#228;hrdungspotenziale im Bereich der Justiz zu 
identifizieren und in die Definition der Ziffer 8 des Anhangs III des
Verordnungsvorschlags aufzunehmen. In vergleichbarer Weise zu den vorherigen
Ziffern des Anhangs III des Verordnungsvorschlags sollten konkrete
Einsatzgebiete definiert werden, bei denen der Einsatz von KI-Methoden zu einer
Gef&#228;hrdung von Gesundheit, Sicherheit oder Grundrechten f&#252;hren kann.
63. Statt der pauschalen Formulierung in Ziffer 8 Buchstabe a in Anhang III des 
Verordnungsvorschlags sollte in Ziffer 8 in Anhang III des
Verordnungsvorschlags konkret herausgearbeitet werden, von welchen Einsatzszenarien in der 
Justiz ein hohes Risiko ausgeht. Die jetzige Fassung w&#252;rde dazu f&#252;hren, dass 
wahrscheinlich zahlreiche bereits jetzt in der Justiz eingesetzte
Softwareanwendungen als Hochrisiko-KI-Systeme gem&#228;&#223; Artikel 6 Absatz 2 des
Verordnungsvorschlags eingestuft werden m&#252;ssten, ohne dass das konkrete von der 
Anwendung tats&#228;chlich ausgehende Risiko Ber&#252;cksichtigung findet. Zudem 
sollte die &#220;berschrift angepasst werden, da keine Regelungen bez&#252;glich
demokratischer Prozesse getroffen werden.
64. Aufgrund von Erw&#228;gungsgrund 32 des Verordnungsvorschlags wird in der
Literatur angenommen, dass sich die Regelung in Artikel 6 Absatz 2 des
Verordnungsvorschlags in Verbindung mit Anhang III des Verordnungsvorschlags nur 
auf eigenst&#228;ndige KI-Systeme bezieht. Diese Auffassung wird durch 
Ziffer 5.2.3 des Verordnungsvorschlags der ausf&#252;hrlichen Erl&#228;uterung einzelner 
Bestimmungen des Vorschlags zwar best&#228;tigt; dies sollte jedoch durch eine
eindeutigere Formulierung in Artikel 6 des Verordnungsvorschlags klargestellt 
werden.
65. Unabh&#228;ngig von den vorherigen &#220;berlegungen sollte eine neue Ziffer 8
Buchstabe b geschaffen werden, in der KI-Systeme, in denen Techniken eingesetzt 
werden, bei denen Modelle mit Daten trainiert werden, die im Rahmen der 
Rechtsberatung eingesetzt werden, ebenfalls als Hochrisiko-KI-Systeme
klassifiziert werden. Der genaue Regelungsumfang sollte sich an dem f&#252;r die Justiz 
gew&#228;hlten Umfang orientieren. Dies w&#252;rde zum einen zu einer
Waffengleichheit zwischen Justiz und Anwaltschaft beziehungsweise Legal-Tech-
Unternehmen f&#252;hren und zum anderen die Rechtsrat suchenden EU-B&#252;rgerinnen und 
-B&#252;rger sch&#252;tzen.
66. Von einer Regelung des strafverfolgungsbeh&#246;rdlichen Einsatzes von KI in der 
auf Wirtschafts- und Gesellschaftsbelange zugeschnittenen KI-Verordnung
sollte abgesehen werden. Sollte an der Einbeziehung des Bereichs der
Strafverfolgung festgehalten werden, ist eine Inkonsistenz zu pr&#252;fen, wonach die in 
Ziffer 6 des Verordnungsvorschlags f&#252;r Strafverfolgungsbeh&#246;rden genannten 
Methoden im Bereich von Polizei und Staatsanwaltschaft als hochriskant
eingestuft werden, im gerichtlichen Bereich jedoch nicht, weil Strafgerichte nicht
unter den in Ziffer 6 des Verordnungsvorschlags verwendeten Begriff der
Strafverfolgungsbeh&#246;rde zu fassen sind.
67. Die Kommission will auch den Einsatz von KI durch staatliche Stellen,
insbesondere die Strafverfolgungs- und Sicherheitsbeh&#246;rden, regeln. Der Einsatz von 
KI zu Strafverfolgungszwecken beziehungsweise zu Gefahrenabwehrzwecken 
ist jedoch in den nationalen Strafverfahrensrechten beziehungsweise
Polizeigesetzen zu regeln. Angesichts der &#228;u&#223;erst begrenzten Gesetzgebungskompetenz 
der EU in diesem Bereich sollte von einer Regelung des Einsatzes zu
Gefahrenabwehrzwecken und des strafverfolgungsbeh&#246;rdlichen Einsatzes von KI in der 
auf Wirtschafts- und Gesellschaftsbelange zugeschnittenen vorgeschlagenen 
KI-Verordnung abgesehen werden. Der Bundesrat fordert daher, dass sich die 
EU auf ihre Kompetenzen beschr&#228;nkt und keine unverh&#228;ltnism&#228;&#223;igen
Versch&#228;rfungen f&#252;r den Einsatz von KI durch die Sicherheitsbeh&#246;rden einf&#252;hrt. Eine auf 
den Bereich der Inneren Sicherheit fokussierte Folgenabsch&#228;tzung ist dringend 
anzustreben.
68. Soweit an der Regelung des KI-Einsatzes durch Strafverfolgungsbeh&#246;rden
festgehalten wird, w&#228;re es vorzugsw&#252;rdig, wenn die Ma&#223;nahmen des pr&#228;ventiven 
und repressiven Bereichs der Strafverfolgungs- und Sicherheitsbeh&#246;rden in eine
gesonderte Regelungslage extrahiert w&#252;rden, die die Notwendigkeit der
Erhaltung der Leistungsf&#228;higkeit und Reaktionsf&#228;higkeit der Strafverfolgungs- und 
Sicherheitsbeh&#246;rden ausreichend ber&#252;cksichtigt. 
69. Dabei weist der Bundesrat darauf hin, dass die Anforderungen der
Strafverfolgungs- und Sicherheitsbeh&#246;rden beim Einsatz von KI in der Verordnung
angemessen ber&#252;cksichtigt werden m&#252;ssen. Die Einstufung zahlreicher
Anwendungen im Bereich der Strafverfolgung als &#8222;Hochrisiko-KI&#8220; (Anhang III des 
Verordnungsvorschlags) zieht als Konsequenz die Notwendigkeit einer
Konformit&#228;tsbewertung der Anwendungen nach sich. Dabei handelt es sich unter 
anderem um Software f&#252;r die biometrische Fernidentifizierung oder Systeme, 
die zur Aufdeckung von sogenannten Deepfakes oder zur Bewertung der
Verl&#228;sslichkeit von Beweismitteln im Zuge der Ermittlung oder Verfolgung von 
Straftaten dienen. Mit diesen sowohl internen wie auch externen Bewertungen 
sind erh&#246;hte Pr&#252;f-, Aufsichts-, Transparenz- und Rechenschaftspflichten
verbunden. Der Einsatz von KI zur Auswertung und Aufbereitung gro&#223;er
Datenmengen wird somit unn&#246;tig erschwert. Auch f&#252;r den Einsatz von KI-gest&#252;tzter 
Gesichtserkennungssoftware zur Fahndung nach Straft&#228;tern oder Gef&#228;hrdern 
mittels Video&#252;berwachung werden &#252;berm&#228;&#223;ig strenge Voraussetzungen
festgeschrieben. Aufgrund der Ausgestaltung der Normen und vorhandener
Definitionsunklarheiten besteht zumindest die Gefahr, dass zukunftsorientierte Projekte 
beziehungsweise Software der Strafverfolgungsbeh&#246;rden verhindert oder
wesentlich erschwert werden. Auch bereits genutzte Software (zum Beispiel Tools 
zur Erkennung und Kategorisierung von Kinderpornographie oder Software zur 
Auswertung komplexer IT-Asservate) k&#246;nnte unter die Definition von KI fallen. 
Die im aktuellen Verordnungsvorschlag enthaltenen Restriktionen k&#246;nnten
somit einen Zeitverzug bei notwendigen Ermittlungsma&#223;nahmen hervorrufen, der 
den Erfolg und die Effizienz der polizeilichen Ma&#223;nahmen gef&#228;hrden k&#246;nnte. 
Die Anforderungen an den Einsatz von KI durch Strafverfolgungs- und
Sicherheitsbeh&#246;rden sollten daher praxisgerechter ausgestaltet und besser auf die
besonderen Belange der Strafverfolgung und Gefahrenabwehr zugeschnitten
werden.
70. Gem&#228;&#223; Artikel 43 Absatz 1 Unterabsatz 3 Satz 2 des Verordnungsvorschlags 
&#252;bernimmt die in Artikel 63 Absatz 5 oder 6 des Verordnungsvorschlags
genannte Markt&#252;berwachungsbeh&#246;rde die Funktion der notifizierten Stelle, wenn 
das System von Strafverfolgungs-, Einwanderungs- oder Asylbeh&#246;rden oder
von Organen, Einrichtungen oder sonstigen Stellen der EU in Betrieb
genommen werden soll. In diese Regelung sollte auch die Justiz insgesamt
aufgenommen werden. Gr&#252;nde f&#252;r eine unterschiedliche Behandlung der Justiz insgesamt 
und der Strafverfolgungsbeh&#246;rden sind nicht ersichtlich.
71. Artikel 70 Absatz 2 des Verordnungsvorschlags enth&#228;lt besondere Vorgaben 
zum Schutz von Strafverfolgungs-, Einwanderungs- oder Asylbeh&#246;rden als
Anbieter von Hochrisiko-KI-Systemen. In diese Regelung sollte auch die Justiz 
insgesamt aufgenommen werden. Gr&#252;nde f&#252;r eine unterschiedliche Behandlung 
der Justiz insgesamt und der Strafverfolgungsbeh&#246;rden sind nicht ersichtlich.
72. In Artikel 71 des Verordnungsvorschlags ist geregelt, dass bei Verst&#246;&#223;en gegen 
die Verordnung Anbietende von KI-Systemen mit Bu&#223;geldern von bis zu 30 
Millionen Euro beziehungsweise im Falle von Unternehmen in H&#246;he von bis zu 
6 Prozent des Jahresumsatzes belegt werden k&#246;nnen. Beh&#246;rden und &#246;ffentliche 
Stellen inklusive der Justiz sollten aus dem Anwendungsbereich der Vorschrift 
ausgenommen werden. Es sollte in der Vorschrift zumindest ausdr&#252;cklich
klargestellt werden, dass von Beh&#246;rden und &#246;ffentlichen Stellen auch die Justiz
erfasst ist. 
Sonstiges
73. Der Bundesrat bittet die Bundesregierung, die m&#246;glichen Auswirkungen des 
Verordnungsvorschlags auf die Entwicklungschancen f&#252;r innovative KI-
L&#246;sungen in Europa zu pr&#252;fen. Mit Blick auf das weitere
Gesetzgebungsverfahren sollten dabei insbesondere die zugrundeliegende, sehr weitgehende
Definition von erfassten KI-Technologien, der Ma&#223;stab f&#252;r die Risikobewertung einer 
konkreten KI-Anwendung sowie das Zusammenwirken mit sektorspezifischen 
Regulierungen, unter anderem hinsichtlich m&#246;glicher Doppelregulierungen
sowie widerspr&#252;chlicher Vorgaben, ber&#252;cksichtigt werden.
74. Er bittet mithin die Bundesregierung, sich im weiteren Gesetzgebungsverfahren 
daf&#252;r einzusetzen, dass: 
&#8211; das zuk&#252;nftige KI-Gesetz f&#252;r Transparenz und Klarheit sorgt, welcher
Regulierungsstufe eine bestimmte Anwendung unterworfen ist und welche 
konkreten Anforderungen damit einhergehen, etwa hinsichtlich der
Anforderungen an die Qualit&#228;t der verwendeten Datens&#228;tze, so dass Unternehmen 
gr&#246;&#223;tm&#246;gliche Rechtssicherheit bei der Entwicklung und Nutzung dieser 
Anwendung erhalten, insbesondere auch durch die m&#246;glichst rasche
Etablierung von harmonisierten Normen, 
&#8211; weitere Vereinfachungen speziell f&#252;r KMU sowie Start-ups bei den
vorgesehenen regulatorischen Anforderungen vorgesehen werden und diese bei 
der Erf&#252;llung dieser Anforderungen m&#246;glichst fr&#252;hzeitig und in geeigneter 
Form unterst&#252;tzt werden, 
&#8211; der Rechtsrahmen so ausgestaltet wird, dass eine Fragmentierung des
Binnenmarktes, beispielsweise hinsichtlich der Ausgestaltung der
Markt&#252;berwachung, in der Praxis vermieden wird sowie
&#8211; Gesch&#228;ftsgeheimnisse im Rahmen der vorgesehenen Pr&#252;f- und
Offenlegungspflichten wirksam gewahrt bleiben.
75. Der Bundesrat weist darauf hin, dass ein zuverl&#228;ssiges Haftungsregime f&#252;r die 
Etablierung eines innovationsfreundlichen Rechtsrahmens von gro&#223;er
Bedeutung ist. Dies gilt auch vor dem Hintergrund der in Artikel 14 des
Verordnungsvorschlags aufgef&#252;hrten obligatorischen menschlichen Aufsicht f&#252;r Hochrisiko-
Systeme. Der Bundesrat bittet die Bundesregierung zu pr&#252;fen, welche
Anpassungen im Produkthaftungsrecht gegebenenfalls notwendig sind, um
insbesondere im Hinblick auf den europ&#228;ischen Binnenmarkt Rechtssicherheit
herzustellen. 
76. Er bittet die Bundesregierung au&#223;erdem um Kl&#228;rung, wie in den Bereichen des 
Anhangs III des Verordnungsvorschlags, f&#252;r die derzeit keine
Aufsichtsstrukturen bestehen, eine entsprechende Zust&#228;ndigkeit geschaffen werden soll. Da die 
Regulierung von KI-Systemen sehr spezialisiertes Fachwissen erfordert, m&#252;ssen 
die Mitgliedstaaten daf&#252;r sorgen, dass die zust&#228;ndigen nationalen Beh&#246;rden mit 
angemessenen finanziellen und personellen Ressourcen ausgestattet werden, 
damit sie ihre Aufgaben im Rahmen der Verordnung wahrnehmen k&#246;nnen. 
77. Der Bundesrat bittet ferner die Bundesregierung, sich bei den weiteren
Verhandlungen daf&#252;r einzusetzen, dass die Spielr&#228;ume der Mitgliedstaaten bei der 
Benennung der zust&#228;ndigen Beh&#246;rden gewahrt bleiben. Auch sollte daf&#252;r Sorge 
getragen werden, dass bei Verst&#246;&#223;en gegen die Verordnung, die die Rechte von 
B&#252;rgerinnen und B&#252;rgern in mehreren Mitgliedstaaten betreffen und die in
Anlehnung an die Begriffsbestimmung der Verordnung (EU) 2017/2394 &#252;ber die 
Zusammenarbeit zwischen den f&#252;r die Durchsetzung der
Verbraucherschutzgesetze zust&#228;ndigen nationalen Beh&#246;rden als &#8222;weitverbreitete Verst&#246;&#223;e&#8220;
angesehen werden k&#246;nnen, geeignete Mechanismen der Kooperation und
Koordinierung zur Verf&#252;gung stehen.
78. Der Bundesrat bittet zudem zu pr&#252;fen, ob eine Regelung zu zust&#228;ndigen
Beh&#246;rden im Falle der Betroffenheit mehrerer Mitgliedstaaten geschaffen werden 
kann.
79. Er sieht kritisch, dass der Verordnungsvorschlag keine Interventionsrechte
derjenigen Personen vorsieht, die durch den Einsatz von KI-Systemen betroffen 
sein k&#246;nnen. Der durch die DSGVO vermittelte Schutz bei automatisierten
Entscheidungsverfahren ist nicht ausreichend, da er bei vorgelagerten
Entscheidungen noch nicht greift und nur die Richtigkeit der verarbeiteten Daten, jedoch 
nicht die der aus ihnen und anderen Daten gezogenen Schlussfolgerungen 
sch&#252;tzt. Zudem fehlt eine Verzahnung mit den Pflichten zur menschlichen
Aufsicht und den Verpflichtungen der Anbietenden und Nutzenden zur
Beobachtung der KI-Systeme nach ihrer Inbetriebnahme.
80. Der Bundesrat begr&#252;&#223;t, dass der Verordnungsvorschlag die Anbietenden und 
Nutzenden zur Beobachtung der von KI-Systemen ausgehenden Risiken nach 
ihrer Inbetriebnahme verpflichtet. Allerdings l&#228;sst der Verordnungsvorschlag 
weitgehend offen, wer im Verh&#228;ltnis zwischen Hersteller, Anbieter und Nutzer 
beispielsweise f&#252;r das Risikomanagement oder die technische Dokumentation 
w&#228;hrend des Betriebs des KI-Systems verantwortlich sein soll. Mit R&#252;cksicht 
auf die Vielgestaltigkeit der KI-Systeme sollten aus Sicht des Bundesrates
zumindest vor Inverkehrbringen oder Inbetriebnahme in einem entsprechenden 
Dokument die Verantwortlichkeiten f&#252;r die Pflichten aus Titel III Kapitel 2 des 
Verordnungsvorschlags festgehalten sein.
81. Er begr&#252;&#223;t die &#220;berlegung der Kommission, freiwillige Verhaltenskodizes f&#252;r 
KI-Systeme, die kein hohes Risiko darstellen, durch die Kommission und die 
Mitgliedstaaten zu f&#246;rdern. Der Bundesrat bittet die Bundesregierung,
Aktivit&#228;ten zur F&#246;rderung entsprechender freiwilliger Verhaltenskodizes im Sinne einer 
marktwirtschaftlichen Anreizsetzung zu unterst&#252;tzen. Er erinnert daran, dass in
den L&#228;ndern bereits erste Anstrengungen unternommen wurden, die es mit den 
vorgeschlagenen Ma&#223;nahmen zu st&#228;rken und aktiv einzubeziehen gilt.
82. Der Bundesrat stellt fest, dass das Verh&#228;ltnis des Verordnungsvorschlages zu 
anderen europ&#228;ischen Rechtsakten, wie etwa zur Richtlinie &#252;ber irref&#252;hrende 
und vergleichende Werbung (2006/114/EG) und insbesondere zur Richtlinie 
&#252;ber audiovisuelle Mediendienste (2010/13/EU, AVMD-Richtlinie), nicht
gekl&#228;rt wird, obwohl in den Regelwerken sich &#252;berschneidende Vorschriften
enthalten sind. Dies betrifft beispielsweise die Regelungen hinsichtlich der
Verwendung von Techniken der unterschwelligen Beeinflussung. 
Der Bundesrat stellt au&#223;erdem fest, dass in dem Verordnungsvorschlag
abweichende Begriffsbestimmungen zur Verordnung (EU) 2019/1020 enthalten sind. 
Er bittet die Bundesregierung, darauf hinzuwirken, dass Begriffsbestimmungen 
der vorgenannten Verordnung gleich und eindeutig &#252;bernommen werden, damit 
die Markt&#252;berwachungsbeh&#246;rden der L&#228;nder in &#220;bereinstimmung mit der
Verordnung (EU) 2019/1020 und dem Markt&#252;berwachungsgesetz die
Markt&#252;berwachung vollziehen k&#246;nnen. 
Der Bundesrat bittet die Bundesregierung, darauf hinzuweisen, dass bereits
bestehende gesetzliche Regelungen &#8211; etwa in der DSGVO &#8211; bei der Regulierung 
von KI ber&#252;cksichtigt werden m&#252;ssen, um Doppelungen zu vermeiden und die 
Regelungen f&#252;r KI so schlank wie m&#246;glich zu halten. Der
Verordnungsvorschlag muss auf bereits bestehende Normierungen abgestimmt sein. 
83. Er weist dar&#252;ber hinaus auf die Subsidiarit&#228;t europ&#228;ischer Regelungen und die 
Kompetenzordnung hin. 
Direktzuleitung der Stellungnahme 
84. Der Bundesrat &#252;bermittelt diese Stellungnahme direkt an die Kommission.]</text>
    <titel>Vorschlag f&#252;r eine Verordnung des Europ&#228;ischen Parlaments und des Rates zur Festlegung harmonisierter Vorschriften f&#252;r k&#252;nstliche Intelligenz (Gesetz &#252;ber k&#252;nstliche Intelligenz) und zur &#196;nderung bestimmter Rechtsakte der Union</titel>
    <datum>2021-09-17</datum>
  </document>
  