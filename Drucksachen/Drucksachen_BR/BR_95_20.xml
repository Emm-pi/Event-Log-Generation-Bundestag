<document>
    <id>238919</id>
    <drucksachetyp>Unterrichtung</drucksachetyp>
    <dokumentart>Drucksache</dokumentart>
    <autoren_anzahl>0</autoren_anzahl>
    <typ>Dokument</typ>
    <vorgangsbezug_anzahl>1</vorgangsbezug_anzahl>
    <dokumentnummer>95/20</dokumentnummer>
    <wahlperiode>19</wahlperiode>
    <herausgeber>BR</herausgeber>
    <pdf_hash>e33bc4385ee6b25b8a53ab429a0a7cb4</pdf_hash>
    <aktualisiert>2022-07-26T19:57:15+02:00</aktualisiert>
    <vorgangsbezug>
      <id>259329</id>
      <titel>Wei&#223;buch 
Zur K&#252;nstlichen Intelligenz - ein europ&#228;isches Konzept f&#252;r Exzellenz und Vertrauen
KOM(2020) 65 endg.; Ratsdok. 6266/20
</titel>
      <vorgangstyp>EU-Vorlage</vorgangstyp>
    </vorgangsbezug>
    <urheber>
      <einbringer>false</einbringer>
      <bezeichnung>EU-Kommission</bezeichnung>
      <titel>Europ&#228;ische Kommission</titel>
    </urheber>
    <fundstelle>
      <pdf_url>https://dserver.bundestag.de/brd/2020/0095-20.pdf</pdf_url>
      <id>238919</id>
      <dokumentnummer>95/20</dokumentnummer>
      <datum>2020-02-20</datum>
      <dokumentart>Drucksache</dokumentart>
      <drucksachetyp>Unterrichtung</drucksachetyp>
      <herausgeber>BR</herausgeber>
      <urheber>Europ&#228;ische Kommission</urheber>
    </fundstelle>
    <text>[Vertrieb: Bundesanzeiger Verlag GmbH, Postfach 10 05 34, 50445 K&#246;ln 
Telefon (02 21) 97 66 83 40, Fax (02 21) 97 66 83 44, www.betrifft-gesetze.de 
ISSN 0720-2946
Bundesrat Drucksache 95/20
20.02.20 
EU - AIS - AV - G - In -  
K - R - U - Vk - Wi
Unterrichtung 
durch die Europ&#228;ische Kommission
Wei&#223;buch der Kommission zur k&#252;nstlichen Intelligenz: 
Ein europ&#228;isches Konzept f&#252;r Exzellenz und Vertrauen 
COM(2020) 65 final
Der Bundesrat wird &#252;ber die Vorlage gem&#228;&#223; &#167; 2 EUZBLG auch durch die Bundesregierung 
unterrichtet.
Hinweis: vgl. Drucksache 158/18 = AE-Nr. 180370, 
Drucksache 631/18 = AE-Nr. 181166, 
Drucksache 165/19 = AE-Nr. 190330 und 
Drucksache 655/19 = AE-Nr. 190960
DE DE
EUROP&#196;ISCHE
KOMMISSION
Br&#252;ssel, den 19.2.2020  
COM(2020) 65 final
WEISSBUCH
Zur K&#252;nstlichen Intelligenz &#8211; ein europ&#228;isches Konzept f&#252;r Exzellenz und Vertrauen
Wei&#223;buch zur K&#252;nstlichen Intelligenz &#8211; 
Ein europ&#228;isches Konzept f&#252;r Exzellenz und Vertrauen 
Die K&#252;nstliche Intelligenz entwickelt sich schnell. Sie wird unser Leben ver&#228;ndern, indem sie die 
Gesundheitsf&#252;rsorge verbessert (z. B. durch pr&#228;zisere Diagnostik und bessere Pr&#228;vention von 
Krankheiten), die Effizienz der Landwirtschaft erh&#246;ht, zum Klimaschutz und zur Anpassung an den 
Klimawandel beitr&#228;gt, die Effizienz von Produktionsanlagen durch vorausschauende Wartung steigert, 
die Sicherheit der Europ&#228;erinnen und Europ&#228;er erh&#246;ht und noch auf viele andere Arten und Weisen, 
die derzeit gar nicht v&#246;llig absehbar sind. Gleichzeitig birgt die K&#252;nstliche Intelligenz (KI) eine Reihe
potenzieller Gefahren z. B. wegen undurchsichtiger Entscheidungsprozesse oder wegen 
Diskriminierung aufgrund des Geschlechts oder anderer Faktoren, durch Eingriffe in unser Privatleben 
oder Missbrauch zu kriminellen Zwecken.
Vor dem Hintergrund des harten weltweiten Wettbewerbs brauchen wir ein solides europ&#228;isches 
Konzept, das auf der im April 2018 vorgelegten europ&#228;ischen KI-Strategie1 aufbaut. Um die mit KI 
einhergehenden Chancen und Herausforderungen anzunehmen, muss die EU geeint handeln und auf 
der Grundlage europ&#228;ischer Werte ihren eigenen Weg zur F&#246;rderung der Entwicklung und Nutzung 
von KI festlegen. 
Die Kommission ist entschlossen, wissenschaftliche Durchbr&#252;che zu erm&#246;glichen, die 
Technologief&#252;hrerschaft der EU zu wahren und sicherzustellen, dass neue Technologien im Dienst 
aller Europ&#228;erinnen und Europ&#228;er stehen &#8211; sie sollen Verbesserungen im Alltag bewirken, und 
gleichzeitig die Rechte der B&#252;rgerinnen und B&#252;rger achten. 
Kommissionspr&#228;sidentin Ursula von der Leyen k&#252;ndigte in ihren politischen Leitlinien 2  ein 
koordiniertes europ&#228;isches Konzept f&#252;r die menschlichen und ethischen Aspekte von KI sowie eine 
Reflexion &#252;ber die bessere Nutzung von Big Data f&#252;r Innovationen an. 
Damit unterst&#252;tzt die Kommission ein auf Regulierung und Finanzierung ausgerichtetes Konzept, das 
die Nutzung von KI f&#246;rdert und gleichzeitig auf die mit dieser Technologie einhergehenden Gefahren 
eingeht. Dieses Wei&#223;buch soll politische Optionen f&#252;r die Verwirklichung dieser Ziele darlegen. Die 
Entwicklung und Nutzung von KI f&#252;r milit&#228;rische Zwecke werden in diesem Wei&#223;buch nicht 
behandelt. Die Kommission l&#228;dt die Mitgliedstaaten, die anderen europ&#228;ischen Organe wie auch alle 
Interessentr&#228;ger, darunter die Industrie, Sozialpartner, Organisationen der Zivilgesellschaft, 
Forscherinnen und Forscher, die breite &#214;ffentlichkeit und alle interessierten Kreise, ein, zu den 
nachstehenden Optionen Stellung zu nehmen und zur k&#252;nftigen Entscheidungsfindung der 
Kommission in diesem Bereich beizutragen.
1. EINLEITUNG
Da digitale Technologien immer weiter in alle Bereiche des Alltags vordringen, sollten die Menschen 
ihnen auch vertrauen k&#246;nnen. Vertrauensw&#252;rdigkeit ist eine Voraussetzung f&#252;r ihre Akzeptanz. Dies 
ist eine Chance f&#252;r ein Europa, das Werten und Rechtsstaatlichkeit gro&#223;e Bedeutung beimisst und 
nachweislich in der Lage ist, sichere, zuverl&#228;ssige und Spitzenprodukte und -dienstleistungen 
anzubieten &#8211; von der Luftfahrt &#252;ber den Energiesektor bis hin zur Automobilindustrie und 
Medizintechnik.  
1 KI f&#252;r Europa, COM/2018/237 final. 
2 https://ec.europa.eu/commission/sites/beta-political/files/political-guidelines-next-commission_de.pdf.
Das nachhaltige Wirtschaftswachstum und das gesellschaftliche Wohlergehen in Europa st&#252;tzen sich 
schon jetzt und auch in Zukunft zunehmend auf die Wertsch&#246;pfung durch Daten. KI ist eine der 
wichtigsten Anwendungen der Datenwirtschaft. Heutzutage beziehen sich die meisten Daten auf 
Verbraucher und werden auf zentralen Cloud-basierten Infrastrukturen gespeichert und verarbeitet. In 
Zukunft hingegen wird ein gro&#223;er Teil der k&#252;nftig sehr viel umfangreicheren Datenmengen aus der 
Industrie, der Wirtschaft und dem &#246;ffentlichen Sektor kommen und in verschiedensten Systemen 
gespeichert werden, insbesondere auf Rechnern, die am Rande des Netzes arbeiten. Dies er&#246;ffnet neue 
Chancen f&#252;r Europa, dessen Position in den Bereichen digitalisierte Anwendungen f&#252;r die Industrie 
und B2B-Anwendungen stark, im Bereich Verbraucherplattformen hingegen relativ schwach ist.
Einfach ausgedr&#252;ckt ist KI ein Bestand an Technologien, die Daten, Algorithmen und Rechenleistung 
kombinieren. Fortschritte in der Informatik und die zunehmende Verf&#252;gbarkeit von Daten sind daher 
der Schl&#252;sselfaktor f&#252;r den derzeitigen Aufstieg der KI. Wie in der europ&#228;ischen Datenstrategie3
dargelegt, kann Europa seine technologischen und industriellen St&#228;rken mit einer hochwertigen 
digitalen Infrastruktur und einem Rechtsrahmen kombinieren, der auf seinen Grundwerten beruht, um 
sich im Bereich der Innovation in der Datenwirtschaft und ihren Anwendungen an die Weltspitze 
zu setzen. Auf dieser Grundlage kann Europa ein KI-&#214;kosystem entwickeln, das der gesamten 
europ&#228;ischen Gesellschaft und Wirtschaft die Vorteile der Technologie erschlie&#223;t: 
&#8226; B&#252;rgerinnen und B&#252;rger kommen in den Genuss neuer Vorteile wie z. B. bessere 
Gesundheitsversorgung, weniger Ausf&#228;lle von Haushaltsger&#228;ten, sicherere und sauberere 
Verkehrssysteme, bessere &#246;ffentliche Dienste; 
&#8226; Unternehmen k&#246;nnen z. B. eine neue Generation von Produkten und Dienstleistungen 
entwickeln in Bereichen, in denen Europa besonders stark ist (Maschinenbau, Verkehr, 
Cybersicherheit, Landwirtschaft, gr&#252;ne Wirtschaft und Kreislaufwirtschaft, Gesundheitswesen 
und Sektoren mit hoher Wertsch&#246;pfung wie Mode und Tourismus); und 
&#8226; Dienste von &#246;ffentlichem Interesse profitieren z. B. durch niedrigere Kosten f&#252;r die 
Erbringung von Dienstleistungen (Verkehr, Bildung, Energie und Abfallentsorgung), durch 
eine Verbesserung der Nachhaltigkeit von Produkten 4  und durch die Ausstattung von 
Strafverfolgungsbeh&#246;rden mit geeigneten Instrumenten zum Schutz der B&#252;rgerinnen und 
B&#252;rger5, mit angemessenen Garantien f&#252;r die Achtung ihrer Rechte und Freiheiten. 
Angesichts der erheblichen Auswirkungen, die KI auf unsere Gesellschaft und die notwendige 
Vertrauensbildung haben kann, ist es von entscheidender Bedeutung, dass die europ&#228;ische KI auf 
unseren Werten und Grundrechten wie Menschenw&#252;rde und Schutz der Privatsph&#228;re fu&#223;t. 
Zudem sollten die Auswirkungen von KI-Systemen nicht nur aus dem Blickwinkel des Einzelnen 
betrachtet werden, sondern auch aus der Perspektive der gesamten Gesellschaft. KI-Systeme k&#246;nnen 
bei der Verwirklichung der nachhaltigen Entwicklungsziele und der F&#246;rderung des demokratischen 
Prozesses und sozialer Rechte eine bedeutende Rolle spielen. Mit den unl&#228;ngst vorgelegten
3 COM(2020) 66 final. 
4 KI und die Digitalisierung allgemein sind ma&#223;gebliche Voraussetzungen f&#252;r die Verwirklichung der Ziele des 
europ&#228;ischen Gr&#252;nen Deals. Der derzeitige &#246;kologische Fu&#223;abdruck des IKT-Sektors entspricht Sch&#228;tzungen zufolge jedoch 
mehr als 2 % aller Emissionen weltweit. In der zusammen mit diesem Wei&#223;buch vorgelegten europ&#228;ischen Digitalstrategie 
werden Ma&#223;nahmen f&#252;r einen umweltvertr&#228;glichen Wandel im digitalen Bereich vorgeschlagen. 
5 Mithilfe von KI-Tools k&#246;nnen EU-B&#252;rger u. U. besser vor Verbrechen und terroristischen Anschl&#228;gen gesch&#252;tzt werden. 
Mit solchen Tools k&#246;nnten beispielsweise terroristische Propaganda im Internet erkannt, verd&#228;chtige Transaktionen beim 
Absatz gef&#228;hrlicher Produkte aufgedeckt, gef&#228;hrliche Gegenst&#228;nde oder illegale Stoffe und Produkte identifiziert, Menschen 
in Notsituationen Hilfe geleistet und Ersthelfer angeleitet werden.
Vorschl&#228;gen f&#252;r den Europ&#228;ischen Gr&#252;nen Deal6 nimmt die EU bei der Bew&#228;ltigung von Klima- und 
Umweltherausforderungen eine Vorreiterrolle ein. Digitale Technologien wie KI tragen entscheidend 
dazu bei, die Ziele des Gr&#252;nen Deals zu erreichen. Angesichts der zunehmenden Bedeutung der KI 
muss den Umweltauswirkungen von KI-Systemen von Anfang bis Ende ihres Lebenszyklus und 
entlang der gesamten Lieferkette geb&#252;hrend Rechnung getragen werden, beispielsweise hinsichtlich 
des Ressourcenverbrauchs beim Trainieren von Algorithmen und der Speicherung von Daten.
Nur mit einem gemeinsamen europ&#228;ischen KI-Konzept k&#246;nnen eine ausreichende Gr&#246;&#223;enordnung 
erreicht und eine Fragmentierung des Binnenmarkts vermieden werden. Werden hier einzelne 
Initiativen auf nationaler Ebene ergriffen, k&#246;nnte dies die Rechtssicherheit gef&#228;hrden, das Vertrauen 
der B&#252;rger untergraben und das Entstehen einer dynamischen europ&#228;ischen Industrie verhindern. 
In diesem Wei&#223;buch werden politische Optionen vorgestellt mit dem Ziel, eine rasche und sichere 
Entwicklung der KI in Europa unter uneingeschr&#228;nkter Achtung der Werte und Rechte der 
europ&#228;ischen B&#252;rgerinnen und B&#252;rger zu erm&#246;glichen. Die wichtigsten Bausteine dieses Wei&#223;buchs 
sind:
&#8226; Der politische Rahmen mit Ma&#223;nahmen zur Abstimmung der Anstrengungen auf europ&#228;ischer, 
nationaler und regionaler Ebene. Der Rahmen zielt darauf ab, in Partnerschaft zwischen 
&#246;ffentlichem und Privatsektor Ressourcen zu mobilisieren, um ein &#8222;&#214;kosystem f&#252;r 
Exzellenz&#8220; aufzubauen, das bei Forschung und Innovation beginnt und sich &#252;ber die gesamte 
Wertsch&#246;pfungskette erstreckt, und die richtigen Anreize zu schaffen, um die Akzeptanz von 
KI-L&#246;sungen auch seitens kleiner und mittlerer Unternehmen (KMU) zu beschleunigen. 
&#8226; Die Schl&#252;sselelemente eines k&#252;nftigen Rechtsrahmens f&#252;r KI in Europa werden ein 
einzigartiges &#8222;&#214;kosystem f&#252;r Vertrauen&#8220; schaffen. Um dieses Ziel zu erreichen, muss durch 
den Rahmen sichergestellt werden, dass die EU-Vorschriften eingehalten werden, 
einschlie&#223;lich der Vorschriften zum Schutz der Grundrechte und der Verbraucherrechte, 
insbesondere im Falle von in der EU eingesetzten KI-Systemen mit hohen Risikopotenzial7. 
Ein &#214;kosystem f&#252;r Vertrauen aufzubauen, ist schon an sich ein strategisches Ziel und sollte 
bei den B&#252;rgerinnen und B&#252;rgern das n&#246;tige Vertrauen schaffen, KI-Anwendungen zu nutzen, 
und Unternehmen und &#246;ffentlichen Stellen die Rechtssicherheit f&#252;r KI-gest&#252;tzte Innovationen. 
Die Kommission bef&#252;rwortet nachdr&#252;cklich ein Konzept, bei dem der Mensch im Mittelpunkt 
steht, das auf der Mitteilung &#252;ber die Schaffung von Vertrauen in eine auf den Menschen 
ausgerichtete KI8 beruht und auch die w&#228;hrend der Pilotphase eingegangenen R&#252;ckmeldungen 
zu den Ethik-Leitlinien der Hochrangigen Expertengruppe f&#252;r K&#252;nstliche Intelligenz 
ber&#252;cksichtigt. 
Die europ&#228;ische Datenstrategie, die zusammen mit diesem Wei&#223;buch vorgelegt wird, soll Europa in 
die Lage versetzen, zur attraktivsten, sichersten und dynamischsten datenagilen Wirtschaft der Welt zu 
werden, indem Europa durch Daten bef&#228;higt wird, bessere Entscheidungen zu treffen und das Leben 
aller seiner B&#252;rgerinnen und B&#252;rger zu ver&#228;ndern. Die Strategie sieht eine Reihe politischer 
Ma&#223;nahmen vor, darunter die Mobilisierung privater und &#246;ffentlicher Investitionen, die zur 
Erreichung dieses Ziels erforderlich sind. Die Auswirkungen von KI, Internet der Dinge und anderen 
digitalen Technologien auf die Sicherheits- und Haftungsvorschriften werden in dem Bericht der 
Kommission analysiert, der ebenfalls zusammen mit diesem Wei&#223;buch vorgelegt wird.
6 COM(2019)640 final. 
7 Unter Umst&#228;nden m&#252;ssen weitere Vorkehrungen getroffen werden, um den Missbrauch von KI zu kriminellen Zwecken zu 
verhindern und zu bek&#228;mpfen, aber dies ist nicht Gegenstand dieses Wei&#223;buchs. 
8 COM(2019)168.
2. DIE ST&#196;RKEN IN INDUSTRIELLEN UND GEWERBLICHEN ABSATZM&#196;RKTEN NUTZEN
Europa verf&#252;gt &#252;ber die Voraussetzungen zum Aussch&#246;pfen des KI-Potenzials, und zwar nicht nur als 
Nutzer, sondern auch als Urheber und Hersteller dieser Technologie. Denn es gibt in Europa 
herausragende Forschungszentren und innovative Start-Ups, es ist weltweit f&#252;hrend in Robotik und hat 
wettbewerbsf&#228;hige Fertigungs- und Dienstleistungssektoren &#8211; von der Automobilindustrie bis zum 
Gesundheitswesen, von der Energieversorgung &#252;ber Finanzdienstleistungen bis hin zur Landwirtschaft. 
Europa hat auch eine starke Recheninfrastruktur entwickelt (z. B. Hochleistungscomputer), die eine 
Voraussetzung f&#252;r den Einsatz von KI ist. Ferner verf&#252;gt Europa &#252;ber gro&#223;e Mengen &#246;ffentlicher und 
industrieller Daten, deren Potenzial nicht ausgesch&#246;pft wird. Anerkannt sind auch seine industriellen 
St&#228;rken im Bereich sichere digitale Systeme mit geringem Stromverbrauch, die f&#252;r die 
Weiterentwicklung der KI von ma&#223;geblicher Bedeutung sind. 
 Wenn die Kapazit&#228;ten der EU f&#252;r Investitionen in Technologien und Infrastrukturen der n&#228;chsten 
Generation sowie in digitale Kompetenzen z. B. im Bereich Daten genutzt werden, st&#228;rkt dies die 
technologische Unabh&#228;ngigkeit Europas bei den Schl&#252;sseltechnologien und -infrastrukturen f&#252;r die 
Datenwirtschaft. Die Infrastrukturen sollten die Schaffung europ&#228;ischer Datenpools unterst&#252;tzen, die 
eine vertrauensw&#252;rdige KI erm&#246;glichen, d. h. eine KI auf der Grundlage europ&#228;ischer Werte und 
Regeln. 
Europa sollte seine St&#228;rken nutzen, um seine Position in den &#214;kosystemen und entlang der 
Wertsch&#246;pfungskette auszubauen &#8211; von der Hardwareherstellung &#252;ber Software bis hin zu 
Dienstleistungen. Bis zu einem gewissen Grad geschieht dies bereits. Europa produziert mehr als ein 
Viertel aller Industrie- und professionellen Serviceroboter (z. B. f&#252;r Pr&#228;zisionslandwirtschaft, 
Sicherheit, Gesundheitswesen und Logistik) und spielt eine wichtige Rolle bei der Entwicklung und 
Nutzung von Softwareanwendungen f&#252;r Unternehmen und Organisationen (B2B-Anwendungen wie 
Software f&#252;r Ressourcenplanung, Design- und Maschinenbau-Software) und von Anwendungen f&#252;r 
elektronische Beh&#246;rdendienste und das &#8222;intelligente Unternehmen&#8220;. 
Europa ist Spitzenreiter beim Einsatz von KI in der verarbeitenden Industrie. Mehr als die H&#228;lfte der 
f&#252;hrenden Hersteller setzt in der Produktion an mindestens einer Station eine KI-Anwendung ein9. 
Ein Grund f&#252;r die starke Stellung Europas in der Forschung ist das EU-F&#246;rderprogramm, das 
entscheidend dazu beigetragen hat, die Anstrengungen zu b&#252;ndeln, Doppelarbeit zu vermeiden und 
&#246;ffentliche und private Investitionen in den Mitgliedstaaten zu mobilisieren. In den letzten drei Jahren 
wurden die europ&#228;ischen FuI-Mittel f&#252;r KI auf 1,5 Mrd. EUR und damit im Vergleich zum vorherigen 
Zeitraum um 70 % aufgestockt. 
Allerdings wird in Europa nur ein Bruchteil dessen in Forschung und Innovation investiert, was in 
anderen Regionen der Welt an &#246;ffentlichen und privaten Investitionen flie&#223;t. 2016 wurden in Europa 
ca. 3,2 Mrd. EUR in KI investiert &#8211; gegen&#252;ber rund 12,1 Mrd. EUR in Nordamerika und 
6,5 Mrd. EUR in Asien10. Deshalb muss Europa erheblich mehr investieren. Der &#8222;Koordinierte Plan 
f&#252;r K&#252;nstliche Intelligenz&#8220;11&#8218; der gemeinsam mit den Mitgliedstaaten erstellt wurde, erweist sich als 
gute Grundlage f&#252;r den Aufbau einer engeren Zusammenarbeit im KI-Bereich in Europa und f&#252;r die 
Schaffung von Synergien zur Maximierung der Investitionen in die KI-Wertsch&#246;pfungskette.
9 Gefolgt von Japan (30 %) und den USA (28 %). Quelle: CapGemini (2019). 
10 &#8222;10 imperatives for Europe in the age of AI and automation&#8220; (Zehn zwingende Erfordernisse f&#252;r Europa im Zeitalter von 
KI und Automatisierung), McKinsey, 2017. 
11 COM(2018)795.
3. NEUE CHANCEN NUTZEN: DIE N&#196;CHSTE DATENWELLE
Europas ist zwar derzeit in den Bereichen Verbraucheranwendungen und Online-Plattformen nicht so 
stark aufgestellt&#8218; was zu einem Wettbewerbsnachteil hinsichtlich des Zugangs zu Daten f&#252;hrt, aber es 
stehen bedeutende Ver&#228;nderungen an hinsichtlich des Werts und der sektor&#252;bergreifenden 
Weiterverwendung von Daten. Die Menge der weltweit produzierten Daten nimmt rasch zu, von 
33 Zettabyte im Jahr 2018 auf voraussichtlich 175 Zettabyte im Jahr 202512. Jede neue Datenwelle 
bringt Europa M&#246;glichkeiten, sich in der datenagilen Wirtschaft zu positionieren und an die Weltspitze 
zu setzen. Abgesehen davon wird sich die Art und Weise, wie Daten gespeichert und verarbeitet 
werden, in den kommenden f&#252;nf Jahren drastisch ver&#228;ndern. Gegenw&#228;rtig erfolgt die Verarbeitung 
und Analyse von Daten in der Cloud zu 80 % in Rechenzentren und zentralen Rechenanlagen und zu 
20 % in intelligenten vernetzten Objekten wie Autos, Haushaltsger&#228;ten oder Fertigungsrobotern und in 
Rechnern nahe beim Nutzer (&#8222;Edge-Computing&#8220;, d. h. dezentrale Datenverarbeitung am Rand des 
Netzes). Bis zum Jahr 2025 d&#252;rften sich diese Anteile deutlich verschieben13. 
Europa ist weltweit f&#252;hrend in der Elektronik mit geringem Stromverbrauch, die f&#252;r die n&#228;chste 
Generation spezialisierter KI-Prozessoren von zentraler Bedeutung ist. Auf diesem Markt dominieren 
derzeit Teilnehmer aus Drittl&#228;ndern. &#196;ndern k&#246;nnte sich dies durch Initiativen wie die Europ&#228;ische 
Prozessorinitiative, die auf die Entwicklung von Rechensystemen mit geringem Stromverbrauch f&#252;r 
Edge-Computing und Hochleistungsrechner der n&#228;chsten Generation abzielt, und die Arbeit des 
gemeinsamen Unternehmens f&#252;r digitale Schl&#252;sseltechnologien, das 2021 an den Start gehen soll. 
Dar&#252;ber hinaus ist Europa f&#252;hrend in neuromorphen L&#246;sungen 14 , die sich hervorragend f&#252;r die 
Automatisierung von industriellen Prozessen (Industrie 4.0) und Verkehrstr&#228;gern eignen. Sie k&#246;nnen 
die Energieeffizienz um ein Mehrfaches steigern. 
Die j&#252;ngsten Fortschritte in der Quanteninformatik werden zu exponentiellen Steigerungen der 
Verarbeitungskapazit&#228;t f&#252;hren15. Europa kann hier dank seiner akademischen St&#228;rken im Bereich 
Quanteninformatik und der starken Position der europ&#228;ischen Industrie im Bereich 
Quantensimulatoren und Programmierumgebungen f&#252;r Quantencomputer eine Vorreiterrolle 
einnehmen. Europ&#228;ische Initiativen, die die Zahl der Quantentest- und Quantenversuchseinrichtungen 
erh&#246;hen sollen, werden dazu beitragen, dass diese neuen Quantenl&#246;sungen in einer ganzen Reihe von 
industriellen und akademischen Sektoren angewendet werden. 
Parallel dazu wird Europa auf der Grundlage seiner eigenen wissenschaftlichen Exzellenz weiterhin 
eine Vorreiterrolle bei den algorithmischen Grundlagen der KI einnehmen. Zwischen Fachdisziplinen, 
die gegenw&#228;rtig separat voneinander arbeiten, wie maschinelles Lernen und &#8222;Deep Learning&#8220; (dessen 
Merkmale begrenzte Interpretierbarkeit, Bedarf an gro&#223;en Datenmengen f&#252;r das Trainieren von 
Modellen und Lernen durch Korrelationen sind) und symbolischen Ans&#228;tzen (bei denen Regeln durch 
menschliche Eingriffe geschaffen werden) m&#252;ssen Br&#252;cken geschlagen werden. Die Kombination von 
symbolischem Schlussfolgern und tiefen neuronalen Netzen kann u. U. helfen, die Erkl&#228;rbarkeit von 
KI-Ergebnissen zu verbessern. 
12 IDC, 2019. 
13 Gartner, 2017. 
14 Neuromorphe L&#246;sungen sind sehr gro&#223;e Systeme integrierter Schaltungen, die neurobiologische Architekturen des 
Nervensystems nachahmen.
15 Quantencomputer werden in Bruchteilen von Sekunden sehr viel umfangreichere Datens&#228;tze verarbeiten k&#246;nnen als 
heutige H&#246;chstleistungsrechner, was die Entwicklung neuer KI-Anwendungen f&#252;r alle Sektoren erm&#246;glicht.
4. EIN &#214;KOSYSTEM F&#220;R EXZELLENZ
Um ein Exzellenz&#246;kosystem aufzubauen, das die Entwicklung und Nutzung von KI in der gesamten 
Wirtschaft und &#246;ffentlichen Verwaltung der EU unterst&#252;tzen kann, m&#252;ssen auf mehreren Ebenen 
verst&#228;rkte Ma&#223;nahmen ergriffen werden.
A. ZUSAMMENARBEIT MIT DEN MITGLIEDSTAATEN
Im Rahmen ihrer KI-Strategie16, die im April 2018 angenommen wurde, hat die Kommission im 
Dezember 2018 einen gemeinsam mit den Mitgliedstaaten erstellten Plan vorgelegt, um die 
Entwicklung und Nutzung von KI in Europa zu f&#246;rdern17.  
In diesem Plan werden etwa 70 gemeinsame Ma&#223;nahmen f&#252;r eine engere und effizientere 
Zusammenarbeit zwischen den Mitgliedstaaten und der Kommission in Schl&#252;sselbereichen wie 
Forschung, Investitionen, Markteinf&#252;hrung, Kompetenzen und Begabungen, Daten und internationale 
Zusammenarbeit vorgeschlagen. Der Plan soll bis 2027 laufen, seine Durchf&#252;hrung wird regelm&#228;&#223;ig 
&#252;berwacht, und er wird periodisch &#252;berarbeitet. 
Ziel ist es, die Wirkung von Investitionen in Forschung, Innovation und Einf&#252;hrung zu maximieren, 
nationale KI-Strategien zu bewerten und mit den Mitgliedstaaten auf dem koordinierten Plan f&#252;r KI 
aufzubauen und ihn auszuweiten:
&#8226; Ma&#223;nahme 1: Die Kommission wird den Mitgliedstaaten unter Ber&#252;cksichtigung der 
Ergebnisse der &#246;ffentlichen Konsultation zum Wei&#223;buch eine Neufassung des koordinierten 
Plans unterbreiten, die bis Ende 2020 angenommen werden sollte 
EU-Mittel f&#252;r KI sollen Investitionen in Bereichen mobilisieren und b&#252;ndeln, in denen Mitgliedstaaten 
im Alleingang nicht genug erreichen k&#246;nnen. Das Ziel ist, in der EU in den n&#228;chsten zehn Jahren 
insgesamt mehr als 20 Mrd. EUR18 an KI-Investitionen pro Jahr zu mobilisieren. Um private und 
&#246;ffentliche Investitionen anzuziehen, wird die EU Mittel aus dem Programm &#8222;Digitales Europa&#8220; und 
Horizont Europa bereitstellen sowie aus den Europ&#228;ischen Struktur- und Investitionsfonds, um den 
Erfordernissen sowohl weniger entwickelter Regionen als auch l&#228;ndlicher Gebiete gerecht zu werden. 
Der Koordinierte Plan k&#246;nnte auch das gesellschaftliche und &#246;kologische Wohlergehen als einen 
wichtigen Grundsatz f&#252;r KI herausstellen. KI-Systeme haben das Potenzial, zur Bew&#228;ltigung der 
dr&#228;ngendsten Probleme wie Klimawandel und Umweltzerst&#246;rung beizutragen. Dies muss unbedingt in 
umweltvertr&#228;glicher Weise geschehen. KI kann und sollte selbst kritisch pr&#252;fen, wie Ressourcen 
verwendet werden und wie hoch der Energieverbrauch ist, und so trainiert werden, dass 
Entscheidungen bevorzugt werden, die gut f&#252;r die Umwelt sind. Die Kommission wird gemeinsam mit 
dem Mitgliedstaaten Optionen pr&#252;fen, die entsprechende KI-L&#246;sungen f&#246;rdern und Anreize daf&#252;r 
bieten.
B. DIE ARBEIT DER FORSCHUNGS- UND INNOVATIONSGEMEINSCHAFT FOKUSSIEREN
Europa kann es sich nicht leisten, an der aktuell fragmentierten Landschaft von Kompetenzzentren 
festzuhalten, in der keines der Zentren die Gr&#246;&#223;enordnung erreicht, mit der es dem Wettbewerb mit 
den weltweit f&#252;hrenden Instituten gewachsen w&#228;re. Es m&#252;ssen unbedingt mehr Synergien zwischen
16 K&#252;nstliche Intelligenz f&#252;r Europa, COM(2018)237. 
17 Koordinierter Plan f&#252;r k&#252;nstliche Intelligenz, COM(2018)795. 
18 COM(2018)237.
den zahlreichen europ&#228;ischen KI-Forschungszentren geschaffen und Netzwerke unter ihnen aufgebaut 
werden; au&#223;erdem m&#252;ssen ihre Bem&#252;hungen um gr&#246;&#223;ere Exzellenz und darum, die besten Forscher 
anzuwerben und zu halten und die besten Technologien zu entwickeln, koordiniert werden. Europa 
braucht ein Leitzentrum f&#252;r Forschung, Innovation und Expertise, das diese Bem&#252;hungen koordiniert 
und eine weltweite Bezugsgr&#246;&#223;e f&#252;r Exzellenz im KI-Bereich wird, Investitionen mobilisieren kann 
und f&#252;r die schlauesten K&#246;pfe in diesem Bereich attraktiv ist.
Die Zentren und Netzwerke sollten sich auf Sektoren konzentrieren, in denen Europa das Zeug zum 
globalen Spitzenreiter hat, wie z. B. Industrie, Gesundheitswesen, Verkehr, Finanzwesen, Agrar- und 
Lebensmittelwertsch&#246;pfungsketten, Energie/Umwelt, Forstwirtschaft, Erdbeobachtung und Raumfahrt. 
In all diesen Bereichen ist der Wettlauf um die F&#252;hrungsposition in der Welt in vollem Gange, und 
Europa verf&#252;gt &#252;ber betr&#228;chtliches Potenzial, Know-how und Fachwissen19. Ebenso wichtig ist die 
Einrichtung von Test- und Versuchsanlagen, um die Entwicklung und anschlie&#223;ende Einf&#252;hrung neuer 
KI-Anwendungen zu unterst&#252;tzen.
&#8226; Ma&#223;nahme 2: Die Kommission wird die Einrichtung von Exzellenz- und Testzentren 
erleichtern, die europ&#228;ische, nationale und private Investitionen b&#252;ndeln k&#246;nnen, 
m&#246;glicherweise einschlie&#223;lich der Schaffung eines neuen Rechtsinstruments. Die Kommission 
hat vorgeschlagen, im Rahmen des Mehrj&#228;hrigen Finanzrahmens 2021-2027 einen nicht 
unerheblichen Betrag aus dem Programm &#8222;Digitales Europa&#8220;, ggf. erg&#228;nzt durch FuI-Mittel 
aus Horizont Europa, eigens f&#252;r die F&#246;rderung europ&#228;ischer Testzentren von Weltrang 
vorzusehen.
C. KOMPETENZEN
Das europ&#228;ische KI-Konzept muss dadurch untermauert werden, dass besonderes Gewicht auf 
Kompetenzen gelegt wird, um dem Fachkr&#228;ftemangel abzuhelfen.20 Die Kommission wird in K&#252;rze 
eine aktualisierte Agenda f&#252;r neue Kompetenzen vorlegen, mit der sichergestellt werden soll, dass alle 
Menschen in Europa vom &#220;bergang zu einer gr&#252;nen Wirtschaft und von der Digitalisierung der 
Wirtschaft in der EU profitieren k&#246;nnen. Eine m&#246;gliche Initiative w&#228;re auch, sektorale 
Regulierungsbeh&#246;rden bei der Erweiterung ihrer KI-Kompetenzen zu unterst&#252;tzen, damit sie 
einschl&#228;gige Vorschriften wirksam und effizient umsetzen k&#246;nnen. Der &#252;berarbeitete Aktionsplan f&#252;r 
digitale Bildung wird dazu beitragen, daten- und KI-gest&#252;tzte Technologien wie Lernanalytik und 
pr&#228;diktive Analytik besser zu nutzen, um die allgemeine und berufliche Bildung zu verbessern und f&#252;r 
das digitale Zeitalter tauglich zu machen. Mithilfe des Plans wird auch auf allen Ebenen des 
Bildungssystems st&#228;rker f&#252;r KI sensibilisiert, damit B&#252;rgerinnen und B&#252;rger dann fundierte 
Entscheidungen treffen k&#246;nnen, bei denen KI eine immer gr&#246;&#223;ere Rolle spielen wird.  
 Die Vermittlung der Kompetenzen, die f&#252;r die Arbeit im KI-Bereich notwendig sind, und die 
Weiterqualifizierung der Arbeitskr&#228;fte, um sie f&#252;r den durch die Entwicklungen im Bereich der KI 
angesto&#223;enen Wandel zu r&#252;sten, werden eine Priorit&#228;t des zusammen mit den Mitgliedstaaten 
&#252;berarbeiteten Koordinierten KI-Plans sein. Dies k&#246;nnte die Umwandlung der Bewertungsliste der 
Ethik-Leitlinien in einen indikativen &#8222;Lehrplan&#8220; f&#252;r KI-Entwickler umfassen, der dann 
Ausbildungseinrichtungen zur Verf&#252;gung gestellt wird. Besonderes Augenmerk sollte darauf gelegt 
werden, mehr Frauen in diesem Bereich auszubilden und zu besch&#228;ftigen.
19 Der geplante Europ&#228;ische Verteidigungsfonds und die St&#228;ndige Strukturierte Zusammenarbeit (SSZ) werden ebenfalls 
M&#246;glichkeiten f&#252;r Forschung und Entwicklung im Bereich der KI bieten. Entsprechende Projekte sollten aber mit den zivilen 
KI-Programmen der EU abgestimmt werden. 
20 https://ec.europa.eu/jrc/en/publication/academic-offer-and-demand-advanced-profiles-eu
Abgesehen davon w&#228;re ein Leitzentrum f&#252;r KI-Forschung und Innovation in Europa aufgrund seiner 
M&#246;glichkeiten f&#252;r Talente aus der ganzen Welt attraktiv. Ein solches Zentrum w&#252;rde auch Exzellenz 
in Kompetenzen entwickeln und verbreiten, die dann in ganz Europa Wurzeln schlagen und wachsen 
k&#246;nnen.
&#8226; Ma&#223;nahme 3: Aufbau und Unterst&#252;tzung von Netzen f&#252;hrender Universit&#228;ten und 
Hochschuleinrichtungen im Rahmen des Programms &#8222;Digitales Europa&#8220;), um die besten 
Lehrkr&#228;fte und Wissenschaftler anwerben und weltweit f&#252;hrende KI-Masterstudieng&#228;nge 
anbieten zu k&#246;nnen 
Neben dem Aspekt der Weiterqualifizierung haben die Entwicklung und der Einsatz von KI-Systemen 
auch unmittelbare Folgen f&#252;r Arbeitnehmer und Arbeitgeber. Die Einbeziehung der Sozialpartner wird 
entscheidend zu einem menschenzentrierten KI-Konzept f&#252;r den Arbeitsplatz beitragen. 
D. SCHWERPUNKT AUF KMU
Es muss sichergestellt werden, dass auch KMU Zugang zu KI haben und diese nutzen k&#246;nnen. Die 
digitalen Innovationszentren21 und die Plattform f&#252;r KI auf Anforderung22 sollten zu diesem Zweck 
weiter gest&#228;rkt werden und die Zusammenarbeit von KMU f&#246;rdern. Das Programm &#8222;Digitales 
Europa&#8220; wird hierbei von entscheidender Bedeutung sein. Zwar sollten alle digitalen 
Innovationszentren KMU dabei unterst&#252;tzen, sich mit KI vertraut zu machen und KI zu nutzen, aber es 
ist wichtig, dass in jedem Mitgliedstaat mindestens ein Innovationszentrum auf KI hochspezialisiert ist.  
KMU und Start-ups m&#252;ssen Zugang zu Finanzmitteln haben, um ihre Verfahren anpassen oder mit KI 
innovativ arbeiten zu k&#246;nnen. Aufbauend auf dem geplanten, mit 100 Mio. EUR ausgestatteten 
Pilotinvestitionsfonds f&#252;r KI und Blockchain will die Kommission den Zugang zu Finanzmitteln f&#252;r 
KI im Rahmen des Programms &#8222;InvestEU&#8220; noch weiter ausbauen23. In der Liste der Bereiche, die f&#252;r 
eine Inanspruchnahme der InvestEU-Garantie infrage kommen, ist KI ausdr&#252;cklich genannt. 
&#8226; Ma&#223;nahme 4: Die Kommission wird mit den Mitgliedstaaten zusammenarbeiten, damit 
mindestens ein digitales Innovationszentrum pro Mitgliedstaat auf KI hochspezialisiert ist. 
Digitale Innovationszentren k&#246;nnen im Rahmen des Programms &#8222;Digitales 
Europa&#8220; unterst&#252;tzt werden. 
&#8226; Die Kommission und der Europ&#228;ische Investitionsfonds werden im ersten Quartal 2020 ein 
Pilotprogramm mit einem Etat von 100 Mio. EUR starten&#8218; um Beteiligungskapital f&#252;r 
innovative KI-Entwicklungen bereitzustellen. Vorbehaltlich der endg&#252;ltigen Einigung &#252;ber 
den MFR beabsichtigt die Kommission ab 2021 eine erhebliche Aufstockung &#252;ber InvestEU.
21 ec.europe.eu/digital-single-market/en/news/digital-innovation-hubs-helping-companies-across-economy-make-
mostdigital-opportunities. 
22 www.Ai4eu.eu. 
23 Europe.eu/investeu.
E. PARTNERSCHAFT MIT DEM PRIVATEN SEKTOR
Der Privatsektor muss unbedingt in vollem Umfang an der Ausarbeitung der Forschungs- und 
Innovationsagenda beteiligt werden und die erforderliche Kofinanzierung bereitstellen. Hierzu m&#252;ssen 
sowohl eine breit angelegte &#246;ffentlich-private Partnerschaft aufgebaut als auch die F&#252;hrungsspitzen 
von Unternehmen mit ins Boot geholt werden. 
&#8226; Ma&#223;nahme 5: Im Kontext von Horizont Europa wird die Kommission eine neue
&#246;ffentlichprivate Partnerschaft f&#252;r KI, Daten und Robotik gr&#252;nden, um die Anstrengungen zu b&#252;ndeln, 
die Koordinierung von KI-Forschung und Innovation zu gew&#228;hrleisten, mit anderen 
&#246;ffentlich-privaten Partnerschaften im Rahmen von Horizont Europa zu kooperieren und mit 
den vorgenannten Testeinrichtungen und digitalen Innovationszentren zusammenzuarbeiten. 
F. DIE NUTZUNG VON KI IM &#214;FFENTLICHEN SEKTOR F&#214;RDERN
Es ist &#228;u&#223;erst wichtig, dass &#246;ffentliche Verwaltungen, Krankenh&#228;user, Versorgungsbetriebe und 
Verkehrsdienste, Finanzaufsichtsbeh&#246;rden und andere Bereiche von &#246;ffentlichem Interesse rasch mit 
der Einf&#252;hrung KI-gest&#252;tzter Produkte und Dienstleistungen beginnen. Ein besonderer Schwerpunkt 
wird auf den Bereichen Gesundheitsf&#252;rsorge und Verkehr liegen, in denen die Technologien so weit 
ausgereift sind, dass sie in gro&#223;em Ma&#223;stab eingesetzt werden k&#246;nnen.
&#8226; Ma&#223;nahme 6: Die Kommission wird offene und transparente Dialoge auf Sektorebene 
initiieren und dabei dem Gesundheitssektor, Verwaltungen l&#228;ndlicher Gebiete und den 
Betreibern &#246;ffentlicher Dienste Vorrang einr&#228;umen, damit ein Aktionsplan vorgelegt werden 
kann, der die Entwicklung, Erprobung und Einf&#252;hrung erleichtert. Im Zuge dieser Dialoge 
soll je Sektor ein Programm zur Einf&#252;hrung von KI erarbeitet werden, das die Beschaffung 
von KI-Systemen f&#246;rdert und dazu beitr&#228;gt, die &#246;ffentlichen Vergabeverfahren anzupassen.
G. DEN ZUGANG ZU DATEN UND RECHENINFRASTRUKTUREN SICHERN
Die in diesem Wei&#223;buch dargelegten Aktionsbereiche erg&#228;nzen den parallel hierzu im Rahmen der 
europ&#228;ischen Datenstrategie vorgelegten Plan. Die Verbesserung des Zugangs zu Daten und ihrer 
Verwaltung ist von grundlegender Bedeutung Ohne Daten ist die Entwicklung von KI- und anderen 
digitalen Anwendungen nicht m&#246;glich. Da die enormen Mengen neuer Daten erst noch erzeugt werden 
m&#252;ssen, hat Europa die Chance, sich an die Spitze der Daten- und KI-Revolution zu setzen. Wenn 
verantwortungsvolle Datenverwaltungsmethoden gef&#246;rdert und die FAIR-Grunds&#228;tze eingehalten 
werden, tr&#228;gt dies zur Vertrauensbildung bei und gew&#228;hrleistet, dass Daten weiterverwendet werden 
k&#246;nnen24. Ebenso wichtig sind Investitionen in ma&#223;gebliche Rechentechnologien und -infrastrukturen. 
Die Kommission schl&#228;gt vor, im Rahmen des Programms &#8222;Digitales Europa&#8220; mehr als 4 Mrd. EUR 
zur F&#246;rderung von Hochleistungs- und Quantenrechnen, einschlie&#223;lich Edge-Computing und KI-, 
Daten- und Cloud-Infrastruktur, bereitzustellen. In der europ&#228;ischen Datenstrategie werden diese 
Priorit&#228;ten weiter ausgef&#252;hrt.
24 FAIR = Findable, Accessible, Interoperable and Reusable (auffindbar, zug&#228;nglich, interoperabel und wiederverwendbar), 
siehe Schlussbericht und Aktionsplan der Expertengruppe der Kommission zu FAIR-Daten, 2018, 
https://ec.europa.eu/info/sites/info/files/turning_fair_into_reality_1.pdf.
H. INTERNATIONALE ASPEKTE
Europa verf&#252;gt &#252;ber gute Voraussetzungen f&#252;r eine globale F&#252;hrungsrolle beim Aufbau von Allianzen 
rund um gemeinsame Werte und bei der F&#246;rderung des ethischen Umgangs mit KI. Die KI-Arbeit der 
EU schl&#228;gt sich bereits in internationalen Diskussionen nieder. Bei der Ausarbeitung der Ethik-
Leitlinien bezog die Hochrangige Expertengruppe eine Reihe von Organisationen aus Drittl&#228;ndern und 
verschiedene Regierungsbeobachter ein. Gleichzeitig war die EU eng an der Entwicklung der 
ethischen Grunds&#228;tze f&#252;r KI der OECD beteiligt25. Diese Grunds&#228;tze wurden anschlie&#223;end von den 
G20 in ihrer Ministererkl&#228;rung zu Handel und digitaler Wirtschaft vom Juni 2019 gebilligt. 
Gleichzeitig wei&#223; die EU sehr wohl, dass auch in anderen multilateralen Foren wie dem Europarat, der 
Organisation der Vereinten Nationen f&#252;r Erziehung, Wissenschaft und Kultur (UNESCO), der 
Organisation f&#252;r wirtschaftliche Zusammenarbeit und Entwicklung (OECD), der 
Welthandelsorganisation (WTO) und der Internationalen Fernmeldeunion (ITU) wichtige Arbeit zum 
Thema KI geleistet wird. Auf der Ebene der Vereinten Nationen ist die EU am Follow-Up zum 
Bericht der Hochrangigen Gruppe f&#252;r digitale Zusammenarbeit beteiligt, die auch eine Empfehlung zu 
KI umfasst.
Die EU wird auch k&#252;nftig sowohl mit gleich gesinnten L&#228;ndern als auch mit globalen Akteuren im KI-
Bereich zusammenarbeiten &#8211; auf der Grundlage eines Konzepts, das auf Regeln und Werten der EU 
basiert (z. B. regulatorische Aufw&#228;rtskonvergenz, Zugang zu grundlegenden Ressourcen 
einschlie&#223;lich Daten und Schaffung gleicher Wettbewerbsbedingungen). Die Kommission wird die 
Politik von Drittl&#228;ndern, die Datenstr&#246;me beschr&#228;nken, aufmerksam verfolgen und in bilateralen 
Verhandlungen sowie auf WTO-Ebene gegen ungerechtfertigte Beschr&#228;nkungen vorgehen. Die 
Kommission ist &#252;berzeugt davon, dass die internationale Zusammenarbeit im KI-Bereich auf einem 
Ansatz beruhen muss, der die Achtung von Grundrechten und Menschenw&#252;rde, Pluralismus, Inklusion, 
Diskriminierungsfreiheit und den Schutz der Privatsph&#228;re und personenbezogener Daten f&#246;rdert26, und 
es wird ihr ein Anliegen sein, ihre Werte in der ganzen Welt zu vermitteln27. Selbstverst&#228;ndlich kann 
die verantwortungsvolle Entwicklung und Nutzung von KI sowohl die Verwirklichung der Ziele f&#252;r 
nachhaltige Entwicklung als auch die Agenda 2030 ma&#223;geblich voranbringen.
5. EIN &#214;KOSYSTEM F&#220;R VERTRAUEN: KI-REGULIERUNGSRAHMEN
Wie jede neue Technologie bringt auch KI sowohl Chancen als auch Risiken mit sich. Angesichts der 
Informationsasymmetrien in algorithmischen Entscheidungsprozessen f&#252;rchten B&#252;rgerinnen und 
B&#252;rger, ihre Rechte und Sicherheit nicht mehr verteidigen zu k&#246;nnen, und Unternehmen sind wegen 
mangelnder Rechtssicherheit beunruhigt. KI kann zwar dazu beitragen, die Sicherheit der B&#252;rgerinnen 
und B&#252;rger zu sch&#252;tzen, und es ihnen erm&#246;glichen, ihre Grundrechte wahrzunehmen, aber es besteht 
auch die Sorge, dass KI unbeabsichtigte Auswirkungen haben oder sogar f&#252;r kriminelle Zwecke 
missbraucht werden kann. Auf diese Sorgen muss eingegangen werden. Abgesehen von fehlenden 
Investitionen und Kenntnissen ist mangelndes Vertrauen ein Haupthinderungsgrund f&#252;r eine breitere 
Akzeptanz von KI.
25 https://www.oecd.org/going-digital/ai/principles/. 
26 Im Rahmen des Partnerschaftsinstruments wird die Kommission ein mit 2,5 Mio. EUR dotiertes Projekt finanzieren, das 
die Zusammenarbeit mit gleich gesinnten Partnern erleichtern wird, um die KI-Ethik-Leitlinien der EU zu f&#246;rdern und 
gemeinsame Grunds&#228;tze und operative Schlussfolgerungen zu verabschieden. 
27 Pr&#228;sidentin Von der Leyen, Eine Union, die mehr erreichen will &#8211; Meine Agenda f&#252;r Europa, Seite 17.
Deshalb legte die Kommission am 25. April 2018 eine KI-Strategie 28  vor, die sowohl verst&#228;rkte 
Investitionen in Forschung, Innovation und KI-Kapazit&#228;ten in der gesamten EU vorsieht als auch 
gleichzeitig den sozio&#246;konomischen Aspekten Rechnung tr&#228;gt. Sie verst&#228;ndigte sich mit den 
Mitgliedstaaten auf einen koordinierten Plan29, um die Strategien abzustimmen. Ferner setzte die 
Kommission eine Hochrangige Expertengruppe ein, die im April 2019 Leitlinien f&#252;r eine 
vertrauensw&#252;rdige KI30 vorlegte.
Die Kommission legte eine Mitteilung31 vor, in der sie die sieben Kernanforderungen der 
Expertengruppe begr&#252;&#223;te:
&#8226; Vorrang menschlichen Handelns und menschlicher Aufsicht 
&#8226; Technische Robustheit und Sicherheit 
&#8226; Privatsph&#228;re und Datenqualit&#228;tsmanagement  
&#8226; Transparenz  
&#8226; Vielfalt, Nichtdiskriminierung und Fairness 
&#8226; Gesellschaftliches und &#246;kologisches Wohlergehen und 
&#8226; Rechenschaftspflicht 
Dar&#252;ber hinaus enthalten die Leitlinien eine Bewertungsliste als praktische Hilfestellung f&#252;r 
Unternehmen. Im zweiten Halbjahr 2019 haben mehr als 350 Einrichtungen diese Bewertungsliste 
getestet und R&#252;ckmeldungen &#252;bermittelt. Die Hochrangige Gruppe &#252;berarbeitet zurzeit ihre Leitlinien 
unter Ber&#252;cksichtigung dieser R&#252;ckmeldungen und wird ihre Arbeit bis Juni 2020 abschlie&#223;en. Eine 
zentrale Erkenntnis aus diesen R&#252;ckmeldungen ist, dass einige der Anforderungen bereits Eingang in 
geltende Rechts- und Verwaltungsvorschriften gefunden haben. Die Anforderungen in Bezug auf 
Transparenz, R&#252;ckverfolgbarkeit und Kontrolle durch den Menschen sind hingegen in den 
Rechtsvorschriften in vielen Wirtschaftszweigen noch nicht ausdr&#252;cklich abgedeckt. 
Neben diesen unverbindlichen Leitlinien der Hochrangigen Expertengruppe und im Einklang mit den 
politischen Leitlinien der Pr&#228;sidentin w&#252;rde ein klarer europ&#228;ischer Regulierungsrahmen das 
Vertrauen von Verbraucherinnen und Verbrauchern und Unternehmen in k&#252;nstliche Intelligenz st&#228;rken 
und damit die Einf&#252;hrung der Technologie beschleunigen. Ein solcher Regulierungsrahmen sollte mit 
anderen Ma&#223;nahmen zur F&#246;rderung der Innovationskapazit&#228;t und Wettbewerbsf&#228;higkeit Europas in 
diesem Bereich im Einklang stehen. Er muss zudem optimale Ergebnisse f&#252;r Gesellschaft, Umwelt 
und Wirtschaft und die Vereinbarkeit mit den Rechtsvorschriften, Grunds&#228;tzen und Werten der EU 
gew&#228;hrleisten. Dies ist insbesondere in solchen Bereichen relevant, in denen B&#252;rgerrechte unmittelbar 
betroffen sein k&#246;nnten, z. B. im Falle von KI-Anwendungen f&#252;r die Bereiche Strafverfolgung und 
Justiz.
Entwickler und Nutzer von KI unterliegen bereits europ&#228;ischen Rechtsvorschriften &#252;ber Grundrechte 
(z. B. Datenschutz, Schutz der Privatsph&#228;re und Nichtdiskriminierung), Verbraucherschutz sowie 
Produktsicherheit und -haftung. Die Verbraucher erwarten die gleiche Sicherheit und die gleiche 
Achtung ihrer Rechte, unabh&#228;ngig davon, ob ein Produkt oder System KI-gest&#252;tzt ist oder nicht. 
Allerdings k&#246;nnen bestimmte Besonderheiten der KI (z. B. die Opazit&#228;t) die Anwendung und 
Durchsetzung dieser Rechtsvorschriften erschweren. Deshalb muss gepr&#252;ft werden, ob die geltenden
28 COM(2018)237. 
29 COM(2018)795. 
30 https://ec.europa.eu/futurium/en/ai-alliance-consultation/guidelines#Top 
31 COM(2019)168.
Rechtsvorschriften den KI-Risiken gewachsen sind und wirksam durchgesetzt werden k&#246;nnen oder ob 
sie angepasst werden m&#252;ssen bzw. neue Rechtsvorschriften erforderlich sind.
Da sich die KI so rasant weiterentwickelt, muss der Regulierungsrahmen Raum f&#252;r weitere 
Entwicklungen lassen. Etwaige &#196;nderungen sollten sich auf eindeutig festgestellte Probleme 
beschr&#228;nken, f&#252;r die es praktikable L&#246;sungen gibt. 
Die Mitgliedstaaten verweisen darauf, dass es gegenw&#228;rtig keinen einheitlichen europ&#228;ischen Rahmen 
gibt. Die Datenethikkommission in Deutschland pl&#228;diert f&#252;r ein f&#252;nfstufiges risikobasiertes 
Regulierungssystem, das von keiner Regulierung f&#252;r die KI-Systeme mit dem geringsten Risiko bis 
hin zu einem vollst&#228;ndigen Verbot f&#252;r die Systeme mit dem h&#246;chsten Risiko reichen w&#252;rde. D&#228;nemark 
hat gerade den Prototyp eines Ethiksiegels f&#252;r Daten vorgestellt, und Malta hat eine freiwillige KI-
Zertifizierung eingef&#252;hrt. Wenn es der EU nicht gelingt, ein EU-weites Konzept vorzustellen, besteht 
die reale Gefahr einer Fragmentierung des Binnenmarkts, was den Zielen Vertrauen, Rechtssicherheit 
und Markteinf&#252;hrung abtr&#228;glich w&#228;re. 
Ein solider europ&#228;ischer Regulierungsrahmen f&#252;r eine vertrauensw&#252;rdige KI wird alle europ&#228;ischen 
B&#252;rgerinnen und B&#252;rger sch&#252;tzen und zur Schaffung eines reibungslos funktionierenden 
Binnenmarkts beitragen, im Interesse der Weiterentwicklung und Verbreitung von KI sowie der 
St&#228;rkung der industriellen Basis Europas im Bereich KI. 
A. PROBLEMSTELLUNG
KI kann viel Gutes bewirken, da sie z. B. Produkte und Verfahren sicherer macht, sie kann aber auch 
Sch&#228;den verursachen. Diese Sch&#228;den k&#246;nnen sowohl materiell (Sicherheit und Gesundheit des 
Einzelnen, einschlie&#223;lich Verlust von Menschenleben, Sachsch&#228;den) als auch immateriell (Verlust der 
Privatsph&#228;re, Einschr&#228;nkung des Rechts auf freie Meinungs&#228;u&#223;erung, Menschenw&#252;rde&#8218; 
Diskriminierung z. B. beim Zugang zu Besch&#228;ftigung) sein und sich in einer Vielzahl von Risiken 
manifestieren. Der Schwerpunkt eines Regulierungsrahmens sollte auf der Frage liegen, wie die 
Gefahr potenzieller und vor allem der schwersten Sch&#228;den minimiert werden kann. 
Die gr&#246;&#223;ten Risiken in Verbindung mit der Nutzung von KI betreffen die Anwendung von 
Vorschriften zum Schutz von Grundrechten (einschlie&#223;lich Datenschutz und Schutz der Privatsph&#228;re 
und Nichtdiskriminierung) sowie Fragen der Sicherheit32 und Haftung. 
Risiken f&#252;r die Grundrechte, einschlie&#223;lich des Schutzes personenbezogener Daten und der 
Privatsph&#228;re und Nichtdiskriminierung
Infolge der Nutzung von KI k&#246;nnen die Werte, auf denen die EU gr&#252;ndet, beeintr&#228;chtigt und 
Grundrechte 33  verletzt werden. Dies gilt auch f&#252;r das Recht auf freie Meinungs&#228;u&#223;erung, die 
Versammlungsfreiheit, die Achtung der Menschenw&#252;rde, die Nichtdiskriminierung ungeachtet des 
Geschlechts, der Rasse oder der ethnischen Herkunft, der religi&#246;sen &#220;berzeugung oder 
Weltanschauung, einer Behinderung, des Alters oder der sexuellen Ausrichtung, den Schutz 
personenbezogener Daten und des Privatlebens 34 , das Recht auf einen wirksamen gerichtlichen
32 Dazu z&#228;hlen auch Cybersicherheitsaspekte, Fragen in Verbindung mit KI-Anwendungen in kritischen Infrastrukturen oder 
mit dem Missbrauch von KI. 
33  Eine Studie im Auftrag des Europarates zeigt, dass eine gro&#223;e Zahl von Grundrechten durch den Einsatz von KI 
beeintr&#228;chtigt werden k&#246;nnte, https://rm.coe.int/algorithms-and-human-rights-en-rev/16807956b5. 
34 Die Datenschutz-Grundverordnung und die e-Datenschutzrichtlinie (neue e-Datenschutzverordnung im 
Annahmeverfahren) gehen zwar auf diese Risiken ein, doch u. U. m&#252;sste untersucht werden, ob KI-Systeme zus&#228;tzliche
Rechtsbehelf und ein faires Verfahren sowie den Verbraucherschutz. Diese Risiken k&#246;nnen das 
Ergebnis von Fehlern in der Gestaltung der KI-Systeme sein (auch hinsichtlich der Kontrolle durch 
den Menschen) oder von Fehlern bei der Verwendung von Daten, wenn etwaige Verzerrungen nicht 
korrigiert wurden (z. B. wenn das System nur mit Daten von M&#228;nnern trainiert wird, was zu 
suboptimalen Ergebnissen f&#252;r Frauen f&#252;hrt).
KI kann viele Funktionen &#252;bernehmen, die zuvor nur vom Menschen wahrgenommen werden konnten. 
Infolgedessen werden B&#252;rgerinnen und B&#252;rger und juristische Personen zunehmend von Ma&#223;nahmen 
und Entscheidungen betroffen, die von oder mithilfe von KI-Systemen gef&#228;llt werden und zuweilen 
schwer nachvollziehbar sind oder kaum wirksam angefochten werden k&#246;nnten. Dar&#252;ber hinaus bietet 
KI immer mehr M&#246;glichkeiten, die t&#228;glichen Gewohnheiten von Menschen zu erfassen und zu 
analysieren. So besteht z. B. potenziell die Gefahr, dass KI &#8211; unter Versto&#223; gegen die Datenschutz-
und andere Vorschriften der EU &#8211; von staatlichen Beh&#246;rden oder anderen Stellen zur 
Massen&#252;berwachung oder von Arbeitgebern zur &#220;berwachung des Verhaltens ihrer Angestellten 
genutzt werden. Durch die Analyse gro&#223;er Datenmengen und die Feststellung von Verbindungen 
zwischen ihnen kann KI auch dazu genutzt werden, Daten von Personen gezielt zur&#252;ckzuverfolgen 
und zu de-anonymisieren, wodurch neue Risiken f&#252;r den Schutz personenbezogener Daten entstehen, 
selbst wenn die Datens&#228;tze an sich keine personenbezogenen Daten enthalten. KI wird auch von 
Online-Mittlern genutzt, um Informationen f&#252;r ihre Nutzer zu priorisieren und Inhalte zu moderieren. 
Dabei k&#246;nnen die verarbeiteten Daten, die Art und Weise, in der die Anwendungen ausgelegt wurden, 
und beschr&#228;nkte M&#246;glichkeiten f&#252;r ein Eingreifen des Menschen auf Kosten des Rechts auf freie 
Meinungs&#228;u&#223;erung, des Schutzes personenbezogener Daten, der Privatsph&#228;re und politischer 
Freiheiten gehen. 
Bestimmte KI-Algorithmen k&#246;nnen, wenn sie zur Vorhersage der R&#252;ckf&#228;lligkeit von Straft&#228;tern genutzt 
werden, aufgrund von Geschlecht oder Rasse diskriminieren; sie weisen unterschiedliche 
R&#252;ckf&#228;lligkeitswahrscheinlichkeiten f&#252;r M&#228;nner und Frauen oder f&#252;r In- und Ausl&#228;nder aus. Quelle: Tolan 
S., Miron M., Gomez E. und Castillo C. &#8222;Why Machine Learning May Lead to Unfairness: Evidence from 
Risk Assessment for Juvenile Justice in Catalonia&#8220;, Preis f&#252;r die beste Arbeit, Internationale Konferenz &#252;ber 
KI und Recht, 2019.
Bestimmte KI-Programme f&#252;r die Gesichtserkennung diskriminieren aufgrund von Geschlecht oder Rasse, 
weil ihre Fehlerquote bei der Bestimmung des Geschlechts im Falle von hellh&#228;utigen M&#228;nnern gering, im 
Falle von dunkelh&#228;utigen Frauen hingegen hoch ist. Quelle: Joy Buolamwini, Timnit Gebru; Proceedings of 
the 1st Conference on Fairness, Accountability and Transparency, PMLR 81:77-91, 2018.
Vorurteile und Diskriminierung k&#246;nnen in allen gesellschaftlichen und wirtschaftlichen 
T&#228;tigkeitsfeldern auftreten. Die Entscheidungsfindung des Menschen ist nicht immun gegen Fehler 
und Voreingenommenheiten. Aber in KI-Systemen k&#246;nnten die gleichen Voreingenommenheiten eine 
viel gr&#246;&#223;ere Wirkung entfalten und ohne die sozialen Kontrollmechanismen, die das menschliche 
Verhalten regeln, viele Menschen beeintr&#228;chtigen und diskriminieren35. Dies kann auch geschehen,
Risiken bergen. Die Kommission wird die Anwendung der Datenschutz-Grundverordnung kontinuierlich &#252;berwachen 
und bewerten. 
35 Der Beratende Ausschuss der Kommission f&#252;r die Chancengleichheit von Frauen und M&#228;nnern erarbeitet zurzeit eine 
&#8222;Stellungnahme zur K&#252;nstlichen Intelligenz&#8220;, in der unter anderem die Auswirkungen der KI auf die Gleichstellung der 
Geschlechter analysiert werden und die voraussichtlich Anfang 2020 angenommen wird. In der Strategie der EU f&#252;r die
wenn das KI-System &#8222;lernt&#8220;, w&#228;hrend es angewendet wird. In solchen F&#228;llen resultieren die Risiken, 
wenn dies in der Entwurfsphase nicht h&#228;tte verhindert oder vorhergesehen werden k&#246;nnen, nicht aus 
Fehlern in der urspr&#252;nglichen Auslegung des Systems, sondern aus den praktischen Folgen der 
Korrelationen oder Muster, die das System in gro&#223;en Datens&#228;tzen identifiziert.
&#8211;
e e u
i n e ie n n
Die besonderen Merkmale vieler KI-Technologien wie Opazit&#228;t (&#8222;Blackbox-Effekt&#8220;), Komplexit&#228;t, 
Unvorhersehbarkeit und teilautonomes Verhalten k&#246;nnen die Pr&#252;fung der Vereinbarkeit und die 
wirksame Durchsetzung von EU-Rechtsvorschriften zum Schutz der Grundrechte erschweren. 
Strafverfolgungsbeh&#246;rden und Betroffene k&#246;nnen u. U. nicht nachvollziehen, wie eine bestimmte 
unter Einsatz von KI getroffene Entscheidung gef&#228;llt wurde, und somit auch nicht verifizieren, ob die 
einschl&#228;gigen Vorschriften eingehalten wurden. Nat&#252;rliche wie juristische Personen k&#246;nnten in F&#228;llen, 
in denen sich solche Entscheidungen nachteilig auf sie auswirken, beim effektiven Zugang zur Justiz 
auf Schwierigkeiten sto&#223;en.
Risiken f&#252;r die Sicherheit und das wirksame Funktionieren der Haftungsregelung 
KI-Technologien k&#246;nnen neue Sicherheitsrisiken f&#252;r die Nutzer mit sich bringen, wenn sie in Produkte 
und Dienstleistungen eingebettet sind. So ist beispielsweise denkbar, dass ein autonomes Fahrzeug 
aufgrund eines Fehlers in der Objekterkennungstechnik einen Gegenstand auf der Stra&#223;e falsch 
identifiziert und einen Unfall mit Verletzungen und Sachsch&#228;den verursacht. Wie bei den Risiken im 
Bereich der Grundrechte k&#246;nnen diese Risiken durch Fehler in der Gestaltung der KI-Technologie 
bedingt sein oder durch Probleme bei der Verf&#252;gbarkeit und der Qualit&#228;t von Daten bzw. anderen 
Problemen, die sich aus dem Maschinellen Lernen ergeben. Einige dieser Risiken sind zwar nicht auf 
KI-gest&#252;tzte Produkte und Dienstleistungen beschr&#228;nkt, allerdings kann der Einsatz von KI die 
Risiken erh&#246;hen oder versch&#228;rfen.
Wenn es keine klaren Sicherheitsvorschriften in Bezug auf diese Risiken gibt, kann dies neben den 
Risiken f&#252;r die betroffenen Personen auch zu Rechtsunsicherheit f&#252;r Unternehmen f&#252;hren, die KI-
gest&#252;tzte Produkte in der EU vermarkten. Markt&#252;berwachungs- und Strafvollzugsbeh&#246;rden k&#246;nnen in 
eine Situation kommen, in der sie nicht wissen, ob sie t&#228;tig werden k&#246;nnen, weil ihnen keine 
entsprechenden Befugnisse erteilt wurden bzw. weil sie nicht &#252;ber die geeigneten technischen 
Kapazit&#228;ten zur Inspektion dieser Systeme verf&#252;gen36. Mangelnde Rechtssicherheit kann somit zu 
einer Senkung des Sicherheitsniveaus f&#252;hren und die Wettbewerbsf&#228;higkeit europ&#228;ischer 
Unternehmen beintr&#228;chtigen. 
Treten Sicherheitsrisiken tats&#228;chlich auf, ist es aufgrund des Fehlens klarer Anforderungen und der 
oben genannten Merkmale der KI-Technologien schwierig, potenziell problematische Entscheidungen, 
die unter Einbeziehung von KI-Systemen getroffen wurden, zur&#252;ckzuverfolgen. Dadurch kann es f&#252;r
Gleichstellung der Geschlechter (2020 2024) wird der Zusammenhang zwischen KI und der Gleichstellung der 
Geschl chter ebenfalls thematisiert. Das Europ&#228;isch Netz der Gleichbehandl ngsstellen (Equinet) wird voraussichtlichNach der Produkth ftungsrichtlinie haften Herst ller f&#252;r Sch&#228;den, die d rch fehlerhafte Produkte verursacht 
im Fr&#252;hjahr 2020 einen Bericht (von Robin Allen und Dee Masters) mit dem Titel &#8222;Regulating AI: the new role for 
Equality Bodies &#8211; Meeting the new challenges to equality and non-discrimination from increased digitalisation and the
werden. Im Falle KI-gest&#252;tzter Systeme wie z. B. bei autonomen Fahrzeugen kann es jedoch schwierig sein, 
use of AI&#8220; (KI regulieren: die neue Rolle f&#252;r Gleichbehandlungsstellen &#8211; Bew&#228;ltigung der neuen Herausforderungen f&#252;r
Chancengleichheit und N chtdiskriminieru g infolge der zunehm nden Digitalis ru g u d der Nutzung von KI)
einen Produktfehler, den entstandenen Schaden und den Kausalzusammenhang zwischen diesen beiden 
nac zuweis n. Dar&#252;ber hinaus besteht ei e gewisse Unsicherh it dar&#252;ber, wi  d in welchem Umfang die 
Produkthaftungsrichtlinie auf bestimmte Arten von M&#228;ngeln Anwendung findet, z. B. wenn diese auf ver&#246;ffentlichen.
36 Ein Beispiel hierf&#252;r w&#228;re etwa die intelligente Uhr f&#252;r Kinder. Dieses Produkt d&#252;rfte dem Kind, das es tr&#228;gt, zwar keinenSchw&#228;chen bei der Cybersicherheit des Produkts zur&#252;ckzuf&#252;hren sind.
direkten Schaden zuf&#252;gen, da jedoch kein Mindestsicherheitsniveau gew&#228;hrleistet ist, k&#246;nnen Dritte &#252;ber die Uhr problemlos
Kontakt zu dem Kind aufnehmen. F&#252;r die Markt&#252;berwachungsbeh&#246;rden kann es schwierig sein, in F&#228;llen t&#228;tig zu werden, in
denen das Risiko nicht mit dem Produkt als solchem zusammenh&#228;ngt.
Personen, die einen Schaden erlitten haben, schwer werden, eine Entsch&#228;digung nach dem geltenden 
EU- und nationalen Haftungsrecht zu erhalten37.
Daher ist die bereits in Bezug auf die Grundrechte erw&#228;hnte Schwierigkeit, potenziell problematische 
Entscheidungen von KI-Systemen zur&#252;ckzuverfolgen, auch bei Sicherheits- und Haftungsfragen 
gegeben. So k&#246;nnten m&#246;glicherweise Gesch&#228;digte z. B. keinen Zugang zu Nachweisen haben, die zur 
Beweisf&#252;hrung in einem Gerichtsverfahren erforderlich sind, und ihnen stehen u. U. weniger 
Rechtsbehelfe zur Verf&#252;gung als in F&#228;llen, in denen der Schaden durch herk&#246;mmliche Technologien 
verursacht wird. Diese Risiken werden mit zunehmender Verbreitung von KI weiter zunehmen. 
B. M&#214;GLICHE ANPASSUNGEN DES BESTEHENDEN EU-RECHTSRAHMENS UNTER 
BER&#220;CKSICHTIGUNG VON KI
Ein umfangreicher Bestand an EU-Produktsicherheits- und Produkthaftungsvorschriften 38 &#8218; 
einschlie&#223;lich sektorspezifischer Bestimmungen, die ferner durch nationale Rechtsvorschriften und 
einschl&#228;gige Normen erg&#228;nzt werden, ist f&#252;r eine Reihe neuer KI-Anwendungen relevant und 
potenziell auf diese anwendbar. 
Was den Schutz der Grundrechte und der Verbraucherrechte angeht, so umfasst der EU-Rechtsrahmen 
Vorschriften wie die Richtlinie zur Anwendung des Gleichbehandlungsgrundsatzes ohne Unterschied 
der Rasse oder der ethnischen Herkunft39, die Richtlinie &#252;ber die Gleichbehandlung in Besch&#228;ftigung 
und Beruf 40 , die Richtlinien zur Gleichbehandlung von M&#228;nnern und Frauen in Arbeits- und 
Besch&#228;ftigungsfragen und beim Zugang zu G&#252;tern und Dienstleistungen 41 , eine Reihe von 
Verbraucherschutzvorschriften42 sowie Vorschriften zum Schutz personenbezogener Daten und der 
Privatsph&#228;re, insbesondere die Datenschutz-Grundverordnung und andere sektorspezifische 
Rechtsvorschriften mit Bestimmungen zum Schutz personenbezogener Daten, wie die Richtlinie zum 
Datenschutz bei der Strafverfolgung 43 . Dar&#252;ber hinaus werden ab 2025 die Vorschriften zur 
Barrierefreiheit von Produkten und Dienstleistungen gelten, die in dem europ&#228;ischen Rechtsakt zur 
Barrierefreiheit festgelegt wurden44. Dar&#252;ber hinaus m&#252;ssen die Grundrechte bei der Umsetzung 
anderer EU-Rechtsvorschriften, u. a. in den Bereichen Finanzdienstleistungen, Migration und 
Verantwortung von Online-Vermittlern, geachtet werden. 
Auch wenn die EU-Rechtsvorschriften unbeschadet des Einsatzes von KI grunds&#228;tzlich weiterhin in 
vollem Umfang anwendbar sind, ist es wichtig zu bewerten, ob sie angemessen durchgesetzt werden 
k&#246;nnen, um den von KI-Systemen ausgehenden Risiken zu begegnen, oder ob manche 
Rechtsinstrumente angepasst werden m&#252;ssen.
37 Die Auswirkungen von KI, dem Internet der Dinge und anderen digitalen Technologien auf die Sicherheits- und 
Haftungsvorschriften werden in dem Bericht der Kommission, der ebenfalls zusammen mit diesem Wei&#223;buch vorgelegt 
wird, analysiert. 
38 Der EU-Rechtsrahmen f&#252;r die Produktsicherheit umfasst als Sicherheitsnetz die Richtlinie &#252;ber die allgemeine 
Produktsicherheit (Richtlinie 2001/95/EG) sowie ferner eine Reihe sektorspezifischer Vorschriften f&#252;r verschiedene 
Produktkategorien &#8211; von Maschinen, Flugzeugen und Autos bis hin zu Spielzeug und Medizinprodukten &#8211;, um ein hohes 
Ma&#223; an Gesundheit und Sicherheit zu gew&#228;hrleisten. Die Produkthaftungsbestimmungen werden durch verschiedene 
Systeme der zivilrechtlichen Haftung f&#252;r Sch&#228;den, die durch Produkte oder Dienstleistungen verursacht werden, erg&#228;nzt. 
39 Richtlinie 2000/43/EG. 
40 Richtlinie 2000/78/EG. 
41 Richtlinie 2004/113/EG. Richtlinie 2006/54/EG. 
42 Beispielsweise die Richtlinie &#252;ber unlautere Gesch&#228;ftspraktiken (Richtlinie 2005/29/EG) und die Richtlinie &#252;ber die 
Verbraucherrechte (Richtlinie 2011/83/EG). 
43 Richtlinie (EU) 2016/680 des Europ&#228;ischen Parlaments und des Rates vom 27. April 2016 zum Schutz nat&#252;rlicher 
Personen bei der Verarbeitung personenbezogener Daten durch die zust&#228;ndigen Beh&#246;rden zum Zwecke der Verh&#252;tung, 
Ermittlung, Aufdeckung oder Verfolgung von Straftaten oder der Strafvollstreckung sowie zum freien Datenverkehr. 
44 Richtlinie (EU) 2019/882 &#252;ber die Barrierefreiheitsanforderungen f&#252;r Produkte und Dienstleistungen.
Beispielsweise sind die Wirtschaftsakteure nach wie vor uneingeschr&#228;nkt daf&#252;r verantwortlich, daf&#252;r 
zu sorgen, dass die bestehenden Verbraucherschutzvorschriften beim Einsatz von KI eingehalten 
werden; algorithmenbasierte Auswertungen des Verbraucherverhaltens, bei denen gegen bestehende 
Vorschriften versto&#223;en wird, sind nicht zul&#228;ssig und Verst&#246;&#223;e werden entsprechend geahndet.
Die Kommission ist der Auffassung, dass der Rechtsrahmen verbessert werden k&#246;nnte, um den 
folgenden Risiken und Situationen zu begegnen: 
&#8226; Wirksame Anwendung und Durchsetzung bestehender Rechtsvorschriften der EU und der 
Mitgliedstaaten: Die wesentlichen Merkmale der KI bringen Herausforderungen f&#252;r die 
ordnungsgem&#228;&#223;e Anwendung und Durchsetzung der Rechtsvorschriften der EU und der 
Mitgliedstaaten mit sich. Der Mangel an Transparenz (Opazit&#228;t der KI) macht es schwer, 
etwaige Verst&#246;&#223;e gegen Rechtsvorschriften zu aufzudecken und nachzuweisen, dies betrifft 
auch Bestimmungen zum Schutz der Grundrechte, zur L&#246;sung von Haftungsfragen und &#252;ber 
die Voraussetzungen f&#252;r die Geltendmachung von Schadenersatz. Um eine wirksame 
Anwendung und Durchsetzung zu gew&#228;hrleisten, kann es daher erforderlich sein, die 
bestehenden Rechtsvorschriften in manchen Bereichen, z. B. in Bezug auf Haftungsfragen, 
anzupassen oder zu pr&#228;zisieren, wie in dem Bericht, der diesem Wei&#223;buch beigef&#252;gt ist, n&#228;her 
ausgef&#252;hrt wird. 
&#8226; Einschr&#228;nkung des Anwendungsbereichs bestehender EU-Rechtsvorschriften: Bei den EU-
Produktsicherheitsvorschriften liegt ein wesentlicher Schwerpunkt auf dem Inverkehrbringen 
von Produkten. Nach den EU-Produktsicherheitsvorschriften muss Software, wenn sie Teil 
des Endprodukts ist, den einschl&#228;gigen Produktsicherheitsvorschriften entsprechen, hingegen 
ist die Frage, ob eigenst&#228;ndige Software von den EU-Produktsicherheitsvorschriften erfasst 
wird &#8211; abgesehen von einigen Sektoren, f&#252;r die es explizite Vorschriften gibt45 &#8211; noch zu 
kl&#228;ren. Die derzeit geltenden allgemeinen Sicherheitsvorschriften sind auf Produkte 
anwendbar und gelten nicht f&#252;r Dienstleistungen, und somit grunds&#228;tzlich auch nicht f&#252;r 
Dienstleistungen, die auf KI-Technologien basieren (z. B. Gesundheitsdienstleistungen, 
Finanzdienstleistungen und Verkehrsdienstleistungen).
&#8226; Ver&#228;nderliche Funktionen der KI-Systeme: Wenn Software, einschlie&#223;lich KI, in Produkte 
eingebunden wird, kann dies die Funktionsweise dieser Produkte und Systeme im weiteren 
Verlauf ihres Lebenszyklus ver&#228;ndern. Dies gilt insbesondere f&#252;r Systeme, die h&#228;ufige 
Software-Updates erfordern oder auf Maschinellem Lernen beruhen. Dies kann zum Entstehen 
neuen Risiken f&#252;hren, die zum Zeitpunkt des Inverkehrbringens des Systems nicht bestanden. 
Diese Risiken werden in den geltenden Rechtsvorschriften, die sich in erster Linie auf 
Sicherheitsrisiken konzentrieren, die zum Zeitpunkt des Inverkehrbringens bestehen, nicht 
angemessen ber&#252;cksichtigt.
&#8226; Unsicherheit hinsichtlich der Aufteilung der Zust&#228;ndigkeiten zwischen den verschiedenen 
Wirtschaftsteilnehmern in der Lieferkette: Generell tr&#228;gt nach den EU-
Produktsicherheitsvorschriften der Hersteller des in Verkehr gebrachten Produkts die 
Verantwortung f&#252;r Produktsicherheit, einschlie&#223;lich aller Komponenten, die z. B. auch KI-
Systeme umfassen k&#246;nnen. Unklarheiten k&#246;nnen bei den Vorschriften jedoch beispielsweise
45 So gilt beispielsweise Software, die vom Hersteller f&#252;r medizinische Zwecke bestimmt ist, als Medizinprodukt im Sinne 
der Verordnung &#252;ber Medizinprodukte (Verordnung (EU) 2017/745).
dann aufkommen, wenn KI integriert wird, nachdem das Produkt von einer Partei in Verkehr 
gebracht wurde, die nicht der Hersteller ist. Dar&#252;ber hinaus wird im EU-Produkthaftungsrecht 
die Haftung der Hersteller geregelt, w&#228;hrend die Haftung anderer in der Lieferkette in den 
nationalen Haftungsregeln geregelt wird.
&#8226; &#196;nderungen des Sicherheitskonzepts: Der Einsatz von KI in Produkten und Dienstleistungen 
kann zu Risiken f&#252;hren, die derzeit in den EU-Rechtsvorschriften nicht explizit erfasst sind. 
Diese Risiken k&#246;nnen beispielsweise mit Cyberbedrohungen, Gef&#228;hrdungen der pers&#246;nlichen 
Sicherheit (z. B. im Zusammenhang mit neuen Anwendungen von KI z. B. f&#252;r Haushaltsger&#228;te) 
oder mit Risiken verbunden sein, die sich aus dem Verlust der Konnektivit&#228;t ergeben. Diese 
Risiken k&#246;nnen zum Zeitpunkt des Inverkehrbringens der Produkte bestehen oder infolge von 
Software-Updates oder eigenst&#228;ndigem Lernen bei der Verwendung des Produkts entstehen. 
Die EU sollte die ihr zur Verf&#252;gung stehenden Instrumente umfassend nutzen, um die 
verf&#252;gbare Faktengrundlage zu potenziellen Risiken im Zusammenhang mit KI-Anwendungen 
zu verbessern, und dabei auch auf die Erfahrungen der EU-Cybersicherheitsagentur (ENISA) 
bei der Bewertung Bedrohungslandschaft im Bereich der KI zur&#252;ckgreifen.
Wie bereits erw&#228;hnt, pr&#252;fen mehrere Mitgliedstaaten bereits Optionen, wie die durch KI geschaffenen 
Herausforderungen in nationalen Rechtsvorschriften angegangen werden k&#246;nnen. Dies birgt die 
Gefahr einer Fragmentierung des Binnenmarkts. Das Bestehen unterschiedlicher nationaler 
Vorschriften d&#252;rfte Hemmnisse f&#252;r Unternehmen schaffen, die KI-Systeme im Binnenmarkt verkaufen 
und betreiben wollen. Ein gemeinsames Konzept auf EU-Ebene w&#252;rde es europ&#228;ischen Unternehmen 
erm&#246;glichen, von einem reibungslosen Zugang zum Binnenmarkt zu profitieren, und ihre 
Wettbewerbsf&#228;higkeit auf den globalen M&#228;rkten st&#228;rken.
Drucksache 95/20 - 18 -
Angesichts der vorstehenden Ausf&#252;hrungen kommt die Kommission zu dem Schluss, dass &#8211; zus&#228;tzlich
Bericht &#252;ber die Auswirkungen von K&#252;nstlicher Intelligenz, des Internets der Dinge und der 
Robotik auf Sicherheits- und Haftungsfragen 
In dem zusammen mit diesem Wei&#223;buch vorgelegten Bericht wird der einschl&#228;gige Rechtsrahmen 
analysiert. Dabei wird der Frage nachgegangen, wo es Unsicherheiten hinsichtlich der Anwendung dieses 
Rechtsrahmens wegen der spezifischen Risiken gibt, die von KI-Systemen und anderen digitalen 
Technologien ausgehen. 
Der Bericht kommt zu dem Schluss, dass die geltenden Produktsicherheitsvorschriften bereits ein 
erweitertes Konzept des Schutzes vor allen Arten von Risiken, die von dem Produkt je nach seiner 
Verwendung ausgehen, unterst&#252;tzen. Um gr&#246;&#223;ere Rechtssicherheit zu schaffen, k&#246;nnten jedoch 
Bestimmungen aufgenommen werden, die sich ausdr&#252;cklich auf neue Risiken im Zusammenhang mit den 
neuen digitalen Technologien beziehen. 
&#8226; Das autonome Verhalten bestimmter KI-Systeme w&#228;hrend ihres Lebenszyklus kann zu 
erheblichen sicherheitsrelevanten &#196;nderungen der Produkte f&#252;hren, die eine neue 
Risikobewertung erforderlich machen k&#246;nnen. Dar&#252;ber hinaus kann es n&#246;tig sein, als 
Schutzma&#223;nahme die Kontrolle durch den Menschen ab der Phase der Auslegung und w&#228;hrend 
des gesamten Lebenszyklus der KI-Produkte und -Systeme vorzusehen. 
&#8226; Explizite Verpflichtungen f&#252;r Hersteller k&#246;nnten ggf. auch in Bezug auf psychische 
Sicherheitsrisiken f&#252;r Anwender in Erw&#228;gung gezogen werden (z. B. bei Zusammenarbeit mit 
humanoiden Robotern). 
&#8226; Die Produktsicherheitsvorschriften der Union k&#246;nnten sowohl spezifische Anforderungen 
vorsehen, um die Sicherheitsrisiken auszur&#228;umen, die von fehlerhaften Daten in der Phase der 
Auslegung ausgehen, als auch Mechanismen, mit denen sichergestellt wird, dass die Qualit&#228;t der 
Daten w&#228;hrend der gesamten Nutzung der KI-Produkte und -Systeme aufrechterhalten wird. 
&#8226; Die Frage der Opazit&#228;t von auf Algorithmen basierenden Systemen k&#246;nnte durch die Festlegung 
von Transparenzanforderungen angegangen werden. 
&#8226; Im Falle eigenst&#228;ndiger Software, die als solche in Verkehr gebracht wird oder nach dem 
Inverkehrbringen in ein Produkt heruntergeladen wird, m&#252;ssen die bestehenden Vorschriften 
m&#246;glicherweise angepasst und pr&#228;zisiert werden, wenn die Software sicherheitsrelevante 
Auswirkungen hat. 
&#8226; Angesichts der zunehmenden Komplexit&#228;t der Lieferketten bei neuen Technologien k&#246;nnten 
auch Bestimmungen, die eine Zusammenarbeit zwischen den Wirtschaftsteilnehmern in der 
Lieferkette und den Nutzern verbindlich vorschreiben, zur Rechtssicherheit beitragen. 
Die Merkmale neuer digitaler Technologien wie KI, Internet der Dinge und Robotik k&#246;nnen bestimmte 
Aspekte der bestehenden Haftungsrahmen infrage stellen und deren Wirksamkeit verringern. Aufgrund 
mancher dieser Eigenschaften k&#246;nnte es schwierig werden, den Schaden zu einer Person 
zur&#252;ckzuverfolgen, was nach den meisten nationalen Vorschriften erforderlich w&#228;re, um 
verschuldensabh&#228;ngige Anspr&#252;che geltend zu machen. Dies k&#246;nnte die Kosten f&#252;r die Gesch&#228;digten 
erheblich erh&#246;hen und dazu f&#252;hren, dass Haftungsanspr&#252;che gegen&#252;ber anderen Akteuren als den 
Herstellern schwer geltend zu machen oder zu belegen sind. 
&#8226; Personen, die infolge der Nutzung von KI-Systemen einen Schaden erlitten haben, m&#252;ssen das 
gleiche Schutzniveau genie&#223;en wie Personen, die durch andere Technologien gesch&#228;digt wurden. 
Gleichzeitig muss genug Raum f&#252;r die Weiterentwicklung technologischer Innovationen bleiben. 
&#8226; Alle Optionen, die zur Erreichung dieses Ziels ins Auge gefasst werden &#8211; einschlie&#223;lich 
m&#246;glicher &#196;nderungen der Produkthaftungsrichtlinie und einer etwaigen weiteren gezielten 
Harmonisierung der nationalen Haftungsvorschriften - sollten sorgf&#228;ltig gepr&#252;ft werden. So bittet 
die Kommission beispielsweise um Stellungnahmen zu der Frage, ob und in welchem Umfang es 
erforderlich sein k&#246;nnte, die Folgen der Komplexit&#228;t abzumildern, indem f&#252;r Sch&#228;den, die durch 
den Betrieb von KI-Anwendungen verursacht werden, die in den nationalen Haftungsvorschriften 
vorgesehenen Beweislastregeln ge&#228;ndert werden.
zu den m&#246;glichen Anpassungen der bestehenden Rechtsvorschriften &#8212; m&#246;glicherweise neue, speziell 
auf KI ausgerichtete Rechtsvorschriften erforderlich sind, um den Rechtsrahmen der EU an die 
derzeitigen und erwarteten technologischen und kommerziellen Entwicklungen anzupassen.
C. ANWENDUNGSBEREICH EINES K&#220;NFTIGEN EU-RECHTSRAHMENS
Eine zentrale Frage f&#252;r den k&#252;nftigen spezifischen Rechtsrahmen f&#252;r KI ist die Festlegung des 
Anwendungsbereichs. Die Arbeitshypothese lautet, dass der Rechtsrahmen f&#252;r Produkte und 
Dienstleistungen gelten soll, bei denen KI zum Einsatz kommt. KI sollte daher f&#252;r die Zwecke dieses 
Wei&#223;buchs sowie f&#252;r alle weiteren k&#252;nftigen politische Initiativen klar definiert werden. 
In ihrer Mitteilung &#252;ber KI f&#252;r Europa legte die Kommission eine erste Definition von KI vor46. Diese 
Definition wurde von der Hochrangigen Expertengruppe weiter pr&#228;zisiert47. 
In jedem neuen Rechtsinstrument muss die KI-Definition einerseits flexibel genug sein, damit dem 
technischen Fortschrift Rechnung getragen werden kann, und andererseits pr&#228;zise, um die 
erforderliche Rechtssicherheit zu gew&#228;hrleisten. 
 F&#252;r die Zwecke dieses Wei&#223;buchs sowie 
etwaiger k&#252;nftiger Diskussionen &#252;ber 
politische Initiativen erscheint es wichtig, 
Klarheit in Bezug auf die wichtigsten 
Elemente, aus denen sich KI 
zusammensetzt, d. h. &#8222;Daten&#8220; und 
&#8222;Algorithmen&#8220;, zu schaffen. KI kann in 
Hardware integriert sein. Bei Techniken 
des Maschinellen Lernens, einer 
Untergruppe der KI, werden Algorithmen 
so trainiert, dass sie auf der Grundlage 
eines Datensatzes bestimmte Muster 
ableiten k&#246;nnen, um zu ermitteln, welche 
Handlungsschritte zur Erreichung eines 
bestimmten Ziels erforderlich sind. Algorithmen k&#246;nnen auch weiterlernen, w&#228;hrend sie im Einsatz 
sind. W&#228;hrend KI-basierte Produkte eigenst&#228;ndig handeln k&#246;nnen, indem sie ihre Umgebung 
wahrnehmen und ohne dass sie vorab festgelegte Anweisungen befolgen, wird ihr Verhalten von den 
Produktentwicklern in breiten Z&#252;gen festgelegt und auch eingeschr&#228;nkt. Der Mensch bestimmt und 
programmiert die Ziele, die ein KI-System erreichen soll.
Beim autonomen Fahren beispielsweise verwendet der 
Algorithmus in Echtzeit die Fahrzeugdaten 
(Geschwindigkeit, Motorverbrauch, Sto&#223;d&#228;mpfer usw.) 
und die Daten der Sensoren, die die gesamte Umgebung 
des Fahrzeugs (Stra&#223;e, Schilder, andere Fahrzeuge, 
Fu&#223;g&#228;nger usw.) abtasten, um abzuleiten, welche Richtung, 
Beschleunigung und Geschwindigkeit das Fahrzeug w&#228;hlen 
sollte, um einen bestimmten Zielort zu erreichen. Anhand 
der Beobachtungsdaten nimmt der Algorithmus 
Anpassungen an die Stra&#223;ensituation und an die &#228;u&#223;eren 
Bedingungen, einschlie&#223;lich des Verhaltens anderer Fahrer, 
vor und leitet daraus das angenehmste und sicherste 
Fahrverhalten ab.
46 COM(2018) 237 final, S. 1: &#8222;K&#252;nstliche Intelligenz (KI) bezeichnet Systeme mit einem &#8222;intelligenten&#8220; Verhalten, die ihre 
Umgebung analysieren und mit einem gewissen Grad an Autonomie handeln, um bestimmte Ziele zu erreichen. 
KI-basierte Systeme k&#246;nnen rein softwaregest&#252;tzt in einer virtuellen Umgebung arbeiten (z. B. Sprachassistenten, 
Bildanalysesoftware, Suchmaschinen, Sprach- und Gesichtserkennungssysteme), aber auch in Hardware-Systeme 
eingebettet sein (z. B. moderne Roboter, autonome Pkw, Drohnen oder Anwendungen des &#8218;Internet der Dinge&#8216;).&#8220; 
47 Hochrangige Expertengruppe, Eine Definition der KI, S. 8: &#8222;K&#252;nstliche-Intelligenz-(KI)-Systeme sind vom Menschen 
entwickelte Software- (und m&#246;glicherweise auch Hardware-) Systeme, die in Bezug auf ein komplexes Ziel auf physischer 
oder digitaler Ebene agieren, indem sie ihre Umgebung durch Datenerfassung wahrnehmen, die gesammelten strukturierten 
oder unstrukturierten Daten interpretieren, Schlussfolgerungen daraus ziehen oder die aus diesen Daten abgeleiteten 
Informationen verarbeiten und &#252;ber die geeignete(n) Ma&#223;nahme(n) zur Erreichung des vorgegebenen Ziels entscheiden. KI-
Systeme k&#246;nnen entweder symbolische Regeln verwenden oder ein numerisches Modell erlernen, und sind auch in der Lage, 
die Auswirkungen ihrer fr&#252;heren Handlungen auf die Umgebung zu analysieren und ihr Verhalten entsprechend anzupassen.&#8220;
Die EU verf&#252;gt &#252;ber einen strengen Rechtsrahmen, um unter anderem den Verbraucherschutz zu 
gew&#228;hrleisten, gegen unlautere Gesch&#228;ftspraktiken vorzugehen und die personenbezogenen Daten und 
die Privatsph&#228;re der B&#252;rgerinnen und B&#252;rger zu sch&#252;tzen. Dar&#252;ber hinaus enth&#228;lt der Besitzstand 
spezifische Vorschriften f&#252;r einzelne Sektoren (z. B. Gesundheitswesen und Verkehr). Diese 
bestehenden EU-Rechtsvorschriften werden auch weiterhin f&#252;r KI gelten, allerdings sind 
m&#246;glicherweise bestimmte Aktualisierungen erforderlich, um dem digitalen Wandel und dem Einsatz 
von KI Rechnung zu tragen (siehe Abschnitt B). Folglich werden die Aspekte, die bereits durch 
bestehende horizontale oder sektorspezifische Rechtsvorschriften abgedeckt sind(z. B. in den 
Rechtsvorschriften &#252;ber Medizinprodukte 48  oder Verkehrssysteme), weiterhin durch diese 
Rechtsvorschriften geregelt.
Grunds&#228;tzlich sollte der neue Rechtsrahmen f&#252;r KI zielf&#252;hrend und nicht &#252;berm&#228;&#223;ig pr&#228;skriptiv sein&#8218; 
um zu vermeiden, dass er insbesondere f&#252;r KMU einen unverh&#228;ltnism&#228;&#223;igen Aufwand verursacht. Um 
dieses Gleichgewicht zu erreichen, sollte nach Ansicht der Kommission ein risikobasierter Ansatz 
verfolgt werden. 
Ein risikobasierter Ansatz ist wichtig, um die Verh&#228;ltnism&#228;&#223;igkeit des regulatorischen Eingreifens zu 
gew&#228;hrleisten. Allerdings bedarf es hier klarer Kriterien, um zwischen den verschiedenen KI-
Anwendungen differenzieren zu k&#246;nnen, insbesondere in Bezug auf die Frage, ob sie ein &#8222;hohes 
Risiko&#8220; darstellen oder nicht49. Es sollte f&#252;r alle Beteiligten klar und leicht verst&#228;ndlich sein, was unter 
einer unter einer KI-Anwendung mit hohem Risiko zu verstehen ist. Allerdings gelten auch f&#252;r KI-
Anwendungen, die nicht als Anwendung mit hohem Risiko eingestuft werden, uneingeschr&#228;nkt die 
bereits bestehenden EU-Vorschriften.
Die Kommission ist der Auffassung, dass bei der Einstufung einer KI-Anwendung als Anwendung mit 
hohem Risiko generell ber&#252;cksichtigt werden sollte, was auf dem Spiel steht, wobei zu pr&#252;fen ist, ob 
sowohl der Sektor als auch die beabsichtigte Verwendung erhebliche Risiken bergen, insbesondere 
unter den Gesichtspunkten Sicherheit, Verbraucherrechte und Grundrechte. Eine KI-Anwendung sollte 
insbesondere dann als Anwendung mit hohem Risiko angesehen werden, wenn sie die beiden 
folgenden Kriterien erf&#252;llt: 
&#8226; Erstens wird die KI-Anwendung in einem Sektor eingesetzt, in dem aufgrund der Art der 
typischen T&#228;tigkeiten mit erheblichen Risiken zu rechnen ist. Mit diesem ersten Kriterium 
wird sichergestellt, dass die regulatorischen Eingriffe auf diejenigen Bereiche ausgerichtet 
sind, in denen das Eintreten von Risiken generell am wahrscheinlichsten ist. Die betreffenden 
Sektoren sollten in dem neuen Rechtsrahmen ausdr&#252;cklich genannt und ersch&#246;pfend 
aufgelistet werden. Beispiele w&#228;ren hier die Sektoren Gesundheitswesen, Verkehr, Energie 
sowie Teile des &#246;ffentlichen Sektors 50 . Die Liste sollte regelm&#228;&#223;ig &#252;berpr&#252;ft und 
erforderlichenfalls entsprechend den einschl&#228;gigen Entwicklungen in der Praxis ge&#228;ndert 
werden;
48  So gibt es beispielsweise bei KI-Systemen unterschiedliche Sicherheitserw&#228;gungen und rechtliche Auswirkungen je 
nachdem, ob es sich um Systeme handelt, die fachspezifische medizinische Informationen f&#252;r &#196;rzte bereitstellen, Systeme, 
die medizinische Informationen direkt f&#252;r Patienten bereitstellen, oder um Systeme, die selbst medizinische Aufgaben direkt 
am Patienten ausf&#252;hren. Die Kommission untersucht zurzeit diese besonderen Herausforderungen, die sich speziell im 
Gesundheitswesen in Bezug auf Sicherheits- und Haftungsfragen stellen. 
49 In den EU-Rechtsvorschriften k&#246;nnen &#8222;Risiken&#8220; je nach dem betreffenden Bereich, z. B. Produktsicherheit, anders 
eingestuft werden als hier beschrieben. 
50 Der &#246;ffentliche Sektor k&#246;nnte Bereiche wie Asyl, Migration, Grenzkontrollen und Justizwesen, soziale Sicherheit und 
Arbeitsverwaltungen umfassen.
&#8226; Zweites Kriterium ist, ob die KI-Anwendung in dem betreffenden Sektor so eingesetzt wird, 
dass mit erheblichen Risiken zu rechnen ist. Dieses zweite Kriterium spiegelt die Erkenntnis 
wider, dass nicht jede Nutzung von KI in den ausgew&#228;hlten Sektoren notwendigerweise mit 
erheblichen Risiken verbunden ist. Hier kann das Gesundheitswesen im Allgemeinen zwar 
tats&#228;chlich ein relevanter Sektor sein, jedoch d&#252;rfte ein Fehler in einem 
Terminvereinbarungssystem eines Krankenhauses in der Regel keine so erheblichen Risiken 
mit sich bringen, dass ein gesetzgeberisches Eingreifen gerechtfertigt w&#228;re. Zur Bewertung 
des Risikos einer bestimmten Verwendung k&#246;nnten die Auswirkungen auf die betroffenen 
Parteien betrachtet werden. So k&#246;nnte zum Beispiel unterschieden werden zwischen KI-
Anwendungen, die rechtliche oder &#228;hnlich erhebliche Auswirkungen auf die Rechte einer 
nat&#252;rlichen Person oder eines Unternehmens haben k&#246;nnen, Anwendungen, von denen 
Verletzungs- oder Lebensgefahr oder die Gefahr eines erheblichen materiellen oder 
immateriellen Schadens ausgeht, und Anwendungen, deren Auswirkungen von nat&#252;rlichen 
oder juristischen Personen realistischerweise nicht vermieden werden k&#246;nnen.
Mit diesen beiden kumulativen Kriterien w&#252;rde sichergestellt, dass der Anwendungsbereich des 
Rechtsrahmens zielgerichtet ist und Rechtssicherheit bietet. Die verbindlichen Anforderungen des 
neuen Rechtsrahmens f&#252;r KI (s. u. Abschnitt D) w&#252;rden grunds&#228;tzlich nur f&#252;r diejenigen 
Anwendungen gelten, die nach diesen beiden kumulativen Kriterien als Anwendungen mit hohem 
Risiko eingestuft wurden. 
Ungeachtet der vorstehenden Ausf&#252;hrungen kann es auch Ausnahmef&#228;lle geben, in denen aufgrund 
der immanenten Risiken der Einsatz von KI-Anwendungen f&#252;r bestimmte Zwecke grunds&#228;tzlich &#8211; d. h. 
unabh&#228;ngig von dem betreffenden Sektor &#8211; als hochriskant einzustufen ist, und in denen die 
nachstehenden Anforderungen dennoch gelten w&#252;rden 51 . Zur Veranschaulichung k&#246;nnten 
insbesondere folgende &#220;berlegungen angestellt werden:
&#8226; Angesichts ihrer Bedeutung f&#252;r den Einzelnen und unter Ber&#252;cksichtigung des EU-Besitzstands 
zur Gleichbehandlung im Besch&#228;ftigungsbereich w&#252;rden KI-Anwendungen, die bei 
Einstellungsverfahren sowie in Situationen eingesetzt werden, die sich auf die Rechte von 
Arbeitnehmern auswirken, ausnahmslos als Anwendungen mit hohem Risiko eingestuft, sodass 
die nachstehenden Anforderungen stets gelten w&#252;rden. Ferner k&#246;nnten hier spezifische 
Anwendungen in Betracht gezogen werden, die Auswirkungen auf die Verbraucherrechte haben.
&#8226; Der Einsatz von KI-Anwendungen f&#252;r die Zwecke der biometrischen Fernidentifikation52 und 
anderer in die Privatsph&#228;re eingreifender &#220;berwachungstechnologien w&#252;rde ausnahmslos als 
mit hohem Risiko behaftet angesehen, sodass die nachstehenden Anforderungen stets gelten 
w&#252;rden.
51 Es sei darauf hingewiesen, dass auch andere EU-Rechtsvorschriften Anwendung finden k&#246;nnen. Beispielsweise kann in 
F&#228;llen, in denen KI in ein Verbraucherprodukt integriert ist, die Richtlinie &#252;ber die allgemeine Produktsicherheit gelten. 
52 Die biometrische Fernidentifikation ist von der biometrischen Authentifizierung zu unterscheiden (bei letzterer handelt es 
sich um einen Sicherheitsprozess, der sich auf die einzigartigen biologischen Merkmale einer Person st&#252;tzt, um deren 
Angaben zu ihrer Identit&#228;t zu &#252;berpr&#252;fen). Bei der biometrischen Fernidentifikation handelt es sich um ein Verfahren, bei 
dem die Identit&#228;t vieler Personen mithilfe biometrischer Identifikatoren (Fingerabdr&#252;cke, Gesicht, Iris, Gef&#228;&#223;muster usw.) 
aus der Ferne im &#246;ffentlichen Raum permanent durch Abgleich mit in einer Datenbank gespeicherten Daten ermittelt 
werden.
D. ARTEN VON ANFORDERUNGEN
Bei der Ausgestaltung des k&#252;nftigen Rechtsrahmens f&#252;r KI wird zu entscheiden sein, welche Arten 
verbindlicher rechtlicher Anforderungen den einschl&#228;gigen Akteuren auferlegt werden sollen. Diese 
Anforderungen k&#246;nnen durch Standards weiter spezifiziert werden. Wie in Abschnitt C ausgef&#252;hrt, 
und zus&#228;tzlich zu bereits bestehenden Rechtsvorschriften, w&#252;rden diese Anforderungen nur f&#252;r KI-
Anwendungen mit hohem Risiko gelten, wodurch sichergestellt w&#252;rde, dass regulatorische Eingriffe 
zielgerichtet und verh&#228;ltnism&#228;&#223;ig sind. 
Unter Ber&#252;cksichtigung der Leitlinien der Hochrangigen Expertengruppe und der vorstehenden 
Ausf&#252;hrungen k&#246;nnten sich die Anforderungen an KI-Anwendungen mit hohem Risiko auf die 
folgenden Schl&#252;sselmerkmale beziehen, die in den nachstehenden Unterabschnitten eingehender 
er&#246;rtert werden:
&#8226; Trainingsdaten 
&#8226; Aufbewahrung von Daten und Aufzeichnungen 
&#8226; Vorzulegende Informationen 
&#8226; Robustheit und Genauigkeit 
&#8226; Menschliche Aufsicht 
&#8226; besondere Anforderungen an bestimmte KI-Anwendungen, z. B. Anwendungen f&#252;r die 
biometrische Fernidentifikation.
Zur Gew&#228;hrleistung der Rechtssicherheit werden diese Anforderungen weiter zu spezifizieren sein, um 
klare Ma&#223;st&#228;be f&#252;r alle Akteure festzulegen, die sie erf&#252;llen m&#252;ssen.
a) Trainingsdaten  
Es ist wichtiger denn je, die Werte und Regeln der EU und insbesondere die Rechte, die den 
B&#252;rgerinnen und B&#252;rgern aus dem EU-Recht erwachsen, zu f&#246;rdern, zu st&#228;rken und zu verteidigen. 
Diese Bem&#252;hungen betreffen zweifellos auch die in der EU vermarkteten und verwendeten KI-
Anwendungen mit hohem Risiko, die hier betrachtet werden. 
Wie bereits erw&#228;hnt, gibt es ohne Daten keine KI. In vielen F&#228;llen h&#228;ngen die Funktionsweise vieler 
KI-Systeme und die Handlungsschritte und Entscheidungen, zu denen sie f&#252;hren k&#246;nnen, stark von 
den Daten ab, mit dem die Systeme trainiert wurden. Daher sollten geeignete Ma&#223;nahmen ergriffen 
werden, damit bei den Daten, die als Trainingsdaten f&#252;r KI-Systeme verwendet werden, die Werte und 
die Regeln der EU eingehalten werden, insbesondere was Sicherheitsfragen und die bestehenden 
Rechtsvorschriften zum Schutz der Grundrechte angeht. So k&#246;nnten f&#252;r die Trainingsdaten von KI-
Systemen folgende Anforderungen in Betracht gezogen werden: 
&#8226; Anforderungen, die hinreichend gew&#228;hrleisten, dass die anschlie&#223;ende Nutzung der KI-
gest&#252;tzten Produkte oder Dienstleistungen sicher ist, weil sie den Standards entspricht, die in 
den geltenden (bereits bestehenden und etwaigen erg&#228;nzenden) EU-Sicherheitsvorschriften 
festgelegt sind. Dies kann beispielsweise Anforderungen umfassen, durch die gew&#228;hrleistet 
wird, dass KI-Systeme anhand von Datens&#228;tzen trainiert werden, die alle Szenarien abdecken, 
die f&#252;r die Vermeidung gef&#228;hrlicher Situationen relevant sind.
&#8226; Ferner die Auflage, angemessene Ma&#223;nahmen zu ergreifen, um sicherzustellen, dass eine 
solche sp&#228;tere Nutzung von KI-Systemen nicht zu Ergebnissen f&#252;hrt, die eine verbotene 
Diskriminierung darstellen. Diese Auflagen k&#246;nnten insbesondere die Verpflichtung umfassen, 
Datens&#228;tze zu verwenden, die ausreichend repr&#228;sentativ sind. Damit soll vor allem 
sichergestellt werden, dass alle relevanten Aspekte wie Geschlecht, ethnische Zugeh&#246;rigkeit
Drucksache 95/20- 23 -
und andere m&#246;gliche Gr&#252;nde f&#252;r verbotene Diskriminierung in diesen Datens&#228;tzen 
angemessen ber&#252;cksichtigt werden;
&#8226; Auflagen, durch die sichergestellt werden soll, dass die Privatsph&#228;re und die 
personenbezogenen Daten bei der Nutzung von KI-gest&#252;tzten Produkten und Diensten 
angemessen gesch&#252;tzt werden. Die Aspekte, die in den Anwendungsbereich der Datenschutz-
Grundverordnung bzw. der Richtlinie &#252;ber den Datenschutz bei der Strafverfolgung fallen, 
werden durch die genannten Rechtsakte geregelt.
b) Aufbewahrung von Daten und Aufzeichnungen 
Unter Ber&#252;cksichtigung von Aspekten wie der Komplexit&#228;t und der Opazit&#228;t vieler KI-Systeme und 
der m&#246;glicherweise damit verbundenen Schwierigkeiten, die Einhaltung der geltenden Vorschriften 
wirksam zu &#252;berpr&#252;fen und durchzusetzen, m&#252;ssen Anforderungen formuliert werden, die f&#252;r die 
Aufbewahrung von Aufzeichnungen &#252;ber die Programmierung des Algorithmus und die f&#252;r KI-
Systeme mit hohem Risiko verwendeten Trainingsdaten sowie in bestimmten F&#228;llen die 
Aufbewahrung der Daten selbst gelten. Entsprechende Anforderungen erm&#246;glichen es in erster Linie, 
potenziell problematische Handlungen oder Entscheidungen von KI-Systemen zur&#252;ckzuverfolgen und 
zu &#252;berpr&#252;fen. Dies d&#252;rfte nicht nur die &#220;berwachung und Durchsetzung erleichtern, sondern auch 
st&#228;rkere Anreize f&#252;r die betreffenden Wirtschaftsteilnehmer bieten, zu einem fr&#252;hen Zeitpunkt zu 
ber&#252;cksichtigen, dass diese Vorschriften eingehalten werden m&#252;ssen. 
Zu diesem Zweck k&#246;nnte in dem Rechtsrahmen die Pflicht vorgesehen werden, Folgendes 
aufzubewahren:
&#8226; genaue Aufzeichnungen zu den f&#252;r das Training und die Erprobung der KI-Systeme 
verwendeten Datens&#228;tze, einschlie&#223;lich einer Beschreibung der wichtigsten Merkmale und der 
Art und Weise, wie die Datens&#228;tze ausgew&#228;hlt wurden;
&#8226; in bestimmten begr&#252;ndeten F&#228;llen die Datens&#228;tze selbst;
&#8226; Dokumentation der f&#252;r Programmierung 53  und Training verwendeten Methoden, der f&#252;r 
Aufbau, Erprobung und Validierung der KI-Systeme eingesetzten Verfahren und Techniken, 
ggf. unter Beachtung von Sicherheitsanforderungen und unter Vermeidung von Verzerrungen, 
die zu verbotenen Diskriminierungen f&#252;hren k&#246;nnten. 
Um eine wirksame Durchsetzung der einschl&#228;gigen Rechtsvorschriften zu gew&#228;hrleisten, m&#252;ssten die 
Aufzeichnungen, die Dokumentation und gegebenenfalls die Datens&#228;tze w&#228;hrend eines begrenzten, 
angemessenen Zeitraums aufbewahrt werden. Es sollten Ma&#223;nahmen getroffen werden, um 
sicherzustellen, dass sie auf Anfrage zur Verf&#252;gung gestellt werden, insbesondere f&#252;r Pr&#252;fungen oder 
Inspektionen durch zust&#228;ndige Beh&#246;rden. Erforderlichenfalls sollten Vorkehrungen getroffen werden, 
um sicherzustellen, dass vertrauliche Informationen wie Gesch&#228;ftsgeheimnisse gesch&#252;tzt werden.
c) Bereitstellung von Informationen 
Transparenz ist auch &#252;ber die unter Buchstabe c genannten Aufzeichnungspflichten hinaus 
erforderlich. Um die angestrebten Ziele zu erreichen &#8211; insbesondere die F&#246;rderung eines 
verantwortungsvollen Einsatzes von KI, die Schaffung von Vertrauen und die Gew&#228;hrleistung eines
53 Beispielsweise Dokumentation zum Algorithmus, einschlie&#223;lich Angaben dazu, wof&#252;r das Modell optimiert werden soll, 
welche Gewichtung zu Beginn bestimmten Parametern zugemessen wurde usw.
geeigneten Rechtsschutzes &#8211;, ist es wichtig, dass proaktiv angemessene Informationen &#252;ber den 
Einsatz von KI-Systemen mit hohem Risiko bereitgestellt werden.
Daher k&#246;nnten folgende Anforderungen in Betracht gezogen werden: 
&#8226; Vorlage eindeutiger Angaben &#252;ber die F&#228;higkeiten und Grenzen des KI-Systems, insbesondere 
&#252;ber den Zweck, f&#252;r den die Systeme bestimmt sind, die Bedingungen, unter denen davon 
ausgegangen werden kann, dass sie bestimmungsgem&#228;&#223; funktionieren, und &#252;ber das erwartete 
Ma&#223; an Genauigkeit bei der Erreichung des angegebenen Zwecks. Diese Angaben sind 
insbesondere f&#252;r die Betreiber der Systeme wichtig, k&#246;nnen aber auch f&#252;r die zust&#228;ndigen 
Beh&#246;rden und die betroffenen Parteien relevant sein.
&#8226; Abgesehen davon sollten B&#252;rgerinnen und B&#252;rger klar und deutlich darauf hingewiesen 
werden, wenn sie mit einem KI-System interagieren, und nicht mit einem Menschen. Die 
Datenschutzvorschriften der EU enthalten zwar bereits eine Reihe entsprechender Regeln54&#8218; 
doch k&#246;nnen zus&#228;tzliche Anforderungen erforderlich sein, um die oben genannten Ziele zu 
erreichen. Dabei sollte unn&#246;tiger Aufwand vermieden werden. Daher ist m&#252;ssen solche 
Angaben beispielsweise dann nicht bereitgestellt werden, wenn f&#252;r die B&#252;rgerinnen und 
B&#252;rger unmittelbar ersichtlich ist, dass sie mit KI-Systemen interagieren. Dar&#252;ber hinaus ist es 
wichtig, dass die bereitgestellten Informationen objektiv, kurzgefasst und leicht verst&#228;ndlich 
sind. Wie diese Informationen bereitzustellen sind, sollte sich nach dem jeweiligen Kontext 
richten. 
d) Robustheit und Genauigkeit 
KI-Systeme &#8211; und dies gilt in besonderem Ma&#223;e f&#252;r KI-Anwendungen mit hohem Risiko &#8211; m&#252;ssen 
technisch solide und pr&#228;zise sein, um vertrauensw&#252;rdig zu sein. Dies bedeutet, dass solche Systeme 
verantwortungsvoll und nach geb&#252;hrender Vorabbewertung der von ihnen m&#246;glicherweise 
ausgehenden Risiken entwickelt werden m&#252;ssen. Bei ihrer Entwicklung und Funktionsweise muss 
gew&#228;hrleistet werden, dass KI-Systeme sich zuverl&#228;ssig gem&#228;&#223; ihrem beabsichtigten 
Verwendungszweck verhalten. Dabei sollten alle zumutbaren Ma&#223;nahmen ergriffen werden, um das 
Risiko etwaiger Sch&#228;den so gering wie m&#246;glich zu halten.
Daher k&#246;nnten folgende Aspekte in Betracht gezogen werden: 
&#8226; Anforderungen, die gew&#228;hrleisten, dass die KI-Systeme in allen Phasen ihres Lebenszyklus 
robust und genau sind oder zumindest ihren Genauigkeitsgrad korrekt wiedergeben; 
&#8226; Anforderungen, die gew&#228;hrleisten, dass die Ergebnisse reproduzierbar sind; 
&#8226; Anforderungen, die gew&#228;hrleisten, dass KI-Systeme in allen Phasen ihre Lebenszyklus Fehler 
und Unstimmigkeiten angemessen bew&#228;ltigen k&#246;nnen.
54 Insbesondere m&#252;ssen nach Artikel 13 Absatz 2 Buchstabe f DSGVO die f&#252;r die Verarbeitung Verantwortlichen zum 
Zeitpunkt der Erhebung der personenbezogenen Daten den betroffenen Personen weitere Informationen &#252;ber das Bestehen 
einer automatisierten Entscheidungsfindung sowie bestimmte zus&#228;tzliche Informationen zur Verf&#252;gung stellen, die 
notwendig sind, um eine faire und transparente Verarbeitung zu gew&#228;hrleisten.
&#8226; Anforderungen, die gew&#228;hrleisten, dass KI-Systeme sowohl gegen offene Angriffe als auch 
gegen subtilere Versuche, Daten oder die Algorithmen selbst zu manipulieren, 
widerstandsf&#228;hig sind und dass in solchen F&#228;llen Abhilfema&#223;nahmen ergriffen werden.
e) Menschliche Aufsicht 
Die menschliche Aufsicht hilft, daf&#252;r zu sorgen, dass ein KI-System die menschliche Autonomie nicht 
untergr&#228;bt oder sich sonst nachteilig auswirkt. Das Ziel einer vertrauensw&#252;rdigen, ethischen und auf 
den Menschen ausgerichteten KI kann nur erreicht werden, wenn daf&#252;r gesorgt wird, dass Menschen 
bei KI-Anwendungen mit hohem Risiko geb&#252;hrend mitwirken.
Zwar werden die KI-Anwendungen, f&#252;r die in diesem Wei&#223;buch spezifische rechtliche Regelungen in 
Betracht gezogen werden, ausnahmslos als Anwendungen mit hohem Risiko angesehen, die jeweils 
geeignete Art und der angemessene Grad der menschlichen Aufsicht k&#246;nnen jedoch von Fall zu Fall 
variieren. Dies wird insbesondere von der beabsichtigten Nutzung der Systeme und den Auswirkungen 
abh&#228;ngen, die die Nutzung auf die betroffenen B&#252;rgerinnen und B&#252;rger und juristischen Personen 
haben k&#246;nnte. Ferner ber&#252;hrt dies auch nicht die in der DSGVO festgelegten Rechte, die greifen, wenn 
das KI-System personenbezogene Daten verarbeitet. Beispielsweise k&#246;nnte die menschliche Aufsicht 
u. a. auf folgendem Wege ausge&#252;bt werden:
&#8226; die Ergebnisse des KI-Systems werden erst dann wirksam, wenn sie zuvor von einem 
Menschen &#252;berpr&#252;ft und validiert wurden (z. B. kann die Ablehnung eines Antrags auf 
Sozialleistungen nur durch einen Menschen erfolgen);
&#8226; die Ergebnisse des KI-Systems werden sofort wirksam, aber menschliches Eingreifen wird in 
einem sp&#228;teren Schritt sichergestellt (z. B. kann die Ablehnung eines Antrags auf eine 
Kreditkarte von einem KI-System bearbeitet werden, doch muss sp&#228;ter eine &#220;berpr&#252;fung 
durch den Menschen m&#246;glich sein);
&#8226; &#220;berwachung des KI-Systems w&#228;hrend seines Betriebs und M&#246;glichkeit, in Echtzeit 
einzugreifen und das System ggf. zu deaktivieren (z. B. verf&#252;gt ein fahrerloses Fahrzeug &#252;ber 
eine Stopptaste oder einen Mechanismus, der aktiviert werden kann, wenn ein Mensch 
feststellt, dass der Fahrbetrieb nicht sicher ist);
&#8226; in der Entwurfsphase, indem Einschr&#228;nkungen f&#252;r den Betrieb des KI-Systems auferlegt 
werden (z. B. muss ein fahrerloses Fahrzeug unter bestimmten Bedingungen bei geringer Sicht 
den Betrieb einstellen, da in diesem Fall die Sensoren m&#246;glicherweise weniger zuverl&#228;ssig 
sind, oder es muss unter allen Umst&#228;nden einen vorgegebenen Abstand vom vorausfahrenden 
Fahrzeug einhalten).
f) Besondere Anforderungen an Systeme f&#252;r biometrische Fernidentifikation 
Die Erfassung und Auswertung biometrischer Daten 55  zum Zweck der Fernidentifikation 56 , 
beispielsweise durch Einsatz von Gesichtserkennungstechnik im &#246;ffentlichen Raum birgt besondere
55 Biometrische Daten werden definiert als &#8222;mit speziellen technischen Verfahren gewonnene personenbezogene Daten zu 
den physischen, physiologischen oder verhaltenstypischen Merkmalen einer nat&#252;rlichen Person, die die eindeutige 
Authentifizierung oder Identifizierung dieser nat&#252;rlichen Person erm&#246;glichen oder best&#228;tigen, wie Gesichtsbilder oder 
daktyloskopische [Fingerabdruck-] Daten&#8220;. (Richtlinie zum Datenschutz bei der Strafverfolgung, Artikel 3 Absatz 13; 
DSGVO, Artikel 4 Absatz 14; Verordnung (EU) 2018/1725, Artikel 3 Absatz 18).
Risiken in Bezug auf die Achtung der Grundrechte57. Im Hinblick auf das Ausma&#223;, in dem sich der 
Einsatz biometrischer Fernidentifikationssysteme auf die Grundrechte auswirkt, gibt es je nach Zweck, 
Kontext und Umfang des Einsatzes gro&#223;e Unterschiede.
Die Verarbeitung biometrischer Daten zum Zwecke der eindeutigen Identifizierung nat&#252;rlicher 
Personen ist nach den Datenschutzvorschriften der EU au&#223;er unter bestimmten Bedingungen 
grunds&#228;tzlich verboten58. Insbesondere darf eine solche Verarbeitung nach der DSGVO nur auf Basis 
einer begrenzten Zahl von Gr&#252;nden erfolgen, typischerweise aus Gr&#252;nden eines wichtigen &#246;ffentlichen 
Interesses. In diesem Fall muss die Verarbeitung auf der Grundlage der Rechtsvorschriften der EU 
oder nationaler Rechtsvorschriften erfolgen, wobei die Anforderungen an die Verh&#228;ltnism&#228;&#223;igkeit, die 
Achtung des Wesensgehalts des Rechts auf Datenschutz und geeignete Garantien einzuhalten sind. 
Gem&#228;&#223; der Richtlinie zum Datenschutz bei der Strafverfolgung muss f&#252;r eine solche Verarbeitung eine 
unbedingte Erforderlichkeit vorliegen, sowie ferner im Prinzip eine Genehmigung nach EU-Recht 
oder nationalem Recht sowie geeignete Garantien. Da jegliche Verarbeitung biometrischer Daten zum 
Zwecke der eindeutigen Identifizierung einer nat&#252;rlichen Person eine Ausnahme von einem im EU-
Recht verankerten Verbot erfordern w&#252;rde, w&#252;rde sie der Charta der Grundrechte der EU unterliegen. 
Daraus folgt, dass nach den geltenden Datenschutzvorschriften der EU und der Charta der 
Grundrechte KI nur dann f&#252;r die Zwecke der biometrischen Fernidentifikation eingesetzt werden darf, 
wenn der betreffende Einsatz hinreichend begr&#252;ndet und verh&#228;ltnism&#228;&#223;ig ist und geeignete Garantien 
gew&#228;hrleistet sind.  
Um m&#246;glichen gesellschaftlichen Bedenken im Zusammenhang mit der Nutzung von KI zu solchen 
Zwecken im &#246;ffentlichen Raum Rechnung zu tragen und eine Fragmentierung des Binnenmarkts zu 
vermeiden, wird die Kommission eine breit angelegte europ&#228;ische Debatte &#252;ber die besonderen 
Umst&#228;nde, die eine solche Nutzung rechtfertigen k&#246;nnten, sowie &#252;ber gemeinsame 
Sicherheitsvorkehrungen einleiten. 
E. ADRESSATEN
In Bezug auf die Adressaten der rechtlichen Auflagen, die f&#252;r die oben genannten KI-Anwendungen 
mit hohem Risiko gelten w&#252;rden, sind im Wesentlichen zwei Fragen zu pr&#252;fen. 
Erstens stellt sich die Frage, wie die Verpflichtungen auf die beteiligten Wirtschaftsteilnehmer 
aufgeteilt werden sollten. Im Lebenszyklus eines KI-Systems sind viele Akteure beteiligt. Hierzu 
geh&#246;ren der Entwickler, der Betreiber (die Person, die ein KI-gest&#252;tztes Produkt oder eine KI-gest&#252;tzte
56 Im Zusammenhang mit der Gesichtserkennung bedeutet Identifizierung, dass das Muster des Gesichtsbilds einer Person 
mit vielen anderen in einer Datenbank gespeicherten Mustern verglichen wird, um herauszufinden, ob ihr Bild dort 
gespeichert ist. Authentifizierung (oder Verifizierung) wiederum wird h&#228;ufig als 1:1-Vergleich bezeichnet. Es erm&#246;glicht den 
Vergleich zweier biometrischer Templates, von denen in der Regel angenommen wird, dass sie derselben Person zuzuordnen 
sind. Es werden zwei biometrische Templates miteinander verglichen, um festzustellen, ob es sich bei den Personen auf den 
beiden Bildern um dieselbe Person handelt. Ein solches Verfahren wird beispielsweise an den f&#252;r Grenz&#252;bertrittskontrollen 
an Flugh&#228;fen verwendeten Sicherheitsschleusen des automatischen Grenzkontrollsystems (ABC) angewandt. 
57 Zum Beispiel in Bezug auf die W&#252;rde der Menschen. Bei der Nutzung von Gesichtserkennungstechnik wiederum geht es 
in Bezug auf Grundrechtefragen vor allem um das Recht auf Achtung des Privatlebens und den Schutz personenbezogener 
Daten. Ferner gibt es auch potenzielle Auswirkungen im Bereich der Nichtdiskriminierung und der Rechte bestimmter 
Gruppen wie Kinder, &#228;ltere Menschen und Menschen mit Behinderungen. Dar&#252;ber hinaus darf die Meinungs-, Vereinigungs- 
und Versammlungsfreiheit nicht durch den Einsatz der Technologie untergraben werden. Siehe: Facial recognition 
technology: fundamental rights considerations in the context of law enforcement (Gesichtserkennungstechnik: &#220;berlegungen 
zu den Grundrechten im Kontext der Strafverfolgung). https://fra.europa.eu/en/publication/2019/facial-recognition. 
58 Artikel 9 DSGVO, Artikel 10 der Richtlinie zum Datenschutz bei der Strafverfolgung. Siehe auch Artikel 10 der 
Verordnung (EU) Nr. 2018/1725 (gilt f&#252;r die Organe und Einrichtungen der EU).
Dienstleistung nutzt) und m&#246;glicherweise weitere Akteure (Hersteller, H&#228;ndler oder Importeur, 
Dienstleister, professioneller oder privater Nutzer).
Nach Auffassung der Kommission sollten in einem k&#252;nftigen Rechtsrahmen die einzelnen 
Verpflichtungen jeweils dem Akteur/den Akteuren obliegen, der/die am besten in der Lage ist/sind, 
potenzielle Risiken zu bew&#228;ltigen. So w&#228;ren m&#246;glicherweise die Entwickler von KI am besten in der 
Lage, den Risiken zu begegnen, die sich aus der Entwicklungsphase ergeben, w&#228;hrend ihre F&#228;higkeit, 
die Risiken in der Nutzungsphase zu kontrollieren, eher eingeschr&#228;nkt w&#228;re. In diesem Fall sollte die 
entsprechende Verpflichtung dem Betreiber auferlegt werden. Dies gilt unbeschadet der Frage, welche 
Partei im Hinblick auf die Haftung gegen&#252;ber Endnutzern oder anderen Gesch&#228;digten und zur 
Gew&#228;hrleistung eines wirksamen Zugangs zu den Gerichten f&#252;r Sch&#228;den haftbar gemacht werden 
sollte. Nach dem EU-Produkthaftungsrecht obliegt die Haftung f&#252;r fehlerhafte Produkte dem 
Hersteller, unbeschadet nationaler Rechtsvorschriften, die auch die Geltendmachung von 
Schadensersatzanspr&#252;chen gegen&#252;ber anderen Parteien zulassen k&#246;nnen. 
Zweitens stellt sich die Frage nach dem geografischen Anwendungsbereich der Rechtsvorschriften. 
Nach Ansicht der Kommission ist es von entscheidender Bedeutung, dass die Auflagen f&#252;r alle 
einschl&#228;gigen Wirtschaftsteilnehmer gelten, die KI-gest&#252;tzte Produkte oder Dienstleistungen in der 
EU anbieten, unabh&#228;ngig davon, ob sie in der EU niedergelassen sind oder nicht. Andernfalls k&#246;nnten 
die oben genannten Ziele der gesetzgeberischen Ma&#223;nahmen nicht vollst&#228;ndig erreicht werden.
F. EINHALTUNG UND DURCHSETZUNG
Um sicherzustellen, dass KI vertrauensw&#252;rdig und sicher ist und dass dabei die Achtung der 
europ&#228;ischen Werte und Vorschriften gew&#228;hrleistet ist, m&#252;ssen die geltenden rechtlichen 
Anforderungen in der Praxis eingehalten und sowohl von den zust&#228;ndigen nationalen und 
europ&#228;ischen Beh&#246;rden als auch von den betroffenen Parteien wirksam durchgesetzt werden. Die 
zust&#228;ndigen Beh&#246;rden sollten in der Lage sein, Einzelf&#228;lle zu untersuchen, aber auch die 
Auswirkungen auf die Gesellschaft zu bewerten.
Angesichts des hohen Risikos, das bestimmte KI-Anwendungen f&#252;r die B&#252;rgerinnen und B&#252;rger und 
f&#252;r unsere Gesellschaft insgesamt darstellen (siehe Abschnitt A), ist die Kommission zum 
gegenw&#228;rtigen Zeitpunkt der Auffassung, dass eine objektive, vorab vorzunehmende 
Konformit&#228;tsbewertung erforderlich w&#228;re, um zu &#252;berpr&#252;fen und sicherzustellen, dass bestimmte der 
oben genannten obligatorischen Auflagen f&#252;r Anwendungen mit hohem Risiko (siehe Abschnitt D) 
erf&#252;llt sind. Eine vorab vorzunehmende Konformit&#228;tsbewertung k&#246;nnte Verfahren f&#252;r die Pr&#252;fung, 
Inspektion oder Zertifizierung umfassen59. Dies k&#246;nnte eine &#220;berpr&#252;fung der Algorithmen und der in 
der Entwicklungsphase verwendeten Datens&#228;tze beinhalten. 
Die Konformit&#228;tsbewertungen f&#252;r KI-Anwendungen mit hohem Risiko sollten Teil der 
Konformit&#228;tsbewertungsmechanismen sein, die es bereits f&#252;r eine gro&#223;e Zahl von Produkten gibt, die 
auf dem EU-Binnenmarkt in Verkehr gebracht werden. Kann nicht auf solche bestehenden 
Mechanismen zur&#252;ckgegriffen werden, m&#252;ssen unter Umst&#228;nden &#228;hnliche Mechanismen eingerichtet 
werden, die sich auf bew&#228;hrte Verfahren und m&#246;gliche Beitr&#228;ge von Interessentr&#228;gern und 
europ&#228;ischen Normungsorganisationen st&#252;tzen. Etwaige neue Mechanismen sollten verh&#228;ltnism&#228;&#223;ig
59 Das System w&#252;rde sich auf die bestehenden Konformit&#228;tsbewertungsverfahren in der EU (vgl. Beschluss 768/2008/EG) 
oder auf die Verordnung (EU) 2019/881 (Rechtsakt zur Cybersicherheit) st&#252;tzen und den Besonderheiten der KI Rechnung 
tragen. Siehe den Leitfaden f&#252;r die Umsetzung der Produktvorschriften der EU 2014 (&#8222;Blue Guide&#8220;).
sein, nicht diskriminieren und transparente und objektive Kriterien zugrunde legen, die im Einklang 
mit internationalen Verpflichtungen stehen.
Bei der Konzeption und Umsetzung eines Systems, das sich auf vorab vorzunehmende 
Konformit&#228;tsbewertungen st&#252;tzt, sollte insbesondere Folgendes ber&#252;cksichtigt werden:
&#8226; M&#246;glicherweise sind nicht alle oben genannten Anforderungen f&#252;r eine &#220;berpr&#252;fung im 
Rahmen einer vorab vorzunehmenden Konformit&#228;tsbewertung geeignet. So ist beispielsweise 
die Anforderung zu den vorzulegenden Informationen im Allgemeinen nicht f&#252;r eine 
&#220;berpr&#252;fung im Rahmen einer solchen Bewertung geeignet.
&#8226; Besonders zu ber&#252;cksichtigen ist die M&#246;glichkeit, dass sich bestimmte KI-Systeme 
weiterentwickeln und lernf&#228;hig sind, was m&#246;glicherweise wiederholte Bewertungen w&#228;hrend 
der Lebensdauer der betreffenden KI-Systeme erforderlich macht.
&#8226; Die Notwendigkeit, die Trainingsdaten und die f&#252;r Programmierung und Training 
verwendeten Methoden, Prozesse und Techniken, welche f&#252;r Aufbau, Erprobung und 
Validierung der KI-Systeme eingesetzt wurden, zu &#252;berpr&#252;fen.
&#8226; Ergibt die Konformit&#228;tsbewertung, dass ein KI-System die Anforderungen nicht erf&#252;llt, z. B. 
in Bezug auf die verwendeten Trainingsdaten, m&#252;ssen die festgestellten M&#228;ngel behoben 
werden, indem beispielsweise das System in der EU so nachtrainiert wird, dass alle geltenden 
Anforderungen erf&#252;llt werden. 
Die Konformit&#228;tsbewertung w&#228;re f&#252;r alle Wirtschaftsteilnehmer, f&#252;r die die Anforderungen gelten, 
unabh&#228;ngig vom Ort ihrer Niederlassung obligatorisch60. Um den Verwaltungsaufwand f&#252;r KMU zu 
begrenzen, k&#246;nnten Unterst&#252;tzungsstrukturen unter anderem im Rahmen von digitalen 
Innovationszentren in Betracht gezogen werden. Dar&#252;ber hinaus k&#246;nnten Standards und spezielle 
Online-Instrumente die Einhaltung der Vorschriften erleichtern. 
Die vorab vorzunehmenden Konformit&#228;tsbewertungen sollten die &#220;berwachung der Einhaltung der 
Vorschriften und die nachtr&#228;gliche Durchsetzung durch die zust&#228;ndigen nationalen Beh&#246;rden nicht 
ber&#252;hren. Dies gilt f&#252;r KI-Anwendungen mit hohem Risiko, aber auch f&#252;r andere KI-Anwendungen, 
die rechtlichen Anforderungen unterliegen; allerdings kann die Tatsache, dass eine Anwendung mit 
einem hohem Risiko behaftet ist, f&#252;r die zust&#228;ndigen nationalen Beh&#246;rden Anlass sein, dieser 
besondere Aufmerksamkeit zu schenken. Ex-post-Kontrollen sollten durch eine angemessene 
Dokumentation der entsprechenden AI-Anwendung erm&#246;glicht werden (siehe Abschnitt E) sowie 
gegebenenfalls durch die M&#246;glichkeit f&#252;r Dritte, z. B. zust&#228;ndige Beh&#246;rden, solche Anwendungen zu 
testen. Dies kann besonders wichtig sein, wenn Risiken f&#252;r die Grundrechte entstehen, da diese 
kontextabh&#228;ngig sind. Eine solche &#220;berwachung der Einhaltung der Vorschriften sollte Teil eines 
kontinuierlichen Markt&#252;berwachungssystems sein. Aspekte im Zusammenhang mit der Governance 
werden in Abschnitt H weiter unten er&#246;rtert.
Dar&#252;ber hinaus sollten sowohl f&#252;r KI-Anwendungen mit hohem Risiko als auch f&#252;r andere KI-
Anwendungen wirksame Rechtsbehelfe f&#252;r Parteien vorgesehen werden, die von negativen 
Auswirkungen von KI-Systemen betroffen sind. Fragen, die sich auf haftungsrelevante Aspekte
60 Zu der einschl&#228;gigen Governance-Struktur, einschlie&#223;lich der f&#252;r die Durchf&#252;hrung der Konformit&#228;tsbewertungen 
benannten Stellen, siehe Abschnitt H.
beziehen, werden im Bericht &#252;ber den Sicherheits- und Haftungsrahmen, der zusammen mit diesem 
Wei&#223;buch vorgelegt wird, weiter er&#246;rtert.
G. FREIWILLIGE KENNZEICHNUNG F&#220;R KI-ANWENDUNGEN OHNE HOHES RISIKO
F&#252;r KI-Anwendungen, die nicht als Anwendungen &#8222;mit hohem Risiko&#8220; eingestuft werden (siehe 
Abschnitt C) und f&#252;r die daher nicht die oben er&#246;rterten obligatorischen Anforderungen gelten (siehe 
Abschnitte D, E und F), w&#228;re eine Option, neben den geltenden Rechtsvorschriften ein freiwilliges 
Kennzeichnungssystem einzuf&#252;hren.
Im Rahmen des Systems k&#246;nnten interessierte Wirtschaftsteilnehmer, die nicht den obligatorischen 
Auflagen unterliegen, sich freiwillig f&#252;r die Einhaltung dieser Auflagen oder eine Reihe &#228;hnlicher 
Anforderungen, die speziell f&#252;r die Zwecke des freiwilligen Systems festgelegt wurden, entscheiden. 
Die KI-Anwendungen der betreffenden Wirtschaftsteilnehmer w&#252;rden dann ein G&#252;tesiegel erhalten. 
Mit dem freiwilligen G&#252;tesiegel k&#246;nnten diese Wirtschaftsakteuren signalisieren, dass ihre KI-
gest&#252;tzten Produkte und Dienstleistungen vertrauensw&#252;rdig sind. So k&#246;nnten Nutzer leicht erkennen, 
dass die betreffenden Produkte und Dienstleistungen bestimmte objektive und standardisierte EU-
weite Vorgaben erf&#252;llen, die &#252;ber die normalerweise geltenden rechtlichen Verpflichtungen 
hinausgehen. Dies w&#252;rde dazu beitragen, das Vertrauen der Nutzer in KI-Systeme zu st&#228;rken und die 
allgemeine Akzeptanz dieser Technologie zu f&#246;rdern. 
Diese Option w&#252;rde die Schaffung eines neuen Rechtsinstruments erfordern, in dem ein Rahmen f&#252;r 
die freiwillige Kennzeichnung f&#252;r Entwickler und/oder Betreiber von KI-Systemen festgelegt wird, die 
nicht als Anwendungen mit hohem Risiko eingestuft sind. Die Teilnahme am Kennzeichnungssystem 
w&#228;re freiwillig, hat sich ein Entwickler oder Betreiber aber einmal f&#252;r die Verwendung des Labels 
entschieden, w&#228;ren die Anforderungen jedoch verbindlich. Durch die Kombination von Ex-ante-
Ma&#223;nahmen und Ex-Post-Durchsetzung m&#252;sste sichergestellt werden, dass alle Anforderungen erf&#252;llt 
werden. 
H. GOVERNANCE
Eine europ&#228;ische Governance-Struktur f&#252;r KI in Form eines Rahmens f&#252;r die Zusammenarbeit der 
zust&#228;ndigen nationalen Beh&#246;rden ist notwendig, um eine Aufsplitterung der Zust&#228;ndigkeiten zu 
vermeiden, die Kapazit&#228;ten in den Mitgliedstaaten auszubauen und sicherzustellen, dass Europa sich 
schrittweise mit der f&#252;r die Pr&#252;fung und Zertifizierung von KI-gest&#252;tzten Produkten und 
Dienstleistungen erforderlichen Kapazit&#228;ten ausstattet. In diesem Zusammenhang w&#228;re es von Vorteil, 
die zust&#228;ndigen nationalen Beh&#246;rden dabei zu unterst&#252;tzen, ihren Auftrag in Bezug auf die Nutzung 
von KI zu erf&#252;llen. 
Eine europ&#228;ische Governance-Struktur k&#246;nnte als Forum f&#252;r einen regelm&#228;&#223;igen Austausch von 
Informationen und bew&#228;hrten Verfahren mit einer Vielzahl von Aufgaben betraut werden, 
einschlie&#223;lich der Ermittlung neuer Trends und der Beratung in den Bereichen Normung und 
Zertifizierung. Sie sollte auch eine Schl&#252;sselrolle spielen, wenn es darum geht, die Umsetzung des 
Rechtsrahmens zu f&#246;rdern, beispielsweise durch die Herausgabe von Leitlinien, Stellungnahmen und 
die Bereitstellung von Fachwissen. Zu diesem Zweck sollte sie sich auf ein Netz nationaler Beh&#246;rden 
st&#252;tzen sowie auf sektorspezifische Netze und Regulierungsbeh&#246;rden auf nationaler und EU-Ebene. 
Dar&#252;ber hinaus k&#246;nnte ein Sachverst&#228;ndigenausschuss die Kommission unterst&#252;tzen. 
Die Governance-Struktur sollte eine gr&#246;&#223;tm&#246;gliche Beteiligung der Interessentr&#228;ger gew&#228;hrleisten. 
Die Interessentr&#228;ger &#8211; Verbraucherorganisationen und Sozialpartner, Unternehmen, Forscher und
Drucksache 95/20 - 30 -
Organisationen der Zivilgesellschaft &#8211; sollten zur Umsetzung und Weiterentwicklung des Rahmens 
konsultiert werden. 
Angesichts der bereits bestehenden Strukturen beispielsweise in den Bereichen Finanzen, Arzneimittel, 
Luftfahrt, Medizinprodukte, Verbraucherschutz und Datenschutz ist darauf zu achten, dass es bei der 
vorgeschlagenen Governance-Struktur keine &#220;berschneidungen mit bestehenden Funktionen gibt. 
Stattdessen sollten enge Beziehungen zu anderen zust&#228;ndigen Beh&#246;rden der EU und der 
Mitgliedstaaten in den verschiedenen Sektoren gekn&#252;pft werden, um das vorhandene Fachwissen zu 
erg&#228;nzen und die bestehenden Beh&#246;rden bei der &#220;berwachung und Beaufsichtigung der T&#228;tigkeiten 
der Wirtschaftsteilnehmer, die KI-Systeme und KI-gest&#252;tzte Produkte und Dienstleistungen einsetzen, 
zu unterst&#252;tzen. 
Wird diese Option tats&#228;chlich weiterverfolgt, k&#246;nnte die Durchf&#252;hrung von Konformit&#228;tsbewertungen 
den von den Mitgliedstaaten benannten benannten Stellen &#252;bertragen werden. Testzentren sollten die 
unabh&#228;ngige Pr&#252;fung und Bewertung von KI-Systemen gem&#228;&#223; den oben genannten Anforderungen 
erm&#246;glichen. Eine unabh&#228;ngige Bewertung wird das Vertrauen st&#228;rken und sorgt f&#252;r Objektivit&#228;t. Dies 
k&#246;nnte auch die Arbeit der jeweils zust&#228;ndigen Beh&#246;rden erleichtern. 
Die EU verf&#252;gt &#252;ber hervorragende Test- und Bewertungszentren und sollte ihre Kapazit&#228;ten auch im 
Bereich der KI ausbauen. Wirtschaftsteilnehmer mit Sitz in Drittl&#228;ndern, die in den Binnenmarkt 
eintreten wollen, k&#246;nnten sich entweder an benannte Stellen mit Sitz in der EU wenden oder &#8211; 
vorbehaltlich der Abkommen &#252;ber die gegenseitige Anerkennung mit Drittl&#228;ndern &#8211; Stellen aus 
Drittl&#228;ndern in Anspruch nehmen, die f&#252;r die Durchf&#252;hrung einer solchen Bewertung benannt wurden. 
Die Governance-Struktur f&#252;r den Bereich KI und die hier er&#246;rterten etwaigen 
Konformit&#228;tsbewertungen w&#252;rden die nach geltendem EU-Recht vorgesehenen Befugnisse und 
Zust&#228;ndigkeiten der jeweils zust&#228;ndigen Beh&#246;rden in einzelnen Sektoren oder bestimmten Bereichen 
(Finanzen, Arzneimittel, Luftfahrt, Medizinprodukte, Verbraucherschutz, Datenschutz usw.) unber&#252;hrt 
lassen. 
6. FAZIT
KI ist eine strategische Technologie, die viele Vorteile f&#252;r B&#252;rgerinnen und B&#252;rger, f&#252;r Unternehmen 
und die Gesellschaft insgesamt bietet, sofern sie auf den Menschen ausgerichtet, ethisch und 
nachhaltig ist und die Grundrechte und -werte achtet. KI bietet wichtige Effizienz- und 
Produktivit&#228;tsgewinne, die die Wettbewerbsf&#228;higkeit der europ&#228;ischen Industrie st&#228;rken und das 
Wohlergehen der B&#252;rger verbessern k&#246;nnen. Sie kann auch dazu beitragen, L&#246;sungen f&#252;r einige der 
dr&#228;ngendsten gesellschaftlichen Herausforderungen zu finden, darunter die Bek&#228;mpfung des 
Klimawandels und der Umweltzerst&#246;rung, die Herausforderungen im Zusammenhang mit der 
Nachhaltigkeit und dem demografischen Wandel, der Schutz unserer Demokratien und, soweit 
erforderlich und verh&#228;ltnism&#228;&#223;ig, die Kriminalit&#228;tsbek&#228;mpfung.
Damit Europa die Chancen, die die KI bietet, in vollem Umfang nutzen kann, muss es die 
erforderlichen industriellen und technologischen Kapazit&#228;ten entwickeln und st&#228;rken. Wie in der 
begleitenden europ&#228;ischen Datenstrategie dargelegt, erfordert dies auch Ma&#223;nahmen, die es der EU 
erm&#246;glichen, zu einem globalen Kotenpunkt f&#252;r Daten zu werden. 
Der europ&#228;ische Ansatz f&#252;r KI zielt darauf ab, die Innovationsf&#228;higkeit Europas im Bereich der KI zu 
f&#246;rdern und gleichzeitig die Entwicklung und Einf&#252;hrung ethischer und vertrauensw&#252;rdiger KI in der 
gesamten EU-Wirtschaft zu unterst&#252;tzen. KI sollte im Dienste der Menschen stehen und eine positive 
Kraft f&#252;r die Gesellschaft sein.
Drucksache 95/20- 31 -
Mit diesem Wei&#223;buch und dem begleitenden Bericht &#252;ber den Sicherheits- und Haftungsrahmen leitet 
die Kommission eine breit angelegte Konsultation der Zivilgesellschaft, der Industrie und der 
Wissenschaftskreise in den Mitgliedstaaten zu konkreten Vorschl&#228;gen f&#252;r ein europ&#228;isches KI-
Konzept ein. Dazu geh&#246;ren sowohl politische Mittel zur Ankurbelung von Investitionen in Forschung 
und Innovation, zur F&#246;rderung der Entwicklung von Kompetenzen und der Akzeptanz von KI durch 
KMU als auch Vorschl&#228;ge f&#252;r Schl&#252;sselelemente eines k&#252;nftigen Rechtsrahmens. Diese Konsultation 
wird einen umfassenden Dialog mit allen betroffenen Parteien erm&#246;glichen, der in die Gestaltung der 
n&#228;chsten Schritte der Kommission einflie&#223;en wird.
Die Kommission bittet um Stellungnahmen zu den im Wei&#223;buch enthaltenen Vorschl&#228;gen im 
Wege einer &#246;ffentlichen Konsultation, die in englischer Sprache verf&#252;gbar ist unter: 
https://ec.europa.eu/info/consultations_en. Stellungnahmen k&#246;nnen bis zum 19. Mai 2020 
&#252;bermittelt werden..
Die Beitr&#228;ge, die die Kommission im Rahmen einer &#246;ffentlichen Konsultation erh&#228;lt, werden in 
der Regel ver&#246;ffentlicht. Allerdings kann beantragt werden, dass Beitr&#228;ge oder Teile davon 
vertraulich behandelt werden. Geben Sie bitte gegebenenfalls auf dem Deckblatt Ihrer 
Stellungnahme klar und deutlich an, dass sie nicht ver&#246;ffentlicht werden soll. In diesem Fall 
&#252;bermitteln Sie bitte der Kommission gleichzeitig eine nichtvertrauliche Fassung der 
Stellungnahme zur Ver&#246;ffentlichung. 
Drucksache 95/20 - 32 -]</text>
    <titel>Wei&#223;buch der Kommission zur k&#252;nstlichen Intelligenz:
Ein europ&#228;isches Konzept f&#252;r Exzellenz und Vertrauen</titel>
    <datum>2020-02-20</datum>
  </document>
  