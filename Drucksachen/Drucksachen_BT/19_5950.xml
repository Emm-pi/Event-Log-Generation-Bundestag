<document>
    <id>224174</id>
    <drucksachetyp>Antrag</drucksachetyp>
    <dokumentart>Drucksache</dokumentart>
    <autoren_anzahl>18</autoren_anzahl>
    <typ>Dokument</typ>
    <vorgangsbezug_anzahl>1</vorgangsbezug_anzahl>
    <dokumentnummer>19/5950</dokumentnummer>
    <wahlperiode>19</wahlperiode>
    <herausgeber>BT</herausgeber>
    <pdf_hash>1024a54d1ecbc2962c76a9660ec8a337</pdf_hash>
    <aktualisiert>2022-07-26T19:57:15+02:00</aktualisiert>
    <vorgangsbezug>
      <id>241811</id>
      <titel>Netzwerkdurchsetzungsgesetz weiterentwickeln - Nutzerrechte st&#228;rken, Meinungsfreiheit in sozialen Netzwerken sicherstellen</titel>
      <vorgangstyp>Antrag</vorgangstyp>
    </vorgangsbezug>
    <urheber>
      <einbringer>false</einbringer>
      <bezeichnung>B90/GR</bezeichnung>
      <titel>Fraktion B&#220;NDNIS 90/DIE GR&#220;NEN</titel>
    </urheber>
    <fundstelle>
      <pdf_url>https://dserver.bundestag.de/btd/19/059/1905950.pdf</pdf_url>
      <id>224174</id>
      <dokumentnummer>19/5950</dokumentnummer>
      <datum>2018-11-22</datum>
      <dokumentart>Drucksache</dokumentart>
      <drucksachetyp>Antrag</drucksachetyp>
      <herausgeber>BT</herausgeber>
      <urheber>Fraktion B&#220;NDNIS 90/DIE GR&#220;NEN</urheber>
    </fundstelle>
    <autoren_anzeige>
      <id>36</id>
      <titel>Renate K&#252;nast, MdB, B&#220;NDNIS 90/DIE GR&#220;NEN</titel>
      <autor_titel>Renate K&#252;nast</autor_titel>
    </autoren_anzeige>
    <autoren_anzeige>
      <id>1191</id>
      <titel>Dr. Konstantin von Notz, MdB, B&#220;NDNIS 90/DIE GR&#220;NEN</titel>
      <autor_titel>Konstantin von Notz</autor_titel>
    </autoren_anzeige>
    <text>[Deutscher Bundestag Drucksache 19/5950 
19. Wahlperiode 22.11.2018 
 
Antrag 
der Abgeordneten Renate K&#252;nast, Dr. Konstantin von Notz, Tabea R&#246;&#223;ner, Margit 
Stumpp, Luise Amtsberg, Canan Bayram, Dr. Anna Christmann, Katja D&#246;rner, 
Britta Ha&#223;elmann, Dieter Janecek, Dr. Kirsten Kappert-Gonther, Katja Keul, 
Monika Lazar, Dr. Irene Mihalic, Filiz Polat, Dr. Manuela Rottmann, Ulle Schauws, 
Beate Walter-Rosenheimer und der Fraktion B&#220;NDNIS 90/DIE GR&#220;NEN 
Netzwerkdurchsetzungsgesetz weiterentwickeln &#8211; Nutzerrechte st&#228;rken, 
Meinungsfreiheit in sozialen Netzwerken sicherstellen 
Der Bundestag wolle beschlie&#223;en: 
I. Der Deutsche Bundestag stellt fest: 
Nach extrem kontroverser &#246;ffentlicher Debatte trat am 1. Oktober 2017 das Gesetz zur 
Verbesserung der Rechtsdurchsetzung in sozialen Netzwerken
(Netzwerkdurchsetzungsgesetz &#8211; NetzDG) in Kraft.  
Ziel des Gesetzes ist die Bek&#228;mpfung strafbarer Inhalte, vor allem von
&#196;u&#223;erungsdelikten, in sozialen Netzwerken. Das Gesetz richtet sich dabei ausschlie&#223;lich und damit 
verengend an Betreiber gro&#223;er Netzwerke, denen eine Reihe von sanktionsbewehrten 
Verpflichtungen bez&#252;glich ihres Kontroll- und Beschwerdemanagements auferlegt 
werden; insbesondere m&#252;ssen &#8222;offensichtlich rechtswidrige Inhalte&#8220; innerhalb von 24 
Stunden nach Eingang einer Beschwerde gel&#246;scht oder gesperrt werden.
Entsprechende Verfahren waren von den Betreibern bis zum 1. Januar 2018 einzuf&#252;hren.  
Die ersten im Gesetz vorgesehenen Transparenzberichte wurden im Juli 2018 von den 
betroffenen Unternehmen vorgelegt. Aufgrund mangelnder Vorgaben sind sie kaum 
vergleichbar und ihr Aussagewert ist daher stark begrenzt. Die Auswertung dieser
Berichte durch das zust&#228;ndige Bundesamt f&#252;r Justiz (BfJ) dauert an, eine Evaluierung des 
Netzwerkdurchsetzungsgesetzes ist nach Auskunft der Bundesregierung vor Ende 
2019 nicht zu erwarten. Unklar ist weiterhin auch, wer die Evaluierung auf welcher 
empirischen Grundlage und mit welchen konkreten Fragestellungen durchf&#252;hren soll. 
Fest steht bereits jetzt, dass das Gesetz durch die betroffenen Unternehmen
uneinheitlich umgesetzt wird und in der g&#252;ltigen Form M&#228;ngel aufweist, die es dringend zu 
beseitigen gilt.  
So fehlt beispielsweise bis heute ein die Meinungsfreiheit wahrendes Verfahren, mit 
dem zu Unrecht gel&#246;schte oder gesperrte Inhalte zeitnah wieder eingestellt werden. 
Genauso fehlt eine Clearingstelle f&#252;r Streitf&#228;lle. Einige Vorgaben des NetzDG sind so 
vage, dass sie von den Betreibern sozialer Netzwerke uneinheitlich und damit f&#252;r die 
Nutzerinnen und Nutzer unbefriedigend umgesetzt wurden: Meldewege sind teilweise 
noch immer sehr umst&#228;ndlich und schrecken Nutzerinnen und Nutzer teilweise ab, da 
sie meinen, juristische Vorkenntnisse haben zu m&#252;ssen, die Transparenzberichte der 
Betreiber sind von minderer G&#252;te und Empfangsbevollm&#228;chtigte bis heute nicht
&#252;berall eingesetzt oder nur schwer zu erreichen, wodurch es immer wieder zu Problemen
bei der notwendigen Zusammenarbeit von Diensteanbietern sozialer Netzwerke und 
Strafverfolgungsbeh&#246;rden kommt.  
Folglich muss das im parlamentarischen Schnellverfahren verabschiedete Gesetz so 
angepasst werden, dass Rechtssicherheit hergestellt wird und die bekannten M&#228;ngel 
bereits vor einer zeitintensiven Evaluation beseitigt werden. Das bekr&#228;ftigt auch der 
Beschluss der 89. Konferenz der Justizministerinnen und Justizminister der L&#228;nder. 
Dabei muss Regulierung breiter ansetzen, als lediglich unternehmerische
Verpflichtungen festzuschreiben. Sie muss der insgesamt ver&#228;nderten Diskussionskultur in der 
digitalen &#214;ffentlichkeit Rechnung tragen. So sind Regelungen erforderlich, die gegen 
die intransparente oder illegitime Beeinflussung der &#246;ffentlichen Willensbildung und 
den missbr&#228;uchlichen Einsatz sogenannter &#8222;social bots&#8220; wirken sowie zu einer
verbesserten IT-Sicherheit, einer h&#246;heren Souver&#228;nit&#228;t der Nutzerinnen und Nutzer
(Digitalkompetenzen) und zur St&#228;rkung &#246;ffentlicher Stellen wie Gerichte,
Staatsanwaltschaften, Polizei, Schulen und Beratungsstellen f&#252;hren (vgl. hierzu auch Antr&#228;ge der
Fraktion B&#220;NDNIS 90/DIE GR&#220;NEN: &#8222;Recht und Transparenz im Netz&#8220; vom 4. April 
2017 auf BT-Drs. 18/11856, &#8222;IT-Sicherheit st&#228;rken, Freiheit erhalten, Frieden sichern&#8220; 
vom 21. M&#228;rz 2018 auf BT-Drs. 19/1328 und &#8222;Faire digitale M&#228;rkte&#8220; vom 25. April 
2018 auf BT-Drs. 19/1852). 
Aufgrund der ausstehenden Evaluierung der ersten Transparenzberichte durch das BfJ 
bleibt ungekl&#228;rt, ob und inwieweit die M&#246;glichkeit eines sogenannten &#8222;Overblocking&#8220; 
tats&#228;chlich stattfindet oder nicht, also eine reale Gefahr ist oder nicht. Diensteanbieter 
k&#246;nnten sich veranlasst sehen, bei Zweifeln &#252;ber die Rechtswidrigkeit von Inhalten 
vorschnell eine L&#246;schung vorzunehmen, um dem Risiko zu entgehen, dass eine
Nichtl&#246;schung als Indiz f&#252;r die systemische Nichterf&#252;llung ihrer &#220;berwachungspflicht mit 
der Folge der Verh&#228;ngung hoher Bu&#223;gelder herangezogen wird. Es gilt darum,
Beschwerdemechanismen und eine Clearingstelle gegen ungerechtfertigte L&#246;schungen 
einzuf&#252;hren und eine Balance zwischen Pers&#246;nlichkeitsschutz und Meinungsfreiheit 
herzustellen. Im Rahmen der im Anwendungsbereich des NetzDG genannten
Straftatbest&#228;nde sind diffizile grundrechtliche Abw&#228;gungen erforderlich, so etwa zwischen 
dem Schutz von Pers&#246;nlichkeitsrechten und der durch Artikel 5 des Grundgesetzes 
gesch&#252;tzten Meinungs- und Informationsfreiheit. Dies darf nicht den Diensteanbietern 
allein &#252;berlassen sein, sondern bedarf im Streitfall effektiver gerichtlicher Kl&#228;rung. 
Zudem m&#252;ssen eine intransparente Beeinflussung demokratischer
Willensbildungsprozesse und die missbr&#228;uchliche Nutzung von &#8222;social bots&#8220; effektiv verhindert
werden. Dies erfordert unter anderem eine gesetzliche Verpflichtung zur Offenlegung
einer automatisch ausgel&#246;sten Kommunikation und Verbreitung von Inhalten durch
automatisierte Programme. Hierdurch soll eindeutig zu erkennen sein, ob Mensch oder 
Maschine agiert. 
Klar ist: Die Wahrung von Verantwortung, Freiheit und Recht im Netz bedarf
st&#228;ndiger Achtsamkeit sowie aktiven Engagements f&#252;r demokratischen Diskurs und
gegenseitigen Respekt. Dies setzt zun&#228;chst eine m&#246;glichst hohe Medienkompetenz aller
B&#252;rgerinnen und B&#252;rger voraus. Jede/r dritte InternetnutzerIn ist minderj&#228;hrig.
Gleichzeitig sind Kinder und Jugendliche besonders gef&#228;hrdet, Opfer von Hate Speech,
Cybermobbing oder Cybergrooming zu werden und dabei nachhaltig in ihrer
Entwicklung gest&#246;rt zu werden. Bedingt durch zunehmende Medienkonvergenz hat sich das 
Mediennutzungsverhalten von Kindern und Jugendlichen in den letzten Jahren massiv 
ver&#228;ndert. Unabh&#228;ngig von einem bestimmten Ort k&#246;nnen Kinder heute jederzeit
spielen, chatten, Bilder und Videos mit anderen teilen. &#220;ber das Social Web sind sie mit 
anderen Nutzerinnen und Nutzern &#8211; Bekannten und Unbekannten &#8211; verbunden und 
werden mit von ihnen verbreiteten Inhalten konfrontiert. Au&#223;erdem geben sie &#252;ber 
eigene Inhalte pers&#246;nliche Informationen von sich preis. Die Grenzen zwischen
virtueller und realer Welt verschwimmen, w&#228;hrend die M&#246;glichkeiten einer stetigen
Begleitung und Kontrolle durch Erziehungsberechtigte immer weniger gew&#228;hrleistet 
sind. Darum ist es erforderlich, ein digitales Umfeld zu schaffen, in dem sie Angebote
und Dienste kompetent und selbstbestimmt nutzen k&#246;nnen und vor m&#246;glichen Risiken 
gesch&#252;tzt sind. 
In einer Zeit, in der die unterschiedlichsten Akteure problemlos publizieren und
weiterverbreiten k&#246;nnen, ohne dass sichergestellt ist, dass Publiziertes durchweg
anerkannten journalistischen Sorgfaltspflichten entspricht, m&#252;ssen die F&#228;higkeit und die 
Bereitschaft gef&#246;rdert werden, Inhalte kritisch zu hinterfragen und bewusst verf&#228;lschte 
und pers&#246;nlichkeitsrechtsverletzende Nachrichten und Straftaten als solche zu
erkennen. Daher bleibt im digitalen Zeitalter der Erwerb von Medien- und
Datenschutzkompetenz &#8211; m&#246;glichst lebenslang &#8211; eine zentrale Herausforderung. Der Erwerb dieser 
Kompetenzen kann regulatorische Ma&#223;nahmen zum Schutz der Privatheit von
Kommunikation und digitaler Infrastrukturen sowie die notwendige Verbesserung der 
Rechtsdurchsetzung aber nicht ersetzen, sondern muss sie erg&#228;nzen. 
II. Der Deutsche Bundestag fordert die Bundesregierung auf,  
a. das Gesetz zur Verbesserung der Rechtsdurchsetzung in sozialen Netzwerken 
(Netzwerkdurchsetzungsgesetz &#8211; NetzDG) wie folgt zu &#252;berarbeiten:  
Zu &#167; 2 (Berichtspflicht):  
&#8226; die Kriterien zur Transparenzberichtspflicht so zu &#252;berarbeiten, dass
vergleichbare Berichte vorgelegt werden und valide Aussagen &#252;ber die
Betroffenen gemacht werden k&#246;nnen und ein umfassendes, anonymisiertes 
Monitoring der Beschwerden sowie der Opfer (z. B. Alter, Geschlecht,
Herkunft) m&#246;glich ist; 
&#8226; die Berichtspflicht auf das Aufkommen und Bem&#252;hungen zur Reduktion 
von social bots und menschliche Interaktion vorgebenden Profilen (&#8222;fake 
profile&#8220;) auszuweiten; 
Zu &#167; 3 (Umgang mit Beschwerden &#252;ber rechtswidrige Inhalte):  
&#8226; ein bu&#223;geldbewehrtes und berichtspflichtiges Wiedereinstellungsverfahren 
(put-back) einzuf&#252;hren, nach dem Inhalte unverz&#252;glich wieder eingestellt 
werden m&#252;ssen oder die Entscheidung hier&#252;ber an eine Einrichtung der
regulierten Selbstregulierung abgegeben werden muss; 
&#8226; einen Vorschlag f&#252;r die Auditierung und Zertifizierung des
Beschwerdemanagements sozialer Netzwerke vorzulegen; 
&#8226; daf&#252;r zu sorgen, dass die Diensteanbieter einheitliche, nutzerfreundliche und 
altersgerechte Standards zu Meldewegen befolgen; Meldewege sollten
einfach auffindbar und verst&#228;ndlich beschrieben sein. Meldungen sollten nicht 
nur f&#252;r eigenst&#228;ndige Inhalte, sondern auch f&#252;r Kommentare dazu in
angemessener Ausf&#252;hrlichkeit m&#246;glich sein; 
&#8226; benutzerfreundliche Meldewege bereitzuhalten, &#252;ber die Nutzerinnen und 
Nutzer mutma&#223;lich missbr&#228;uchlich eingesetzte social bots und &#8222;Fake-
Profile&#8220; leichter melden k&#246;nnen; 
&#8226; den Meldungen nachzugehen und den Meldenden sowie den f&#252;r den
Account Verantwortlichen &#252;ber den Verfahrensstand zu informieren; 
&#8226; die Einrichtung einer Clearingstelle durch die Diensteanbieter, bei denen auf 
Kosten der Betreiber insbesondere auch Beschwerden vorgebracht werden 
k&#246;nnen, wenn eine &#196;u&#223;erung nicht aufgrund des NetzDG gel&#246;scht wurde 
und auch danach nicht rechtswidrig ist, sondern es aufgrund anderer Gr&#252;nde, 
zum Beispiel der Gemeinschaftsstandards der Diensteanbieter, gel&#246;scht 
wurde; 
&#8226; im Zuge der Evaluierung der Transparenzberichte durch das Bundesamt f&#252;r 
Justiz (BfJ) ein Konzept zur verbesserten zivilrechtlichen Unterst&#252;tzung der
Opfer vorzulegen und good practices gegebenenfalls zu f&#246;rdern, um das
Prozesskostenrisiko nicht alleinig den Betroffenen zu &#252;berlassen; 
&#8226; einen Dialog mit dem Ziel zu initiieren, bestehende Defizite zu analysieren 
und die Zusammenarbeit zwischen Diensteanbietern, Einrichtungen der
freiwilligen Selbstkontrolle und den Strafverfolgungsbeh&#246;rden im Sinne einer 
verbesserten Rechtsdurchsetzung zu effektivieren; 
&#8226; die Schaffung eines zus&#228;tzlichen besonderen Gerichtsstandes in der
Strafprozessordnung und in der Zivilprozessordnung zu pr&#252;fen, um schnellen 
Rechtsschutz mit hoher Expertise zu gew&#228;hrleisten; 
Zu &#167; 5 (Inl&#228;ndischer Zustellungsbevollm&#228;chtigter):  
&#8226; die Einsetzung eines solchen Bevollm&#228;chtigten tats&#228;chlich durchzusetzen, 
eine Klarstellung der Empfangsbefugnis des inl&#228;ndischen
Zustellungsbevollm&#228;chtigten f&#252;r zivilrechtliche Angelegenheiten und dabei eine
verschl&#252;sselte Kommunikation mit diesem sicherzustellen; 
&#8226; zu pr&#252;fen, ob die Bu&#223;geldbew&#228;hrung der Auskunftsverweigerung gegen&#252;ber 
den Strafverfolgungsbeh&#246;rden nach &#167; 4 Absatz 1 Nummer 8 des
Netzwerkdurchsetzungsgesetzes auch inhaltsleere Antworten auf Anfragen der
Strafverfolgungsbeh&#246;rden, etwa durch Verweise auf Online-Plattformen,
umfassen sollte; 
b. das Telemediengesetz (TMG) so zu &#228;ndern, dass das bestehende Melde- und
Abhilfeverfahren (&#8222;Notice and take down&#8220;, vgl. &#167; 10 Satz 1 TMG) bei
rechtswidrigen Inhalten f&#252;r Diensteanbieter von Telemedien verbindlich strukturiert und 
konkretisiert wird (ggf. nach bestimmten, festzulegenden Gr&#246;&#223;enordnungen
dieser Diensteanbieter mit abgestuft geltenden Pflichten), damit eine sorgf&#228;ltige
Pr&#252;fung unter Einbeziehung der Beteiligten erfolgt, bei der die Rechte beider Seiten 
gewahrt bleiben. 
III. Der Deutsche Bundestag fordert die Bundesregierung dar&#252;ber hinaus auf,  
&#8226; eine rechtliche Einsch&#228;tzung zur Grundrechtsbindung f&#252;r Betreiber sozialer
Netzwerke und zu den Auswirkungen auf die Gemeinschaftsstandards vorzulegen; 
&#8226; durch Erg&#228;nzung und Konkretisierung der Richtlinien f&#252;r das Strafverfahren und 
das Bu&#223;geldverfahren (RiStBV) Regelungen zu schaffen, durch die die
Staatsanwaltschaft in F&#228;llen des Verdachts strafbarer Online-&#196;u&#223;erung (bzw. Information) 
a) wegen Schnelligkeit und Reichweite der Verbreitung der ehrverletzenden
&#196;u&#223;erungen das &#246;ffentliche Interesse annehmen kann und  
b) auch im Falle der Verweisung auf das Privatklageverfahren jedenfalls zuvor 
die Herkunft von pseudonymen und anonymen &#196;u&#223;erungen, gegebenenfalls 
auch unter Auskunftseinholung vom Diensteanbieter, ermittelt; 
&#8226; attraktive und altersgerechte Angebote zu schaffen, die die F&#228;higkeit und die
Bereitschaft der B&#252;rgerinnen und B&#252;rger f&#246;rdern (z. B. in schulischen und
au&#223;erschulischen Institutionen), &#252;ber Medien (Internet, Rundfunk, Print) verbreitete
Inhalte kritisch zu hinterfragen, bewusst verf&#228;lschte Inhalte als solche zu erkennen 
und sie f&#252;r pers&#246;nlichkeitsrechtsverletzende Inhalte zu sensibilisieren
(Medienkompetenz) sowie das vielf&#228;ltige zivilgesellschaftliche Engagement und die
Gegenrede zu unterst&#252;tzen; 
&#8226; unabh&#228;ngige und kostenfreie Informations- und Beratungsstellen zum Umgang 
mit Ph&#228;nomenen wie &#8222;Hate Speech&#8220;, &#8222;Desinformation&#8220;, &#8222;Cybermobbing&#8220;,
&#8222;Cyberstalking&#8220;, &#8222;Cybergrooming&#8220; und &#8222;Doxing&#8220; zu f&#246;rdern und dabei eine  
(Teil-)Finanzierung durch eine verpflichtende Abgabe von Diensteanbietern von
Telemedien ab einer festzulegenden Gr&#246;&#223;enordnung zu pr&#252;fen. Dabei muss
sichergestellt sein, dass die Informations- und Beratungsstellen niedrigschwellig 
auch Kindern und Jugendlichen zur Verf&#252;gung stehen, diese explizit ansprechen 
und Berater und Beraterinnen in Jugendschutzfragen geschult sind;  
&#8226; sich in Abstimmung mit den L&#228;ndern daf&#252;r einzusetzen, dass die einfache Online-
Anzeige von Beschwerden oder rechtswidriger Inhalte, beispielsweise per
polizeilicher &#8222;Internetwache&#8220;, in allen Bundesl&#228;ndern m&#246;glich ist;  
&#8226; in Zusammenarbeit mit den L&#228;ndern im Rahmen des Paktes f&#252;r den Rechtsstaat 
darauf hinzuwirken, dass die Strafverfolgungsbeh&#246;rden und Gerichte personell 
und technisch so ausgestattet werden, dass sie Strafrechtsverst&#246;&#223;e im Netz ad&#228;quat 
und in angemessener Zeit bearbeiten k&#246;nnen;  
&#8226; auf europ&#228;ischer und internationaler Ebene Regulierungen voranzutreiben und die 
grenz&#252;berschreitende Zusammenarbeit bei der Strafverfolgung zu intensivieren;  
&#8226; die Forschung zur Wirkung von Hate Speech, Desinformation und missbr&#228;uchlich 
eingesetzten Social Bots auf die demokratische Debattenkultur im Netz zu
unterst&#252;tzen;  
&#8226; die unabh&#228;ngige und selbstverwaltete &#220;berpr&#252;fung von online ver&#246;ffentlichten 
Fakten nach journalistischen Standards (&#8222;Fact-Checking&#8220;) und zu etablierenden 
Prozessen durch beispielsweise Nichtregierungsorganisationen oder
Zusammenschl&#252;sse von Medien weiterhin zu unterst&#252;tzen und dabei zu pr&#252;fen, ob und wie 
eine (Teil-)Finanzierung eines unabh&#228;ngigen Recherche-Fonds durch eine
verpflichtende Abgabe von Diensteanbietern von Telemedien ab einer festzulegenden 
Gr&#246;&#223;enordnung machbar ist;  
&#8226; eine Selbstverpflichtung der im Netz werbenden Wirtschaft zu initiieren, auf die 
Schaltung von Werbung auf solchen Webseiten zu verzichten, deren
Gesch&#228;ftsmodell ganz &#252;berwiegend auf die Verbreitung von zu definierenden
Falschmeldungen (Desinformation) ausgerichtet ist;  
&#8226; gemeinsam mit den L&#228;ndern effektiven Jugendmedienschutz durch die
Landesmedienanstalten (bzw. deren Kommission f&#252;r Jugendmedienschutz) zu
gew&#228;hrleisten. Hierf&#252;r ist ihnen ein weiteres Auskunftsrecht einzur&#228;umen, um bei Verst&#246;&#223;en 
gegen &#167; 4 JMStV den Anbieter von Telemedien zu ermitteln sowie weitere nach 
JMStV zustehende Ma&#223;nahmen durch die Landesmedienanstalt durchsetzen zu 
k&#246;nnen;  
&#8226; gegen&#252;ber den L&#228;ndern anzuregen, den Landesmedienanstalten die gem&#228;&#223; &#167; 54 
Absatz 3 RStV bestehenden Aufsichts- und Sanktionsm&#246;glichkeiten auch bei
Verst&#246;&#223;en von Telemedienanbietern mit journalistisch-redaktionell gestaltetem
Angebot zu er&#246;ffnen, wenn diese die nach &#167; 54 Absatz 2 RStV einzuhaltenden
journalistischen Sorgfaltspflichten verletzen; 
&#8226; gemeinsam mit den L&#228;ndern die Sachgerechtigkeit und Konsistenz der Bund-
L&#228;nder-Kompetenzverteilung im Bereich der Plattform- und Telemedienregulierung 
(v. a. Rundfunkstaatsvertrag, Jugendmedienschutzstaatsvertrag,
Jugendschutzgesetz, Netzwerkdurchsetzungsgesetz) angesichts der Entwicklungen des Internets 
grundlegend zu &#252;berpr&#252;fen und notwendige Ver&#228;nderungen aufzuzeigen und
anzugehen. 
Berlin, den 19. November 2018 
Katrin G&#246;ring-Eckardt, Dr. Anton Hofreiter und Fraktion
Begr&#252;ndung 
Zu I. 
Die einbringende Fraktion B&#220;NDNIS 90/DIE GR&#220;NEN hat am 13. Januar 2017 ein umfassendes Konzept mit 
dem Titel &#8222;Verantwortung, Freiheit und Recht im Netz&#8220; vorgelegt sowie im April 2017 einen umfassenden
Antrag &#8222;Transparenz und Recht im Netz &#8211; Ma&#223;nahmen gegen Hasskommentare, &#8222;Desinformation&#8220; und Missbrauch 
von &#8222;Social Bots&#8220;&#8220; (Drucksache 18/11856) eingebracht. Am 7. Juli 2017 wurde durch die Stimmen der
Regierungskoalition das Gesetz zur Verbesserung der Rechtsdurchsetzung in sozialen Netzwerken
(Netzwerkdurchsetzungsgesetz &#8211; NetzDG) im Bundestag beschlossen, welches am 1. Oktober 2017 in Kraft trat. Nicht nur das 
parlamentarische Verfahren, auch die materielle Regelung stie&#223; seitdem auf massive Kritik einer ungew&#246;hnlich 
breiten gesellschaftlichen Allianz. Ein im Anwendungsbereich limitiertes Netzwerkdurchsetzungsgesetz kann 
zudem nicht &#252;ber den Reformbedarf im Telemedienrecht insgesamt hinwegt&#228;uschen. Digitale Gatekeeper m&#252;ssen 
entschlossen dazu gebracht werden, ihrer Verantwortung nachzukommen und geltendes Recht zu beachten.
Digitale B&#252;rgerrechte laufen bisher unter der Regierungskoalition ins Leere.  
Auch die einbringende Fraktion sieht dringenden Handlungsbedarf, um offensichtliche Fehler des Gesetzes zu 
korrigieren. Die Bundesregierung sollte unverz&#252;glich einen Gesetzentwurf zur &#196;nderung des NetzDG und des 
TMG zu den unter II. und III. genannten Punkten vorlegen.  
Dar&#252;ber hinaus ist das zivilgesellschaftliche Engagement zahlreicher Menschen und Organisationen, wie die &#8222;No 
Hate Speech&#8220;-Kampagne des Europarats zu begr&#252;&#223;en und zu unterst&#252;tzen. 
Zu II.  
Zu &#167; 2 (Berichtspflicht):  
Die Berichtspflichten dienen der Transparenz. Es ist vor allem Interesse der Nutzerinnen und Nutzer, beim
Eingehen eines Rechtsverh&#228;ltnisses mit einem Diensteanbieter erkennen zu k&#246;nnen, welche Kriterien die
Diensteanbieter bei Meldungen rechtswidriger Informationen f&#252;r ihre Entscheidung zugrunde legen und in welchem 
Zeitraum Meldungen tats&#228;chlich bearbeitet werden. 
&#8226; (Transparenzberichte) Forschung sowie Rechtsanwender zeigen, dass die Auslegung des &#167; 2 h&#246;chst
unterschiedlich geschieht und eine Vergleichbarkeit der Berichte so kaum m&#246;glich ist.  
&#8226; Frauen und M&#228;dchen1 sind &#252;berdurchschnittlich h&#228;ufig von Hass und Gewalt im Netz, sogenannter &#8222;digitaler 
Gewalt&#8220;, betroffen. Diese Form von Gewalt gegen Frauen, die erhebliche seelische und psychische
Beschwerden und h&#228;ufig auch den R&#252;ckzug aus der Netz&#246;ffentlichkeit zur Folge hat, muss st&#228;rker
ber&#252;cksichtigt werden. Die Bundesregierung ist hier jahrelang nicht ernsthaft t&#228;tig geworden. Berechtigte
Schutzanspr&#252;che laufen unter der Gro&#223;en Koalition bisher ins Leere. Die Erweiterung der Berichtspflicht zu Angaben 
&#252;ber Geschlecht der Opfer sowie Meldenden kann hier eine wichtige empirische Grundlage f&#252;r weitere 
Schritte sein. 
&#8226; (Social bots) Die Kennzeichnung von social bots sollte durch eine entsprechende Berichtspflicht f&#252;r die
Unternehmen erg&#228;nzt werden. Es gibt sinnvolle Anwendungen von social bots: Sie k&#246;nnen dazu beitragen, sich 
tausendfach wiederholende Abl&#228;ufe zu automatisieren und Menschen zu entlasten. Sie k&#246;nnen dabei helfen, 
Hilfesuchende auf Fundstellen aufmerksam zu machen, Nutzerinnen und Nutzer k&#246;nnen in sozialen
Netzwerken auf neue journalistische Artikel hingewiesen werden oder Nutzerinnen und Nutzer automatisiert auf 
geltende Diskussionsregeln verwiesen werden. Genauso k&#246;nnen sie bei entsprechender Programmierung 
aber auch missbr&#228;uchlich eingesetzt werden und demokratische Diskurse vergiften. Durch ihre verst&#228;rkende 
Wirkung k&#246;nnen social bots vermeintliche Mehrheitsverh&#228;ltnisse und die gesellschaftliche Bedeutung von 
Themen vort&#228;uschen. Diskussionen k&#246;nnen inhaltlich verzerrt und Desinformationen massenhaft verbreitet 
werden. Social bots k&#246;nnen auch zum gezielten &#8222;Phishing&#8220; und &#8222;Social Engineering&#8220; gegen&#252;ber
Privatpersonen und Unternehmen und als Bestandteil von internationalen Desinformationskampagnen eingesetzt
werden. Mit abnehmenden Kosten und technischem Aufwand ist zu bef&#252;rchten, dass social bots zuk&#252;nftig
vermehrt auch als Instrument des Mobbings gegen Einzelpersonen eingesetzt werden.  
                                                        
1 Die aktuelle repr&#228;sentative Studie des IDZ im Auftrag von Campact in Hessen zeigt: Opfer von Hate Speech werden neben Frauen und M&#228;dchen 
vor allem gefl&#252;chtete Menschen und Muslimas und Muslime, sowie vor allem junge Menschen im Alter von 18-24 Jahren. Das sind die
gef&#228;hrdeten Gruppen, die gezielt auch bundesweit ermittelt werden m&#252;ssen, um f&#252;r gezielte Schutzma&#223;nahmen zu sorgen, https://blog.cam-
pact.de/2018/10/pilotstudie-in-hessen/.
Zu &#167; 3 (Umgang mit Beschwerden &#252;ber rechtswidrige Inhalte):  
&#8226; (Put-Back-Verfahren) &#8222;Um die einseitige Ausrichtung des NetzDG auf das L&#246;schen von Inhalten
auszugleichen, wird insbesondere angemahnt, das sogenannte Put-back-Verfahren zu installieren, also Verfahren, in 
denen der Nutzer eines sozialen Netzwerks die Wiederherstellung gel&#246;schter, aber nicht rechtswidriger und 
von der Meinungsfreiheit gedeckter Beitr&#228;ge erreichen kann. In ihrer Empfehlung vom 1. M&#228;rz 2018 &#8222;f&#252;r 
wirksame Ma&#223;nahmen im Umgang mit illegalen Online-Inhalten&#8220; fordert die Europ&#228;ische Kommission die 
Mitgliedstaaten dazu auf, Host-Providern Vorgaben zu einem benutzerfreundlichen Umgang mit
Gegendarstellungen zu machen, mit denen ggf. die R&#252;ckg&#228;ngigmachung einer L&#246;schungsentscheidung erwirkt werden 
kann&#8220; (Peukert, 20182). 
&#8226; (Meldewege) Es sollten benutzerfreundliche Melde-Tools bereitgehalten werden. Diensteanbieter stellen in 
unterschiedlicher Form und Zug&#228;nglichkeit Wege bereit, um rechtswidrige Inhalte zu melden. Schriften bzw. 
Online-Texte wie der von Facebook &#252;ber &#8222;Zugriff auf deine Informationen und Download deiner
Informationen&#8220; sind viel zu kompliziert und unzureichend verbreitet. Die Meldewege sind unterschiedlich gut
auffindbar und zug&#228;nglich. So ist eine Meldung nach dem NetzDG auf Facebook nur nach Durchsicht des
Kleingedruckten am unteren Ende der Webseite neben dem Impressum m&#246;glich, Kommentare bei Instagram sind 
kaum zu melden. Viele Inhalte werden darum nicht gemeldet. Die Transparenzberichte zeigen einen klaren 
Zusammenhang von Auffindbarkeit des Meldeweges und Beschwerdeaufkommen. Die f&#252;r die
Diensteanbieter au&#223;erdem geforderten Dokumentationspflichten und Vorkehrungen zur fachgerechten Bearbeitung von 
Beschwerden etc. dienen der Effizienz und der Beweissicherung. Geltende Datenschutzstandards m&#252;ssen 
dabei gewahrt bleiben.  
&#8226; (Meldungen Social Bots) Die Verbreitung von durch Algorithmen ausgel&#246;ster automatischer
Kommunikation und Information nimmt absehbar weiter stark zu. Dem Staat kommt eine wichtige Schutzverantwortung 
zu. Er sollte Risiken f&#252;r den demokratischen Diskurs, m&#246;gliche Manipulationen, Verzerrungen oder gar
Zersetzung von gesellschaftlichen Meinungsbildungs- und politischen Entscheidungsprozessen bis hin zu
Wahlentscheidungen fr&#252;hzeitig entschlossen begegnen und eine m&#246;gliche Transparenz in der digitalen Welt
sicherstellen. Selbstverpflichtungen, das hat die Vergangenheit gezeigt, reichen auch nicht aus.  
&#8226; (Verfahrensstand) Die Information der Meldenden und Betroffenen &#252;ber ihren Verfahrensstand ist eine
notwendige St&#228;rkung im Sinne der Betroffenenrechte.  
&#8226; (Clearingstelle) Der- oder diejenige, der/die einen rechtm&#228;&#223;igen Inhalt in das soziale Netzwerk eingestellt 
hat, hat im Falle der L&#246;schung keine rechtliche M&#246;glichkeit, hiergegen vorzugehen. F&#252;r den Betroffenen, 
der sich der L&#246;schung eines rechtm&#228;&#223;igen Inhalts ausgesetzt sieht, ist die Situation unbefriedigend und es 
droht eine Gefahr f&#252;r die Meinungs&#228;u&#223;erungsfreiheit (Artikel 5 Absatz 1 Satz 1 des Grundgesetzes). Daher 
erscheint es erw&#228;genswert, die Diensteanbieter zu verpflichten, auf ihre Kosten eine Clearingstelle
einzurichten, bei der von einer L&#246;schung Betroffene ihre Beschwerden vorbringen und insbesondere den
Nachweis der Rechtm&#228;&#223;igkeit ihrer &#196;u&#223;erung f&#252;hren k&#246;nnen.  
&#8226; (Zivilrechtliche Unterst&#252;tzung) Das Prozesskostenrisiko sollte nicht allein Betroffenen &#252;berlassen sein.  
&#8226; (Dialog) Ein Dialogprozess k&#246;nnte, &#228;hnlich dem Kampf gegen Darstellung von Kindesmissbrauch im
Internet, in ein Harmonisierungspapier m&#252;nden.  
&#8226; (Besondere Gerichtsst&#228;nde) F&#252;r Straftaten, die durch einen in ein soziales Netzwerk eingestellten Inhalt
begangen werden, sowie f&#252;r zivilrechtliche Klagen gegen Diensteanbieter und/oder Nutzer wegen eines dort 
eingestellten Inhaltes k&#246;nnten zus&#228;tzliche besondere Gerichtsst&#228;nde zu einem Angebot f&#252;r schnellen und 
besonders qualifizierten Rechtsschutz bzw. entsprechende Strafverfolgung f&#252;hren. Denn mit der Zahl der 
F&#228;lle steigt die Expertise bei Gerichten und Staatsanwaltschaften sowohl im Hinblick auf den
Sachgegenstand als auch die Kenntnis der sozialen Netzwerke und ihrer T&#228;tigkeit/ihres Verhaltens. Fl&#228;chendeckend 
wird sich diese Expertise eben so wenig kaum realisieren lassen, jedenfalls nicht in &#252;berschaubarer Zeit, wie 
ein schnelles Online-Rechtsschutzangebot. Dieses k&#246;nnte bei einem besonderen Gerichtsstand &#8211; vielleicht 
auch zun&#228;chst als Pilotprojekt &#8211; vorgehalten werden. All dies soll die Bundesregierung (gemeinsam mit den 
L&#228;ndern) pr&#252;fen. 
                                                        
2 &#8222;Put it back: Ein Vorschlag f&#252;r ein NetzDG, das die Meinungsfreiheit wahrt&#8220;, Alexander Peukert (2018), https://verfassungsblog.de/put-it-back-
ein-vorschlag-fuer-ein-netzdg-das-die-meinungsfreiheit-wahrt/.
Zu &#167; 5 (Inl&#228;ndischer Zustellungsbevollm&#228;chtigter): 
F&#252;r eine effektive Rechtsdurchsetzung ist die Bestellung eines oder einer inl&#228;ndischen empfangs- und
zustellungsbevollm&#228;chtigten Verantwortlichen bei den Dienstanbietern unabdingbar. Damit ist auch Verkehr in
deutscher Sprache sichergestellt. Der oder die inl&#228;ndische Zustellungsbevollm&#228;chtigte muss ebenso leicht erkennbar 
sein wie der Name, die Anschrift des Diensteanbieters und der Vertretungsberechtigte (vgl. &#167; 5 TMG und &#167; 55 
Absatz 2 des Rundfunkstaatsvertrages). Eine Benennung des Ansprechpartners erst im Verfahren gegen&#252;ber den 
Beh&#246;rden gen&#252;gt nicht. Die Praxis zeigt, dass Unternehmen teilweise ihre Zustellungsbevollm&#228;chtigten nur f&#252;r 
strafrechtlich relevante Angelegenheiten einsetzen. Zivilrechtliche Anspr&#252;che k&#246;nnen somit weiterhin nur 
schwer geltend gemacht werden.  
Zu II b. (Melde- und Abhilfeverfahren)  
Das sogenannte Notice-and-take-down-Verfahren erfolgt derzeit ohne konkrete gesetzliche Regelungen. Das
Notice-and-take-down-Verfahren ist in Artikel 14 Absatz 1 Buchstabe b der Richtlinie &#252;ber den elektronischen
Gesch&#228;ftsverkehr (Richtlinie 2000/31/EG) und in &#167; 10 Satz 1 des Telemediengesetzes grunds&#228;tzlich angelegt. In 
einer Vielzahl von F&#228;llen bleibt zun&#228;chst offen, ob es sich um klar rechtswidrige Postings handelt. Es bleibt damit 
den Providern selbst &#252;berlassen, auf welche Art und Weise sie ihren aus der Kenntnis von Hinweisen auf
mutma&#223;lich rechtswidrige Inhalte erwachsenden Obliegenheitspflichten nachkommen. Der Bundesgerichtshof hat in 
einer Reihe von Entscheidungen zu unterschiedlichen Fallkonstellationen die von Providern zu beachtenden
Aspekte, wie etwa die Kontaktaufnahme zu den Inhalte einstellenden Personen und die Einr&#228;umung einer knappen 
Erwiderungsfrist, lediglich umrissen. Es obliegt dem Gesetzgeber, die zunehmende Anzahl von
Auseinandersetzungen zwischen den durch rechtswidrige Postings mutma&#223;lich Gesch&#228;digten und den Diensteanbietern so zu 
strukturieren, dass sowohl die effektive Durchsetzung der Rechte des mutma&#223;lich Gesch&#228;digten gew&#228;hrleistet 
wird als auch die ebenfalls grundrechtlichen Schutz genie&#223;enden Kommunikationsfreiheiten der Diensteanbieter 
und des sich &#228;u&#223;ernden Nutzers im Verfahren mit dem Umgang mit Verdachtsmeldungen gewahrt bleiben. Da 
das Melde- und Abhilfeverfahren bereits im TMG angelegt ist, bietet es sich an, eine Neuregelung ebenfalls 
innerhalb des TMG zu treffen. &#220;ber die Melde- und Abhilfeverfahren hinaus bedarf es auch einer verbesserten 
Mitwirkung der Diensteanbieter bei der Aufkl&#228;rung von Straftaten durch die Beh&#246;rden. Die Praxis bem&#228;ngelt 
den Umgang der Diensteanbieter mit Anfragen seitens der Staatsanwaltschaft, die entweder gar nicht oder mit 
erheblicher Zeitverz&#246;gerung beantwortet werden. Um die Ermittlungen zu beschleunigen, soll auch hier eine 
kurze Frist zur Bearbeitung der Anfragen von Strafverfolgungsbeh&#246;rden und Gerichten gegen&#252;ber den
Diensteanbietern festgelegt werden. 
Aus anderen Mitgliedstaaten ist bekannt, dass sie erg&#228;nzend zu dem Grundsatz ,,notice and take down&#8220; der E-
Commerce-Richtlinie konkrete Verfahren zur Meldung und Entfernung illegaler Inhalte haben. Dies sind
Finnland, Frankreich, Litauen und Ungarn. 
Zu III.  
(Grundrechtsbindung) Eine rechtliche Kl&#228;rung ist auch im Hinblick auf Urteile wie die des OLG M&#252;nchen
(Beschl. v. 27. August 2018, Az.:18 W 1294/18) n&#246;tig.  
(Richtlinien f&#252;r das Strafverfahren und das Bu&#223;geldverfahren) Die Richtlinien f&#252;r das Strafverfahren und das 
Bu&#223;geldverfahren (RiStBV) stammen bei den hier einschl&#228;gigen Nummern 86 und 87 aus der Zeit vor der
Verbreitung des Internets. Sie bed&#252;rfen deshalb der Erg&#228;nzung. Zwar wurde 2015 in der Folge der NSU-Taten und 
der Forderungen des ersten NSU-Untersuchungsausschusses bereits eine Erg&#228;nzung in Nummer 86 Absatz 2 
Satz 1 eingef&#252;gt, die aber nicht das Ziel des vorliegenden Antrages erfasst (siehe dazu bereits die Antr&#228;ge der 
Fraktion B&#220;NDNIS 90/DIE GR&#220;NEN &#8222;Demokratie st&#228;rken &#8211; Dem Hass keine Chance geben&#8220; auf Drucksache 
18/7553 und &#8222;Hasskriminalit&#228;t wirkungsvoll statt symbolisch verfolgen&#8220; auf Drucksache 18/3150). Delikte wie 
Beleidigung oder Bedrohung sind als Privatklagedelikte ausgestaltet, d. h., die Staatsanwaltschaft hat hier zu 
pr&#252;fen, ob ein &#246;ffentliches Interesse an der Verfolgung von Amts wegen besteht. Die RiStBV sollen deshalb 
k&#252;nftig die Anweisung enthalten, dass die Staatsanwaltschaft bei der Feststellung des &#246;ffentlichen Interesses bei 
Privatklagedelikten, das die Verfolgung der m&#246;glichen Straftat von Amts wegen ausl&#246;sen w&#252;rde, die Umst&#228;nde 
der Reichweite der im Internet verbreiteten &#196;u&#223;erungen verst&#228;rkt zu ber&#252;cksichtigen hat. Au&#223;erdem soll die 
Staatsanwaltschaft im Falle einer Verweisung auf den Privatklageverfahren verpflichtet sein, zuvor die Herkunft 
einer im Internet anonym oder pseudonym gemachten strafverd&#228;chtigen &#196;u&#223;erung (Information) nach den
einschl&#228;gigen strafprozessualen Bestimmungen zu ermitteln. Die Diensteanbieter sind aufgrund von &#167; 14 Absatz 2
i. V. m. &#167; 15 Absatz 5 Satz 4 TMG befugt, auf Anordnung der zust&#228;ndigen Stellen &#252;ber Bestands- und
Nutzungsdaten Auskunft zu erteilen. 
Die Kommunikation mit den Strafverfolgungsbeh&#246;rden steht nicht zur freien Disposition der Diensteanbieter und 
kann nicht etwa durch Vorgaben wie die nachfolgend zitierten von Facebook einseitig bestimmt werden
(&#8222;Informationen f&#252;r Strafverfolgungsbeh&#246;rden&#8220;, worin es hei&#223;t: &#8222;Diese Betriebsrichtlinien gelten f&#252;r Mitarbeiter der 
Strafverfolgungsbeh&#246;rden, die Daten bei Facebook und Instagram anfordern&#8220;). 
(Medienkompetenz) Zur Pr&#228;vention von Hassreden im Netz und einem kompetenten Umgang mit Informationen 
und Nachrichten im Netz ist das Angebot von Medien- und Datenschutzkompetenzvermittlungen deutlich
auszuweiten. Die Vermittlung von Medien- und Datenschutzkompetenz muss in den Schulen, der politischen
Bildung und als Aufgabe der Jugendhilfe gest&#228;rkt werden. Hierzu braucht es entsprechende Fortbildungsprogramme 
f&#252;r die Fachkr&#228;fte. Netz- und Medienkompetenz f&#252;hren ebenso zu einer Verbesserung der technischen und
sozialen F&#228;higkeiten der Mediennutzung und Medienkritik, die insbesondere M&#228;dchen und Frauen darin st&#228;rken, sich 
sicher und selbstbewusst im Netz zu bewegen und an Online-Prozessen und Diskursen mitzuwirken.  
(Unabh&#228;ngige Informations- und Beratungsstellen) &#8222;Digitale Gewalt&#8220; nimmt mit der wachsenden Bedeutung von 
digitaler Kommunikation immer st&#228;rker zu. Cybergewalt umfasst Cybermobbing, -grooming, -stalking, -
sexismus und Doxing. Betroffene von Hassreden finden bisher kaum Informationen und Beratung, wie sie individuell 
und rechtlich mit diffamierenden Inhalten umgehen sollen. Diensteanbieter ab einer zu definierenden
Gr&#246;&#223;enordnung sollen auch durch eine (Teil-)Finanzierung ihrer Verantwortung f&#252;r eine demokratische Debattenkultur 
nachkommen.  
92 Prozent aller Kinder und Jugendlichen zwischen zw&#246;lf und 17 Jahren verf&#252;gen &#252;ber ein Smartphone, mit dem 
sie regelm&#228;&#223;ig online sind (JIM-Studie). Sie sind in besonderem Ma&#223;e gef&#228;hrdet, Opfer von digitaler Gewalt zu 
werden und dabei nachhaltig in ihrer Pers&#246;nlichkeitsentwicklung gest&#246;rt zu werden. Informations- und
Beratungsstellen m&#252;ssen deshalb niedrigschwellig auch f&#252;r Kinder und Jugendliche erreichbar und in
Jugendschutzfragen kompetent ausgestattet sein.  
Frauen und M&#228;dchen sind hiervon &#252;berproportional stark betroffen. Der bff &#8211; Bundesverband
Frauenberatungsstellen und Frauennotrufe berichtet von einem Anstieg der Beratungsanfragen zu digitalen Gewaltformen. 
Schwere beleidigende Online-Botschaften, Androhung von Vergewaltigung etc. erleben besonders Bloggerinnen 
und (Online-)Journalistinnen sowie Politikerinnen und Wissenschaftlerinnen. Frauen und M&#228;dchen wird es durch 
systematische anonyme Drohungen erschwert, das Internet gleichberechtigt zu nutzen, ihre Meinung frei zu
&#228;u&#223;ern und damit eine Gegen&#246;ffentlichkeit im Netz herzustellen. 
(Online-Anzeige) Eine einfache, schnelle und zeitgem&#228;&#223;e Online-Anzeigenerstattung sollte in allen
Bundesl&#228;ndern m&#246;glich sein.  
(Personal und Ausstattung f&#252;r Strafverfolgungsbeh&#246;rden und Gerichte) Mangel an Personal oder mangelhafte 
Ausstattung darf nicht dazu f&#252;hren, dass T&#228;terinnen und T&#228;ter nicht ermittelt werden k&#246;nnen und die Verfahren 
aus diesem Grunde eingestellt werden m&#252;ssen. Die Justiz muss technisch und personell gemeinsam mit den
L&#228;ndern dem digitalen Zeitalter angemessen ausgestattet werden. Auch dies sollte Gegenstand des Paktes f&#252;r den 
Rechtsstaat sein. 
(Europ&#228;ische und internationale Ebene) Angesichts der internationalen Dimension des Netzes sind europ&#228;ische 
und internationale Regulierungsans&#228;tze unausweichlich und ist die grenz&#252;berschreitende Zusammenarbeit bei 
der Strafverfolgung zu st&#228;rken. 
(Forschung) Die wissenschaftliche Forschung und empirischen Erkenntnisse zur Auswirkung von Hate Speech, 
Desinformation und social bots auf die &#246;ffentliche Debattenkultur stehen noch am Anfang. Die Sachverst&#228;ndigen 
der Anh&#246;rung &#8222;Fake News, Social Bots, Hacks und Co. &#8211; Manipulationsversuche demokratischer
Willensbildungsprozesse im Netz&#8220; des Ausschusses Digitale Agenda am 25. Januar 2015 bekr&#228;ftigten, dass eine
Ausweitung der Forschung dringend geboten sei. 
(Unabh&#228;ngiges Fact-Checking) Eine aktuelle Studie3 zeigt auf, dass Fact Checking nicht alle Menschen, die auch 
Desinformation ausgesetzt waren, erreicht oder diese Menschen nicht erreicht werden m&#246;chten. Dennoch kommt 
die Studie zu dem Schluss, dass &#8222;Fact-Checking&#8220; als Mittel gegen Desinformation ein wichtiges erg&#228;nzendes 
Mittel ist, um die Gesellschaft &#252;ber Desinformation zu informieren. Zudem leistet die transparente
Gegeninformation einen Beitrag f&#252;r mehr Medienkompetenz der Nutzerinnen und Nutzer. Um das Instrument weiter zu 
                                                        
3 Stiftung Neue Verantwortung, &#8222;Feuerwehr ohne Wasser &#8211; M&#246;glichkeiten und Grenzen des Fact-Checking als Mittel gegen Desinformation&#8220;, 
Juli 2018.
st&#228;rken, sollten Standards etabliert werden, die eine verl&#228;ssliche, dauerhafte und vor allem unabh&#228;ngige
Fakten&#252;berpr&#252;fung sicherstellen, die sich an Modellen wie etwa denen der Freiwilligen Selbstkontrolle Multimedia-
Diensteanbieter, Unterhaltungssoftware Selbstkontrolle und Freiwilligen Selbstkontrolle der Filmwirtschaft
orientieren. Eine entsprechende Organisation nach dem Modell der Freiwilligen Selbstkontrolle sollte nur solche 
Rechercheeinheiten einsetzen, die bestimmte Qualit&#228;tskriterien erf&#252;llen, und diese Einhaltung auch regelm&#228;&#223;ig 
&#252;berpr&#252;fen. Dabei sollte auf effiziente Prozesse und die Vernetzung der Rechercheeinheiten geachtet werden. 
Technische Tools k&#246;nnten genutzt werden, um Desinformation zu identifizieren und die Sichtbarkeit des Fakten-
Checks zu erh&#246;hen (etwa indem die Fakten-Checks an die Desinformation so gebunden sind, dass sie nur noch 
mit dieser weiterverbreitet werden k&#246;nnen). Zudem w&#228;ren eine Kontrolle der Organisation durch etwa die
Landesmedienanstalten und au&#223;ergerichtliche Beschwerdem&#246;glichkeiten sinnvoll. Des Weiteren ist zu pr&#252;fen,
inwiefern dieses Modell &#252;ber eine Verpflichtung der Diensteanbieter von Telemedien ab einer bestimmten
definierten Gr&#246;&#223;e, eine bestimmte Abgabe in einen Recherche-Fonds einzuzahlen, zumindest (teil-)finanziert werden 
kann.  
(Werbeschaltung im Kontext von Desinformation) Es sind bereits erste internationale F&#228;lle bekannt, bei denen 
gezielt Falschmeldungen, insbesondere zu gesellschaftlich relevanten, politischen Ereignissen, ver&#246;ffentlicht 
wurden, um verst&#228;rkt Klickzahlen zu generieren, dadurch werbliche Attraktivit&#228;t zu steigern und Gewinne zu 
erzielen. Um diesen Trend zu unterbinden, ist eine Selbstverpflichtung der Wirtschaft sinnvoll, auf die Werbung 
auf solchen Webseiten zu verzichten. Dabei ist allerdings eine rechtssichere Definition notwendig, was genau 
unter &#8222;gezielten Falschmeldungen&#8220; (sogenannter Desinformation) verstanden werden soll.  
(Auskunftsrecht der Landesmedienanstalten) Die Landesmedienanstalten haben f&#252;r Verst&#246;&#223;e im Bereich
rechtswidriger &#196;u&#223;erungen (wie etwa Rassenhass, Volkverhetzung u. &#196;., siehe &#167; 4 JMStV) im Rahmen des
Jugendmedienschutzstaatsvertrages bereits eine klare gesetzliche Zust&#228;ndigkeit, die h&#228;ufig neben der Zust&#228;ndigkeit der 
Strafverfolgungsbeh&#246;rden besteht (&#167; 20 JMStV). Dabei sind ihnen Untersagung oder auch Bu&#223;gelder als
Ma&#223;nahmen m&#246;glich. Allerdings fehlen den Landesmedienanstalten Auskunftsrechte f&#252;r den Fall, dass der nach &#167; 20 
JMStV auskunftspflichtige Telemedienanbieter nicht ermittelbar ist, so dass sie ihre Aufgaben hier h&#228;ufig nicht 
durchsetzen k&#246;nnen. Die Bundesregierung sollte sich mit den L&#228;ndern ins Benehmen setzen, um &#8211; gerade zur 
Entlastung der Strafverfolgungsbeh&#246;rden, f&#252;r F&#228;lle, bei denen das Interesse an der Strafverfolgung nicht gesehen 
wird, und zur St&#228;rkung der Rechtsdurchsetzung &#8211; eine Erg&#228;nzung der Landesmedienanstalten als
Auskunftsberechtigte in &#167; 14 Absatz 2 TMG f&#252;r die Zwecke der Verfolgung von Verst&#246;&#223;en gegen &#167; 4 JMStV zu pr&#252;fen.  
(Aufsicht &#252;ber journalistisch-redaktionelle Telemedien) Die Regelungen nach Telemediengesetz und
Rundfunkstaatsvertrag sind nicht zweckm&#228;&#223;ig aufeinander abgestimmt. Telemedien mit journalistisch-redaktionellen
Angeboten k&#246;nnen mittlerweile eine der Presse und dem Rundfunk vergleichbare Breitenwirkung entfalten und 
damit erheblich auf die &#246;ffentliche Meinungsbildung einwirken. Diese Angebote k&#246;nnen unter dem Deckmantel 
eines seri&#246;sen Journalismus gezielt Falschmeldungen verbreiten, aus politischen oder auch gewinnorientierten 
Absichten. Diese Telemedien sind bereits jetzt journalistischen Sorgfaltspflichten unterworfen (&#167; 54 Absatz 2 
des Rundfunkstaatsvertrages), im Falle des Versto&#223;es k&#246;nnen aber keine Aufsichtsma&#223;nahmen ergriffen werden. 
Hier sollte sich die Bundesregierung mit den L&#228;ndern ins Benehmen setzen, um zu pr&#252;fen, ob &#196;nderungen
vorgenommen werden sollten, um beispielsweise den zust&#228;ndigen Landesmedienanstalten die
Sanktionsm&#246;glichkeiten des &#167; 59 Absatz 3 des Rundfunkstaatsvertrages im Falle von Verst&#246;&#223;en gegen journalistische
Sorgfaltspflichten zu er&#246;ffnen. 
(Bund-L&#228;nder-Kompetenzverteilung Plattform- und Telemedienregulierung) Die Regelungen im Bereich der 
Plattform- und Telemedienregulierung sind nicht zweckm&#228;&#223;ig aufeinander abgestimmt, das wurde nicht zuletzt 
auch in den Anh&#246;rungen zum NetzDG bem&#228;ngelt. So gibt es in vielen Bereichen Inkongruenzen bzw.
&#220;berschneidungen. Abschnitt VI des Rundfunkstaatsvertrages etwa enth&#228;lt eine Inhaltsregulierung von Telemedien, 
aus welcher sich u. a. die Bindung von Telemediendiensteanbietern an die allgemeinen Gesetze und somit auch 
an das Strafgesetzbuch ergibt (&#167; 54 Absatz 1 Satz 3 RStV). In der Folge sind nach einem abgestuften
Sanktionssystem, das auch den Bed&#252;rfnissen der Meinungsfreiheit Rechnung tr&#228;gt, die staatsfern organisierten
Landesmedienanstalten zust&#228;ndig (&#167; 59 RStV).  
Gleiches gilt f&#252;r den Bereich des Jugendmedienschutzes und des NetzDG. Der Jugendmedienschutzstaatsvertrag 
nutzt u. a. das Prinzip der regulierten Selbstregulierung, das f&#252;r die Telemedienanbieter bei Beachtung
bestimmter Vorgaben Haftungsprivilegien vorsieht und im &#220;brigen die Aspekte der Medienfreiheiten sorgf&#228;ltig mit dem 
Schutzanspruch der Jugendf&#252;rsorge ausgleicht.
Demgegen&#252;ber hat das NetzDG ein eigenst&#228;ndiges &#8222;Sperr- und L&#246;schsystem&#8220; eingef&#252;hrt, das den
Anwendungsbereich des JMStV verdr&#228;ngt bzw. sich &#252;berschneidet. Dar&#252;ber hinaus sind auch im Verh&#228;ltnis
Jugendmedienschutzstaatsvertrag und Jugendschutzgesetz dringend Novellierungen erforderlich, um der zunehmenden
Medienkonvergenz Rechnung zu tragen und den Kinder- und Jugendmedienschutz zu vereinheitlichen und unabh&#228;ngig 
von medialen Verbreitungswegen am Gef&#228;hrdungsgrad der verbreiteten Medieninhalte auszurichten. Die
Bundesregierung muss sich dieser inkongruenten Regulierungssysteme annehmen sowie zusammen mit den L&#228;ndern 
evaluieren, inwiefern eine zweckm&#228;&#223;ig aufeinander abgestimmte Plattform- und Telemedienregulierung f&#252;r die 
Zukunft erreicht werden kann. 
Satz: Satzweiss.com Print, Web, Software GmbH, Mainzer Stra&#223;e 116, 66121 Saarbr&#252;cken, www.satzweiss.com
Druck: Printsystem GmbH, Schafw&#228;sche 1-3, 71296 Heimsheim, www.printsystem.de
Vertrieb: Bundesanzeiger Verlag GmbH, Postfach 10 05 34, 50445 K&#246;ln, Telefon (02 21) 97 66 83 40, Fax (02 21) 97 66 83 44, www.betrifft-gesetze.de 
ISSN 0722-8333]</text>
    <titel>Netzwerkdurchsetzungsgesetz weiterentwickeln - Nutzerrechte st&#228;rken, Meinungsfreiheit in sozialen Netzwerken sicherstellen</titel>
    <datum>2018-11-22</datum>
  </document>
  