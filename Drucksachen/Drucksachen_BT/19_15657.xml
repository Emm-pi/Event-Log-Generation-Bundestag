<document>
    <id>236850</id>
    <drucksachetyp>Antwort</drucksachetyp>
    <dokumentart>Drucksache</dokumentart>
    <autoren_anzahl>0</autoren_anzahl>
    <typ>Dokument</typ>
    <vorgangsbezug_anzahl>1</vorgangsbezug_anzahl>
    <dokumentnummer>19/15657</dokumentnummer>
    <wahlperiode>19</wahlperiode>
    <herausgeber>BT</herausgeber>
    <pdf_hash>1199b61a16ca55506d40f66db11a5a93</pdf_hash>
    <aktualisiert>2022-07-26T19:57:18+02:00</aktualisiert>
    <vorgangsbezug>
      <id>255463</id>
      <titel>Besch&#228;ftigung der Bundesregierung mit Deepfakes</titel>
      <vorgangstyp>Kleine Anfrage</vorgangstyp>
    </vorgangsbezug>
    <urheber>
      <einbringer>false</einbringer>
      <bezeichnung>BRg</bezeichnung>
      <titel>Bundesregierung</titel>
    </urheber>
    <ressort>
      <federfuehrend>true</federfuehrend>
      <titel>Bundesministerium der Justiz und f&#252;r Verbraucherschutz</titel>
    </ressort>
    <fundstelle>
      <pdf_url>https://dserver.bundestag.de/btd/19/156/1915657.pdf</pdf_url>
      <id>236850</id>
      <dokumentnummer>19/15657</dokumentnummer>
      <datum>2019-12-02</datum>
      <dokumentart>Drucksache</dokumentart>
      <drucksachetyp>Antwort</drucksachetyp>
      <herausgeber>BT</herausgeber>
      <urheber>Bundesregierung</urheber>
    </fundstelle>
    <text>[Antwort
der Bundesregierung
auf die Kleine Anfrage der Abgeordneten Manuel H&#246;ferlin, Frank Sitta,
Grigorios Aggelidis, weiterer Abgeordneter und der Fraktion der FDP
&#8211; Drucksache 19/15210 &#8211;
Besch&#228;ftigung der Bundesregierung mit Deepfakes
V o r b e m e r k u n g  d e r  F r a g e s t e l l e r
Der Begriff &#8222;Deepfake&#8220; bezeichnet t&#228;uschend echt wirkende Bild-,
Audiooder auch Videomanipulationen, die zumeist mit Hilfe k&#252;nstlicher Intelligenz 
hergestellt wurden. Hierf&#252;r werden neuronale Netzwerke entsprechend
programmiert und trainiert, sodass die Bilder bzw. Videos weitgehend autonom 
erzeugt werden k&#246;nnen. So wurde beispielsweise bereits das Gesicht Dr.
Angela Merkels durch das von Donald Trump ersetzt (www.tagesschau.de/fakten
finder/hintergrund/deep-fakes-101.html) oder ein Video erstellt, in dem Mark 
Zuckerberg von der Macht schw&#228;rmt, die ihm die gestohlenen Daten von
Milliarden von Menschen verleihen (www.welt.de/wirtschaft/webwelt/video1951
89665/Deepfake-Video-Mark-Zuckerberg-schwaermt-von-Weltherrschaft-ver
blueffend-echt.html). Auch wenn sich zu Beginn viele F&#228;lschungen noch bei 
genauerem Hinsehen mit blo&#223;em Auge erkennen lie&#223;en, werden die
Manipulationen zunehmend besser und sind vor allem beim schnellen Erfassen
beispielsweise &#252;ber Social Media auf dem Handybildschirm kaum als F&#228;lschung 
zu erkennen.
&#8222;Im Oktober 2019 hat der US-Bundesstaat Kalifornien das Verbreiten von 
&#8222;materially deceptive audio or visual media&#8220; in Bezug auf politische
Kandidaten f&#252;r den Zeitraum von 60 Tagen vor einer Wahl verboten (Assembly Bill 
No. 730 &#8222;Elections: deceptive audio or visual media.&#8220;). Das Gesetz nimmt f&#252;r 
&#8222;materially deceptive audio or visual media&#8220; in SEC. 4 subdivision (e) eine 
Definition vor. (Quelle: www.leginfo.legislature.ca.gov/faces/billTextClient.x
html?bill_id=201920200AB730)&#8220;
Die missbr&#228;uchliche Nutzung von Deepfakes ist aus Sicht der Fragesteller
zurzeit haupts&#228;chlich in drei Feldern zu beobachten bzw. zu bef&#252;rchten. Zum
einen bieten Deepfakes neue und bessere M&#246;glichkeiten f&#252;r Desinformation. So 
k&#246;nnen beispielsweise falsche Statements bzw. Fotos oder Videos von
Personen oder Ungl&#252;cksf&#228;llen nach Ansicht der Fragesteller im schlimmsten Fall 
Einfluss auf politische Prozesse nehmen. Ein weiterer Bereich ist die Nutzung 
von Deepfakes f&#252;r pornographische Inhalte. Publik wurde dieses Thema
k&#252;rzlich durch den Erfolg der App &#8222;DeepNude&#8220;, die aus Fotos einer bekleideten 
Person ein Nackt-Foto ebenjener Person generierte. Das Programm wurde
binnen k&#252;rzester Zeit 100.000fach heruntergeladen, sodass schlie&#223;lich die
Entwickler selbst die App vom Markt nahmen. Sie begr&#252;ndeten dies damit, dass 
Deutscher Bundestag Drucksache 19/15657
19. Wahlperiode 02.12.2019
Die Antwort wurde namens der Bundesregierung mit Schreiben des Bundesministeriums der Justiz und f&#252;r 
Verbraucherschutz vom 28. November 2019 &#252;bermittelt.
Die Drucksache enth&#228;lt zus&#228;tzlich &#8211; in kleinerer Schrifttype &#8211; den Fragetext.
bei einer solchen Masse an Nutzern trotz der getroffenen
Sicherheitsvorkehrungen (wie z. B. Wasserzeichen auf den Bildern) ein Missbrauch der
Anwendung nicht auszuschlie&#223;en sei und sie auf diesem Wege kein Geld verdienen 
wollen (www.twitter.com/deepnudeapp/status/1144307316231200768). 
Anzumerken ist jedoch, dass dies lediglich mit weiblichen K&#246;rpern
funktionierte (www.heise.de/tr/artikel/Deepfakes-Die-nackte-Gefahr-4458332.html). 
Dar&#252;ber hinaus werden immer bessere Videos pornographischen Inhalts
erstellt, in denen die Gesichter der Akteure mit Hilfe k&#252;nstlicher Intelligenz
ausgetauscht werden. Zurzeit sind hiervon haupts&#228;chlich prominente
K&#252;nstlerinnen betroffen, jedoch sind vermehrt auch Privatpersonen das Ziel der
Manipulationen. Bereits jetzt gibt es die M&#246;glichkeit, gegen Bitcoins einen Deepfake-
Porno mit einer beliebigen Person zu erwerben (www.wired.com/story/most-d
eepfakes-porn-multiplying-fast/). Voraussetzung ist lediglich gen&#252;gend
Bildmaterial, was zum Teil bereits durch die Links zu Social-Media-Profilen
gegeben ist. Solche Videoclips k&#246;nnen nach Ansicht der Fragesteller als Grundlage 
f&#252;r beispielsweise Erpressungen, Verleumdungen oder weiteres strafrechtlich 
relevantes Verhalten dienen. Bisher ist zu beobachten, dass von dieser
Problematik haupts&#228;chlich Frauen betroffen sind. Eine weitere Gefahr von
Deepfakes ist der Bereich der Identifizierung bzw. Authentifizierung. Biometrische 
Merkmale wie die Stimme, die Iris oder das Gesicht lassen sich mit immer 
weniger Aufwand bei zeitgleich immer besserer Qualit&#228;t unter Zuhilfenahme 
k&#252;nstlicher Intelligenz f&#228;lschen. Vor allem im Hinblick auf das Video-Ident-
Verfahren er&#246;ffnet sich hier die Gefahr eines weitreichenden
Identit&#228;tsdiebstahls (vgl. www.computerwoche.de/a/so-manipulieren-hacker-audio-und-vide
odaten,3545745).
Zusammenfassend l&#228;sst sich sagen, dass Deepfakes nach Ansicht der
Fragesteller das Potential haben, die Sicherheit momentan angewendeter Methoden 
zur Authentifizierung im Rechtsverkehr zu untergraben, das Vertrauen der
Bev&#246;lkerung in den &#246;ffentlichen Diskurs zu besch&#228;digen sowie gerade bei
pornographischen Inhalten nicht nur massiv die Pers&#246;nlichkeitsrechte Betroffener zu 
verletzen, sondern auch tiefgreifende pers&#246;nliche Sch&#228;den zu verursachen.
Jedoch gibt es auch aktive Bestrebungen und Forschungen zur Erkennung von 
manipulierten Bild-, Ton- oder Videoaufnahmen. So hat Facebook zusammen 
mit einigen Partnern wie Microsoft oder Amazon die &#8222;Deepfake Detection 
Challenge&#8220;, kurz: DFDC (www.deepfakedetectionchallenge.ai/), ins Leben 
gerufen, welche im Dezember 2019 starten wird und die Forschung im
Bereich der automatisierten Erkennung von Deepfakes vorantreiben soll.
Es kann jedoch auch durchaus positive Einsatzm&#246;glichkeiten von Deepfakes 
geben. Im kulturellen Bereich hat beispielsweise die Zeitung &#8222;The Times&#8220;
zusammen mit Rothco einen ersten Schritt mit dem Projekt &#8222;JFK Unsilenced&#8220; 
gemacht, indem sie die Rede, die John F. Kennedy am Tag seiner Ermordung 
in Dallas h&#228;tte halten sollen, mit Hilfe von k&#252;nstlicher Intelligenz und einem 
Deepfake in seiner Stimme vertont hat (www.rothco.ie/work/jfk-unsilenced/). 
Ebenso ist ein Einsatz im medizinischen Bereich denkbar. Deepfakes k&#246;nnen 
zum Beispiel Menschen helfen, die aufgrund von Behinderungen oder
chronischen Erkrankungen ihre Stimme verlieren, eine authentische Stimme zur 
Kommunikation zu erhalten oder sogar ihre eigene Stimme gewisserma&#223;en zu 
behalten (www.projectrevoice.org/).
1. In welchen Zusammenh&#228;ngen besch&#228;ftigt sich die Bundesregierung mit 
dem Thema Deepfakes?
Welche Ressorts und dort jeweils welche Abteilungen, Referate oder 
Stabsstellen besch&#228;ftigen sich konkret mit dem Thema?
Das Thema Deep Fakes wird in der Bundesregierung &#252;bergreifend &#8211; auch
innerhalb der obersten Bundesbeh&#246;rden &#8211; behandelt. Insbesondere im Rahmen 
der Kabinettklausur am 17. und 18. November 2019 in Meseberg hat sich die 
Bundesregierung mit dem Thema auseinandergesetzt.
Deep Fakes k&#246;nnen eine gro&#223;e Gefahr f&#252;r Gesellschaft und Politik darstellen, 
wenn sie dazu genutzt werden, die &#246;ffentliche Meinung zu manipulieren und 
den politischen Prozess gezielt zu beeinflussen. Mit dem Themenkomplex
Desinformation besch&#228;ftigen sich im Ausw&#228;rtigen Amt verschiedene
Arbeitseinheiten unter der Federf&#252;hrung der Steuerungsgruppe Strategische
Kommunikation und ebenfalls die Beauftragte der Bundesregierung f&#252;r Kultur und Medien 
sowie das Bundesministerium der Justiz und f&#252;r Verbraucherschutz. Im 
Bundesministerium f&#252;r Bildung und Forschung besch&#228;ftigt sich die Abteilung 
&#8222;Forschung f&#252;r Digitalisierung und Innovationen&#8220; mit dem Thema Deep Fakes 
durch die F&#246;rderung von Forschungsvorhaben zur Erkennung und Bek&#228;mpfung 
von Desinformationen (&#8222;Fake News&#8220;) und im Rahmen der IT-Forensik.
Deep Fakes stellen bei der Kriminalit&#228;tsbek&#228;mpfung eine gro&#223;e
Herausforderung dar und stehen daher aufgrund der hierbei genutzten KI-gest&#252;tzten
Technologien auch mit im Fokus des entsprechenden Arbeitsbereichs der Abteilung 
Cyber- und Informationssicherheit im Bundesministerium des Innern, f&#252;r Bau 
und Heimat (BMI). Des Weiteren besch&#228;ftigt sich das BMI federf&#252;hrend mit 
hybriden Bedrohungen. In diesem Kontext sind Deep Fakes ein denkbares
Mittel der Einflussnahme durch Verbreitung von Desinformation.
Die Arbeitseinheiten in den Abteilungen &#8222;Digitale Gesellschaft;
Verwaltungsdigitalisierung und Informationstechnik&#8220; und &#8222;&#214;ffentliche Sicherheit&#8220;
besch&#228;ftigen sich mit dem Thema im Kontext der Fernidentifizierung. Durch den
Einsatz von Deep Fakes ist es m&#246;glich, videobasierte Verfahren zu manipulieren. 
Beispielsweise kann eine zu identifizierende Person eine andere Person auf
einem gestohlenen Ausweisdokument imitieren.
Mit Deep Fakes aus sozialwissenschaftlicher Perspektive als Instrument
hybrider Kriegsf&#252;hrung besch&#228;ftigt sich an der Helmut-Schmidt-Universit&#228;t/
Universit&#228;t der Bundeswehr Hamburg, welche dem Bundesministerium der
Verteidigung (BMVg) zugeordnet ist, die Professur f&#252;r Politische Theorie im Rahmen 
der thematischen Schwerpunkte &#8222;Digitale Demokratie&#8220; und &#8222;Hybride
Bedrohungen&#8220; und fragt danach, welche funktionalen Voraussetzungen liberaler
Demokratien dadurch besch&#228;digt werden.
Dar&#252;ber hinaus beobachtet das BMVg technologische Entwicklungen in
Zusammenhang mit Deep Fakes in ihren Implikationen f&#252;r den Gesch&#228;ftsbereich 
BMVg wachsam.
Die zielgruppengerechte Vermittlung von Digitalkompetenzen ist eine
Kernherausforderung der digitalen Gesellschaft. Dazu geh&#246;rt auch die zeitgem&#228;&#223;e und 
dem jeweiligen Stand der Technik entsprechende Kompetenz,
Falschinformationen aller Art zu erkennen und bewerten zu k&#246;nnen. Das Bundesministerium 
f&#252;r Familie, Senioren Frauen und Jugend entwickelt und f&#246;rdert in
unterschiedlichen Projekten und Ma&#223;nahmen Kompetenzvermittlung (vgl. Ma&#223;nahmen im 
Handlungsfeld Digitale Kompetenz der Umsetzungsstrategie Digitalisierung 
der Bundesregierung) als auch entsprechende grundlegende Konzepte und
Forschung (wie z. B. im Rahmen des Projektes Digitales Deutschland www.digid.j
ff.de).
Auch das Bundeskanzleramt befasst sich im Rahmen seiner Aufgaben mit dem 
Themenkomplex hybride Bedrohungen und betrachtet hierbei u. a. Fragen der 
(gesellschaftlichen) Resilienz.
Im Presse- und Informationsamt der Bundesregierung besch&#228;ftigen sich alle 
Abteilungen im Rahmen ihrer Zust&#228;ndigkeiten auch mit diesem Thema.
2. Welche Definition von Deepfakes legt die Bundesregierung ihrer
Besch&#228;ftigung mit diesem Thema zugrunde?
Die Bundesregierung sieht kein Erfordernis einer eigenen, von &#246;ffentlichen 
Quellen abweichenden Definition.
3. Unterscheidet die Bundesregierung in ihrer Besch&#228;ftigung mit dem Thema 
Deepfakes zwischen legitimen oder harmlosen (bzw. rechtm&#228;&#223;igen) und 
illegitimen oder gef&#228;hrlichen (bzw. rechtswidrigen) Zwecken zur
Erstellung oder Verwendung von Deepfakes?
In welche Kategorie fallen f&#252;r die Bundesregierung Manipulationen von 
Medien (Audio, Foto, Video) zu Zwecken der Satire, der (kulturellen)
Bildung oder der pornographischen Darstellung?
4. In welchen Bereichen sieht die Bundesregierung konkreten Nutzen, der 
von Deepfakes ausgeht?
Wie sch&#228;tzt die Bundesregierung den Nutzen von Deepfakes
beispielsweise zum Zweck der Satire, der (kulturellen) Bildung oder der
pornographischen Darstellung ein?
5. In welchen Bereichen sieht die Bundesregierung konkrete Gefahren, die 
von Deepfakes ausgehen?
Wie sch&#228;tzt die Bundesregierung die Gefahren von Deepfakes
beispielsweise zum Zweck der Satire, der (kulturellen) Bildung oder der
pornographischen Darstellung ein?
Die Fragen 3 bis 5 werden gemeinsam beantwortet.
Die Entwicklung und Forschung zum Thema Deep Fakes steht noch am
Anfang. Auf dieser noch fortzuentwickelnden wissenschaftlichen Basis ist eine 
strikte Unterscheidung zwischen harmlos und gef&#228;hrlich zurzeit nicht
zielf&#252;hrend. Vor diesem Hintergrund kann auch das konkrete Nutzungspotential von 
Deep-Fake-Anwendungen noch nicht sicher abgesch&#228;tzt werden. Positive
Aspekte k&#246;nnen aber unter Umst&#228;nden zum Beispiel in der Museumsp&#228;dagogik 
oder f&#252;r k&#252;nstlerische und satirische Zwecke erzielt werden.
Gleichzeitig k&#246;nnen Deep-Fake-Anwendungen auch eine Gefahr darstellen, da 
Deep Fakes grunds&#228;tzlich zur Manipulation der &#246;ffentlichen Meinung und
damit zur gezielten Einflussnahme auf den politischen Prozess eingesetzt werden 
k&#246;nnen. Grunds&#228;tzlich f&#252;hren moderne Methoden der K&#252;nstlichen Intelligenz 
(KI) wie die durch neuronale Netze gest&#252;tzte k&#252;nstliche Erzeugung von Bildern 
und Videoclips oder auch das gezielte Ver&#228;ndern von Bildern dazu, dass
k&#252;nstliches Bild- und Videomaterial immer echter wirkt. So wird es in der Praxis
zunehmend schwieriger, zwischen authentischem und k&#252;nstlich erzeugtem bzw. 
ver&#228;ndertem Material zu unterscheiden. Dies k&#246;nnte auch f&#252;r Angriffe auf
videobasierte Fernidentifizierungsverfahren genutzt werden. Mit fortschreitender 
Entwicklung der Technik verbessern sich gleichzeitig auch die Mechanismen 
zur Erkennung von F&#228;lschungen und F&#228;lschungsversuchen, wenngleich kaum 
eine 100prozentige Verifizierung m&#246;glich sein wird. Daher ist es wichtig, dass 
die Sicherheitsbeh&#246;rden ihre technologiegest&#252;tzten F&#228;higkeiten und Methoden 
stetig weiterentwickeln.
6. Hat die Bundesregierung zur Erforschung von Nutzen und Gefahren von 
Deepfakes bereits Studien in Auftrag gegeben?
Wenn ja, welche?
Welche bereits existierenden Studien zum Nutzen und zu den Gefahren 
von Deepfakes sind der Bundesregierung bekannt?
Die Bundesregierung h&#228;lt die St&#228;rkung der Medienkompetenz, insbesondere 
der Nachrichten- und der digitalen Informationskompetenz, f&#252;r entscheidend, 
um gegen Desinformation im Allgemeinen und Deep Fakes im Besonderen
gewappnet zu sein. Dies beinhaltet u. a. F&#228;higkeitenausbau zur Identifizierung 
von Deep Fakes, Zusammenarbeit mit der Privatwirtschaft, der
Zivilgesellschaft und unabh&#228;ngigen Medien sowie die St&#228;rkung von Resilienz gegen&#252;ber 
Desinformation.
Die Beauftragte der Bundesregierung f&#252;r Kultur und Medien f&#246;rdert aktuell
eine Studie der Stiftung Neue Verantwortung, die die digitale
Nachrichtenkompetenz in Deutschland alters&#252;bergreifend erfassen und damit Ansatzpunkte zu
ihrer Verbesserung aufzeigen soll.
Der Schwerpunkt der Medienkompetenzf&#246;rderung der Beauftragten f&#252;r Kultur 
und Medien soll in Zukunft auf der St&#228;rkung der Nachrichten- und digitalen
Informationskompetenz liegen.
Im Forschungsrahmenprogramm der Bundesregierung zur IT-Sicherheit 
&#8222;Selbstbestimmt und sicher in der digitalen Welt 2015&#8211;2020&#8220; stellen
Untersuchungen zur sicheren und demokratischen Gestaltung der direkten politischen 
und gesellschaftlichen Beteiligung einen wichtigen Bestandteil dar. Ein
Beispiel daf&#252;r ist das Projekt DORIAN, in dem ein Podcast beim Hessischen 
Rundfunk entstand, der als Material in Schulen dienen wird, um Sch&#252;lerinnen 
und Sch&#252;ler f&#252;r die Merkmale von Desinformation zu sensibilisieren. Ein
weiteres Beispiel sind die verschiedenen Aufkl&#228;rungsformate (bspw.
b&#252;rgerorientierte Veranstaltungen, Beitr&#228;ge in &#252;berregionalen Medien) des Nationalen
Forschungszentrums f&#252;r angewandte Cybersicherheit CRISP/ATHENE zum
Thema Deep Fake. Im &#220;brigen wird auf die Antwort der Bundesregierung auf die 
Kleine Anfrage der Fraktion der FDP auf Bundestagsdrucksache 19/3649
verwiesen.
7. Welche rechtlichen Regelungen existieren nach Ansicht der
Bundesregierung bereits, die konkret auf Deepfakes anwendbar sind?
Welchen Regelungsbedarf in Bezug auf Deepfakes sieht die
Bundesregierung dar&#252;ber hinaus &#8211; m&#246;glicherweise auch nur in Bezug auf einzelne
Anwendungsbereiche von Deepfakes?
Auf so genannte Deep Fakes finden generell-abstrakte Regelungen
Anwendung. Spezifische Regelungen auf Bundesebene, die ausschlie&#223;lich Deep-Fake-
Anwendungen erfassen oder f&#252;r diese geschaffen wurden, existieren nicht. Die 
Bundesregierung &#252;berpr&#252;ft den Rechtsrahmen auf Bundesebene fortlaufend
daraufhin, ob aufgrund von technologischen oder gesellschaftlichen
Herausforderungen ein Anpassungsbedarf besteht.
8. Hat die Bundesregierung zur rechtlichen Einordnung und zum rechtlichen 
Regelungsbedarf in Bezug auf Deepfakes bereits Studien in Auftrag
gegeben?
Wenn ja, welche?
Welche bereits existierenden Studien zur rechtlichen Einordnung und zum 
rechtlichen Regelungsbedarf in Bezug auf Deepfakes sind der
Bundesregierung bekannt?
Es wird auf die Antwort zu Frage 6 verwiesen.
9. Wie viele gerichtliche Auseinandersetzungen oder Strafverfahren, in
denen es um Deepfakes und ihre Auswirkungen ging, gab es nach Kenntnis 
der Bundesregierung seit dem Jahr 2015 (bitte nach Jahren aufschl&#252;sseln)?
Die F&#252;hrung von Zivil- und Strafverfahren f&#228;llt grunds&#228;tzlich in die
Zust&#228;ndigkeit der L&#228;nder. Die Bundesregierung &#228;u&#223;ert sich grunds&#228;tzlich nicht zu
Sachverhalten, die in die Zust&#228;ndigkeit der L&#228;nder fallen. Erg&#228;nzend ist darauf
hinzuweisen, dass keine bundesweite statistische Erfassung von gerichtlichen
Auseinandersetzungen, in denen es um das Ph&#228;nomen der Deep Fakes und ihren 
Auswirkungen geht, existiert.
10. Wie sch&#228;tzt die Bundesregierung die M&#246;glichkeit der Ausl&#246;sung oder 
Vertiefung diplomatischer Spannungsf&#228;lle durch Deepfakes ein?
Wie bereitet sich die Bundesregierung auf m&#246;gliche diplomatische
Spannungsf&#228;lle vor, die durch Deepfakes ausgel&#246;st oder vertieft werden?
Welche konkreten Ma&#223;nahmen hat die Bundesregierung bisher dazu
ergriffen oder sind in Planung (wie z. B. die Entwicklung von Strategien 
oder Leitf&#228;den zur Krisenkommunikation, Szenarienworkshops, Media 
Forensik, Aufbau von Expertise im Ausw&#228;rtigen Amt)?
Es kann nicht ausgeschlossen werden, dass aufgrund der schnellen
technologischen Fortschritte k&#252;nftig auch eine Bedrohung demokratischer Prozesse durch 
Deep Fakes erfolgen kann. So k&#246;nnten Desinformationskampagnen durch Deep 
Fakes begleitet und ihr Effekt verst&#228;rkt werden. Mit Desinformation im
Kontext hybrider Bedrohungen befasst sich die ressort&#252;bergreifende Arbeitsgruppe 
zur Strategischen Koordination des Umgangs mit Hybriden Bedrohungen (vgl. 
Ziffer 2 der Vorbemerkung der Bundesregierung zur Antwort auf die Kleine 
Anfrage auf Bundestagsdrucksache 19/12489). Die Bundesregierung stimmt 
sich in der Horizontalen Arbeitsgruppe &#8222;St&#228;rkung der Resilienz und Abwehr 
hybrider Bedrohungen&#8220; mit den anderen Mitgliedstaaten der EU ab. Die
Mitgliedstaaten sind au&#223;erdem &#252;ber das Rapid Alert System (RAS) miteinander 
verbunden, in welchem Erkenntnisse zu Desinformation und damit auch zu 
Deep Fakes geteilt werden k&#246;nnen. Auch die Klausurtagung des
Bundeskabinetts im November 2019 behandelte u. a. das Thema Deep Fakes.
11. Welche Ma&#223;nahmen plant die Bundesregierung, um die gesellschaftliche 
Resilienz und Medienkompetenz der Bev&#246;lkerung zu st&#228;rken und die 
B&#252;rgerinnen und B&#252;rger dazu zu bef&#228;higen, Deepfakes und ihre
Auswirkungen besser zu erkennen?
Es wird auf die Antwort zu Frage 6 verwiesen.
12. Welche Hilfem&#246;glichkeiten existieren nach Kenntnis der
Bundesregierung f&#252;r Betroffene von Deepfakes?
Welche Beratungs- und Hilfestellen existieren nach Kenntnis der 
Bundesregierung, die insbesondere Betroffene von Deepfakes
adressieren?
Die Beratung der Verbraucherinnen und Verbraucher ist grunds&#228;tzlich Aufgabe 
der L&#228;nder. Die Bundesregierung verf&#252;gt derzeit nicht &#252;ber Informationen
dar&#252;ber, ob in den L&#228;ndern entsprechende Beratungs- und Hilfeeinrichtungen
speziell zu Deep-Fake-Anwendungen bestehen. Unabh&#228;ngig davon bestehen
Beratungseinrichtungen f&#252;r die Opfer von Straftaten und die Beratungsstellen der 
Verbraucherzentralen.
Vorkommnisse im Zusammenhang mit Deep Fakes k&#246;nnen im
Gesch&#228;ftsbereich des BMVg &#252;ber die etablierten Meldewege dienstlich zur Kenntnis
gebracht werden.
13. Welchen gesamtgesellschaftlichen Einfluss k&#246;nnten Deepfakes nach
Ansicht der Bundesregierung entfalten?
Wie sch&#228;tzt die Bundesregierung etwa das Potential von Deepfakes zur 
Verunsicherung der Bev&#246;lkerung in Bezug auf das Vertrauen in wahre 
und unwahre Informationen ein?
Deep Fakes k&#246;nnen das gesellschaftliche Vertrauen in die grunds&#228;tzliche
Echtheit von Audio- und Videoaufnahmen und damit die Glaubw&#252;rdigkeit
&#246;ffentlich verf&#252;gbarer Informationen schw&#228;chen. Noch k&#246;nnen auch komplexe Deep 
Fakes zeitnah und schnell erkannt werden. Ein problematisches Szenario w&#228;re 
eine schwererkennbare Technik in Massenanwendung im Rahmen plausibler, 
aber verf&#228;lschter Narrative. Angesichts der noch geringen Relevanz f&#252;r die
&#214;ffentlichkeit warnen Wissenschaftler vor einer &#220;berbewertung der Gefahren von 
Deep Fakes f&#252;r demokratische Prozesse (z. B. verglichen mit Desinformation).
14. Was plant die Bundesregierung, um Deepfakes insbesondere im
Zusammenhang mit Wahlen zu bek&#228;mpfen?
Plant die Bundesregierung in diesem Bereich Ma&#223;nahmen in Bezug auf 
Social-Media-Plattformen?
Wenn ja, welche?
Es besteht die M&#246;glichkeit, dass Deep Fakes mit dem Ziel der Desinformation 
beispielsweise &#252;ber soziale Netzwerke verbreitet werden, um Einfluss auf den 
politischen Prozess zu nehmen. Die Bundesregierung begr&#252;&#223;t in diesem
Zusammenhang den EU Code of practice on disinformation, den die gro&#223;en 
Online-Plattformen und Verb&#228;nde der Werbewirtschaft im Dezember 2018 mit 
der EU-Kommission unterzeichnet haben. Die Bundesregierung begr&#252;&#223;t
gleichfalls, dass die EU sich nach dem Zwischenbericht zur Umsetzung des
Aktionsplans gegen Desinformation (JOIN(2019) 12 final) weitere Schritte,
einschlie&#223;lich regulatorischer Ma&#223;nahmen, vorbeh&#228;lt.
15. Welche Bem&#252;hungen und Ma&#223;nahmen oder Vorschl&#228;ge f&#252;r Ma&#223;nahmen 
in Bezug auf Deepfakes sind der Bundesregierung auf EU-Ebene und auf 
Ebene der anderen EU-Mitgliedstaaten bekannt?
Gem&#228;&#223; dem EU-Aktionsplan gegen Desinformation (JOIN(2018) 36 final) 
wird die Kommission gegebenenfalls Informationskampagnen unterst&#252;tzen, um
die &#214;ffentlichkeit f&#252;r neueste Technologien wie Deep Fakes zu sensibilisieren. 
Dar&#252;ber hinaus k&#246;nnte der geplante Digital Services Act
Regulierungsma&#223;nahmen zu Deep Fakes beinhalten.
16. Wird die Bundesregierung den Umgang mit Deepfakes &#8211; im
Zusammenhang mit, aber auch au&#223;erhalb von Wahlen &#8211; als ein Thema der
deutschen EU-Ratspr&#228;sidentschaft 2021 festlegen?
Es wird auf die Vorbemerkung der Bundesregierung in der Antwort auf die 
Kleine Anfrage der Fraktion B&#220;NDNIS 90/DIE GR&#220;NEN
(Bundestagsdrucksache 19/15236) verwiesen.
17. Wurde das Thema Deepfakes nach Kenntnis der Bundesregierung in den 
Verhandlungen zum Medienstaatsvertrag behandelt?
Wenn ja, in welcher Form?
Wenn nein, warum nicht?
Der Medienstaatsvertrag f&#228;llt in die Zust&#228;ndigkeit der L&#228;nder. Der
Bundesregierung liegen keine Informationen vor, ob bzw. inwieweit das Thema Deep 
Fakes in den Verhandlungen zur Novellierung des Medienstaatsvertrags er&#246;rtert 
wurde.
18. Welche technischen M&#246;glichkeiten zur Erkennung von Deepfakes sind 
der Bundesregierung bekannt?
Welche Forschungsvorhaben gibt es nach Kenntnis der Bundesregierung 
hierzu in Deutschland und weltweit?
Mit jeder neuen Technologie entstehen seit jeher auch neue M&#246;glichkeiten und 
Angriffsszenarien im Zusammenhang mit Straftaten. KI-Technologie, die von 
Straft&#228;tern bei der Erstellung von Deep Fakes verwendet wird, kann auf Seiten 
der Sicherheitsbeh&#246;rden als Instrument ma&#223;geblich bei der Strafverfolgung,
Ermittlung und Analyse unterst&#252;tzen. So k&#246;nnen beispielsweise Methoden der 
K&#252;nstlichen Intelligenz (KI) bzw. des maschinellen Lernens auch herangezogen 
werden, um Deep Fakes, welche mittels KI-Methoden erzeugt werden, gezielt 
zu erkennen. Weiterhin wird der aktuelle Forschungsstand beobachtet, z. B. zur 
Erkennung und zu Nutzen und Gefahren von Deep Fakes.
Zur Erkennung von Deep Fakes eignen sich Werkzeuge der
Multimediaforensik, mit denen sich Manipulationsspuren in Multimediadaten technisch
erkennen und nachweisen lassen. In Deutschland besch&#228;ftigt sich insbesondere das 
Nationale Forschungszentrum f&#252;r angewandte Cybersicherheit CRISP/ATHE-
NE, aber auch die TU M&#252;nchen oder das Fraunhofer-Institut mit diesem
Thema. Zudem haben der deutsche Auslandssender Deutsche Welle (DW), das 
Fraunhofer-Institut f&#252;r Digitale Medientechnologie (IDMT) und das Athens 
Technology Center (ATC) das gemeinsame Forschungsprojekt &#8222;Digger&#8220;
gestartet. Ziel des Projekts ist es, die webbasierte Verifikationsplattform &#8222;Truly
Media&#8220; von DW und ATC u. a. um die Audioforensik-Technologien des
Fraunhofer IDMT zu erweitern und Journalisten auf diese Weise zu helfen,
Manipulationen an audiovisuellen Inhalten zu erkennen. Weltweit wird die Erkennung von 
Deep Fakes zudem beispielsweise von Wissenschaftlern an der New York
University oder an der University of California/Berkeley erforscht. Zudem ist die 
Software &#8222;Face Forensics&#8220; bekannt, die mittels K&#252;nstlicher Intelligenz die
zugrundeliegenden Muster bei der Erstellung von Deep Fakes erkennt.
Noch nicht abgeschlossen ist nach Kenntnis der Bundesregierung ein aktuelles 
Forschungsvorhaben der Konrad-Adenauer-Stiftung zu den gesellschaftlichen 
Auswirkungen von Deep Fakes, das in Zusammenarbeit mit Counter
Extremism Project unter Beteiligung von Prof. Dr. Hany Farid (University of
California, Berkeley) durchgef&#252;hrt wird.
Im &#220;brigen wird auf die Antwort der Bundesregierung auf die Schriftliche
Frage 30 des Abgeordneten Konstantin Kuhle auf Bundestagsdrucksache 19/13020 
verwiesen, deren Aussagen auch hier sinngem&#228;&#223; gelten.
Auch die Datenethikkommission der Bundesregierung hat sich ihren am 
23. Oktober 2019 ver&#246;ffentlichten Empfehlungen mit dem Thema Deep Fakes 
besch&#228;ftigt. Die Empfehlungen der Datenethikkommission sind abrufbar unter 
https://datenethikkommission.de/wp-content/uploads/191028_DEK_Gutach
ten_bf.pdf .
Gesamtherstellung: H. Heenemann GmbH &amp; Co. KG, Buch- und Offsetdruckerei, Bessemerstra&#223;e 83&#8211;91, 12103 Berlin, www.heenemann-druck.de
Vertrieb: Bundesanzeiger Verlag GmbH, Postfach 10 05 34, 50445 K&#246;ln, Telefon (02 21) 97 66 83 40, Fax (02 21) 97 66 83 44, www.betrifft-gesetze.de
ISSN 0722-8333]</text>
    <titel>auf die Kleine Anfrage
- Drucksache 19/15210 -
Besch&#228;ftigung der Bundesregierung mit Deep Fakes</titel>
    <datum>2019-12-02</datum>
  </document>
  