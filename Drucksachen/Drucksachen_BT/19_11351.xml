<document>
    <id>231721</id>
    <drucksachetyp>Antwort</drucksachetyp>
    <dokumentart>Drucksache</dokumentart>
    <autoren_anzahl>0</autoren_anzahl>
    <typ>Dokument</typ>
    <vorgangsbezug_anzahl>1</vorgangsbezug_anzahl>
    <dokumentnummer>19/11351</dokumentnummer>
    <wahlperiode>19</wahlperiode>
    <herausgeber>BT</herausgeber>
    <pdf_hash>5bd77a2b49b5731e1a7d9384550d7a38</pdf_hash>
    <aktualisiert>2022-07-26T19:57:18+02:00</aktualisiert>
    <vorgangsbezug>
      <id>249659</id>
      <titel>Aussagen der Bundesministerin der Justiz und f&#252;r Verbraucherschutz zur Algorithmenkontrolle</titel>
      <vorgangstyp>Kleine Anfrage</vorgangstyp>
    </vorgangsbezug>
    <urheber>
      <einbringer>false</einbringer>
      <bezeichnung>BRg</bezeichnung>
      <titel>Bundesregierung</titel>
    </urheber>
    <ressort>
      <federfuehrend>true</federfuehrend>
      <titel>Bundesministerium der Justiz und f&#252;r Verbraucherschutz</titel>
    </ressort>
    <fundstelle>
      <pdf_url>https://dserver.bundestag.de/btd/19/113/1911351.pdf</pdf_url>
      <id>231721</id>
      <dokumentnummer>19/11351</dokumentnummer>
      <datum>2019-07-03</datum>
      <dokumentart>Drucksache</dokumentart>
      <drucksachetyp>Antwort</drucksachetyp>
      <herausgeber>BT</herausgeber>
      <urheber>Bundesregierung</urheber>
    </fundstelle>
    <text>[Die Antwort wurde namens der Bundesregierung mit Schreiben des Bundesministeriums der Justiz und f&#252;r  
Verbraucherschutz vom 2. Juli 2019 &#252;bermittelt.  
Die Drucksache enth&#228;lt zus&#228;tzlich &#8211; in kleinerer Schrifttype &#8211; den Fragetext. 
Deutscher Bundestag  Drucksache 19/11351 
19. Wahlperiode 03.07.2019 
Antwort 
der Bundesregierung 
auf die Kleine Anfrage der Abgeordneten Roman M&#252;ller-B&#246;hm, Stephan Thomae,  
Grigorios Aggelidis, weiterer Abgeordneter und der Fraktion der FDP 
&#8211; Drucksache 19/10965 &#8211; 
Aussagen der Bundesministerin der Justiz und f&#252;r Verbraucherschutz zur 
Algorithmenkontrolle 
V o r b e m e r k u n g  d e r  F r a g e s t e l l e r  
Die k&#252;rzlich zur&#252;ckgetretene Bundesministerin der Justiz und f&#252;r
Verbraucherschutz, Dr. Katarina Barley, hat am 24. Mai 2019 zu den Forderungen der
Verbraucherschutzministerkonferenz bez&#252;glich einer Algorithmenkontrolle
Stellung bezogen. Dabei betonte sie, dass das letzte Wort bei wichtigen
Entscheidungen immer der Mensch haben m&#252;sse. Gleichzeitig forderte die
Bundesministerin Dr. Katarina Barley eine &#220;berpr&#252;fbarkeit bei Entscheidungen, die
Computer &#252;ber Menschen treffen sowie eine st&#228;rkere Regulierung des Trackings auf 
europ&#228;ischer Ebene (www.bmjv.de/SharedDocs/Zitate/DE/2019/052419_ 
Algorithmen.html;jsessionid=2522E98D37E43D92C4EC3FC2A04B0A56.1_ 
cid334). 
Fraglich ist, welche konkreten Ma&#223;nahmen aus den Aussagen der
Bundesministerin, insbesondere nach ihrem R&#252;cktritt, folgen. 
1. Inwiefern f&#252;hlt sich die Bundesregierung an die Aussagen und Forderungen 
der ehemaligen Bundesjustizministerin, Dr. Katarina Barley, hinsichtlich der 
Verbraucherschutzministerkonferenz (www.bmjv.de/SharedDocs/Zitate/DE/ 
2019/052419_Algorithmen.html;jsessionid=2522E98D37E43D92C4EC3FC 
2A04B0A56.1_cid334) auch nach ihrem R&#252;cktritt gebunden? 
2. Inwiefern stimmt die Bundesregierung den Aussagen und Forderungen der 
ehemaligen Bundesjustizministerin, Dr. Katarina Barley, hinsichtlich der 
Verbraucherschutzministerkonferenz zu?
3. Welche Ma&#223;nahmen folgen f&#252;r die Bundesregierung im Allgemeinen und 
das Bundesministerium der Justiz und f&#252;r Verbraucherschutz (BMJV)  
im Speziellen aus der Aussage der ehemaligen Bundesjustizministerin  
Dr. Katarina Barley, es brauche Transparenz und &#220;berpr&#252;fbarkeit bei
Entscheidungen, die Computer &#252;ber Menschen treffen? 
4. Gab oder gibt es Bestrebungen oder Vorbereitungen innerhalb der
Bundesregierung im Allgemeinen und dem BMJV im Speziellen, eine Regulierung 
von Algorithmen hinsichtlich ihrer Transparenz, Nachvollziehbarkeit oder 
&#220;berpr&#252;fbarkeit vorzunehmen? 
Wenn ja, welche? 
Die Fragen 1 bis 4 werden zusammen beantwortet.  
Algorithmen-basierte Entscheidungen bergen neben vorhandenen Chancen auch 
Risiken, etwa wenn damit die Verarbeitung von Verbraucherdaten verbunden ist 
und weil h&#228;ufig die Anwendbarkeit eines Algorithmus die Bewertung von
Pers&#246;nlichkeitsmerkmalen voraussetzt sowie wenn Prognosen &#252;ber das Verhalten 
von Verbrauchern erstellt werden. Algorithmen-basierte Entscheidungen k&#246;nnen 
gesellschaftliche Ungleichheit festigen und Diskriminierungen fortschreiben, 
wenn in den der Entscheidung zugrunde liegenden Daten bereits
Benachteiligungen angelegt sind. Hierdurch k&#246;nnen insbesondere die Handlungsfreiheit, die 
Chancengleichheit und die Selbstbestimmung von Verbraucherinnen und
Verbrauchern gef&#228;hrdet werden. Wenn Algorithmen dar&#252;ber entscheiden, welche
Informationen welcher Person an welcher Stelle in sozialen Netzwerken angezeigt 
werden, kann dies Auswirkungen auf die Vielfalt von Informationen, den
&#246;ffentlichen Diskurs und damit auf den demokratischen Willensbildungsprozess haben.  
Vor diesem Hintergrund pr&#252;ft die Bundesregierung, welche Ma&#223;nahmen auf
nationaler und europ&#228;ischer Ebene erforderlich sind. Die Bundesregierung hat im 
Herbst 2018 eine Datenethikkommission eingesetzt, die binnen eines Jahres
ethische Ma&#223;st&#228;be entwickeln sowie konkrete Regulierungsoptionen in den
Bereichen Umgang mit Daten, Algorithmen-basierte Entscheidungen und K&#252;nstliche 
Intelligenz vorschlagen soll. Die Leitfragen der Bundesregierung an die
Datenethikkommission k&#246;nnen hier abgerufen werden:  
www.bmjv.de/SharedDocs/Downloads/DE/Ministerium/ForschungUndWissenschaft/ 
DEK_Leitfragen.pdf?__blob=publicationFile&amp;v=1 
Die Datenethikkommission wird ihre Ergebnisse voraussichtlich am 23. Oktober 
2019 der Bundesregierung vorstellen. Die Bundesregierung wird die
Empfehlungen der Datenethikkommission abwarten, bevor sie ihre Pr&#252;fung m&#246;glichen
gesetzgeberischen Handlungsbedarfs abschlie&#223;t. Im Rahmen ihrer &#220;berlegungen 
werden auch die auf internationaler Ebene formulierten Prinzipien f&#252;r die
Entwicklung und Anwendung von K&#252;nstlicher Intelligenz einflie&#223;en. Hierzu geh&#246;ren 
zum Beispiel die von der Organisation for Economic Co-operation and
Development (OECD) verabschiedeten Empfehlungen, die unter anderem das Erfordernis 
der Menschenzentriertheit und Transparenz von KI-Anwendungen betonen.
5. Glaubt die Bundesregierung an die technische Umsetzbarkeit einer
&#220;berpr&#252;fung von Algorithmen? 
a) Falls ja, inwiefern gilt dies auch f&#252;r Systeme, die &#8222;maschinelles Lernen&#8220; 
betreiben? 
b) Falls ja, wie stellt sich die Bundesregierung eine solche &#220;berpr&#252;fung
sowohl in technischer Hinsicht als auch im Hinblick auf die beh&#246;rdliche
Zust&#228;ndigkeit vor? 
c) Falls nein, wie l&#228;sst sich dies mit den Aussagen der ehemaligen
Bundesjustizministerin Dr. Katarina Barley vereinbaren? 
d) Welche Konsequenzen plant die Bundesregierung f&#252;r Algorithmen, die 
sich (z. B. aufgrund ihres Aufbaus oder ihrer Komplexit&#228;t) nicht
kontrollieren lassen? 
Die &#220;berpr&#252;fbarkeit von Algorithmen-basierten Entscheidungen und KI-
Anwendungen ist eine wichtige Voraussetzung zum Schutz von B&#252;rgerinnen und
B&#252;rgern. Vor diesem Hintergrund hat die Bundesregierung die
Datenethikkommission auch darum gebeten, sich mit der &#220;berpr&#252;fbarkeit von Algorithmen-
basierten Entscheidungen und KI-Anwendungen zu befassen. Die Bundesregierung hat 
an die Datenethikkommission unter anderem folgende Leitfragen gerichtet: 
&#61485; Wie kann Verl&#228;sslichkeit, Reproduzierbarkeit und &#220;berpr&#252;fbarkeit von
Algorithmen-basierten-Entscheidungen gew&#228;hrleistet werden? 
&#61485; Gibt es Grenzen des Einsatzes von Algorithmen-basierten Entscheidungen, 
wenn Einsatz und Kriterien den betroffenen Menschen nicht erkl&#228;rt werden 
k&#246;nnen? 
&#61485; Sind Testmethoden m&#246;glich, die selbstlernende Algorithmen-basierte
Entscheidungen &#252;berpr&#252;fbar machen? 
Die technische Umsetzung einer &#220;berpr&#252;fbarkeit von Algorithmen-basierten
Entscheidungen und KI-Anwendungen ist Gegenstand der wissenschaftlichen
Debatte. Dabei steht gerade auch die &#220;berpr&#252;fung von selbstlernenden Systemen im 
Mittelpunkt der Forschung. Diese hat inzwischen diverse L&#246;sungsans&#228;tze
entwickelt, so zum Beispiel den &#8222;Counterfactual Explanations&#8220;-Ansatz, bei dem  
der Input variiert wird, um herauszufinden, ab welcher Abweichung des Inputs  
ein anderes Ergebnis erzielt w&#252;rde, oder der &#8222;Layer-wise Relevance
Propagation&#8220;-Ansatz, bei dem &#8211; grob vereinfacht &#8211; ein KI-Prozess r&#252;ckw&#228;rts vom Output 
zum Input simuliert wird, um zu ermitteln, inwieweit einzelne neuronalen
Schichten f&#252;r die Entscheidung relevant geworden sind.  
Die Datenethikkommission soll sich entsprechend der Leitfragen zudem damit 
befassen, wie Algorithmen-basierte Entscheidungen und KI-Anwendungen
beaufsichtigt werden k&#246;nnen. Die Bundesregierung wird die Empfehlungen der
Datenethikkommission abwarten, bevor sie ihre Pr&#252;fung des m&#246;glichen
Handlungsbedarfs auch in Bezug auf beh&#246;rdliche Zust&#228;ndigkeiten abschlie&#223;t.
6. Welche Ma&#223;nahmen folgen f&#252;r die Bundesregierung im Allgemeinen und 
das BMJV im Speziellen aus der Aussage der ehemaligen
Bundesjustizministerin Dr. Katarina Barley, der Mensch m&#252;sse bei wichtigen
Entscheidungen immer das letzte Wort haben? 
a) Plant die Bundesregierung, diese Forderung gesetzlich zu statuieren? 
Wenn ja, wann plant die Bundesregierung die Einbringung eines
entsprechenden Gesetzentwurfs in den Deutschen Bundestag? 
b) Welche Entscheidungen sind aus Sicht der Bundesregierung &#8222;wichtige 
Entscheidungen&#8220;, bei denen der Mensch das letzte Wort haben solle? 
Mit der Aussage, der Mensch m&#252;sse bei wichtigen Entscheidungen immer das 
letzte Wort haben, wird ein wesentlicher Grundwert unserer
Gesellschaftsordnung zum Ausdruck gebracht. Dieser Grundwert ist mit dem grunds&#228;tzlichen
Verbot der automatisierten Einzelfallentscheidung bereits in Artikel 22 DSGVO
angelegt. Auch die Prinzipien der OECD zur Entwicklung und Anwendung von 
K&#252;nstlicher Intelligenz betonen die Bedeutung der Menschenzentriertheit von  
KI-Anwendungen. Zudem folgt bereits aus dem Grundgesetz, das der Mensch 
nicht zum blo&#223;en Objekt von Maschinen-Entscheidungen werden darf. Im
&#220;brigen wird auf die Antwort zu den Fragen 1 bis 4 verwiesen. 
7. Inwiefern findet nach Ansicht der Bundesregierung, wie von der ehemaligen 
Bundesjustizministerin ge&#228;u&#223;ert, eine &#8222;Manipulation des Einzelnen&#8220; durch 
Algorithmen statt?  
a) Welche F&#228;lle von Manipulation des Einzelnen durch Algorithmen sind 
der Bundesregierung bekannt? 
b) Welche F&#228;lle, bei denen Algorithmen die Auswahl von &#196;rzten
vorbestimmt haben, sind der Bundesregierung bekannt? 
c) Welche F&#228;lle, bei denen Algorithmen die Jobsuche vorbestimmt haben, 
sind der Bundesregierung bekannt? 
d) Welche F&#228;lle, bei denen Algorithmen die Partnersuche vorbestimmt
haben, sind der Bundesregierung bekannt? 
e) Falls nein, wie l&#228;sst sich dies mit den Aussagen der Bundesministerin 
Dr. Katarina Barley auf der Homepage des BMJV vereinbaren? 
Die M&#246;glichkeiten durch Big-Data-Analysen Prognosen &#252;ber zuk&#252;nftiges 
menschliches Verhalten zu erstellen, nehmen stetig zu. Dadurch steigt das Risiko 
weitreichender Vorfestlegungen und von ungerechtfertigten Benachteiligungen. 
Dieses Risiko ist umso problematischer, je sensibler der betroffene Lebensbereich 
ist, z. B. bei Entscheidungen zur privaten Lebensgestaltung oder zu
gesundheitlichen oder beruflichen Fragen. Software zur Bewerberauswahl, die eine
automatisierte Vorauswahl mit Hilfe von Online-Pers&#246;nlichkeitstests vornimmt, kann 
zur Folge haben, dass Bewerberinnen und Bewerber zu einem fr&#252;hen Zeitpunkt 
allein deswegen aus dem Bewerbungsprozess ausscheiden, weil sie bestimmte 
Kriterien erf&#252;llen, die von der Algorithmen-basierten Entscheidung negativ
bewertet werden, obwohl diese Kriterien keine R&#252;ckschl&#252;sse auf die berufliche 
Qualifikation zulassen.
8. Teilt die Bundesregierung die Auffassung der ehemaligen
Bundesjustizministerin, dass das Tracking auf europ&#228;ischer Ebene st&#228;rker reguliert werden 
m&#252;sse? 
a) Inwiefern hat die Bundesregierung sich bereits f&#252;r eine st&#228;rkere
Regulierung des Trackings auf europ&#228;ischer Ebene eingesetzt? 
b) Inwiefern wird sich die Bundesregierung f&#252;r eine st&#228;rkere Regulierung 
des Trackings auf europ&#228;ischer Ebene einsetzen? 
c) Falls nein, wie l&#228;sst sich dies mit den Aussagen der Bundesministerin 
Dr. Katarina Barley auf der Homepage des BMJV vereinbaren? 
9. Welche Ma&#223;nahmen folgen f&#252;r die Bundesregierung im Allgemeinen und 
das BMJV im Speziellen aus der Aussage der ehemaligen
Bundesjustizministerin Dr. Katarina Barley, es brauche noch konkretere Regelungen f&#252;r die 
elektronische Kommunikation in der E-Privacy-Verordnung? 
a) Welchen konkreteren Regelungsbedarf sieht die Bundesregierung? 
b) Inwiefern hat die Bundesregierung sich bereits f&#252;r konkretere Regelungen 
eingesetzt? 
c) Inwiefern wird die Bundesregierung sich f&#252;r konkretere Regelungen
einsetzen? 
Die Fragen 8 und 9 werden wegen des Sachzusammenhangs gemeinsam
beantwortet. 
Die Bundesregierung weist darauf hin, dass es sich beim &#8222;Tracking&#8220; um einen 
rechtlich nicht definierten Begriff handelt. In der politischen Diskussion wird das 
Tracking eines Nutzers in Internet und digitaler Welt als die Erfassung und
Speicherung des kompletten Verhaltens und der Interaktionen eines Nutzers bei
Nutzung eines vernetzten Ger&#228;ts oder eines Dienstes verstanden. Dies kann
insbesondere die Interaktionen mit einer Webseite (z. B. Nachrichtenseite oder soziales 
Netzwerk), die Surfhistorie, die Kommunikation &#252;ber webbasierte E-Mail- und 
Messengerdienste, die Verweildauer auf einer Webseite, die Art und Weise des 
Eintippens oder die Lesegeschwindigkeit umfassen. Bei Nutzung eines mobilen 
vernetzten Endger&#228;tes k&#246;nnen zus&#228;tzlich Informationen &#252;ber den geografischen 
Standort und &#252;ber Uhrzeit, Datum und Dauer eines Anrufs hinzukommen. Aus 
diesen Tracking-Daten k&#246;nnen mittels Profiling pr&#228;zise Schlussfolgerungen &#252;ber 
eine Person gezogen werden. Die Tracking-Daten und die daraus mittels Profiling 
ermittelten Schlussfolgerungen sind h&#228;ufig die Basis sowohl f&#252;r die Erstellung 
von Algorithmen als auch f&#252;r die profilabh&#228;ngige Anwendung eines Algorithmus 
auf den einzelnen Nutzer. Die Erfassung und Verarbeitung von
personenbezogenen Daten bei der Nutzung von vernetzten Ger&#228;ten in Internet und digitaler Welt 
ist in der EU-Datenschutz-Grundverordnung geregelt sowie, wenn das Tracking 
auf der Speicherung von Informationen oder dem Zugriff auf Informationen im 
Endger&#228;t eines Nutzers, z. B. mittels Cookies, basiert, in den E-Privacy-
Regelungen. 
Nach Artikel 5 Absatz 3 der geltenden ePrivacy-Richtlinie (Richtlinie 2002/ 
58/EG in der durch die Richtlinie 2009/136/EG ge&#228;nderten Fassung) d&#252;rfen
Ger&#228;te-Identifier wie Cookies grunds&#228;tzlich nur mit Einwilligung des Nutzers
verwendet werden, es sei denn, solche Verfahren sind aus bestimmten Gr&#252;nden
technisch erforderlich. Artikel 8 des Entwurfs einer ePrivacy-Veordnung, &#252;ber die 
derzeit im Rat verhandelt wird, erlaubt nach der gegenw&#228;rtigen im Rat
verhandelten Fassung ohne die Einwilligung des Endnutzers nur in engen Grenzen, dass 
auf dessen Endeinrichtungen durch Dritte zugegriffen werden darf, um dort
Informationen zu speichern und abzurufen. Die Speicherung von Informationen
oder der Zugriff auf Informationen im Endger&#228;t zum Zwecke des Tracking geh&#246;rt 
nicht zu den T&#228;tigkeiten, f&#252;r die auf Endeinrichtungen des Endnutzers ohne
dessen Einwilligung zugegriffen werden darf. Die Bundesregierung hat sich im Rat 
im Rahmen der laufenden Verhandlungen zur ePrivacy-Verordnung daf&#252;r
eingesetzt, dass die von der Kommission vorgeschlagene Regelung des Artikels 8 nicht 
abgeschw&#228;cht wird. Sie setzt sich dar&#252;ber hinaus daf&#252;r ein, dass eine Regelung 
zu den Einstellungen zum Schutz der Privatsph&#228;re bei Internetbrowsern in die 
zuk&#252;nftige Verordnung aufgenommen wird. Eine solche Regelung, die
sicherstellen soll, dass Endnutzer ihre Privatsph&#228;re &#252;ber entsprechende Einstellungen in 
der Browsersoftware bewusst und wirksam sch&#252;tzen, war in dem urspr&#252;nglichen 
Vorschlag der Kommission enthalten. Die Bundesregierung hat dazu einen
konkreten Vorschlag vorgelegt. 
Die Bestimmungen der geltenden ePrivacy-Richtlinie bzw. der zuk&#252;nftigen  
ePrivacy-Verordnung regeln jedoch nicht die nachfolgende Verarbeitung
personenbezogener Daten, die im Rahmen eines nach den E-Privacy-Regelungen
zul&#228;ssigen Zugriffs auf Informationen in Endeinrichtungen erhoben werden. Die 
Rechtm&#228;&#223;igkeit dieser Datenverarbeitung beurteilt sich nach der Datenschutz-
Grundverordnung. Ob die Geschehnisse um das Unternehmen Cambridge
Analytica, auf die die Bundesministerin der Justiz und f&#252;r Verbraucherschutz in dem 
genannten Zitat Bezug nimmt, weitere Regelungen in der Datenschutz-
Grundverordnung zum Schutz der Nutzerinnen und Nutzer von Internet und vernetzten
Ger&#228;ten erfordern, bedarf weiterer Pr&#252;fung, insbesondere von Regelungen zur
Profilbildung und zur weiteren St&#228;rkung der Betroffenenrechte. Die
Bundesregierung weist dazu als n&#228;chsten Schritt auf den Bericht &#252;ber die Bewertung und 
&#220;berpr&#252;fung dieser Verordnung hin, den die Europ&#228;ische Kommission bis zum 
25. Mai 2020 dem Europ&#228;ischen Parlament und dem Rat vorlegen muss
(Artikel 97 DSGVO). 
Was die in der Frage angesprochenen konkreteren Regelungen in der
gegenw&#228;rtig beratenen E-Privacy-Verordnung und die entsprechenden Stellungnahmen 
der Bundesregierung betrifft, wird auf die Antwort der Bundesregierung zu der 
Frage 5e der Kleinen Anfrage der Fraktion DIE LINKE. betreffend
Verhandlungen &#252;ber den Datenschutz in der elektronischen Kommunikation (ePrivacy-
Reform) auf Bundestagsdrucksache 19/6709 verwiesen. Auf der Tagung des Rates 
der EU (Telekommunikation) am 7. Juni 2019 in Luxemburg hat sich
Deutschland dahingehend ge&#228;u&#223;ert, dass die e-Privacy-VO ein hohes, &#252;ber die DSGVO 
hinausreichendes Schutzniveau gew&#228;hrleisten m&#252;sse. Der vorliegende Text
erreiche dies nicht, weshalb Deutschland diesen nicht unterst&#252;tzen k&#246;nne.
&#196;nderungen seien n&#246;tig, speziell bei Artikel 6 bez&#252;glich der &#8222;kompatiblen
Weiterverarbeitung&#8220;. Au&#223;erdem setze man sich f&#252;r einen Erhalt von Artikel 10 ein. DEU 
w&#252;rde ein rasches Fortschreiten der Verhandlungen begr&#252;&#223;en.
 
 
 
 
 
Satz: Satzweiss.com Print, Web, Software GmbH, Mainzer Stra&#223;e 116, 66121 Saarbr&#252;cken, www.satzweiss.com 
Druck: Printsystem GmbH, Schafw&#228;sche 1-3, 71296 Heimsheim, www.printsystem.de 
Vertrieb: Bundesanzeiger Verlag GmbH, Postfach 10 05 34, 50445 K&#246;ln, Telefon (02 21) 97 66 83 40, Fax (02 21) 97 66 83 44, www.betrifft-gesetze.de 
ISSN 0722-8333]</text>
    <titel>auf die Kleine Anfrage
- Drucksache 19/10965 -
Aussagen der Bundesministerin der Justiz und f&#252;r Verbraucherschutz zur Algorithmenkontrolle</titel>
    <datum>2019-07-03</datum>
  </document>
  