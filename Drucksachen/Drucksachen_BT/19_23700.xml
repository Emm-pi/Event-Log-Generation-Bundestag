<document>
    <id>246822</id>
    <drucksachetyp>Unterrichtung</drucksachetyp>
    <dokumentart>Drucksache</dokumentart>
    <autoren_anzahl>0</autoren_anzahl>
    <typ>Dokument</typ>
    <vorgangsbezug_anzahl>1</vorgangsbezug_anzahl>
    <dokumentnummer>19/23700</dokumentnummer>
    <wahlperiode>19</wahlperiode>
    <herausgeber>BT</herausgeber>
    <pdf_hash>2a983dd0d5d3e0c1e462a7c36974a60d</pdf_hash>
    <aktualisiert>2022-07-26T19:57:15+02:00</aktualisiert>
    <vorgangsbezug>
      <id>237080</id>
      <titel>Enquete-Kommission "K&#252;nstliche Intelligenz - Gesellschaftliche Verantwortung und wirtschaftliche, soziale und &#246;kologische Potenziale"</titel>
      <vorgangstyp>Enquete-Kommission</vorgangstyp>
    </vorgangsbezug>
    <urheber>
      <einbringer>false</einbringer>
      <bezeichnung>Enquete-Kommission K&#252;nstliche Intelligenz</bezeichnung>
      <titel>Enquete-Kommission "K&#252;nstliche Intelligenz - Gesellschaftliche Verantwortung und wirtschaftliche, soziale und &#246;kologische Potenziale"</titel>
    </urheber>
    <fundstelle>
      <pdf_url>https://dserver.bundestag.de/btd/19/237/1923700.pdf</pdf_url>
      <id>246822</id>
      <dokumentnummer>19/23700</dokumentnummer>
      <datum>2020-10-28</datum>
      <verteildatum>2020-11-02</verteildatum>
      <dokumentart>Drucksache</dokumentart>
      <drucksachetyp>Unterrichtung</drucksachetyp>
      <herausgeber>BT</herausgeber>
      <urheber>Enquete-Kommission "K&#252;nstliche Intelligenz - Gesellschaftliche Verantwortung und wirtschaftliche, soziale und &#246;kologische Potenziale"</urheber>
    </fundstelle>
    <text>[Deutscher Bundestag Drucksache 19/23700
19. Wahlperiode 28.10.2020
Unterrichtung
der Enquete-Kommission K&#252;nstliche Intelligenz &#8211; Gesellschaftliche 
Verantwortung und wirtschaftliche, soziale und &#246;kologische Potenziale&#8727;
Bericht der Enquete-Kommission K&#252;nstliche Intelligenz &#8211; Gesellschaftliche 
Verantwortung und wirtschaftliche, soziale und &#246;kologische Potenziale
&#8727; Eingesetzt durch Beschluss des Deutschen Bundestages vom 26. Juni 2018 (Bundestagsdrucksache 19/2978).
Inhal tsverzeichnis
Seite
A. Kurzfassung des Berichts ............................................................. 28
Einleitung....................................................................................................... 28
&#220;berblick zu den Projektgruppen und dem Mantelbericht...................... 29
Zusammenfassung und Handlungsempfehlungen (Auswahl)................... 31
1 Daten .............................................................................................. 33
2 Forschung ...................................................................................... 34
3 Nachhaltigkeit durch KI und nachhaltige KI............................. 35
4 Wirtschaft und Arbeit .................................................................. 36
5 Kompetenzen, Bildung, M&#252;ndigkeit ........................................... 38
6 Mensch und Gesellschaft.............................................................. 40
7 Regulierung und Staat.................................................................. 41
B. Allgemeiner Teil: Auftrag und Arbeitsweise.............................. 43
1 Einsetzung und Konstituierung der Enquete-Kommission....... 43
2 Zusammensetzung der Enquete-Kommission ............................ 43
3 Organisatorische und verwaltungsm&#228;&#223;ige Begleitung der
Kommissionsarbeit ....................................................................... 44
4 Arbeitsauftrag der Enquete-Kommission................................... 44
5 Arbeitsweise der Enquete-Kommission ...................................... 45
Struktur der Arbeit .......................................................................... 45
Textarbeit in Projektgruppen und weiteren Arbeitsgruppen........... 45
Einbeziehung der &#214;ffentlichkeit und Pressearbeit.......................... 47
6 Kontext der Arbeit der Enquete-Kommission ........................... 49
C. Besonderer Teil: Bestandsaufnahme, Analyse,
Entwicklungsperspektiven und Handlungsempfehlungen........ 51
I. Mantelbericht: Projektgruppen&#252;bergreifende Themen............ 51
1 Begriffskl&#228;rung K&#252;nstliche Intelligenz ....................................... 51
KI-Systeme und KI-Arten............................................................... 51
Training von lernenden KI-Systemen............................................. 52
Arten des Trainings und Trainingsdaten......................................... 52
Einsatz und Qualit&#228;t von KI-Systemen........................................... 53
Seite
2 KI und Daten................................................................................. 53
Definitionen .................................................................................... 54
Qualit&#228;t von Daten.......................................................................... 54
Arten von Daten.............................................................................. 55
Zugang zu Daten............................................................................. 56
Personenbezogene Daten ................................................................ 56
Politischer Handlungsrahmen bez&#252;glich KI und Daten.................. 58
3 KI und Umgang mit Bias/Diskriminierung ................................ 60
Begriffskl&#228;rung Bias ....................................................................... 60
Diskriminierung durch Bias............................................................ 61
Erkennung von Diskriminierung..................................................... 61
Vermeidung von Diskriminierung .................................................. 62
Handlungsempfehlungen ................................................................ 63
4 KI und Umgang mit Risiko .......................................................... 63
Begriffskl&#228;rung Risiko.................................................................... 63
Transparenz, Nachvollziehbarkeit und Erkl&#228;rbarkeit ..................... 64
Sektorspezifisches Risikomanagement........................................... 65
KI-spezifisches Risikomanagement................................................ 66
Handlungsempfehlungen ................................................................ 67
5 KI und Recht ................................................................................. 67
Allgemeine Einf&#252;hrung zum Rechtsrahmen................................... 67
Datenschutzrecht............................................................................. 68
Urheberrecht ................................................................................... 70
Wettbewerbsrecht ........................................................................... 72
Haftungsrecht.................................................................................. 74
5.5.1 E-Person.......................................................................................... 75
5.5.2 Zurechnung der Haftung im Rahmen der Verschuldenshaftung..... 75
5.5.3 M&#246;gliche Ausweitung der Gef&#228;hrdungshaftung............................. 75
5.5.4 M&#246;gliche L&#252;cken in der Produkthaftung ........................................ 75
5.5.5 Handlungsempfehlungen ................................................................ 77
Einsatz von KI in der &#246;ffentlichen Verwaltung .............................. 77
Handlungsempfehlungen ................................................................ 78
6 Ethische Perspektiven auf KI ...................................................... 80
Ziele und Zwecke einer KI-Ethik ................................................... 80
Ethische Perspektiven auf KI (Prinzipien, Werte) .......................... 81
Seite
6.2.1 Autonomie (Selbstbestimmung des Menschen als Handelnder, 
Entscheidungsfreiheit, Nicht-Manipulation)................................... 83
6.2.2 Menschsein (Mensch-Maschine-Interaktion, Selbstverst&#228;ndnis).... 84
6.2.3 Vertrauen (Zuversicht, Optimismus, Kritik, Zusammenhalt) ......... 84
6.2.4 Gemeinwohl (Wohlstandsf&#246;rderung, Benefits, Interessen) ............ 84
6.2.5 Verantwortung (Gutes tun, Akteure, Zusammenarbeit).................. 85
6.2.6 Transparenz (Nachvollziehbarkeit, Erkl&#228;rbarkeit, Offenheit) ........ 85
6.2.7 Gerechtigkeit (Partizipation/Teilhabe, Verteilung, Leistung)......... 86
6.2.8 Diskriminierungsfreiheit (Gleichberechtigung, Fairness)............... 86
Ethik und KI &#8211; Wirksamkeit von Ethik und Dialog........................ 86
7 KI und Gesellschaft ...................................................................... 87
Gesellschaftlicher Reflexionsbedarf in Bezug auf die Wirkung 
von KI-Systemen ............................................................................ 87
Auswirkungen von KI-Systemen auf die Gesellschaft ................... 88
Entwicklung und Einsatz von KI-Systemen im Sinne von 
Nachhaltigkeit und Wohlstand........................................................ 91
Handlungsempfehlungen ................................................................ 92
8 KI und &#246;kologische Nachhaltigkeit ............................................. 93
Definition, Abgrenzung, Forschungsstand ..................................... 94
Energie- und Ressourcenverbrauch ................................................ 95
Potenziale von KI f&#252;r das Vorantreiben der Energiewende............ 96
8.3.1 KI kann die Akzeptanz der Energiewende in der Bev&#246;lkerung 
st&#228;rken............................................................................................. 96
8.3.2 KI kann helfen, Erneuerbare Energien besser in das
Energiesystem zu integrieren.......................................................... 96
8.3.3 KI kann helfen, Energiem&#228;rkte effizienter zu machen und damit
Kosten zu reduzieren ...................................................................... 97
KI in der Klimawissenschaft........................................................... 97
Einsatz von KI-Anwendungen im Naturschutz und im Umwelt-
Monitoring ...................................................................................... 98
Fazit ................................................................................................ 99
Handlungsempfehlungen ................................................................ 99
9 KI und Forschung......................................................................... 100
Einleitung und &#220;berblick................................................................ 100
Leitlinien......................................................................................... 101
9.2.1 Leitlinie 1: Zugrundeliegende Werte .............................................. 101
9.2.2 Leitlinie 2: F&#246;rderung von Leuchtturm-Institutionen in der
Forschung ....................................................................................... 101
Seite
9.2.3 Leitlinie 3: F&#246;rderung der Forschung in der Breite ........................ 102
9.2.4 Leitlinie 4: Beziehung Wissenschaft &#8211; Wirtschaft &#8211;
Zivilgesellschaft.............................................................................. 102
Strategische Ziele............................................................................ 102
SWOT-Analyse der KI-Forschung in Deutschland ........................ 103
9.4.1 Welche St&#228;rken hat die KI-Forschung in Deutschland? ................. 103
9.4.2 Welche Probleme hat die KI-Forschung in Deutschland? .............. 104
9.4.3 Welche Potenziale k&#246;nnen erschlossen werden? ............................ 105
9.4.4 Welche Risiken bestehen? .............................................................. 105
Zentrale Handlungsempfehlungen f&#252;r den Staat............................. 106
Zukunftsthemen .............................................................................. 108
10 KI und SARS-CoV-2 .................................................................... 108
Potenziale und Anwendungsbeispiele von KI zur Eind&#228;mmung 
und Beherrschung von Pandemien (insbesondere der Covid-19-
Pandemie) ....................................................................................... 110
Notwendige Entwicklungen in der KI sowie strukturelle
Verbesserungen, um auf zuk&#252;nftige Pandemien besser
vorbereitet zu sein........................................................................... 112
Chance in der Krise f&#252;r st&#228;rkere Translation und h&#246;here
Akzeptanz von KI ........................................................................... 115
Fazit ................................................................................................ 116
II. K&#252;nstliche Intelligenz und Wirtschaft (Projektgruppe 1) ........ 116
1 Kurzfassung des Projektgruppenberichts .................................. 116
2 Vorbemerkungen .......................................................................... 120
3 Einf&#252;hrung: Anwendungsfelder und Potenziale von KI in 
der Wirtschaft ............................................................................... 123
Grundlagen und Sachstandskl&#228;rung: KI hat gro&#223;es Potenzial, ist
aber kein Selbstl&#228;ufer...................................................................... 123
KI in einf&#252;hrenden Szenarien ......................................................... 127
Zielstellungen: Deutschland im Jahr 2030 &#8211; eine Vision................ 130
3.3.1 Angestrebte Gesellschafts- und Politikziele: Die Wirtschaft 
setzt KI unter Einhaltung ethisch vereinbarter Normen ein............ 131
3.3.2 Angestrebte Forschungsziele: KI-Forschung ist in Unternehmen 
etabliert ........................................................................................... 133
3.3.3 Angestrebte Wirtschaftsziele: &#8222;KI made in Germany&#8220; als
internationales G&#252;tesiegel............................................................... 133
4 Thematischer Schwerpunkt ......................................................... 136
Status quo von KI im Bereich der Wirtschaft ................................. 136
4.1.1 Stand der Gesellschaft: Akzeptanz und Erwartungen..................... 137
Seite
4.1.2 Stand der Forschung ....................................................................... 139
4.1.2.1 Die Herausforderungen einer holistischen KI-Forschung und 
-Entwicklung................................................................................... 139
4.1.2.2 Diversit&#228;t als St&#228;rke? Die deutsche Akteurslandschaft in
Forschung und Entwicklung ........................................................... 140
4.1.2.3 Bestehende Ans&#228;tze zur F&#246;rderung von KI in Forschung und 
Entwicklung.................................................................................... 141
4.1.3 Stand des Marktes........................................................................... 142
4.1.3.1 Akteure im Markt: Start-ups, KMU und Konzerne 144
4.1.3.1.1 Themenfeld Start-ups...................................................................... 145
4.1.3.1.2 Themenfeld Mittelstand.................................................................. 147
4.1.3.1.3 Themenfeld Konzerne: Konzerne in der KI-Transformation.......... 149
4.1.3.2 Branchen......................................................................................... 150
4.1.3.2.1 Themenfeld Industrie und Produktion: Daten als
Produktkomponente in der produzierenden Industrie ..................... 150
4.1.3.2.2 Themenfeld Handel......................................................................... 151
4.1.3.2.3 Themenfeld Finanzmarkt und Versicherungen............................... 153
4.1.3.2.4 Themenfeld Agrar&#246;konomie und Landwirtschaft........................... 155
4.1.4 Hardware/Infrastruktur ................................................................... 156
4.1.5 &#214;kologie ......................................................................................... 157
4.1.6 Stand der Administration/Politik &#8211; rechtliche Fragen..................... 160
4.1.7 Zugang zu Daten f&#252;r KI-Anwendungen ......................................... 164
SWOT-Analyse............................................................................... 166
5 Handlungsempfehlungen und Perspektiven ............................... 168
Wachstum, Wertsch&#246;pfung und Nachhaltigkeit mit 
und durch KI ................................................................................... 168
5.1.1 &#8222;KI made in Germany&#8220; und der europ&#228;ische Weg ......................... 169
5.1.2 Unternehmerischer Mut und Transferf&#246;rderung ............................. 171
5.1.3 Technologische Souver&#228;nit&#228;t .......................................................... 172
5.1.4 Nachhaltigkeit................................................................................. 173
Unterst&#252;tzung der KI-Akteure ........................................................ 174
5.2.1 Innovation und Start-ups: Start-up-&#214;kosysteme, 
Start-up-F&#246;rderungen...................................................................... 174
5.2.2 KMU............................................................................................... 176
5.2.3 Konzerne im Spannungsfeld zwischen etablierten und neuen 
Gesch&#228;ftsmodellen.......................................................................... 177
Erkenntnisse zu Branchen............................................................... 178
5.3.1 Industrie und Produktion ................................................................ 178
5.3.2 Handel............................................................................................. 179
5.3.3 Finanzmarkt und Versicherungen................................................... 179
5.3.4 Landwirtschaft ................................................................................ 180
Handlungsempfehlungen zu Daten und Plattformen ...................... 180
Seite
Fachkr&#228;fte ....................................................................................... 182
Rechtsentwicklung und Politik ....................................................... 183
KI-Forschung.................................................................................. 184
III. K&#252;nstliche Intelligenz und Staat (Projektgruppe 2) .................. 185
Allgemeiner Teil ............................................................................................ 185
1 Kurzfassung des Projektgruppenberichts .................................. 185
2 Vorbemerkungen (AG-unabh&#228;ngig) ........................................... 191
3 Handlungsempfehlungen.............................................................. 193
Auswirkungen von KI-Empfehlungen auf die
Entscheidungsautonomie untersuchen ............................................ 193
Soziale Innovationen f&#246;rdern.......................................................... 194
Einsatzgebiete f&#252;r KI systematisch identifizieren........................... 194
Standardprozesse f&#252;r Beschaffung, Einkauf, Implementierung 
und Betrieb etablieren..................................................................... 194
Kompetenzen aufbauen................................................................... 194
Transparenz schaffen und Risiken systematisch klassifizieren ...... 194
KI-gest&#252;tzte Entscheidungen regelm&#228;&#223;ig auf
Diskriminierungsfreiheit &#252;berpr&#252;fen .............................................. 195
Datenkonzepte erarbeiten und umsetzen ........................................ 195
Partizipation f&#246;rdern ....................................................................... 195
AG-Berichte................................................................................................... 196
1 AG 1: KI in der Verwaltung und internationale Vorbilder ...... 196
Einf&#252;hrung ...................................................................................... 196
Thematischer Scherpunkt ............................................................... 199
Handlungsempfehlungen und Operationalisierung......................... 210
2 AG 2: Smart City und Open Data ............................................... 211
Einf&#252;hrung ...................................................................................... 211
Thematischer Schwerpunkt............................................................. 214
Handlungsempfehlungen und Operationalisierung......................... 218
3 AG 3: Innere Sicherheit, &#196;u&#223;ere Sicherheit, IT-Sicherheit ...... 220
Innere Sicherheit ............................................................................. 220
3.1.1 Einf&#252;hrung ...................................................................................... 220
3.1.2 Thematischer Schwerpunkt............................................................. 220
3.1.3 Handlungsempfehlungen und Perspektiven.................................... 226
Seite
&#196;u&#223;ere Sicherheit ........................................................................... 227
3.2.1 Einf&#252;hrung ...................................................................................... 227
3.2.2 Thematischer Schwerpunkt............................................................. 227
3.2.3 Handlungsempfehlungen und Operationalisierung......................... 231
IT-Sicherheit ................................................................................... 233
3.3.1 Einf&#252;hrung ...................................................................................... 233
3.3.2 Thematischer Schwerpunkt............................................................. 234
3.3.3 Handlungsempfehlungen und Perspektiven.................................... 235
IV. K&#252;nstliche Intelligenz und Gesundheit (Projektgruppe 3) ....... 236
1 Zusammenfassung ........................................................................ 236
Potenziale spezifischer Anwendungen von KI und ihre
Risikoabsch&#228;tzung im Gesundheitsbereich..................................... 237
St&#228;rken und Schw&#228;chen, Chancen und Risiken.............................. 238
Handlungsfelder.............................................................................. 239
1.3.1 Voraussetzungen f&#252;r den Einsatz von KI im
Gesundheitsbereich: Digitalisierung, Datenverf&#252;gbarkeit und 
Aufbau von KI-Expertise in Gesundheitsberufen........................... 239
1.3.2 F&#246;rderung des Forschungs- und Wirtschaftsstandorts zur 
souver&#228;nen Entwicklung von KI im Gesundheitsbereich ............... 240
1.3.3 Zulassung, Erstattung und Haftung im Zusammenhang mit
neuen KI-Methoden ........................................................................ 241
1.3.4 Intelligente Assistenzsysteme und Robotik in der Pflege............... 242
Zehn Handlungsempfehlungen f&#252;r die Entwicklung und den 
Einsatz von KI im Gesundheitsbereich........................................... 243
2 Einf&#252;hrung: KI und Gesundheit ................................................. 244
Was macht KI im Gesundheitswesen aus? ..................................... 244
Ziele, Themen und Leitfragen ........................................................ 245
Ethische Fragen .............................................................................. 246
3 Anwendungen von KI in Gesundheit und Pflege ....................... 247
KI-Anwendungen in der Medizin &#8211; Beispiele aus Diagnose und
Therapie .......................................................................................... 248
3.1.1 Bilderkennung: KI-Verfahren in der Krebsdiagnose ...................... 248
3.1.2 Spracherkennung: Diagnose von Alzheimer durch 
automatisierte kognitive Tests ........................................................ 250
3.1.3 Mustererkennung in medizinischen Daten zur Pr&#228;vention,
zur Diagnose und zum Monitoring ................................................. 250
KI-Anwendungen in der Pflege ...................................................... 253
Weitere Anwendungsgebiete mit Gesundheitsbezug...................... 255
SWOT-Analyse............................................................................... 256
Seite
4 Handlungsfelder............................................................................ 258
Voraussetzungen f&#252;r KI im Gesundheitsbereich ............................ 258
4.1.1 Digitalisierung und digitale Infrastruktur ....................................... 258
4.1.2 Datenschutz, Datenverf&#252;gbarkeit und Umgang mit
Patientendaten................................................................................. 259
4.1.3 Aus-, Weiter- und Fortbildung in Gesundheitsberufen................... 263
4.1.4 Handlungsempfehlungen ................................................................ 264
F&#246;rderung des Forschungs- und Wirtschaftsstandorts &#8211; f&#252;r eine 
souver&#228;ne Entwicklung von KI im Gesundheitsbereich ................. 265
4.2.1 KI in der medizinischen Forschung ................................................ 265
4.2.2 Forschungsdaten &#8211; Verf&#252;gbarkeit, Qualit&#228;t und offene
Standards......................................................................................... 266
4.2.3 Forschungslandschaft, F&#246;rderstrukturen und Kooperationen ......... 268
4.2.4 Wirtschaftsstandort, Transfer und Start-ups ................................... 269
4.2.5 Handlungsempfehlungen ................................................................ 270
Entwicklung, Marktzulassung, Erstattung und Haftung f&#252;r KI-
basierte Anwendungen im Gesundheitsbereich .............................. 270
4.3.1 Entwicklung, Marktzulassung und Erstattung ................................ 270
4.3.2 Haftungsfragen ............................................................................... 272
4.3.3 Handlungsempfehlungen ................................................................ 274
KI in der Pflege sowie f&#252;r Menschen mit Behinderung.................. 274
4.4.1 Verortung, Potenziale und Risiken ................................................. 274
4.4.2 Status quo von KI-Anwendungen in der Pflege.............................. 276
4.4.3 Rahmenbedingungen f&#252;r einen erfolgreichen Einsatz von KI in 
der Pflege........................................................................................ 277
4.4.4 Handlungsempfehlungen ................................................................ 279
5 Hintergrundinformationen zur Projektgruppe KI und 
Gesundheit..................................................................................... 279
Expertise durch handelnde Akteure ................................................ 279
Arbeitsstruktur der Gruppe ............................................................. 280
Auftrag gem&#228;&#223; Einsetzungsbeschluss............................................. 281
V. K&#252;nstliche Intelligenz und Arbeit (Projektgruppe 4)................ 281
1 Kurzfassung des Projektgruppenberichts .................................. 281
2 Vorbemerkungen .......................................................................... 289
3 Einf&#252;hrung .................................................................................... 290
Grundlagen und Sachstandskl&#228;rung................................................ 290
Einf&#252;hrende Beispiele bzw. Anwendungsf&#228;lle (Use Cases) ........... 292
3.2.1 Beispiele f&#252;r KI-Anwendungen im betrieblichen Einsatz oder
in der Erprobung ............................................................................. 292
Seite
3.2.1.1 Assistenz- und Serviceroboter ........................................................ 292
3.2.1.2 Wissens- und Assistenzsysteme...................................................... 293
3.2.1.3 Prozessoptimierung durch Predictive Analysis............................... 294
3.2.1.4 KI-basierte Chatbots ....................................................................... 295
3.2.1.5 Intelligente Sprachanalyse .............................................................. 296
3.2.2 Beispiele f&#252;r KI-Anwendungen in Schule und Hochschule ........... 297
3.2.2.1 Lehrmittel mit intelligenter Sensorik und Data Analytics .............. 297
3.2.2.2 Learning Analytics und Data Analytics im Lernmanagement........ 298
3.2.2.3 Lernunterst&#252;tzender Einsatz von KI-Systemen............................... 298
3.2.2.4 KI-Grundlagen und Robotik an Schulen......................................... 299
3.2.3 Beispiele f&#252;r KI-Anwendungen in der Forschung .......................... 299
3.2.3.1 Prognose bzw. Simulation .............................................................. 299
3.2.3.2 Auswertung von Forschungsergebnissen bzw. 
Forschungsanalyse .......................................................................... 300
Deutschland 2030: Vision einer &#8222;freundlichen KI&#8220;........................ 300
3.3.1 Wie die Arbeitswelt von morgen aussehen k&#246;nnte......................... 300
3.3.1.1 Leitvorstellungen ............................................................................ 300
3.3.1.2 Vision 2030 &#8211; mit KI arbeiten ........................................................ 301
3.3.2 Wie die Bildung von morgen aussehen k&#246;nnte............................... 302
3.3.3 Wie die Forschung von morgen aussehen k&#246;nnte........................... 303
4 Technologieakzeptanz als Erfolgskriterium f&#252;r 
den KI-Einsatz (Treiber und Bremser)....................................... 304
Treiber der Entwicklung ................................................................. 305
Bremser der Entwicklung ............................................................... 306
5 Status quo und Handlungsempfehlungen: KI und Arbeit,
Bildung, Forschung....................................................................... 306
KI in der Arbeitswelt ...................................................................... 306
5.1.1 Entwicklung des Arbeitsmarktes (Prognosen, 
Arbeitsmarktforschung) .................................................................. 306
5.1.1.1 Folgen der Automatisierung f&#252;r den Arbeitsmarkt ......................... 306
5.1.1.2 Bislang wenig Forschung zu den Besch&#228;ftigungseffekten 
von KI ............................................................................................. 307
5.1.1.3 Handlungsempfehlungen ................................................................ 308
5.1.1.3.1 Die Auswirkungen von KI f&#252;r den Arbeitsmarkt weiter
erforschen ....................................................................................... 308
5.1.1.3.2 Strukturwandel flankieren &#8211; politische Ma&#223;nahmen evaluieren
und anpassen................................................................................... 309
5.1.2 (Qualitative) Auswirkungen von KI auf die Arbeitswelt................ 309
5.1.2.1 Strukturelle &#196;nderungen der Arbeitswelt: Plattformarbeit ............. 310
5.1.2.2 Mensch-Maschine-Interaktion ........................................................ 311
5.1.2.3 Neue Qualifikationsanforderungen................................................. 311
5.1.2.4 Arbeitsbedingungen........................................................................ 313
5.1.2.5 Partizipation und Mitbestimmung................................................... 317
Seite
5.1.2.6 Handlungsempfehlungen ................................................................ 319
5.1.2.6.1 Im Allgemeinen .............................................................................. 319
5.1.2.6.2 Mensch-Maschine-Interaktion ........................................................ 320
5.1.2.6.3 Mitbestimmung modernisieren ....................................................... 320
5.1.3 Arbeitsorganisation und Arbeitsverwaltung ................................... 322
5.1.3.1 Arbeitsorganisation......................................................................... 322
5.1.3.2 Einsatz von automatisierten Entscheidungssystemen und KI in 
der Personalverwaltung................................................................... 324
5.1.3.3 KI in der Arbeits- und Sozialverwaltung ........................................ 325
5.1.3.4 Weiterentwicklung der sozialen Sicherungssysteme ...................... 327
5.1.3.5 Handlungsempfehlungen ................................................................ 328
5.1.3.5.1 Arbeitsorganisation......................................................................... 328
5.1.3.5.2 Einsatz von automatisierten Entscheidungssystemen und KI in 
der Personalverwaltung................................................................... 330
5.1.3.5.3 KI in der Arbeits- und Sozialverwaltung ........................................ 331
5.1.3.5.4 Weiterentwicklung der sozialen Sicherungssysteme ...................... 332
KI in der Bildung ............................................................................ 332
5.2.1 Lernen &#252;ber KI................................................................................ 333
5.2.2 Lernen mit KI ................................................................................. 333
5.2.3 Umgang mit KI bzw. Learning Analytics....................................... 335
5.2.4 Anforderungen an den Schulunterricht ........................................... 336
5.2.5 Lehrkr&#228;ftebildung ........................................................................... 338
5.2.6 KI und Hochschule ......................................................................... 338
5.2.7 KI in Aus- und Weiterbildung ........................................................ 339
5.2.8 Handlungsempfehlungen ................................................................ 340
5.2.8.1 Lehrkr&#228;ftebildung ........................................................................... 340
5.2.8.2 Aus- und Weiterbildung.................................................................. 341
KI in der Forschung ........................................................................ 344
5.3.1 Disembodied und Embodied KI...................................................... 344
5.3.1.1 Disembodied KI.............................................................................. 344
5.3.1.2 Embodied KI................................................................................... 345
5.3.2 Formen der KI-Forschung .............................................................. 345
5.3.3 Handlungsempfehlungen ................................................................ 346
Gestaltungsinstrumente und Gestaltungsakteure ............................ 347
SWOT-Analyse............................................................................... 348
6 Appendix........................................................................................ 351
Auflistung der in den Sitzungen angeh&#246;rten Expertinnen und 
Experten.......................................................................................... 351
Auflistung der Mitglieder der Projektgruppe.................................. 352
Aufgaben der Normsetzungsinstanzen in der Arbeitswelt.............. 353
Aufgaben der Normsetzungsinstanzen in der Bildung ................... 354
Seite
VI. K&#252;nstliche Intelligenz und Mobilit&#228;t (Projektgruppe 5) ........... 355
1 Kurzfassung des Projektgruppenberichts .................................. 355
Kurzfassung .................................................................................... 355
1.1.1 Themen&#252;bergreifende Handlungsempfehlungen der
Projektgruppe.................................................................................. 356
1.1.2 Themenschwerpunkte ..................................................................... 357
Anmerkung zur Corona-Pandemie 2020 ........................................ 359
2 Vorbemerkungen .......................................................................... 359
Expertise durch handelnde Akteure:............................................... 360
Vorgehensweise und Arbeitsstruktur.............................................. 360
3 Einf&#252;hrung .................................................................................... 361
4 Thematischer Schwerpunkt und Handlungsempfehlungen...... 362
Zukunft der Mobilit&#228;t...................................................................... 362
4.1.1 Vision KI und Mobilit&#228;t &#8211; Status quo............................................. 362
4.1.2 Anwendungsbeispiele, Trends und Ausblicke der einzelnen 
Themenfelder.................................................................................. 365
4.1.3 Handlungsempfehlungen ................................................................ 368
Intermodalit&#228;t und Plattformen....................................................... 370
4.2.1 Definitionen .................................................................................... 370
4.2.2 Status quo........................................................................................ 371
4.2.3 Mobilit&#228;t im innerst&#228;dtischen Raum............................................... 373
4.2.4 Gemeinn&#252;tzige KI-L&#246;sungen.......................................................... 374
4.2.5 Mobilit&#228;t im l&#228;ndlichen Raum ........................................................ 374
4.2.6 Plattformen: Tendenz zur Bildung von Monopolen und 
Oligopolen ...................................................................................... 375
4.2.7 Handlungsempfehlungen ................................................................ 375
Stra&#223;enverkehr................................................................................ 376
4.3.1 KI und Mobilit&#228;t: Automobil und Stra&#223;enverkehr.......................... 376
4.3.2 Begriffsbestimmungen.................................................................... 377
4.3.3 Status quo........................................................................................ 378
4.3.4 KI und autonome Automobile ........................................................ 379
4.3.5 KI und Organisation der Stra&#223;e ...................................................... 382
4.3.6 KI und Organisation der Mobilit&#228;t.................................................. 383
4.3.7 Die Erh&#246;hung der Sicherheit und die ganzheitliche Betrachtung 
der Mobilit&#228;t ................................................................................... 384
4.3.8 Handlungsempfehlungen ................................................................ 384
Schienenverkehr ............................................................................. 386
4.4.1 Status quo und Politik ..................................................................... 386
4.4.2 Potenziale........................................................................................ 388
Seite
4.4.3 Handlungsempfehlungen ................................................................ 389
Luftverkehr ..................................................................................... 389
4.5.1 Status quo........................................................................................ 389
4.5.2 Potenziale von KI in der Luftfahrt .................................................. 390
4.5.3 Handlungsempfehlungen ................................................................ 393
Schiffsverkehr................................................................................. 394
4.6.1 Status quo........................................................................................ 394
4.6.2 Potenziale und Beispiele................................................................. 395
4.6.3 Handlungsempfehlungen ................................................................ 396
&#220;bergreifende Themen (&#214;konomie und Wettbewerb, 
Stadtentwicklung) ........................................................................... 397
4.7.1 Status quo........................................................................................ 397
4.7.2 KI mit Blick auf &#214;konomie und Wettbewerb................................. 400
4.7.3 KI und Stadtentwicklung ................................................................ 401
4.7.4 Sicherheit bei KI-gest&#252;tzter Mobilit&#228;t: ........................................... 403
4.7.5 Handlungsempfehlungen ................................................................ 403
VII. K&#252;nstliche Intelligenz und Medien (Projektgruppe 6) .............. 404
1 Kurzfassung des Projektgruppenberichts .................................. 404
2 Vorbemerkungen .......................................................................... 410
3 Einf&#252;hrung .................................................................................... 412
Grundlagen und Sachstandskl&#228;rung................................................ 413
3.1.1 Exemplarische Betrachtung des Zusammenhangs Medien und 
KI .................................................................................................... 414
3.1.1.1 Journalismus ................................................................................... 414
3.1.1.2 Moderation und Avatare ................................................................. 415
3.1.1.3 Musikproduktion und -distribution................................................. 415
3.1.1.4 Film- und Serienproduktion............................................................ 416
3.1.1.5 Digitale Spiele ................................................................................ 417
3.1.2 Neue Akteure: Social Media und Informationsintermedi&#228;re .......... 418
Einf&#252;hrung in die technischen Grundlagen..................................... 419
3.2.1 Sprachverarbeitung ......................................................................... 419
3.2.2 System zur Inhaltsgenerierung........................................................ 421
3.2.3 Personalisierte Empfehlungssysteme in den digitalen Medien....... 422
3.2.4 Technische Grundlagen von Empfehlungssystemen ...................... 422
3.2.5 Monitoring-Systeme ....................................................................... 424
Seite
4 Hintergrund................................................................................... 425
Medienkonsum und Nutzungsverhalten ......................................... 425
4.1.1 Mediennutzung ............................................................................... 425
4.1.2 Die Mediennutzung in Deutschland................................................ 425
4.1.3 Nachrichtennutzung........................................................................ 428
Medienm&#228;rke und KI ...................................................................... 429
4.2.1 Anbieter von Medieninhalten ......................................................... 429
4.2.2 Medienkonzerne ............................................................................. 433
4.2.3 Intermedi&#228;re: Plattformen und soziale Medien............................... 436
4.2.4 Exkurs: KI im medialen Marketing (Werbung).............................. 441
4.2.5 Marktwirtschaftliche Einordnung der KI-Relevanz in den
Medien ............................................................................................ 442
4.2.6 Handlungsempfehlungen ................................................................ 443
Ziele und Aufgaben von Medienpolitik .......................................... 444
5 Produktion..................................................................................... 445
Analyse des Einsatzes von KI im klassischen Journalismus .......... 446
5.1.1 Funktionen des Journalismus.......................................................... 446
5.1.2 Qualit&#228;t und Ethik des Journalismus............................................... 446
5.1.3 Herausforderungen durch die Digitalisierung................................. 447
Automated Writing, redaktionelle Qualit&#228;tskontrolle..................... 448
5.2.1 Handlungsempfehlungen ................................................................ 449
Deep Fake erkennen, Medienforensik ............................................ 449
5.3.1 Definition, Funktionsweise und Anwendungsfelder....................... 449
5.3.2 Statistische H&#228;ufigkeit von Deep Fakes ......................................... 451
5.3.3 Methoden zur Erkennung von Deep Fakes..................................... 451
5.3.4 Handlungsempfehlungen ................................................................ 452
Datenzugang als Voraussetzung f&#252;r Datenanalyse ......................... 453
5.4.1 Handlungsempfehlungen ................................................................ 454
Datenanalyse: KI als Werkzeug f&#252;r den Journalismus ................... 455
6 Distribution ................................................................................... 456
Problematische Aspekte von Empfehlungssystemen...................... 457
6.1.1 Handlungsempfehlungen ................................................................ 458
Personalisierung.............................................................................. 458
6.2.1 Algorithmisch personalisierte Nachrichtenkan&#228;le und 
politisches Microtargeting .............................................................. 458
6.2.2 Handlungsempfehlungen ................................................................ 461
6.2.3 Milieubildung: Filterblasen und Echokammern ............................. 462
6.2.4 Handlungsempfehlungen ................................................................ 464
Seite
Social Bots ...................................................................................... 464
6.3.1 Handlungsempfehlungen ................................................................ 467
7 Regulierung ................................................................................... 468
Internationale Regulierung ............................................................. 468
7.1.1 Handlungsempfehlungen ................................................................ 470
Nationale Regulierung .................................................................... 470
7.2.1 Medienrecht (Medienstaatsvertrag) ................................................ 470
7.2.1.1 Handlungsempfehlungen ................................................................ 472
7.2.2 Wettbewerbsrecht ........................................................................... 473
7.2.2.1 Handlungsempfehlungen ................................................................ 474
Technische M&#246;glichkeiten der Governance von KI-Systemen in
der Produktion und Verteilung von Medien durch Software
(Governance by algorithms) ........................................................... 474
7.3.1 Algorithmische Governance von generativen KI-Systemen........... 474
7.3.2 Technische M&#246;glichkeiten der Governance von ADM-
Systemen......................................................................................... 474
7.3.2.1 Handlungsempfehlungen ................................................................ 476
Uploadfilter..................................................................................... 476
7.4.1 Filter bei der Umsetzung von Urheberrecht.................................... 476
7.4.1.1 Handlungsempfehlungen ................................................................ 478
7.4.2 Hassrede.......................................................................................... 478
7.4.2.1 Das Netzwerkdurchsetzungsgesetz gegen Hassrede....................... 478
7.4.2.2 Beispiel YouTube ........................................................................... 479
7.4.2.3 Beispiel Facebook........................................................................... 480
7.4.2.4 Beispiel Twitter .............................................................................. 480
7.4.2.5 Technische Perspektive auf das automatische Auffinden............... 481
7.4.2.5.1 Handlungsempfehlungen ................................................................ 482
7.4.3 Weitere Anwendungen ................................................................... 482
7.4.3.1 Handlungsempfehlungen ................................................................ 482
Seite
D. Sondervoten zum Gesamtbericht ............................................... 483
1 Sondervoten der CDU/CSU-Fraktion ........................................ 483
Sondervotum zu Kapitel 1 der Kurzfassung des Berichts
(&#8222;Daten&#8220;) sowie Kapitel 5.7 des Mantelberichts (&#8222;KI und Recht
&#8211; Handlungsempfehlungen&#8220;) des sachverst&#228;ndigen Mitglieds
Dr. Sebastian Wieczorek und der Abgeordneten Marc Biadacz,
Hansj&#246;rg Durz, Ronja Kemmer, Jan Metzler, Stefan Sauer,
Prof. Dr. Claudia Schmidtke, Andreas Steier und Nadine Sch&#246;n 
sowie der sachverst&#228;ndigen Mitglieder Susanne Dehmel, 
Prof. Dr. Wolfgang Ecker, Prof. Dr. Alexander Filipovi&#263;,
Prof. Dr. Antonio Kr&#252;ger und Prof. Dr. J&#246;rg M&#252;ller-Lietzkow ..... 483
Sondervotum zu Kapitel 6 der Kurzfassung des Berichts
(&#8222;Mensch und Gesellschaft&#8220;) sowie Kapitel 4.2.6 des Berichts
der Projektgruppe 6 &#8222;KI und Medien&#8220; (&#8222;Medienm&#228;rkte und KI
&#8211; Handlungsempfehlungen&#8220;) der Abgeordneten Ronja Kemmer
und der Abgeordneten Marc Biadacz, Hansj&#246;rg Durz, Jan
Metzler, Stefan Sauer, Andreas Steier, Prof. Dr. Claudia
Schmidtke und Nadine Sch&#246;n sowie der sachverst&#228;ndigen 
Mitglieder Susanne Dehmel, Prof. Dr. Wolfgang Ecker,
Prof. Dr. Antonio Kr&#252;ger und Dr. Sebastian Wieczorek ............... 485
Sondervotum zu Kapitel 9.4.1 des Mantelberichts (&#8222;Welche 
St&#228;rken hat die KI-Forschung in Deutschland?&#8220;) des 
sachverst&#228;ndigen Mitglieds Dr. Sebastian Wieczorek und
der Abgeordneten Marc Biadacz, Hansj&#246;rg Durz und
Prof. Dr. Claudia Schmidtke sowie der sachverst&#228;ndigen 
Mitglieder Prof. Dr. Wolfgang Ecker und Prof. Dr. Alexander
Filipovi&#263; ......................................................................................... 486
Sondervotum zu Kapitel 1 des Berichts der Projektgruppe 2 
&#8222;KI und Staat&#8220; (&#8222;Kurzfassung des Projektgruppenberichtes&#8220;) 
der Abgeordneten Ronja Kemmer und der Abgeordneten Marc
Biadacz, Hansj&#246;rg Durz, Jan Metzler, Stefan Sauer,
Prof. Dr. Claudia Schmidtke, Andreas Steier und Nadine Sch&#246;n
sowie der sachverst&#228;ndigen Mitglieder Susanne Dehmel,
Prof. Dr. Wolfgang Ecker, Prof. Dr. Antonio Kr&#252;ger, 
Prof. Dr. J&#246;rg M&#252;ller-Lietzkow und Dr. Sebastian Wieczorek ...... 489
2 Sondervoten der SPD-Fraktion ................................................... 490
Sondervotum zu Kapitel 4 des Mantelberichts (&#8222;KI und 
Umgang mit Risiko&#8220;) der Abgeordneten Daniela Kolbe, Elvan 
Korkmaz-Emre, Falko Mohrs, Ren&#233; R&#246;spel und Jessica Tatti
sowie der sachverst&#228;ndigen Mitglieder Dr. Florian Butollo, 
Prof. Dr.-Ing. Sami Haddadin, Jan Kuhlen, Lena-Sophie M&#252;ller
und Lothar Schr&#246;der ....................................................................... 490
Seite
Sondervotum zu Kapitel 5.7 des Mantelberichts (&#8222;KI und 
Recht &#8211; Handlungsempfehlungen&#8220;) der Abgeordneten Elvan 
Korkmaz-Emre und des sachverst&#228;ndigen Mitglieds Jan 
Kuhlen, der Abgeordneten Arno Klare, Daniela Kolbe, Falko 
Mohrs und Ren&#233; R&#246;spel sowie der sachverst&#228;ndigen Mitglieder
Prof. Dr.-Ing. Sami Haddadin, Lena-Sophie M&#252;ller und 
Lothar Schr&#246;der ............................................................................. 492
Sondervotum zu Kapitel C. III. &#8222;K&#252;nstliche Intelligenz und 
Staat (Projektgruppe 2)&#8220; der Abgeordneten Daniela Kolbe, 
Elvan Korkmaz-Emre, Falko Mohrs, Ren&#233; R&#246;spel und Jessica
Tatti sowie der sachverst&#228;ndigen Mitglieder Prof. Dr.-Ing. Sami
Haddadin, Jan Kuhlen, Lena-Sophie M&#252;ller und 
Lothar Schr&#246;der ............................................................................. 492
3 Sondervoten der AfD-Fraktion.................................................... 493
Sondervotum zu Kapitel 3 des Mantelberichts (&#8222;KI und 
Umgang mit Bias/Diskriminierung&#8220;) des Abgeordneten 
Dr. Marc Jongen sowie der Abgeordneten Joana Cotar
und Peter Felser ............................................................................. 493
Sondervotum zu Kapitel 6 des Mantelberichts (&#8222;Ethische
Perspektiven auf KI&#8220;) des Abgeordneten Dr. Marc Jongen 
sowie der Abgeordneten Joana Cotar und Peter Felser .................. 494
Sondervotum zu Kapitel 7 des Mantelberichts (&#8222;KI und 
Gesellschaft&#8220;) des Abgeordneten Dr. Marc Jongen sowie 
der Abgeordneten Joana Cotar und Peter Felser............................. 495
Sondervotum zu Kapitel 8 des Mantelberichts (&#8222;KI und 
&#246;kologische Nachhaltigkeit&#8220;) des Abgeordneten Dr. Marc 
Jongen sowie der Abgeordneten Joana Cotar und Peter Felser ..... 496
Sondervotum zu Kapitel 9 des Mantelberichts (&#8222;KI und 
Forschung&#8220;) des Abgeordneten Dr. Marc Jongen sowie 
der Abgeordneten Joana Cotar und Peter Felser ............................ 498
Sondervotum zu den Kapiteln 4.1.3.1.1 und 5.2.1 des Berichts
der Projektgruppe 1 &#8222;KI und Wirtschaft&#8220; (&#8222;Themenfeld
Startups&#8220; und &#8222;Innovation und Start-ups: Start-up-&#214;kosysteme, 
Start-up-F&#246;rderungen&#8220;) der Abgeordneten Joana Cotar sowie
der Abgeordneten Peter Felser und Dr. Marc Jongen .................... 499
Sondervotum zu Kapitel 2 der AG-Berichte der
Projektgruppe 2 &#8222;KI und Staat&#8220; (&#8222;AG 2: Smart City und Open
Data&#8220;) des Abgeordneten Dr. Marc Jongen sowie der
Abgeordneten Joana Cotar und Peter Felser .................................. 502
Sondervotum zu Kapitel 3.1 der AG-Berichte der
Projektgruppe 2 &#8222;KI und Staat&#8220; (&#8222;AG 3: Innere Sicherheit, 
&#196;u&#223;ere Sicherheit, IT-Sicherheit &#8211; Innere Sicherheit&#8220;) des 
Abgeordneten Peter Felser sowie der Abgeordneten 
Joana Cotar und Dr. Marc Jongen .................................................. 506
Seite
Sondervotum zu Kapitel 3.1 der AG-Berichte der
Projektgruppe 2 &#8222;KI und Staat&#8220; (&#8222;AG 3: Innere Sicherheit, 
&#196;u&#223;ere Sicherheit, IT-Sicherheit &#8211; Innere Sicherheit&#8220;) des 
Abgeordneten Peter Felser sowie der Abgeordneten 
Joana Cotar und Dr. Marc Jongen .................................................. 507
Sondervotum zu den Kapiteln 3.1 und 3.2 der AG-Berichte 
der Projektgruppe 2 &#8222;KI und Staat&#8220; (&#8222;AG 3: Innere Sicherheit, 
&#196;u&#223;ere Sicherheit, IT-Sicherheit &#8211; Innere Sicherheit&#8220; und
&#8222;&#196;u&#223;ere Sicherheit&#8220;) des Abgeordneten Peter Felser sowie 
der Abgeordneten Joana Cotar und Dr. Marc Jongen .................... 508
Sondervotum zu Kapitel 3.2.2, 5.2.4, 5.2.6 und 5.2.8.1 des
Berichts der Projektgruppe 4 &#8222;KI und Arbeit, Bildung, 
Forschung&#8220; (&#8222;Beispiele f&#252;r KI-Anwendungen in Schule und 
Hochschule&#8220;, &#8222;Anforderungen an den Schulunterricht&#8220;, 
&#8222;KI und Hochschule&#8220; und &#8222;Lehrkr&#228;ftebildung&#8220;) des 
sachverst&#228;ndigen Mitglieds Prof. Dr. Boris Hollas sowie der 
Abgeordneten Joana Cotar, Peter Felser und Dr. Marc Jongen ..... 509
Sondervotum zu den Kapiteln 1 und 4.3 des Berichts der
Projektgruppe 6 &#8222;KI und Medien&#8220; (&#8222;Kurzfassung des 
Projektgruppenberichts&#8220; und &#8222;Ziele und Aufgaben von 
Medienpolitik&#8220;) der Abgeordneten Joana Cotar sowie der
Abgeordneten Peter Felser und Dr. Marc Jongen .......................... 512
Sondervotum zu den Kapiteln 5.1.1 bis 5.1.3 des Berichts
der Projektgruppe 6 &#8222;KI und Medien&#8220; (&#8222;Funktionen des
Journalismus&#8220;, &#8222;Qualit&#228;t und Ethik des Journalismus&#8220; und 
&#8222;Herausforderungen durch die Digitalisierung&#8220;) des 
Abgeordneten Dr. Marc Jongen sowie der Abgeordneten
Joana Cotar und Peter Felser .......................................................... 516
Sondervotum zu den Kapiteln 5.1.1 bis 5.1.3 des Berichts
der Projektgruppe 6 &#8222;KI und Medien&#8220; (&#8222;Funktionen des
Journalismus&#8220;, &#8222;Qualit&#228;t und Ethik des Journalismus&#8220; und 
&#8222;Herausforderungen durch die Digitalisierung&#8220;) des 
Abgeordneten Dr. Marc Jongen sowie der Abgeordneten
Joana Cotar und Peter Felser ......................................................... 517
Sondervotum zu den Kapiteln 7.4.2 und 7.4.2.1 des Berichts
der Projektgruppe 6 &#8222;KI und Medien&#8220; (&#8222;Hassrede&#8220; und &#8222;Das 
Netzwerkdurchsetzungsgesetz gegen Hassrede&#8220;) der 
Abgeordneten Joana Cotar sowie der Abgeordneten 
Peter Felser und Dr. Marc Jongen .................................................. 520
4 Sondervoten der FDP-Fraktion ................................................... 523
Sondervotum zu Kapitel 5.7 des Mantelberichts (&#8222;KI und Recht
&#8211; Handlungsempfehlungen&#8220;) der Abgeordneten Mario 
Brandenburg, Carl-Julius Cronenberg und Daniela Kluckert
sowie der sachverst&#228;ndigen Mitglieder Dr. Aljoscha Burchardt
und Andrea Martin ......................................................................... 523
Seite
Sondervotum zu den Kapiteln 3 und 6.2.1 des Mantelberichts
(&#8222;KI und Umgang mit Bias/Diskriminierung&#8220; und &#8222;Autonomie
(Selbstbestimmung des Menschen als Handelnder, 
Entscheidungsfreiheit, Nicht-Manipulation)&#8220;) der 
Abgeordneten Mario Brandenburg, Carl-Julius Cronenberg, 
Daniela Kluckert und Jessica Tatti sowie der sachverst&#228;ndigen
Mitglieder Dr. Aljoscha Burchardt und Andrea Martin ................. 524
Sondervotum zu Kapitel 6.2.4 des Mantelberichts (&#8222;Ethische
Perspektive auf KI &#8211; Gemeinwohl (Wohlstandsf&#246;rderung,
Benefits, Interessen)&#8220;) der Abgeordneten Mario Brandenburg, 
Carl-Julius Cronenberg und Daniela Kluckert sowie der
sachverst&#228;ndigen Mitglieder Dr. Aljoscha Burchardt und 
Andrea Martin ................................................................................ 524
Sondervotum zu den Kapiteln 1 und 3.1 des Berichts der
Projektgruppe 1 &#8222;KI und Wirtschaft&#8220; (&#8222;Kurzfassung des 
Projektgruppenberichts&#8220; und &#8222;Grundlagen und 
Sachstandskl&#228;rung: KI hat gro&#223;es Potenzial, ist aber kein
Selbstl&#228;ufer&#8220;) der Abgeordneten Mario Brandenburg, Carl-
Julius Cronenberg und Daniela Kluckert sowie der
sachverst&#228;ndigen Mitglieder Dr. Aljoscha Burchardt und 
Andrea Martin................................................................................. 524
Sondervotum zu Kapitel 5.1.3.4 des Berichts der
Projektgruppe 4 &#8222;KI und Arbeit, Bildung, Forschung&#8220;
(&#8222;Weiterentwicklung der sozialen Sicherungssysteme&#8220;) des
Abgeordneten Carl-Julius Cronenberg ........................................... 524
Sondervotum zu Kapitel 4.1.3 des Berichts der Projektgruppe 5 
&#8222;KI und Mobilit&#228;t&#8220; (&#8222;Zukunft der Mobilit&#228;t &#8211;
Handlungsempfehlungen&#8220;) der Abgeordneten Mario
Brandenburg, Carl-Julius Cronenberg und Daniela Kluckert
sowie der sachverst&#228;ndigen Mitglieder Dr. Aljoscha Burchardt
und Andrea Martin.......................................................................... 527
5 Sondervoten der Fraktion DIE LINKE. ..................................... 527
Sondervotum zu Kapitel 4 der Kurzfassung des Berichts
(&#8222;Wirtschaft und Arbeit&#8220;) der Abgeordneten Dr. Petra Sitte
und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds
Dr. Florian Butollo.......................................................................... 527
Sondervotum zu Kapitel 3.2 des Mantelberichts
(&#8222;Diskriminierung durch Bias&#8220;) der Abgeordneten Dr. Petra 
Sitte und Jessica Tatti sowie des sachverst&#228;ndigen
Mitglieds Dr. Florian Butollo ......................................................... 527
Sondervotum zu Kapitel 3.5 des Mantelberichts
(&#8222;Handlungsempfehlungen&#8220; zu &#8222;KI und Umgang mit
Bias/Diskriminierung&#8220;) der Abgeordneten Dr. Petra Sitte
und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds
Dr. Florian Butollo.......................................................................... 527
Sondervotum zu Kapitel 4.4 des Mantelberichts (&#8222;KI-
spezifisches Risikomanagement&#8220;) der Abgeordneten 
Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen 
Mitglieds Dr. Florian Butollo ......................................................... 528
Seite
Sondervotum zu Kapitel 4.5 des Mantelberichts
(&#8222;Handlungsempfehlungen&#8220; zu &#8222;KI und Umgang mit Risiko&#8220;) 
der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des
sachverst&#228;ndigen Mitglieds Dr. Florian Butollo ............................ 528
Sondervotum zu Kapitel 5.2 des Mantelberichts
(&#8222;Datenschutzrecht&#8220;) der Abgeordneten Dr. Petra Sitte
und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds
Dr. Florian Butollo.......................................................................... 528
Sondervotum zu Kapitel 5.5 des Mantelberichts
(&#8222;Haftungsrecht&#8220;) der Abgeordneten Dr. Petra Sitte und
Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds
Dr. Florian Butollo.......................................................................... 528
Sondervotum zu Kapitel 5.6 des Mantelberichts (&#8222;Einsatz
von KI in der &#246;ffentlichen Verwaltung&#8220;) der Abgeordneten 
Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen
Mitglieds Dr. Florian Butollo ......................................................... 529
Sondervotum zu Kapitel 5.7 des Mantelberichts
(&#8222;Handlungsempfehlungen&#8220; zu &#8222;KI und Recht&#8220;) der 
Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie
des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo....................... 529
Sondervotum zu Kapitel 6 des Mantelberichts (&#8222;Ethische
Perspektiven auf KI&#8220;) der Abgeordneten Dr. Petra Sitte und
Jessica Tatti..................................................................................... 529
Sondervotum zu Kapitel 7.1 des Mantelberichts
(&#8222;Gesellschaftlicher Reflexionsbedarf in Bezug auf die 
Wirkung von KI-Systemen&#8220;) der Abgeordneten Dr. Petra Sitte
und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds
Dr. Florian Butollo.......................................................................... 529
Sondervotum zu Kapitel 7.4 des Mantelberichts
(&#8222;Handlungsempfehlungen&#8220; zu &#8222;KI und Gesellschaft&#8220;) der
Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des 
sachverst&#228;ndigen Mitglieds Dr. Florian Butollo ............................. 529
Sondervotum zu Kapitel 8.7 des Mantelberichts
(&#8222;Handlungsempfehlungen&#8220; zu &#8222;KI und &#246;kologische
Nachhaltigkeit&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica
Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo.... 530
Sondervotum zu Kapitel 9.2.3 des Mantelberichts (&#8222;Leitlinie 3: 
F&#246;rderung der Forschung in der Breite&#8220;) der Abgeordneten 
Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen
Mitglieds Dr. Florian Butollo ......................................................... 530
Sondervotum zu Kapitel 9.5 des Mantelberichts (&#8222;Zentrale 
Handlungsempfehlungen f&#252;r den Staat&#8220;) der Abgeordneten 
Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen
Mitglieds Dr. Florian Butollo ......................................................... 530
Sondervotum zu Kapitel 10 des Mantelberichts (&#8222;KI und 
SARS-CoV-2&#8220;) der Abgeordneten Dr. Petra Sitte und
Jessica Tatti..................................................................................... 531
Seite
Sondervotum zu Kapitel 10.1 des Mantelberichts
(&#8222;Potenziale und Anwendungsbeispiele von KI zur
Eind&#228;mmung und Beherrschung von Pandemien 
(insbesondere der Covid-19-Pandemie)&#8220;) der Abgeordneten 
Dr. Petra Sitte und Jessica Tatti ...................................................... 531
Sondervotum zu Kapitel 10.3 des Mantelberichts (&#8222;Chance 
in der Krise f&#252;r st&#228;rkere Translation und h&#246;here Akzeptanz
von KI&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti
sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo ............ 531
Sondervotum zu Kapitel 10.4 des Mantelberichts (&#8222;Fazit&#8220;
zu &#8222;KI und SARS-CoV-2&#8220;) der Abgeordneten Dr. Petra 
Sitte und Jessica Tatti ..................................................................... 532
Sondervotum zu Kapitel 10.4 des Mantelberichts (&#8222;Fazit&#8220;
zu &#8222;KI und SARS-CoV-2&#8220;) der Abgeordneten Dr. Petra 
Sitte und Jessica Tatti sowie des sachverst&#228;ndigen
Mitglieds Dr. Florian Butollo ......................................................... 533
Sondervotum zu Kapitel 1 des Berichts der Projektgruppe
&#8222;KI und Wirtschaft&#8220; (&#8222;Kurzfassung des
Projektgruppenberichts&#8220;) der Abgeordneten Dr. Petra Sitte
und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds
Dr. Florian Butollo.......................................................................... 533
Sondervotum zu Kapitel 3.1 des Berichts der Projektgruppe
&#8222;KI und Wirtschaft&#8220; (&#8222;Grundlagen und Sachstandskl&#228;rung:
KI hat gro&#223;es Potenzial, ist aber kein Selbstl&#228;ufer&#8220;) der 
Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des
sachverst&#228;ndigen Mitglieds Dr. Florian Butollo ............................. 533
Sondervotum zu Kapitel 3.2 des Berichts der Projektgruppe
&#8222;KI und Wirtschaft&#8220; (&#8222;KI in einf&#252;hrenden Szenarien&#8220;) der
Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des
sachverst&#228;ndigen Mitglieds Dr. Florian Butollo ............................. 534
Sondervotum zu Kapitel 3.3 des Berichts der Projektgruppe
&#8222;KI und Wirtschaft&#8220; (&#8222;Zielstellungen: Deutschland im Jahr
2030 &#8211; eine Vision&#8220;) der Abgeordneten Dr. Petra Sitte und
Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds
Dr. Florian Butollo.......................................................................... 534
Sondervotum zu Kapitel 3.3.1 des Berichts der
Projektgruppe &#8222;KI und Wirtschaft&#8220; (&#8222;Angestrebte 
Gesellschafts- und Politikziele: Die Wirtschaft setzt KI
unter Einhaltung ethisch vereinbarter Normen ein&#8220;) der 
Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des
sachverst&#228;ndigen Mitglieds Dr. Florian Butollo ............................. 538
Sondervotum zu Kapitel 3.3.3 des Berichts der
Projektgruppe &#8222;KI und Wirtschaft&#8220; (&#8222;Angestrebte 
Wirtschaftsziele: &#8222;KI made in Germany&#8220; als internationales
G&#252;tesiegel&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica
Tatti sowie des sachverst&#228;ndigen Mitglieds
Dr. Florian Butollo.......................................................................... 539
Seite
Sondervotum zu Kapitel 4.1.3 des Berichts der
Projektgruppe &#8222;KI und Wirtschaft&#8220; (&#8222;Stand des Marktes&#8220;) 
der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie
des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo....................... 539
Sondervotum zu Kapitel 4.1.3.1.2 des Berichts der
Projektgruppe &#8222;KI und Wirtschaft&#8220; (&#8222;Themenfeld
Mittelstand&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica
Tatti sowie des sachverst&#228;ndigen Mitglieds
Dr. Florian Butollo.......................................................................... 540
Sondervotum zu Kapitel 4.1.3.2.1 des Berichts der
Projektgruppe &#8222;KI und Wirtschaft&#8220; (&#8222;Themenfeld Industrie
und Produktion: Daten als Produktkomponente in der
produzierenden Industrie&#8220;) der Abgeordneten Dr. Petra 
Sitte und Jessica Tatti sowie des sachverst&#228;ndigen 
Mitglieds Dr. Florian Butollo ......................................................... 540
Sondervotum zu Kapitel 4.1.3.2.4 des Berichts der
Projektgruppe &#8222;KI und Wirtschaft&#8220; (&#8222;Themenfeld
Agrar&#246;konomie und Landwirtschaft&#8220;) der Abgeordneten
Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen
Mitglieds Dr. Florian Butollo ......................................................... 540
Sondervotum zu Kapitel 4.1.5 des Berichts der
Projektgruppe &#8222;KI und Wirtschaft&#8220; (&#8222;&#214;kologie&#8220;) der 
Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des
sachverst&#228;ndigen Mitglieds Dr. Florian Butollo ............................. 541
Sondervotum zu Kapitel 4.1.6 des Berichts der
Projektgruppe &#8222;KI und Wirtschaft&#8220; (&#8222;Stand der
Administration/Politik &#8211; rechtliche Fragen&#8220;) der 
Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des
sachverst&#228;ndigen Mitglieds Dr. Florian Butollo ............................. 541
Sondervotum zu Kapitel 5 des Berichts der Projektgruppe
&#8222;KI und Wirtschaft&#8220; (&#8222;Handlungsempfehlungen und 
Perspektiven&#8220;) der Abgeordneten Dr. Petra Sitte und
Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds
Dr. Florian Butollo.......................................................................... 542
Sondervotum zu Kapitel C. III. &#8222;K&#252;nstliche Intelligenz und 
Staat (Projektgruppe 2)&#8220; der Abgeordneten Dr. Petra Sitte
und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds
Dr. Florian Butollo.......................................................................... 549
Sondervotum zu Kapitel 3.2.1.3 des Berichts der
Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220;
(&#8222;Prozessoptimierung durch Predictive Analysis&#8220;) der 
Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des
sachverst&#228;ndigen Mitglieds Dr. Florian Butollo ............................. 555
Sondervotum zu Kapitel 5.1.1.2 des Berichts der
Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220;
(&#8222;Bislang wenig Forschung zu den Besch&#228;ftigungseffekten 
von KI&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti 
sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo ............ 555
Seite
Sondervotum zu Kapitel 5.2 des Berichts der Projektgruppe
&#8222;KI und Arbeit, Bildung, Forschung&#8220; (&#8222;KI in der Bildung&#8220;)
der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie
des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo....................... 556
Sondervotum zu Kapitel 5.5 des Berichts der Projektgruppe
&#8222;KI und Arbeit, Bildung, Forschung&#8220; (&#8222;SWOT-Analyse&#8220;) 
der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie
des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo....................... 557
Sondervotum zu Kapitel C. VI. &#8222;K&#252;nstliche Intelligenz und 
Mobilit&#228;t (Projektgruppe 5)&#8220; der Abgeordneten Dr. Petra 
Sitte und Jessica Tatti ..................................................................... 557
6 Sondervoten der Fraktion B&#220;NDNIS 90/DIE GR&#220;NEN.......... 558
Sondervotum zu Kapitel 5.3 des Berichtsteils &#8222;Allgemeiner
Teil: Auftrag und Arbeitsweise&#8220; (&#8222;Einbeziehung der
&#214;ffentlichkeit und Pressearbeit&#8220;) der Abgeordneten 
Dr. Anna Christmann, Dieter Janecek, Dr. Petra Sitte und
Jessica Tatti sowie der sachverst&#228;ndigen Mitglieder
Prof. Dr. Hannah Bast, Dr. Florian Butollo und 
Dr. Stefan Heumann ....................................................................... 558
Sondervotum zu Kapitel 9 des Mantelberichts (&#8222;KI und 
Forschung&#8220;) die Abgeordneten Dr. Anna Christmann 
und der Abgeordnete Dieter Janecek sowie der
sachverst&#228;ndigen Mitglieder Prof. Dr. Hannah Bast
und Dr. Stefan Heumann ................................................................ 559
Sondervotum zu Kapitel C. VII. &#8222;K&#252;nstliche Intelligenz
und Medien (Projektgruppe 6)&#8220; der Abgeordneten 
Tabea R&#246;&#223;ner, Dr. Petra Sitte und Jessica Tatti und
der sachverst&#228;ndigen Mitglieder Dr. Florian Butollo und 
Dr. Stefan Heumann ....................................................................... 560
E. Repliken ......................................................................................... 564
1 Repliken der CDU/CSU-Fraktion ............................................... 564
Replik der Abgeordneten Ronja Kemmer und der
Abgeordneten Marc Biadacz, Hansj&#246;rg Durz, Jan Metzler, 
Stefan Sauer, Prof. Dr. Claudia Schmidtke, Nadine Sch&#246;n, 
Andreas Steier sowie der sachverst&#228;ndigen Mitglieder Susanne
Dehmel, Prof. Dr. Wolfgang Ecker, Prof. Dr. Alexander
Filipovic, Dr. Tina Kl&#252;wer, Prof. Dr. Antonio Kr&#252;ger, 
Prof. Dr. J&#246;rg M&#252;ller-Lietzkow und Dr. Sebastian Wieczorek
zu den Sondervoten 3.3 und 3.4 des Abgeordneten Dr. Marc 
Jongen und anderer zu den Kapiteln 7 und 8 des
Mantelberichts (&#8222;KI und Gesellschaft&#8220; und &#8222;KI und 
&#246;kologische Nachhaltigkeit&#8220;) ......................................................... 564
Seite
Replik der Abgeordneten Ronja Kemmer und der
Abgeordneten Marc Biadacz, Hansj&#246;rg Durz, Jan Metzler, 
Stefan Sauer, Prof. Dr. Claudia Schmidtke, Nadine Sch&#246;n, 
Andreas Steier sowie der sachverst&#228;ndigen Mitglieder Susanne
Dehmel, Prof. Dr. Wolfgang Ecker, Prof. Dr. Alexander
Filipovic, Dr. Tina Kl&#252;wer, Prof. Dr. Antonio Kr&#252;ger, 
Prof. Dr. J&#246;rg M&#252;ller-Lietzkow und Dr. Sebastian Wieczorek
zum Sondervotum 3.5 des Abgeordneten Dr. Marc Jongen und 
anderer zu Kapitel 9 des Mantelberichts (&#8222;KI und Forschung&#8220;)..... 565
Replik der Abgeordneten Ronja Kemmer und der
Abgeordneten Marc Biadacz, Hansj&#246;rg Durz, Jan Metzler, 
Stefan Sauer, Prof. Dr. Claudia Schmidtke, Nadine Sch&#246;n, 
Andreas Steier sowie der sachverst&#228;ndigen Mitglieder Susanne
Dehmel, Prof. Dr. Wolfgang Ecker, Prof. Dr. Alexander
Filipovic, Dr. Tina Kl&#252;wer, Prof. Dr. Antonio Kr&#252;ger, 
Prof. Dr. J&#246;rg M&#252;ller-Lietzkow und Dr. Sebastian Wieczorek
zum Sondervotum 3.11 des sachverst&#228;ndigen Mitglieds
Prof. Dr. Boris Hollas und anderer zu den Kapiteln 3.2.2, 5.2.4, 
5.2.6 und 5.2.8.1 des Berichts der Projektgruppe &#8222;KI und 
Arbeit, Bildung, Forschung&#8220; (&#8222;Beispiele f&#252;r KI-Anwendungen 
in Schule und Hochschule&#8220;, &#8222;Anforderungen an den 
Schulunterricht&#8220;, &#8222;KI und Hochschule&#8220; und 
&#8222;Lehrkr&#228;ftebildung&#8220;) ...................................................................... 565
2 Repliken der SPD-Fraktion ......................................................... 566
Replik des Abgeordneten Ren&#233; R&#246;spel und der Abgeordneten 
Arno Klare, Daniela Kolbe, Elvan Korkmaz-Emre und Falko
Mohrs sowie der sachverst&#228;ndigen Mitglieder Prof.Dr.-Ing. 
Sami Haddadin, Jan Kuhlen, Lena-Sophie M&#252;ller und 
Lothar Schr&#246;der zum Sondervotum 4.5 des Abgeordneten Carl-
Julius Cronenberg zu Kapitel 5.1.3.4 des Berichts der
Projektgruppe 4 &#8222;KI und Arbeit, Bildung, Forschung&#8220;
(&#8222;Weiterentwicklung der Sozialen Sicherungssysteme&#8220;) ............... 566
Replik des Abgeordneten Ren&#233; R&#246;spel und der Abgeordneten 
Dr. Danyal Bayaz, Dr. Anna Christmann, Anke Domscheit-
Berg, Arno Klare, Daniela Kolbe, Elvan Korkmaz-Emre,
Falko Mohrs, Tabea R&#246;&#223;ner, Dr. Petra Sitte und Jessica Tatti 
sowie der sachverst&#228;ndigen Mitglieder Dr. Florian Butollo, 
Prof. Dr.-Ing. Sami Haddadin, Dr. Stefan Heumann, 
Jan Kuhlen, Lena-Sophie M&#252;ller, Lothar Schr&#246;der und 
Prof. Dr. Katharina Zweig zum Sondervotum 3.11 des
sachverst&#228;ndigen Mitglieds Prof. Dr. Boris Hollas und anderer
zu den Kapiteln 3.2.2, 5.2.4, 5.2.6 und 5.2.8.1 des Berichts der
Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220; (&#8222;Beispiele
f&#252;r KI-Anwendungen in Schule und Hochschule&#8220;, 
&#8222;Anforderungen an den Schulunterricht&#8220;, &#8222;KI und Hochschule&#8220;
und &#8222;Lehrkr&#228;ftebildung&#8220;) ............................................................... 567
Seite
3 Replik der FDP-Fraktion ............................................................. 567
Replik der Abgeordneten Mario Brandenburg, Daniela Kluckert
und Carl-Julius Cronenberg sowie der sachverst&#228;ndigen 
Mitglieder Dr. Aljoscha Burchardt und Andrea Martin zum
Sondervotum 3.11 des sachverst&#228;ndigen Mitglieds Prof. 
Dr. Boris Hollas und anderer zu den Kapiteln 3.2.2, 5.2.4, 5.2.6 
und 5.2.8.1 des Berichts der Projektgruppe &#8222;KI und Arbeit, 
Bildung, Forschung&#8220; (&#8222;Beispiele f&#252;r KI-Anwendungen in 
Schule und Hochschule&#8220;, &#8222;Anforderungen an den 
Schulunterricht&#8220;, &#8222;KI und Hochschule&#8220; und 
&#8222;Lehrkr&#228;ftebildung&#8220;) ...................................................................... 567
4 Literaturverzeichnis zu den Sondervoten und Repliken........... 568
F. Anhang........................................................................................... 584
1 Glossar ........................................................................................... 584
2 Literaturverzeichnis zum Bericht ............................................... 593
Einsetzungsbeschluss...................................................................... 664
Organisation.................................................................................... 668
2.2.1 Zusammensetzung der Enquete-Kommission................................. 668
2.2.2 Obleute............................................................................................ 668
2.2.3 Zusammensetzung der Projektgruppen........................................... 669
2.2.4 Fraktionsreferentinnen und -referenten........................................... 672
2.2.5 Mitarbeiterinnen und Mitarbeiter der Mitglieder............................ 672
2.2.6 &#220;bersicht &#252;ber die Mitarbeiterinnen und Mitarbeiter des
Kommissionssekretariats ................................................................ 674
Protokolle........................................................................................ 675
2.3.1 Liste der Protokolle der Enquete-Kommission............................... 675
2.3.2 Liste der Protokolle der Projektgruppe 1 &#8222;KI und 
Wirtschaft&#8220;...................................................................................... 676
2.3.3 Liste der Protokolle der Projektgruppe 2 &#8222;KI und Staat&#8220; .............. 676
2.3.4 Liste der Protokolle der Projektgruppe 3 &#8222;KI und 
Gesundheit&#8220; .................................................................................... 677
2.3.5 Liste der Protokolle der Projektgruppe 4 &#8222;KI und Arbeit&#8220; ............. 677
2.3.6 Liste der Protokolle der Projektgruppe 5 &#8222;KI und 
Mobilit&#228;t&#8220; ....................................................................................... 678
2.3.7 Liste der Protokolle der Projektgruppe 6 &#8222;KI und Medien&#8220; .......... 678
Verzeichnisse und &#220;bersichten ...................................................... 679
2.4.1 Liste der Drucksachen der Enquete-Kommission .......................... 679
2.4.2 Liste der Drucksachen der Projektgruppe 1 &#8222;KI und 
Wirtschaft&#8220; ..................................................................................... 688
2.4.3 Liste der Drucksachen der Projektgruppe 2 &#8222;KI und Staat&#8220; ........... 690
Seite
2.4.4 Liste der Drucksachen der Projektgruppe 3 &#8222;KI und 
Gesundheit&#8220; .................................................................................... 692
2.4.5 Liste der Drucksachen der Projektgruppe 4 &#8222;KI und Arbeit&#8220; ......... 695
2.4.6 Liste der Drucksachen der Projektgruppe 5 &#8222;KI und 
Mobilit&#228;t&#8220;........................................................................................ 700
2.4.7 Liste der Drucksachen der Projektgruppe 6 &#8222;KI und 
Medien&#8220; .......................................................................................... 703
2.4.8 Liste der Materialien der Enquete-Kommission ............................ 706
2.4.9 Liste der Materialien der Projektgruppe 3 &#8222;KI und 
Gesundheit&#8220; .................................................................................... 708
2.4.10 Liste der Materialien der Projektgruppe 5 &#8222;KI und 
Mobilit&#228;t&#8220;........................................................................................ 709
2.4.11 Anh&#246;rungsg&#228;ste der Enquete-Kommission .................................... 709
2.4.12 Anh&#246;rungsg&#228;ste der Projektgruppen .............................................. 713
2.4.12.1 Projektgruppe 1 &#8222;KI und Wirtschaft&#8220; ............................................ 713
2.4.12.2 Projektgruppe 2 &#8222;KI und Staat&#8220; ...................................................... 715
2.4.12.3 Projektgruppe 3 &#8222;KI und Gesundheit&#8220;............................................ 715
2.4.12.4 Projektgruppe 4 &#8222;KI und Arbeit&#8220;.................................................... 717
2.4.12.5 Projektgruppe 5 &#8222;KI und Mobilit&#228;t&#8220; ............................................... 719
2.4.12.6 Projektgruppe 6 &#8222;KI und Medien&#8220;.................................................. 720
G. Anlagen .......................................................................................... 722
Vorwort der Vorsitzenden
Sehr geehrte Damen und Herren, 
geneigte Leserinnen und Leser,
die Zeit, in der wir leben, ist gepr&#228;gt von unglaublich vielen Umbr&#252;chen.
K&#252;nstliche Intelligenz (KI) nimmt sich neben anderen Entwicklungen fast klein aus.
Doch diese Technologie hat das Potenzial, Treiber und Verst&#228;rker
gesellschaftlicher Ver&#228;nderungen zu sein. Sie kann ein Werkzeug sein, um Probleme zu l&#246;sen
oder sie wom&#246;glich auch zu verschlimmern. Gut, dass der Deutsche Bundestag
eine Enquete-Kommission zu diesem wichtigen Thema eingesetzt hat. Denn, ob
wir in Deutschland und Europa die KI-Entwicklung mitpr&#228;gen k&#246;nnen und wie
wir diese Technologie einsetzen, entscheidet sich jetzt.
Diese Enquete-Kommission hat meinen Bundestagskolleginnen und -kollegen
sowie mir ganz pers&#246;nlich die M&#246;glichkeit einger&#228;umt, au&#223;erhalb des
gew&#246;hnlichen, eng getakteten parlamentarischen Betriebs, sehr intensiv &#252;ber das Thema
KI zu sprechen, dabei viel zu lernen und eine eigenst&#228;ndige parlamentarische 
Position zu entwickeln. Diese Erkundungsreise wurde begleitet und befruchtet
vom intensiven Austausch zwischen Politikerinnen und Politikern und
sachkundigen Vertreterinnen und Vertretern aus Wirtschaft, Gewerkschaften, Forschung
und Zivilgesellschaft.
Der vorliegende Bericht zeichnet aktuelle Konsense und Kompromisslinien nach
und gibt eine Vielzahl zum Teil sehr spezifischer Handlungsempfehlungen ab.
Parallel dazu ist allen Beteiligten deutlich geworden, an welchen Stellen noch
Diskussionsbedarf besteht und wo es politische Unterschiede gibt. Auch das sind
wertvolle Erkenntnisse. Mit diesem Bericht ist die Arbeit daher nicht
abgeschlossen. Sie hat gerade erst begonnen. Ich hoffe, dass die hier gesammelten
&#220;berlegungen und Handlungsempfehlungen eine gute Grundlage f&#252;r das weitere
politische Handeln und einen breiten gesellschaftlichen Dialog &#252;ber die Entwicklung
von KI und ihre Rolle in unserem Leben sein werden. 
Ich m&#246;chte den Mitgliedern der Kommission, also den externen
Sachverst&#228;ndigen und den beteiligten Bundestagsabgeordneten, f&#252;r ihre Arbeit und den Willen
danken, sich so tief auf ein Thema, aber auch auf andere Sichtweisen einzulassen.
Ich habe gro&#223;en Respekt vor der Zeit, Kraft und Expertise, die sie eingebracht
haben. Au&#223;erdem m&#246;chte ich sehr herzlich dem Kommissionssekretariat des
Deutschen Bundestages danken, das unsere Arbeit auf gro&#223;artige Weise begleitet
und gest&#252;tzt hat. Gerade unter den herausfordernden Umst&#228;nden der Corona-
Pandemie w&#228;re die Arbeit ohne sie nicht denkbar gewesen. 
Nun w&#252;nsche ich Ihnen, liebe Leserinnen und Leser, eine anregende Lekt&#252;re und
den Abgeordneten des Deutschen Bundestages und den Mitgliedern der
Bundesregierung viel Mut und Schaffenskraft, die Empfehlungen umzusetzen.
Daniela Kolbe
Vorsitzende
A. Kurzfassung des Berichts
Der nachfolgende Text fasst die wesentlichen Ergebnisse der im Jahr 2018 eingesetzten Enquete-Kommission
&#8222;K&#252;nstliche Intelligenz &#8211; Gesellschaftliche Verantwortung und wirtschaftliche, soziale und &#246;kologische
Potenziale&#8220; des Deutschen Bundestages zusammen.
Einleitung
K&#252;nstliche Intelligenz (KI) wird zuk&#252;nftig in immer mehr Bereichen unserer Lebenswelten eine relevante Rolle
spielen.
So erkennen KI-Systeme Sprachanweisungen, filtern Spammails heraus, erkennen Bilder, sortieren
Suchergebnisse, korrigieren Schreibfehler und schlagen Produkte vor. Sie &#252;bersetzen Texte und spielen Go oder Schach,
letzteres schon lange besser als ein Mensch. Die Systeme steuern Staubsaugerroboter, Fahrassistenzsysteme und
ganze Fertigungsanlagen.
KI-Systeme helfen Medizinern zunehmend bei der Diagnose und bei der Auswahl der individuell besten
Therapie. Es geht dabei um verschiedene Vorteile wie Komfort und Effizienz, aber auch um Sicherheit und Gesundheit.
KI und intelligente Systeme bergen dar&#252;ber hinaus gro&#223;es Potenzial zur L&#246;sung aktueller gesellschaftlicher
Herausforderungen, wie die einer zunehmend &#228;lter werdenden Gesellschaft oder des Klimawandels.
Auf welchen Begriff von KI hat sich die Enquete-Kommission verst&#228;ndigt?
Um eine Diskussionsgrundlage zu haben, hat sich die Enquete-Kommission auf eine Beschreibung der KI
verst&#228;ndigt. W&#228;hrend der Arbeit kam wiederkehrende Kritik an dem sperrigen und emotionsbeladenen Begriff &#8222;KI&#8220;
auf, welcher sowohl &#252;berzogene Erwartungen als auch &#196;ngste wecken kann. Die Enquete-Kommission hat
bewusst auf eine eigene Definition von KI verzichtet und stattdessen eine Begriffskl&#228;rung vorgenommen
(Kapitelverweis). Sie besch&#228;ftigte sich in ihrer Arbeit prim&#228;r mit dem Aspekt der lernenden Systeme.
Warum sollten sich Politik und Gesellschaft aktiv damit besch&#228;ftigen?
Der Einsatz von KI in immer mehr Bereichen wird das Arbeits- und Privatleben noch viel st&#228;rker und
kontinuierlich weiter ver&#228;ndern. Diesen Wandel aufzuhalten, ist weder m&#246;glich noch sinnvoll. Der Anspruch ist, diesen
Wandel zu gestalten und darauf hinzuwirken, dass er wertegeleitet und zum Wohl von Mensch und Umwelt
erfolgt. Um diesem Anspruch gerecht zu werden, m&#252;ssen Deutschland und Europa eine f&#252;hrende Rolle in der
Entwicklung und Anwendung dieser Schl&#252;sseltechnologie &#252;bernehmen. Es sollen die Vorteile und Chancen, die
sich mit den neuen technologischen M&#246;glichkeiten ergeben, bef&#246;rdert und genutzt werden, wobei gleichzeitig
die Risiken abgewogen und wenn n&#246;tig eingegrenzt werden. 
Was war die Aufgabe der Enquete-Kommission?
Der Deutsche Bundestag hat aus diesem Grund am 26. Juni 2018 eine Enquete-Kommission eingesetzt, die sich
intensiv mit KI und ihren gesellschaftlichen, wirtschaftlichen und &#246;kologischen Folgen besch&#228;ftigen soll.
Basierend auf einem gemeinsamen Verst&#228;ndnis der Technologien sollten existierende und zuk&#252;nftige Auswirkungen
auf verschiedene Gesellschaftsbereiche untersucht und gemeinsam Handlungsempfehlungen f&#252;r den Gesetzgeber
entwickelt werden.
Wer hat an der Enquete-Kommission mitgewirkt?
Die Enquete-Kommission wurde zu gleichen Teilen mit Bundestagsabgeordneten und Sachverst&#228;ndigen besetzt.
Zus&#228;tzlich wurden sowohl zu den Sitzungen der Projektgruppen als auch zu den Sitzungen der Enquete-
Kommission zahlreiche weitere Expertinnen und Experten eingeladen, die die Diskussionen mit Denkanst&#246;&#223;en und
Detailwissen bereicherten.
Wie hat die Enquete-Kommission &#214;ffentlichkeit hergestellt?
Auch wenn eine Enquete-Kommission in erster Linie dazu dient, dem Deutschen Bundestag Empfehlungen zu
geben, gab es einen fraktions&#252;bergreifenden Konsens dazu, &#214;ffentlichkeit herzustellen. Aus diesem Grund sind
alle in den Enquete-Sitzungen gehaltenen Vortr&#228;ge von Expertinnen und Experten &#246;ffentlich zug&#228;nglich.1 Die
Zusammenfassungen der Teilberichte hat die Enquete-Kommission jeweils nach Ende der Projektgruppenphase
ver&#246;ffentlicht und im Fr&#252;hjahr 2020 eine digitale Plattform eingerichtet, auf der interessierte B&#252;rgerinnen und
B&#252;rger untereinander und mit den Mitgliedern der Enquete-Kommission in den Dialog treten konnten. Auch die
Ergebnispr&#228;sentation am 28. September 2020 wurde per Livestream &#252;bertragen und bot die M&#246;glichkeit, Fragen 
an die Enquete-Mitglieder zu stellen. Die Ver&#246;ffentlichung dieses Abschlussberichts kann zu einer breiten
Debatte zu KI beitragen. Die Enquete-Kommission bedankt sich noch einmal ausdr&#252;cklich bei allen B&#252;rgerinnen
und B&#252;rgern sowie bei allen Expertinnen und Experten f&#252;r ihre wertvollen Beitr&#228;ge. 
In welchem Umfeld arbeitete die Enquete-Kommission?
Die Arbeit dieser Enquete-Kommission ist eingebettet in eine Vielzahl von politischen Initiativen, die sich mit
den Implikationen einer immer breiteren Nutzung von KI in allen Gesellschaftsbereichen besch&#228;ftigen. Hierzu
geh&#246;ren beispielsweise die Fortschreibung der KI-Strategie der Bundesregierung, die Arbeit der
Datenethikkommission, das Wei&#223;buch zu KI der Europ&#228;ischen Kommission sowie die zahlreichen KI-Initiativen der
europ&#228;ischen Partner. Nat&#252;rlich ist es auch in Zukunft wichtig, diesen Dialog auf allen politischen Ebenen
weiterzuf&#252;hren.
Wie beeinflusste die Corona-Pandemie die Arbeit der Enquete-Kommission?
Auch f&#252;r die Arbeit der Enquete-Kommission bedeutete die Covid-19-Pandemie eine starke Z&#228;sur. Anstatt sich
physisch zu treffen, arbeiteten die einzelnen Gruppen seitdem prim&#228;r in Videokonferenzen und &#252;ber digitale
Plattformen. Sitzungen der gesamten Kommission fanden online oder in hybrider Form statt. Zudem lieferten die
Erfahrungen aus der Pandemie der Enquete-Kommission auch inhaltlich Denkanst&#246;&#223;e, die in den Endbericht
eingeflossen sind.2 Au&#223;erdem musste die Befragung von Fokusgruppen entfallen und eine geplante
Delegationsreise nach Russland und Finnland musste abgesagt werden.
&#220;berblick zu den Projektgruppen und zum Mantelbericht
Der Gesamtbericht ist das Produkt intensiver Befassung mit der Technologie, ihren Voraussetzungen und ihren
Anwendungsgebieten sowie den Chancen und Risiken, die sich daraus ergeben. Die Enquete-Kommission
entschied sich, diese in sechs Projektgruppen zu gliedern, die in verschiedenen Politikfeldern konkrete
Anwendungsf&#228;lle des KI-Einsatzes beleuchten sollten. Dabei diskutierten die Projektgruppenmitglieder den aktuellen
Status quo, zuk&#252;nftige Herausforderungen und daraus resultierende Handlungsempfehlungen und
dokumentierten dies in den Projektgruppenberichten. Auf Basis dieser fachspezifischen und dennoch praxisnahen
Diskussionen identifizierten die Mitglieder der Enquete-Kommission dann gemeinsam &#252;bergreifende Themen, die sich
durch alle Anwendungsgebiete ziehen. Diese wurden im Mantelteil des Berichts zusammengef&#252;hrt. Der Bericht
schlie&#223;t mit einem Kapitel zur Arbeitsweise der Enquete-Kommission ab. Im Folgenden werden die Berichtsteile
kurz inhaltlich und strukturell vorgestellt. 
Mantelbericht: Projektgruppen&#252;bergreifende Themen 
Der Mantelbericht startet mit dem Kapitel &#8222;Begriffskl&#228;rung K&#252;nstliche Intelligenz&#8220;, in dem wesentliche, in den
Berichtsteilen verwendete Grundbegriffe erl&#228;utert werden. Die nachfolgenden Kapitel setzen sich mit
projektgruppen&#252;bergreifenden Themen, wie Daten oder Recht, auseinander. Es werden Grundlagen und Erkenntnisse
beschrieben, die f&#252;r das Gesamtverst&#228;ndnis des Berichts wichtig sind sowie &#252;bergreifende
Handlungsempfehlungen gegeben.3 
1 Sie sind abrufbar unter https://www.bundestag.de/ausschuesse/weitere_gremien/enquete_ki (zuletzt abgerufen am 13.
Oktober 2020).
2 Siehe auch Kapitel 10 des Mantelberichts [KI und SARS-CoV-2].
3 Siehe auch den Mantelbericht in Kapitel C. I. [Mantelbericht: Projektgruppen&#252;bergreifende Themen].
K&#252;nstliche Intelligenz und Wirtschaft (Projektgruppe 1)
Die Projektgruppe &#8222;KI und Wirtschaft&#8220; beginnt ihren Bericht mit einer objektiven Sachstandskl&#228;rung und einer
gemeinsame Zielsetzung f&#252;r das Jahr 2030. In konkreten Szenarien werden die Situation und Handlungsoptionen
der drei zentralen Akteure &#8211; Start-ups, mittelst&#228;ndische Unternehmen und Konzerne &#8211; er&#246;rtert. Eine St&#228;rken-
Schw&#228;chen-Analyse stellt dann den Status quo in der wirtschaftsbezogenen Forschung und den Status quo der
KI-Implementierung f&#252;r ausgew&#228;hlte Branchen (Industrie/Produktion, Handel, Finanz- und
Versicherungswirtschaft, Agrar&#246;konomie und Landwirtschaft) und f&#252;r die drei oben genannten Akteure fest. Auf dieser Basis
entstand abschlie&#223;end ein Katalog von Handlungsempfehlungen.
K&#252;nstliche Intelligenz und Staat (Projektgruppe 2)
Aufgrund der breiten Anwendungsbereiche von KI durch den Staat wurde der Projektgruppenbericht in drei Teile
gegliedert, die von je einer Arbeitsgruppe (AG) erstellt wurden. AG 1 besch&#228;ftigte sich mit KI in der &#246;ffentlichen
Verwaltung, AG 2 befasste sich mit Smart City sowie Open Data und AG 3 diskutierte KI im Kontext von Innerer
Sicherheit, &#196;u&#223;erer Sicherheit und IT-Sicherheit. Den AG-Berichten ist ein allgemeiner Teil vorangestellt, der
einen umfassenden Katalog an themen&#252;bergreifenden Handlungsempfehlungen enth&#228;lt. Dar&#252;ber hinaus finden
sich themenspezifische Handlungsempfehlungen am Ende des jeweiligen Kapitels im AG-Bericht.
K&#252;nstliche Intelligenz und Gesundheit (Projektgruppe 3)
Der Bericht der Projektgruppe &#8222;KI und Gesundheit&#8220; beginnt mit einem beispielhaften &#220;berblick &#252;ber die
konkreten Anwendungsgebiete (z. B. Fr&#252;herkennung, Versorgung und Monitoring, personalisierte Therapien,
Pflege), gefolgt von einer St&#228;rken-Schw&#228;chen-Analyse f&#252;r Deutschland. Darauf folgt ein &#220;berblick &#252;ber KI-
spezifische Handlungsfelder (insbesondere Digitalisierung und Datenverf&#252;gbarkeit, Forschungs- und
Wirtschaftsstandort Deutschland, Haftung und Zulassung, intelligente Assistenzsysteme beispielweise in der Pflege).
Zu jedem der Handlungsfelder werden konkrete Handlungsempfehlungen formuliert, die in der Einleitung in 
zehn ausgew&#228;hlten Handlungsempfehlungen zusammengefasst sind.
K&#252;nstliche Intelligenz und Arbeit, Bildung, Forschung (Projektgruppe 4)
Die Projektgruppe besch&#228;ftigte sich zum einen mit den Anwendungsf&#228;llen und Auswirkungen von KI auf die
Arbeitswelt, zum anderen damit, wie KI in der Aus- und Weiterbildung eingesetzt werden kann, in welchen
Bildungsfeldern zum Thema KI aus- und weitergebildet werden sollte und letztlich auch damit, welche
Forschungsfelder f&#252;r KI relevant sind. Mit Anwendungsf&#228;llen (&#8222;Use Cases&#8220;) wird thematisiert, wo KI im
betrieblichen Umfeld und im Umfeld der Verwaltung erprobt bzw. wie KI bereits eingesetzt wird. Analog sind Beispiele
aufgef&#252;hrt, wo KI in Schule und Hochschule sowie in der Forschung eingesetzt werden kann bzw. schon wird.
Erg&#228;nzt werden die Anwendungsf&#228;lle mit einer Vision f&#252;r das Jahr 2030 und damit, wie die Arbeitswelt, Bildung
und Forschung von morgen aussehen k&#246;nnte sowie einer Betrachtung der Treiber und Bremser f&#252;r diese
Entwicklung. Nach diesem &#220;berblick werden in allen Bereichen die wesentlichen Herausforderungen identifiziert
und entsprechende Handlungsempfehlungen entwickelt.
K&#252;nstliche Intelligenz und Mobilit&#228;t (Projektgruppe 5)
Der Bericht der Projektgruppe besteht neben der Kurzfassung, den Vorbemerkungen und der Einf&#252;hrung aus
einer Reihe thematischer Schwerpunkte. Zuerst wurden KI-basierte Zukunftsvisionen der Mobilit&#228;t sowie
Intermodalit&#228;t und Plattformen diskutiert. Danach wurden Stra&#223;en-, Schienen-, Luft- und Schiffsverkehr in Bezug auf
den KI-Einsatz betrachtet sowie abschlie&#223;end &#252;bergreifende Themen der &#214;konomie, des Wettbewerbs und der
Stadtentwicklung analysiert. Jedes der daraus resultierenden Schwerpunktkapitel beinhaltet eigene
Handlungsempfehlungen, die sowohl den Personen- als auch den G&#252;terverkehr thematisieren.
K&#252;nstliche Intelligenz und Medien (Projektgruppe 6)
Die Projektgruppe &#8222;KI und Medien&#8220; trug dem vielschichtigen Charakter von Medien Rechnung. Erstens
thematisiert der Bericht die Zusammenh&#228;nge zwischen KI und Medien in der Breite. In diesen Teilen wurden sowohl
die Perspektive der Nutzerinnen und Nutzer bzw. Rezipientinnen und Rezipienten als auch die der Anbietenden
bzw. die Marktebene betrachtet. Hierbei ber&#252;cksichtigt der Bericht sowohl Informations- als auch
Unterhaltungsmedien. Dar&#252;ber hinaus wirft der Bericht im Rahmen der Marktanalyse einen umf&#228;nglichen Blick auf die
Plattformm&#228;rkte. Zweitens er&#246;rtert der Bericht einzelne Themen wie Deep Fakes, Empfehlungssysteme,
automatisierten Journalismus, Social Bots sowie politisches Microtargeting in der Tiefe. Drittens galt ein besonderer Blick
der Medienregulierung, wo KI-Relevanz im Kontext von Hate Speech oder Uploadfiltern im Zusammenhang mit
gro&#223;en Plattformen behandelt wurde. Abgerundet wurden die jeweils von der Herangehensweise
unterschiedlichen Abschnitte durch konkrete Handlungsempfehlungen, die der Vielfalt der Medien und KI-Bez&#252;ge Rechnung
tragen. 
Auftrag und Hintergrund der Enquete-Kommission
Das Kapitel &#8222;Auftrag und Arbeitsweise der Enquete-Kommission&#8220; gibt einen &#220;berblick &#252;ber die Hintergr&#252;nde,
Zusammensetzung und Arbeit der Enquete-Kommission. Die Liste der externen Sachverst&#228;ndigen ist im Anhang
2.4.11 [Anh&#246;rungsg&#228;ste der Enquete-Kommission] und im Anhang 2.4.12 [Anh&#246;rungsg&#228;ste der Projektgruppen]
beigef&#252;gt.
Zusammenfassung und Handlungsempfehlungen (Auswahl)
Bei der Arbeit der Enquete-Kommission waren einige Aspekte allgegenw&#228;rtig. Eine Auswahl wird im Folgenden 
dargestellt.
Das Ver&#228;nderungspotenzial von KI f&#252;r unsere Gesellschaft
KI ist die n&#228;chste Stufe einer durch technologischen Fortschritt getriebenen Digitalisierung. Ihr Potenzial, in
vielen Lebens- und Gesellschaftsbereichen einen tiefgreifenden Wandel herbeizuf&#252;hren, wird in den Analysen
des Status quo der Projektgruppenberichte sichtbar (siehe Kapitel 3.1 des Berichts der Projektgruppe &#8222;KI und 
Arbeit, Bildung, Forschung&#8220; [Grundlagen und Sachstandskl&#228;rung], Kapitel 2.1 des Berichts der Projektgruppe
&#8222;KI und Staat&#8220; [Einf&#252;hrung], Kapitel 4.4.2 des Berichts der Projektgruppe &#8222;KI und Gesundheit&#8220; [Status quo von 
KI-Anwendungen in der Pflege], Kapitel 4.1 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220; [Status quo von 
KI im Bereich der Wirtschaft], Kapitel 4.1 des Berichts der Projektgruppe &#8222;KI und Mobilit&#228;t&#8220; [Zukunft der
Mobilit&#228;t], Kapitel 3.2 des Berichts der Projektgruppe &#8222;KI und Medien&#8220; [Einf&#252;hrung in die technischen
Grundlagen]). Der parallel mit dem technologischen Wandel einhergehende Wertewandel ist nicht per se schlecht, der
Wertewandel geh&#246;rt zur Entwicklung von Mensch und Gesellschaft. Die technische Entwicklung braucht daher
demokratische Gestaltung &#8211; und zwar auf der Basis einer &#220;bereinkunft &#252;ber gutes und gerechtes Leben f&#252;r heute
und f&#252;r zuk&#252;nftige Generationen (siehe Kapitel 6.1 des Mantelberichts [Ziele und Zwecke einer KI-Ethik]). Die
Enquete-Kommission hat einen gesellschaftlichen Reflexionsbedarf in Bezug auf die Wirkung von KI-Systemen
festgehalten, direkte Auswirkungen des Einsatzes von KI-Systemen auf das Zusammenleben und die Diskurse
dar&#252;ber dargestellt und die M&#246;glichkeiten einer nachhaltigen und wohlstandsorientierten politischen Gestaltung
der Chancen und Auswirkungen von KI-Systemen beleuchtet (siehe Kapitel 7 des Mantelberichts [KI und
Gesellschaft]).
Der Mensch steht im Mittelpunkt  
Die Enquete-Kommission hat sich in ihren Debatten am Leitbild einer menschenzentrierten KI orientiert. Das
bedeutet, dass KI-Anwendungen vorrangig auf das Wohl und die W&#252;rde der Menschen ausgerichtet sein und
einen gesellschaftlichen Nutzen bringen sollten. Dabei ist zu beachten, dass der Einsatz von KI-Systemen die
Selbstbestimmung des Menschen als Handelnden und seine Entscheidungsfreiheiten wahrt und m&#246;glicherweise
sogar st&#228;rkt. Die Enquete-Kommission ist zuversichtlich, dass mit dieser Pr&#228;misse das positive Potenzial von KI-
Anwendungen ausgesch&#246;pft und das Vertrauen der Anwenderinnen und Anwender bei der Verwendung von KI-
Systemen am besten begr&#252;ndet und gest&#228;rkt werden kann. Dieses Vertrauen ist grundlegender Schl&#252;ssel f&#252;r die
gesellschaftliche Akzeptanz und den wirtschaftlichen Erfolg dieser Technologie. Und dieser Erfolg wiederum ist
der Schl&#252;ssel daf&#252;r, dies als KI europ&#228;ischer Pr&#228;gung zu etablieren, eine zukunftsf&#228;hige Volkswirtschaft
sicherzustellen und nicht von KI, der andere Wertegrundhaltungen zu Grunde liegen, gepr&#228;gt zu werden.
Neue Technologie zeigt Handlungsbedarfe auf und verst&#228;rkt sie mitunter
KI-Systeme machen den Handlungsbedarf bei bestehenden gesellschaftlichen, wirtschaftlichen und staatlichen
Aufgaben mitunter st&#228;rker sichtbar oder verst&#228;rken ihn sogar. Dazu z&#228;hlen etwa Bildungs- und
Geschlechtergerechtigkeit, die Bek&#228;mpfung von Rassismus und anderen Diskriminierungen sowie die Begleitung des
&#246;kologischen und &#246;konomischen Strukturwandels. In den Debatten der Enquete-Kommission wurde an vielen Stellen
deutlich, dass KI-Systeme ein m&#228;chtiges Werkzeug, aber eben nur ein Werkzeug sind. Parlament und Regierung
m&#252;ssen weiterhin politische L&#246;sungen f&#252;r gesellschaftliche Herausforderungen finden &#8211; KI kann dann f&#252;r die
Umsetzung eingesetzt werden. Mitunter &#246;ffnen sich f&#252;r gesellschaftliche Herausforderungen aber auch neue
L&#246;sungsans&#228;tze durch KI. Bemerkenswert ist, dass allein die Diskussion um KI selbst bewirkt, dass sich Wirtschaft,
Arbeitnehmerinnen und Arbeitnehmer sowie Politik gesamtheitlich nicht nur intensiv mit den technologischen
Aspekten von KI, sondern auch mit Themen wie Verteilungsgerechtigkeit und Gestaltungsoptionen f&#252;r Fairness
in digitalen M&#228;rkten besch&#228;ftigen (siehe Kapitel 4.1.3 des Berichts der Projektgruppe KI und Wirtschaft [Stand 
des Marktes]).
Eine gemeinsame Europ&#228;ische KI-Strategie
Ein starkes, wiederkehrendes Element in den Diskussionen der Enquete-Kommission war, eine zuk&#252;nftige KI-
Strategie auch europ&#228;isch zu denken.
KI-Entwicklung ist auf die Kooperation verschiedener Akteure in Forschung, Entwicklung und Anwendung
angewiesen. Deutschland allein hat wenige M&#246;glichkeiten, die Entwicklung von KI-Systemen im Sinne der oben
genannten Zielsetzungen zu gestalten. Es braucht daher eine europ&#228;ische Verst&#228;ndigung, um KI-Anwendungen
nach europ&#228;ischen Vorstellungen gestalten zu k&#246;nnen. 
Dies machte sich auch an vielen zentralen Handlungsempfehlungen bemerkbar, die eine europ&#228;ische Dimension 
in Bezug auf eine digitale Infrastruktur (siehe Kapitel 9.2 des Mantelberichts [Leitlinien]) sowie einen europa-
und deutschlandweit beschleunigten Ausbau der Kapazit&#228;ten, z. B. beim Cloud-Computing und beim
Netzausbau, anraten. Weiterhin werden das Erreichen technologischer Souver&#228;nit&#228;t (siehe Kapitel 5.1.3 des Berichts der
Projektgruppe &#8222;KI und Wirtschaft&#8220; [Technologische Souver&#228;nit&#228;t]), eine gemeinsame Forschungsstrategie (siehe
Kapitel 9.5 des Mantelberichts [Zentrale Handlungsempfehlungen f&#252;r den Staat]), ein auf europ&#228;ischen Werten
basierter Umgang mit Daten (siehe Kapitel 2.6 des Mantelberichts [Politischer Handlungsrahmen bez&#252;glich KI
und Daten]) und eine europaweit einheitliche Regulierung (siehe Kapitel 4.4 des Mantelberichts [KI-spezifisches 
Risikomanagement]) gefordert.
Interdisziplinarit&#228;t hebt Potenziale 
Ein interdisziplin&#228;rer Dialog zwischen den unterschiedlichen Akteuren und der Gesellschaft ist notwendig, um
die Potenziale rund um KI zu heben, m&#246;gliche Risiken fr&#252;hzeitig zu erkennen und der Komplexit&#228;t der Materie
gerecht zu werden. Daf&#252;r ist es notwendig, dass Aus- und Weiterbildung zu KI breit angelegt sind, um diesen 
interdisziplin&#228;ren Dialog zu erm&#246;glichen. Auch tr&#228;gt Aufkl&#228;rung dazu bei, Bef&#252;rchtungen und W&#252;nsche
bez&#252;glich der KI-getriebenen gesellschaftlichen Entwicklung fr&#252;hzeitig aufzunehmen und ein realistischeres Bild der
M&#246;glichkeiten und Gefahren des Einsatzes von KI-Systemen zu zeichnen.
Ebenso ist technische Interdisziplinarit&#228;t Schl&#252;ssel f&#252;r erfolgreiche KI-Innovation in Deutschland: KI-Software,
KI-Hardware und KI-Anwendung m&#252;ssen gemeinsam betrachtet werden, denn nur zusammen kann eine
energieeffiziente L&#246;sung erreicht, die Sicherheit (Robustheit, Zuverl&#228;ssigkeit) der Gesamtl&#246;sung (z. B. f&#252;r autonome
Verkehrsmittel) sichergestellt oder &#8211; bei der wirtschaftliche Nutzung einer KI-L&#246;sung &#8211; deren Kosten
gegen&#252;bergestellt werden.
Standardisierung f&#246;rdern
Standardisierungs- und Normungsprozesse sind in vielen Wirtschaftssektoren bew&#228;hrte Mittel, um den
Austausch von Unternehmen zu f&#246;rdern und Produkte und Dienstleistungen schnell und unkompliziert am Markt zu
etablieren. Auch gelingt es dadurch h&#228;ufig, Technologien &#252;ber Branchengrenzen hinweg zu verbinden.
Entsprechend hoch sind auch die Erwartungen, im Bereich KI mit Standardisierung und Normung erfolgreich zu agieren.
Einen Anpassungsbedarf sieht die Enquete-Kommission hier u. a. in Regelungen oder Standards, die f&#252;r die
Einf&#252;hrung von KI in die Prozesse und in die Produkte der Industrie gegeben werden.
Innovation und Experimentierr&#228;ume
Experimentierr&#228;ume, auch als Sandboxes bezeichnet, sind ein mehrfach genanntes Mittel, um KI-Innovation
voranzubringen. Experimentierr&#228;ume werden ben&#246;tigt, um KI-Technologien in realen Umgebungen sicher
erproben und weiterentwickeln zu k&#246;nnen. Dies unterst&#252;tzt auch den oft geforderten schnellen Transfer von
Forschungsergebnissen in die Anwendung. Besonders in den Projektgruppen Wirtschaft, Mobilit&#228;t und Gesundheit,
aber auch im Kapitel Forschung wurden Experimentierr&#228;ume als probates Mittel genannt. Der Gesetzgeber muss
flankierend den rechtlichen Rahmen definieren und die Ausweisung von Experimentierr&#228;umen unterst&#252;tzen.
Digitale Infrastruktur als Voraussetzung f&#252;r den Einsatz von KI 
Um KI in verschiedenen Sektoren nutzbar zu machen, ist eine leistungsf&#228;hige digitale Infrastruktur in der
Verwaltung (siehe den Bericht der Projektgruppe &#8222;KI und Staat&#8220; in Kapitel C. III. [K&#252;nstliche Intelligenz und Staat 
(Projektgruppe 2)]), im Gesundheitswesen (siehe Kapitel den Bericht der Projektgruppe &#8222;KI und Gesundheit&#8220; in
Kapitel C. IV. [K&#252;nstliche Intelligenz und Gesundheit (Projektgruppe 3)]), in Bildungseinrichtungen und
fl&#228;chendeckend im Land zwingend. Bund und L&#228;nder m&#252;ssen hier noch st&#228;rker zusammenwirken, um bestehende
L&#252;cken in der Breitbandversorgung, aber auch in Hard- und Software in &#246;ffentlichen Einrichtungen zu schlie&#223;en.
Die nachfolgenden Kapitel zitieren ausgew&#228;hlte Handlungsempfehlungen aus dem Gesamtbericht in gek&#252;rzter
Form. Ziel dieser Aufstellung ist es, den Leserinnen und Lesern beim Identifizieren und Auffinden von zentralen
Handlungsempfehlungen zu unterst&#252;tzen.
1 Daten4 
Daten spielen f&#252;r KI-Systeme in der Anwendung, beim Testen, vor allem aber beim Training eine zentrale Rolle.
Deshalb finden sich in vielen Berichtsteilen Handlungsempfehlungen, um den Umgang mit Daten zu verbessern.
Die hier exemplarisch aufgef&#252;hrten Handlungsempfehlungen besch&#228;ftigen sich mit der besseren Verf&#252;gbarkeit
durch Trust Center, h&#246;herer Interoperabilit&#228;t durch Standards, der F&#246;rderung von Open Data und der Pr&#228;zisierung 
von Datenschutzregelungen.
Verf&#252;gbarkeit von Daten
Zus&#228;tzliche politische Ma&#223;nahmen k&#246;nnen die Datenverf&#252;gbarkeit auch au&#223;erhalb von Regierung und
Verwaltung verbessern. So fehlen in der Wissenschaft oft die Ressourcen, in Forschungsprojekten erhobene Daten
breiter zug&#228;nglich zu machen. Der Austausch von Daten zwischen Unternehmen oder ihre gemeinsame Nutzung ist
mit Rechtsunsicherheit, insbesondere in Bezug auf das Kartellrecht, verbunden. Hier besteht Handlungsbedarf,
der von der Enquete-Kommission u. a. in der F&#246;rderung eines freiwilligen Teilens von Daten oder in der
Gestaltung von Datenzugangsrechten gesehen wird.5 
Datenverwendung
Die [Enquete-Kommission] erwartet, dass durch die Verbreitung von vertrauensschaffenden Konzepten zur
Anonymisierung und Pseudonymisierung von Daten die Menge verf&#252;gbarer Trainingsdaten steigen k&#246;nnte. Daher
empfiehlt sie, Trust-Strukturen zum interdisziplin&#228;ren, vertrauensw&#252;rdigen Austausch nicht personenbezogener
Daten aufzubauen.6 
Datenfreigabe
Die [Enquete-Kommission] empfiehlt, eine abgestufte, freiwillige und widerrufbare Datenfreigabe in enger
Abstimmung mit den Datenschutzaufsichtsbeh&#246;rden zu erm&#246;glichen, abgestimmte, interoperable und, wo m&#246;glich,
offene Standards [&#8230;] zu nutzen, ein nationales Versorgungsregister bzw. einen Registerverbund und die
dazugeh&#246;rigen dezentralen Vertrauensstellen aufzubauen und die Datenschutzgesetzgebung f&#252;r den
Gesundheitsbereich auf Grundlage der Datenschutzgrundverordnung (DSGVO) schnell zu vereinheitlichen.7 
Vernetzte Dateninfrastruktur
Die Abh&#228;ngigkeit von au&#223;erhalb der EU ans&#228;ssigen Anbietern l&#228;sst sich nur durch den Aufbau bzw. die St&#228;rkung
eigener Kompetenzen reduzieren. Hier verf&#252;gt die Verwaltung in der Beschaffung &#252;ber einen wichtigen Hebel.
Zus&#228;tzlich sollten Kompetenzen europ&#228;ischer Unternehmen in diesem Bereich gest&#228;rkt werden. Mit der GAIA-
X-Initiative hat die Bundesregierung eine europ&#228;ische Initiative zum Aufbau einer vernetzten Dateninfrastruktur
4 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion der CDU/CSU vor [Sondervotum zu Kapitel 1 der Kurzfassung des
Berichts (&#8222;Daten &#8220;) sowie Kapitel 5.7 des Mantelberichts (&#8222;KI und Recht &#8211; Handlungsempfehlungen &#8220;) des sachverst&#228;ndigen Mitglieds
Dr. Sebastian Wieczorek und der Abgeordneten Marc Biadacz, Hansj&#246;rg Durz, Ronja Kemmer, Jan Metzler, Stefan Sauer, Prof.
Dr. Claudia Schmidtke, Andreas Steier und Nadine Sch&#246;n sowie der sachverst&#228;ndigen Mitglieder Susanne Dehmel, Prof. Dr.
Wolfgang Ecker, Prof. Dr. Alexander Filipovi&#263;, Prof. Dr. Antonio Kr&#252;ger und Prof. Dr. J&#246;rg M&#252;ller-Lietzkow].
5 Siehe auch Kapitel 2.6 des Mantelberichts [Politischer Handlungsrahmen bez&#252;glich KI und Daten].
6 Siehe auch Kapitel 5.4 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220; [Handlungsempfehlungen zu Daten und Plattformen].
7 Siehe auch Kapitel 1.4 des Berichts der Projektgruppe &#8222;KI und Gesundheit&#8220; [Zehn Handlungsempfehlungen f&#252;r die Entwicklung und 
den Einsatz von KI im Gesundheitsbereich].
        
 
 
   
  
 
   
  
   
  
  
 
 
 
   
 
      
 
 
   
  
    
    
  
    
         
 
  
       
 
  
    
  
    
   
                                               
        
       
       
     
2
gestartet. Im Forschungsbereich soll der Aufbau einer Nationalen Forschungsdateninfrastruktur Kompetenzen
beim Forschungsdatenmanagement vernetzen und st&#228;rken. Beim Aufbau von Infrastrukturen ist auf nachhaltige
Verwendung von Ressourcen zu achten.8 
Datenstandards f&#246;rdern Interoperabilit&#228;t
Datenstandards bef&#246;rdern die organisations&#252;bergreifende Nutzung von Daten und unterst&#252;tzen breite
Anwendungsm&#246;glichkeiten von bzw. Interoperabilit&#228;t zwischen KI-Systemen. Auch das Zusammenf&#252;hren von
Datens&#228;tzen aus unterschiedlichen Quellen wird mithilfe von Standards vereinfacht. Die Enquete-Kommission
empfiehlt daher, die dezentralen Datenbest&#228;nde, z. B. in Wertsch&#246;pfungsketten, Forschernetzwerken und &#246;ffentlichen
Verwaltungen, st&#228;rker interoperabel zu vernetzen. Hierf&#252;r sollten Leitinitiativen zur dezentralen
Datenvernetzung, wie die International Data Spaces, die oben bereits genannte Nationale Forschungsdateninfrastruktur oder
die Open Knowledge Foundation, durch entsprechende gesetzliche Rahmenbedingungen und gezielte F&#246;rderung
unterst&#252;tzt werden.9 
Weiterentwicklung der Open-Data-Gesetzgebung
Auch eine Weiterentwicklung der h&#246;chst unterschiedlichen Open-Data-Gesetzgebung im Bund, in den L&#228;ndern 
und in Europa ist f&#252;r die Entwicklung einer Datenpolitik zentral. Sie muss den Grundrechtsschutz betonen und
als Alternative zu Datenmodellen positioniert werden, die wie in China von staatlichen Sicherheits- und
Kontrollinteressen getrieben und wie in den USA stark von den Interessen gro&#223;er Internetplattformen und der Tech-
Industrie gepr&#228;gt sind.10 
Datenschutz
Die durch die DSGVO erreichte Balance zwischen Datenschutz und Innovation sollte erhalten werden.
Rechtsunsicherheiten, die sich bei der Interpretation der DSGVO-Vorschriften mit Blick auf die Funktionsweise von
KI-Systemen noch ergeben, sollten gekl&#228;rt werden. In Teilen sollte das durch eine Konkretisierung der Vorgaben
durch die in der DSGVO vorgesehene regulierte Selbstregulierung, also in Form von Codes of Conduct und
Zertifizierungen, geschehen. Die Selbstverpflichtungen sollten nach f&#252;nf Jahren evaluiert und bei Bedarf durch
geeignete gesetzliche Regelungen ersetzt werden. Zum anderen sollten Probleme durch Klarstellung beseitigt
werden, die im Rahmen der DSGVO-Evaluierung festgestellt werden. Die Grundprinzipien der DSGVO bleiben
dabei unber&#252;hrt. [.] Der Versuch, aus anonymisierten Daten R&#252;ckschl&#252;sse auf Personen zu ziehen, ist bisher nicht
strafbar. Gepr&#252;ft werden sollte, ob und inwieweit es sinnvoll w&#228;re, das vors&#228;tzliche De-Anonymisieren von
Daten unter Strafe zu stellen.11 
Forschung 
Auf vielen Teilgebieten der KI hat die Forschung in Deutschland international einen ausgezeichneten Ruf.
Europa als Ganzes ist je nach Datenlage auf Augenh&#246;he mit den USA und China. Deutschland hat in der
Spitzenforschung Nachholbedarf, sowohl im Verg&#252;tungssystem, den Forschungsbedingungen als auch bei der
nachhaltigen Gewinnung von ausl&#228;ndischen Forschenden bzw. dem Halten der hier ans&#228;ssigen. F&#252;hrende deutsche
Forschungseinrichtungen sind im internationalen Vergleich wenig sichtbar. Durch gezielte zus&#228;tzliche Investitionen
k&#246;nnte Deutschland eigene Schwerpunkte setzen, die an bestehenden St&#228;rken ansetzen und ausgew&#228;hlte
Kernthemen von gesamtgesellschaftlicher Relevanz besonders entwickeln (siehe Kapitel 9.1 [Einleitung und &#220;berblick],
Kapitel 9.4.1 [Welche St&#228;rken hat die KI-Forschung in Deutschland?], Kapitel 9.4.2 [Welche Probleme hat die 
KI-Forschung in Deutschland?], Kapitel 9.4.3 [Welche Potenziale k&#246;nnen erschlossen werden?] und Kapitel 9.5
[Zentrale Handlungsempfehlungen f&#252;r den Staat] des Mantelberichts).
8 Siehe auch Kapitel 5.4 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220; [Handlungsempfehlungen zu Daten und Plattformen].
9 Siehe auch Kapitel 2.6 des Mantelberichts [Politischer Handlungsrahmen bez&#252;glich KI und Daten].
10 Siehe auch Kapitel 2.6 des Mantelberichts [Politischer Handlungsrahmen bez&#252;glich KI und Daten].
11 Siehe auch Kapitel 5.7 des Mantelberichts [Handlungsempfehlungen].
Werte
Gesellschaftliche Werte und das Wohlergehen der Menschen sowie der Erkenntnisgewinn m&#252;ssen im
Mittelpunkt der Bestrebungen von Wissenschaft und Forschung stehen. Die Ergebnisse und die darauf basierenden
Anwendungen sollen nachhaltig, vertrauensw&#252;rdig und ressourcenbewusst sein.12 
F&#246;rderung
Um an der Gestaltung von KI mitwirken zu k&#246;nnen, muss Deutschland gemeinsam mit anderen europ&#228;ischen
Staaten deutlich mehr Ressourcen in die Forschung zu KI investieren und so die Technologiesouver&#228;nit&#228;t sichern.
Dabei sind nicht nur nationale Leuchtt&#252;rme wichtig und notwendig, sondern es m&#252;ssen auch die europ&#228;ischen
Bestrebungen der Zentrumsbildung, welche auf breiten Forschungs- und Industrienetzwerken aufbauen,
unterst&#252;tzt werden. Dazu geh&#246;rt auch, die Attraktivit&#228;t des Forschungsstandortes Deutschland f&#252;r internationale
Forschende zu erh&#246;hen. Auch muss die KI-Grundlagenforschung in Algorithmik, Systemen, Hardware und Software
ausgebaut und nachhaltig in Universit&#228;ten und Forschungsinstitutionen verankert werden. Emerging Fields, also
Felder mit hohem Entwicklungs- und Erfolgspotenzial, m&#252;ssen bereits jetzt aufgebaut und stark gef&#246;rdert
werden.13 
Transfer
Die Zusammenarbeit zwischen Forschung, Wirtschaft und Gesellschaft ist essenziell, um Technologien aus der
Forschung heraus auf den Markt und in die Gesellschaft zu tragen. Ein zentrales Thema hierbei ist das
Bereitstellen von Daten und Technologien, die f&#252;r die Forschung notwendig sind. In den Universit&#228;ten und
Forschungsinstitutionen sollten, um den Transfer zu erm&#246;glichen, Prozesse vereinfacht und Sonderregeln f&#252;r die
Zusammenarbeit mit Start-ups entwickelt werden. Damit die gesamte Gesellschaft von den Fortschritten der KI-
Forschung profitiert, sind der Aufbau und die Vernetzung einer leistungsstarken und fl&#228;chendeckenden
Forschungsinfrastruktur n&#246;tig.14 
Forschungsthemen
Die Chance und die Herausforderung f&#252;r die Forschungsf&#246;rderung im Bereich von KI bestehen darin, in den
Bereichen Grundlagenforschung und Anwendungen mittel- bis langfristige Themen zu identifizieren, die von
gro&#223;er strategischer, wirtschaftlicher und gesellschaftlicher Bedeutung sind. Dazu geh&#246;ren insbesondere neben
den Grundlagen der KI-Algorithmen und KI-Systeme die Energieversorgung, die industrielle Fertigung, der
Verkehr und die Logistik, Smart Cities, E-Demokratie und der gesellschaftliche Diskurs, die Bildung und
Weiterbildung, die soziale Inklusion durch Assistenz- und Kommunikationssysteme, die Sicherheit und Verteidigung,
diagnostische Verfahren und insgesamt die Verbesserung von Pr&#228;vention, Intervention und Versorgung im Bereich
Gesundheit. Zu erforschen sind auch die Mechanismen und Auswirkungen von algorithmisch personalisierten
Nachrichten, Microtargeting, Filterblasen und Hate Speech.15 
3 Nachhaltigkeit durch KI und nachhaltige KI
Nachhaltigkeit in einem umfassenden Verst&#228;ndnis war Thema in fast allen Projektgruppen der Enquete-
Kommission. Verschiedene Aspekte der sozialen, &#246;konomischen und &#246;kologischen Dimension von Nachhaltigkeit
wurden zudem im Mantelbericht (siehe Kapitel 7. 3 [Entwicklung und Einsatz von KI-Systemen im Sinne von
Nachhaltigkeit und Wohlstand] und Kapitel 8 [KI und &#246;kologische Nachhaltigkeit] des Mantelberichts)
beschrieben. 
KI-Systeme k&#246;nnen zu einer nachhaltigen Entwicklung der Mobilit&#228;t (siehe Kapitel 4.1 des Berichts der
Projektgruppe &#8222;KI und Mobilit&#228;t&#8220; [Zukunft der Mobilit&#228;t]), zu einem effizienteren Umgang mit Ressourcen und einer
gelingenden Energiewende (siehe Kapitel 8.3 des Mantelberichts [Potenziale von KI f&#252;r das Vorantreiben der
12 Siehe auch Kapitel 9.2. [Leitlinien] und Kapitel 9.5 [Zentrale Handlungsempfehlungen f&#252;r den Staat] des Mantelberichts.
13 Siehe auch Kapitel 9.2. [Leitlinien] und Kapitel 9.5 [Zentrale Handlungsempfehlungen f&#252;r den Staat] des Mantelberichts.
14 Siehe auch Kapitel 9.2. [Leitlinien] und Kapitel 9.5 [Zentrale Handlungsempfehlungen f&#252;r den Staat] des Mantelberichts.
15 Siehe auch Kapitel 9.6 des Mantelberichts [Zukunftsthemen], Kapitel 2.3 des Berichts der Projektgruppe &#8222;KI und Staat&#8220; [
Handlungsempfehlungen und Operationalisierung], Kapitel 5.1 [Wachstum, Wertsch&#246;pfung und Nachhaltigkeit mit und durch KI] und 5.2 
[Unterst&#252;tzung der KI-Akteure] des Berichts der Projektgruppe &#8222;KI und Wirtschaft,  Kapitel 4.2.5 des Berichts der Projektgruppe
&#8222;KI und Gesundheit&#8220; [Handlungsempfehlungen] und Kapitel 6.2 des Berichts der Projektgruppe &#8222;KI und Medien&#8220; [Personalisierung].
Energiewende]) beitragen und so auch das Erreichen der Klimaziele unterst&#252;tzen. Die Enquete-Kommission
bef&#252;rwortet, dass KI-Systeme auch gezielt genutzt werden, um gesellschaftlichen Fortschritt &#8211; z. B. weniger
Diskriminierung, mehr Chancengerechtigkeit, bessere Arbeitsbedingungen und ein Erreichen der UN-
Nachhaltigkeitsziele (SDGs) &#8211; zu unterst&#252;tzen. 
Gleichzeitig gilt es zu ber&#252;cksichtigen, dass der Einsatz von KI-L&#246;sungen nicht per se wirtschaftlich, &#246;kologisch
und sozial nachhaltig ist. Hier m&#252;ssen klare Rahmenbedingungen daf&#252;r sorgen, dass nachhaltige Innovationen 
gef&#246;rdert werden (siehe Kapitel 8.6 des Mantelberichts [Fazit]).
Nachhaltiger und wohlstandsorientierter Einsatz von KI
KI bietet vielf&#228;ltige Potenziale bei der L&#246;sung dr&#228;ngender Zukunftsprobleme &#8211; vom Klimawandel bis zum
demographischen Wandel. Ob sich solche Potenziale realisieren, h&#228;ngt wesentlich davon ab, ob es eine gezielte 
F&#246;rderung solcher Ans&#228;tze auf Ebene der Forschungs- und der Wirtschaftsf&#246;rderung insbesondere in Feldern 
gibt, die noch nicht marktreif sind.16 
Marke Sustainable AI
Empfohlen wird, das (Markt-)Potenzial einer Marke &#8222;Sustainable AI&#8220; (siehe Kapitel 1 des Berichts der
Projektgruppe &#8222;KI und Wirtschaft&#8220; [Kurzfassung des Projektgruppenberichts]), also von KI-Anwendungen, die
hinsichtlich des Energie- und Ressourceneinsatzes und des Effizienzpotenzials im Einsatz optimiert sind, bei der
Weiterentwicklung der KI-Strategie zentral zu ber&#252;cksichtigen. Damit einhergehend wird mehr Forschung zur
systematischen Analyse des CO2-Minderungspotenzials durch KI-Anwendungen in den Schl&#252;sselsektoren
Energie, Industrie, Landwirtschaft, Wohnen und Mobilit&#228;t empfohlen. Suffizienzfragen sollen dabei beachtet
werden.17 
Verbesserung der Datenbasis zum Energieverbrauch und nachhaltige IT
Empfohlen wird eine Verbesserung der Datenbasis &#252;ber den Beitrag von KI-Anwendungen zur Entwicklung des
Energieverbrauchs und zwar sowohl hinsichtlich positiver wie negativer Effekte. Die Enquete-Kommission
empfiehlt weiter eine st&#228;rkere F&#246;rderung von nachhaltiger IT als infrastrukturelle Voraussetzung f&#252;r die Verringerung
des &#246;kologischen Fu&#223;abdrucks von KI.18 
4 Wirtschaft und Arbeit19 
Die disruptive Natur von KI-Technologien erm&#246;glicht nicht nur komplett neue Produkte, sondern auch neuartige
Gesch&#228;ftsmodelle. Neue Konkurrenten f&#252;r etablierte Firmen werden erscheinen, aber auch die Chance f&#252;r neue
Gesch&#228;fte geboten. Als Schl&#252;sselprobleme f&#252;r die Durchsetzungsf&#228;higkeit der deutschen wie europ&#228;ischen
Ans&#228;tze im KI-Bereich wurden die ausbleibende schnelle Skalierung von Ideen und Piloten zu wirkungsvollen 
Gro&#223;projekten und Akteuren, der verz&#246;gerte digitale Infrastrukturausbau in der Fl&#228;che und die fehlende
technologische Souver&#228;nit&#228;t etwa mit Blick auf die Entwicklung von Rechenleistungen (inkl. Hardware und Quanten-
Computing), Cloud-Strukturen oder Datenpooling identifiziert. Handlungsempfehlungen, die diese Themen
adressieren, finden sich im Bericht der Projektgruppe &#8222;KI und Wirtschaft&#8220; in Kapitel C II [K&#252;nstliche Intelligenz
und Wirtschaft (Projektgruppe 1)].
Die KI erm&#246;glicht auch neue Formen der Automatisierung, die einerseits monotone, gef&#228;hrliche oder
anstrengende T&#228;tigkeiten durch Maschinen erledigen lassen, die aber auch andererseits Arbeitspl&#228;tze wegfallen und neue 
mit anderen Anforderungen entstehen lassen. Auch erm&#246;glicht die KI neue Verfahren der Personalf&#252;hrung. 
Systematisches Monitoring von KI
Die wirkungsvolle strategische Steuerung des Zukunftsthemas KI durch Recht und Politik setzt voraus, dass eine
fundierte St&#228;rken-Schw&#228;chen-Analyse vorliegt und realistische technische wie wirtschaftliche Erwartungen be-
16 Siehe auch Kapitel 7.4, Nummer 6 des Mantelberichts [Handlungsempfehlungen].
17 Siehe auch Kapitel 8.7, Nummer 2 des Mantelberichts [Handlungsempfehlungen].
18 Siehe auch Kapitel 8.7 Nummer 3 und 5 des Mantelberichts [Handlungsempfehlungen].
19 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 4 der Kurzfassung des Berichts
(&#8222;Wirtschaft und Arbeit &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian
Butollo].
stehen. Die Enquete-Kommission regt daher an, f&#252;r Deutschland (und Europa) eine valide, differenzierende
Datenbasis zu den &#246;konomischen Effekten des KI-Einsatzes als Entscheidungsgrundlage zu erstellen. Zudem sollte
ein dynamisches Ziel- und Monitoringsystem entworfen werden, welches eine weisungsbefugte zentrale
Steuerungsstruktur f&#252;r KI unterst&#252;tzt. Um den Strukturwandel besser vorbereiten und gestalten zu k&#246;nnen, sind
evidenzbasierte Forschung und belastbare Prognosen f&#252;r die &#246;konomischen und Besch&#228;ftigungseffekte des KI-
Einsatzes unerl&#228;sslich. Neben den Aktivit&#228;ten des KI-Observatoriums sind spezielle F&#246;rderprogramme zur
systematischen Erfassung und Analyse der arbeitsmarktrelevanten Auswirkungen von KI aufzulegen.20 
Start-ups als Treiber f&#252;r die KI-Transformation
Start-ups werden als wesentlicher Treiber f&#252;r die KI-Transformation gesehen. Entsprechend werden verschiedene
Empfehlungen zur St&#228;rkung eines KI-Startup-&#214;kosystems gegeben. Dazu geh&#246;ren Ma&#223;nahmen wie Fonds und 
F&#246;rderm&#246;glichkeiten in der Wachstumsphase junger Unternehmen durch die EU, den Bund und die L&#228;nder
ebenso wie Vorschl&#228;ge zur Verbesserung des Transfers aktueller Forschung in neue Gesch&#228;ftsmodelle durch
Spin-off-Prozesse und Forschungsausgr&#252;ndungen. Eine vermehrte Vergabe von Auftr&#228;gen der &#246;ffentlichen
Verwaltung an deutsche Start-ups wird nicht nur als St&#228;rkung des Startup-&#214;kosystems, sondern auch als Enabler f&#252;r
die st&#228;rkere Zusammenarbeit zwischen KI-Start-ups und mittelst&#228;ndischen Unternehmen angesehen. Hierf&#252;r ist
es notwendig, dass H&#252;rden zur Teilnahme an Vergabeprozessen weiter gesenkt und diese Start-up-freundlich 
gemacht werden, z. B. durch weiteren B&#252;rokratieabbau, schnelle Vergabeentscheidungen und
innovationsf&#246;rdernde Vergabeverfahren, angelehnt an den &#8222;wettbewerblichen Dialog&#8220; und an &#8222;Innovationspartnerschaften&#8220;
nach europ&#228;ischem Vergaberecht.21 
Anreize f&#252;r KMU / Wirtschaftsf&#246;rderung
Mit Blick auf KMU sollten die Beratung und konkrete Unterst&#252;tzungsleistungen beim Technologie-Scouting
sowie bez&#252;glich des Transfers durch die Mittelstand-4.0-Kompetenzzentren, KI-Trainerinnen und -Trainer und
spezifische Qualifizierungsma&#223;nahmen intensiviert werden. Wesentlich erscheint die Schaffung von Datenpools,
etwa in Form interdisziplin&#228;rer Datengenossenschaften, sowie die weitere F&#246;rderung regionaler Cluster und
Hubs. Zudem sollten f&#252;r KMU st&#228;rkere Anreize geschaffen und M&#246;glichkeiten aufgezeigt werden, wie nicht
personenbezogene bzw. anonymisierte Daten sicher und gemeinschaftlich mit anderen Unternehmen und
Organisationen geteilt werden k&#246;nnen, um hieraus f&#252;r alle Beteiligten Mehrwerte zu generieren, z. B. durch Trust-
Center f&#252;r den Datenaustausch oder Schaffung interdisziplin&#228;rer Datengenossenschaften [...]. So k&#246;nnen
Konzentrationseffekte und Monopolisierungstendenzen in der Daten&#246;konomie eingeschr&#228;nkt werden, die gro&#223;en
internationalen Akteure (insb. GAFAM) aufgrund ihrer umfangreichen Datenbest&#228;nde und Daten-Expertise einen
Wettbewerbsvorteil im KI-Markt verleihen.22 
KI-Moonshot-Projekte
KI bietet vielf&#228;ltige Potenziale zur L&#246;sung dr&#228;ngender Zukunftsprobleme. Ob sich solche Potenziale realisieren,
h&#228;ngt aber wesentlich davon ab, ob es eine gezielte F&#246;rderung solcher Ans&#228;tze auf der Ebene der Forschung und
der Wirtschaftsf&#246;rderung gibt, insbesondere in Feldern, die noch nicht marktreif sind oder deren Anwendung
bislang nicht durch wettbewerbliche Anreize belohnt wird. Als Instrument hierf&#252;r wird vorgeschlagen,
gesellschaftlich w&#252;nschenswerte &#8222;KI-Moonshot-Projekte&#8220; zu f&#246;rdern und umzusetzen.23 
Transfer f&#246;rdern
KI ist mehr als nur eine Technologie; die dadurch bewirkten Ver&#228;nderungen wirken bereits in einigen Branchen
und M&#228;rkten disruptiv, in anderen Bereichen sind Ver&#228;nderungen mit hoher Wahrscheinlichkeit zu erwarten. [...]
Politik und Staat m&#252;ssen diese Transformation mitgestalten. Die Enquete-Kommission empfiehlt, die Beratung
f&#252;r Unternehmen zur Transformation der eigenen Gesch&#228;ftsprozesse und -modelle und den Austausch von Best
Practices [...] weiter auszubauen, vorhandene dezentrale KI-Ressourcen auf einer Plattform unter neutraler, nicht-
20 Siehe auch Kapitel 1 des Projektgruppenberichts &#8222;KI und Wirtschaft&#8220; [Kurzfassung des Projektgruppenberichts] und Kapitel 1 des
Projektgruppenberichts &#8222;KI und Arbeit, Bildung, Forschung&#8220; [Kurzfassung des Projektgruppenberichts].
21 Siehe auch Kapitel 5.1.3 des Projektgruppenberichts &#8222;KI und Wirtschaft&#8220; [Technologische Souver&#228;nit&#228;t].
22 Siehe auch Kapitel 1 [Kurzfassung des Projektgruppenberichts] und  Kapitel 5.2 [Innovation und Start-ups: Start-up-&#214;kosysteme,
Start-up-F&#246;rderungen] des Projektgruppenberichts &#8222;KI und Wirtschaft&#8220;.
23 Siehe auch Kapitel 7 des Mantelberichts [KI und Gesellschaft] und Kapitel 5.1 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220;
[Wachstum, Wertsch&#246;pfung und Nachhaltigkeit mit und durch KI].
kommerzieller Federf&#252;hrung und mit politischer Flankierung zusammenzuf&#252;hren und &#8222;Regulatory Sandboxes&#8220;
[&#8230;] bzw. freie Experimentierr&#228;ume einzurichten, die Forscherinnen und Forschern unter geeigneten
Voraussetzungen zur Durchf&#252;hrung von Realexperimenten dienen k&#246;nnen.24 
Mit KI gute Arbeit sichern
Um Potenziale f&#252;r Emanzipation, Nachhaltigkeit und gute Arbeit zu f&#246;rdern und Risiken f&#252;r Besch&#228;ftigte durch
Entwertung ihrer F&#228;higkeiten, ihrer Pers&#246;nlichkeitsrechte und ihrer beruflichen Anschlussf&#228;higkeit zu
minimieren sowie ungerechtfertigte Kontrolle, Entm&#252;ndigung, Arbeitsverdichtung und Arbeitsplatzverluste zu
vermeiden, braucht die Arbeitsgestaltung besondere Leitvorstellungen. Es ist sinnvoll, die Einflussnahme des
Gesetzgebers und der weiteren Normsetzungsakteure unter anderem auf folgende Ziele auszurichten: Das Potenzial von
KI zur Produktivit&#228;tssteigerung und zur Steigerung des Wohlergehens der Erwerbst&#228;tigen sollte genutzt werden,
neue Gesch&#228;ftsmodelle zu entwickeln und zu f&#246;rdern, die zur Besch&#228;ftigungssicherung und zum
Besch&#228;ftigungsausbau beitragen, &#8222;Gute Arbeit by Design&#8220; zu entwickeln und vorrangig eint&#246;nige oder gef&#228;hrliche Aufgaben an
Maschinen zu &#252;bertragen,[&#8230;] und daf&#252;r zu sorgen, dass der Mensch als soziales Wesen an seinem Arbeitsplatz
die M&#246;glichkeit hat, sozial mit anderen Menschen zu interagieren, menschliches Feedback zu erhalten und sich
als Teil einer Belegschaft zu begreifen.25 
Mitbestimmung modernisieren
Die Akzeptanz unter den Besch&#228;ftigten und die erfolgreiche Implementierung von KI h&#228;ngt ma&#223;geblich von 
fr&#252;hzeitiger Information und Beteiligung ab. Zur Wahrung von Einflussm&#246;glichkeiten von Arbeitnehmerinnen
und Arbeitnehmern beim Schutz ihrer Pers&#246;nlichkeitsrechte, der Vermeidung von &#220;berlastung, der Bew&#228;ltigung
von betrieblicher Transformation und der Gestaltung von Besch&#228;ftigungsbedingungen ist ein Update der
Mitbestimmung erforderlich, das der technischen Entwicklung Rechnung tr&#228;gt und die bisherige Balance zwischen
Arbeitnehmerrechten und Eigentumsrechten fortentwickelt. Um dem Prozesscharakter lernender Maschinen
gerecht zu werden und um vorausschauend, wirksam und schnell zu wirken, muss die betriebliche Mitbestimmung 
auf das Konzept der Entwicklung, des Einsatzes und der Fortentwicklung der Systeme ausgerichtet sein. Sie muss
sich au&#223;erdem der normativen Wirkung aller wesentlichen Fragen der Pers&#246;nlichkeitsrechte annehmen k&#246;nnen
und einen wirksamen Einfluss auf die Arbeitsmenge, die Arbeitsorganisation und die Qualifizierung er&#246;ffnen,
die sich im Zusammenhang mit dem Einsatz von KI-Systemen ergeben.26 
Bedingungen der KI-Anwendung im Personalwesen
Beim Einsatz von KI-Anwendungen muss gew&#228;hrleistet sein, dass Menschen weiterhin in Personalfragen
entscheiden. In der Personalverwaltung d&#252;rfen f&#252;r die Nutzung in automatisierten Programmen oder KI-L&#246;sungen
keine Daten erhoben und verwendet werden, welche der willentlichen Steuerung der Betroffenen grunds&#228;tzlich
entzogen sind.27 
Weiterentwicklung der sozialen Sicherungssysteme
Die zunehmende Verbreitung von KI-Systemen in Wirtschaft und Gesellschaft gibt einer bereits laufenden
Debatte um die Weiterentwicklung der sozialen Sicherungssysteme zus&#228;tzliche Bedeutung. Die Empfehlung lautet,
in der n&#228;chsten Legislaturperiode des Deutschen Bundestages eine Expertenkommission zu dieser Fragestellung
einzurichten. Auf Grundlage empirischer Forschungsergebnisse soll gepr&#252;ft werden, ob und inwieweit f&#252;r die 
sozialversicherungsrechtliche Einstufung schutzbed&#252;rftiger Mitarbeiterinnen und Mitarbeiter bei
Plattformunternehmen passende Kriterien und Regelungen geschaffen werden k&#246;nnen.28 
5 Kompetenzen, Bildung, M&#252;ndigkeit
Nahezu alle Projektgruppen haben Empfehlungen zu notwendigen Investitionen f&#252;r den Kompetenzaufbau zu KI
formuliert. Diese Empfehlungen betreffen alle Facetten des Bildungssektors, mit einem besonderen Gewicht auf
der Schaffung der notwendigen Voraussetzungen f&#252;r KI (insbesondere in den MINT-F&#228;chern und &#8222;soft skills&#8220;), 
24 Siehe auch Kapitel 5.2 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220; [Unterst&#252;tzung der KI-Akteure].
25 Siehe auch Kapitel 3.3.1 des Berichts der Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220; [Leitvorstellungen].
26 Siehe auch Kapitel 5.1.2.6 des Berichts der Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220; [Handlungsempfehlungen].
27 Siehe auch Kapitel 5.1.3.5 des Berichts der Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220; [Handlungsempfehlungen].
28 Siehe auch Kapitel 5.1.3.5 des Berichts der Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220; [Handlungsempfehlungen].
dem generellen Aufbau von F&#228;higkeiten zu KI bereits in der Schule &#8211; gleicherma&#223;en f&#252;r M&#228;dchen wie f&#252;r Jungen
&#8211; sowie der beruflichen Weiterbildung. In der Schule ist weiterhin zu betrachten, ob und wie KI als unterst&#252;tzende
Ma&#223;nahme im Unterricht zum Einsatz kommen kann. Weiterhin geht es um Ma&#223;nahmen, die einen m&#252;ndigen
Umgang der Gesellschaft mit KI erm&#246;glichen. 
Bildungspolitik um KI-spezifische Themen erweitern
Ein weiteres essenzielles Themenfeld ist die Bildungspolitik. Bei der Bildungspolitik ist der Staat gefordert,
umfangreiche Ma&#223;nahmen schon im schulischen Bereich zu initiieren, die die Bildung im Feld der KI, insbesondere
in den MINT-F&#228;chern, aber auch im Sinne einer dom&#228;nen&#252;bergreifenden, interdisziplin&#228;ren Bildung bef&#246;rdern,
damit auch in der Folge gen&#252;gend junge Menschen die Lehrangebote an den Hochschulen vollumf&#228;nglich nutzen
k&#246;nnen. Nur dann kann mittel- bis langfristig eine hinreichend gro&#223;e Anzahl von KI-Spezialistinnen und -
Spezialisten, die in allen Bereichen ben&#246;tigt werden, an den Hochschulen ausgebildet werden und sowohl f&#252;r die
Forschung als auch f&#252;r die Anwendung in Wirtschaft und Staat zur Verf&#252;gung stehen.29 
Einsatz von KI-Systemen im Unterricht weiter erforschen
Um KI in Lernprozessen p&#228;dagogisch sinnvoll einzusetzen, sollte noch mehr erforscht werden, wie KI-Systeme
auf Lernende und Lehrende wirken und wie sie diese dabei unterst&#252;tzen k&#246;nnen, p&#228;dagogische Ziele (u. a.
Inklusion) zu erreichen. Bei der Einf&#252;hrung von KI-Systemen und der zugeh&#246;rigen Dateninfrastruktur ist eine
medienp&#228;dagogische Prozessbegleitung zur Verf&#252;gung zu stellen.30 
Diversit&#228;t f&#246;rdern
Bestehende Ungleichgewichte, die zwischen M&#228;dchen und Jungen bzw. Frauen und M&#228;nnern im Hinblick auf
das Wissen &#252;ber und die Anwendung von KI bestehen, sollen ausgeglichen werden. Dazu k&#246;nnen sowohl Schulen
als auch Hochschulen Angebote entwickeln, die M&#228;dchen und junge Frauen f&#252;r Informatik und KI interessieren 
und ihnen Gestaltungsm&#246;glichkeiten mitgeben. Lehrkr&#228;fte sollen daf&#252;r in ihrer Ausbildung sensibilisiert werden.
Hochschulen sollen die M&#246;glichkeiten von spezifischen Angeboten f&#252;r M&#228;dchen und Jungen innerhalb von
Informatikstudieng&#228;ngen pr&#252;fen. Das Wissen in der Bev&#246;lkerung zu KI sollte inklusiv erweitert werden, das hei&#223;t,
die Heterogenit&#228;t der Gesellschaft sollte ebenso wie die verschiedenen Einsatzfelder ber&#252;cksichtigt werden.31 
Aus- und Weiterbildungsangebote zu KI schaffen
Im Bereich Aus- und Weiterbildung m&#252;ssen Bildungsangebote geschaffen werden, die die KI-Kompetenz der
Erwerbst&#228;tigen f&#246;rdern. Diese Fortbildungsangebote sollten einheitliche Standards erf&#252;llen. [...] Die St&#228;rkung
der betrieblichen Weiterbildung ist zentral, um das durch KI immer wichtiger werdende lebenslange Lernen zu
erm&#246;glichen. Dem Mismatch-Problem, das hei&#223;t dem gleichzeitigen Vorhandensein von Jobverlusten und
Fachkr&#228;ftemangel auf dem Arbeitsmarkt, ist nur durch einen sp&#252;rbaren Ausbau einer funktionierenden
Wissensinfrastruktur zu begegnen. Berufliche Weiterbildung ist eine bildungspolitische Aufgabe und sie muss allen Menschen
zug&#228;nglich sein.32 
&#220;ber den Einsatz von KI aufkl&#228;ren
Die Menschen m&#252;ssen &#252;ber Meinungsbildung, Bef&#228;higung, Transparenz, Teilhabe und Schutz bestm&#246;glich f&#252;r
die gesellschaftlichen Umbr&#252;che (positiv wie negativ) infolge des Einsatzes von KI-Systemen vorbereitet
werden, um eine breite Akzeptanz f&#252;r KI-Systeme zu erreichen. Ein wichtiges Handlungsfeld ist die F&#246;rderung des
Verst&#228;ndnisses und des Bewusstseins f&#252;r die Chancen von KI-Systemen sowie bez&#252;glich der eigenen Kompetenz
und des Wissens &#252;ber deren Wirkungsmechanismen.33 
29 Siehe auch Kapitel 9.5 des Mantelberichts [Zentrale Handlungsempfehlungen f&#252;r den Staat].
30 Siehe auch Kapitel 5.2.8 des Berichts der Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220; [Handlungsempfehlungen].
31 Siehe auch Kapitel 5.2.8.1 des Berichts der Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220; [Lehrkr&#228;ftebildung].
32 Siehe auch Kapitel 5.2.8.2 des Berichts der Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220; [Aus- und Weiterbildung].
33 Siehe auch Kapitel 7.4, Nummer 2 des Mantelberichts [Handlungsempfehlungen].
        
 
 
    
   
  
   
 
  
 
       
 
 
    
   
 
  
  
  
  
   
     
 
 
 
  
  
  
  
 
 
   
 
  
      
 
                                               
            
     
 
      
          
    
  
         
         
         
6
Allgemein verf&#252;gbare Weiterbildungsplattform f&#252;r KI erstellen
Um die Bev&#246;lkerung in die Lage zu versetzen, grundlegende Zusammenh&#228;nge im Bereich KI zu verstehen und
die Funktionsweise einordnen zu k&#246;nnen, sollte eine Weiterbildungsplattform entwickelt werden.  [&#8230;] Dabei ist
darauf zu achten, dass eine staatliche Weiterbildungsplattform verschiedene Angebote nicht nur geb&#252;ndelt
darstellt, sondern dass der Zugang niedrigschwellig ist.34 
Auswirkungen von KI-Empfehlungen auf die Entscheidungsautonomie untersuchen
Es ist ungekl&#228;rt, welchen Einfluss die Empfehlungen von KI-Systemen auf die abschlie&#223;ende Entscheidung des
Menschen haben. So ist fraglich, ob und inwieweit Besch&#228;ftigte in der Verwaltung im Arbeitsalltag einer KI-
Empfehlung widersprechen und so zur Fehlervermeidung beitragen. Deshalb m&#252;ssen die soziologischen und
psychologischen Auswirkungen von KI-Empfehlungen auf den Menschen in seiner Entscheidungsautonomie
untersucht werden. KI-Systeme sollten stets so gestaltet sein, dass sie der Autonomie der oder des Einzelnen nicht
entgegenstehen. Hier besteht eindeutiger und interdisziplin&#228;rer Forschungsbedarf, weshalb Untersuchungen zu
dieser Thematik aktiv gef&#246;rdert werden m&#252;ssen.35 
Mensch und Gesellschaft36 
KI-basierte Systeme wirken sich schon heute auf das Verhalten und den Wissensstand von Individuen in vielen
Bereichen der Gesellschaft aus und sind damit also auch ein Faktor, der auf das kollektive Verhalten wirkt.
Beispiele sind die Navigation von Fahrzeugen und die Anzeige bzw. Empfehlung von Inhalten in sozialen
Netzwerken und auf Videoportalen. In vielen Kontexten hat die Enquete-Kommission &#252;ber die Gestaltungsprozesse und
Gestaltung solcher Systeme diskutiert. Im Folgenden sind Handlungsempfehlungen aus den Bereichen Mobilit&#228;t
und Medien aufgef&#252;hrt, ein besonderer Fokus liegt auf den Themen Meinungsfreiheit und &#8211;vielfalt,
Diskriminierungsfreiheit, Transparenz und Nachvollziehbarkeit.
Ganzheitliche Betrachtung der Mobilit&#228;t
Die Mobilit&#228;t der Zukunft und damit auch KI-Anwendungen in der Mobilit&#228;t m&#252;ssen ganzheitlich betrachtet
werden. [...] Es gilt, die innovativen und zielf&#252;hrenden Anstrengungen in einem holistischen Ansatz zu b&#252;ndeln
und somit die KI f&#252;r den gesamten Mobilit&#228;tssektor voranzubringen. Dazu bedarf es einer st&#228;rkeren Vernetzung
in der Verkehrsplanung, in der Forschung und Entwicklung sowie auch in der rechtlichen Rahmensetzung sowohl
in Deutschland als auch in Europa.37 
Medienvielfalt erhalten
Der Wirkungsgrad bzw. die Hebelwirkung des Einsatzes von KI bei Empfehlungssystemen ist evident und st&#228;rkt
insbesondere Intermedi&#228;re in den Medienm&#228;rkten, selbst wenn sie keine eigenen medialen Inhalte anbieten.  [...]
Will man die Medienvielfalt erhalten, bleibt aus dieser Perspektive als sinnvolles Instrument &#8211; neben der
Anwendung des Kartellrechts &#8211; die Einf&#252;hrung einer Digitalsteuer auf die KI-basierten Dienste der Plattform- und
Social-Media-Anbieter, die dadurch &#252;berproportional an den Werbem&#228;rkten teilhaben.38 
34 Siehe auch Kapitel 5.2.8.2 des Berichts der Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220; [Aus- und Weiterbildung].
35 Siehe auch Kapitel I. 3.1 des Berichts der Projektgruppe &#8222;KI und Staat&#8220; [Auswirkungen von KI-Empfehlungen auf die
Entscheidungsautonomie untersuchen].
36 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion der CDU/CSU vor [Sondervotum zu Kapitel 6 der Kurzfassung des
Berichts (&#8222;Mensch und Gesellschaft &#8220;) sowie Kapitel 4.2.6 des Berichts der Projektgruppe 6 &#8222;KI und Medien&#8220; (&#8222;Medienm&#228;rkte und KI 
&#8211; Handlungsempfehlungen &#8220;) der Abgeordneten Ronja Kemmer und der Abgeordneten Marc Biadacz, Hansj&#246;rg Durz, Jan Metzler,
Stefan Sauer, Andreas Steier, Prof. Dr. Claudia Schmidtke und Nadine Sch&#246;n sowie der sachverst&#228;ndigen Mitglieder Susanne
Dehmel, Prof. Dr. Wolfgang Ecker, Prof. Dr. Antonio Kr&#252;ger und Dr. Sebastian Wieczorek].
37 Siehe auch Kapitel 1.1.2 des Berichts der Projektgruppe &#8222;KI und Mobilit&#228;t&#8220; [Themenschwerpunkte].
38 Siehe auch Bericht der Projektgruppe &#8222;KI und Medien&#8220; in Kapitel C. VII. [K&#252;nstliche Intelligenz und Medien (Projektgruppe 6)].
Begrenzung von politischem Microtargeting
Es sollte &#228;hnlich wie bei der personalisierten Ansprache im Offline-Bereich (etwa bei postalischer Wahlwerbung)
Begrenzungen daf&#252;r geben, welche pers&#246;nlichen Verhaltensdaten f&#252;r politisches Microtargeting genutzt werden
d&#252;rfen. Diese Begrenzung sollte sowohl f&#252;r das Targeting (durch die Werbetreibenden) als auch f&#252;r die
Ausspielung (durch die KI der Plattformen) gelten. Hier sollten gesetzliche Regeln die freiwilligen Ma&#223;nahmen einiger
kommerzieller Plattformen ersetzen.39 
Uploadfilter vorerst ausschlie&#223;en
Der unkontrollierte Einsatz von Uploadfiltern sollte weitestm&#246;glich ausgeschlossen werden, wenn es um
kontextabh&#228;ngige oder rechtlich nicht-triviale Einsch&#228;tzungen geht. Das steht einer Verwendung von KI-basierten
Filtersystemen zur Vorsortierung im Vorfeld einer menschlichen Pr&#252;fung nicht entgegen. Eine Verbesserung
derzeit eingesetzter Systeme und eine regulatorische Begleitung ihres Einsatzes erscheinen vor diesem
Hintergrund w&#252;nschenswert, wobei eine Automatisierung der Rechtsdurchsetzung in jedem Fall zu vermeiden ist. Eine
automatisierte L&#246;schung bzw. Nichtver&#246;ffentlichung sollte auf F&#228;lle begrenzt sein, in denen die Verbreitung
spezifischer Inhalte unabh&#228;ngig von jedem denkbaren Kontext unterbunden werden soll.40 
Forschungstransfer im Bereich Diskriminierungserkennung
Zu Diskriminierungserkennung und -vermeidung in KI-Systemen wurde in den letzten Jahren viel geforscht. Der
n&#228;chste Schritt, der Transfer dieser Erkenntnisse in den Software-Entwicklungsalltag, sollte gef&#246;rdert werden,
damit die Erkenntnisse m&#246;glichst schnell und breit umgesetzt werden k&#246;nnen und durch Forschung begleitet
werden.41 
KI-gest&#252;tzte Entscheidungen regelm&#228;&#223;ig auf Diskriminierungsfreiheit &#252;berpr&#252;fen
Es muss sichergestellt werden, dass staatlich entwickelte und genutzte KI-Systeme [&#8230;] nicht diskriminieren. Es
muss gepr&#252;ft werden, ob die Daten in dem algorithmischen Entscheidungssystem in einem der
Anwendungsfelder zum Einsatz kommen, die grundrechtlich besonders gesch&#252;tzt sind und in denen es in besonderem Ma&#223;e auf
Gleichbehandlung ankommt (z. B. Zugang zu Sozialleistungen). Dann muss das Ergebnis der maschinellen
Entscheidung und [&#8230;] das der finalen Entscheidung durch den Menschen regelm&#228;&#223;ig daraufhin untersucht werden,
ob die Entscheidung diskriminierend ist.42 
KI-Einsatz transparent machen
Regeln f&#252;r den Einsatz von KI m&#252;ssen deswegen mit einem die Diversit&#228;t der Gesellschaft reflektierenden Blick
und ggf. unter Beteiligung der Betroffenen erarbeitet werden. Je nach Kritikalit&#228;t m&#252;ssen B&#252;rgerinnen und
B&#252;rger &#252;ber den Einsatz von KI informiert und generell f&#252;r den Umgang mit KI gebildet werden. [..] Dort, wo
Menschen von den Folgen einer Entscheidung auf Basis eines KI-Systems betroffen sind, m&#252;ssen sie gen&#252;gend
Informationen erhalten, um ihre Rechte angemessen wahrnehmen und die Entscheidung ggf. infrage stellen zu
k&#246;nnen.43 
7 Regulierung und Staat
Als ein durch den Gesetzgeber ins Leben gerufenes Gremium hat sich die Enquete-Kommission immer wieder
mit Regulierungsfragen in Bezug auf KI besch&#228;ftigt. Den gr&#246;&#223;eren Rahmen f&#252;r die Gestaltung von KI bilden das
Grundgesetz der Bundesrepublik Deutschland und die Grundrechtecharta der Europ&#228;ischen Union mit dem
Begriff der Menschenw&#252;rde als Ma&#223;gabe f&#252;r alle politische Gestaltung. Wie anhand der hier aufgef&#252;hrten
Handlungsempfehlungen ersichtlich, ging es dabei u. a. um die Definition von Grunds&#228;tzen, Fragen der
Verh&#228;ltnism&#228;&#223;igkeit, die Notwendigkeit von risiko- und sektorspezifischer Regulierung sowie Haftungsfragen. Die generelle
39 Siehe auch Kapitel 6.2.2 des Berichts der Projektgruppe &#8222;KI und Medien&#8220; [Handlungsempfehlungen].
40 Siehe auch Kapitel 7.4.2.5.1 des Berichts der Projektgruppe &#8222;KI und Medien&#8220; [Handlungsempfehlungen].
41 Siehe auch Kapitel 3.5, Nummer 1 des Mantelberichts [Handlungsempfehlungen].
42 Siehe auch Kapitel I. 3.7 des Berichts der Projektgruppe &#8222;KI und Staat&#8220; [KI-gest&#252;tzte Entscheidungen regelm&#228;&#223;ig auf
Diskriminierungsfreiheit &#252;berpr&#252;fen].
43 Siehe auch Kapitel 7.2 des Mantelberichts [Auswirkungen von KI-Systemen auf die Gesellschaft].
und ex ante Einteilung von KI-Systemen in Risikoklassen, wie von der Datenethikkommission empfohlen, war
in der Enquete-Kommission umstritten.
Vertrauen durch eine vertrauensw&#252;rdige KI aufbauen
Vertrauen ist ein wichtiger Erfolgsfaktor f&#252;r KI. Daher muss beim Einsatz von KI-Systemen ausreichende
Nachvollziehbarkeit und Transparenz f&#252;r Verbraucherinnen und Verbraucher sowie f&#252;r Besch&#228;ftigte geschaffen
werden. Bedenken aus der Bev&#246;lkerung sollten aktiv angesprochen und durch geeignete Aufkl&#228;rung sowie durch
Schutzmechanismen und Verpflichtungen ausger&#228;umt werden. Dabei muss darauf geachtet werden, dass eine
angemessene Balance zwischen Verbraucher- und Unternehmensinteressen gefunden wird &#8211; Ma&#223;gaben m&#252;ssen 
f&#252;r beide Seiten transparent und handhabbar sein, um nicht innovationshemmend zu wirken.44 
Wahrung der Verh&#228;ltnism&#228;&#223;igkeit
Bei der Bewertung des Einsatzes von KI-Systemen im Bereich Innere Sicherheit sollte neben der Relation von
Kosten und Nutzen auch die Wahrung der Verh&#228;ltnism&#228;&#223;igkeit von Ma&#223;nahmen gepr&#252;ft werden. Hier m&#252;ssen
die Grundrechte der Betroffenen sorgf&#228;ltig abgewogen werden.45 
Sektorspezifische Regulierung
Bestehende sektorspezifische Regelungsregime sollten gepr&#252;ft und um KI-spezifische Vorgaben erweitert
werden, sofern durch den Einsatz von KI im jeweiligen Einsatzkontext zus&#228;tzliche Risiken entstehen. [...] Die
Aufsicht und Durchsetzung von Vorgaben sollte prim&#228;r jeweils den sektoralen Aufsichtsbeh&#246;rden zugewiesen
werden, die bereits sektorspezifische Sachkompetenz ausgebildet haben.46 
Haftung
Das bestehende Haftungssystem ist nach Auffassung der Enquete-Kommission grunds&#228;tzlich geeignet, auch
durch KI-Systeme verursachte Sch&#228;den auszugleichen. Eine dringende Notwendigkeit, neue Haftungstatbest&#228;nde
speziell f&#252;r KI-Systeme zu schaffen, wird derzeit nicht gesehen. Bei der Normierung von KI-Systemen sollte
jedoch in besonderem Ma&#223;e darauf geachtet werden, dass Vorg&#228;nge in KI-Systemen nachvollziehbar und damit
dem Beweis zug&#228;nglich sind.47 
Der Staat als Dienstleister
KI-Systeme sollten sowohl zur Entlastung von B&#252;rgerinnen und B&#252;rgern in der Informationsbeschaffung und
Antragstellung f&#252;hren, als auch zur Entlastung von Verwaltungsmitarbeiterinnen und -mitarbeitern bei der
Bearbeitung. KI-Systeme sollten dabei unterst&#252;tzen, den Serviceumfang um ein jederzeit zug&#228;ngliches,
mehrsprachiges sowie barriere- und kostenfreies Leistungsangebot zu erweitern. KI-Systeme k&#246;nnen Barrierefreiheit erh&#246;hen
und Anspruch auf Teilhabe erf&#252;llen. B&#252;rokratische H&#252;rden sollten gezielt mittels KI-Systemen gesenkt werden,
wodurch der Informationszugang und das Antragswesen grundlegend vereinfacht werden k&#246;nnen.48 
Internationale &#196;chtung t&#246;dlicher autonomer Waffensysteme
Die Bundesregierung muss sich auch in Zukunft auf internationaler Ebene r&#252;stungskontrollpolitisch f&#252;r eine
weltweite &#196;chtung von t&#246;dlichen autonomen Waffensystem einsetzen. Dabei muss ein Weg verfolgt werden, mit
dem eine m&#246;glichst gro&#223;e Gruppe von Staaten eingebunden werden kann.49 
44 Siehe auch Kapitel 1 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220; [Kurzfassung des Projektgruppenberichts].
45 Siehe auch Kapitel 3.1 des Berichts der Projektgruppe &#8222;KI und Staat&#8220; [Innere Sicherheit].
46 Siehe auch Kapitel 4.5 des Mantelberichts [Handlungsempfehlungen].
47 Siehe auch Kapitel 5.5 des Mantelberichts [Haftungsrecht].
48 Siehe auch Kapitel 1.1 des Berichts der Projektgruppe &#8222;KI und Staat&#8220; [Einf&#252;hrung].
49 Siehe auch Kapitel 3.2.3 des Berichts der Projektgruppe &#8222;KI und Staat&#8220; [Handlungsempfehlungen und Operationalisierung].
B. Allgemeiner Teil: Auftrag und Arbeitsweise
KI ist einer der wesentlichen technologischen Treiber der Digitalisierung und ein zunehmend wichtiger
Wirtschaftsfaktor und wird dabei die Gesellschaft nachhaltig ver&#228;ndern. KI-Systeme sind immer leistungsf&#228;higer: Sie
k&#246;nnen Prozesse selbstst&#228;ndig planen, Prognosen treffen und mit Menschen interagieren. KI erlaubt es, die
Vielzahl der heute gesammelten Daten auf neue Weise auszuwerten. Unternehmen und Staaten wenden erhebliche
Ressourcen auf, um sich diese Analysem&#246;glichkeiten zunutze zu machen. Damit verbunden sind Fragestellungen,
die auf Grundlage unseres Wertesystems sowie der Grund- und Menschenrechte beantwortet werden m&#252;ssen.50 
Vor diesem Hintergrund haben sich CDU, CSU und SPD im Koalitionsvertrag f&#252;r die 19. Legislaturperiode an
verschiedenen Stellen mit KI als Zukunftstechnologie befasst51 und die Einsetzung einer Enquete-Kommission
im Deutschen Bundestag &#8211; sp&#228;ter unterst&#252;tzt von anderen Fraktionen &#8211; vereinbart.
1 Einsetzung und Konstituierung der Enquete-Kommission
Die Bedeutung von KI wurde in der Debatte zur Beratung des Einsetzungsantrages der Fraktionen der CDU/CSU,
der SPD, der FDP und DIE LINKE.52 in der 42. Sitzung des Deutschen Bundestages am 28. Juni 2018 von allen 
Rednerinnen und Rednern unterstrichen.53 Der Einsetzungsantrag auf Bundestagsdrucksache 19/2978 wurde
daher einstimmig angenommen. Ein &#196;nderungsantrag der Fraktion B&#220;NDNIS 90/DIE GR&#220;NEN auf
Bundestagsdrucksache 19/3016 wurde dabei gegen die Stimmen der Fraktionen der AfD, DIE LINKE. und B&#220;NDNIS
90/DIE GR&#220;NEN sowie eines Abgeordneten der Fraktion der FDP abgelehnt.54 
Die konstituierende Sitzung der Enquete-Kommission &#8222;K&#252;nstliche Intelligenz &#8211; Gesellschaftliche
Verantwortung und wirtschaftliche, soziale und &#246;kologische Potenziale&#8220; fand daraufhin am 27. September 2018 statt. Den
Vorsitz der Enquete-Kommission &#252;bernahm die Abgeordnete Daniela Kolbe (SPD), als Stellvertreter fungierte
der Abgeordnete Stefan Sauer (CDU/CSU). Als Obleute wurden seitens der Fraktionen folgende Mitglieder
benannt:
&#8226; f&#252;r die Fraktion der CDU/CSU Ronja Kemmer, MdB
&#8226; f&#252;r die Fraktion der SPD Ren&#233; R&#246;spel, MdB
&#8226; f&#252;r die Fraktion der AfD Uwe Kamann, MdB (inzwischen fraktionslos), ab Januar 2019 Joana Cotar, MdB,
bzw. ab November 2019 Peter Felser, MdB
&#8226; f&#252;r die Fraktion der FDP Mario Brandenburg, MdB
&#8226; f&#252;r die Fraktion DIE LINKE. Dr. Petra Sitte, MdB
&#8226; f&#252;r die Fraktion B&#220;NDNIS 90/DIE GR&#220;NEN Dr. Anna Christmann, MdB (von Dezember 2019 bis April
2020 vertreten durch Dieter Janecek, MdB)
Bundestagspr&#228;sident Dr. Wolfgang Sch&#228;uble, der die Sitzung er&#246;ffnete, betonte die Bedeutung des Themas: Die
Dynamik der Digitalisierung habe mit der Forschung zur K&#252;nstlichen Intelligenz eine neue Dimension erreicht.
Auch wenn KI vielen als &#8222;neue Zauberformel des technischen Fortschritts&#8220; gelte, gebe es aber auch Warnungen
mit Blick auf Gefahren wie die &#220;berwachung durch KI-Systeme oder neue Formen der Kriegsf&#252;hrung. Darum
sei es wichtig zu verstehen, was KI eigentlich bedeute, was sie leisten k&#246;nne und welche Chancen und
Herausforderungen f&#252;r Staat, Gesellschaft und Recht entst&#252;nden. Dazu stelle sich die Frage, wie diese Entwicklung so
gestaltet werden k&#246;nne, dass KI den Menschen diene. Das sei &#8222;kein kleiner Auftrag&#8220;, sagte der
Bundestagspr&#228;sident und dankte den Mitgliedern der Kommission f&#252;r ihre Bereitschaft, in dem Gremium mitzuarbeiten.55 
2 Zusammensetzung der Enquete-Kommission
Der Enquete-Kommission geh&#246;rten 19 Mitglieder des Deutschen Bundestages und 19 Sachverst&#228;ndige an. F&#252;r
die parlamentarischen Mitglieder wurde eine gleich gro&#223;e Anzahl stellvertretender Kommissionsmitglieder
benannt. Die 19 sachverst&#228;ndigen Mitglieder geh&#246;rten nicht dem Deutschen Bundestag oder der Bundesregierung
an. Sie wurden &#8211; wie auch die parlamentarischen Mitglieder &#8211; von den im Deutschen Bundestag vertretenden
50 Ausf&#252;hrlich: Bundestagsdrucksache 19/2978, S. 1.
51 Schwerpunktm&#228;&#223;ig im Kapitel &#8222;Offensive f&#252;r Bildung, Forschung und Digitalisierung&#8220;, siehe Koalitionsvertrag zwischen CDU, CSU
und SPD, 19. Legislaturperiode, u. a. Zeilennummer 1488 ff.; 1770 ff.; 1917 ff.
52 Vgl. Bundestagsdrucksache 19/2978.
53 Vgl. Plenarprotokoll 19/42, S. 4149 ff.
54 Vgl. Plenarprotokoll 42/19, S. 4163.
55 Vgl. &#8222;heute im Bundestag&#8220;, hib-Meldung 712/18 vom 27. September 2018.
Fraktionen benannt und vom Pr&#228;sidenten des Deutschen Bundestages in die Kommission berufen.56 Die
Benennungsrechte f&#252;r die sachverst&#228;ndigen Mitglieder entsprachen dem St&#228;rkeverh&#228;ltnis der Fraktionen in der
Enquete-Kommission. Die Fraktion der CDU/CSU hat danach sieben, die Fraktion der SPD vier und die Fraktionen
der AfD, der FDP, DIE LINKE. und B&#220;NDNIS 90/DIE GR&#220;NEN jeweils zwei Sachverst&#228;ndige benannt. Der
&#220;berblick &#252;ber die Zusammensetzung der Enquete-Kommission ist im Anhang 2.2.1 [Zusammensetzung der
Enquete-Kommission] dargestellt.
3 Organisatorische und verwaltungsm&#228;&#223;ige Begleitung der Kommissionsarbeit
Der Enquete-Kommission wurde von der Verwaltung des Deutschen Bundestages ein Sekretariat zur Seite
gestellt. Das Sekretariat war beauftragt, die organisatorischen und administrativen Kommissionsgesch&#228;fte zu
erledigen sowie der Vorsitzenden und den Kommissionsmitgliedern zuzuarbeiten. Besonderes Gewicht lag dabei auf
der Planung, Organisation, Begleitung und administrativen Unterst&#252;tzung der Sitzungen der Enquete-
Kommission und der sechs Projektgruppen. Bei der Erstellung der Berichtsbeitr&#228;ge durch die Mitglieder der Enquete-
Kommission unterst&#252;tzte das Sekretariat die Koordination der Produktion, die Debatte, die Abstimmung und die
redaktionelle Korrektur der Berichtselemente. Dar&#252;ber hinaus unterst&#252;tzten und begleiteten Mitarbeiterinnen und
Mitarbeiter der Fraktionen, der Abgeordneten und der sachverst&#228;ndigen Mitglieder die T&#228;tigkeit der Enquete-
Kommission. Eine &#220;bersicht &#252;ber die beteiligten Personen geben der Anhang 2.2.4 [Fraktionsreferentinnen und
-referenten], der Anhang 2.2.5 [Mitarbeiterinnen und Mitarbeiter der Mitglieder] und der Anhang 2.2.6 [
&#220;bersicht &#252;ber die Mitarbeiterinnen und Mitarbeiter des Sekretariat].
4 Arbeitsauftrag der Enquete-Kommission
Die Enquete-Kommission ist durch den Einsetzungsbeschluss beauftragt worden, in verschiedenen
Themenbereichen Chancen und Potenziale der KI sowie die damit verbundenen Herausforderungen zu untersuchen und
Antworten auf die Vielzahl an technischen, rechtlichen, politischen und ethischen Fragen im Kontext von KI zu 
erarbeiten &#8211; unabh&#228;ngig von und zus&#228;tzlich zu aktuellen Gesetzgebungsverfahren.57 Zu diesen Themenbereichen
z&#228;hlten insbesondere:
&#8226; der wissenschaftliche Rahmen &#8211; u. a. die Befassung mit Grundlagen und Arten von KI sowie den
Akteurinnen und Akteuren auf nationaler und internationaler Ebene
&#8226; Staat, Gesellschaft und Demokratie &#8211; u. a. die Befassung mit Auswirkungen von KI auf demokratische
Prozesse sowie auf einzelne Politik- und Lebensbereiche wie die &#246;ffentliche Verwaltung, Mobilit&#228;t, Gesundheit
oder Klima- und Verbraucherschutz
&#8226; Werte und ethische Aspekte &#8211; u. a. die Herausarbeitung von ethischen Prinzipien f&#252;r die Entwicklung,
Programmierung und den Einsatz von KI sowie Kriterien und Grenzen von KI-basierten Entscheidungen zur
Sicherstellung rechtm&#228;&#223;iger Ergebnisse
&#8226; Wirtschaft &#8211; u. a. die Betrachtung von Ver&#228;nderungen der Arbeitswelt, von Wertsch&#246;pfungsketten sowie
von Auswirkungen auf die Soziale Marktwirtschaft, auf die Tarifbindung und die Mitbestimmung sowie auf
die Konzepte zum Ausbau der Dateninfrastruktur, zum Datenschutz und zur IT-Sicherheit
&#8226; Bildung und Forschung &#8211; u. a. M&#246;glichkeiten zur St&#228;rkung und Weiterentwicklung der Grundlagen- und
Anwendungsforschung im Zusammenhang mit KI sowie zur Schaffung eines innovationsfreundlichen
Umfeldes
Kernaufgabe der Enquete-Kommission war es, konkrete Vorschl&#228;ge f&#252;r die politischen
Entscheidungstr&#228;gerinnen und -tr&#228;ger zu erarbeiten und damit Impulse f&#252;r die Erforschung, Entwicklung und Anwendung von KI in 
Deutschland zu setzen sowie Handlungsbedarfe national, auf europ&#228;ischer Ebene und international zu
benennen.58 
56 Vgl. &#167; 56 der Gesch&#228;ftsordnung des Deutschen Bundestages (GO-BT) in der Fassung der Bekanntmachung vom 25. M&#228;rz 2020 
(BGBl. I S. 764).
57 Details vgl. Bundestagsdrucksache 19/2978, S. 2 f.
58 Vgl. Bundestagsdrucksache 19/2978, S. 4.
5 Arbeitsweise der Enquete-Kommission
Zentral war der umfassende fachliche und politische Austausch zwischen den Abgeordneten und den
sachverst&#228;ndigen Mitgliedern der Enquete-Kommission. Zu spezifischen Aspekten wurde zus&#228;tzlicher Sachverstand
eingeholt.59 Ein &#220;berblick &#252;ber die bis zur Verabschiedung des Berichts am 26. Oktober 2020 durchgef&#252;hrten
Sitzungen und Anh&#246;rungen sowie die angeh&#246;rten Expertinnen und Experten ist im Anhang 2.4.11 [Anh&#246;rungsg&#228;ste
der Enquete-Kommission] beigef&#252;gt. 
Aufgrund der Auswirkungen der Covid-19-Pandemie fanden die Beratungen der Enquete-Kommission und der
Projektgruppen im Einvernehmen aller Fraktionen ab M&#228;rz 2020 nur noch virtuell per Videokonferenz bzw. als
hybride Sitzungen (physisch und digital)60, die Textarbeit an Berichtsteilen und die Abstimmung von
&#196;nderungsantr&#228;gen weitestgehend im schriftlichen Verfahren statt.
Struktur der Arbeit
Entsprechend des Arbeitsauftrags strukturierte die Enquete-Kommission ihre Sitzungen und arbeitete sich
systematisch durch verschiedene Themengebiete, die sich im Bericht widerspiegeln: Begriffskl&#228;rung KI, Einbettung
in die nationale und internationale Debatte, gesellschaftliche Wahrnehmung und Akzeptanz, Forschung und
Entwicklung, Potenziale f&#252;r Wirtschaft und Gesellschaft, rechtliche Perspektive, Daten und Datenschutz,
Nachhaltigkeit, Bias, Diskriminierung und Risiko sowie Fachkr&#228;ftegewinnung.61 Daneben besch&#228;ftigte sich die Enquete-
Kommission auch mit ethischen Aspekten; diese zogen sich &#8211; verk&#246;rpert durch zentrale Begriffe wie Autonomie
und Menschsein, Vertrauen und Gemeinwohl, Verantwortung und Transparenz, Gerechtigkeit und
Diskriminierungsfreiheit &#8211; als roter Faden und Klammer durch die Beratungen der Themengebiete. Um den aktuellen
Entwicklungen auch mit Blick auf den Arbeitsauftrag angemessen Rechnung zu tragen, entschied die Enquete-
Kommission au&#223;erdem, sich mit den spezifischen M&#246;glichkeiten und Chancen des Einsatzes von KI bei Pandemien
zu besch&#228;ftigen; f&#252;r diesen erg&#228;nzenden Teil des Berichts wurden schriftliche Stellungnahmen externer
Sachverst&#228;ndiger und verschiedener Bundesministerien eingeholt.62 
Neben den ordentlichen Sitzungen fanden drei Klausurtagungen statt. Die erste &#8211; f&#252;r einen Austausch zu
inhaltlichen und organisatorischen Fragen &#8211; wurde am 15. Oktober 2018 durchgef&#252;hrt. Zentral war dabei die Frage,
wie der Begriff KI inhaltlich zu f&#252;llen und zu konkretisieren ist. Die zweite Klausurtagung am 14. Januar 2019 
widmete sich vor allem der Strukturierung der Arbeit in den Projektgruppen und ethischen Grundsatzfragen im
Zusammenhang mit KI. Bei der dritten Klausurtagung am 29. und 30. November 2019 besch&#228;ftigte sich die
Enquete-Kommission insbesondere mit der Erarbeitung projektgruppen&#252;bergreifender Thesen und
Handlungsempfehlungen zu den Bereichen Recht, Daten und Gesellschaft.
Textarbeit in Projektgruppen und weiteren Arbeitsgruppen
Aufgrund der thematischen Breite des Arbeitsauftrags entschieden die Mitglieder der Enquete-Kommission, sich
in parallel arbeitenden Projektgruppen mit den Auswirkungen von KI auf konkrete Lebensfelder zu besch&#228;ftigten
und daraus separate Berichtsteile und spezifische Handlungsempfehlungen zu entwickeln.63 Am
Einsetzungsantrag auf Bundestagsdrucksache 19/2978 orientiert, wurden sechs Projektgruppen mit folgenden
Themenbereichen eingesetzt:
&#8226; Projektgruppe 1: KI und Wirtschaft (Industrie/Produktion, Finanzen, Dienstleistungen, Innovationen)
Vorsitz: Ronja Kemmer, MdB (CDU/CSU)
&#8226; Projektgruppe 2: KI und Staat (Verwaltung, Sicherheit, Infrastruktur)
Vorsitz: Anke Domscheit-Berg, MdB (DIE LINKE.)
&#8226; Projektgruppe 3: KI und Gesundheit (Pflege, Sport)
Vorsitz: Dr. Anna Christmann, MdB (B&#220;NDNIS 90/DIE GR&#220;NEN)
59 Als Anh&#246;rungen in den Sitzungen der Enquete-Kommission und Projektgruppen oder in Form schriftlicher Stellungnahmen. Details
zu den Anh&#246;rpersonen ergeben sich aus den &#246;ffentlich zug&#228;nglichen Tagesordnungen der Sitzungen, die auf der Seite der Enquete-
Kommission im Internet auf https://www.bundestag.de ver&#246;ffentlicht sind.
60 Zur Reichweite und zur rechtlichen Zul&#228;ssigkeit &#167; 126a Absatz 2 GO-BT sowie Beschlussempfehlung und Bericht des Ausschusses
f&#252;r Wahlpr&#252;fung, Immunit&#228;t und Gesch&#228;ftsordnung auf Bundestagsdrucksache 19/18126.
61 Details ergeben sich aus den &#246;ffentlich zug&#228;nglichen Tagesordnungen der Sitzungen, die auf der Seite der Enquete-Kommission im
Internet auf https://www.bundestag.de ver&#246;ffentlicht sind.
62 Details finden sich im Kapitel 10 des Mantelberichts [KI und SARS-CoV-2].
63 Vgl. Kommissionsdrucksachen 19(27)10 und 19(27)11 vom 11. Januar 2019.
&#8226; Projektgruppe 4: KI und Arbeit, Bildung, Forschung
Vorsitz: Ren&#233; R&#246;spel, MdB (SPD)
&#8226; Projektgruppe 5: KI und Mobilit&#228;t (Energie, Logistik, Umwelt)
Vorsitz: Daniela Kluckert, MdB (FDP)
&#8226; Projektgruppe 6: KI und Medien (Social Media, Meinungsbildung, Demokratie)
Vorsitz: Joana Cotar, MdB (AfD)
Die Projektgruppen setzten sich aus jeweils 13 ordentlichen Mitgliedern aus dem Kreis der Abgeordneten und
der sachverst&#228;ndigen Mitglieder zusammen. Aus diesem Kreis benannten die Fraktionen zus&#228;tzlich weitere
stellvertretende Mitglieder. Die Entsendung der ordentlichen Mitglieder erfolgte entsprechend dem
Berechnungsschl&#252;ssel nach dem Verfahren Sainte-Lagu&#235;/Schepers auf Grundlage der Sitzverteilung im Parlament. Danach
benannte die Fraktion der CDU/CSU jeweils f&#252;nf ordentliche Mitglieder, die Fraktion der SPD drei ordentliche
Mitglieder, die Fraktion der AfD zwei ordentliche Mitglieder und die Fraktionen FDP, DIE LINKE. und B&#220;ND-
NIS 90/DIE GR&#220;NEN jeweils ein ordentliches Mitglied f&#252;r jede Projektgruppe. Jede Fraktion erhielt den Vorsitz
einer Projektgruppe. Alle Mitglieder der Projektgruppen hatten Rederecht, die ordentlichen Mitglieder der
Projektgruppen auch Stimmrecht, alle teilnehmenden stellvertretenden Mitglieder der Projektgruppen hatten im
Vertretungsfall Stimmrecht. Auf Basis des Verfahrens Sainte-Lague/Schepers ergab sich in den Projektgruppen eine
Stimmverteilung von f&#252;nf Stimmen f&#252;r die Fraktion der CDU/CSU, drei Stimmen f&#252;r die Fraktion der SPD, zwei
Stimmen f&#252;r die Fraktion der AfD und je eine Stimme f&#252;r die Fraktionen FDP, DIE LINKE. und B&#220;NDNIS
90/DIE GR&#220;NEN.
Die Projektgruppen traten regelm&#228;&#223;ig an den Enquete-Sitzungstagen sowie an zus&#228;tzlichen Terminen zusammen. 
Neben den Beratungssitzungen fanden auch in den Projektgruppen Expertenanh&#246;rungen zu den jeweiligen
Themenbereichen statt, zudem wurden schriftliche Stellungnahmen weiterer Expertinnen und Experten eingeholt.64 
Die Arbeit in den Projektgruppen fand in zwei Phasen von jeweils rund zehn Monaten statt: Die ersten drei 
Projektgruppen arbeiteten von Februar bis Oktober 2019; die Projektgruppen 4 bis 6 von Oktober 2019 bis Juli
2020. 
Dar&#252;ber hinaus trafen sich ab Dezember 2019 interessierte Mitglieder regelm&#228;&#223;ig in kleineren Arbeitsgruppen,
um die im Rahmen der Projektgruppenarbeit identifizierten &#252;bergreifenden Themen wie etwa Recht, Daten oder
Gesellschaft zu beraten und entsprechende Berichtskapitel f&#252;r den sogenannten Mantelbericht zu verfassen.
Parallel dazu haben sachverst&#228;ndige Mitglieder in einer Task Force &#8222;Forschung&#8220; den Stand der Wissenschaft und
Technik zusammengetragen, um einen &#220;berblick &#252;ber die technischen M&#246;glichkeiten und Herausforderungen
sowie Optimierungsvorschl&#228;ge im Bereich der Forschung zu geben; die Ergebnisse sind in den Mantelberichtsteil 
KI und Forschung eingeflossen.65 In Abgrenzung dazu befasste sich die Projektgruppe &#8222;KI und Arbeit, Bildung,
Forschung&#8220; neben ihrem Schwerpunktthema Arbeit mit KI als Instrument in Bildung und Forschung.
64 &#220;bersichten &#252;ber die Mitglieder der Projektgruppen sowie &#252;ber die Expertengespr&#228;che und schriftlichen Stellungnahmen sind in den 
jeweiligen Projektgruppenberichten und im Anhang 2.2.3 [Zusammensetzung der Projektgruppen] und im Anhang 2.4.12 [
Anh&#246;rungsg&#228;ste der Projektgruppen] aufgef&#252;hrt.
65 Vgl. Kapitel 9 des Mantelberichts [KI und Forschung].
Einbeziehung der &#214;ffentlichkeit und Pressearbeit66 
Die Sitzungen der Enquete-Kommission waren &#8211; wie auch bei den st&#228;ndigen Aussch&#252;ssen &#252;blich67 &#8211;
grunds&#228;tzlich nicht&#246;ffentlich, um einen gesch&#252;tzten Raum f&#252;r den Gedankenaustausch zu erm&#246;glichen. Gleichwohl war es
den Mitgliedern der Enquete-Kommission wichtig, kontinuierlich Wissen und Erkenntnisse zum Thema KI in 
die &#214;ffentlichkeit zu tragen. Daher wurden alle einleitenden Vortr&#228;ge von Expertinnen und Experten, die zu
Anh&#246;rungen geladen waren, und auch die Diskussion &#252;ber die KI-Strategie der Bundesregierung in &#246;ffentlicher
Sitzung durchgef&#252;hrt.68 Die &#246;ffentlichen Teile der Sitzungen wurden zum Teil live, zum Teil zeitversetzt im 
Parlamentsfernsehen &#252;bertragen und sind auf der Seite der Enquete-Kommission im Internet dauerhaft
abrufbar.69 
Um den Dialog mit B&#252;rgerinnen und B&#252;rgern zu intensivieren, beauftragte die Enquete-Kommission ein
wissenschaftliches Gutachten, mit dessen Hilfe die Haltung der &#214;ffentlichkeit zu Thesen und Handlungsempfehlungen
eingeholt wurde.70 Als Grundlage f&#252;r dieses Gutachten hat die Enquete-Kommission vom 10. M&#228;rz 2020 bis
19. April 2020 einen Online-Dialog durchgef&#252;hrt, an dem sich B&#252;rgerinnen und B&#252;rger und Fachleute aus
Wissenschaft, Wirtschaft und Zivilgesellschaft gleicherma&#223;en beteiligen und ihre Vorstellungen in die Diskussion
der Enquete-Kommission einbringen konnten.71 
66 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion B&#220;NDNIS 90/DIE GR&#220;NEN vor [Sondervotum zu Kapitel 5.3 des
Berichtsteils &#8222;Allgemeiner Teil: Auftrag und Arbeitsweise&#8220; (&#8222;Einbeziehung der &#214;ffentlichkeit und Pressearbeit &#8220;) der Abge-ordneten
Dr. Anna Christmann, Dieter Janecek, Dr. Petra Sitte und Jessica Tatti sowie der sachverst&#228;ndigen Mitglieder Prof. Dr. Hannah Bast,
Dr. Florian Butollo und Dr. Stefan Heumann].
67 Vgl. &#167; 69 Absatz 1 Satz 1 GO-BT.
68 Eine Ausnahme bildete aufgrund der eingeschr&#228;nkten Bildqualit&#228;t lediglich die letzte Anh&#246;rungssitzung der Enquete-Kommission
am 4. Mai 2020, die als Videokonferenz durchgef&#252;hrt wurde.
69 Weitere Informationen dazu unter: https://www.bundestag.de/ausschuesse/weitere_gremien/enquete_ki (zuletzt abgerufen am 9.
Oktober 2020).
70 Vgl. Beschluss vom 3. Juni 2019.
71 Weitere Informationen dazu unter: www.enquetebeteiligung.de (zuletzt abgerufen am 9. Oktober 2020).
Anmerkung: Die Frist zur Beteiligung wurde sp&#228;ter aufgrund der Auswirkungen der Corona-Pandemie bis zum 19. April 2020 
verl&#228;ngert.
Geplant war zudem, f&#252;r das Gutachten nicht digital-affine Fokusgruppen im Fr&#252;hjahr 2020 pers&#246;nlich zu
befragen, darauf hat die Enquete-Kommission aufgrund des m&#246;glichen Ansteckungsrisikos durch Corona verzichtet.
Bei kleineren Gruppen stand die Repr&#228;sentativit&#228;t der Aussagen infrage. Das Gutachten hat &#8211; nach
entsprechender Ausschreibung &#8211; die Bietergemeinschaft aus Liquid Democracy und Nexus, Institut f&#252;r
Kooperationsmanagement und interdisziplin&#228;re Forschung, erstellt. Das Gutachten ist dem Bericht als Anlage beigef&#252;gt.
Die Mitglieder der Enquete-Kommission pflegten zu vielen anderen Gelegenheiten einen intensiven Austausch
mit B&#252;rgerinnen und B&#252;rgern sowie Stakeholdern. So waren bei zahlreichen Veranstaltungen Mitglieder der
Enquete-Kommission auf Podien oder in Workshops pr&#228;sent; hierzu z&#228;hlen etwa die Digital-Gipfel in N&#252;rnberg im
Jahr 2018 und in Dortmund im Jahr 2019, die &#246;ffentliche Sitzung der Datenethikkommission der
Bundesregierung am 7. Februar 2019, der Tag der Ein- und Ausblicke im Deutschen Bundestag am 8. September 201972 und
Kongresse, die von einzelnen Fraktionen oder Stiftungen zum Thema KI und zur Arbeit der Enquete-
Kommission durchgef&#252;hrt wurden.73 Dar&#252;ber hinaus waren die Mitglieder der Enquete-Kommission regelm&#228;&#223;ig gefragte
Interviewpartner zum Themenbereich KI, so dass viele &#246;ffentlich zug&#228;ngliche Beitr&#228;ge entstanden sind, die von
einer intensiven Enquete-Arbeit zeugen und die Ergebnisse in die gesellschaftliche Debatte trugen.
Zudem gab es zur Arbeit und zu den Ergebnissen der Enquete Kommission einen regelm&#228;&#223;igen politischen
Austausch im Plenum: So fand neben der Einsetzungsdebatte am 20. Dezember 2019 eine Vereinbarte Debatte zur
Zwischenbilanz der Arbeit der Enquete-Kommission statt.74 Dieser Debatte war die Ver&#246;ffentlichung von
Zusammenfassungen der Zwischenergebnisse der Projektgruppen 1 bis 3 vorausgegangen.75 
Mit einer abschlie&#223;enden Ergebnispr&#228;sentation am 28. September 2020 hat die Enquete-Kommission schlie&#223;lich
in hybrider Form &#252;ber ihre Arbeitsergebnisse sowie &#252;ber die Ergebnisse des Online-Dialogs umfassend
informiert. Eine Dokumentation der Veranstaltung, die live im Parlamentsfernsehen und auf www.bundestag.de
&#252;bertragen wurde, ist dem Bericht ebenfalls als Anlage beigef&#252;gt.
Die Mitglieder der Enquete-Kommission bedauern, dass es zum Ende ihrer Arbeit aufgrund der Corona-
Pandemie keine M&#246;glichkeiten gab, weitere pers&#246;nliche Austauschr&#228;ume zu schaffen. So musste auch eine
internationale Delegationsreise der Enquete-Kommission, die im Fr&#252;hjahr 2020 stattfinden sollte, wegen der
internationalen Reisewarnung infolge der Corona-Pandemie kurzfristig abgesagt werden.
72 B&#252;rgergespr&#228;ch zum Thema &#8222;Pflegeroboter, autonomes Fahren oder vernetzte K&#252;chenger&#228;te &#8211; wie ver&#228;ndert K&#252;nstliche Intelligenz 
unser Leben?&#8220;.
73 Weitere Informationen dazu unter: https://www.cducsu.de/veranstaltungen/k-nstliche-intelligenz-perspektiven-f-r-gesellschaft-und-
staat/programm, https://www.spdfraktion.de/termine/kuenstlicheintelligenz und https://www.kas.de/de/veranstaltungsberichte/de-
tail/-/content/politikempfehlungen-fuer-ki-2 (zuletzt abgerufen am 9. Oktober 2020).
74 Vgl. Plenarprotokoll 19/138, S. 17233 ff.
75 Die Dokumente sind abrufbar unter https://www.bundestag.de/ausschuesse/weitere_gremien/enquete_ki/sonstige_veroeffentlichun-
gen.
        
 
 
  
  
  
     
 
    
      
    
  
 
   
     
    
       
 
    
 
       
          
       
      
  
 
           
          
   
                                               
       
  
        
     
    
  
 
     
        
    
  
      
   
        
           
    
  
  
    
        
      
   
  
6
Kontext der Arbeit der Enquete-Kommission
Die Enquete-Kommission hat in einem sehr dynamischen Umfeld gearbeitet. W&#228;hrend ihrer Beratungen gab es
auf nationaler und europ&#228;ischer Ebene zahlreiche (politische) Initiativen zum Themenkomplex KI. Mit den
Ergebnissen dieser Institutionen und Gremien hat sich die Enquete-Kommission intensiv auseinandergesetzt und
sich u. a. in Anh&#246;rungen regelm&#228;&#223;ig mit Akteurinnen und Akteuren ausgetauscht. Exemplarisch76 f&#252;r staatliche
Initiativen sind zu nennen
&#8226; Die nationale Strategie f&#252;r K&#252;nstliche Intelligenz der Bundesregierung (KI-Strategie)77, ver&#246;ffentlicht am 
15. November 2018. Hierzu hat die Enquete-Kommission in ihrer 5. Sitzung am 10. Dezember 2018 mit
Vertretern der Bundesregierung diskutiert78. Im Rahmen der Evaluierung der KI-Strategie gab es einen
Austausch mit der Bundeministerin f&#252;r Bildung und Forschung, dem Bundesminister f&#252;r Arbeit und Soziales
und dem Beauftragten des BMWi f&#252;r die Digitale Wirtschaft und Start-ups in Vertretung des
Bundesministers f&#252;r Wirtschaft und Energie am 8. September 2020.
&#8226; Die Einsetzung einer Datenethikkommission der Bundesregierung, die ihre Arbeit am 5. September 2018 
aufgenommen und am 23. Oktober 2019 ihr Gutachten vorgelegt hat.79 Die Enquete-Kommission hat sich
hierzu u. a. in der 14. Sitzung am 4. November 2019 mit den Co-Sprecherinnen80 ausgetauscht und die
Ergebnisse in ihren Bericht einbezogen.
&#8226; Die Einsetzung der Kommission Wettbewerbsrecht 4.0 der Bundesregierung zum 20. September 2018, die
ihren Abschlussbericht am 9. September 2019 &#252;bergeben hat.81 Der Kommission geh&#246;rten auch zwei
Mitglieder der Enquete-Kommission an82, die dar&#252;ber in der 14. Sitzung am 4. November 2019 berichtet haben.
&#8226; Die von der Europ&#228;ischen Kommission eingesetzte High-Level Expert Group on AI. Diese hat am 8.
April 2019 zun&#228;chst die von ihr erarbeiteten Ethik-Richtlinien und am 26. Juni 2019 ihre Empfehlungen f&#252;r
eine vertrauensw&#252;rdige KI vorgestellt.83 Auf dieser Grundlage hat die Kommission am 19. Februar 2020 ihr
Wei&#223;buch zu K&#252;nstlicher Intelligenz vorgelegt.84 Mit diesen europ&#228;ischen Initiativen hat sich die Enquete-
Kommission in mehreren Sitzungen besch&#228;ftigt.85 
&#8226; Die Ver&#246;ffentlichung von Grunds&#228;tzen f&#252;r KI durch die Organisation f&#252;r wirtschaftliche Zusammenarbeit
und Entwicklung (OECD) im Mai 201986. Damit hat sich die Enquete-Kommission in der 20. Sitzung am
4. Mai 2020 befasst.87 
76 Im Umfeld von KI gibt es diverse weitere Initiativen &#8211; etwa die Digitalstrategie der Bundesregierung &#8211; und Gremien &#8211; etwa den
Digitalrat und die Denkfabrik Digitale Arbeitsgesellschaft; hierzu tauschten sich Mitglieder der Enquete-Kommission auf Einladung
des Bundesministeriums f&#252;r Arbeit und Soziales (BMAS) am 4. November 2019 aus.
77 Bundesregierung (2018): Strategie K&#252;nstliche Intelligenz der Bundesregierung.
78 Gespr&#228;ch mit Hubertus Heil, Bundesminister f&#252;r Arbeit und Soziales, Oliver Wittke, Parlamentarischer Staatssekret&#228;r beim
Bundesminister f&#252;r Wirtschaft und Energie, und Dr. Michael Meister, Parlamentarischer Staatssekret&#228;r bei der Bundesministerin f&#252;r Bildung 
und Forschung.
79 Datenethikkommission der Bundesregierung (2019): Gutachten der Datenethikkommission der Bundesregierung.
80 Prof. Dr. med. Christiane Woopen und Prof. Dr. Christiane Wendehorst.
81 Vgl. Schallbruch et al. (2019): Ein neuer Wettbewerbsrahmen f&#252;r die Digitalwirtschaft. Bericht der Kommission
Wettbewerbsrecht 4.0.
82 Die Abgeordneten Hansj&#246;rg Durz (CDU/CSU) und Falko Mohrs (SPD).
83 High-Level Expert Group on Artificial Intelligence (2019): Ethik-Leitlinien f&#252;r eine vertrauensw&#252;rdige KI&#8288;; High-Level Expert Group 
on Artificial Intelligence (2019): Policy and investment recommendations for trustworthy Artificial Intelligence.
84 Europ&#228;ische Kommission (2020): Wei&#223;buch zur K&#252;nstlichen Intelligenz &#8211; ein europ&#228;isches Konzept f&#252;r Exzellenz und Vertrauen.
85 Gespr&#228;ch mit Dr. Carl-Christian Buhr, stellvertretender Kabinettschef der damaligen EU-Kommissarin f&#252;r digitale Wirtschaft und 
Gesellschaft Mariya Gabriel, und mit Saskia Steinacker, Mitglied der High-Level Expert Group on AI der EU-Kommission, in der
4. Sitzung am 5. November 2018. Anh&#246;rung von Prof. Dr.-Ing. Sami Haddadin, der sowohl Mitglied der High-Level Expert Group 
on AI als auch sachverst&#228;ndiges Mitglied der Enquete-Kommission war, am 9. Dezember 2019 in der 16. Sitzung. Austausch mit
Christiane Canenbley, stellvertretende Kabinettschefin der gesch&#228;ftsf&#252;hrenden Vizepr&#228;sidentin der Europ&#228;ischen Kommission,
Margarethe Vestager, zum Wei&#223;buch der EU-Kommission in der 20. Sitzung am 4. Mai 2020.
86 Vgl. OECD (2019): OECD-Grunds&#228;tze f&#252;r K&#252;nstliche Intelligenz.
87 Anh&#246;rung von Verena Weber, Head of Communication Infrastructures and Services Unit im Directorate for Science, Technology
and Innovation der OECD.
Gleichzeitig widmete sich die Enquete-Kommission auch intensiv Projekten und Initiativen nichtstaatlicher
Akteurinnen und Akteure aus Wissenschaft und Forschung sowie der Zivilgesellschaft. Beispielhaft zu nennen sind
hier:
&#8226; Gespr&#228;che mit Vertretern der Fraunhofer-Gesellschaft, der Helmholtz Gemeinschaft, der Leibnitz-
Gemeinschaft sowie der Max-Planck-Gesellschaft in der 8. Sitzung am 11. M&#228;rz 201988;
&#8226; Austausch mit Start-ups und KI-Branchenvertreterinnen und -vertretern, u. a. in der 9. Sitzung am 1.
April 201989;
&#8226; Diskussion mit zivilgesellschaftlichen Organisationen wie dem Verbraucherzentrale Bundesverband,
Algorithmwatch sowie der Initiative Z-inspection, u. a. in der 18. Sitzung am 10. Februar 202090.
88 Prof. Dr. Emmanuel M&#252;ller, Fraunhofer-Gesellschaft; Prof. Dr. Morris Riedel, Helmholtz Gemeinschaft; Prof. Dr. S&#246;ren Auer,
Leibniz-Gemeinschaft; Prof. Dr. Klaus-Robert M&#252;ller, Max-Planck-Gesellschaft.
89 Hans-Christian Boos, arago GmbH; Roy Uhlmann, Bundesverband Deutsche Startups.
90 Prof. Roberto V. Zicari, Initiative Z-inspection; Matthias Spielkamp, Algorithmwatch; Lina Ehrig, Verbraucherzentrale
Bundesverband.
C. Besonderer Teil:
Bestandsaufnahme, Analyse, Entwicklungsperspektiven und Handlungsempfehlungen
I. Mantelbericht: Projektgruppen&#252;bergreifende Themen
1 Begriffskl&#228;rung K&#252;nstliche Intelligenz
In den vergangenen Jahren hat die K&#252;nstliche Intelligenz (KI) fl&#228;chendeckend stark an Bedeutung gewonnen.
Ma&#223;geblich f&#252;r diese Entwicklung waren und sind die folgenden f&#252;nf Umst&#228;nde:
1. die Digitalisierung, durch die gro&#223;e Datenmengen f&#252;r eine maschinelle Verarbeitung zur Verf&#252;gung
stehen,
2. die bisher exponentiell wachsende Rechenleistung, die es erm&#246;glicht, diese gro&#223;en Datenmengen effizient
zu verarbeiten,
3. die Vernetzung und Kommunikationstechnologie, durch die global Daten (oft verz&#246;gerungsfrei) in
Prozesse einflie&#223;en und gro&#223;e Datenpools schaffen k&#246;nnen,
4. die massive Entwicklung leistungsf&#228;higer Hardwarekomponenten und Systemplattformen wie Sensoren,
Aktoren und Energiesysteme,
5. die Weiterentwicklung von KI-Algorithmen zur Marktreife.
Dieser Abschnitt erl&#228;utert wesentliche Grundbegriffe zum Thema KI, die f&#252;r die Arbeit und den Abschlussbericht
der Enquete-Kommission von Bedeutung sind. 
Die Enquete-Kommission hat sich dabei bewusst f&#252;r eine Begriffskl&#228;rung und gegen eine eigene Definition
entschieden. Eine Definition liefert z. B. die &#8222;High-Level Expert Group on Artificial Intelligence&#8220;, die von der
Europ&#228;ischen Kommission eingerichtet wurde.91 
KI-Systeme und KI-Arten
KI-Systeme sind von Menschen konzipierte, aus Hardware- und/oder Softwarekomponenten bestehende
intelligente Systeme, die zum Ziel haben, komplexe Probleme und Aufgaben in Interaktion mit der und f&#252;r die digitale
oder physische Welt zu l&#246;sen. 
Dazu erfassen, verarbeiten und analysieren KI-Systeme Daten und zeigen ein geeignetes Verhalten zur L&#246;sung
und Erf&#252;llung der jeweiligen Probleme und Aufgaben. Interagiert die KI durch einen technischen K&#246;rper
physisch mit ihrer Umwelt, z. B. als Roboter, spricht man von verk&#246;rperter KI (&#8222;embodied AI&#8220;).
Beispiele f&#252;r KI-Systeme sind medizinische Diagnosesysteme, Systeme zur automatischen Gesichtserkennung,
Sprachassistenzsysteme, autonome Fahrzeuge oder multifunktionelle Haushaltsroboter.92 
Grunds&#228;tzlich lassen sich zwei Arten von KI-Systemen unterscheiden:
Regelbasierte KI-Systeme sind dadurch gekennzeichnet, dass das Verhalten vollst&#228;ndig durch algorithmische
Regeln und maschinenlesbares Wissen von menschlichen Expertinnen oder Experten definiert ist. Dazu geh&#246;ren
insbesondere sogenannte Expertensysteme und die ihnen zugrunde liegenden Wissensdatenbanken. Das
Verhalten regelbasierter KI-Systeme ist f&#252;r den Menschen nachvollziehbar, da die Verfahren der Ergebnisfindung von
Menschen gestaltet, definiert und einsehbar sind. Allerdings kann sich dies durch viele komplexe oder sogar
adaptive Regeln, wie durch das Zusammenspiel vieler solcher Systeme, sehr schwierig und damit nur f&#252;r die
Expertin oder den Experten nachvollziehbar gestalten.
Lernende KI-Systeme zeichnen sich dadurch aus, dass ihre initiale Konfiguration durch den Menschen nur die
Grundlage f&#252;r die konkrete Funktionsweise im eigentlichen Betrieb darstellt. Mithilfe von Daten trainieren sie,
wie ein Problem zu l&#246;sen bzw. eine Aufgabe zu erf&#252;llen ist. Sie passen hierbei ihre Funktionsweise durch einen
entsprechenden Lernprozess kontinuierlich an. Dieser Prozess wird in Kapitel 1.3 des Mantelberichts [Arten des
91 Vgl. High-Level Expert Group on Artificial Intelligence (2019): Eine Definition der KI: Wichtigste F&#228;higkeiten und
Wissenschaftsgebiete. Weitere Informationen dazu unter: https://ec.europa.eu/futurium/en/ai-alliance-consultation (zuletzt abgerufen am 4. August
2020).
92 Die Plattform Lernende Systeme hat unterschiedliche Anwendungsszenarien f&#252;r KI in den Bereichen &#8222;Mobilit&#228;t und
Verkehrssysteme&#8220;, &#8222;Gesundheit, Medizintechnik, Pflege&#8220;, &#8222;Lebensfeindliche Umgebungen&#8220; sowie &#8222;Arbeit, Qualifikation und Mensch-Maschine
Interaktion&#8220; entwickelt, die einen realistischen Blick auf kommende Technologien der n&#228;chsten zehn Jahre geben sollen, weitere 
Informationen dazu unter: https://www.plattform-lernende-systeme.de/anwendungsszenarien.html (zuletzt abgerufen am 4. August
2020).
Trainings und Trainingsdaten], genauer beschrieben. Die Daten k&#246;nnen explizit vom Menschen in das System
eingespeist oder durch gezielte Interaktion mit der Umwelt vom System mittels Sensoren selbst gewonnen
werden. Nach heutigem Stand sind aber auch bei diesen Systemen die &#252;bergeordneten Problemstellungen und Ziele
vom Menschen vorgegeben. Das Systemverhalten ist hierbei f&#252;r Menschen h&#228;ufig schwer nachvollziehbar, wie
im n&#228;chsten Absatz genauer erkl&#228;rt wird. 
Unter den lernenden KI-Systemen haben in den letzten zehn Jahren insbesondere solche Systeme eine besondere
Aufmerksamkeit erregt, die auf dem sogenannten tiefen Lernen (englisch &#8222;Deep Learning&#8220;) basieren. Das tiefe
Lernen ist eine besondere Art des Maschinellen Lernens (im Sinne des vorherigen Absatzes) mittels sogenannter
neuronaler Netze. Der Begriff der Tiefe bezieht sich hier auf die gro&#223;e Anzahl Schichten dieser Rechennetze.
Anders als bei den bis dahin &#252;berwiegend verwendeten Systemen m&#252;ssen die Daten beim tiefen Lernen viel
weniger (und teilweise &#252;berhaupt nicht mehr) vom Menschen vorverarbeitet und vorstrukturiert werden. Die
sinnvolle Strukturierung der Rohdaten wird dann zu einem Teil des Lernprozesses. Durch diesen zus&#228;tzlichen
Freiheitsgrad ist die Qualit&#228;t der Ergebnisse denen bisheriger Systeme oft &#252;berlegen. Allerdings sind die
Ergebnisse solcher Systeme gerade wegen der geringeren Vorverarbeitung oder Vorstrukturierung durch den Menschen
besonders schwer nachvollziehbar.
Die Grenzen heutzutage eingesetzter KI-Systeme werden in Kapitel 1.4 des Mantelberichts [Einsatz und Qualit&#228;t 
von KI-Systemen], diskutiert. Insbesondere wird dort kurz auf den Unterschied zwischen sogenannter schwacher
KI und starker KI eingegangen.
Training von lernenden KI-Systemen
Lernalgorithmen in KI-Systemen bestehen aus zwei Teilen: einem Grundger&#252;st, das vom Menschen vorgegeben
ist (z. B. in der Form eines Rechennetzwerkes oder einer komplexen Formel mit einer bestimmten Struktur), und
einer Anzahl von Parametern (oft sehr viele), f&#252;r die nur ein initialer Wert vorgegeben ist und die im Laufe des
Trainings angepasst (&#8222;gelernt&#8220;) werden.
Um nun eine spezifische F&#228;higkeit oder ein Verhalten zu trainieren, wird das System normalerweise schrittweise
mit Beispielen, oft Trainingsdaten genannt, gef&#252;ttert. Diese Daten kommen entweder vom Menschen und/oder
das System verschafft sich die Daten durch selbstst&#228;ndige (wenn auch vom Menschen methodisch vorgegebene)
Interaktion und Messung. In jedem solchen Trainingsschritt werden die Parameter derart angepasst, dass sich das
Verhalten des Systems auf Basis dieser Trainingsdaten verbessert. Das Training wird so lange durchgef&#252;hrt, bis
keine wesentliche Verbesserung mehr eintritt oder wie es die zur Verf&#252;gung stehenden Ressourcen erlauben. In 
der Regel ist das Ergebnis des Trainings umso besser, je mehr Trainingsdaten zur Verf&#252;gung stehen.
Das Trainieren eines KI-Systems kann grunds&#228;tzlich auch w&#228;hrend seines Einsatzes fortgesetzt werden. Der
Vorteil ist, dass das System dann seine F&#228;higkeiten durch die kontinuierlich hinzukommenden Daten immer weiter
verbessern kann. Ein Nachteil ist, dass sich das Verhalten wieder verschlechtern kann, etwa durch Fehler beim
Lernen. Im schlimmsten Fall kann dies sogar zu kompletten Fehlklassifikationen oder komplettem Fehlverhalten 
f&#252;hren. W&#228;hrend heute typischerweise verk&#246;rperte KI-Systeme wie Roboter oder Autos nur einmal trainiert
werden, sind viele andere KI-Systeme wie Suchmaschinen oder Empfehlungssysteme gerade deshalb so
wirkungsvoll, weil sie st&#228;ndig weiterlernen.
Arten des Trainings und Trainingsdaten
Grunds&#228;tzlich lassen sich drei Arten des Trainings unterscheiden:
Beim sogenannten &#252;berwachten Lernen (englisch &#8222;supervised learning&#8220;) sind die Trainingsdaten mit
Zusatzinformationen, sogenannten Annotationen, versehen, die direkte Hinweise in Bezug auf das gew&#252;nschte Verhalten
geben. Das kann z. B. eine Menge von Bildern sein, die Angaben zu den darauf abgebildeten Objekte enthalten.
Solche annotierten Daten sind f&#252;r das Lernen meistens besonders effektiv, es ist aber oft sehr schwer oder
kostspielig, sie in gro&#223;er Menge zu erhalten, da die Annotationen in der Regel das Produkt menschlicher Arbeit sind.
Beim sogenannten nicht-&#252;berwachten Lernen (englisch &#8222;unsupervised learning&#8220;) werden Trainingsdaten ohne
solche Annotationen verwendet. Diese Daten stehen oft in sehr gro&#223;en Mengen zur Verf&#252;gung, z. B. Terabytes
von Texten oder Millionen von Bildern. Auch aus solchen Daten k&#246;nnen KI-Systeme lernen, z. B. k&#246;nnen sie
Erkenntnisse gewinnen &#252;ber die grunds&#228;tzliche Syntax und Semantik einer Sprache oder den grunds&#228;tzlichen
Aufbau eines Bildes. In der Praxis kommt heutzutage oft eine Kombination aus &#252;berwachtem und nicht-
&#252;berwachtem Lernen zum Einsatz.
        
 
 
 
 
    
  
  
         
  
 
 
   
       
  
       
     
   
   
 
  
 
  
 
 
     
 
 
  
       
     
  
    
   
 
  
   
     
  
     
   
       
 
2
Beim sogenannten best&#228;rkenden Lernen (englisch &#8222;reinforcement learning&#8220;) muss sich das System innerhalb 
einer bestimmten Umgebung f&#252;r Handlungen entscheiden. Vom Menschen vorgegeben ist lediglich das
&#252;bergeordnete Ziel, z. B. der Gewinn eines Spiels oder eine gew&#252;nschte Ver&#228;nderung in der physischen Welt. Selbst
die genaue mathematische Formulierung des Ziels kann parametrisiert und Teil des Lernprozesses sein.
Einsatz und Qualit&#228;t von KI-Systemen
Im praktischen Einsatz reproduzieren KI-Systeme das gelernte Verhalten, indem sie in der antrainierten Weise
auf ihnen bis dahin unbekannte Daten und Sensorsignale reagieren. F&#252;r den Einsatz sind die KI-Systeme dann in 
der Regel nicht mehr auf die f&#252;r das Training verwendeten Daten angewiesen.
In der Durchf&#252;hrung und L&#246;sung spezifischer und wohldefinierter Aufgaben- und Problemstellungen sind KI-
Systeme dem Menschen &#252;berlegen, teilweise deutlich. Dazu geh&#246;rt schon lange ein Spiel wie Schach und seit
einigen Jahren auch Spiele mit weitaus mehr Zugm&#246;glichkeiten wie Go sowie weitere komplexe Computerspiele. 
Dazu geh&#246;ren aber ebenso die Bilderkennung in der medizinischen Diagnostik und das autonome Fahren.
Grunds&#228;tzlich l&#228;sst sich sagen, dass heutige KI-Systeme dem Menschen potenziell bei solchen kognitiven
Prozessen &#252;berlegen sind, bei denen die Problemstellung, die Art der ben&#246;tigten Daten und das Erfolgsma&#223; klar
definiert werden k&#246;nnen und diese Daten in gro&#223;er Menge zur Verf&#252;gung stehen. Selbst ein einzelner
herk&#246;mmlicher Computer kann dadurch heutzutage problemlos in kurzer Zeit ein Vielfaches mehr an Texten oder Bildern
lernend verarbeiten, als ein einzelner Mensch in einem ganzen Leben auch nur anzuschauen vermag. Man spricht
im Zusammenhang mit solchen Problemstellungen auch oft von &#8222;schwacher KI&#8220;.
Allen diesen Problemen ist aber aufgrund ihrer Komplexit&#228;t gemein, dass die optimale L&#246;sung nicht exakt
ausgerechnet werden kann und sich auch KI-Systeme ihr nur schrittweise in iterativen Prozessen ann&#228;hern k&#246;nnen.
Auch wenn also KI-Systeme bei der L&#246;sung der beschriebenen Art von Problemen den Menschen an Pr&#228;zision
&#252;bertreffen, garantieren sie keine Fehlerfreiheit.
Umgekehrt ist Menschen eine allgemeine Intelligenz zu eigen, die es ihnen erlaubt, Informationen der
verschiedenen Sinne in einen gr&#246;&#223;eren Zusammenhang zu stellen und Probleme aus den unterschiedlichsten Bereichen
zu l&#246;sen oder daf&#252;r L&#246;sungsstrategien zu entwickeln. Dies gilt insbesondere bei der Interaktion mit der
physischen Welt, die selbst bei f&#252;r einen Menschen vergleichsweise einfachen T&#228;tigkeiten ein komplexes
Zusammenspiel verschiedener Sinneswahrnehmungen in Kombination mit einer komplexen Motorik und Agilit&#228;t erfordert.
Man spricht im Zusammenhang mit diesen F&#228;higkeiten auch von &#8222;starker KI&#8220;. Es gibt heutzutage kein KI-
System, das diesen F&#228;higkeiten des Menschen auch nur nahekommt. Es ist innerhalb der Wissenschaft umstritten, 
wie nahe KI-Systeme diesen F&#228;higkeiten &#252;berhaupt kommen k&#246;nnen. Es gilt als sehr unwahrscheinlich, dass eine
solche Entwicklung kurz oder mittelfristig bevorsteht.
F&#252;r die Arbeit dieser Enquete-Kommission stehen daher schwache KI-Systeme im Fokus, die bereits heute im
Einsatz sind oder deren Einsatz innerhalb der n&#228;chsten Jahre realistisch erscheint. Der vorliegende Bericht
konzentriert sich dabei im Wesentlichen auf die Eigenschaften und den Umgang mit lernenden KI-Systemen. Der
Begriff KI-System wird dementsprechend im Weiteren im Sinne von lernenden KI-Systemen verwendet.
KI und Daten
Wie in Kapitel 1 des Mantelberichts [Begriffskl&#228;rung K&#252;nstliche Intelligenz] beschrieben, spielen Daten f&#252;r KI-
Systeme in der Anwendung, beim Testen, vor allem aber beim Training eine zentrale Rolle. Dabei werden durch
KI-Systeme generalisierende Gesetzm&#228;&#223;igkeiten ausgepr&#228;gt, die in den zum Training verwendeten Daten
vorhanden sind. Trainingsdaten bestimmen also ma&#223;geblich das antrainierte Verhalten des KI-Systems, weil nur
Zusammenh&#228;nge erlernt werden k&#246;nnen, die auch in den Trainingsdaten abgebildet werden. F&#252;r das Training gilt 
dabei in der Regel: Je komplexer die zu erlernende Aufgabe ist, desto mehr Daten werden ben&#246;tigt. Die Quantit&#228;t
der zur Verf&#252;gung stehenden Daten spielt neben der Qualit&#228;t also f&#252;r KI eine wichtige Rolle.
Im Folgenden werden ausgew&#228;hlte Aspekte und Eigenschaften von Daten erkl&#228;rt, die f&#252;r das Verst&#228;ndnis der
weiteren Berichtsteile wesentlich sind.
Definitionen
Daten bestehen aus (Zahlen-)Werten, die beispielsweise durch Beobachtungen, Messungen oder statistische
Erhebungen gewonnen oder abgeleitet werden.93 Im Kontext von KI gibt es sehr unterschiedliche Daten. Diese
reichen von Bildern oder Texten &#252;ber den Standort eines Roboters, das Klickprofil, das von Suchmaschinen
erstellt wird, bis hin zu Sensordaten aus einer Flugzeugturbine. Daten werden physikalisch gespeichert, z. B. auf
einem USB-Stick oder einer Festplatte, und k&#246;nnen von einem physikalischen Speicher in einen anderen
&#252;bertragen werden. Die Datenverarbeitung umfasst jeden Vorgang, bei dem Daten die Grundlage darstellen. Dies
beinhaltet neben der Verwendung von Daten f&#252;r Berechnungen94 auch das Erheben, Speichern und &#220;bertragen
sowie insbesondere die L&#246;schung, &#220;berschreibung und Sichtbarmachung.95 
Informationen bezeichnen den Sinngehalt, der aus den Daten durch menschliche Interpretation entsteht.
W&#228;hrend Daten die Tr&#228;ger von Informationen sind, sind Informationen selbst dementsprechend subjektive und
kontextbasierte Zuschreibungen.96 
Die Verwendungsm&#246;glichkeiten der Informationen, die aus einem Datensatz gewonnen werden k&#246;nnen,
bestimmen dessen Nutzen. Aus dem Zusammenspiel von Nachfrage und Angebot bildet sich der &#246;konomische Wert
von Daten. Im Gegensatz zu physischen G&#252;tern werden Daten allerdings durch die Nutzung nicht verbraucht und
k&#246;nnen in der Regel problemlos vervielf&#228;ltigt werden. 
Qualit&#228;t von Daten
Da Trainingsdaten ma&#223;geblich die Eigenschaften eines KI-Systems bestimmen, ist die Qualit&#228;t der Daten ein
wesentlicher Aspekt f&#252;r die Qualit&#228;t des KI-Systems. Viele Faktoren spielen dabei eine Rolle, ob ein Datensatz
dazu geeignet ist, ein KI-System zu trainieren. Im Folgenden werden die wichtigsten beschrieben:
1. Der Informationsgehalt der Daten: Wie beschrieben kann das KI-System nur solche Zusammenh&#228;nge
auspr&#228;gen, die in den Daten in ausreichendem Ma&#223;e97 enthalten sind. Beispielsweise wird ein KI-System,
das auf einer hinreichend gro&#223;en Basis von Bildern trainiert wurde, um B&#228;lle zu erkennen, wahrscheinlich
den Zusammenhang zwischen einer runden Form und einem Ball auspr&#228;gen. Wenn die Trainingsdaten keine
Bilder enthalten, die es erm&#246;glichen, B&#228;lle von anderen rund dargestellten Gegenst&#228;nden abzugrenzen, wird
das KI-System wahrscheinlich auch Planeten, Orangen, Ringe und Reifen als B&#228;lle identifizieren. F&#252;r die
Beurteilung der Qualit&#228;t der Daten ist daher im Vorfeld zu bestimmen, ob das KI-System nur in der Lage
sein soll, B&#228;lle richtig zu erkennen, oder ob es B&#228;lle auch von anderen runden Gegenst&#228;nden abgrenzen
k&#246;nnen muss. 
2. Die Genauigkeit der Daten: Um es KI-Systemen zu erm&#246;glichen, die in den Daten enthaltenen
differenzierenden Merkmale zu nutzen, m&#252;ssen diese m&#246;glichst exakt und st&#246;rungsfrei erkennbar sein. Basierend
auf dem obigen Beispiel w&#252;rden unscharfe, verrauschte oder zu gering aufgel&#246;ste Bilder wahrscheinlich die
Erkennungsleistung des KI-Systems verringern. Allerdings gilt es zu beachten, dass die f&#252;r das Training
n&#246;tige Genauigkeit der Daten in der Regel dadurch bestimmt wird, welche Daten das KI-System im Einsatz
verarbeiten soll. Wenn im Einsatz also beispielsweise mit Unsch&#228;rfe, Rauschen oder geringer Aufl&#246;sung zu
rechnen ist, kann es f&#252;r das KI-System besser sein, auf der Basis &#228;hnlicher Daten zu trainieren, um
Robustheit gegen diese Art von St&#246;rungen zu entwickeln.
3. Die Korrektheit der Daten: KI-Systeme sind davon abh&#228;ngig, dass die f&#252;r ihr Training verwendeten Daten
die zu erlernenden Zusammenh&#228;nge korrekt wiedergeben. Einzelne falsche Datenpunkte f&#252;hren dabei
normalerweise nicht zu Fehlverhalten des Systems, beeintr&#228;chtigen aber unter Umst&#228;nden die Genauigkeit.
Systematische Fehler dagegen k&#246;nnen dazu f&#252;hren, dass falsche Zusammenh&#228;nge ausgepr&#228;gt werden.
Basierend auf dem obigen Beispiel w&#228;re bei wenigen f&#228;lschlich als Kugel gekennzeichneten W&#252;rfeln noch
93 Vgl. Duden: Daten.
94 Diese Berechnungen bilden die Grundlage etwa f&#252;r Analysen, Diagnosen, Auswertungen und Vorhersagen.
95 Nach Artikel 4 Nummer 2 der Datenschutz-Grundverordnung (DSGVO) bezeichnet Verarbeitung &#8222;jeden mit oder ohne Hilfe
automatisierter Verfahren ausgef&#252;hrten Vorgang oder jede solche Vorgangsreihe im Zusammenhang mit personenbezogenen Daten wie 
das Erheben, das Erfassen, die Organisation, das Ordnen, die Speicherung, die Anpassung oder Ver&#228;nderung, das Auslesen, das
Abfragen, die Verwendung, die Offenlegung durch &#220;bermittlung, Verbreitung oder eine andere Form der Bereitstellung, den
Abgleich oder die Verkn&#252;pfung, die Einschr&#228;nkung, das L&#246;schen oder die Vernichtung&#8220;.
96 Technisch gesehen k&#246;nnen diese Interpretationen beschrieben und somit als Daten gespeichert werden.
97 Man spricht in diesem Zusammenhang auch von der statistischen Signifikanz der Daten.
nicht davon auszugehen, dass die G&#252;te des KI-Systems ma&#223;geblich sinkt. Bei zu vielen als Kugel
gekennzeichneten W&#252;rfeln w&#252;rde das KI-System allerdings W&#252;rfel folgerichtig auch als Kugeln erkennen. 
Zusammenfassend ist die Qualit&#228;t von Daten also keine absolute Eigenschaft, sondern kann nur relativ zum
Anwendungsfall bewertet werden. Inwieweit die Qualit&#228;t der Daten zu Bias und Diskriminierung f&#252;hren kann, wird
in Kapitel 3 des Mantelberichts [KI und Umgang mit Bias/Diskriminierung] n&#228;her erl&#228;utert.
Arten von Daten
Die Daten f&#252;r KI-Systeme k&#246;nnen aus unterschiedlichen Quellen kommen. Im Weiteren werden die g&#228;ngigen
Datenarten erkl&#228;rt, die im Laufe des Berichts diskutiert werden:
Rohdaten sind solche Daten, die durch Beobachtungen, Messungen oder statistische Erhebungen gewonnen
werden.98 Sie werden auch als Prim&#228;r-, Real-, oder Originaldaten bezeichnet. Daten zu Vorg&#228;ngen und Zust&#228;nden
der physischen Welt werden &#252;ber Sensoren erzeugt, die daf&#252;r analoge Signale umwandeln.99 
Echtzeitdaten sind eine spezielle Form der Rohdaten, die (meist regelm&#228;&#223;ig erfasst) in einer vorgegebenen
Zeitspanne verarbeitet werden. Sie zeichnen sich u. a. dadurch aus, dass sie neben dem beobachteten Fakt auch einen
R&#252;ckschluss auf den Zeitpunkt der Erfassung zulassen. Im betriebswirtschaftlichen Kontext werden
Echtzeitdaten auch als Produktivdaten bezeichnet.  
F&#252;r das Training von KI-Systemen sind Rohdaten von besonderer Bedeutung, weil sie es erm&#246;glichen, auch
solche Zusammenh&#228;nge zu lernen, die dem Menschen unbekannt oder unzug&#228;nglich sind. So k&#246;nnen KI-Systeme
z. B. lernen, basierend auf einer gro&#223;en Menge von Sensordaten Sch&#228;den an Maschinen vorherzusagen,100 die 
f&#252;r den Menschen nur schwer erkennbar oder verborgen sind.
Sekund&#228;rdaten sind &#8211; im Gegensatz zu Rohdaten &#8211; alle jene Daten, die durch Datenverarbeitung entstanden
sind. Dabei k&#246;nnen f&#252;r diese Datenverarbeitung sowohl Rohdaten als auch Sekund&#228;rdaten die Grundlage bilden.
Oft sind Sekund&#228;rdaten bereits Generalisierungen oder Modelle, aus denen kaum noch R&#252;ckschl&#252;sse auf die
Rohdaten m&#246;glich sind. Ermittelt man beispielsweise den Altersdurchschnitt einer Schulklasse und nimmt diesen 
als Sekund&#228;rdatum, dann l&#228;sst sich hieraus kein R&#252;ckschluss auf die Altersverteilung ziehen.
Synthetische Daten sind eine spezielle Form der sekund&#228;ren Daten. Sie werden durch Datenverarbeitung
k&#252;nstlich erzeugt. Meist basieren sie auf einer Kombination aus Regeln &#252;ber die gew&#252;nschte Struktur und
Eigenschaften der Daten, die vom Menschen vorgegeben wird oder auf anderen Datens&#228;tzen beruht. In diesem vorgegebenen
Rahmen werden synthetische Daten zuf&#228;llig101 generiert. Synthetische Daten enthalten dementsprechend nur
vorher bekannte Informationen und sind somit im Vergleich zu Rohdaten nur begrenzt geeignet, neue oder
unbekannte Erkenntnisse zu gewinnen. Da nach initialer Konfiguration ohne nennenswerten Aufwand quasi
unbegrenzt synthetische Daten produziert werden k&#246;nnen, stellen sie aber eine M&#246;glichkeit dar, gro&#223;e Mengen von
Daten f&#252;r das Trainieren und Testen von KI-Systemen zu erzeugen.102 Weiterhin ist die Generierung und
Verwendung von synthetischen Daten eine Alternative, wenn existierende Rohdaten nicht direkt verwendet werden
k&#246;nnen, weil diese beispielsweise personenbezogene Informationen enthalten oder Gesch&#228;ftsgeheimnisse
offenlegen w&#252;rden. Entsprechend ist auch die Erstellung von Modellen durch Simulation oder mittels modellhafter
Abbilder von Gegenst&#228;nden relevant. Gerade diese Modelle k&#246;nnen einerseits dazu genutzt werden, beim
Training extreme Zust&#228;nde, die in der Realit&#228;t kaum oder fast nie vorkommen, gezielt einzusetzen, um die Robustheit
des Gesamtsystems auszureizen. Auch k&#246;nnen diese Modelle nach Abschluss des Trainingsprozesses verwendet
werden, um reproduzierbare Pr&#252;fmethoden zur Freigabe und Zertifizierung des Gesamtsystems zu entwickeln.103 
98 Diese Definition ist angelehnt an die Beschreibung von Daten im Duden, vgl. Duden: Daten.
99 Rohdaten sind nicht notwendigerweise eine neutrale Abbildung der Realit&#228;t, da die Entscheidungen dar&#252;ber, welche Daten in
welchem Umfang mit welchen Mitteln von wem erfasst werden, bereits eine Wertung beinhalten kann (vgl. Gitelman (2013): &#8222;Raw data&#8220;
is an oxymoron).
100 Diese Informationen werden in der Praxis z. B. genutzt, um vorbeugende Instandhaltungsma&#223;nahmen (Predictive Maintenance)
vorzunehmen.
101 Normalerweise basieren synthetische Daten auf einer deterministischen mathematischen Berechnung in Kombination mit einem
zuf&#228;llig ausgew&#228;hlten Wert, z. B. dem aktuellen Zeitpunkt.
102 Dies wird u. a. dann wichtig, wenn Realdaten nicht oder nur in geringem Ma&#223;e verf&#252;gbar sind, beispielsweise zu seltenen
Katastrophen oder extremen physikalischen Zust&#228;nden.
103 Vgl. Drechsler und Jentzsch (2018): Synthetische Daten.
Metadaten beschreiben die Natur der eigentlichen Daten, beispielsweise die Sprache von Textdaten, die
verwendete Kamera oder Aufnahmeort und -zeit bei Bilddaten, und werden u. a. zur Verwaltung gr&#246;&#223;erer
Datenmengen eingesetzt.
Zugang zu Daten
Datenzugang bezeichnet die M&#246;glichkeit, auf bestimmte Daten zugreifen und diese verarbeiten zu k&#246;nnen. Um
die Nutzung von Daten f&#252;r das Training von KI-Systemen zu erm&#246;glichen, m&#252;ssen diese &#252;ber digitale
Schnittstellen verf&#252;gbar gemacht werden. Bei der Gewinnung von und dem Zugriff auf Daten sind gegebenenfalls
gesetzliche Regelungen zu beachten, wie die Europ&#228;ische Datenschutzgrundverordnung (DSGVO) oder das
Urheberrechtsgesetz. Open Data hingegen sollen jederzeit von allen Interessierten u. a. auch zu kommerziellen
Zwecken genutzt werden k&#246;nnen.104 
Datenformate sind Regeln, nach denen Daten strukturiert gespeichert und bereitgestellt werden. Standardisierte
Datenformate, die von vielen Systemen angewendet werden, sind hilfreich, um Daten effizient durch
verschiedene Systeme verarbeiten und zwischen diesen austauschen zu k&#246;nnen.105 
Datensicherheit wird in diesem Bericht analog zu dem Konzept der Informationssicherheit verwendet, das das
Bundesamt f&#252;r Sicherheit in der Informationstechnik (BSI) beschrieben hat.106 Zentral f&#252;r dieses Konzept sind
drei Eigenschaften:
1. Vertraulichkeit beschreibt den Schutz vor unerlaubtem Zugang zu Informationen. Dies kann &#252;ber eine
Zugangskontrolle zu den Daten erfolgen. In vielen F&#228;llen wird aber alternativ oder zus&#228;tzlich eine
Verschl&#252;sselung der Daten vorgenommen, die es Unbefugten trotz Zugang zu den Daten unm&#246;glich macht,
deren Inhalt zu erkennen. 
2. Verf&#252;gbarkeit bezeichnet die Eigenschaft eines Informationssystems, zum gew&#252;nschten Zeitpunkt Daten
bereitstellen zu k&#246;nnen. Daf&#252;r ist es notwendig, dass Systeme in der Lage sind, vordefinierte
Daten&#252;bertragungsraten auch w&#228;hrend zuf&#228;lliger oder mutwillig herbeigef&#252;hrter107 Hochlastphasen zu garantieren.108 
3. Integrit&#228;t bedeutet, dass die Daten im System vollst&#228;ndig und unver&#228;ndert sind und somit nicht
unbeabsichtigt oder mutwillig durch Unbefugte gel&#246;scht oder ver&#228;ndert werden k&#246;nnen. Dies ist gerade im Kontext
von KI wichtig, da die im Training verwendeten Daten erheblichen Einfluss auf das Verhalten des Systems
haben.
Personenbezogene Daten
Personenbezogene Daten sind gem&#228;&#223; der DSGVO alle Informationen, die sich auf identifizierte oder
identifizierbare Personen beziehen.109 Neben dem Namen oder der Telefonnummer geh&#246;ren dazu auch Kfz-
Kennzeichen, Konto- und Kreditkartennummern, IP-Adressen und biometrische Daten wie Bilder von Gesichtern,
Fingerabdr&#252;cke und Iris-Scans. Auch Gesundheitsdaten und die damit verbundenen medizinischen und genetischen
Daten sowie Patientendaten geh&#246;ren zu den personenbezogenen Daten. Folgende Begriffe stehen im engen
Zusammenhang mit personenbezogenen Daten:
1. Informationelle Selbstbestimmung bezeichnet ein Konzept, bei dem die Entscheidung &#252;ber Erhebung, 
Speicherung und die Nutzung von personenbezogenen Daten bei den betroffenen Personen selbst liegen
soll. Der Mensch bestimmt selbst, ob und wie die ihn betreffenden Daten genutzt werden. Er kann
entsprechend den eigenen Vorstellungen seine Privatsph&#228;re sch&#252;tzen. Das Recht auf informationelle
Selbstbestimmung wurde im Volksz&#228;hlungsurteil des Bundesverfassungsgerichts von 1983 aufgegriffen und genie&#223;t bis
heute Verfassungsrang. 
104 Siehe AG-Bericht 2 des Berichts der Projektgruppe &#8222;KI und Staat&#8220; [AG 2: Smart City und Open Data].
105 Ein bekanntes Beispiel ist der Standard ISO 8601, der die Datenstruktur f&#252;r den Austausch von Uhrzeit (hh:mm:ss) und Datum
(YYYY-MM-DD) definiert.
106 Vgl. BSI-Standard 200-1, weitere Informationen dazu unter: https://www.bsi.bund.de/DE/Themen/ITGrundschutz/ITGrundschutz-
Standards/Leitfaden_Basisabsicherung/Leitfaden_Basisabsicherung_node.html (zuletzt abgerufen am 4. August 2020).
107 Man spricht hier von &#8222;Denial of Service (DoS)&#8220;-Attacken.
108 Garantierte &#220;bertragungsraten werden &#252;blicherweise in Form von Service-Level-Agreements (SLAs) definiert.
109 Vgl. Artikel 4 Nummer 1 DSGVO.
2. Datensouver&#228;nit&#228;t und Datenhoheit werden meist synonym zu informationeller Selbstbestimmung
verwendet und heben die Autonomie der Person110 im Umgang mit ihren personenbezogenen Daten hervor.
Eine datensouver&#228;ne Person ist in der Lage, selbstbestimmt mit ihren Informationen umzugehen und
Entscheidungen &#252;ber deren Nutzung zu treffen. 
3. Datenfreigabe ist ein Teilaspekt der informationellen Selbstbestimmung und bezeichnet das bewusste Zur-
Verf&#252;gung-Stellen111 von personenbezogenen Daten f&#252;r bestimmte Zwecke, wie z. B. die medizinische
Forschung. 
Nutzergenerierte Daten werden von einem Individuum durch Nutzung eines Endger&#228;ts erzeugt, weisen aber
nicht notwendigerweise Informationen zu diesem Individuum auf. Sie sind in einigen Bereichen mittlerweile eine
breit anerkannte und weitgehend hochqualitative Grundlage f&#252;r die Unterst&#252;tzung von Entscheidungen in einer
Reihe von Anwendungsgebieten.112 
Nicht-personenbezogene Daten sind dagegen solche Daten, die keine Informationen zu Individuen enthalten 
oder keine Identifizierung zulassen. Ein Datensatz ist dementsprechend nicht-personenbezogen, wenn es kein
bekanntes Verfahren gibt, aus diesem personenbezogene Informationen zu gewinnen. Damit birgt jeder
nichtpersonenbezogene Datensatz das latente Risiko, durch neue technische Verfahren, innovative Nutzung
bestehender Verfahren oder durch Kombination mit weiteren Informationen personenbezogen zu werden. 
Anonymisierung umfasst verschiedene Methoden der Datenverarbeitung, die zum Ziel haben,
personenbezogene Informationen in Datens&#228;tzen unzug&#228;nglich zu machen, gleichzeitig aber nicht-personenbezogene
Informationen soweit m&#246;glich zu erhalten. Eine Anonymisierung kann dabei sowohl durch Menschen als auch maschinell
erfolgen. Erfolgreich anonymisierte Datens&#228;tze, bei denen der Personenbezug nachhaltig entfernt wurde, fallen
dementsprechend nicht in den Geltungsbereich der DSGVO. Zu beachten ist allerdings, dass die Anonymisierung 
selbst eine Verarbeitung von personenbezogenen Daten gem&#228;&#223; DSGVO darstellt. Au&#223;erdem verschlechtert die
Anonymisierung h&#228;ufig die Qualit&#228;t der Daten im Sinne des Maschinellen Lernens. Ersetzt man z. B. in
Kundendatenbanken Kontaktdaten, Kaufzeitpunkte und IP-Adressen durch Platzhalter wie &#8222;[Kontaktdaten]&#8220;, &#8222;[
Kaufzeitpunkte]&#8220; und &#8222;[IP-Adresse]&#8220;, dann sind die Daten nur noch bedingt aussagekr&#228;ftig. 
Pseudonymisierung umfasst, &#228;hnlich der Anonymisierung, verschiedene Methoden der Datenverarbeitung, um
personenbezogene Informationen in Datens&#228;tzen unzug&#228;nglich zu machen. Sie wird in Artikel 4 der DSGVO
rechtlich definiert und kann die Zul&#228;ssigkeit einer Verarbeitung personenbezogener Daten erm&#246;glichen oder
erleichtern. Bei der Pseudonymisierung wird das Identifikationsmerkmal durch ein Pseudonym, beispielsweise eine
Ziffernfolge ersetzt. Die Zuordnung von Pseudonymen und Identifikationsmerkmalen wird getrennt vom
Datensatz aufbewahrt. Ohne die Information dar&#252;ber, welches Pseudonym zu welchem Identifikationsmerkmal geh&#246;rt, 
ist der Personenbezug bei erfolgreicher Pseudonymisierung nicht herstellbar. Anders als bei der Anonymisierung 
kann der Personenbezug deshalb bei Bedarf wiederhergestellt werden, wobei auf die getrennt gespeicherte
Zuordnung zur&#252;ckgegriffen wird. Im Rechtsinne bleibt bei pseudonymisierten Datens&#228;tzen dementsprechend ein
Personenbezug bestehen, sodass diese weiter in den Geltungsbereich der DSGVO fallen. 
Sowohl beim anonymisierten als auch beim pseudonymisierten Datensatz gibt es nach heutigen Verfahren in der
Regel keine absolute Sicherheit daf&#252;r, dass der Datensatz keine verwertbaren personenbezogenen Informationen
mehr enth&#228;lt. F&#252;r die erfolgreiche R&#252;ckgewinnung der personenbezogenen Informationen werden jedoch
normalerweise Wissen &#252;ber Schwachstellen des verwendeten Verfahrens und &#252;ber potenziell enthaltene Informationen
(z. B. durch Zusammenf&#252;hren mit anderen Datens&#228;tzen) sowie eine hinreichend gro&#223;e Rechenleistung ben&#246;tigt.
Eine erfolgreiche Anonymisierung oder Pseudonymisierung zeichnet sich deshalb dadurch aus, dass der
potenzielle Aufwand der R&#252;ckgewinnung von personenbezogenen Informationen den zu erwartenden Nutzen
&#252;bersteigt.
110 Siehe Kapitel 6 des Mantelberichts [Ethische Perspektiven auf KI].
111 Rechtlich ma&#223;geblich ist die verfassungsrechtliche wie datenschutzrechtliche Einordnung als Einwilligung im Sinne von Artikel 6 
Absatz 1 Satz 1a DSGVO samt der damit einhergehenden Vorgaben. Die Enquete-Kommission K&#252;nstliche Intelligenz hat sich
entschieden, von &#8222;Datenfreigabe&#8220; zu sprechen und nicht den h&#228;ufig verwendeten Begriff &#8222;Datenspende&#8220; zu benutzen; siehe dazu auch
den Bericht der Projektgruppe &#8222;KI und Gesundheit&#8220; in Kapitel C. IV. [K&#252;nstliche Intelligenz und Gesundheit (Projektgruppe 3)].
112 Vgl. Resch (2017): Nutzergenerierte Daten f&#252;r Entscheidungsunterst&#252;tzung in naher Echtzeit.
Politischer Handlungsrahmen bez&#252;glich KI und Daten
Wie beschrieben sind die Funktionsweise und Leistungsf&#228;higkeit von KI-Systemen eng mit den sowohl im
Training, beim Test als auch in der Anwendung genutzten Daten verkn&#252;pft.
Ein deutscher bzw. europ&#228;ischer Ansatz zur Entwicklung und Anwendung von KI muss daher auch Antworten
auf zentrale Herausforderungen in Bezug auf Vielfalt, Verf&#252;gbarkeit und Nutzung von Daten sowie
Datensicherheit und Datenschutz geben. Ein solcher Handlungsrahmen f&#252;r den Umgang mit Daten sollte die Besonderheiten
der europ&#228;ischen Daten&#246;konomie ber&#252;cksichtigen. Dabei ist die F&#246;rderung des Zugangs zu Daten mit unseren 
Werten bez&#252;glich eines selbstbestimmten Umgangs mit personenbezogenen Informationen in Einklang zu
bringen. Angesichts der Kritik an starker Konzentration des Zugangs zu Daten bei gro&#223;en, globalen
Internetplattformen sind insbesondere dezentrale, auf Kooperation setzende Datennutzungsmodelle anzustreben. Auch eine
Weiterentwicklung der h&#246;chst unterschiedlichen Open-Data-Gesetzgebung im Bund, in den L&#228;ndern und in
Europa ist f&#252;r die Entwicklung einer Datenpolitik zentral. Sie muss den Grundrechtsschutz betonen und als
Alternative zu Datenmodellen positioniert werden, die wie in China von staatlichen Sicherheits- und
Kontrollinteressen getrieben und wie in den USA stark von den Interessen gro&#223;er Internetplattformen und der Tech-Industrie
gepr&#228;gt sind. 
In Bezug auf Einsatz und Nutzung von KI sind bei der Entwicklung eines solchen Datenmodells eine Reihe von
Aspekten hervorzuheben, die den breiteren Handlungsrahmen f&#252;r die politische Gestaltung der Schnittstelle
zwischen KI- und Datenpolitik bilden. Im Folgenden werden diese Aspekte des allgemeinen Handlungsrahmens
weiter ausgef&#252;hrt. 
Die Verf&#252;gbarkeit von Daten ist Grundvoraussetzung f&#252;r Entwicklung und Einsatz von KI. Eine F&#246;rderung der
KI muss sich daher mit der Verbesserung der Verf&#252;gbarkeit von Daten befassen. Das Vorantreiben der
Digitalisierung und die Modernisierung von IT-Systemen schaffen die Grundlage f&#252;r eine breitere Verf&#252;gbarkeit von
Daten. Das gilt f&#252;r Regierung und Verwaltung ebenso wie f&#252;r Unternehmen und gemeinn&#252;tzige Organisationen.
Regierung und Verwaltung k&#246;nnen eigene Datens&#228;tze als Open-Data-Wirtschaft und Gesellschaft zur Verf&#252;gung
stellen. Um einen echten Nutzen und Mehrwert sicherzustellen, m&#252;ssen hierbei gewisse Vorgaben beachtet
werden. Zus&#228;tzliche politische Ma&#223;nahmen k&#246;nnen die Datenverf&#252;gbarkeit auch au&#223;erhalb von Regierung und
Verwaltung verbessern. So fehlen in der Wissenschaft oft die Ressourcen, in Forschungsprojekten erhobene Daten
breiter zug&#228;nglich zu machen. Der Austausch von Daten oder ihre gemeinsame Nutzung zwischen Unternehmen 
ist mit Rechtsunsicherheit, insbesondere in Bezug auf das Kartellrecht, verbunden. Hier besteht, wie auch von
der Datenethikkommission angezeigt, Handlungsbedarf.113 Neben der F&#246;rderung eines freiwilligen Teilens von
Daten spielen f&#252;r die Verf&#252;gbarkeit von Daten auch Datenzugangsrechte eine wichtige Rolle. So wird diskutiert,
Unternehmen zu verpflichten, Daten zu teilen, wenn ein &#252;bergeordnetes &#246;ffentliches Interesse besteht, wie z. B. 
bei der Entwicklung unternehmens&#252;bergreifender, intelligenter Mobilit&#228;ts- und Energiel&#246;sungen.114 Des
Weiteren wird auch im Wettbewerbsrecht die zunehmende Bedeutung des Datenzugangs thematisiert und daran
anschlie&#223;end die Frage, ob marktbeherrschende Unternehmen im Sinne der F&#246;rderung von Wettbewerb und
Innovation dazu verpflichtet werden sollten, bestimmte Daten mit Wettbewerbern zu teilen.115 
Datenstandards
Datenstandards bef&#246;rdern die organisations&#252;bergreifende Nutzung von Daten und unterst&#252;tzen breite
Anwendungsm&#246;glichkeiten von bzw. Interoperabilit&#228;t zwischen KI-Systemen. Auch das Zusammenf&#252;hren von
Datens&#228;tzen aus unterschiedlichen Quellen wird mithilfe von Standards vereinfacht. Bei Open Data sollten
internationale Standards eingehalten werden und, wo notwendig, neue Standards etabliert werden. Gerade in der
Diskussion um den Einsatz von KI wird oft auf die Bedeutung von Datenqualit&#228;t verwiesen. Es kann, wie in Kapitel 2.2 
des Mantelberichts [Qualit&#228;t von Daten], beschrieben, jedoch keine allgemeing&#252;ltigen Standards f&#252;r
Datenqualit&#228;t geben, weil die Anforderungen an Trainingsdatens&#228;tze immer im konkreten Anwendungskontext zu
definieren sind. Hierf&#252;r gilt es ein entsprechendes Bewusstsein und Kompetenzen bei Anwenderinnen und Anwender
sowie Aufsichtsbeh&#246;rden zu schaffen. Angesichts der Bedeutung von Daten f&#252;r Training und Anwendung von 
KI-Systemen sind gegebenenfalls Vorgaben bzw. Dokumentationspflichten im Hinblick auf Herkunft, Struktur
113 Vgl. Datenethikkommission der Bundesregierung (2019): Gutachten der Datenethikkommission der Bundesregierung, S. 145. Die 
Datenethikkommission empfiehlt eine Weiterentwicklung der Rechtslage dahingehend, dass Datenpartnerschaften, beispielsweise
zum Zweck der Kooperation beim Datenaustausch oder beim Datenpooling, gepr&#252;ft werden.
114 Vgl. Datenethikkommission der Bundesregierung (2019): Gutachten der Datenethikkommission der Bundesregierung, S. 154.
115 Vgl. Schallbruch et al. (2019): Ein neuer Wettbewerbsrahmen f&#252;r die Digitalwirtschaft. Bericht der Kommission
Wettbewerbsrecht 4.0.
und Verwendung von Datens&#228;tzen beim Training von KI-Modellen zu entwickeln. Diese beschreiben dann auch
die Grenzen der Systeme und tragen so dazu bei, Anwendungsfehler zu vermeiden.
Dateninfrastrukturen
Verf&#252;gbarkeit und Standards bringen ohne Infrastrukturen zur Vorhaltung und Analyse von Daten wenig. Ob
einzelne B&#252;rgerinnen und B&#252;rger, kleine oder gro&#223;e Unternehmen oder Beh&#246;rden &#8211; seit vielen Jahren gibt es
einen starken Trend, diese Infrastrukturen nicht mehr selbst aufzubauen oder zu betreiben, sondern sie als ein
&#8222;Cloud-Angebot&#8220; von spezialisierten IT-Dienstleistern zu beziehen. Dabei ist eine gro&#223;e Abh&#228;ngigkeit von
ausl&#228;ndischen Cloud-Anbietern entstanden. Diese verbinden das Angebot zum Datenvorhalten mit dem Zugriff auf
innovative Werkzeuge zur Datenverarbeitung. So erm&#246;glichen die gro&#223;en Anbieter &#252;ber ihre Cloud-Infrastruktur
auch den Zugriff auf KI-Werkzeuge wie das Maschinelle Lernen. Die Abh&#228;ngigkeit von au&#223;erhalb der EU
ans&#228;ssigen Anbietern l&#228;sst sich nur durch Aufbau bzw. St&#228;rkung eigener Kompetenzen reduzieren. Hier verf&#252;gt die
Verwaltung in der Beschaffung &#252;ber einen wichtigen Hebel. Zus&#228;tzlich sollten Kompetenzen europ&#228;ischer
Unternehmen in diesem Bereich gest&#228;rkt werden. Mit der GAIA-X-Initiative hat die Bundesregierung eine
europ&#228;ische Initiative zum Aufbau einer vernetzten Dateninfrastruktur gestartet.116 Im Forschungsbereich soll der
Aufbau einer Nationalen Forschungsdateninfrastruktur Kompetenzen beim Forschungsdatenmanagement vernetzen 
und st&#228;rken.117 Beim Aufbau von Infrastrukturen ist auf nachhaltige Verwendung von Ressourcen zu achten
(siehe Kapitel 8 des Mantelberichts [KI und &#246;kologische Nachhaltigkeit]).
Datenschutz
Der wirtschaftliche und gesellschaftliche Nutzen von Daten und dem daraus ableitbaren Wissen sowie ihre
Bedeutung f&#252;r die F&#246;rderung innovativer KI-Anwendungen sind gro&#223;. Allerdings sind zugleich bei der Erhebung,
Speicherung, Weitergabe und Auswertung von Daten Grundrechte zwingend zu beachten. Das gilt nicht nur im
staatlichen Sicherheitsbereich, wo der rechtsstaatliche Schutz der B&#252;rgerinnen und B&#252;rger vor
unverh&#228;ltnism&#228;&#223;igen Grundrechtseingriffen zu gew&#228;hrleisten ist. Im privatwirtschaftlichen Bereich ist die DSGVO bei
personenbezogenen Daten einzuhalten (siehe Kapitel 5 des Mantelberichts [KI und Recht]). Datentreuh&#228;ndermodelle
sowie Datenassistenz oder -managementans&#228;tze bieten die Chance, die Verbesserung der pers&#246;nlichen Kontrolle 
&#252;ber Daten und die Verbesserung des Datenzugangs in Einklang zu bringen.118 Der technische Datenschutz, wie
z. B. dezentrales Lernen und Differential Privacy119, birgt ebenfalls gro&#223;es Potenzial, die Verbesserung von
Datenschutz und Datenverf&#252;gbarkeit miteinander zu vereinbaren. Bei der Anonymisierung von Datens&#228;tzen k&#246;nnen
KI-Systeme einen wichtigen Beitrag beim Erkennen und Ersetzen von personenbezogenen Informationen
leisten.120 Zur Frage, ob die Anonymisierung eines Datensatzes unter die DSGVO f&#228;llt, hat der Bundesbeauftragte
f&#252;r Datenschutz und Informationsfreiheit ein Konsultationsverfahren durchgef&#252;hrt.121 Rechtsunsicherheiten bei
Anonymisierungsprozessen sollten reduziert werden, indem hierf&#252;r eine ausdr&#252;ckliche Rechtsgrundlage
geschaffen wird. Diese und weitere Aspekte des Datenschutzes werden ausf&#252;hrlicher im Kapitel 5 des Mantelberichts
[KI und Recht] dargestellt.
Datensicherheit
Neben der Beachtung des Datenschutzrechts ist im Umgang mit Daten auch ihr Schutz vor unbefugtem Zugriff
zu beachten. Dabei sind zur IT-Sicherheit notwendige rechtliche und technische Standards einzuhalten und
weiterzuentwickeln. Der Schutz von Trainingsdaten und im Betrieb von KI-Systemen genutzten Daten ist notwendig,
um Integrit&#228;t und Funktionsf&#228;higkeit von KI-Systemen gew&#228;hrleisten zu k&#246;nnen. Eine vertiefte Befassung mit 
diesem Thema findet sich im Bericht der Projektgruppe &#8222;KI und Staat&#8220; in Kapitel C. III. [K&#252;nstliche Intelligenz
und Staat (Projektgruppe 2)].
116 Weitere Informationen dazu unter: https://www.bmwi.de/Redaktion/DE/Artikel/Digitale-Welt/dateninfrastruktur.html (zuletzt
abgerufen am 4. August 2020).
117 Weitere Informationen dazu unter: https://www.forschungsdaten.org/index.php/Nationale_Forschungsdateninfrastruktur_-
_NFDI#n.C3.A4chste_Termine (zuletzt abgerufen am 4. August 2020).
118 Vgl. Datenethikkommission der Bundesregierung (2019): Gutachten der Datenethikkommission der Bundesregierung, S. 135.
119 Unter Differential Privacy versteht man eine formal nachweisbare Privatheitsgarantie f&#252;r statistische Datenbanken.
120 Einen Ansatz, um Gesichter ohne Bezug zu real existierenden Personen generieren zu k&#246;nnen, kann man beispielsweise hier finden:
https://thispersondoesnotexist.com/ (zuletzt abgerufen am 4. August 2020).
121 Vgl. Der Bundesbeauftragte f&#252;r den Datenschutz und die Informationsfreiheit (2020): BfDI nutzt erstmals Konsultationsverfahren.
        
 
 
  
   
     
   
  
   
 
   
       
   
          
 
  
   
     
  
  
          
  
    
   
 
      
 
                                               
    
       
          
  
  
   
       
        
     
   
     
     
     
            
 
   
       
         
    
3
KI und Umgang mit Bias/Diskriminierung122 
Die Diskriminierung bestimmter Gruppen ist ein Ph&#228;nomen, das in unserer Gesellschaft und weltweit seit
Langem existiert. Mit Diskriminierung ist dabei eine ungerechtfertigte Benachteiligung oder Bevorzugung
gemeint.123 Auch KI-Systeme, die mit personenbezogenen Daten arbeiten, sind daher nicht automatisch frei von
Diskriminierung, sondern &#252;bernehmen bestehende Muster. Dies hat sich auch bereits in vielen F&#228;llen gezeigt, in
denen in verschiedenen L&#228;ndern bereits eingesetzte KI-Systeme wegen Diskriminierung kritisiert worden sind.124 
Um m&#246;gliche Diskriminierung beim Einsatz von KI zu verstehen, m&#252;ssen sowohl die technische Ebene der KI
als auch das Umfeld betrachtet werden, in dem sie eingesetzt wird.125 
Ein KI-System hat in der Regel einen gr&#246;&#223;eren Wirkungskreis als eine einzelne Person. Seine &#220;berpr&#252;fung bringt 
technische Herausforderungen mit sich, erm&#246;glicht aber potenziell eine h&#246;here Transparenz als bei menschlichen
Entscheidungen. Die Enquete-Kommission KI legt daher mit diesem Abschnitt ein besonderes Augenmerk auf
potenzielle Diskriminierung durch KI-Systeme und auf Handlungsbedarfe, um diese in gesellschaftlich
problematischen F&#228;llen und insbesondere bei Rechtsverst&#246;&#223;en zu verhindern.
Begriffskl&#228;rung Bias
In der Informatik bezeichnet man mit Bias ein Fehlverhalten, das auf einer systematischen Verzerrung beruht.126 
Da das Verhalten von KI-Systemen auf gelernten Zusammenh&#228;ngen basiert, ist in der Regel127 die
Beschaffenheit128 der daf&#252;r verwendeten Trainingsdaten f&#252;r den Bias in KI-Systemen urs&#228;chlich.
Wie in Kapitel 1 des Mantelberichts [Begriffskl&#228;rung K&#252;nstliche Intelligenz] beschrieben, garantieren KI-
Systeme kein fehlerfreies Verhalten. Dabei kann grunds&#228;tzlich weder zuf&#228;lliges noch systematisches Fehlverhalten
(also Bias) ausgeschlossen werden.129 In den meisten Anwendungsf&#228;llen spielt die Unterscheidung zwischen
diesen beiden Arten von Fehlverhalten keine praktische Rolle, solange das KI-System in der Gesamtbetrachtung 
eine akzeptable Qualit&#228;t gew&#228;hrleistet. Beispielsweise w&#228;re ein System, das handschriftliche Texte digitalisiert,
m&#246;glicherweise akzeptabel, obwohl es den Buchstaben &#223; systematisch als B erkennt, solange die Fehlerquote
insgesamt gering ist. 
122 Zu diesem Kapitel liegen Sondervoten aus der Fraktion der AfD [Sondervotum zu Kapitel 3 des Mantelberichts (&#8222;KI und Umgang 
mit Bias/Diskriminierung&#8220;) des Abgeordneten Dr. Marc Jongen sowie der Abgeordneten Joana Cotar und Peter Felser] sowie aus der
Fraktion der FDP [Sondervotum zu den Kapiteln 3 und 6.2.1 des Mantelberichts (&#8222; KI und Umgang mit Bias/Diskriminierung &#8220; und 
&#8222; Autonomie (Selbstbestimmung des Menschen als Handelnder, Entscheidungsfreiheit, Nicht-Manipulation)&#8220;) der Abgeordneten 
Mario Brandenburg, Carl-Julius Cronenberg, Daniela Kluckert und Jessica Tatti sowie der sachverst&#228;ndigen Mitglieder Dr. Aljoscha 
Burchardt und Andrea Martin] vor.
123 Siehe Kapitel 6 des Mantelberichts [Ethische Perspektiven auf KI].
124 Vgl. O'Neil (2016): Angriff der Algorithmen; Noble (2018): Algorithms of oppression.
125 Die Verwendung von KI-Systemen kann auch schon dadurch Ungleichheit erzeugen, dass nur bestimmte Gruppen von ihnen
betroffen sind. Das gilt z. B. f&#252;r algorithmische Systeme in den USA, die &#252;ber Sozialleistungen (mit-)entscheiden und damit haupts&#228;chlich
Arme und Arbeitslose betreffen, vgl. Eubanks (2018): Automating inequality.
126 Vgl. Datenethikkommission der Bundesregierung (2019): Gutachten der Datenethikkommission der Bundesregierung.
127 Nat&#252;rlich kann in der Interaktion mit dem KI-System immer auch der Mensch urs&#228;chlich f&#252;r Bias sein, beispielsweise durch
systematisch falsche Eingaben oder eine verzerrte Interpretation der Ergebnisse. Es ist dar&#252;ber hinaus aber auch m&#246;glich, dass auf einem
ausgewogenen Datensatz trainierte KI-Systeme diskriminierendes Verhalten zeigen.
128 Die Beschaffenheit betrifft sowohl die Quantit&#228;t der Daten (z. B. m&#252;ssen gen&#252;gend Daten auch zu Minderheiten vorliegen, um
Angeh&#246;rige dieser Minderheit beispielsweise in Anwendungen der Gesichtserkennung identifizieren zu k&#246;nnen) als auch die Qualit&#228;t 
(z. B. m&#252;ssen Daten aktuell und nicht-diskriminierend annotiert sein, um keine Diskriminierung zu reproduzieren).
129 Tats&#228;chlich ist das Erzeugen von Bias notwendig, um KI-Systemen das Generalisieren von Zusammenh&#228;ngen zu erm&#246;glichen,
vgl. Mitchell: The Need for Biases in Learning Generalizations.
Diskriminierung durch Bias130 
Anders verh&#228;lt es sich, wenn Bias zu Diskriminierung im rechtlichen131 und moralischen132 Sinne f&#252;hrt.
Diskriminierung entsteht also, wenn die Datenauswahl ein systematisches Fehlverhalten des KI-Systems hervorruft,
sodass Menschen aufgrund von &#228;u&#223;eren und inneren Pers&#246;nlichkeitsmerkmalen ungerechtfertigt bevor- oder
benachteiligt werden.133 Im Folgenden werden mittels Beispielen einige g&#228;ngige Ursachen f&#252;r datenbasierten Bias
von KI-Systemen beschrieben, der zu Diskriminierung f&#252;hrt.
a) Fehlende Diversit&#228;t: Ein KI-System zur Erkennung von Gesichtern ben&#246;tigt Trainingsdaten, die die
Vielfalt der zu erkennenden Personen abbilden. Personengruppen, die in den Trainingsdaten wenig oder nicht
repr&#228;sentiert sind, werden m&#246;glicherweise schlechter erkannt134 und k&#246;nnen dadurch beispielsweise beim
Einsatz des KI-Systems bei der automatisierten Passkontrolle diskriminiert werden.
b) Reproduzierte Diskriminierung: Ein KI-System, das zur automatisierten Vorauswahl von Bewerberinnen
und Bewerbern eingesetzt wird, lernt im Training die Auswahlkriterien basierend auf den in den Daten
repr&#228;sentierten menschlichen Entscheidungen aus der Vergangenheit. Hat der Mensch im urspr&#252;nglichen 
Auswahlprozess diskriminiert, wird das KI-System m&#246;glicherweise dieses Verhalten reproduzieren135 und 
somit die vorher bestehende Diskriminierung fortsetzen.
c) Fairnesskonflikte: Es gibt ca. zwei Dutzend mathematische Formeln, mit denen die Fairness von
algorithmischen Entscheidungen gemessen wird; jede entspricht einer bestimmten Idee von Gerechtigkeit. Diese
k&#246;nnen &#8211; wie andere Gerechtigkeitsanspr&#252;che auch &#8211; miteinander unvereinbar sein136 und dann nicht
gleichzeitig eingehalten werden. Ein Beispiel daf&#252;r wurde von dem journalistischen Thinktank ProPublica
aufgedeckt: Ein System zur Vorhersage des R&#252;ckf&#228;lligkeitsrisikos irrte sich deutlich h&#228;ufiger bei
Afroamerikanerinnen und Afroamerikanern zu deren Ungunsten als bei wei&#223;en Amerikanerinnen und Amerikanern &#8211;
dies ist sicherlich nicht fair. Die Softwareentwickler wiesen darauf hin, dass sie darauf achteten, dass eine
Risikoklasseneinordnung f&#252;r alle Bev&#246;lkerungsgruppen dasselbe bedeutet. Eine Hochrisikoklassifizierung
soll also f&#252;r alle Personen dieselbe R&#252;ckf&#228;lligkeitsgefahr anzeigen: Wenn 60 Prozent der gesamten Gruppe
nachher r&#252;ckf&#228;llig werden, soll dies auch f&#252;r alle Teilgruppen gelten und keine der Teilgruppen prozentual
davon zu weit abweichen. Auch das ist eine wichtige Forderung, damit dieselbe Aussage der Maschine
statistisch auch dieselbe Interpretation zul&#228;sst und nicht von weiteren Eigenschaften abh&#228;ngt. Es konnte
gezeigt werden, dass diese beiden Ziele nicht miteinander vereinbar sind &#8211; es liegt ein Fairnesskonflikt vor.
Erkennung von Diskriminierung
Diskriminierung ist nicht immer leicht zu erkennen, speziell wenn sie auf einer Kombination verschiedener
expliziter und impliziter Merkmale basiert.137 Technisch gesehen werden Diskriminierungen &#252;ber die Berechnung
von sogenannten Fairnessma&#223;en entdeckt. Diese beruhen wiederum auf Qualit&#228;tsma&#223;en der Entscheidungen, die
von einer Maschine basierend auf einem Testdatensatz getroffen werden. 
130 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 3.2 des Mantelberichts
(&#8222;Diskriminierung durch Bias &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian
Butollo].
131 Vgl. Artikel 21 der Charta der Grundrechte der Europ&#228;ischen Union (Nicht-Diskriminierung) sowie Artikel 3 des Grundgesetzes und 
das Allgemeine Gleichbehandlungsgesetz (AGG).
132 Siehe auch Kapitel 6 des Mantelberichts [Ethische Perspektiven auf KI].
133 Nicht jede Ungleichbehandlung ist ungerechtfertigt (und somit diskriminierend), beispielsweise wenn Ungleichbehandlung dazu 
f&#252;hrt, dass sch&#252;tzenswerte Minderheiten, z. B. Behinderte, einen besonderen Schutz erfahren.
134 Die Ursachen unterschiedlicher Erkennungsraten basierend auf Hautfarbe und Geschlecht wurden beispielsweise durch Boulamwini
und Gebru (2018): Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification beschrieben.
135 Die Diskriminierung von Bewerberinnen bzw. Bewerbern basierend auf ihrem Geschlecht wurde beispielsweise in folgender
Publikation beschrieben: Kodiyan (2019): An overview of ethical issues in using AI systems in hiring with a case study of Amazon&#8217;s AI
based hiring tool.
136 Ein Beispiel f&#252;r einen Fairnesskonflikt aus der analogen Welt betrifft beispielsweise die Frage, ob Sozialleistungen wie das
Kindergeld an alle Eltern gleicherma&#223;en ausgezahlt werden sollen oder ob z. B. Geringverdienende st&#228;rker unterst&#252;tzt werden sollten.
137 Beispielsweise w&#228;re ein System denkbar, das zwar weder in Bezug auf das Geschlecht noch die Hautfarbe noch das Alter
diskriminiert, aber dennoch afroamerikanische junge Frauen benachteiligt.
Beispielsweise kann die Qualit&#228;t eines KI-Systems daran gemessen werden, wie viele Entscheidungen f&#252;r ein
Testdatenset von der Maschine korrekt getroffen wurden. &#8222;Korrekt&#8220; hei&#223;t hierbei z. B., dass die Maschine
vorhersagt, dass eine Person aufgrund ihrer Eigenschaften vermutlich einen Kredit zur&#252;ckzahlen wird und eine
andere nicht. Wenn dann in dem Testdatensatz &#8211; der aus der Vergangenheit stammt &#8211; die erste Person auch wirklich
den Kredit zur&#252;ckgezahlt hat und die zweite nicht, gelten die Entscheidungen als korrekt. 
Ein korrespondierendes Fairnessma&#223; w&#252;rde verlangen, dass die Qualit&#228;t der Entscheidungen f&#252;r alle
Bev&#246;lkerungsgruppen nach ihrer sensitiven Eigenschaft getrennt (Geschlecht, Religion etc.) nicht zu stark voneinander
abweicht. Eine Bank sollte also &#8211; wenn die Entscheidungen eines Kreditnehmerbewertungssystems auf der Basis
eines Testdatensatzes zu 80 Prozent korrekt sind &#8211; pr&#252;fen, ob die Fehleranf&#228;lligkeit der Entscheidungen auch f&#252;r
Kundinnen und Kunden ungef&#228;hr gleich ist, wenn sie nach Geschlechtergruppen eingeteilt werden. Sollten die
Entscheidungen f&#252;r z. B. Frauen deutlich &#246;fter zutreffen als f&#252;r M&#228;nner, h&#228;tten letztere weniger Zugang zu
Krediten, als aufgrund ihrer Zahlkraft m&#246;glich w&#228;re. 
Es ist wichtig zu bemerken, dass es meistens nicht m&#246;glich ist, die Qualit&#228;t oder die Fairness eines KI-Systems
beliebig zu maximieren. Oftmals stehen sie miteinander in direktem Konflikt. Zudem gibt es auch unter den
Fairnessma&#223;en mindestens zwei Dutzend,138 die auch miteinander in Konflikt stehen k&#246;nnen.139 Daher ist der
wichtigste Schritt bei der Vermeidung von Diskriminierung eine genaue Definition des Fairnessma&#223;es, das zu
ihrer Entdeckung verwendet werden soll. 
Vermeidung von Diskriminierung
Auch die Vermeidung erkannter Diskriminierung ist nicht immer einfach zu gew&#228;hrleisten. Im Folgenden werden
einige Vermeidungsstrategien f&#252;r die beschriebenen Arten von Bias aus dem letzten Abschnitt diskutiert:
a) Vermeidung von Diskriminierung durch fehlende Diversit&#228;t: In Deutschland werden oft keine
Informationen zu Religion, Hautfarbe, politischer Orientierung oder anderen Merkmalen erhoben, aufgrund derer
Diskriminierung stattfinden k&#246;nnte. Sind diese Daten nicht vorhanden, kann man sie zur Fairnesstestung
von KI auch nicht benutzen, obwohl eine Diskriminierung stattfindet. Wenn beispielsweise eine Bewerberin
oder ein Bewerber aufgrund der Herkunft nicht zu einem Bewerbungsgespr&#228;ch eingeladen wird, diese
Variable bei der Fairnesspr&#252;fung aber nicht zur Verf&#252;gung steht, bleibt die Diskriminierung verborgen. Im
oben beschriebenen Beispiel zur Gesichtserkennung k&#246;nnte die erfolgreiche Vermeidung von
Diskriminierung auf der Beschaffung oder Generierung weiterer Daten f&#252;r unterrepr&#228;sentierte Personengruppen
beruhen, sodass alle Gruppen gleich gut erkannt werden. Sollte dies nicht m&#246;glich sein, lie&#223;e sich auch die
Datenbasis f&#252;r &#252;berrepr&#228;sentierte Personengruppen verringern, um zu erreichen, dass alle Personengruppen
gleich schlecht erkannt werden, was allerdings nat&#252;rlich zulasten der Qualit&#228;t der Voraussagen geht.
b) Vermeidung von reproduzierter Diskriminierung: &#196;hnlich wie in Beispiel a ist auch bei dem Beispiel
zur Bewerberauswahl die Beschaffung weiterer Daten ein geeignetes Mittel zur Vermeidung von Bias,
solange es sich um Daten handelt, die diese Art der Diskriminierung nicht enthalten. In der Praxis ist dies
allerdings in den meisten F&#228;llen nicht ohne Weiteres m&#246;glich. Alternativ k&#246;nnte man hier das bestehende
System aber auch nutzen, um getrennte Rankings f&#252;r jede Personengruppe zu erstellen (also z. B. je ein
Ranking f&#252;r M&#228;nner und Frauen) und basierend darauf aus jeder Gruppe eine gleiche Zahl von Personen
ausw&#228;hlen. Dadurch w&#252;rde also trotz des datenbasierten Bias im Verhalten des trainierten Modells ein KI-
System erstellt werden, das Diskriminierung zwischen Personengruppen vermeidet. 
c) Vermeidung von Fairnesskonflikten: Auch bei den R&#252;ckfallquoten f&#252;r Straft&#228;terinnen und Straft&#228;ter
k&#246;nnte m&#246;glicherweise eine der unter a und b beschriebenen Ma&#223;nahmen helfen, die Diskriminierung zu
mindern. Allerdings zeigt gerade dieses Beispiel auch die in Kapitel 3.3 des Mantelberichts [Erkennung von 
Diskriminierung] dargestellten Grenzen der technischen Diskriminierungsvermeidung auf. Es ist n&#228;mlich
nicht vordergr&#252;ndig eine technische Frage, ob es besser ist, den Gesamtfehler des Systems zu minimieren,
oder ob man eine h&#246;here Fehlerquote akzeptiert, um eine h&#246;here Fairness herzustellen, sondern eine, die
diejenigen treffen, die das KI-System anwenden wollen. Es ist in der Regel nicht m&#246;glich, alle gew&#252;nschten 
Fairnessma&#223;e zu ber&#252;cksichtigen, ohne gleichzeitig ungew&#252;nschte Nebeneffekte in Kauf zu nehmen, wie
beispielsweise die erw&#228;hnten Qualit&#228;tseinbu&#223;en.140 
138 Vgl. beispielsweise Barocas et al. (2019): Fairness and Machine Learning Kapitel 2.
139 Vgl. Kleinberg et al. (2017): Inherent Trade-Offs in the Fair Determination of Risk Scores.
140 Eine detaillierte Diskussion m&#246;glicher Konflikte findet sich bei Corbett-Davies und Goel (2018): The Measure and Mismeasure of
Fairness: A Critical Review of Fair Machine Learning.
Wie aus Beispiel c hervorgeht, ist es ein grunds&#228;tzliches Problem bei der Vermeidung von Diskriminierung, dass
es oft &#8211; sofern nicht durch das Rechtssystem vorgegeben &#8211; keine allgemein akzeptierte Definition von Fairness
gibt. Wie in den Kapiteln 3 [KI und Umgang mit Bias/Diskriminierung] und 5 [Ethische Perspektiven auf KI] 
des Mantelberichts, gezeigt, muss die normative Vorgabe dazu aus einem interdisziplin&#228;ren und
gesellschaftlichen Diskurs kommen. Eine gemeinsame Definition von Fairness ist insbesondere im globalen Kontext
offenkundig schwer zu finden.
Handlungsempfehlungen141 
1. Zu Diskriminierungserkennung und -vermeidung in KI-Systemen wurde in den letzten Jahren viel
geforscht.142 Der n&#228;chste Schritt, der Transfer dieser Erkenntnisse in den Software-Entwicklungsalltag, sollte
gef&#246;rdert werden, damit die Erkenntnisse m&#246;glichst schnell und breit umgesetzt werden k&#246;nnen und durch
Forschung begleitet werden. 
2. Im Rahmen der Ma&#223;nahmen f&#252;r breite gesellschaftliche Bildung (Schule, Ausbildung, Beruf) muss das
Verst&#228;ndnis f&#252;r die Funktionsweise von Algorithmen und KI-Systemen gezielt in alle Bildungsbereiche
integriert werden.143 
3. Individuen m&#252;ssen in der Lage sein, sich gegen Diskriminierung durch KI genauso zur Wehr zu setzen wie
in anderen F&#228;llen. Um dies sicherzustellen, braucht es, wenn KI &#252;ber Menschen urteilt, einen Anspruch auf
Transparenz, Nachvollziehbarkeit und Erkl&#228;rbarkeit von KI-Entscheidungen, damit eine gerichtliche
&#220;berpr&#252;fung automatisierter Entscheidungen m&#246;glich ist.
4 KI und Umgang mit Risiko144 
Der Umgang mit Risiken ist ein h&#228;ufig diskutiertes Thema, wenn es um den Einsatz von KI-Systemen geht. In 
diesem Abschnitt soll kurz in das Thema Risikomanagement eingef&#252;hrt und es sollen KI-spezifische Aspekte
und Ans&#228;tze diskutiert werden.
Begriffskl&#228;rung Risiko
Unter einem Risiko versteht man im Allgemeinen einen m&#246;glichen negativen Ausgang einer Unternehmung, der
mit Nachteilen, Verlusten oder Sch&#228;den verbunden ist.145 Solche Unternehmungen k&#246;nnen also verschiedene
Ausg&#228;nge nehmen, bei denen einige unerw&#252;nscht sind oder unerw&#252;nschte Nebeneffekte haben. Risiken sind 
dementsprechend immer verbunden mit Unsicherheiten bez&#252;glich des Schadenseintritts und des konkreten
Ausgangs. Erw&#228;hnenswert ist in diesem Zusammenhang, dass auch das Unterlassen eine risikobehaftete
Unternehmung sein kann, wenn dadurch negative Folgen m&#246;glich sind.146 
Der Umgang mit Risiken wird oft als Risikomanagement bezeichnet und ist u. a. durch die ISO-Norm 31000147
standardisiert. Der Standard definiert dabei, in welcher Art Risiken beurteilt und gesteuert werden. 
Bei der Risikobeurteilung werden risikobasierte Ereignisse in Bezug auf ihre Auswirkung und ihre
Wahrscheinlichkeit bewertet, typischerweise als Produkt aus Eintrittswahrscheinlichkeit eines Schadens und Schadensh&#246;he.
Auswirkungen von Risiken k&#246;nnen je nach Kontext sehr unterschiedlich sein und z. B. finanzielle Einbu&#223;en,
141 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 3.5 des Mantelberichts
(&#8222;Handlungsempfehlungen &#8220; zu &#8222;KI und Umgang mit Bias/Diskriminierung &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des
sachverst&#228;ndigen Mitglieds Dr. Florian Butollo].
142 Auf Google Scholar sind &#252;ber 30 000 wissenschaftliche Artikel seit dem Jahr 2016 gelistet, die die W&#246;rter &#8222;discrimination&#8220;, &#8222;AI&#8220;
und &#8222;algorithm&#8220; enthalten. Zudem gibt es seit dem Jahr 2018 eine eigene Konferenz der renommierten ACM dazu, die &#8222;ACM
Conference on Fairness, Accountability and Transparency&#8220; (ACM FAccT). Das BMBF f&#246;rdert dazu das Projekt &#8222;Fair and Good ADMs&#8220;, 
das erforscht, welche politischen Prozesse zu fairen und qualitativ hochwertigen KI-Systemen f&#252;hren k&#246;nnen, wenn der Staat diese
entwickelt, einkauft oder einsetzt.
143 Siehe auch den Bericht der Projektgruppe &#8222;KI und Staat&#8220; in Kapitel C. III. [K&#252;nstliche Intelligenz und Staat (Projektgruppe 2)], den 
Bericht der Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220; in Kapitel C. V. [K&#252;nstliche Intelligenz und Arbeit (Projektgruppe 4)]
und das Kapitel 7 des Mantelberichts [KI und Gesellschaft].
144 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion der SPD vor [Sondervotum zu Kapitel 4 des Mantelberichts (&#8222;KI und
Umgang mit Risiko &#8220;) der Abgeordneten Daniela Kolbe, Elvan Korkmaz-Emre, Falko Mohrs, Ren&#233; R&#246;spel und Jessica Tatti sowie
der sachverst&#228;ndigen Mitglieder Dr. Florian Butollo, Prof. Dr.-Ing. Sami Haddadin, Jan Kuhlen, Lena-Sophie M&#252;ller und Lothar
Schr&#246;der].
145 Vgl. Duden: Risiko.
146 Analog dazu &#167; 13 Strafgesetzbuch (StGB), der &#8222;Begehen durch Unterlassen&#8220; beschreibt.
147 Vgl. iso.org: ISO 31000.
Komfortverlust, Stabilit&#228;t von Wirtschaftssystemen, Einschr&#228;nkung von Rechten oder k&#246;rperliche Sch&#228;den
umfassen.
Basierend auf dieser Beurteilung werden in der Risikosteuerung Ma&#223;nahmen definiert, die diese Risiken z. B. 
vermeiden oder sowohl die Eintrittswahrscheinlichkeit als auch die Auswirkungen vermindern, aber auch
Ma&#223;nahmen, die die Risiken transferieren oder akzeptieren.
Transparenz, Nachvollziehbarkeit und Erkl&#228;rbarkeit
Wie in Kapitel 1 des Mantelberichts [Begriffskl&#228;rung K&#252;nstliche Intelligenz] beschrieben, sind bei KI-Systemen
die gelernten Zusammenh&#228;nge oft nicht direkt zug&#228;nglich &#8211; dies wird oft auch als Black-Box-Problematik
bezeichnet &#8211;, da sie nicht wie bei klassischen Algorithmen in Form von menschenlesbaren Regeln existieren,
sondern in ihren derzeitigen Auspr&#228;gungen lediglich als komplexe Berechnungsvorschriften vorliegen, deren
Auspr&#228;gung ma&#223;geblich von den f&#252;r das Lernen genutzten Daten abh&#228;ngt. Deshalb werden im Kontext von KI-
basierten Risiken h&#228;ufig Transparenz, Nachvollziehbarkeit und Erkl&#228;rbarkeit von diesen Systemen thematisiert. 
In der Praxis werden diese Begriffe oft synonym verwendet. Sie beziehen sich aber auf verschiedene Aspekte der
Offenlegung, die im Weiteren grundlegend definiert werden.
Transparenz bezieht sich auf die Frage nach dem &#8222;Was&#8220;. Sie hat zum Ziel, den Einsatz von KI-Komponenten 
in einem System erkennbar zu machen und seine relevanten Eigenschaften zu beschreiben. Dies kann
Informationen &#252;ber die G&#252;te der Komponenten, die Art und Menge der zum Training genutzten Daten sowie Ma&#223;nahmen
zur Qualit&#228;tssicherung und Kontrolle umfassen. Diese Kenntnis ist notwendig, um eine bewusste Entscheidung
&#252;ber die Nutzung des KI-Systems zu erm&#246;glichen. 
Nachvollziehbarkeit bezieht sich in diesem Zusammenhang auf die M&#246;glichkeit, die transparent gemachten
Eigenschaften eigenst&#228;ndig und unabh&#228;ngig &#252;berpr&#252;fen zu k&#246;nnen. Daf&#252;r ist es typischerweise notwendig,
Zugang zu Systemschnittstellen zu schaffen, um das Verhalten des Systems mit eigenen Eingaben und Interaktionen
zu validieren.
Erkl&#228;rbarkeit bezieht sich auf die Frage nach dem &#8222;Warum&#8220;. Durch sie kann das Verhalten der KI-
Komponenten und ihr Zusammenspiel in einer konkreten Situation verstanden werden. Diese Kenntnis erm&#246;glicht es,
Entscheidungen des KI-Systems auf ihre Einflussfaktoren zur&#252;ckzuf&#252;hren und so die Ursache von einzelnen
Entscheidungen nachzuvollziehen. 
Der Grad der Erkl&#228;rbarkeit ist stark von den jeweils eingesetzten Komponenten abh&#228;ngig. Dabei ist zu beachten, 
dass KI-Komponenten mit einem geringen Grad an Erkl&#228;rbarkeit in den meisten F&#228;llen die h&#246;here Qualit&#228;t zeigen
und oft nicht ad&#228;quat ersetzt werden k&#246;nnen, weil besser erkl&#228;rbare Alternativen mit den ben&#246;tigten
Funktionalit&#228;ten oder Qualit&#228;tseigenschaften nicht existieren. Die Erkl&#228;rbarkeit von KI-Systemen h&#228;ngt aber auch vom
Grad der Expertise der begutachtenden Person ab, da mit dem Verst&#228;ndnis &#252;ber die Wirkweise der jeweiligen
KI-Komponente auch die F&#228;higkeit steigt, das Verhalten verstehen zu k&#246;nnen. Deshalb wurde die Erkl&#228;rbarkeit
von KI-Systemen als ein wichtiges Forschungsgebiet identifiziert, das in Deutschland gezielt gef&#246;rdert wird.148 
Sch&#228;den durch Fehlentscheidungen oder Diskriminierung lassen sich daher f&#252;r die oder den Einzelnen oder f&#252;r
die Interessensvertretungen nur schwer nachvollziehen und k&#246;nnten eventuell verbessert werden, wenn ihnen
Einsicht in die Verwendung und Entscheidungslogik des KI-Systems gew&#228;hrt w&#252;rde. Gleichzeitig er&#246;ffnet der
Einsatz von KI-Systemen im Vergleich zu Menschen zus&#228;tzliche M&#246;glichkeiten der Nachvollziehbarkeit, weil
trainierte Systeme sich einfach automatisiert testen lassen und bei dieser &#220;berpr&#252;fung ihr Verhalten nicht
ver&#228;ndern. 
Die f&#252;r Transparenz, Nachvollziehbarkeit und Erkl&#228;rbarkeit notwendige Offenlegung von Implementierungsdetails
und Zug&#228;ngen zu KI-Systemen, ihren KI-Komponenten wie Modellen, Trainingsroutinen und zum Lernen
verwendeten Daten geht in vielen F&#228;llen allerdings auch mit der Offenlegung von Betriebs- und Gesch&#228;ftsgeheimnissen149, 
beh&#246;rdlichen Geheimnissen150 und schutzbed&#252;rftigen Daten151 einher. Zudem kann die vollst&#228;ndige Ver&#246;ffentlichung 
148 Vgl. Bekanntmachung der Richtlinie zur F&#246;rderung von Projekten zum Thema &#8222;Erkl&#228;rbarkeit und Transparenz des Maschinellen 
Lernens und der K&#252;nstlichen Intelligenz&#8220; vom 14. M&#228;rz 2019, Bundesanzeiger vom 4. April 2019.
149 Betriebsgeheimnisse umfassen technisches Wissen, Gesch&#228;ftsgeheimnisse umfassen kaufm&#228;nnisches Wissen; beide sind f&#252;r den 
wirtschaftlichen Erfolg eines Unternehmens ma&#223;geblich.
150 Zu den beh&#246;rdlichen Geheimnissen geh&#246;rt beispielsweise das Wissen &#252;ber die Methoden der Strafverfolgung, das von potenziellen 
T&#228;terinnen und T&#228;tern genutzt werden k&#246;nnte.
151 Schutzbed&#252;rftige Daten sind beispielsweise personenbezogene oder urheberrechtlich gesch&#252;tzte Daten sowie Daten, die durch ihre 
Ver&#246;ffentlichung an Wert verlieren.
von Algorithmen oder der freie Zugang zu Daten neben den positiven Auswirkungen der Erkl&#228;rbarkeit, Transparenz
und Nachvollziehbarkeit durchaus auch f&#252;r die Gesellschaft ungewollte Folgen haben, z. B. in Bezug auf die
Privatheit.
In der Praxis wird der Zugang deshalb &#252;blicherweise nur einem begrenzten Personenkreis152 erm&#246;glicht, der &#252;ber
die notwendige Expertise zur Begutachtung verf&#252;gt und sich zur Geheimhaltung verpflichtet. Der erforderliche
Grad an Transparenz, Nachvollziehbarkeit und Erkl&#228;rbarkeit ist dabei immer eine Abw&#228;gung zwischen den
berechtigten Interessen an der Offenlegung einerseits und dem Informationsschutz andererseits. Die Definitionen 
von Transparenz, Nachvollziehbarkeit und Erkl&#228;rbarkeit sind dementsprechend nicht als grunds&#228;tzliche
Anforderungen f&#252;r den Einsatz von KI-Systemen im Allgemeinen zu verstehen. Die jeweils gestellten Anforderungen
sollten stattdessen auf einer sektor- und anwendungsspezifischen Bewertung beruhen.
Sektorspezifisches Risikomanagement
Basierend auf dem allgemeinen Rahmen f&#252;r Risikomanagement werden Systeme in vielen Industriesektoren
einer Risikobeurteilung unterzogen und dabei in Risikoklassen eingeteilt. 
Die Risikoklassifizierung erfolgt auf der Grundlage unterschiedlicher Kriterien wie beispielsweise der Gefahr 
f&#252;r Menschen, der Gefahr f&#252;r das Wirtschaftssystem oder der Gefahr des Verlusts der Geldanlage. Auch f&#252;r die
Einstufung sind sektorabh&#228;ngig unterschiedliche Akteure verantwortlich. In einfachen F&#228;llen ist dies oft der
Hersteller selbst. Je h&#246;her die Risikoklasse ist, desto unabh&#228;ngiger muss die beurteilende Instanz sein. 
Ausgehend von dieser Risikobeurteilung werden f&#252;r die verschiedenen Risikoklassen dann unterschiedliche
Ma&#223;nahmen zur Risikosteuerung definiert. Hier kann es sich beispielsweise um Sicherheitsvorschriften handeln, 
die umgesetzt werden m&#252;ssen und deren Einhaltung regelm&#228;&#223;ig und nach bestimmten Kriterien &#252;berpr&#252;ft wird. 
F&#252;r die Prozessindustrie153 gilt beispielsweise die Sicherheitsnorm IEC 61511, die das Risikomanagement f&#252;r
den Einsatz von elektrischen, elektronischen und programmierbar elektronischen Ger&#228;ten in Industrieanlagen
regelt.154 Das Risiko wird hier &#8211; basierend auf dem Ausma&#223; des m&#246;glichen finanziellen Schadens, der Zeitdauer
des Aufenthalts von Personen im Gefahrenbereich, der M&#246;glichkeit der Gefahrenabwehr und der
Eintrittswahrscheinlichkeit &#8211; in vier Risikoklassen unterteilt (SIL1 &#8211; SIL4). F&#252;r jede dieser Risikoklassen gelten
dementsprechend spezifische Auflagen. Diese k&#246;nnen bei SIL1 von einer unabh&#228;ngigen Einzelpersonen &#252;berwacht werden
und bei SIL2 von einer unabh&#228;ngigen Abteilung. Ab SIL3 muss das Unternehmen eine Organisation wie den
T&#220;V mit der &#220;berwachung beauftragen. 
Ein weiteres Beispiel ist die Aufsicht &#252;ber Versicherungsunternehmen und Pensionsfonds durch die
Bundesanstalt f&#252;r Finanzdienstleistungsaufsicht (BaFin). Diese teilt die betreffenden Finanzdienstleister in vier
Risikoklassen (A &#8211; D) ein und richtet daran die Intensit&#228;t ihrer Aufsicht aus.155 Die Hauptkriterien f&#252;r die Einteilung sind
dabei die Marktauswirkung des Unternehmens und dessen Qualit&#228;t. Dar&#252;ber hinaus werden
Versicherungsunternehmen durch die BaFin zus&#228;tzlich bez&#252;glich ihrer T&#228;tigkeit gruppenweise156 in Risikoklassen unterteilt.
Auch f&#252;r Medizinprodukte gibt es eine spezifische Risikoklassifizierung, bei der die entsprechenden
Risikoklassen EU-weit &#252;ber die Verordnung (EU) 2017/745157 definiert sind. Diese umfasst vier Klassen (I, IIa, IIb, III).
Die Zuordnung richtet sich nach der Verletzbarkeit des menschlichen K&#246;rpers und basiert u. a. auf der Dauer der
Anwendung und dem Grad der Invasivit&#228;t. Daraus abgeleitet ergeben sich f&#252;r jede der Klassen unterschiedliche
Anforderungen an die Zulassungsverfahren.
Weitere Risikoklassifizierungen finden sich in nahezu allen Bereichen. Wie in den beschriebenen Beispielen gilt 
f&#252;r die meisten, dass sie nicht den Einsatz spezifischer Technologien regeln oder beschr&#228;nken, sondern sich
unabh&#228;ngig von der konkreten Art der Umsetzung auf die Gefahrentiefe und -wahrscheinlichkeit beziehen und dass
sich hieraus Ma&#223;nahmen zu Aufsicht, Einsatz und Kontrolle ableiten lassen. 
152 Dies k&#246;nnen z. B. Gutachterinnen und Gutachter oder auch Zertifizierungsstellen sein.
153 Die Prozessindustrie umfasst u. a. Unternehmen aus den Bereichen Chemie, Pharmazie und Lebensmittelherstellung.
154 F&#252;r eine detaillierte Erkl&#228;rung sei hier auf die Brosch&#252;re von Siemens verwiesen: https://www.automation.siemens.com/w1/efiles/au-
tomation-technology/pi/sil/sil_broschuere_de.pdf (zuletzt abgerufen am 4. August 2020).
155 Die beschriebene Vorgehensweise der BaFin wird auf folgender Seite im Detail erl&#228;utert: https://www.bafin.de/DE/Publikationen-
Daten/Jahresbericht/Jahresbericht2016/Kapitel4/Kapitel4_2/Kapitel4_2_1/kapitel4_2_1_node.html (zuletzt abgerufen am 4. August
2020).
156 Dies geschieht auf Grundlage der EU-Direktive 2009/138/EC, beschrieben unter: https://www.bafin.de/DE/Aufsicht/VersichererPen-
sionsfonds/Aufsichtsregime/SolvencyII/solvency_II_node.html (zuletzt abgerufen am 4. August 2020).
157 Verordnung (EU) 2017/745 vom 5. April 2017 &#252;ber Medizinprodukte.
KI-spezifisches Risikomanagement158 
F&#252;r KI-Systeme wird momentan die Notwendigkeit von sektoren&#252;bergreifendem Risikomanagement diskutiert, 
das KI-spezifische Schadenspotenziale adressieren soll. Die durch die Bundesregierung eingesetzte
Datenethikkommission (DEK) empfiehlt in ihrem Abschlussbericht159 die Entwicklung einer EU-Verordnung f&#252;r
algorithmische Systeme160 und schl&#228;gt eine Klassifizierung in f&#252;nf Kritikalit&#228;ts-Stufen vor.161 Diese richten sich nach
dem Sch&#228;digungspotenzial der Anwendung. 
Auch im Wei&#223;buch der Europ&#228;ischen Kommission zur K&#252;nstlichen Intelligenz162 wird ein solcher
Kritikalit&#228;tsansatz gefordert. Im Unterschied zur Kritikalit&#228;tspyramide der Datenethikkommission sollen hier nicht
&#8222;algorithmische Systeme&#8220;, sondern KI-Anwendungen163 auf ihre Kritikalit&#228;t gepr&#252;ft werden. Die EU-Kommission ist
im Gegensatz zur DEK der Ansicht, dass sowohl der Sektor als auch die beabsichtigte Verwendung der KI-
Anwendung in diesem Sektor164 betrachtet werden sollten, wenn es um die Risikobewertung unter den
Gesichtspunkten Sicherheit, Verbraucherrechte und Grundrechte geht. Diese Risikoklassifizierung erfolgt dann in zwei
Klassen, eine Anwendung ist entweder eine Anwendung mit &#8222;hohem Risiko&#8220; oder eine Anwendung &#8222;ohne hohes
Risiko&#8220;. Wenn die KI-Anwendung als Hochrisikoanwendung klassifiziert ist, muss ein umfangreicher Katalog 
an Anforderungen erf&#252;llt werden, um eine Anwendung in der Praxis zu realisieren. Au&#223;erdem wird in dem
Wei&#223;buch ein nationales und europ&#228;isches Netzwerk von Regulierungsbeh&#246;rden bei KI-Systemen mit einem &#8222;hohem
Risiko&#8220; gefordert. Dabei soll u. a. an bestehende vertikale beh&#246;rdliche Strukturen angekn&#252;pft werden.
Auch in anderen L&#228;ndern werden M&#246;glichkeiten der Bewertung und Einstufung von algorithmischen Systemen 
entwickelt, h&#228;ufig mit einer differenzierten Betrachtungsweise, die die Vielzahl potenzieller Algorithmen sowie
die M&#246;glichkeit abbilden, diese zu kombinieren und weiterzuentwickeln.165
Die M&#246;glichkeit einer pauschalen Kritikalit&#228;tseinstufung von KI-Systemen vor ihrem Einsatz ist durch ihren 
Status als Werkzeug, unterst&#252;tzende Software und Entscheidungshilfe in einem spezifischen Einsatzkontext
begrenzt. Erst die Betrachtung des individuellen Anwendungskontextes und der individuellen Einsatzumgebung
erlauben eine umfassende Bewertung der mit dem Gebrauch von Algorithmen und KI-Systemen einhergehenden
Kritikalit&#228;t.
Um ein ganzheitliches Bild der Risikolandschaft zeichnen zu k&#246;nnen, ist es in diesem Prozess dar&#252;ber hinaus
sinnvoll, das kontextspezifische Referenzszenario einzubeziehen, in dem kein KI-System zum Einsatz kommt.
Denn oftmals bestehen in den Einsatzszenarien auch ohne den Einsatz von KI bereits Risiken (ggf. sogar gr&#246;&#223;ere
als mit dem Einsatz von KI), die ebenso bewertet werden m&#252;ssen. Zudem m&#252;ssen auch die
Eintrittswahrscheinlichkeit von Risiken und der jeweilige Nutzen des KI-Einsatzes gegen&#252;ber dem Risiko abgewogen werden. Auch
der begleitende Prozess des Einsatzes von KI-Systemen kann f&#252;r eine umfassende Kritikalit&#228;tsabsch&#228;tzung
relevant sein. Bei der verpflichtenden Einf&#252;hrung einer solchen Absch&#228;tzung in Form eines Pr&#252;fprozesses sind
zudem Aufwand und Kosten, insbesondere f&#252;r KMU und Start-ups, sowie die Auswirkung auf die allgemeine
Innovationsf&#228;higkeit der Unternehmenslandschaft zu ber&#252;cksichtigen. Zur Kommunikation der getroffenen
Einstufungen an Au&#223;enstehende k&#246;nnen Labels oder Kennzeichnungen &#228;hnlich der von
Energieverbrauchskennzeichnungen f&#252;r elektronische Ger&#228;te entwickelt und genutzt werden.
158 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 4.4 des Mantelberichts (&#8222;KI-
spezifisches Risikomanagement &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds Dr.
Florian Butollo]. 
159 Vgl. Datenethikkommission der Bundesregierung (2019): Gutachten der Datenethikkommission der Bundesregierung.
160 Ein algorithmisches System besteht nach Definition der Datenethikkommission &#8222;in der Regel aus einer Vielzahl von Algorithmen&#8220;
(vgl. Datenethikkommission der Bundesregierung (2019): Gutachten der Datenethikkommission der Bundesregierung, Teil C).
Allerdings legt die Datenethikkommission entsprechend ihres Auftrags den Schwerpunkt auf &#8222;intelligente&#8220; Algorithmen (Teil F).
161 Die DEK baut auf dem Vorschlag von Krafft und Zweig auf (vgl. Krafft und Zweig (2019): Transparenz und Nachvollziehbarkeit
algorithmenbasierter Entscheidungsprozesse), der bis zu f&#252;nf Risikoklassen vorsieht, wobei f&#252;r die erste Klasse (Stufe 0) keinerlei
Pflichten gefordert werden, w&#228;hrend f&#252;r die letzte Klasse (Stufe 4) aus technischen Gr&#252;nden oder weil ihr Einsatz grundlegende 
Rechte verletzen w&#252;rde, KI-Systeme nicht geeignet sind.
162 Vgl. Europ&#228;ische Kommission (2020): Wei&#223;buch zur K&#252;nstlichen Intelligenz &#8211; ein europ&#228;isches Konzept f&#252;r Exzellenz und
Vertrauen.
163 Englischer Wortlaut: &#8222;AI applications&#8220;, vgl. Europ&#228;ische Kommission (2020): Wei&#223;buch zur K&#252;nstlichen Intelligenz &#8211; ein
europ&#228;isches Konzept f&#252;r Exzellenz und Vertrauen, S. 17.
164 Es m&#252;ssen &#8222;signifikante Risiken&#8220; in der Anwendung entstehen; zu weiteren Ausf&#252;hrungen in diesem Zusammenhang, vgl.
Europ&#228;ische Kommission (2020): Wei&#223;buch zur K&#252;nstlichen Intelligenz &#8211; ein europ&#228;isches Konzept f&#252;r Exzellenz und Vertrauen, S. 17.
165 So z. B. in Kanada, weitere Informationen dazu unter: https://www.canada.ca/en/government/system/digital-government/digital-
government-innovations/responsible-use-ai/algorithmic-impact-assessment.html (zuletzt abgerufen am 10. August 2020) oder auch
durch die EU-Leitlinien zur Ethik in der KI, vgl. Madiega (2019): EU-Leitlinien zur Ethik in der KI.
Handlungsempfehlungen166 
1. Deutschland sollte sich aktiv daf&#252;r einsetzen, dass das EU-Wei&#223;buch zu einer EU-weit einheitlichen
Strategie zum Umgang mit allgemeinen und sektorspezifischen Risiken beim Einsatz von KI-Systemen
weiterentwickelt wird. Erforderlich sind beispielsweise geeignete Zertifizierungsverfahren, Zulassungsverfahren
und Selbstverpflichtungen167 f&#252;r KI-Systeme.
2. Bestehende sektorspezifische Regelungsregime sollten gepr&#252;ft und um KI-spezifische Vorgaben erweitert
werden, sofern durch den Einsatz von KI im jeweiligen Einsatzkontext zus&#228;tzliche Risiken entstehen. 
3. Praktische Ans&#228;tze zum Risikomanagement f&#252;r den Einsatz von KI-Systemen in Unternehmen und
Beh&#246;rden sollten gef&#246;rdert und weiterentwickelt werden (Best Practice, Standardisierung).
4. KI-Systeme sollten nicht unter Pauschalverdacht gestellt werden; durch Beschr&#228;nkung auf Vorgaben f&#252;r
Hochrisikoanwendungen sollte die Verh&#228;ltnism&#228;&#223;igkeit gewahrt bleiben. Dabei sollte ein differenzierender
Ansatz verfolgt werden, der m&#246;gliche Anforderungen an die Transparenz und Nachvollziehbarkeit der
Systeme mit der Kritikalit&#228;t des Systems im jeweiligen Anwendungsfall begr&#252;ndet.
5. Die Aufsicht und Durchsetzung von Vorgaben sollte prim&#228;r jeweils den sektoralen Aufsichtsbeh&#246;rden
zugewiesen werden, die bereits sektorspezifische Sachkompetenz ausgebildet haben. Diese Beh&#246;rden m&#252;ssen
mit den daf&#252;r erforderlichen Skills sowie finanziellen, personellen und technischen Ressourcen ausgestattet
werden.168 Die Zivilgesellschaft, d. h. B&#252;rgerinnen und B&#252;rger, m&#252;ssen in die Lage versetzt werden, die
Vorgaben mithilfe dieser Beh&#246;rden durchsetzen zu k&#246;nnen.
5 KI und Recht
Allgemeine Einf&#252;hrung zum Rechtsrahmen
F&#252;r die M&#246;glichkeiten, KI-Systeme in der Unternehmenspraxis oder in der Verwaltung zu entwickeln und
einzusetzen, spielt der bestehende Rechtsrahmen eine wichtige Rolle. Im Folgenden wird ausgef&#252;hrt, welche
rechtlichen Rahmenbedingungen es gibt und wo und wie sie weiterentwickelt werden k&#246;nnten, um Rechtssicherheit
zu erzielen und damit KI-Innovationen auf eine sichere rechtliche Grundlage zu stellen.
Zun&#228;chst einmal ist festzuhalten, dass KI-Systeme schon heute nicht in einem rechtsfreien Raum entwickelt und 
eingesetzt werden. Geltendes Recht bildet auch den Rahmen f&#252;r die Entwicklung und den Einsatz von KI-
Systemen. In diesem Abschnitt werden insbesondere &#252;bergreifend anwendbare Rechtsvorschriften behandelt. Eine
Reihe von sektor- oder anwendungsspezifischen Vorschriften wird im Rahmen der Projektgruppenberichte zu
den jeweiligen Themen detaillierter behandelt.
N&#228;her eingegangen wird hier auf das allgemeine Datenschutzrecht, einige urheber- und wettbewerbsrechtliche
Aspekte sowie auf die wichtigsten haftungsrechtlichen Regelungen. Grunds&#228;tzlich handelt es sich sowohl beim
Training von KI-Systemen als auch bei ihrem tats&#228;chlichen Einsatz immer um eine automatisierte
Datenverarbeitung. Insofern sind zun&#228;chst einmal alle bestehenden Vorschriften anwendbar, die Unternehmen und
Beh&#246;rden auch sonst bei der automatisierten Verarbeitung von Daten beachten m&#252;ssen. Dabei wird in vielen F&#228;llen das
Datenschutzrecht aus der DSGVO und den Bundes- und Landesdatenschutzgesetzen zu beachten sein. Ferner
sind hier beispielsweise das allgemeine Zivilrecht im B&#252;rgerlichen Gesetzbuch (BGB), das Wettbewerbsrecht
mit dem Gesetz gegen den unlauteren Wettbewerb (UWG) und das Urheberrecht (UrhG) anwendbar. F&#252;r den
&#246;ffentlichen Sektor sind das Verwaltungsverfahrensgesetz (VwVfG) und spezielle Verwaltungsvorschriften
einschl&#228;gig. In Organisationen sind zus&#228;tzlich die allgemeinen arbeitsrechtlichen Vorschriften, der
Besch&#228;ftigtendatenschutz, das Allgemeine Gleichbehandlungsgesetz (AGG) und Arbeitsschutzvorschriften sowie das
Mitbestimmungsrecht (Betriebsverfassungsgesetz &#8211; BetrVG) zu beachten. Beim Inverkehrbringen von Produkten, die
lernende Komponenten enthalten, gibt es rechtliche Anforderungen an die physische Sicherheit (&#8222;Safety&#8220;),
welche mit entsprechenden Haftungsregelungen unterlegt sind (Produkthaftungsgesetz &#8211; ProdHaftG etc.). Beim
Einsatz von KI-Systemen kann also eine Vielzahl von Gesetzen eine Rolle spielen; je nach Einsatzgebiet sind neben
166 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 4.5 des Mantelberichts
(&#8222;Handlungsempfehlungen &#8220; zu &#8222;KI und Umgang mit Risiko &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des
sachverst&#228;ndigen Mitglieds Dr. Florian Butollo].
167 Vgl. auch Datenethikkommission der Bundesregierung (2019): Gutachten der Datenethikkommission der Bundesregierung.
168 Vgl. auch Datenethikkommission der Bundesregierung (2019): Gutachten der Datenethikkommission der Bundesregierung,
Empfehlung 55.
den allgemeing&#252;ltigen Vorschriften auch fachspezifische Regelungen und Zulassungsregelungen zu beachten
wie beispielsweise die EU-Medizinprodukteverordnung oder das Stra&#223;enverkehrsgesetz (StVG).
Datenschutzrecht169 
KI-Systeme funktionieren nur auf Basis von Daten. Die seit dem 25. Mai 2018 geltende europ&#228;ische
Datenschutz-Grundverordnung 2016/679 (DSGVO) enth&#228;lt eine Reihe von Regelungen, die auf KI-Systeme
angewendet werden m&#252;ssen, sofern sie personenbezogene Daten170 verarbeiten. Weil solche Systeme eine automatisierte 
Datenverarbeitung darstellen, gilt, dass jede Anwendung, in der personenbezogene Daten verarbeitet werden, nur
dann erlaubt ist, wenn es f&#252;r sie eine gesetzliche oder vertragliche Grundlage gibt oder die Anwenderin bzw. der
Anwender die Einwilligung der Personen eingeholt hat, deren Daten verarbeitet werden. Aus dem
Anwendungsbereich der DSGVO fallen Informationen heraus, die sich von vornherein nicht auf eine identifizierte oder
identifizierbare nat&#252;rliche Person beziehen oder die in einer Weise anonymisiert worden sind, dass die betroffene
Person nicht oder nicht mehr identifiziert werden kann.171 Wenn solche Daten z. B. f&#252;r statistische oder f&#252;r
Forschungszwecke verwendet werden, ist die DSGVO nicht anwendbar. 
Fallen die vom KI-System verarbeiteten Daten in den Anwendungsbereich der DSGVO, gelten neben dem
Erfordernis einer gesetzlichen, vertraglichen oder einwilligungsbasierten Grundlage auch einige generell zu
beachtende Prinzipien. Das sind die rechtm&#228;&#223;ige Verarbeitung nach Treu und Glauben, die Erforderlichkeit der
Verarbeitung zum festgelegten Zweck, die Beschr&#228;nkung der Verarbeitung auf den festgelegten Zweck
(Zweckbindung), die Datenminimierung, die Richtigkeit der Daten, die begrenzte Speicherung bzw. Verpflichtung zur
L&#246;schung nach Wegfall der Erforderlichkeit oder des Zwecks, die Wahrung von Integrit&#228;t und Vertraulichkeit der
Daten (Artikel 5 Absatz 1 DSGVO). Wer Daten verarbeitet, ist daf&#252;r verantwortlich, dass dies korrekt geschieht,
und muss die Einhaltung der rechtlichen Vorgaben im Zweifel nachweisen (Rechenschaftspflicht/Accountability
aus Artikel 5 Absatz 2 DSGVO). 
F&#252;r den Einsatz von KI-Systemen und die damit verbundenen Pflichten ist es also relevant, festzustellen, ob die
verwendeten Daten in den Anwendungsbereich der DSGVO fallen. Die Abgrenzung ist hier nicht immer ganz
einfach, weil auch auf den ersten Blick rein technische Daten, wie z. B. die Sensordaten einer Maschine aus der
Fabrikhalle, dann zu personenbezogenen Daten werden k&#246;nnen, wenn sie in Kombination mit Daten verarbeitet
werden, die etwa Aussagen dar&#252;ber treffen, wer die Maschine w&#228;hrend der Erzeugung des Sensordatums gerade
bedient hat. Umgekehrt kann man personenbezogene Daten vor der Verarbeitung im KI-System so bearbeiten, 
dass sie nicht mehr auf eine bestimmte Person zur&#252;ckf&#252;hrbar sind. Dann spricht man von anonymisierten Daten,
die nicht mehr in den Anwendungsbereich der DSGVO fallen.172
Die Anonymisierung von Daten, die z. B. f&#252;r das Trainieren von KI-Systemen verwendet werden sollen, ist nicht
trivial. Zum einen muss sichergestellt werden, dass der Personenbezug nicht wiederhergestellt werden kann. Zum
anderen ist aber wichtig, dass so viele Bez&#252;ge in den Daten wie m&#246;glich erhalten bleiben, damit die Ergebnisse
des Lernprozesses nicht verf&#228;lscht werden. Dazu gibt es verschiedene technische und mathematische Ans&#228;tze
wie K-Anonymit&#228;t, &#8222;differential privacy&#8220; oder &#8222;federated learning&#8220;.173 Bei der Anwendung muss sehr sorgf&#228;ltig 
vorgegangen werden, um Verf&#228;lschungen der Ergebnisse zu vermeiden oder zu minimieren.174 Eine rechtliche 
H&#252;rde f&#252;r die Anwendung von Anonymisierungsverfahren in der Praxis ist die momentan von deutschen Auf-
169 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 5.2 des Mantelberichts
(&#8222;Datenschutzrecht &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo].
170 Definition aus Artikel 4 Nummer 1 DSGVO, siehe auch Kapitel 2.5 des Mantelberichts [Personenbezogene Daten].
171 Erw&#228;gungsgrund 26 Satz 5 DSGVO; der Prozess der Anonymisierung selbst f&#228;llt jedoch unter die DSGVO.
172 N&#228;heres zu Anonymisierung und Pseudonymisierungfinden sich in Kapitel 2 des Mantelberichts [KI und Daten].
173 Bei K-Anonymit&#228;t werden Daten so preisgegeben, dass keine R&#252;ckschl&#252;sse auf ein einzelnes Individuum gezogen werden k&#246;nnen.
Unter &#8222;differential privacy&#8220; versteht man eine formal nachweisbare Privatheitsgarantie f&#252;r statistische Datenbanken. Beim &#8222;federated 
learning&#8220; oder f&#246;deralen Lernen werden die KI-Berechnungen, die f&#252;r das Training des Algorithmus wichtig sind, auf dem Endger&#228;t
selbst gemacht, also dort, wo die Daten entstehen bzw. eingetragen werden. Lediglich die Resultate der Berechnungen, die
Lernergebnisse des Algorithmus werden &#252;bertragen und zusammengef&#252;hrt. Zu den Konzepten siehe Buchmann: Datenschutz und Privatheit
in vernetzten Informationssystemen.
174 Dazu beispielhaft Abadi et al. (2016): Deep Learning with Differential Privacy; Ah-Fat und Huth (2019): Optimal Accuracy-Privacy
Trade-Off for Secure Computations; Bellovin et al. (2019): Privacy and Synthetic Datasets; Choudhury et al. (2020): Anonymizing 
Data for Privacy-Preserving Federated Learning sowie Bauer et al. (2018): Machine Learning und die Transparenzanforderungen der
DSGVO, siehe auch die Ausf&#252;hrungen in Kapitel 2 des Mantelberichts [KI und Daten].
sichtsbeh&#246;rden vertretene Ansicht, dass f&#252;r den Vorgang der Anonymisierung eine eigene Rechtsgrundlage
notwendig sei, weil es sich hier um eine Datenverarbeitung handelt.175 Zudem ist teilweise unklar, ab wann
tats&#228;chlich der Zustand der Anonymisierung entsprechend der Definition in der DSGVO erreicht ist.
Der Grundsatz der Zweckbindung176 ist ein wichtiges Prinzip der DSGVO. In der Praxis kann dies bei KI-
Anwendungen mit personenbezogenen Daten zu Herausforderungen f&#252;hren. Oft ben&#246;tigen KI-Systeme sehr viele 
Trainingsdaten, bis sie ihre Prognosen mit einer brauchbaren Wahrscheinlichkeit treffen. Daf&#252;r kann nicht immer
auf anonymisierte oder synthetische Daten zur&#252;ckgegriffen werden.177 Daten, die bereits f&#252;r andere Zwecke
gesammelt wurden, k&#246;nnen nur dann f&#252;r weitere Zwecke verarbeitet werden, wenn diese weiteren Zwecke mit den
urspr&#252;nglichen Zwecken vereinbar sind oder nachtr&#228;glich eine Einwilligung der Betroffenen eingeholt wird. Ob
eine Vereinbarkeit mit dem urspr&#252;nglichen Zweck besteht, muss anhand einer Reihe verschiedener Kriterien wie
z. B. Zusammenhang mit dem urspr&#252;nglichen Zweck oder auch Erwartungshaltung der Betroffenen gepr&#252;ft
werden. Um die Vorhersehbarkeit f&#252;r die Betroffenen nicht zu gef&#228;hrden, wird die M&#246;glichkeit einer
zweck&#228;ndernden Verarbeitung eher eng auszulegen sein. Die Unternehmen w&#252;nschen sich hingegen in Teilen eine weitere 
Auslegung der Zweck&#228;nderungsm&#246;glichkeit, um neue Erkenntnisse durch Verfahren zu erlangen wie z. B. durch 
solche, bei denen Muster in gro&#223;en unstrukturierten Datenmengen gesucht werden. Argumentiert wird
insbesondere, dass man in Innovationsprozessen nicht unbedingt im Vorhinein wisse, wozu die Daten verwendet w&#252;rden,
und eine weitere explorative Datenverwendung n&#246;tig sei, um ergebnisoffen in den Prozess zu starten. &#196;hnliches
gilt f&#252;r das Prinzip der Datenminimierung, wo argumentiert wird, dass eine gro&#223;e Datenmenge gewisse
Innovationsprozesse erst erm&#246;gliche. Hier kann ein nicht ohne Weiteres aufzul&#246;sender Widerspruch zwischen den
Rechten der Betroffenen auf Vorhersehbarkeit der Nutzung ihrer Daten einerseits und dem Innovationsinteresse von
datenverarbeitenden Organisationen andererseits entstehen. 
Beim Einsatz automatisierter Entscheidungssysteme f&#252;r Entscheidungen mit rechtlicher Wirkung oder &#228;hnlicher
Beeintr&#228;chtigung in erheblicher Weise f&#252;r die betroffenen Personen gem&#228;&#223; Artikel 22 DSGVO m&#252;ssen zus&#228;tzlich 
aussagekr&#228;ftige Informationen &#252;ber die involvierte Logik sowie die Tragweite und die angestrebten
Auswirkungen der Verarbeitung f&#252;r die betroffene Person gegeben werden. Diese Informationen sind auf ein Niveau
begrenzt, das f&#252;r durchschnittliche Nutzerinnen und Nutzer verst&#228;ndlich ist, und sollen die Voraussetzung daf&#252;r
bieten, individuelle Rechte und Freiheiten der Nutzerinnen und Nutzer durchzusetzen. Nur teilweise unterst&#252;tzen
diese Vorgaben die systematische Gew&#228;hrleistung gruppenbezogener und gesellschaftsbezogener Ziele.178
Zus&#228;tzlich gilt dann auch ein umfangreiches Widerspruchsrecht der Betroffenen und, falls es keine entsprechende
Vertragsbeziehung gibt, in der der Einsatz des Systems erforderlich ist, haben Betroffene generell das Recht,
nicht einer automatisierten Entscheidung unterworfen zu sein, die ihnen gegen&#252;ber rechtliche Wirkung entfaltet
oder sie in &#228;hnlicher Weise beeintr&#228;chtigt.179
Eine weitere f&#252;r den Einsatz von KI-Systemen relevante Vorgabe der DSGVO ist die sogenannte Datenschutz-
Folgenabsch&#228;tzung, welche insbesondere bei Verwendung neuer Technologien vorgeschrieben ist, bei denen
aufgrund der Art, des Umfangs, der Umst&#228;nde und der Zwecke der Verarbeitung voraussichtlich ein hohes Risiko
f&#252;r die Rechte und Freiheiten nat&#252;rlicher Personen besteht. In jedem Fall durchzuf&#252;hren ist die Datenschutz-
Folgenabsch&#228;tzung beispielsweise bei dem systematischen Profiling180 als Entscheidungsgrundlage oder bei der
systematischen &#220;berwachung im &#246;ffentlichen Bereich. Hierbei wird umfassend untersucht, inwieweit die
angedachte Datenverarbeitung in die Grundrechte betroffener Personen eingreift und welche Folgen das f&#252;r diese
Personen haben k&#246;nnte. Daraufhin sind entsprechende Schutzma&#223;nahmen zu treffen, welche die festgestellten 
Risiken minimieren. Sollte es nicht m&#246;glich sein, die Risiken zu minimieren, muss ggf. die Aufsicht eingeschaltet
oder von der Anwendung Abstand genommen werden. Die bisherigen Erfahrungen mit der Vorschrift haben
gezeigt, dass ihre Umsetzung insbesondere f&#252;r kleine und mittlere Unternehmen nicht leicht ist, weil erhebliches
175 Handlungsempfehlungen von Oliver S&#252;me (Vorstandsvorsitzender, eco &#8211; Verband der Internetwirtschaft e. V.),
Kommissionsdrucksache 19(27)98 vom 13. Januar 2020, S. 2. Der Bundesbeauftragte f&#252;r den Datenschutz und die Informationsfreiheit (BfDI) hat zu 
diesem Thema ein &#246;ffentliches Konsultationsverfahren durchgef&#252;hrt und ein Positionspapier ver&#246;ffentlicht, vgl. Der
Bundesbeauftragte f&#252;r den Datenschutz und die Informationsfreiheit (2020): Positionspapier zur Anonymisierung unter der DSGVO unter
besonderer Ber&#252;cksichtigung der TK-Branche.
176 Zweckbindung nach Artikel 5 Absatz 1 DSGVO bedeutet, dass personenbezogene Daten f&#252;r festgelegte, eindeutige und legitime Zwecke
erhoben werden m&#252;ssen und nicht in einer mit diesem Zweck nicht zu vereinbarenden Weise weiterverarbeitet werden d&#252;rfen.
177 Siehe auch die Ausf&#252;hrungen in Kapitel 2 des Mantelberichts [KI und Daten].
178 Vgl. Dreyer und Schulz (2018): Was bringt die Datenschutz-Grundverordnung f&#252;r automatisierte Entscheidungssysteme?
179 Teilweise wird diskutiert, ob Artikel 22 DSGVO auch f&#252;r teilautomatisierte Entscheidungssysteme gelten sollte.
180 Darunter versteht man das systematische Erfassen von Verhaltenseigenschaften von einem oder mehreren Menschen.
Know-how und erhebliche Ressourcen erforderlich sind, um eine rechtssichere Pr&#252;fung durchzuf&#252;hren und zu
dokumentieren.181 
Der durch die DSGVO geschaffene einheitliche Rechtsrahmen in der EU ist auch f&#252;r die KI-Entwicklung eine
wichtige Errungenschaft. Denn er stellt einheitliche Vorgaben f&#252;r den gesamten EU-Binnenmarkt sowie f&#252;r alle
Anbieter auf, die innerhalb des Binnenmarktes aktiv sind und Daten europ&#228;ischer B&#252;rgerinnen und B&#252;rger
verarbeiten. Damit wirkt er auf gleiche Wettbewerbsbedingungen und die Weiterentwicklung
datenschutzfreundlicher Technologien hin. Allerdings bedeutet die Vereinheitlichung der Vorschriften in Form einer Verordnung
noch nicht, dass die Vorschriften in den Mitgliedstaaten einheitlich durchgesetzt werden. Zwar sieht die DSGVO
Prozesse vor, die einer einheitlichen Auslegung und Durchsetzung der Verordnung dienen sollen. Bislang haben
diese jedoch nur punktuell zu abgestimmten Positionen der Aufsichtsbeh&#246;rden auf europ&#228;ischer und nationaler
Ebene gef&#252;hrt und Entscheidungen in Einzelf&#228;llen obliegen weitgehend den einzelnen Datenschutzbeh&#246;rden.
Diese Praxis konterkariert das grundlegende Ziel einer Vollendung des europ&#228;ischen Binnenmarktes. 
Die Durchsetzung der datenschutzrechtlichen Vorgaben gegen&#252;ber Unternehmen und Beh&#246;rden obliegt in
Deutschland insgesamt 17 Aufsichtsbeh&#246;rden sowie den sonst zust&#228;ndigen europ&#228;ischen Aufsichtsbeh&#246;rden. Die
Befugnisse der Aufsichtsbeh&#246;rden, um gegen Verst&#246;&#223;e vorzugehen, wurden durch die DSGVO erg&#228;nzt und
gest&#228;rkt. Sie haben umfangreiche Untersuchungsbefugnisse, k&#246;nnen Warnungen und Verwarnungen aussprechen,
Anordnungen treffen und empfindliche Geldbu&#223;en (Artikel 58 DSGVO) verh&#228;ngen. Verst&#246;&#223;e gegen die
Vorgaben der Verordnung k&#246;nnen mit hohen Geldbu&#223;en (bis 4 Prozent des weltweiten Konzernumsatzes) geahndet
werden und es gibt Schadensersatzanspr&#252;che (Artikel 82 bis 84 DSGVO). Wirksame Durchsetzungsinstrumente
sind also prinzipiell vorhanden. F&#246;derale Zust&#228;ndigkeiten und die vorgegebene Unabh&#228;ngigkeit der Stellen
erschweren aber eine koh&#228;rente Rechtsauslegung. Die personellen und materiellen Kapazit&#228;ten der
Aufsichtsbeh&#246;rden sind abh&#228;ngig von den Zuweisungen in den jeweiligen Landeshaushalten. Daher sind momentan
Ressourcen und Know-how zur &#220;berpr&#252;fung komplexer technischer Sachverhalte nicht &#252;berall in erforderlichem Ma&#223;e
vorhanden. 
Insofern ist eine solide gesetzliche datenschutzrechtliche Grundlage f&#252;r die Verarbeitung von personenbezogenen
Daten durch KI-Systeme vorhanden. Es gibt jedoch noch keine gesicherte, einheitliche Auslegung und
Anwendung der gesetzlichen Vorschriften bei der Beurteilung von einzelnen Anwendungsf&#228;llen im Zusammenhang mit
dem Training oder Einsatz von KI-Systemen. Dies ist zum einen der schnellen technologischen Entwicklung
geschuldet, liegt aber auch an der nationalen Struktur der f&#252;r die Rechtsdurchsetzung zust&#228;ndigen Beh&#246;rden. 
Urheberrecht
Schutz von KI-Software
Die einzelnen unter KI zusammengefassten Systeme k&#246;nnen als Computerprogramme im Sinne des &#167; 69a UrhG 
urheberrechtlich gesch&#252;tzt bzw. urheberrechtlich schutzf&#228;hig sein.182 Nach &#167; 69a Absatz 2 Satz 2 UrhG k&#246;nnen 
zwar allgemeing&#252;ltige mathematische bzw. informatische Grundregeln &#8211; einschlie&#223;lich der Schnittstellen, auf
denen das Programm beruht &#8211; nicht gesch&#252;tzt werden, gesch&#252;tzt ist aber die &#8222;kreative&#8220; Leistung der
Programmierenden, also die konkrete Quellcode-Gestaltung durch die Entwickelnden als konkreter Ausdruck eines
Werkes, also nicht der blo&#223;e Informationsinhalt.183 Sofern es sich bei den zu betrachtenden Systemen deshalb nicht
um sogenannte Banalprogramme184 handelt, was bei KI-Systemen ausgeschlossen wird,185 sind sie schutzf&#228;hig.186
Hieraus ergibt sich, dass die architektonische Grundstruktur von beispielsweise k&#252;nstlichen neuronalen Netzen
(KNN) urheberrechtlich schutzf&#228;hig ist, nicht jedoch die im Ergebnis brauchbare Konfiguration des &#8222;trainierten&#8220;
181 Vgl. Bitkom e. V.: Zwei Drittel der Unternehmen haben DS-GVO gr&#246;&#223;tenteils umgesetzt.
182 So im Ergebnis Linke (2019): Urheberrechtlicher Schutz von &#8222;KI&#8220; als Computerprogramme &#8211; Squeezing today&#180;s innovations into 
yesterday&#180;s system?, S. 47; f&#252;r k&#252;nstliche neuronale Netzwerke ebenso Ehinger und Stiemerling (2018): Die urheberrechtliche
Schutzf&#228;higkeit von K&#252;nstlicher Intelligenz am Beispiel von Neuronalen Netzen, S. 766.
183 Vgl. Die Wissenschaftlichen Dienste des Deutschen Bundestags (2018): Autonomes und automatisiertes Fahren auf der Stra&#223;e &#8211;
rechtlicher Rahmen, S. 17.
184 Unter dem Begriff &#8222;Banalprogramme&#8220; fasst man Trivialsoftware, also alle Programme, die sich in einer technisch-mechanischen
Aneinanderreihung von vorbekanntem Material ersch&#246;pfen, die zum Gemeingut geh&#246;ren oder vollst&#228;ndig auf rein allt&#228;glicher
Programmierarbeit beruhen.
185 Vgl. Die Wissenschaftlichen Dienste des Deutschen Bundestags (2018): Autonomes und automatisiertes Fahren auf der Stra&#223;e &#8211;
rechtlicher Rahmen, S. 18.
186 Auch der Bundesgerichtshof ist der Auffassung, dass jedenfalls die Art und Weise der Implementierung und Zuordnung zueinander
urheberrechtsschutzf&#228;hig sein kann: vgl. Linke (2019): Urheberrechtlicher Schutz von &#8222;KI&#8220; als Computerprogramme &#8211; Squeezing 
today&#180;s innovations into yesterday&#180;s system?, S. 41.
Netzwerkes.187 Separat gespeicherte Trainingsergebnisse eines KNN k&#246;nnen aber grunds&#228;tzlich als
Gesch&#228;ftsgeheimnis schutzf&#228;hig sein.188 
Zugriff auf urheberrechtlich gesch&#252;tztes Material
Daten, die ein KI-System verarbeitet, insbesondere beim Training im Rahmen des Maschinellen Lernens, k&#246;nnen
urheberrechtlich gesch&#252;tzt sein, beispielsweise wenn es sich um Lichtbilder oder von Menschen geschriebene
Texte handelt oder sie als Datenbanken unter ein Leistungsschutzrecht fallen. Rechte sind insoweit betroffen, als
im Rahmen der Verarbeitung Vervielf&#228;ltigungen oder Bearbeitungen entstehen, gegebenenfalls auch bei der
Verbreitung von Ergebnissen der Verarbeitung.
Aufgrund der Vielzahl an Eingaben, die f&#252;r das Training eines KI-Systems erforderlich sind, ist eine
Lizenzierung oft nicht praktikabel. Insbesondere wenn die Trainingsdaten automatisiert aus dem &#246;ffentlich zug&#228;nglichen
Internet extrahiert werden (Webscraping), ist eine Kl&#228;rung der Rechte im Einzelfall kaum m&#246;glich.189 
Von gro&#223;er Bedeutung ist daher in diesem Zusammenhang die Schranke f&#252;r Text- und Data-Mining (TDM) im
Urheberrecht. Diese Nutzungserlaubnis erm&#246;glicht die automatisierte Auswertung einer Vielzahl von Werken zu
Zwecken der nicht-kommerziellen wissenschaftlichen Forschung. Mit Artikel 3 und 4 der DSM-Richtlinie190 
wurde eine europ&#228;ische Regelung getroffen, wonach TDM auch f&#252;r andere als wissenschaftliche Zwecke zul&#228;ssig
sein soll. Die Mitgliedstaaten sollen demnach, anders als derzeit im deutschen Urheberrechtsgesetz, keinen
finanziellen Ausgleich f&#252;r diese Nutzung vorsehen191; entsprechend sieht auch ein erster Diskussionsentwurf des
Bundesjustizministeriums keine Verg&#252;tung vor.192 
Die Richtlinie unterscheidet eine Schrankenregelung f&#252;r die wissenschaftliche Forschung und eine f&#252;r alle
anderen Zwecke, wobei der wesentliche Unterschied darin besteht, dass bei der Verwendung von TDM f&#252;r
nichtwissenschaftliche Zwecke der Rechteinhaber eine Widerspruchsm&#246;glichkeit erh&#228;lt, etwa durch maschinenlesbare
Hinweise bei Onlinever&#246;ffentlichungen, wie sie heute schon &#252;blich sind. Diese Widerspruchsm&#246;glichkeit k&#246;nnte
f&#252;r Anwendungen, beispielsweise im Rahmen des Datenjournalismus, problematisch sein. 
Voraussetzung der Nutzungserlaubnis ist in jedem Fall der rechtm&#228;&#223;ige Zugang zu den betreffenden Werken. 
Auch technische Mittel wie Kopierschutzma&#223;nahmen k&#246;nnen einer Nutzung praktisch im Weg stehen. Im Fall 
des Minings f&#252;r wissenschaftliche Zwecke ist die Nutzung zul&#228;ssig, wenn ein rechtm&#228;&#223;iger Zugang besteht, und
es besteht ein Anspruch gegen&#252;ber dem Rechteinhaber darauf, das Mining zu erm&#246;glichen (&#167; 95b UrhG bzw. 
Artikel 7 Absatz 2 DSM-Richtlinie).
Nicht abschlie&#223;end gekl&#228;rt ist bei alledem allerdings, inwieweit die hier verwendete TDM-Definition193
tats&#228;chlich auch das Training eines neuronalen Netzes, beispielsweise mit Lichtbildern, abdeckt194.
187 Vgl. Ehinger und Stiemerling (2018): Die urheberrechtliche Schutzf&#228;higkeit von K&#252;nstlicher Intelligenz am Beispiel von Neuronalen 
Netzen, S. 768.
188 Vgl. Ehinger und Stiemerling (2018): Die urheberrechtliche Schutzf&#228;higkeit von K&#252;nstlicher Intelligenz am Beispiel von Neuronalen
Netzen, S. 769.
189 In diesem Fall k&#246;nnen nat&#252;rlich neben dem Urheberrecht noch andere Rechte einer Verwertung entgegenstehen, insbesondere der
Schutz personenbezogener Daten. So ist beispielsweise die Nutzung einer Datenbank frei lizenzierter Fotos zur Entwicklung von 
Gesichtserkennung unter diesem Aspekt kritisch diskutiert worden, vgl. Berger (2019): IBM nutzte Flickr-Fotos f&#252;r
Gesichtserkennung, ohne Nutzer zu informieren.
190 Richtlinie (EU) 2019/790 vom 17. April 2019 &#252;ber das Urheberrecht und die verwandten Schutzrechte im digitalen Binnenmarkt und 
zur &#196;nderung der Richtlinien 96/9/EG und 2001/29/EG (DSM-Richtlinie).
191 Vgl. Erw&#228;gungsgrund 17 der DSM-Richtlinie.
192 Vgl. Bundesministerium der Justiz und f&#252;r Verbraucherschutz (2020): Entwurf eines Ersten Gesetzes zur Anpassung des
Urheberrechts an die Erfordernisse des digitalen Binnenmarkts.
193 Nach Artikel 2 Nummer 2 der DSM-Richtlinie bezeichnet Text- und Data-Mining eine Technik f&#252;r die automatisierte Analyse von 
Texten und Daten in digitaler Form, mit deren Hilfe Informationen unter anderem &#8211; aber nicht ausschlie&#223;lich &#8211; &#252;ber Muster, Trends
und Korrelationen gewonnen werden k&#246;nnen.
194 Daf&#252;r Raue (2019): Rechtssicherheit f&#252;r datengest&#252;tzte Forschung und Deutsche Vereinigung f&#252;r gewerblichen Rechtschutz und
Urheberrecht e. V. (2019): Stellungnahme des GRUR Fachausschusses f&#252;r Urheber- und Verlagsrecht zur Umsetzung der EU-RLn
im Urheberrecht (DSM-RL (EU) 2019/790 und Online-SatCab-RL (EU) 2019/789), S. 2.
Werkerstellung
Die Ergebnisse einer KI m&#252;ssen dem &#228;u&#223;eren Erscheinungsbild nach einem menschlichen Werk in nichts
nachstehen. Ein urheberrechtlicher Werkschutz nach deutschem und EU-Recht erfordert aber immer ein menschliches
Schaffen.195 Das bedeutet, dass autonom erschaffene &#8222;Sch&#246;pfungen&#8220;, die einem menschlichen Sch&#246;pfer nicht
zugerechnet werden k&#246;nnen, nicht urheberrechtlich schutzf&#228;hig sind.196 Entscheidend ist also, inwieweit KI
eigenst&#228;ndig komponiert, malt oder schreibt und wie gro&#223; der menschliche Einfluss sein muss, um dem Ergebnis
einen urheberrechtlichen Werkschutz zuzugestehen. Werden alle wesentlichen Gestaltungsentscheidungen allein
durch technische Hilfsmittel, z. B. eine KI-Anwendung auf Grundlage von Deep Learning oder einen
Zufallsgenerator, gepr&#228;gt, ist die Gestaltung einem urheberrechtlichen Schutz nicht zug&#228;nglich.197 Die konkrete
Festlegung, ob und inwieweit ein menschlicher Einfluss eigensch&#246;pferisch ist, muss jeweils anhand des konkreten
Einzelfalles erfolgen und kann komplex sein. So ist es beispielsweise bereits umstritten, ob die reine Auswahl
aus verschiedenen Ergebnissen eines vollst&#228;ndig autonomen und unbeeinflussbaren Systems einen
urheberrechtlich gesch&#252;tzten sch&#246;pferischen Prozess darstellt.198
Ein dem Urheberrecht verwandtes Schutzrecht f&#252;r KI-Leistungen w&#228;re grunds&#228;tzlich denkbar, wenn es sich dabei
um einen Investitionsschutz handeln w&#252;rde. Hierzu bed&#252;rfte es einer wirtschaftlichen Notwendigkeit im Sinne
des immaterialg&#252;terrechtlichen Anreizgedankens.  
Wettbewerbsrecht
Branchen&#252;bergreifend hat die Digitalisierung gro&#223;e Auswirkungen auf die Wettbewerbssituation in M&#228;rkten. So
werden die Funktionsweise der Daten&#246;konomie, die Entstehung von Plattformm&#228;rkten und die zunehmende
Bedeutung markt&#252;bergreifender digitaler &#214;kosysteme zu den zentralen Ver&#228;nderungsfaktoren der Wirtschaft im
digitalen Zeitalter.199 Das Wettbewerbsrecht reguliert dabei nicht den Einsatz bestimmter Technologien, sondern
ist vielmehr darauf gerichtet, den Wettbewerb zu erhalten und die M&#228;rkte f&#252;r Konkurrenz offenzuhalten. Eine
Grundannahme des funktionsf&#228;higen Wettbewerbs ist, die Vermachtung von Wirtschaftsbereichen durch enge
Oligopole zu verhindern. 
Das Wettbewerbsrecht spielt deshalb f&#252;r KI mittelbar eine bedeutende Rolle, weil je nach Ausgestaltung der
Zugang zu Daten erm&#246;glicht, erleichtert, erschwert oder verhindert wird. Der Zugang zum Rohstoff Daten f&#252;r
die Anwendung von KI beeinflusst mithin also die Wettbewerbssituation auf digitalen M&#228;rkten. Im Zuge der
letzten Novelle des Gesetzes gegen Wettbewerbsbeschr&#228;nkungen (GWB)200 wurden Anpassungen
vorgenommen, um die wahrgenommene L&#252;cke zu schlie&#223;en: Es wurde klargestellt, dass unentgeltliche Leistungen einem
Markt zugeordnet werden k&#246;nnen (&#167; 18 Absatz 2a GWB), besondere Marktstellungsmerkmale f&#252;r die
Beurteilung mehrseitiger M&#228;rkte, insbesondere Plattformm&#228;rkte (&#167; 18 Absatz 3a GWB), und ferner erg&#228;nzende
Umsatzschwellen in der Fusionskontrolle wurden eingef&#252;hrt.201 
Dennoch m&#252;ssen weitere Anpassungen am Wettbewerbsrecht vorgenommen werden, damit es mit den neuen
Verh&#228;ltnissen in der Digitalwirtschaft umgehen kann. Die Bundesregierung hatte dazu eine &#8222;Kommission
Wettbewerbsrecht 4.0&#8220; eingesetzt, die Vorschl&#228;ge f&#252;r eine Weiterentwicklung des europ&#228;ischen Wettbewerbsrechts
unterbreitet hat.202 Auf dieser Basis wird derzeit eine 10. Novelle des Gesetzes gegen
Wettbewerbsbeschr&#228;nkungen (GWB) erarbeitet, die das Wettbewerbsrecht noch effektiver machen und die richtige Balance zwischen den
195 Vgl. &#167; 7 UrhG: &#8222;Urheber ist der Sch&#246;pfer des Werkes.&#8220;; &#167; 2 Absatz 2 UrhG: &#8222;pers&#246;nlich geistige Sch&#246;pfung&#8220;; Urteil des Europ&#228;ischen
Gerichtshofs vom 12. September 2019 (Az.: C-683/17): Werk ist &#8222;... eine eigene geistige Sch&#246;pfung seines Urhebers&#8220;; es ist ein
Original, wenn es &#8222;die Pers&#246;nlichkeit seines Urhebers widerspiegelt&#8220;.
196 Vgl. Lauber-R&#246;nsberg (2019): Autonome &#8222;Sch&#246;pfung&#8220; &#8211; Urheberschaft und Schutzf&#228;higkeit, S. 249.
197 Vgl. Lauber-R&#246;nsberg (2019): Autonome &#8222;Sch&#246;pfung&#8220; &#8211; Urheberschaft und Schutzf&#228;higkeit, S. 247.
198 Dagegen: Lauber-R&#246;nsberg (2019): Autonome &#8222;Sch&#246;pfung&#8220; &#8211; Urheberschaft und Schutzf&#228;higkeit, S. 247; Darstellung Prof. Dr. Jan 
Bernd Nordemann (Humboldt-Universit&#228;t zu Berlin) in der Sitzung der Projektgruppe &#8222;KI und Medien&#8220; am 2. M&#228;rz 2020; wohl
daf&#252;r: Dreier und Schulze (2008): Urheberrechtsgesetz &#167; 2, Rn. 8 mit weiteren Nachweisen.
199 Vgl. Schallbruch et al. (2019): Ein neuer Wettbewerbsrahmen f&#252;r die Digitalwirtschaft. Bericht der Kommission
Wettbewerbsrecht 4.0.
200 Das Gesetz gegen Wettbewerbsbeschr&#228;nkungen (GWB) wurde in den letzten Jahrzehnten wiederholt an ver&#228;nderte
marktwirtschaftliche Gegebenheiten angepasst. Am 28. September 2016 hat das Bundeskabinett den vom Bundesministerium f&#252;r Wirtschaft und 
Energie (BMWi) vorgelegten Entwurf f&#252;r die 9. Novelle des Gesetzes gegen Wettbewerbsbeschr&#228;nkungen (GWB) verabschiedet,
die im Juni 2017 in Kraft getreten ist. Die 10. GWB Novelle ist derzeit in Arbeit. Vgl. Bundesregierung (2020): Gestaltung einer
digitalen Ordnungspolitik.
201 Vgl. Beckmann und M&#252;ller (2014): Teil 10 Kartellrecht, Abschnitt A, Rn. 2.
202 Vgl. Schallbruch et al. (2019): Ein neuer Wettbewerbsrahmen f&#252;r die Digitalwirtschaft. Bericht der Kommission
Wettbewerbsrecht 4.0.
Wachstumsm&#246;glichkeiten deutscher und europ&#228;ischer Plattformen einerseits und der Verhinderung des
Missbrauchs von Marktmacht andererseits finden soll.203 
Dazu geh&#246;rt auch, k&#252;nftig einen wettbewerbswidrigen Umgang mit Daten zu verhindern. Daten gewinnen als
Inputfaktor f&#252;r Angebote immer mehr an Bedeutung. U. a. mithilfe von KI werden Daten zur Effizienzsteigerung
oder zur Personalisierung von Produkten oder Dienstleistungen eingesetzt. Dies birgt f&#252;r Verbraucherinnen und
Verbraucher die Gefahr von sogenannten Lock-in-Effekten204, da ein personalisiertes Angebot den Wechsel zu
konkurrierenden Anbietern erschwert. 
Insbesondere in Verbindung mit plattformbasierten Gesch&#228;ftsmodellen treten sogenannte Netzwerkeffekte auf,
die m&#246;glichst viele Nutzerinnen und Nutzer dazu anhalten, eine bestimmte Plattform zu verwenden. Dies
beg&#252;nstigt Tendenzen einer monopolartigen Marktentwicklung. Eine andere Form des Netzwerkeffekts sorgt
hingegen daf&#252;r, dass die durch Nutzung des Netzwerks gewonnenen Daten f&#252;r die Entwicklung davon unabh&#228;ngiger
Angebote eingesetzt werden k&#246;nnen. Dies beg&#252;nstigt die Expansion eines Unternehmens in neue M&#228;rkte, da die
durch Datenerhebung gewonnenen Erkenntnisse z. B. &#252;ber Kundenw&#252;nsche oder Kundengewohnheiten in
anderen Branchen genutzt werden k&#246;nnen. Insofern spricht man im Rahmen der Plattformwirtschaft von unechten
Netzwerken, da die Plattformen die Netzwerkstrukturen erm&#246;glichen und deren zentralen Knotenpunkt bilden,
&#252;ber den alle Interaktionen und alle Vernetzungen laufen.205 
Diese Entwicklungen f&#252;hren zu starken Monopolisierungstendenzen und zu verzweigten
Unternehmensstrukturen. Der Datenreichtum dieser Unternehmen st&#228;rkt ihre Wettbewerbsposition und macht es f&#252;r datenarme
Wettbewerber zunehmend schwierig bis unm&#246;glich, diese wirtschaftliche Machtposition anzugreifen, insbesondere
weil kein Zugang zu den Daten des marktm&#228;chtigen Wettbewerbers besteht.206 Somit haben datenreiche
Unternehmen einen Vorteil, wenn es um den Einsatz von KI-Technologien geht, da sie auf einen gr&#246;&#223;eren Datenschatz
zugreifen k&#246;nnen. 
Eine Strategie, um dieser Situation zu begegnen, kann die Zusammenarbeit von Unternehmen sein. Dabei kann
das Teilen von zuvor getrennten Datenpools der Unternehmen vereinbart werden. Diese
Unternehmenskooperationen scheitern jedoch oftmals an der Tatsache, dass Unternehmen damit m&#246;glicherweise gegen das
Wettbewerbsrecht versto&#223;en. Diese Rechtsunsicherheit verhindert das Teilen von Datenbest&#228;nden.207 
Diese Entwicklungen haben zu einer globalen Debatte gef&#252;hrt, wie das Wettbewerbs- und Kartellrecht
auszugestalten ist, um den Monopolisierungstendenzen in der digitalen Wirtschaft entgegenzutreten. Das BMWi hat
bereits einen Referentenentwurf f&#252;r die Novellierung des Gesetzes gegen Wettbewerbsbeschr&#228;nkungen (GWB)
ver&#246;ffentlicht, der derzeit beraten wird. Da das Wettbewerbsrecht jedoch zu gro&#223;en Teilen EU-rechtlich
harmonisiert ist, hat der deutsche Gesetzgeber nur einen engen Handlungsspielraum. Allerdings gibt es auch auf EU-
Ebene Bestrebungen, das Wettbewerbsrecht zu &#228;ndern.
In der Diskussion befinden sich derzeit z. B. Verhaltensregeln f&#252;r marktm&#228;chtige Plattformen. Auf europ&#228;ischer
Ebene wurde Ende 2019 die sogenannte P2B-Verordnung beschlossen208, die den Umgang von
Plattformanbietern mit H&#228;ndlern regelt; eine &#196;nderung des Digital Services Act soll eingeleitet werden, in dem weitere
Verhaltensregeln f&#252;r Plattformen festgeschrieben werden sollen. Der Entwurf der GWB-Digitalisierungsnovelle richtet 
sich hingegen nicht ausschlie&#223;lich an Plattformanbieter, sondern will Verhaltensregeln f&#252;r Unternehmen mit
&#252;berragender markt&#252;bergreifender Bedeutung einf&#252;hren. 
Der Entwurf sieht vor, Vorgaben f&#252;r marktm&#228;chtige Unternehmen bez&#252;glich der Datenportabilit&#228;t und
Interoperabilit&#228;t zu machen, um die Lock-in-Effekte f&#252;r Verbraucherinnen und Verbraucher abzumildern und den
Wettbewerb zu f&#246;rdern. Ebenso ist ein zumindest teilweiser Zugang von Wettbewerbern zu Datenpools von
marktbeherrschenden Anbietern im Gespr&#228;ch. Dies wird dadurch erm&#246;glicht, dass Daten in Zukunft unter die sogenannte
203 Weitere Informationen zum aktuellen Stand unter: https://www.bundesregierung.de/breg-de/themen/digital-made-in-de/gestaltung-
einer-digitalen-ordnungspolitik-1547010 (zuletzt abgerufen am 5. August 2020).
204 Unter dem Lock-in-Effekt versteht man in der Betriebswirtschaft eine Art Abh&#228;ngigkeitsverh&#228;ltnis von einem Kunden zu einem
Anbieter. Der Lock-in-Effekt, auch Anbindeeffekt, beschreibt dabei die Tatsache, dass ein Wechsel des Kunden zu einem anderen
Anbieter aufgrund hoher Wechselkosten unwirtschaftlich ist. Der Kunde ist also an seinen jetzigen Anbieter &#8222;gebunden&#8220;, da ein
Wechsel nur dann sinnvoll ist, wenn der neu entstandene Nutzen durch den Wechsel gr&#246;&#223;er als oder zumindest gleich gro&#223; ist wie
die Kosten des Wechsels.
205 Vgl. Spiecker genannt D&#246;hmann (2019): Digitale Mobilit&#228;t: Plattform Governance, S. 342.
206 F&#252;r die Folgen der Digitalisierung auf den Wettbewerb von Unternehmen vgl. Schallbruch et al. (2019): Ein neuer
Wettbewerbsrahmen f&#252;r die Digitalwirtschaft. Bericht der Kommission Wettbewerbsrecht 4.0, S. 12 ff.
207 Dieser Umstand wird bereits durch den Entwurf der 10. GWB-Novelle aufgegriffen.
208 Die Verordnung zur F&#246;rderung von Fairness und Transparenz (EU) 2019/1150 vom 20. Juni 2019 trat am 31. Juli 2019 in Kraft und
ist seit dem 12. Juli 2020 anzuwenden.
Essential-Facilities-Doktrin209 z&#228;hlen k&#246;nnen, wonach die Verhinderung des Zugangs zu wesentlichen
(Infrastruktur-)Einrichtungen (englisch &#8222;essential facility&#8220;, also hier Daten) eine Untergruppe des Missbrauchs einer
marktbeherrschenden Stellung durch Gesch&#228;ftsverweigerung darstellt.
Bei der Schaffung eines Datenzugangs k&#246;nnen jedoch Konflikte mit dem Datenschutzrecht sowie dem Schutz
von Unternehmensgeheimnissen auftreten, die mitunter zu langen Rechtsstreitigkeiten f&#252;hren k&#246;nnen. Diese
Konflikte k&#246;nnten durch das Zwischenschalten von Ombudspersonen, Clearingstellen oder Datentreuh&#228;ndern
entsch&#228;rft werden.210 Um Rechtsunsicherheiten bei Unternehmenskooperationen zu vermeiden und somit
Monopole durch St&#228;rkung von Wettbewerbern zu verhindern, ist die Schaffung einer vorherigen
Bewertungsm&#246;glichkeit auf Anfrage der beteiligten Unternehmen bei der zust&#228;ndigen Beh&#246;rde im Gespr&#228;ch.
Haftungsrecht211 
Das Haftungs- oder Schadenersatzrecht dient in erster Linie der Kompensation von erlittenen Nachteilen, ohne
die Sch&#228;digende oder den Sch&#228;digenden zu bestrafen. 
Als n&#252;tzliche Folge der Kompensation entfaltet aber auch das Schadenersatzrecht pr&#228;ventive Wirkung212, indem
es Anreize f&#252;r ein risikoarmes Verhalten der verantwortlichen Akteure schafft. Schlie&#223;lich konkretisiert es den
verfassungsrechtlichen Auftrag des Staates, Rechtsg&#252;ter seiner B&#252;rgerinnen und B&#252;rger zu sch&#252;tzen, indem es
Verantwortlichkeiten f&#252;r den Integrit&#228;tsschutz dieser Rechtsg&#252;ter festschreibt. Ein gutes Haftungssystem ist stets 
auch wirtschaftlich sinnvoll, indem es Kosten f&#252;r Sch&#228;den denjenigen Akteuren auferlegt, welche die Sch&#228;den
mit dem geringsten Aufwand vermeiden oder versichern k&#246;nnen. 
Die Verantwortlichkeit f&#252;r den Einsatz von KI-Systemen und deren Folgen muss immer bei einer (Rechts-)Person
verbleiben und darf nicht an die Technik delegiert werden k&#246;nnen.
F&#252;r die Herstellung und das Betreiben von KI-Systemen gibt es derzeit keine speziellen Haftungsregelungen. KI
bietet f&#252;r die bestehenden Herausforderungen des Haftungssystems aus sich heraus auch keine sinnvollen
gesetzgeberischen Abgrenzungskriterien.
Das derzeitige Haftungsregime besteht aus einer Reihe von Gesetzen, die zu verschiedenen Zeitpunkten
unterschiedlichen Akteuren Pflichten und Risiken zuschreiben und diese im Schadenfall durch einen Ersatzanspruch
des oder der Gesch&#228;digten kompensieren. Pr&#228;ventiv, also schadensvorbeugend, wirken allgemeine und
sektorspezifische Schutzgesetze wie die Produktsicherheitsrichtlinie oder die Medizinprodukteverordnung. Sie
beschreiben, welche Voraussetzungen gegeben sein m&#252;ssen, damit ein entsprechendes Produkt als sicher gilt und
in Verkehr gebracht werden darf. Das auf der europ&#228;ischen Produkthaftungsrichtlinie basierende
Produkthaftungsgesetz kn&#252;pft am Produkt an und schreibt vor, dass der Hersteller haftet, wenn das Produkt durch einen
Fehler einen physischen Schaden verursacht. Die Produzentenhaftung wiederum l&#228;sst den Hersteller haften, wenn 
er durch fehlerhaftes Verhalten nach Inverkehrbringen seines Produkts einen Schaden verursacht hat. Hersteller
k&#246;nnen au&#223;erdem nachtr&#228;glich nach &#167; 823 des B&#252;rgerlichen Gesetzbuchs (BGB) auch f&#252;r Verm&#246;genssch&#228;den
haften, wenn sie gegen die pr&#228;ventiven Schutzgesetze versto&#223;en haben. Dar&#252;ber hinaus kann der Hersteller aus
vertragsrechtlichen Anspr&#252;chen f&#252;r Sch&#228;den haften, die sein mangelhaftes Produkt verursacht hat. Im Grundsatz
gelten all diese Haftungsregelungen auch f&#252;r KI-Systeme, jedoch mit der Einschr&#228;nkung, dass noch nicht
abschlie&#223;end gekl&#228;rt ist, ob und inwieweit der &#8222;Produktbegriff&#8220; auch Software betrifft, die nicht in einem
k&#246;rperlichen Produkt integriert ist.
Zus&#228;tzlich zu den Pflichten und Schadensersatzanspr&#252;chen, die dem Hersteller auferlegt sind, gibt es die
Gef&#228;hrdungshaftung, welche den Betreiber, Hersteller oder Halter einer Gefahrenquelle in die Pflicht nimmt, f&#252;r
m&#246;gliche Sch&#228;den einzustehen. Sie setzt kein Verschulden voraus, sondern kn&#252;pft allein an die Tatsache an, dass
bspw. durch das Halten eines Haustiers oder den Betrieb eines Systems eine Gefahrenquelle geschaffen wurde.
Beispiele f&#252;r die Gef&#228;hrdungshaftung gibt es f&#252;r den Stra&#223;en-, Bahn- und Luftverkehr, f&#252;r die Haltung von
Haustieren sowie f&#252;r den Betrieb von Anlagen (z. B. Elektrizit&#228;t oder Atomanlagen). 
209 Die Essential-Facilities-Doktrin ist eine aus dem US-amerikanischen Wettbewerbsrecht stammende Lehre, die den Missbrauch einer
marktbeherrschenden Stellung durch sogenannte Gesch&#228;ftsverweigerung unterbinden will.
210 Handlungsempfehlungen von Prof. Dr. Rupprecht Podszun (Heinrich-Heine-Universit&#228;t D&#252;sseldorf), Projektgruppendrucksache
19(27)PG 6-25 vom 11. Februar 2020.
211 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 5.5 des Mantelberichts
(&#8222;Haftungsrecht &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo].
212 Vgl. Oetker (2019): &#167; 249 Rn. 8.
Derzeit werden mit Blick auf KI-Systeme verschiedene Konzepte betrachtet, um eventuell auftretende
Haftungsl&#252;cken zu schlie&#223;en. Grunds&#228;tzlich werden m&#246;gliche Haftungsl&#252;cken sowohl in der Verschuldenshaftung als
auch in der Gef&#228;hrdungshaftung gesehen. 
5.5.1 E-Person
Unter dem Stichwort Elektronische Person (&#8222;E-Person&#8220;) soll autonom agierenden Systemen und damit auch KI-
Systemen eine Rechtspers&#246;nlichkeit und eigene Verantwortung zugeschrieben werden.213 Die Enquete-
Kommission empfiehlt dem Deutschen Bundestag von dem Konzept der E-Person Abstand zu nehmen. Das Konzept
widerspricht der grunds&#228;tzlichen &#220;berzeugung der Enquete-Kommission, KI-Technologien als ein Werkzeug in
der Verantwortung des Menschen anzusehen.
5.5.2 Zurechnung der Haftung im Rahmen der Verschuldenshaftung
Beim Einsatz eines sch&#228;digenden KI-Systems ist die Haftung der Einsetzenden an einen Sorgfaltspflichtversto&#223; 
beim Einsatz oder bei der &#220;berwachung des KI-Systems gebunden. F&#252;r ein sorgfaltspflichtwidriges Handeln
einer autonom agierenden KI entsteht eine Haftungsl&#252;cke, insoweit die Sorgfaltspflichtverletzung keinen
menschlichen Ankn&#252;pfungspunkt findet. Ein Beispiel daf&#252;r w&#228;re etwa ein chirurgischer Roboter, der einen
fehlerhaften Eingriff bei richtiger Funktionsweise durchf&#252;hrt, etwa einen zu langen Operationsschnitt. W&#228;hrend das
Verschulden eines menschlichen Akteurs in diesen F&#228;llen demjenigen zugerechnet wird, der diesen
Erf&#252;llungsgehilfen214 einsetzt, entsteht in einem autonomen System keine Sorgfaltspflichtverletzung, die zugerechnet
werden k&#246;nnte. 
Trotz der Schwierigkeiten, in manchen Einzelf&#228;llen f&#252;r autonome Systeme eine angemessene Entsprechung der
Sorgfaltspflichtverletzung zu finden, h&#228;lt es beispielsweise die Datenethikkommission f&#252;r sinnvoll, eine
Zurechnung entsprechend der Regelungen der Erf&#252;llungsgehilfenhaftung (&#167; 278 BGB) f&#252;r autonome Systeme
vorzunehmen.215 &#220;ber die Frage, ob eine solche Zurechnung vorgenommen werden soll, wird derzeit rege in der
Rechtswissenschaft diskutiert.216 
5.5.3 M&#246;gliche Ausweitung der Gef&#228;hrdungshaftung
In der Rechtswissenschaft217 wird diskutiert, ob es weiterer Gef&#228;hrdungshaftungstatbest&#228;nde f&#252;r den Einsatz
autonomer KI-Systeme in besonders gef&#228;hrlichen Produkten bedarf. Aufgrund der zunehmenden Autonomie
moderner KI-Systeme stellt sich zunehmend die Frage, ob die Betreiber bzw. Halter oder unter Umst&#228;nden die
Hersteller die f&#252;r eine Verantwortungszuweisung mit relevante, dominierende Einflussm&#246;glichkeit auf die Systeme
haben. 
5.5.4 M&#246;gliche L&#252;cken in der Produkthaftung
Das Produkthaftungsrecht bietet einen speziellen Anspruch gegen den Hersteller eines Produkts, der zwischen
reiner Verschuldenshaftung und verschuldensunabh&#228;ngiger Gef&#228;hrdungshaftung steht. Der Gesch&#228;digte hat bei
einem materiellen Schaden einen Anspruch auf Schadenersatz gegen den Hersteller eines Produktes, wenn er den
Schaden, einen Fehler des Produkts und den urs&#228;chlichen Zusammenhang zwischen dem fehlerhaften Produkt
und dem Schaden nachweisen kann. Der Hersteller einer KI haftet danach nur insoweit, als das System bereits
beim Inverkehrbringen den Fehler hatte und er diesen nach Stand der Wissenschaft und Technik h&#228;tte erkennen
k&#246;nnen.
Momentan wird in Br&#252;ssel die &#220;berarbeitung der europ&#228;ischen Produkthaftungsrichtlinie im Hinblick auf neue 
Technologien gepr&#252;ft. Ein Aspekt der Debatte ist die &#220;berarbeitung des Produktbegriffes. Nach dem Wortlaut
des Produkthaftungsgesetzes ist als Produkt eine &#8222;bewegliche&#8220;, d. h. k&#246;rperliche Sache anzusehen. Ob
Haftungsvorschriften f&#252;r bewegliche Sachen auf KI-Systeme, die aus Computer-Algorithmen und damit aus Software
bestehen, angewendet werden k&#246;nnen, ist in der Rechtswissenschaft umstritten. Die EU-Kommission geht wohl
213 Vgl. Entschlie&#223;ung des Europ&#228;ischen Parlaments vom 16. Februar 2017 mit Empfehlungen an die Kommission zu zivilrechtlichen 
Regelungen im Bereich Robotik (2015/2103/INL), S. 28.
214 Als Erf&#252;llungsgehilfe wird eine Person benannt, die mit Wissen und Wollen des Schuldners bei Erf&#252;llung einer dem Schuldner
obliegenden Verbindlichkeit t&#228;tig wird und dabei von Weisungen des Schuldners abh&#228;ngig ist.
215 Vgl. Datenethikkommission der Bundesregierung (2019): Gutachten der Datenethikkommission der Bundesregierung, S. 219 f.
216 Vgl. Hacker (2020): Europ&#228;ische und nationale Regulierung von K&#252;nstlicher Intelligenz, S. 2142 ff. mit weiteren Nachweisen.
217 Vgl. u. a. Wendehorst (2016): Die Digitalisierung und das BGB; Pieper und Gehrmann (2019): K&#252;nstliche Intelligenz &#8211; Wer haftet?
davon aus, dass das Produkthaftungsrecht auch auf Software Anwendung findet.218 F&#252;r die gerichtliche
Auslegung der Vorschriften in den Mitgliedstaaten und durch den Europ&#228;ischen Gerichtshof (EuGH) ist das jedoch
nicht verbindlich. Nach der Rechtsprechung unterliegt aber jedenfalls derjenige der Produkthaftung, der Ger&#228;te
oder Ger&#228;tekomponenten mit eigen- oder fremdprogrammierter Software zur Steuerung oder Kontrolle des
Ger&#228;ts bzw. der Komponente in Verkehr bringt, beispielsweise Fahr- und Sprachassistenzsysteme oder Roboter.
Ein Produkt muss zum Zeitpunkt seines Inverkehrbringens die Sicherheit bieten, die berechtigterweise zu
erwarten ist. Andernfalls weist es einen Fehler auf, der eine Produkthaftung begr&#252;nden kann (vgl. &#167; 3 des
Produkthaftungsgesetz &#8211; ProdHaftG). Wenn allerdings der Fehler nach dem Stand der Wissenschaft und Technik zum
Zeitpunkt des Inverkehrbringens nicht zu vermeiden war, scheidet die Haftung des Herstellers aus (&#167; 1 Absatz 2
Nummer 5 ProdHaftG). Der Stand der Wissenschaft und Technik wird vor allem durch technische Standards,
z. B. DIN-, CEN- und ISO-Normen, indiziert. Auch f&#252;r KI werden solche Standards entwickelt, die sicherstellen 
sollen, dass Systeme bestimmte Qualit&#228;tsanforderungen erf&#252;llen.219 Dazu geh&#246;rt es z. B., eine Qualit&#228;tssicherung
der Trainingsdaten durchzuf&#252;hren, das erlernte Modell zu validieren und die Lernergebnisse zu kontrollieren und
zu testen.220 F&#252;r einzelne Produktkategorien sind sehr viel speziellere technische Vorgaben sogar gesetzlich
vorgeschrieben (z. B. f&#252;r Medizinprodukte).
Ein weiterer Diskussionspunkt ist die Frage, ob es notwendig ist, die Produkthaftung auf Produktfehler
auszuweiten, die erst nach dem Inverkehrbringen infolge sich selbst ver&#228;ndernder Software, erfolgter oder
pflichtwidrig unterlassener Updates oder produktspezifischer Daten auftreten, wof&#252;r sich z. B. auch die
Datenethikkommission ausgesprochen hat.221 Letztere d&#252;rfte in bestimmten F&#228;llen jedoch schon im Rahmen der
Produzentenhaftung gegeben sein, wonach Hersteller nach &#167; 823 Absatz 1 BGB je nach Risiko im Einzelfall auch Pflichten
zur Pflege oder zum Update eines KI-Systems treffen k&#246;nnen. Was nachtr&#228;glich im Lernvorgang entstehende
Fehler angeht, die bei Inverkehrbringen des Produkts noch nicht bestanden, w&#228;re allerdings auch denkbar, hierf&#252;r
im Rahmen bestehender Gef&#228;hrdungshaftungsregelungen L&#246;sungen zu finden.
Auch die Frage der Beweislast f&#252;r den Nachweis eines Fehlers von Seiten des Gesch&#228;digten wird derzeit
diskutiert. So spricht die Studie, welche die EU-Kommission zur Evaluierung der Produkthaftungsrichtlinie in Auftrag
gegeben hat, davon, dass 53 Prozent der abgewiesenen F&#228;lle wegen des Fehlens des Nachweises eines Fehlers
zur&#252;ckgewiesen werden.222 Bei komplexen Systemen, an deren Herstellung und Betrieb mehrere Akteure
beteiligt sind, k&#246;nnen Verursachungsbeitr&#228;ge f&#252;r einen konkreten Schaden generell schwierig zu ermitteln und
nachzuweisen sein. Die Rechtsprechung hat Gesch&#228;digten daher bereits gewisse Beweiserleichterungen wie
Anscheinsbeweis und Fehlervermutung einger&#228;umt. Allerdings besteht keine Einigkeit dar&#252;ber, ob diese
Erleichterungen ausreichend sind. Es kann einerseits sehr schwierig werden, diese f&#252;r lernende Algorithmen zu
analysieren und zu evaluieren. Andererseits k&#246;nnten aber auch neue M&#246;glichkeiten entstehen, das Verhalten von
autonomen Systemen zu &#252;berwachen.223 
Weitere Ausf&#252;hrungen zur Problematik der Haftung bei KI-Systemen finden sich in den
Projektgruppenberichten.224 
218 Die Kommission f&#252;hrt in dem bereitgestellten &#8222;inception impact assessment&#8220; zwar aus, dass noch keine finale Entscheidung gefallen 
ist, skizziert jedoch, neben der Beibehaltung des Status quo, bereits vier denkbare Szenarien f&#252;r die &#220;berarbeitung der Richtlinie
2001/95/EG.
219 Siehe z. B. verschiedene DIN SPECs unter https://www.din.de/de/forschung-und-innovation/themen/kuenstliche-intelligenz/stan-
dards-fuer-ki; ISO Standardisierungsprojekte unter https://www.iso.org/committee/6794475.html (zuletzt abgerufen am 9. Oktober
2020).
220 Vgl. dazu auch Russell und Norvig (2016): Artificial intelligence, Kapitel 19.
221 Vgl. Datenethikkommission der Bundesregierung (2019): Gutachten der Datenethikkommission der Bundesregierung, S. 222.
222 Vgl. Europ&#228;ische Kommission (2018): Bewertung der Richtlinie 85/374 / EWG des Rates vom 25. Juli 1985 &#252;ber die Ann&#228;herung
an die Gesetze, Verordnungen und Verwaltungsbestimmungen der Mitgliedstaaten betreffend Haftung f&#252;r fehlerhafte Produkte, S. 25.
223 Vgl. Wagner (2019): Robot Liability, S. 46.
224 Siehe auch den Bericht der Projektgruppe &#8222;KI und Wirtschaft&#8220; in Kapitel C. II. [K&#252;nstliche Intelligenz und Wirtschaft (Projektgruppe
1)], den Bericht der Projektgruppe &#8222;KI und Gesundheit&#8220; in C. IV. [K&#252;nstliche Intelligenz und Gesundheit (Projektgruppe 3)] und den
Bericht der Projektgruppe &#8222;KI und Mobilit&#228;t&#8220; in C. VI. [K&#252;nstliche Intelligenz und Mobilit&#228;t (Projektgruppe 5)].
5.5.5 Handlungsempfehlungen
1. Das bestehende Haftungssystem ist nach Auffassung der Enquete-Kommission grunds&#228;tzlich geeignet, auch
durch KI-Systeme verursachte Sch&#228;den auszugleichen. Eine dringende Notwendigkeit, neue
Haftungstatbest&#228;nde speziell f&#252;r KI-Systeme zu schaffen, wird derzeit nicht gesehen. Bei der Normierung von KI-
Systemen sollte jedoch in besonderem Ma&#223;e darauf geachtet werden, dass Vorg&#228;nge in KI-Systemen
nachvollziehbar und damit dem Beweis zug&#228;nglich sind.
2. Bestehende Rechtsunsicherheiten bzgl. der Anwendbarkeit bestehender Haftungstatbest&#228;nde auf KI-
Systeme k&#246;nnen und sollten im Rahmen der &#220;berpr&#252;fung der Produkthaftungsrichtlinie auch mit Blick auf
andere technologische Neuerungen beseitigt werden. Es wird daher angeregt zu pr&#252;fen, inwieweit das
geltende Haftungssystem einer punktuellen &#220;berarbeitung im Hinblick auf neue Technologien bedarf. 
3. Die Einf&#252;hrung neuer Haftungstatbest&#228;nde der Gef&#228;hrdungshaftung sollte nur dort erwogen werden, wo
explizit durch KI-Systeme neue Gefahren f&#252;r besonders wichtige Rechtsg&#252;ter geschaffen werden, die nicht
bereits durch bestehende Haftungsvorschriften adressiert werden. Es bietet sich im Hinblick auf den
europ&#228;ischen Wettbewerb an, derartige Regelungen &#8211; so sie in Zukunft f&#252;r erforderlich gehalten werden &#8211; auf 
europ&#228;ischer Ebene zu suchen. 
Einsatz von KI in der &#246;ffentlichen Verwaltung225 
Da sich die Enquete-Kommission an verschiedenen Stellen mit dem Einsatz von KI in der &#246;ffentlichen
Verwaltung auseinandergesetzt hat, insbesondere in der Projektgruppe &#8222;KI und Staat&#8220;, sollen hier die rechtlichen
Grundlagen dargelegt werden.
Die Verwaltung ist an Recht und Gesetz gebunden. Das Grundgesetz und die jeweils anwendbaren
datenschutzrechtlichen Regelungen, wie etwa die Datenschutzgesetze der L&#228;nder, das Bundesdatenschutzgesetz (BDSG) und
sehr eingeschr&#228;nkt auch die DSGVO selbst, gelten f&#252;r die Verwaltung deshalb ohnehin. Daneben existieren im
Verwaltungsrecht drei Vorschriften, die den Einsatzbereich von vollst&#228;ndig automatischer Entscheidungsfindung
definieren: &#167; 155 der Abgabenordnung (AO), &#167; 31a des Zehnten Buches Sozialgesetzbuch (SGB X) sowie &#167; 35a 
des Verwaltungsverfahrensgesetzes (VwVfG).
&#167; 35a VwVfG stellt eine allgemeine Bestimmung dar, die grunds&#228;tzlich von allen Teilen der &#246;ffentlichen
Verwaltung zu beachten ist. Doch auch diese Norm regelt nur einen kleinen Teil der denkbaren Anwendungsf&#228;lle
von KI in der &#246;ffentlichen Verwaltung.
Einschl&#228;gig ist die Norm nur dann, wenn ein Verwaltungsakt (VA) vollst&#228;ndig durch automatische Einrichtungen
erlassen wird, also dann, wenn das Handeln der &#246;ffentlichen Verwaltung auf die Setzung einer konkret-
individuellen oder konkret-generellen Rechtsfolge gegen&#252;ber Personen au&#223;erhalb des Rechtskreises der Verwaltung
gerichtet ist. Beispiele sind Geb&#252;hrenbescheide, Baugenehmigungen oder Verkehrszeichen. Dies bedeutet
zun&#228;chst, dass das schlichte Verwaltungshandeln nicht von der Vorschrift erfasst wird. Darunter versteht man das
Handeln einer Beh&#246;rde, das nicht auf die Setzung einer Rechtsfolge gerichtet ist. Schlichtes Verwaltungshandeln
durch KI k&#246;nnte beispielsweise in der Erteilung von Ausk&#252;nften oder Anleitungen zum Ausf&#252;llen eines
Formulars, etwa durch einen Chatbot, bestehen. 
Des Weiteren gilt &#167; 35a VwVfG nur f&#252;r die F&#228;lle, in denen der VA vollst&#228;ndig durch automatische Einrichtungen,
also ohne jegliches Zutun eines Menschen, erlassen wird. Spielt eine KI beim Erlass eines VA also lediglich eine
unterst&#252;tzende oder vorschlagende Rolle, greift die Vorschrift nicht.
Folgen f&#252;r vollst&#228;ndig automatisiert erlassene gebundene Verwaltungsakte
Wird ein VA vollst&#228;ndig durch automatische Einrichtungen erlassen, so verlangt &#167; 35a VwVfG, dass daf&#252;r eine
gesonderte Rechtsgrundlage gegeben sein muss und diese Rechtsgrundlage der Beh&#246;rde weder Ermessen noch
einen Beurteilungsspielraum einr&#228;umt. Ein Beurteilungsspielraum bedeutet, dass einer Beh&#246;rde eine
Entscheidungsfreiheit im Hinblick auf das Vorliegen einzelner Tatbestandsmerkmale zusteht. Bei diesen
Tatbestandsmerkmalen handelt es sich um unbestimmte Rechtsbegriffe, wie z. B. &#8222;Gemeinwohl&#8220; oder &#8222;&#246;ffentliches
Interesse&#8220;. Anders als bei &#8222;gew&#246;hnlichen&#8220; Tatbestandsmerkmalen k&#246;nnen Gerichte deren Beurteilung durch die
Verwaltung nur eingeschr&#228;nkt (d. h. auf offensichtlichen Missbrauch des Beurteilungsspielraums) &#252;berpr&#252;fen. Steht
225 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 5.6 des Mantelberichts (&#8222;Einsatz 
von KI in der &#246;ffentlichen Verwaltung &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds
Dr. Florian Butollo].
eine Entscheidung im Ermessen der Beh&#246;rde, so ist sie, wenn die Tatbestandsvoraussetzungen vorliegen, nicht
gezwungen, eine bestimmte Rechtsfolge zu setzen. Vielmehr kann sie entscheiden, ob und ggf. welche
Rechtsfolge im konkreten Fall eintreten soll. Auch die Aus&#252;bung des Ermessens kann gerichtlich &#252;berpr&#252;ft werden,
etwa auf die Ber&#252;cksichtigung sachfremder Erw&#228;gungen oder die Auswahl einer unzul&#228;ssigen Rechtsfolge.
F&#252;r den Einsatz von KI in der Verwaltung spielen die genannten Differenzierungen vor allem im Hinblick auf
die verfassungsrechtliche Rechtsweggarantie eine Rolle. Nach diesem Grundsatz (vgl. Artikel 19 Absatz 4 GG)
muss bei allen staatlichen Ma&#223;nahmen die M&#246;glichkeit einer gerichtlichen &#220;berpr&#252;fung bestehen. Damit
Gerichte die Ausf&#252;llung eines Beurteilungsspielraums oder die Aus&#252;bung eines Ermessens &#252;berpr&#252;fen k&#246;nnen,
m&#252;ssen sie die tragenden Erw&#228;gungen f&#252;r die jeweilige Entscheidung kennen. In diesen F&#228;llen k&#246;nnen daher nur
solche KI-Systeme zum Einsatz kommen, die einen Einblick in die f&#252;r die jeweilige Entscheidung tragenden
Erw&#228;gungen erlauben. Gerade diese Anforderung erf&#252;llen neuronale Netze und lernende KI-Systeme im
Gegensatz zu den klassischen (statischen) Expertensystemen (bislang) aber nicht. Solange die Entscheidungsfindung
eines KI-Systems f&#252;r Au&#223;enstehende eine &#8222;Black Box&#8220; bleibt, scheidet es also f&#252;r einen Einsatz in F&#228;llen mit 
Beurteilungsspielr&#228;umen und Ermessensentscheidungen derzeit noch aus.
M&#246;glich ist ein vollst&#228;ndig automatisierter VA-Erlass nach geltender Rechtslage demnach nur bei gesetzlich
explizit vorgesehenen226 gebundenen Entscheidungen, also in denjenigen F&#228;llen, in denen das Gesetz, wenn
bestimmte Tatbestandsvoraussetzungen vorliegen, das Setzen einer fest vorgegebenen Rechtsfolge vorschreibt
(typischerweise zu erkennen an der Verwendung von Wendungen wie &#8222;muss&#8220;, &#8222;ist zu&#8220;, &#8222;hat &#8230; zu&#8220;).
Folgen f&#252;r Verwaltungsakte, die mit KI-Unterst&#252;tzung erlassen werden
Wird KI beim Erlass eines VA lediglich unterst&#252;tzend eingesetzt, also beispielsweise als Entscheidungshilfe f&#252;r
einen menschlichen Sachbearbeiter, so ist dieser Fall bislang gesetzlich nicht geregelt. Ob es in diesen F&#228;llen
einer gesetzlichen Erm&#228;chtigungsgrundlage f&#252;r den KI-Einsatz bedarf, h&#228;ngt nach dem aus Artikel 20 Absatz 3
GG folgenden Vorbehalt des Gesetzes davon ob, ob der KI-Einsatz selbst eine spezifisch belastende Wirkung f&#252;r
die Adressatin oder den Adressaten entfaltet. Eine solche belastende Wirkung k&#246;nnte etwa in der Einschr&#228;nkung
der Entscheidungsautonomie der Sachbearbeiterin oder des Sachbearbeiters liegen. Je eher also empirisch
nachzuweisen w&#228;re, dass ein Sachbearbeiter typischerweise der Empfehlung des KI-Systems folgt, desto eher k&#228;me
dieser Empfehlung selbst eine belastende Wirkung zu. Ob und inwieweit der unterst&#252;tzende Einsatz von KI in 
der Verwaltung gesetzlich geregelt werden muss, h&#228;ngt demnach entscheidend von den Ergebnissen einer
Untersuchung &#252;ber die Auswirkungen von KI-Empfehlungen auf die Entscheidungsautonomie ab.
Handlungsempfehlungen227 
Die Frage, wohin sich die Rechtsordnung angesichts des Einsatzes von KI-Systemen entwickelt sollte, wird
derzeit intensiv diskutiert. Die von der Bundesregierung eingesetzten Kommissionen, die
&#8222;Datenethikkommission&#8220;228 und die &#8222;Kommission Wettbewerbsrecht 4.0&#8220;, haben bereits Empfehlungen zur Anpassung der
Gesetzeslage gegeben. Zudem hat die EU-Kommission mit dem Wei&#223;buch zur KI229 eine erste Diskussionsgrundlage
zur Harmonisierung der Regulierung auf EU-Ebene unterbreitet. Vor diesem Hintergrund haben auch die
Projektgruppen unter dem jeweils spezifischen Blickwinkel Empfehlungen gegeben. Grunds&#228;tzlich h&#228;lt die Enquete-
Kommission f&#252;r die zuvor beschriebenen Rechtsgebiete Folgendes fest:
226 Eine Erlaubnisnorm befindet sich z. B. in &#167; 31a Satz 1 SGB X f&#252;r das Sozialrecht, n&#228;her dargestellt im Bericht der Projektgruppe
&#8222;KI und Staat&#8220; in Kapitel C. III. [K&#252;nstliche Intelligenz und Staat (Projektgruppe 2)].
227 Zu diesem Kapitel liegen Sondervoten aus der Fraktion der CDU/CSU [Sondervotum zu Kapitel 1 der Kurzfassung des Berichts
(&#8222;Daten &#8220;) sowie Kapitel 5.7 des Mantelberichts (&#8222;KI und Recht &#8211; Handlungsempfehlungen &#8220;) des sachverst&#228;ndigen Mitglieds
Dr. Sebastian Wieczorek und der Abgeordneten Marc Biadacz, Hansj&#246;rg Durz, Ronja Kemmer, Jan Metzler, Stefan Sauer, Prof.
Dr. Claudia Schmidtke, Andreas Steier und Nadine Sch&#246;n sowie der sachverst&#228;ndigen Mitglieder Susanne Dehmel, Prof. Dr.
Wolfgang Ecker, Prof. Dr. Alexander Filipovi&#263;, Prof. Dr. Antonio Kr&#252;ger und Prof. Dr. J&#246;rg M&#252;ller-Lietzkow], aus der Fraktion der SPD
[Sondervotum zu Kapitel 5.7 des Mantelberichts (&#8222;KI und Recht &#8211; Handlungsempfehlungen &#8220;) der Abgeordneten Elvan Korkmaz-
Emre und des sachverst&#228;ndigen Mitglieds Jan Kuhlen, der Abgeordneten Arno Klare, Daniela Kolbe, Falko Mohrs und Ren&#233; R&#246;spel
sowie der sachverst&#228;ndigen Mitglieder Prof. Dr.-Ing. Sami Haddadin, Lena-Sophie M&#252;ller und Lothar Schr&#246;der], aus der Fraktion
der FDP [Sondervotum zu Kapitel 5.7 des Mantelberichts (&#8222; KI und Recht &#8211; Handlungsempfehlungen &#8220;) der Abgeordneten Mario 
Brandenburg, Carl-Julius Cronenberg und Daniela Kluckert sowie der sachverst&#228;ndigen Mitglieder Dr. Aljoscha Burchardt und
Andrea Martin] sowie aus der Fraktion DIE LINKE. [Sondervotum zu Kapitel 5.7 des Mantelberichts (&#8222;Handlungsempfehlungen &#8220; zu 
&#8222;KI und Recht&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo] vor.
228 Vgl. Datenethikkommission der Bundesregierung (2019): Gutachten der Datenethikkommission der Bundesregierung.
229 Vgl. Europ&#228;ische Kommission (2020): Wei&#223;buch zur K&#252;nstlichen Intelligenz &#8211; ein europ&#228;isches Konzept f&#252;r Exzellenz und
Vertrauen.
1. Die bestehenden Regelungen sollten auf ihre Anwendbarkeit auf neue KI-Systeme &#252;berpr&#252;ft und bei Bedarf
nachgebessert werden.
2. Die durch die DSGVO erreichte Balance zwischen Datenschutz und Innovation sollte erhalten werden.
Rechtsunsicherheiten, die sich bei der Interpretation der DSGVO-Vorschriften mit Blick auf die
Funktionsweise von KI-Systemen noch ergeben, sollten gekl&#228;rt werden. In Teilen sollte das durch eine
Konkretisierung der Vorgaben durch die in der DSGVO vorgesehene regulierte Selbstregulierung, also in Form von
Codes of Conduct und Zertifizierungen geschehen. Die Selbstverpflichtungen sollten nach f&#252;nf Jahren
evaluiert und bei Bedarf durch geeignete gesetzliche Regelungen ersetzt werden. Zum anderen sollten Probleme
durch Klarstellung beseitigt werden, die im Rahmen der DSGVO-Evaluierung festgestellt werden. Die
Grundprinzipien der DSGVO bleiben dabei unber&#252;hrt. Um den Einsatz datenschutzfreundlicher Verfahren
f&#252;r KI-Anwendungen zu f&#246;rdern, sollte beispielsweise die Rechtsunsicherheit bei der Anwendung von
Anonymisierungsverfahren reduziert werden, indem entweder bereits der Vorgang der Anonymisierung selbst
von der DSGVO ausgenommen oder eine ausdr&#252;ckliche Rechtsgrundlage hierf&#252;r geschaffen wird.230 
3. Die f&#252;r die Durchsetzung dieser Regelungen zust&#228;ndigen Stellen sollten durch Know-how und Ressourcen
gest&#228;rkt werden. Da es ohnehin schon zu viele verteilte Kompetenzen gibt, sollte davon abgesehen werden,
neue staatliche Aufsichtsbeh&#246;rden zur Kontrolle des KI-Einsatzes zu schaffen. Um die Aufsicht durch die
Landesdatenschutzbeh&#246;rden effizienter zu machen, sollten die Landesbeh&#246;rden zum einen besser mit
Ressourcen ausgestattet werden. Zum anderen ist eine verst&#228;rkte Abstimmung zwischen den Beh&#246;rden mit Blick 
auf eine koh&#228;rente Rechtsauslegung und -durchsetzung sowie eine st&#228;rkere Arbeitsteilung im Sinne einer
Spezialisierung einzelner Beh&#246;rden f&#252;r bestimmte Themenbereiche zu empfehlen. Eine weitere M&#246;glichkeit
w&#228;re &#8211; wie es die Datenethikkommission und angeh&#246;rte Expertinnen und Experten vorgeschlagen haben &#8211;
die Zust&#228;ndigkeit f&#252;r den privatwirtschaftlichen Bereich einer Aufsichtsbeh&#246;rde zu &#252;bertragen.231 Um
Detailfragen im KI-Bereich zu kl&#228;ren, sollte die Aufsicht auch privatwirtschaftliches Know-how einbeziehen 
(Zertifizierer o. &#196;.). Von einer pauschalen Offenlegung von Algorithmen wird abgeraten. Eher denkbar ist
die Einsichtnahme durch die zust&#228;ndige Datenschutzaufsicht oder eine sonstige bereichsspezifische
Aufsicht sowie die Einrichtung von Schnittstellen, wenn ein begr&#252;ndeter Verdacht auf Datenmissbrauch besteht, 
sodass nicht alle Algorithmen und KI-Anwendungen per se kontrolliert werden. 
4. Die Anonymisierung von personenbezogenen Daten ist eine Methode, um KI bereits heute
datenschutzkonform zu trainieren. Der Versuch, aus anonymisierten Daten R&#252;ckschl&#252;sse auf Personen zu ziehen, ist bisher
nicht strafbar. Gepr&#252;ft werden sollte, ob und inwieweit es sinnvoll w&#228;re, das vors&#228;tzliche De-Anonymisieren 
von Daten unter Strafe zu stellen.
5. Offenen Verwaltungsdaten wird u. a. ein hoher wirtschaftlicher Wert zugemessen, weil KI auf ihrer Basis 
trainiert werden kann. Innovative Produkte und Dienstleistungen k&#246;nnen aus der Verwendung oder
Kombination offener Verwaltungsdaten entstehen. Das Zur-Verf&#252;gung-Stellen von Open-Governmental-Data
sollte daher weiterentwickelt werden. Die Empfehlungen dazu werden im Bericht der Projektgruppe &#8222;KI
und Staat&#8220; dargelegt.
6. Die zentrale Norm des Verwaltungsverfahrensrechtes erlaubt den KI-Einsatz f&#252;r Verwaltungsakte nur dann,
wenn eine entsprechende Erlaubnisnorm existiert. Mit Blick auf das Verwaltungsrecht wird daher
empfohlen, die Pr&#252;fung weiterer Erlaubnisnormen gem&#228;&#223; &#167; 35a VwVfG vorzunehmen.
7. Im Urheberrecht wird kein Anpassungsbedarf gesehen, was den Werk- oder Urheberbegriff angeht.
Inwieweit sich eine wirtschaftliche Notwendigkeit im Sinne des Anreizgedankens f&#252;r ein neues verwandtes
Schutzrecht f&#252;r KI-Ergebnisse ergibt, ist weiter zu beobachten. Hierbei ist insbesondere zu ber&#252;cksichtigen,
ob eine solche Regelung zu Innovationshemmnissen oder einem Nachteil europ&#228;ischer
Technologieentwickler f&#252;hren w&#252;rde oder derartige Risiken sogar verhindert.
8. Die Regelungen der DSM-Richtlinie zu Text- und Data-Mining sollten z&#252;gig in nationales Recht umgesetzt
werden. Ob die Regelung ausreichend ist, um KI-Anwendungen zu erm&#246;glichen, muss in der Praxis weiter
beobachtet werden; gegebenenfalls sind weitergehende Schrankenregelungen auf europ&#228;ischer Ebene zu
pr&#252;fen. 
230 Das grundlegende Prinzip der Anonymisierung von Daten und daraus entstehende Herausforderungen in Bezug auf die DSGVO
werden in Kapitel 2 des Mantelberichts [KI und Daten] diskutiert.
231 Handlungsempfehlungen von Eva Gardyan-Eisenlohr (Konzerndatenschutzbeauftragte der Bayer AG), Kommissionsdrucksache 
19(27)97 vom 13. Januar 2020, S. 2.
9. Bei der Reform gilt es, die richtige Balance zwischen den Wachstumsm&#246;glichkeiten deutscher und
europ&#228;ischer Plattformen einerseits und der Verhinderung des Missbrauchs von Marktmacht andererseits zu finden.
10. Die Ergebnisse der Kommission Wettbewerbsrecht 4.0 werden als gute Grundlage gesehen, um das
Wettbewerbsrecht effizienter auszugestalten. Die Enquete-Kommission spricht sich daf&#252;r aus, diese und die in
den Projektgruppenberichten dargelegten Handlungsempfehlungen232 bei der Novellierung des nationalen
und europ&#228;ischen Wettbewerbsrechts zu ber&#252;cksichtigen. Insgesamt sollte &#8211; um Verzerrungen zu vermeiden
und KI in der Breite zu implementieren &#8211; eine st&#228;rkere Harmonisierung des Wettbewerbsrechts auf
europ&#228;ischer Ebene angestrebt werden. Die 10. GWB-Novelle k&#246;nnte hierf&#252;r ein gutes Vorbild sein. 
11. Im Zuge der 10. GWB-Novelle sind praxisnahe Vorgaben zur Dateninteroperabilit&#228;t und -portabilit&#228;t f&#252;r
Unternehmen mit &#252;berragender markt&#252;bergreifender Bedeutung einzuf&#252;hren. Dabei ist auch auf die
Interkonnektivit&#228;t zu achten, um kleinen Unternehmen die M&#246;glichkeit eines Markteintritts zu er&#246;ffnen.233 
6 Ethische Perspektiven auf KI234 
Ziele und Zwecke einer KI-Ethik
Neue technische M&#246;glichkeiten bieten Chancen, rufen aber auch Unsicherheiten hervor. Auch angesichts von
KI-Technologien stellen sich die Fragen nach dem guten und richtigen Umgang mit der Technologie. &#8222;Was sollen
wir tun?&#8220; &#8211; Diese Frage m&#246;chte die Ethik beantworten. Die Ethik besch&#228;ftigt sich mit dieser Frage aber in
besonderer Weise: Es geht bei Ethik letztlich um gl&#252;ckendes und gelingendes Leben und nicht blo&#223; um
pragmatische Regeln. Die Ethik fragt beispielsweise: Welchen &#252;bergeordneten Zielen k&#246;nnen wir Menschen uns
verpflichten und wie m&#252;ssen wir KI-Technologien und deren Einsatz gestalten, damit diese Ziele erf&#252;llt werden?
Einfacher: Wie wollen bzw. sollen wir leben &#8211; in einer Welt, in der es hochentwickelte KI-Technologie gibt?
Noch grundlegender: Was ist unsere Idee vom Menschsein in einer von KI-Technologie durchdrungenen Welt?
Ethik hat also nicht nur die Aufgabe, sogenannte rote Linien zu ziehen (etwa in Form einer moralisch begr&#252;ndeten
Absage an letale autonome Waffensysteme), sondern auch in positiver Hinsicht zu bestimmen, welchen Zielen
die Gestaltung von KI-Technologien und deren Einsatz folgen soll. Ethik im Sinne von geltenden moralischen
&#220;berzeugungen ist dabei das Ergebnis eines gesellschaftlichen Dialogs, in den sich praktische Philosophinnen
und Philosophen (Ethikerinnen und Ethiker), aber auch alle Menschen, Kirchen, zivilgesellschaftliche
Organisationen, Technikerinnen und Techniker, Politikerinnen und Politiker, Soziologinnen und Soziologen,
&#214;konominnen und &#214;konomen usw. einbringen k&#246;nnen und sollen.
Ethik hat in Sachen KI sicherlich zurzeit Konjunktur. Das ist verst&#228;ndlich: Es handelt sich um eine
leistungsf&#228;hige Technologie, deren Einsatz weitreichende Folgen f&#252;r Menschen und Gesellschaft haben kann. Dennoch 
stellt sich die Frage, ob eine so breit einsetzbare Technologie &#252;berhaupt das Objekt einer ethischen Betrachtung
sein kann. W&#252;rde man heute eine Ethik f&#252;r Elektrizit&#228;t oder den Einsatz von Verbrennungsmotoren fordern?
Oder eher eine Ethik f&#252;r die verschiedenen Einsatzgebiete bzw. Anwendungsf&#228;lle von KI?
Das Besondere an KI ist sicherlich, dass sie mit ihren F&#228;higkeiten dem Menschen punktuell nahekommt (siehe
Kapitel 1 des Mantelberichts [Begriffskl&#228;rung K&#252;nstliche Intelligenz]). Auch wenn also KI spezifisch
menschliche F&#228;higkeiten heute und auf mittlere Sicht h&#246;chstens simulieren kann, ist es doch besonders eindr&#252;cklich, mit
einem Computer relativ normal zu sprechen, einen Computer beim &#8222;Lernen&#8220; zu beobachten oder &#8222;Urteile&#8220; eines
Computers &#252;ber den Gesundheitszustand eines Menschen zu akzeptieren. Ethik ist im Feld KI wichtig, weil die
Maschinen zwar immer mehr leisten k&#246;nnen und in die Dom&#228;nen des Menschen eindringen, dabei aber nicht
gleichzeitig auch verantwortungsvoller werden &#8211; denn Verantwortung tragen kann nur ein Mensch. KI-Systeme
k&#246;nnen immer mehr, k&#246;nnen selbst aber nicht Verantwortung tragen: Dieses Auseinanderdriften von (immer
gr&#246;&#223;er werdender) &#8222;Handlungsmacht&#8220; einerseits und (fehlender) Verantwortung andererseits stellt einen
wichtigen Grund dar, mit dem Einsatz von KI-Systemen besonnen umzugehen.
232 Siehe auch den Bericht der Projektgruppe &#8222;KI und Wirtschaft in Kapitel C. II. [K&#252;nstliche Intelligenz und Wirtschaft
(Projektgruppe 1)]. 
233 Siehe auch Kapitel 5.5 des Mantelberichts [Haftungsrecht]. 
234 Zu diesem Kapitel liegen Sondervoten aus der Fraktion der AfD [Sondervotum zu Kapitel 6 des Mantelberichts (&#8222;Ethische
Perspektiven auf KI&#8220;) des Abgeordneten Dr. Marc Jongen sowie der Abgeordneten Joana Cotar und Peter Felser] sowie aus der Fraktion
DIE LINKE. [Sondervotum zu Kapitel 6 des Mantelberichts (&#8222;Ethische Perspektiven auf KI &#8220;) der Abgeordneten Dr. Petra Sitte und 
Jessica Tatti] vor.
Ethik darf aber nicht als Argument gegen jeglichen technologischen Wandel ins Feld gef&#252;hrt werden, auch wenn
die Gew&#246;hnung an die neue Technologie schwerfallen mag. Der parallel mit dem technologischen Wandel
einhergehende Wertewandel ist nicht per se schlecht, der Wertewandel geh&#246;rt zur Entwicklung von Mensch und
Gesellschaft. Aber Technikwandel und der damit verbundene Wertewandel brechen nicht &#252;ber die Menschen
herein, sondern sind Folgen des &#220;berlegens und Handelns der Menschen. Die technische Entwicklung braucht
daher unsere demokratische Gestaltung &#8211; und zwar auf der Basis einer moralischen &#220;bereinkunft &#252;ber gutes und
gerechtes Leben f&#252;r uns heute und f&#252;r zuk&#252;nftige Generationen. 
Wenn oben im Zusammenhang mit (schwacher!) KI235 von Lernen, Urteilen, Handeln etc. die Rede war, dann
muss an dieser Stelle davor gewarnt werden, diese Metaphern mit &#228;hnlichen Erwartungen aufzuladen, wie man 
sie an menschliches Lernen oder menschliche Urteile stellen w&#252;rde. Ein sorgsamer Sprachgebrauch geh&#246;rt
ebenfalls zur ethischen Betrachtung solch einer Technologie.
Kristallisationspunkt f&#252;r ethische Anspr&#252;che beim Thema KI ist das technische System (heute auch landl&#228;ufig
als &#8222;der Algorithmus&#8220; bezeichnet), dem gegen&#252;ber oft Unbehagen zum Ausdruck gebracht wird. Der Umstand,
dass KI-Systemen der Ruf anhaftet, sich als &#8222;unbeherrschbar&#8220; entwickeln zu k&#246;nnen, mag in ihrer nicht
ausreichenden Transparenz (s. u.) und Komplexit&#228;t begr&#252;ndet sein. Eine andere Begr&#252;ndung findet sich in
unzureichenden Informationen dar&#252;ber, in welche Handlungsnormen und in welchen sozialen Kontext, in welche ethischen
Prinzipien die Systeme eingebunden sind. Ethische Prinzipien zu erarbeiten und zu kommunizieren, kann daher
zur Akzeptanz beitragen, was wiederum als Voraussetzung daf&#252;r angesehen werden kann, dass die
wohlstandsversprechenden Potenziale von KI-Systemen als solche begriffen und umgesetzt werden k&#246;nnen.236 
Schlie&#223;lich ist auch das ein Argument f&#252;r eine Ethik, die eine wirtschaftlich-technische und allgemein
gesellschaftliche Entwicklung in Deutschland und Europa erm&#246;glichen und bef&#246;rdern m&#246;chte: In eine Technik sind
immer Werte ihrer Entwicklerinnen und Entwickler (also Programmiererinnen und Programmierer von
Algorithmen oder wichtiger noch &#8222;Trainerinnen&#8220; und &#8222;Trainer&#8220; von lernenden Systemen) &#8222;eingeschrieben&#8220;. Wenn wir in 
Deutschland und Europa nicht selbst diese Technologien entwickeln, m&#252;ssen wir Systeme benutzen, die andere
gebaut und gefertigt und entsprechend implizit mit ihren Werten versehen haben. Wenn wir die KI-Systeme nicht 
selbst herstellen, werden wir auch nicht unsere Werte in diese Technologien einschreiben k&#246;nnen.237 
Eine Ethik der KI gibt der politischen Gestaltung den Rahmen vor &#8211; und ist selbst in einem erweiterten Sinn
Ergebnis eines politischen Prozesses, n&#228;mlich dem gesellschaftlichen Diskurs &#252;ber Chancen und Grenzen der KI. 
Dieser Bericht zielt letztlich darauf ab, dem Gesetzgeber Handlungsvorschl&#228;ge zu machen, die sich dann in
Gesetzen wiederfinden sollen. Aber auch das Recht kann und soll nicht alles regeln; das Recht l&#228;sst Platz f&#252;r
eigenverantwortliches Handeln von Individuen und Organisationen. Auch in diesem Bereich ist Ethik von Bedeutung,
indem sie Hinweise gibt, wie man &#252;ber das Recht hinaus oder bei Rechtsunsicherheit verantwortlich agieren
kann.
Ethische Perspektiven auf KI (Prinzipien, Werte)
KI bietet zusammen mit der Digitalisierung von Prozessen in vielen Bereichen Chancen, die f&#252;r mehr
Transparenz, Chancengleichheit, Verteilungsgerechtigkeit, schnellere Dienstleistungen, Inklusion oder Nachhaltigkeit 
sorgen k&#246;nnen. Ethische Herausforderungen werden in der KI in den Bereichen selbstfahrende Autos,
Gesundheitswesen, autonome Waffensysteme, politische Manipulation durch KI-Anwendungen, Gesichtserkennung,
algorithmische Diskriminierung, soziale Sortierung durch Ranking-Algorithmen, Filterblasen, interaktive Bots
usw. gesehen. Die Chancen und Probleme kommen im Bericht zur Sprache. In diesem allgemeinen Teil sollen
vor allem die grundlegenden ethischen Perspektiven auf KI festgehalten werden.
Angesichts von Globalisierung und der Marktmacht einzelner privater Unternehmen bei der Entwicklung und
Umsetzung von KI stellt sich die Frage, ob Deutschland und Europa es schaffen werden, &#252;ber die rechtlichen und
ethischen Standards bei KI zu entscheiden, oder ob die Agenda von den gro&#223;en geopolitischen Akteuren wie den
USA und China dominiert werden wird. Damit w&#228;re die Gestaltung der KI-Technologie wesentlich von politi-
235 Siehe auch Kapitel 1 des Mantelberichts [Begriffskl&#228;rung K&#252;nstliche Intelligenz]. 
236 Zur gesellschaftlichen Wahrnehmung und Akzeptanz die Pr&#228;sentationen der sachverst&#228;ndigen Mitglieder Susanne Dehmel,
Kommissionsdrucksache 19(27)25, und Lena-Sophie M&#252;ller, Kommissionsdrucksache 19(27)26 vom 11. Februar 2019.
237 Dies betrifft auch die Daten, die f&#252;r das Training und den Betrieb von KI-Systemen genutzt werden: Diese selbst m&#252;ssen unter guten 
und richtigen rechtlichen und ethischen Umst&#228;nden erhoben worden sein.
schen und wirtschaftlichen (Partikular-)Interessen geleitet statt durch gesamtgesellschaftliche und ethische
Erw&#228;gungen. Auch deswegen muss die Kommission die moralischen Grundlagen kl&#228;ren, die in der Gesetzgebung
leitend wirken sollen.238 
Eine Vielzahl von Akteuren hat im Laufe der j&#252;ngsten Zeit Vorschl&#228;ge f&#252;r Prinzipien und Leitlinien zum
ethischen Einsatz von KI ver&#246;ffentlicht. Das &#8222;AI Ethics Guidelines Global Inventory&#8220; der gemeinn&#252;tzigen
Organisation &#8222;Algorithm Watch&#8220; z&#228;hlte im Juli 2019 insgesamt 83 katalogisierte KI-Richtlinien.239 In den meisten
Leitlinien werden Anforderungen hinsichtlich Gleichheit/Nicht-Diskriminierung, Rechenschaftspflichten und
Sicherheit formuliert, erg&#228;nzt um soziale Vertr&#228;glichkeit und Menschenrechte. Die Schnittmenge von ethischen
Anspr&#252;chen dr&#252;cken sich aus in den Begriffen Transparenz und Erkl&#228;rbarkeit, Fairness, Sicherheit und Stabilit&#228;t,
Arbeitsgestaltung, Accountability (Rechenschaftspflicht) und Verantwortung, Wahrung von
Pers&#246;nlichkeitsrechten und Gemeinwohlorientierung. Prominente und f&#252;r den deutschen Kontext einschl&#228;gige Prinzipien und
Leitlinien sind beispielsweise:
&#8226; Ethik-Leitlinien f&#252;r eine vertrauensw&#252;rdige KI (Hochrangige Expertengruppe f&#252;r K&#252;nstliche Intelligenz der
Europ&#228;ischen Kommission), ver&#246;ffentlicht am 8. April 2019240 
&#8226; Gutachten der Datenethikkommission der Bundesregierung, ver&#246;ffentlicht am 23. Oktober 2019241 
&#8226; Montrealer Erkl&#228;rung f&#252;r eine verantwortungsvolle Entwicklung von KI (Universit&#228;t Montreal) / Montr&#233;al
Declaration for a Responsible Development of Artificial Intelligence (Universit&#233; de Montr&#233;al)242,
ver&#246;ffentlicht am 4. Dezember 2018
&#8226; KI-Prinzipien der Akademie f&#252;r KI von Bejing / Bejing AI Principles (Bejing Academy of Artificial
Intelligence)243, ver&#246;ffentlicht am 25. Mai 2019
&#8226; Leitfaden f&#252;r ein ethik- und wertorientiertes Design &#8211; 1. Auflage / Ethically Aligned Design &#8211; 1st Edition
(Institute of Electrical and Electronics Engineers &#8211; IEEE), ver&#246;ffentlicht am 25. M&#228;rz 2019244 
Die Enquete-Kommission will diesen KI-Ethik-Leitlinien keinen weiteren Katalog hinzuf&#252;gen. Sie verweist auf
Untersuchungen, die diese Ethik-Kataloge vergleichen und kritisch evaluieren.245 Eine Untersuchung246 hat
84 KI-Ethik-Dokumente analysiert und die Erw&#228;hnung &#8222;ethischer Prinzipien&#8220; (moralische Wertbegriffe) gez&#228;hlt.
Dabei hat sich folgende Rangliste ethischer Prinzipien im Kontext von KI ergeben:
&#8226; Transparenz (73/84): Transparenz, Erkl&#228;rbarkeit, Verst&#228;ndlichkeit, Interpretierbarkeit, Kommunikation,
Offenlegung, Darstellung
&#8226; Gerechtigkeit und Fairness (68/84): Gerechtigkeit, Fairness, Koh&#228;renz, Inklusion, Integration, Gleichheit,
(Nicht-)Voreingenommenheit, (Nicht-)Diskriminierung, Vielfalt, Pluralit&#228;t, Zug&#228;nglichkeit,
Umkehrbarkeit, Rechtsmittel, Rechtsbehelf, Zugang, Teilhabe und Verteilung
&#8226; Nicht-Sch&#228;dlichkeit (60/84): Nicht-Sch&#228;dlichkeit, Sicherheit, Schutz, Schaden, Vorsorge, Pr&#228;vention,
Integrit&#228;t (k&#246;rperlich oder geistig)
&#8226; Verantwortung (60/84): Verantwortung, Verantwortlichkeit, Haftung, integres Handeln 
&#8226; Datenschutz (47/84) Datenschutz, pers&#246;nliche oder private Informationen 
&#8226; Nutzen (41/84): Nutzen, Wohlt&#228;tigkeit, Wohlbefinden, Frieden, soziales Gut, Gemeinwohl
&#8226; Freiheit und Autonomie (34/84): Freiheit, Autonomie, Zustimmung, Wahl, Selbstbestimmung, Freiheit,
Erm&#228;chtigung
238 Vgl. Daly et al. (2019): Artificial Intelligence Governance and Ethics: Global Perspectives.
239 Weitere Informationen dazu unter: https://algorithmwatch.org/en/project/ai-ethics-guidelines-global-inventory/ (zuletzt abgerufen 
am 6. August 2020).
240 Vgl. High-Level Expert Group on Artificial Intelligence (2019): Ethik-Leitlinien f&#252;r eine vertrauensw&#252;rdige KI.
241 Vgl. Datenethikkommission der Bundesregierung (2019): Gutachten der Datenethikkommission der Bundesregierung.
242 Weitere Informationen dazu unter: http://montrealdeclaration-responsibleai.com/ (zuletzt abgerufen am 6. August 2020).
243 Vgl. Bejing Academy of Artificial Intelligence (2019): Beijing AI Principles.
244 Abrufbar unter: https://standards.ieee.org/content/dam/ieee-standards/standards/web/documents/other/ead1e.pdf?utm_medium=
undefined&amp;utm_source=undefined&amp;utm_campaign=undefined&amp;utm_content=undefined&amp;utm_term=undefined (zuletzt abgerufen am
19. August 2020).
245 Z. B. Hagendorff (2020): The Ethics of AI Ethics: An Evaluation of Guidelines.
246 Vgl. Jobin et al. (2019): The global landscape of AI ethics guidelines.
&#8226; Vertrauen (28/84): Vertrauen 
&#8226; Nachhaltigkeit (14/84): Nachhaltigkeit, Umwelt (Natur), Energie, Ressourcen
&#8226; W&#252;rde (13/84): W&#252;rde
&#8226; Solidarit&#228;t (6/84): Solidarit&#228;t, soziale Sicherheit, Zusammenhalt
Die Enquete-Kommission hat den ethischen Handlungsrahmen anhand relevanter Prinzipien wie
Menschenw&#252;rde, Verantwortung oder Autonomie in ihren Sitzungen untersucht und legt diese &#220;berlegungen ihren
Handlungsempfehlungen zugrunde.247 
Den gr&#246;&#223;eren Rahmen f&#252;r die Gestaltung von KI geben das Grundgesetz der Bundesrepublik Deutschland und
die Grundrechtecharta der Europ&#228;ischen Union mit dem Begriff der Menschenw&#252;rde als Ma&#223;gabe f&#252;r alle
politische Gestaltung. Kein Einsatz von KI-Technologie darf diese W&#252;rde beschr&#228;nken, KI-Technologie ist so zu 
gestalten und einzusetzen, dass sie die W&#252;rde des Menschen (und die Idee der Menschenw&#252;rde schlechthin)
mindestens nicht gef&#228;hrdet, idealerweise sch&#252;tzt und bef&#246;rdert. Damit dies geschehen kann, sind folgende Werte
bei der Regulierung, bei der Entwicklung und bei der Anwendung von KI-Technologie zu ber&#252;cksichtigen:
6.2.1 Autonomie (Selbstbestimmung des Menschen als Handelnder, Entscheidungsfreiheit,
Nicht-Manipulation)248 
In modernen demokratischen Gesellschaften ist Freiheit der zentrale Wert.249 Der Dreiklang Freiheit, Gleichheit
und Geschwisterlichkeit stellt das politisch-ethische Erbe der Aufkl&#228;rung dar. Die Menschenrechte k&#246;nnen in
ihrer Gesamtheit (Abwehrrechte und Sozialrechte) als Freiheitsrechte verstanden werden, der Respekt vor den
Menschenrechten und ihre Einhaltung sichern die Freiheit aller Menschen. Freiheit als moralische Kategorie hat
wesentlich zwei Bedeutungen:
1. die (rechtliche) Freiheit des Menschen von Zw&#228;ngen (etwa staatlichen), beispielsweise die Reisefreiheit
2. die (positive) Freiheit zur Entscheidung , wobei die Freiheitsm&#246;glichkeiten des Menschen auch konkret
genutzt werden k&#246;nnen, beispielsweise die Verf&#252;gung &#252;ber Ressourcen, die das Reisen erm&#246;glichen
(Wohlstand, Bildung, Selbstsicherheit).
Im Zuge der Aufkl&#228;rung betont Immanuel Kant, dass Freiheit das Verm&#246;gen ist, sich in sittlicher (rechtlicher)
Hinsicht selbst bestimmen zu k&#246;nnen (Autonomie). Darin liegt die W&#252;rde des Menschen begr&#252;ndet. Dieses
Verst&#228;ndnis der Freiheit als Autonomie betont die moralisch geforderte Selbstbestimmung des Menschen als
Handelnder, betont mit Blick auf KI das Recht des Menschen, ihn betreffende Entscheidungen zu kennen, sie
nachvollziehen und Einspruch erheben zu k&#246;nnen. KI-Systeme d&#252;rfen also die menschliche Selbstbestimmung nicht
beschr&#228;nken. Autonomie betont damit auch das grunds&#228;tzliche Recht auf Nicht-Manipulation. Die positive
Freiheit bringt aber auch in den Blick, dass die KI-Systeme Mittel sein k&#246;nnen, die Handlungsfreiheit des Menschen
zu erweitern. Freiheit bzw. Autonomie ist damit auf grunds&#228;tzlicher Ebene moralisches Leitprinzip f&#252;r KI.
Konkret wird dies beispielsweise durch Human-in-the-Loop-, Human-on-the-Loop- und Human-in-Command-
Ans&#228;tze erreicht.250 
247 Siehe auch der separat behandelte Begriff der Nachhaltigkeit in Kapitel 8 des Mantelberichts [KI und &#246;kologische Nachhaltigkeit]
und das Thema &#8222;Sicherheit und Datenschutz&#8220; in Kapitel 2 des Mantelberichts [KI und Daten].
248 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion der FDP vor [Sondervotum zu den Kapiteln 3 und 6.2.1 des Mantelberichts
(&#8222; KI und Umgang mit Bias/Diskriminierung &#8220; und &#8222; Autonomie (Selbstbestimmung des Menschen als Handelnder,
Entscheidungsfreiheit, Nicht-Manipulation) &#8220;) der Abgeordneten Mario Brandenburg, Carl-Julius Cronenberg, Daniela Kluckert und Jessica Tatti
sowie der sachverst&#228;ndigen Mitglieder Dr. Aljoscha Burchardt und Andrea Martin].
249 Vgl. Thesen des sachverst&#228;ndigen Mitglieds Prof. Dr. Alexander Filipovi&#263;, Kommissionsdrucksache 19(27)34 vom 11. M&#228;rz 2019.
250 Drei Ans&#228;tze zur Rolle der KI bei der Entscheidungsfindung:
1. &#8222;Human in the loop&#8220;: Bei diesem Ansatz k&#246;nnen Menschen die von einem KI-Produkt getroffenen Entscheidungen direkt
beeinflussen oder &#228;ndern.
2. &#8222;Human on the loop&#8220;: Bei diesem Ansatz, beispielsweise bei einem Notbremsassistenten, legen Expertinnen bzw. Experten
w&#228;hrend der Entwicklung bestimmte Parameter als Grundlage f&#252;r die Entscheidung des KI-Systems fest; in die Entscheidung selbst
k&#246;nnen sie nicht eingreifen. Im Nachhinein &#252;berpr&#252;fen die Entwicklerinnen und Entwickler, ob sich die Maschine an die vom
Menschen gegebenen Vorgaben gehalten hat. Falls n&#246;tig, k&#246;nnen die Parameter ver&#228;ndert werden.
3. &#8222;Human in command&#8220;: Bei diesem Ansatz wird das KI-Produkt lediglich als Werkzeug verwendet. Der Mensch entscheidet zu
jeder Zeit, wann und wie er die durch das Werkzeug dargestellten Ergebnisse nutzt. Ein Beispiel ist, wenn eine Maschine
Menschen bei Aufgaben hilft.
6.2.2 Menschsein (Mensch-Maschine-Interaktion, Selbstverst&#228;ndnis)
Das Menschenbild ist wesentlich mit der Menschenw&#252;rde verkn&#252;pft.251 Der Mensch begreift sich als Person, als
ein einzigartiges, freies, vernunftbegabtes Wesen, das mit unver&#228;u&#223;erlicher W&#252;rde ausgestattet ist. Daneben
versteht der Mensch sich aber auch als Bed&#252;rfniswesen, sieht sich als solidarisches Wesen, hat ganz unterschiedliche
Vorstellungen vom guten Leben usw. Technische und andere wissenschaftliche Umbr&#252;che f&#252;hren nun dazu,
&#8222;dass wir uns selbst in einem anderen Licht betrachteten und unser Selbstverst&#228;ndnis&#8220; korrigieren.252 Im Kontext
von KI kann das bedeuten: Der Mensch sieht zwar eine punktuelle &#8222;Menschen&#228;hnlichkeit&#8220; der KI-Systeme,
erkennt aber gerade in dieser &#196;hnlichkeit seine fundamentale Unterschiedlichkeit, die er in Abgrenzung unter
Umst&#228;nden jetzt sogar noch st&#228;rker betont. Er versteht sich also angesichts der KI-Systeme selbst nicht blo&#223; als
&#8222;neuronales Netz&#8220;, er begreift sich nicht als eine selbstlernende Maschine. Menschen begreifen sich nicht als
Systeme und triviale Maschinen, die &#252;ber Optimierung von Input zielgerichtet verbessert werden k&#246;nnen und
sollen. Erstrebenswert sind daher eine Welt und eine Gesellschaft, in der Menschen nicht in ihrer Technologie
aufgehen. Der Begriff des Mensch-Seins, das Bild des Menschen von sich selbst, kann insofern eine ethische
Korrektur einer Perspektive sein, die die Logik von KI-Systemen in einer Rangfolge vor den Menschen stellt.
Diese allgemeinen ethischen &#220;berlegungen zur Menschenw&#252;rde und zum menschlichen Selbstverst&#228;ndnis zeigen
sich in der Praxis im Verh&#228;ltnis von Mensch und Maschine, also in Interaktionen zwischen Menschen und KI-
Systemen. Ausgehend von der Idee der Menschenw&#252;rde kann es nicht darum gehen, Menschen schlechthin durch
KI-Systeme zu ersetzen. Abgesehen von der Frage, ob und in welchen Bereichen eine solche &#8222;Ersetzung&#8220;
&#252;berhaupt m&#246;glich ist, ist vielmehr die Perspektive einer dem Wohl und der W&#252;rde des Menschen
entgegenkommenden, produktiven Zusammenarbeit von Mensch und KI-System wichtig. In einer solchen recht verstandenen
Mensch-KI-System-Interaktion ist der Mensch gestaltendes Subjekt und pr&#228;gt die Interaktion.
6.2.3 Vertrauen (Zuversicht, Optimismus, Kritik, Zusammenhalt)
Ohne Vertrauen in die sozio-technischen Systeme, mit denen KI eingesetzt wird, k&#246;nnen sich deren
N&#252;tzlichkeitspotenziale nicht entfalten. Vertrauen ist eine Leistung des Menschen, die an viele Bedingungen gekn&#252;pft ist, 
in unserem Kontext u. a. an Verst&#228;ndnis, an eine plausible, erfahrungsgem&#228;&#223;e oder regulatorisch sichergestellte
Vertrauensw&#252;rdigkeit von KI-Systemen. In immer komplexer werdenden technischen Umwelten ist Vertrauen
eine notwendige Voraussetzung, um am gesellschaftlichen Leben teilzunehmen. Vertrauensw&#252;rdigkeit von
Technik gesellschaftsweit zu gew&#228;hrleisten wird dabei immer wichtiger und gleichzeitig immer schwieriger. Im
Umgang mit Menschen oder Institutionen hat Vertrauen dennoch immer einen optimistischen Vorschuss-Charakter:
Man erhofft sich ein gutes Ergebnis und akzeptiert seine Verletzlichkeit gegen&#252;ber dem Vertrauensnehmer.253 
Bei KI-Systemen ist ein technisches System der Vertrauensgegenstand. Vertrauensw&#252;rdigkeit speziell von KI-
Systemen ist dabei ein anspruchsvolles Ziel: Es handelt sich um vermittelte Mensch-Maschine-Mensch-
Interaktion, wobei die eingeschr&#228;nkte Kontrolle beim Lernprozess ebenso ein wichtiges Moment darstellt wie der
Nutzungskontext, der kritisch ist f&#252;r das Funktionieren des Systems. Aus dieser noch komplizierteren &#8222;Akteurslage&#8220;
ergibt sich eine Forderung nach Transparenz, Nachvollziehbarkeit und Erkl&#228;rbarkeit von KI-Systemen (siehe
Kapitel 4 des Mantelberichts [KI und Umgang mit Risiko]).
6.2.4 Gemeinwohl (Wohlstandsf&#246;rderung, Benefits, Interessen)254 
Der Begriff &#8222;Gemeinwohl&#8220; wird im Zusammenhang mit KI nicht klar von Begriffen wie &#8222;Gemeinnutz&#8220;
abgegrenzt. Es geht hier weniger wie in der politischen Philosophie um abstrakte &#220;berlegungen zur Limitation und
Legitimation von Herrschaft, sondern eher um die Frage, wer vom durch KI erwirtschafteten Wohlstand profitiert
und wessen Interessen vertreten werden. Insofern w&#228;re eine erste Begriffsbestimmung im ethischen Interesse:
Das Gemeinsame soll in besonderer Weise Ber&#252;cksichtigung finden &#8211; dies fordert die ethische Norm des Ge-
251 Vgl. Thesenpapier des sachverst&#228;ndigen Mitglieds Prof. Dr. Alexander Filipovi&#263;, Kommissionsdrucksache 19(27)34 vom 11. M&#228;rz 
2019.
252 Floridi (2015): Die 4. Revolution.
253 Vortragsthesen von Prof. Dr. Joachim Fetzer (wissenschaftlicher Direktor des Zentrums f&#252;r Wirtschaftsethik),
Kommissionsdrucksache 19(27)36 vom 1. April 2019.
254 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion der FDP vor [Sondervotum zu Kapitel 6.2.4 des Mantelberichts (&#8222; Ethische
Perspektive auf KI &#8211; Gemeinwohl (Wohlstandsf&#246;rderung, Benefits, Interessen)&#8220;) der Abgeordneten Mario Brandenburg, Carl-Julius
Cronenberg und Daniela Kluckert sowie der sachverst&#228;ndigen Mitglieder Dr. Aljoscha Burchardt und Andrea Martin].
meinwohls von Handlungsakteuren. Damit betont der Begriff des Gemeinwohls, dass neben individuellen
(privaten) Interessen auch &#252;berindividuelle (gemeinsame, &#246;ffentliche) Interessen Ma&#223;st&#228;be des Handelns sein
k&#246;nnen und sollen.255 
Um dem staatlich getriebenen Ansatz Chinas und dem privatwirtschaftlich getriebenen Ansatz der USA etwas
entgegenzusetzen, wird in Europa h&#228;ufig Gemeinwohl-Orientierung vorgeschlagen. Problematisch ist hierbei
aber die Frage, inwieweit moderne Gesellschaften ein einheitliches Welt- und Menschenbild haben, worauf sich
der Begriff Gemeinwohl beziehen soll oder wer die Definitionsmacht hat. Ein Vorschlag ist, anstelle dieses
Begriffs eher ein dynamisches Strukturprinzip im Zusammenwirken von Politik, Wirtschaft, gesellschaftlichem
Diskurs und Wissenschaft zu entwickeln.256 KI-Systeme sollen danach, ethisch gesprochen, in einem
gesellschaftsweiten, diskursiven Prozess im Hinblick auf &#246;ffentliche Interessen evaluiert werden.
6.2.5 Verantwortung (Gutes tun, Akteure, Zusammenarbeit)
Der Begriff der Verantwortung macht darauf aufmerksam, dass es ein wichtiges Kennzeichen einer moralischen
Handlung ist, die Folgen seiner eigenen Handlung abzusehen und zu bewerten und sein Handeln dann evtl. auch
zu ver&#228;ndern. Handeln gem&#228;&#223; einer klugen und vern&#252;nftigen Einsch&#228;tzung der Folgen des eigenen Handelns
unter Hinzuziehung von moralischen Kriterien (Werten, Normen, Prinzipien, Maximen) &#8211; das kann man
moralisch verantwortliches Handeln nennen.
Besonders in komplizierten Zusammenh&#228;ngen ist die Verantwortung f&#252;r moralische Folgen wichtig und komplex
zugleich. In unserer technischen Zivilisation, in der alles mit allem zusammenh&#228;ngt, kann Handeln riskant sein.
Der &#8222;Ruf nach Verantwortung&#8220;257 reagiert auf diese Situation und fordert bedachtes Handeln ein.
Im Kontext der KI sind von dieser Forderung alle Akteure betroffen, wirtschaftliche wie politische Akteure in
verschiedener Weise. Rechenschaftspflicht soll besonders von Akteuren eingefordert werden, die KI-Systeme 
verwenden. Ausgehend von diesen ethischen &#220;berlegungen sollten Mechanismen geschaffen werden, die
Verantwortung und Rechenschaftspflicht f&#252;r KI-Systeme und ihre Ergebnisse gew&#228;hrleisten.
6.2.6 Transparenz (Nachvollziehbarkeit, Erkl&#228;rbarkeit, Offenheit)
Vertrauen st&#252;tzt sich aber auch auf Anforderungen hinsichtlich der Kontrollierbarkeit und
Erwartungskonformit&#228;t. Derartige Bedingungen werden unter einem ethisch &#8222;vieldeutigen Transparenzbegriff&#8220; er&#246;rtert.258 Mit diesem 
Begriff verbinden sich unterschiedliche Regulationsvorstellungen zum KI-Einsatz. Es geht u. a. um Transparenz
in Bezug auf den Einsatz von KI-Systemen selbst sowie um Transparenz der Datenherkunft und ihrer
Stimmigkeit, der Systemziele und Verarbeitungsparameter, der Verantwortlichkeiten und Stufen der autonomen
Schlussfolgerungen sowie der Kontroll- und Revisionsmechanismen. 
Insofern bietet Transparenz als ethischer Begriff eine wichtige, wenngleich unscharfe Orientierung. In ethischer
Perspektive wird damit besonders betont, dass dem Menschen &#252;berhaupt Ver&#228;nderungsm&#246;glichkeiten gegen&#252;ber
KI-Systemen in der Hand bleiben m&#252;ssen. Der ethische Begriff der Transparenz hat daher zum Ziel, den Einsatz
von KI-Komponenten in einem System erkennbar zu machen und seine relevanten Eigenschaften zu beschreiben.
Eine solche Kenntnis ist notwendig, um eine bewusste Entscheidung &#252;ber die Nutzung des KI-Systems zu
erm&#246;glichen und damit dem Kriterium der menschlichen Freiheit und Autonomie zu gen&#252;gen.259 &#8222;Transparenz
versetzt Betroffene in die Lage, ihr Verhalten anzupassen, um Entscheidungen zu beeinflussen. Transparenz ist 
f&#252;r Betroffene und ihre Vertreterinnen und Vertreter eine unverzichtbare Grundlage, um Rechtsverletzungen zu
identifizieren und Rechte durchzusetzen.&#8220;260 
255 Vgl. Filipovi&#263; (2017): Gemeinwohl als medienethischer Begriff. &#220;ber &#246;ffentliche Kommunikation und gesellschaftliche
Mitverantwortung, S. 10.
256 Vgl. Vogel (2013): Gemeinwohl oder: Die gute Ordnung f&#252;r die Gesellschaft.
257 Kaufmann (1992): Der Ruf nach Verantwortung.
258 Handlungsempfehlungen von Carla Hustedt (Projektleitung &#8222;Ethik der Algorithmen&#8220;, Bertelsmann Stiftung),
Kommissionsdrucksache 19(27)45 vom 6. Mai 2019.
259 Siehe dazu auch die Begriffe &#8222;Nachvollziehbarkeit&#8220; und &#8222;Erkl&#228;rbarkeit&#8220; in Kapitel 4.2 des Mantelberichts [Transparenz,
Nachvollziehbarkeit und Erkl&#228;rbarkeit].
260 Handlungsempfehlungen von Carla Hustedt (Projektleitung &#8222;Ethik der Algorithmen&#8220;, Bertelsmann Stiftung),
Kommissionsdrucksache 19(27)45 vom 6. Mai 2019.
Wie die ethischen Transparenzanforderungen technisch umgesetzt werden k&#246;nnen und m&#252;ssen, kann die Ethik
selbst nicht mehr kl&#228;ren (siehe dazu auch Kapitel 4 des Mantelberichts [KI und Umgang mit Risiko]).261 
6.2.7 Gerechtigkeit (Partizipation/Teilhabe, Verteilung, Leistung)
Die Frage nach der Gerechtigkeit steht seit jeher im Zentrum politischer und gesellschaftlicher Debatten. In
mancherlei Hinsicht ist Gleichbehandlung gerecht (etwa vor Gericht), in anderen F&#228;llen wird Ungleichbehandlung
als gerecht angesehen (etwa bei Begabtenf&#246;rderung oder bei der unterschiedlichen Besteuerung nach
Einkommen). Betont wird etwa auch, dass gesellschaftliche Strukturen und Institutionen nur gerecht sind, wenn
Menschen an Entscheidungen partizipieren k&#246;nnen und das, was sie betrifft, auch mitgestalten k&#246;nnen (daher gilt die
Demokratie als gerechte politische Form).
F&#252;r den Themenbereich KI bedeutet Gerechtigkeit vor allem, dass KI-Systeme nicht so eingesetzt werden d&#252;rfen,
dass sie unfaire Ergebnisse produzieren und dass relevante Ergebnisse Menschen betreffend nicht ohne deren
Mitwirkung (mindestens bei Entwicklung und Test der Systeme) gef&#228;llt werden d&#252;rfen. Gerechtigkeit spielt
schlie&#223;lich auch eine Rolle im Hinblick auf die Bildung: Menschen k&#246;nnen KI-Technologien nur gut nutzen und
verstehen, wenn sie &#252;ber KI-Technologien genug wissen. Ein gerechter Zugang zu Bildung im Bereich KI und
zu den zugrunde liegenden Technologien, Chancengerechtigkeit in der Nutzung der Technik sowie Teilhabe an
gesellschaftlichen Debatten &#252;ber KI sind ebenfalls auf allgemeiner Ebene ethisch zu ber&#252;cksichtigen.
6.2.8 Diskriminierungsfreiheit (Gleichberechtigung, Fairness)
Diskriminierungsfreiheit ist rechtlich durch Artikel 3 des Grundgesetzes festgelegt. Das Verbot von
Diskriminierung meint eine ungerechtfertigte Benachteiligung oder Bevorzugung und fordert Gleichbehandlung.
Konkretisiert wird dies in Deutschland im Allgemeinen Gleichbehandlungsgesetz. Danach m&#252;ssen auch KI-Systeme 
diskriminierungsfrei sein.262 Dies hei&#223;t, dass Ergebnisse, die ein KI-System berechnet hat, keine Gruppe
bevorteilen oder benachteiligen d&#252;rfen und damit gerecht und fair sein m&#252;ssen. Technisch ist dies herausfordernd, aber
m&#246;glich (siehe auch Kapitel 3 des Mantelberichts [KI und Umgang mit Bias/Diskriminierung]). Aus ethischer
Sicht ist das Diskriminierungsverbot f&#252;r KI-Systeme eine Herausforderung, weil Algorithmen und Daten
typischerweise ein Abbild der (gesellschaftlichen) Realit&#228;t sind, die Stereotype und damit Voreingenommenheit
beinhaltet. Hinzu kommt, dass die normative Vorgabe, was &#8222;unvoreingenommen&#8220; bzw. &#8222;voreingenommen&#8220; im
Einzelfall bedeutet &#8211; und was damit gerecht und fair ist &#8211;, von Menschen au&#223;erhalb des Systems kommen muss.
Unerl&#228;sslich ist deshalb eine interdisziplin&#228;re (gesellschaftliche, politische, technische, anwendungsbezogene)
Betrachtung sowie die Schaffung von Regeln &#8211; selbstverpflichtende und gesetzliche &#8211;, um absichtliche
Diskriminierung beim Einsatz von KI-Systemen zu erkennen und idealerweise im Vorfeld des Einsatzes zu verhindern. 
Auch im Einsatz m&#252;ssen KI-Systeme in dieser Hinsicht laufend gepr&#252;ft werden.
Ethik und KI &#8211; Wirksamkeit von Ethik und Dialog
Die ethische Perspektive m&#246;chte immer eine Hilfe f&#252;r konkrete Fragen der Gestaltung sein. Oft k&#246;nnen auch
allgemeine moralische Begriffe das Handeln anleiten. Die Entwicklung und der Betrieb von KI-Systemen k&#246;nnen
und sollten sich an den hier skizzierten ethischen Begriffen orientieren. Das Problem von Ethikcodizes bleibt
aber oft, ob und wie sich die allgemeinen Prinzipien auch in der konkreten Praxis, etwa in der Informatik oder
im privatwirtschaftlichen oder &#246;ffentlichen Betrieb, umsetzen lassen. Die Frage ist etwa, ob diese Leitlinien zu
Kriterien der Unternehmenssteuerung geworden sind, zum Gegenstand betrieblichen Controllings genutzt oder
in Ausbildungsprozesse integriert werden. Das von der Bundesregierung eingesetzte deutsche &#8222;Observatorium
f&#252;r K&#252;nstliche Intelligenz&#8220; soll dazu beitragen, solche Erkenntnisl&#252;cken zu schlie&#223;en.263 
Hilfreich f&#252;r die Verbreitung von Ethikma&#223;st&#228;ben ist deren dialogische Entwicklung und Integration in
Entscheidungsprozesse. Die Akteursvielfalt in Entscheidungsmechanismen und die Bandbreite der KI-
Einsatzm&#246;glichkeiten bieten zahlreiche Ansatzpunkte, ethische Prinzipien in den soziotechnischen Systemen des Einsatzes zu
verankern. Derartige Prozesse k&#246;nnen unterst&#252;tzt werden durch:
261 Handlungsempfehlungen von Carla Hustedt (Projektleitung &#8222;Ethik der Algorithmen&#8220;, Bertelsmann Stiftung),
Kommissionsdrucksache 19(27)45 vom 6. Mai 2019.
262 Thesenpapier von Prof. Dr. Judith Simon (Universit&#228;t Hamburg), Kommissionsdrucksache 19(27)52 vom 3. Juni 2019.
263 Weitere Informationen dazu unter: https://www.denkfabrik-bmas.de/ (zuletzt abgerufen am 6. August 2020).
&#8226; die Entwicklung und Verbreitung einer Berufsethik von Softwareentwicklerinnen und -entwicklern
&#8226; die Dokumentation von Trainings- und Testprozessen der KI-Systeme und damit auch zumindest implizit 
der Grenzen des jeweiligen Systems
&#8226; die systematische und verbindliche Herstellung von Transparenz in Bezug auf existierende Ethikprinzipien
und insbesondere deren praktische Umsetzung in Prozessen, Methoden und Technologien, etwa mittels des
Observatoriums der Bundesregierung
&#8226; das Aufstellen von Regeln zur Integration von Fragen nach den ethischen Implikationen in
Folgeabsch&#228;tzungen, in die Auditierung und Zertifizierung von KI-Systemen
&#8226; die F&#246;rderung der Entwicklung von Benchmarking-Systemen, etwa zur Selbstregulierung der Wirtschaft
und zur gesellschaftlichen Beurteilung von Institutionen bei der Anwendung von Ethikprinzipien
&#8226; die Implementierung eines Systems ethischer Ma&#223;st&#228;be &#8211; in Anlehnung an den Corporate-Governance-
Kodex f&#252;r gute Unternehmensf&#252;hrung &#8211;, das von den am Wirtschaftsgeschehen beteiligten Stakeholder-
Gruppen entwickelt wird und an dem Wirtschaftsunternehmen und Beh&#246;rden ihr eigenes Handeln messen
k&#246;nnen264
&#8226; die Vermittlung von Ethikanspr&#252;chen in Bildungsma&#223;nahmen zum Ausbau der Urteilsf&#228;higkeit
&#8226; die Entwicklung einer Vorbildfunktion des Staates bei der Verwirklichung ethischer Ma&#223;st&#228;be
&#8226; die F&#246;rderung von Dialogen zur Entwicklung und zum Austausch von Ethikprinzipien
7 KI und Gesellschaft265 
Die rasante Dynamik des digitalen Wandels f&#252;hrt zu tiefgreifenden gesellschaftlichen Ver&#228;nderungen. Dies wird 
durch die Entwicklung und Anwendung von KI-Systemen weiter forciert, da diese Systeme bestimmte Aufgaben
wahrnehmen k&#246;nnen, die vorher nur von Menschen ausgef&#252;hrt werden konnten.266 Die Gestaltung solcher
Systeme ist damit ein wichtiges Feld, in dem die Art und Weise verhandelt wird, wie wir in unserer Gesellschaft
zusammenleben werden.
Gesellschaft ist ein komplexer Begriff und kann sehr unterschiedlich verstanden werden. Gesellschaft in einem
ersten allgemeinen Sinne liegt dort vor, wo mehrere Menschen miteinander handelnd in Wechselwirkung
treten.267 Je nach Perspektive wird im Gesellschaftsbegriff einer der folgenden drei Punkte betont: erstens das
Kollektiv der Menschen und ihre Beziehungen und Verh&#228;ltnisse, zweitens die Funktionen und Leistungen von
sozialen Strukturen sowie drittens die Handlungskoordination von freien Individuen. Wird der Unterschied von
Gesellschaft, Staat und Wirtschaft hervorgehoben, r&#252;cken mit der Zivilgesellschaft die F&#228;higkeit einer Gesellschaft
zur Selbstorganisation und ihre demokratische Verfasstheit in den Blick.
Unter dem Stichwort &#8222;KI und Gesellschaft&#8220; werden drei Fragen untersucht, die das (selbstorganisierte und
demokratische) Zusammenleben der Menschen in Deutschland unter dem Einfluss von KI-Technologie direkt
betreffen. Zun&#228;chst wird der gesellschaftliche Reflexionsbedarf in Bezug auf die Wirkung von KI-Systemen
thematisiert, dann werden die direkten Auswirkungen des Einsatzes von KI-Systemen auf das Zusammenleben und
die Diskurse dar&#252;ber er&#246;rtert und im Anschluss werden die M&#246;glichkeiten einer nachhaltigen und
wohlstandsorientierten politischen Gestaltung der Chancen und Auswirkungen von KI-Systemen beleuchtet.
Gesellschaftlicher Reflexionsbedarf in Bezug auf die Wirkung von KI-Systemen268 
Das Charakteristikum des digitalen Wandels der Gegenwart ist die immer st&#228;rkere Vernetzung und
Durchdringung gesellschaftlicher Handlungsfelder durch Technologie.269 Das Internet dient nicht mehr allein als Medium 
der zwischenmenschlichen Kommunikation und der Informationsbeschaffung, sondern ist Knotenpunkt einer
264 Siehe auch Kapitel 3.3.3 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220; [Angestrebte Wirtschaftsziele: &#8222;KI made in Germany&#8220;
als internationales G&#252;tesiegel].
265 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion der AfD vor [Sondervotum zu Kapitel 7 des Mantelberichts (&#8222;KI und 
Gesellschaft&#8220;) des Abgeordneten Dr. Marc Jongen sowie der Abgeordneten Joana Cotar und Peter Felser].
266 Siehe auch Kapitel 1 des Mantelberichts [Begriffskl&#228;rung K&#252;nstliche Intelligenz]. 
267 Vgl. Simmel (1908): Soziologie: Untersuchungen &#252;ber die Formen der Vergesellschaftung, S. 17.
268 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 7.1 des Mantelberichts
(&#8222;Gesellschaftlicher Reflexionsbedarf in Bezug auf die Wirkung von KI-Systemen &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti
sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo].
269 Vgl. Case (2016): The third wave; Brynjolfsson und McAfee (2016): The second machine age.
umfassenden Vernetzung unserer Umwelt &#8211; inzwischen kommunizieren nicht nur die Menschen miteinander,
sondern &#252;ber den Austausch von Daten auch &#8222;Dinge&#8220; (Internet der Dinge). Digitalisierung ist nicht mehr auf
Ger&#228;te wie PCs und Smartphones beschr&#228;nkt, sondern wird Teil des Zuhauses (Smart Home), der Kraftfahrzeuge
(autonomes Fahren), der Medizin (eHealth und &#8222;Quantified Self&#8220;), der St&#228;dte (Smart Cities), der staatlichen
Verwaltung (eGovernment), der Wirtschaft (Industrie 4.0 / Smart Services) und der Landwirtschaft (Smart
Agriculture) &#8211; die Liste lie&#223;e sich beliebig erweitern. Damit gehen viele neue technische M&#246;glichkeiten f&#252;r unsere
Gesellschaft einher, die zu einer Unterst&#252;tzung der menschlichen F&#228;higkeiten f&#252;hren. Dieser Zuwachs an
M&#246;glichkeiten wirft moralische Fragen auf und zwingt dazu, sich mit Themen, die sich bisher nur bei menschlichem
Handeln stellten, neu auseinanderzusetzen.270 Entscheiderinnen und Entscheider in Politik, Wissenschaft,
Wirtschaft und Zivilgesellschaft stehen vor der Aufgabe, den Einsatz von KI-Systemen und deren &#214;kosystem so zu
gestalten, dass positive Effekte f&#252;r Gesellschaft und Wirtschaft hervorgerufen und negative Begleiterscheinungen
unterbunden werden. Dabei gilt es, Zielkonflikte zu bearbeiten, die auf den Ebenen Werte, Akteure und Zeit
beschrieben werden k&#246;nnen:271 
a) Werte: Werte spiegeln ein gemeinsames Verst&#228;ndnis wider, an dem Politik und Gesellschaft ihr Handeln
(z. B. politische Entscheidungen) ausrichten. So findet sich der Wertekonsens der Bundesrepublik
Deutschland u. a. im Grundrechtekatalog des Grundgesetzes wieder. Im Fall einer Werteabw&#228;gung werden zwei
oder mehrere gegens&#228;tzliche Schutzg&#252;ter gegeneinander abgewogen. Beispiel daf&#252;r ist der immerw&#228;hrende
Konflikt zwischen Freiheit und Sicherheit, beispielsweise beim Einsatz von KI-basierter
Gesichtserkennung, oder auch das Spannungsverh&#228;ltnis zwischen Personalisierung und gemeinsamer &#214;ffentlichkeit, z. B. 
beim Einsatz von Filtermechanismen in sozialen Medien.272 Ziel der Reflexion ist nicht ein Entweder-oder, 
sondern es gilt, beide Schutzg&#252;ter so gut wie m&#246;glich zum Wohle der Gesellschaft zu bedienen.
b) Akteure: Die Interessenabw&#228;gung zeigt die Herausforderung auf, zwischen den Anspr&#252;chen verschiedener
Akteure zu vermitteln und auf eine bestm&#246;gliche Balance hinzuwirken. Ein Beispiel daf&#252;r ist der Konflikt
zwischen der Anwenderfreundlichkeit von Dienstleistungen und der Preisgabe der privaten Daten oder auch
die Frage, wie hoch die Fehlertoleranz KI-basierter Ergebnisse sein darf, wenn sie erhebliche Nachteile f&#252;r
B&#252;rgerinnen und B&#252;rger bedeuten k&#246;nnen.273 F&#252;r diese Art der Zielkonflikte gilt es in einer fairen
Gesellschaft Entscheidungsgrunds&#228;tze zu definieren, die im Kern beiden Zielsetzungen entsprechen.
c) Zeit: Die zeitliche Folgenabw&#228;gung erfordert eine vorausschauende Bewertung m&#246;glicher Auswirkungen:
KI-Technologien k&#246;nnen kurzfristig positiven Einfluss aus&#252;ben, jedoch langfristig negative Folgen f&#252;r ein 
Individuum oder die Gesellschaft haben. KI sollte gem&#228;&#223; den Prinzipien der Technikfolgenabsch&#228;tzung mit
R&#252;cksicht auf solche langfristigen Effekte bewertet und eingesetzt werden. Dabei muss ber&#252;cksichtigt
werden, dass eine solche Folgenabsch&#228;tzung durch die eingangs erw&#228;hnte Dynamik technischer Entwicklung
und die kontinuierliche und nicht immer erlebbare Durchdringung vieler Handlungsfelder mit erheblichen
Schwierigkeiten verbunden ist. Dadurch m&#252;ssen Entwicklungen st&#228;ndig beobachtet und einmal gef&#228;llte
Entscheidungen fortlaufend &#252;berpr&#252;ft werden.
Auswirkungen von KI-Systemen auf die Gesellschaft
Die Auswirkungen des Einsatzes von KI-Systemen in vielen Lebens- und Arbeitsbereichen sind schwer von
anderen Aspekten der Digitalisierung zu trennen, zumal Menschen teilweise nicht mit einzelnen KI-
Technologien direkt interagieren.274 Beispiele sind neben den oben genannten auch Systeme des Alltags wie Smartphones,
Suchmaschinen, Sprachassistenten oder Navigationssysteme. Die Bandbreite an m&#246;glichen
Anwendungsbereichen und Einsatzgebieten f&#252;r KI-Systeme ist umfassend und ihre Gestalt unterscheidet sich mitunter erheblich.
Ihre gesellschaftliche Bewertung erfordert daher stets eine kontextbezogene Sichtweise. Inwieweit Menschen mit
der neuen Technologie Erfahrungen sammeln und ihren Auswirkungen ausgesetzt sind, h&#228;ngt auch damit
zusammen, inwieweit sie an der digitalen Gesellschaft partizipieren.
270 Siehe auch Kapitel 1 des Mantelberichts [Begriffskl&#228;rung K&#252;nstliche Intelligenz]. 
271 In Anlehnung an Buytendijk et al. (2016): Kick-Start the Conversation on Digital Ethics, 2016, adaptiert in M&#252;ller und Andersen
(2017): Denkimpuls Digitale Ethik.
272 Siehe auch Bericht der Projektgruppe &#8222;KI und Medien&#8220; in Kapitel C. VII. [K&#252;nstliche Intelligenz und Medien (Projektgruppe 6)].
273 Vgl. Darstellung des sachverst&#228;ndigen Mitglieds Prof. Dr. Katharina Zweig in der Sitzung der gesamten Enquete-Kommission am
15. Oktober 2020.
274 Siehe auch Kapitel 1 des Mantelberichts [Begriffskl&#228;rung K&#252;nstliche Intelligenz]; vgl. ebenfalls High-Level Expert Group on
Artificial Intelligence (2019): Eine Definition der KI: Wichtigste F&#228;higkeiten und Wissenschaftsgebiete.
Menschen eignen sich Ver&#228;nderungen, die mit dem technologischen Fortschritt einhergehen, sehr unterschiedlich
an. Dies l&#228;sst sich u. a. festmachen an:
&#8226; ihren Zugangsm&#246;glichkeiten zur digitalisierten Welt (beispielsweise zu Ger&#228;ten wie Smartphones,
Sprachassistenten und zur digitalen Infrastruktur)
&#8226; der gesellschaftlichen Position bzw. dem sozialen Umfeld (beispielsweise gr&#246;&#223;eres Nutzungsspektrum bei
Berufst&#228;tigen, Adaption bestimmter Netzwerke wie Instagram und TikTok vor allem durch j&#252;ngere
Altersklassen / Sch&#252;lerinnen und Sch&#252;ler)
&#8226; ihren Kompetenzniveaus (beispielsweise im Hinblick auf das Verst&#228;ndnis von Begriffen wie &#8222;K&#252;nstliche
Intelligenz&#8220;, Anwendungsf&#228;higkeiten sowie kritische Reflexion)
&#8226; ihren Einstellungen zum digitalen Wandel (beispielsweise die Bewertung als Chance oder Belastung)
Es zeigt sich ein heterogenes Bild der digitalen Gesellschaft in Deutschland.
Unterschiedliche Bev&#246;lkerungsgruppen und Nutzertypen sind entsprechend unterschiedlich gut auf die
Umbruchphase durch KI-Technologien vorbereitet. Geht es darum, im KI-Zeitalter Handlungsfreiheit, die
Selbstbestimmung der B&#252;rgerinnen und B&#252;rger und soziale Teilhabe zu f&#246;rdern und es allen Menschen zu erm&#246;glichen,
gleicherma&#223;en von den Chancen der neuen Technologie zu profitieren, bedarf dieses Vorgehen
zielgruppenspezifischer Ma&#223;nahmen, insbesondere um die Funktionsweise und die Auswirkungen von KI unterschiedlichen 
gesellschaftlichen Gruppen n&#228;herzubringen.
Menschen k&#246;nnen als aktiv Nutzende eines KI-Systems oder passiv von der Datenerzeugung/-verarbeitung von
KI-Systemen betroffen sein. Eine aktive Nutzung w&#228;re beispielsweise der Einsatz einer Software f&#252;r die
Routenplanung, die Nutzung KI-basierter Assistenzsysteme in der Arbeitswelt, von Bildbearbeitungsprogrammen oder
auch von Sprachassistenten. Menschen sind jedoch auch ohne ihr aktives Zutun durch die Anwendung von KI
betroffen, wenn beispielsweise ihre Bewegungsdaten aus Mobilger&#228;ten f&#252;r die Routenplanung in der
entsprechenden Software genutzt werden, KI-Systeme breit auf eine gro&#223;e Menschengruppe angewendet werden (z. B. 
bei automatisierten Personenkontrollen mithilfe von Gesichtserkennung275) oder wenn sie von KI-basierten
Entscheidungen betroffen sind (beispielsweise bestimmte automatisierte Empfehlungssysteme in
Bewerbungsprozessen, Diagnosen oder Kreditvergaben). Menschen k&#246;nnen also auch ohne aktive Teilnahme und auch ohne ihr
Wissen vom Einsatz der Systeme positiv wie negativ betroffen sein.
275 Gesichtserkennungen finden in Deutschland bislang nur im Testbetrieb und unter Kenntlichmachung der Ma&#223;nahme im &#246;ffentlichen 
Raum statt, beispielsweise beim Test der biometrischen Gesichtserkennung am Bahnhof Berlin-S&#252;dkreuz 2017/2018 durch das
Bundesministerium des Innern, f&#252;r Bau und Heimat, das Bundespolizeipr&#228;sidium, das Bundeskriminalamt und die Deutsche Bahn AG.
In anderen L&#228;ndern wie China ist Gesichtserkennung im &#246;ffentlichen Raum bereits weit verbreitet.
Regeln f&#252;r den Einsatz von KI m&#252;ssen deswegen mit einem die Diversit&#228;t der Gesellschaft reflektierenden Blick
und ggf. unter Beteiligung der Betroffenen erarbeitet werden. Je nach Kritikalit&#228;t276 m&#252;ssen B&#252;rgerinnen und
B&#252;rger &#252;ber den Einsatz von KI informiert und generell f&#252;r den Umgang mit KI gebildet werden, damit sie
sowohl bei passiver Betroffenheit als auch bei der aktiven Nutzung von KI informierte Entscheidungen treffen
k&#246;nnen.
Beteiligung und Meinungsbildung setzen ein Grundverst&#228;ndnis &#252;ber KI-Systeme voraus. Ein Bild der
gesellschaftlichen Einstellungen und des Kenntnisstands in der Bev&#246;lkerung zum Thema KI zu zeichnen, ist aus
verschiedenen Gr&#252;nden schwierig. Im Jahr 2018 gaben 85 Prozent der B&#252;rgerinnen und B&#252;rger in einer
repr&#228;sentativen Befragung des Bitkom an, sie h&#228;tten bereits vom Begriff &#8222;KI&#8220; geh&#246;rt oder gelesen. Nur 38 Prozent
behaupteten aber von sich, gut erkl&#228;ren zu k&#246;nnen, was der Begriff bedeutet.277 In einer Umfrage der Initiative D21 im 
gleichen Jahr gaben 52 Prozent an, den Begriff &#8222;KI&#8220; erkl&#228;ren zu k&#246;nnen oder ungef&#228;hr zu wissen, was er bedeutet. 
Die Unterschiede in der Bev&#246;lkerung zeigten sich, als man die Zustimmungsraten der am wenigsten
digitalaffinen Gruppe, der digital &#8222;Abseitsstehenden&#8220;, (9 Prozent) mit den &#8222;digitalen Vorreitern&#8220; (zwischen 78 und 84
Prozent) verglich.278 Laut einer Studie des T&#220;V-Verbandes vom Januar 2020 kennen inzwischen 94 Prozent der
Befragten den Begriff &#8222;KI&#8220;, aber nur etwa jede dritte Person (34 Prozent) kann die wichtigsten Eigenschaften
erkl&#228;ren oder die Technologie sogar in all ihren Facetten beschreiben. Fast die H&#228;lfte der Befragten (47 Prozent)
kann dar&#252;ber allenfalls eine grobe Erkl&#228;rung abgeben, wei&#223; aber nichts Genaues. 16 Prozent wissen sehr wenig
oder gar nichts, obwohl viele den Begriff schon einmal geh&#246;rt haben.279 
Menschen haben mittlerweile zwar fast t&#228;glich mit KI zu tun. So finden sich KI-Technologien z. B. in jedem
Smartphone und 79 Prozent der Deutschen nutzten 2019 ein Smartphone.280 Allerdings sind es oft nur einzelne
Prozesse oder Teile, die von KI-Technologien unterst&#252;tzt werden, im Smartphone beispielsweise der
Bildstabilisator der Kamerasoftware oder die Sprachkomponente. Das gesamte System jedoch wird nicht als &#8222;die KI&#8220;
wahrgenommen, obwohl ein Smartphone im Sinne dieses Berichts ein KI-System ist. Vermutlich ist Menschen
daher nicht immer bewusst, wann sie mit KI-Technologien in Ber&#252;hrung kommen. Sie bringen das digitale Ger&#228;t
Smartphone nicht mit KI in Verbindung. Eine von der Gesellschaft f&#252;r Informatik beauftragte Studie des Instituts
f&#252;r Demoskopie Allensbach ergab, dass die Vorstellungen der Menschen, was KI ist und was sie kann, bei vielen 
Menschen vor allem durch Wissen aus Science-Fiction-Filmen gepr&#228;gt ist. Der freundliche Roboter R2-D2 (20 
Prozent) ist die Maschine, die die Vorstellung von KI bei den Menschen am meisten gepr&#228;gt hat. Lieutenant
Commander Data (Star Trek) und der Terminator liegen auf Platz 2 bzw. 3.281 
Das Bild von KI ist in der gesellschaftlichen Wahrnehmung also noch sehr diffus, &#252;ber die gesellschaftlichen 
Gruppen unterschiedlich verteilt und zu einem gro&#223;en Teil durch Science-Fiction-Vorstellungen gepr&#228;gt. &#8222;Die&#8220;
Bev&#246;lkerung daher nach ihren Einstellungen und Bewertungen der KI-Technologie zu befragen und dies
auszuwerten, erweist sich als nicht einfach.282 Daher hat sich die Enquete-Kommission entschieden, die Einstellung 
und Bewertung der interessierten &#214;ffentlichkeit im Rahmen eines Online-Dialogs zu erheben und zu diskutieren.
Die Ergebnisse sind in einem Gutachten aufbereitet. Sie wurden am 26. September 2020 live im
Parlamentsfernsehen und auf www.bundestag.de im vorgestellt.283 Es gilt somit, Menschen &#252;ber Bef&#228;higung, Transparenz,
Teilhabe und Schutz bestm&#246;glich f&#252;r die gesellschaftlichen Umbr&#252;che (positiv wie negativ) infolge des Einsatzes
von KI vorzubereiten. Wie in vielen anderen Gesellschaftsbereichen werden Menschen mit hohem Bildungsgrad 
und einem Grundverst&#228;ndnis f&#252;r Technologie wahrscheinlich eher Chancen nutzen und individuelle Risiken
verringern k&#246;nnen als Menschen, die sich keine klare Vorstellung von KI machen k&#246;nnen. Es ist daher zum einen
wichtig, m&#246;glichst vielen Menschen die M&#246;glichkeit zu geben, sich umfassend &#252;ber KI zu informieren. Es ist
aber auf der anderen Seite auch notwendig, den Einsatz von KI in sensiblen Bereichen transparent zu machen
und Menschen generell durch klare Regeln vor bestimmten Risiken zu sch&#252;tzen, die nicht alle f&#252;r sich selbst
absch&#228;tzen k&#246;nnen. 
276 Siehe auch Kapitel 3 [KI und Umgang mit Bias/Diskriminierung] und Kapitel 4.4 [KI-spezifisches Risikomanagement] des
Mantelberichts.
277 Pr&#228;sentation des sachverst&#228;ndigen Mitglieds Susanne Dehmel, Kommissionsdrucksache 19(27)25 vom 11. Februar 2019, S. 3.
278 Pr&#228;sentation des sachverst&#228;ndigen Mitglieds Lena-Sophie M&#252;ller, Kommissionsdrucksache 19(27)26 vom 11. Februar 2019, S. 3.
279 Vgl. Verband der T&#220;V e. V. (2020): Sicherheit und K&#252;nstliche Intelligenz, S. 10.
280 Vgl. Initiative D21 e. V. (2020): Wie digital ist Deutschland? &#8211; D21 Digital Index 19/20 &#8211; J&#228;hrliches Lagebild zur Digitalen
Gesellschaft, S. 20.
281 Vgl. Gesellschaft f&#252;r Informatik (2019): KI und Popkultur.
282 Vgl. Verband der T&#220;V e. V. (2020): Sicherheit und K&#252;nstliche Intelligenz.
283 Weitere Informationen dazu finden sich im Gutachten zur Online-Beteiligung der Enquete-Kommission in der Anlage des Berichts.
Damit die Menschen einsch&#228;tzen k&#246;nnen, wann sie mit KI-Systemen in Ber&#252;hrung kommen, und die Chance
haben, deren Wirkungsmechanismen zu verstehen, zu hinterfragen und davon zu profitieren, brauchen sie das
notwendige Verst&#228;ndnis (Digitalkompetenzen) und ggf. eine einfache Kennzeichnung im Kontext der
Anwendung (z. B. bei Chatbots). Ein Ansatz daf&#252;r ist ein kostenloser Online-Kurs zu Elementen der KI, den die EU &#8211;
initiiert durch Finnland &#8211; mit dem Ziel zur Verf&#252;gung stellt, vorerst 1 Prozent der europ&#228;ischen Bev&#246;lkerung
&#252;ber diesen Kanal weiterzubilden.284 
Das hei&#223;t jedoch eben nicht, dass die Verantwortung zum reflektierten Umgang mit KI allein auf die Bev&#246;lkerung
&#252;bertragen werden kann. Dort, wo F&#228;higkeiten zum Verst&#228;ndnis von KI nicht ausgepr&#228;gt sind, der
Komplexit&#228;tsgrad das Niveau der Allgemeinbildung &#252;berschreitet oder die Transparenz und Nachvollziehbarkeit von KI-
Systemen nicht gegeben ist, gilt es, Menschen vor negativen Auswirkungen zu bewahren.
Dies kann beispielsweise bereits im Entstehungsprozess von KI-Systemen ber&#252;cksichtigt werden. W&#228;hrend des
gesamten Entstehungs- und Lebenszyklus eines KI-Systems werden Entscheidungen von Menschen getroffen,
die Auswirkungen auf die Wirkungsweise des Systems und letztlich die Nutzenden haben.285 
Menschen, die an der Entscheidung &#252;ber KI-Systeme, deren Entwicklung und &#220;berpr&#252;fung beteiligt sind,
ben&#246;tigen rollenspezifische Spezialkenntnisse in Bezug auf ihre technische Kompetenz, aber auch in Bezug auf die
gesellschaftliche Wirkung verschiedener Gestaltungsoptionen.286 Kritische Felder der KI-Gestaltung betreffen
daher u. a. Fragen der Digitalkompetenz bezogen auf KI-Anwendungen, Fragen der Transparenz und
Nachvollziehbarkeit287, der Fairness und Inklusion288, der Datenqualit&#228;t, der Fehleranf&#228;lligkeit bzw. der Reproduktion von 
Diskriminierung (&#8222;Bias&#8220;) sowie Fragen der Aufsicht und Kontrolle.289 Besonders KI-Systeme, die unmittelbar
oder mittelbar Entscheidungen &#252;ber Menschen pr&#228;gen, m&#252;ssen so ausgestaltet sein, dass sie unseren
Grundrechten in jeder Hinsicht gen&#252;gen und zudem f&#252;r die Nutzerinnen und Nutzer transparent und nachvollziehbar sind.
Dies ist bei selbstlernenden Systemen, deren Entscheidungsalgorithmus durch Anwendung auf Datens&#228;tze
trainiert wird, eine Herausforderung. Hier setzen aktuelle Forschungsprojekte an, die sich mit M&#246;glichkeiten der
Erkl&#228;rbarkeit und Nachvollziehbarkeit von KI-Systemen auseinandersetzen. N&#228;here Ausf&#252;hrungen finden sich
in Kapitel 2 [KI und Daten] und Kapitel 3 [KI und Umgang mit Bias/Diskriminierung] des Mantelberichts.290 
Entwicklung und Einsatz von KI-Systemen im Sinne von Nachhaltigkeit und
Wohlstand
Technisch betrachtet bietet der Einsatz von KI-Technologien nie dagewesene Handlungsoptionen: KI-Systeme
haben in vielf&#228;ltiger Weise das Potenzial, menschliche Handlungen zu unterst&#252;tzen und somit zum
gesellschaftlichen Wohlstand beizutragen. Damit diese Potenziale auch gesellschaftlichen Nutzen entfalten, bedarf es jedoch
einer bewussten Reflexion dar&#252;ber, welche positiven Optionen erschlossen werden sollten und welche
Fehlentwicklungen durch die vertrauensw&#252;rdige291 Ausgestaltung von KI-Systemen vermieden werden sollten.292 
KI-Technologien k&#246;nnen zudem wesentliche Bausteine zur Bew&#228;ltigung gesellschaftlicher Herausforderungen
sein. Ein &#252;bergeordnetes gesellschaftliches Interesse kann hierbei verschieden bewertet werden, so lassen sich
darunter die Bek&#228;mpfung des Klimawandels, Ma&#223;nahmen gegen die Herausforderungen des demografischen
Wandels oder Diskussionen um soziale Gerechtigkeit summieren. KI kann hierbei eine bedeutsame Rolle spielen.
Sie wird z. B. zur Steuerung smarter Energienetze ben&#246;tigt, welche wiederum die Grundlage f&#252;r den
fl&#228;chendeckenden Einsatz Erneuerbarer Energien sind. Sie kann zur intelligenten Verkehrssteuerung genutzt werden und
damit zu lebenswerteren St&#228;dten beitragen. Sie kann zur Herstellung gleichwertiger Lebensbedingungen in Stadt
284 Dieses Ziel, das nur ein Element einer umfassenden Aufkl&#228;rung &#252;ber KI im Rahmen verschiedener Bildungsformate (Schule,
Berufsausbildung, Volkshochschulen, Hochschulen etc.) sein kann, w&#228;re in Deutschland dann erreicht, wenn 830 000 Menschen diesen 
Kurs absolvierten, also etwas mehr als alle Einwohnerinnen und Einwohner von Frankfurt am Main.
285 Vgl. Zweig (2019): Ein Algorithmus hat kein Taktgef&#252;hl.
286 Siehe auch den Bericht der Projektgruppe &#8222;KI und Staat&#8220; in Kapitel C. III. [K&#252;nstliche Intelligenz und Staat (Projektgruppe 2)] und 
den Bericht der Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220; in Kapitel C. IV. [K&#252;nstliche Intelligenz und Arbeit
(Projektgruppe 4)].
287 Vgl. Balkow und Eckardt (2019): Denkimpuls Digitale Ethik.
288 Vgl. Zweig (2019): Ein Algorithmus hat kein Taktgef&#252;hl; Burchardt und Uszkoreit (2018): IT f&#252;r soziale Inklusion.
289 Handlungsempfehlungen von Prof. Dr. Norbert Pohlmann (Westf&#228;lische Hochschule Gelsenkirchen), Projektgruppendrucksache
19(27)54 vom 3. Juni 2019; Handlungsempfehlungen von Prof. Dr. Judith Simon (Universit&#228;t Hamburg), Projektgruppendrucksache
19(27)52 vom 3. Juni 2019.
290 Vgl. Bekanntmachung der Richtlinie zur F&#246;rderung von Projekten zum Thema &#8222;Erkl&#228;rbarkeit und Transparenz des Maschinellen 
Lernens und der K&#252;nstlichen Intelligenz&#8220; vom 14. M&#228;rz 2019, Bundesanzeiger vom 4. April 2019.
291 Die High-Level Expert Group on Artificial Intelligence der Europ&#228;ischen Kommission spricht von &#8222;trustworthy&#8220;.
292 Vgl. High-Level Expert Group on Artificial Intelligence (2019): Ethik-Leitlinien f&#252;r eine vertrauensw&#252;rdige KI.
und Land eingesetzt werden. Ebenso sind die Erforschung von Krankheiten und die Entwicklung von Therapien
wichtige Einsatzgebiete f&#252;r KI-Technologien. Etwa konnten im Rahmen der Corona-Pandemie mithilfe von KI
gro&#223;e Datenmengen z&#252;gig ausgewertet und Erkenntnisse von Expertinnen und Experten aus Medizin und
Gesundheitswesen weltweit zusammengef&#252;hrt werden.  
Der Wissenschaftliche Beirat der Bundesregierung Globale Umweltver&#228;nderungen (WBGU) stellt einen
Zusammenhang zwischen gesellschaftlicher Transformation und der Technologieanwendung her, wenn er argumentiert, 
dass Digitalisierung ausdr&#252;cklich in den Dienst einer Transformation zur Nachhaltigkeit gestellt werden sollte.293 
Inwiefern KI-Systeme zur L&#246;sung dieser globalen Herausforderungen und zur L&#246;sung wesentlicher
Zukunftsfragen der Gesellschaft beitragen k&#246;nnen, h&#228;ngt also wesentlich von ihrer Gestaltung und ihren konkreten
Einsatzszenarien ab. Der Rahmen daf&#252;r kann und muss politisch gesetzt werden. 
Dort, wo KI-Anwendungen sich nur schwer am Markt etablieren lassen, aber der Gesellschaft potenziell nutzen
k&#246;nnten, ist eine gezielte &#246;ffentliche F&#246;rderung notwendig. &#214;konomische Anreize f&#252;r die Entwicklung eines
spezifischen KI-Systems k&#246;nnen etwa fehlen, weil die angewandten Technologien noch nicht ausgereift sind 
oder weil ein &#252;bergeordnetes gesellschaftliches Interesse gegeben ist, das durch die Kr&#228;fte des freien Marktes
bislang nicht bedient wird. Die zweckgebundene &#246;ffentliche F&#246;rderung von Zukunftstechnologien kann eine
entscheidende Rolle dabei spielen, diesen &#252;berhaupt &#252;ber die Schwelle zu verhelfen, ab der sie sich &#246;konomisch
rentieren. Sie war daher historisch gesehen oftmals von wichtiger Bedeutung f&#252;r die Durchsetzung
bahnbrechender Innovationen.294 
Ein &#252;bergeordnetes gesellschaftliches Interesse besteht gegenw&#228;rtig vor allem in Bezug auf die Bek&#228;mpfung des
Klimawandels, Fragen der sozialen Gerechtigkeit oder die Sicherung von Fachkr&#228;ften, um auch in der digitalen 
Welt Wertsch&#246;pfung in Deutschland zu erm&#246;glichen und den Wohlstand der Gesellschaft mindestens zu
erhalten.295 
Handlungsempfehlungen296 
Die Enquete-Kommission empfiehlt mit Blick auf KI und Gesellschaft daher Folgendes:
1. KI sollte reflektiert und wertekonform eingesetzt werden. Die Notwendigkeit, KI-Systeme ethisch und
vertrauensw&#252;rdig zu gestalten, zog sich wie ein roter Faden durch die Diskussionen in der Enquete-
Kommission. Es ist daher unerl&#228;sslich, den Einsatz von KI in Bezug auf die gesellschaftlichen Folgewirkungen zu
reflektieren und kontinuierlich zu beobachten, was beispielsweise durch das KI-Observatorium des BMAS
erfolgt. In Bezug auf die Gestaltung von KI-Systemen sollte sich der europ&#228;ische Ansatz besonders durch
Transparenz, Nachvollziehbarkeit, Nicht-Diskriminierung und Rechenschaftspflicht auszeichnen &#8211;
Aspekte, die jeweils ausf&#252;hrlich in Kapitel 3 [KI und Umgang mit Bias/Diskriminierung], in Kapitel 5 [KI und 
Recht] und in Kapitel 6 [Ethische Perspektiven auf KI] des Mantelberichts diskutiert werden.
2. Die Menschen m&#252;ssen bef&#228;higt werden, mit den gesellschaftlichen Umbr&#252;chen (positiv wie negativ) infolge
des Einsatzes von KI-Systemen umzugehen. Ein wichtiges Handlungsfeld ist die F&#246;rderung des
Verst&#228;ndnisses und des Bewusstseins f&#252;r KI-Systeme im Alltag sowie bez&#252;glich der eigenen Kompetenz und des
Wissens &#252;ber deren Wirkungsmechanismen. So ist es beispielsweise n&#246;tig, angesichts KI-basierter
Informations- und Medienr&#228;ume die digitale Nachrichtenkompetenz der B&#252;rgerinnen und B&#252;rger zu st&#228;rken.
Hierbei kann eine positive Aufkl&#228;rungskampagne zu den Einsatzfeldern von KI-Technologien im Leben der
Menschen ein Anreiz sein, sich aktiv mit dem Thema zu besch&#228;ftigen. Sie sollte verbunden sein mit dem
Angebot eines Selbsteinsch&#228;tzungstests sowie M&#246;glichkeiten, die eigenen Kompetenzen auszubauen.
293 Vgl. Wissenschaftlicher Beirat der Bundesregierung Globale Umweltver&#228;nderungen (WBGU) (2019): Unsere gemeinsame digitale
Zukunft &#8211; Zusammenfassung.; Lange und Santarius (2018): Smarte gr&#252;ne Welt?
294 Das bedeutsamste Beispiel f&#252;r diesen Zusammenhang ist der Entwicklungsschub, den die umfangreiche staatliche
Forschungsf&#246;rderung zu milit&#228;rischen Zwecken im Kalten Krieg ausl&#246;ste. Sowohl das Internet als auch die Halbleiterindustrie insgesamt erlebten in 
dieser Phase Innovationssch&#252;be, die in vielf&#228;ltiger Weise die Grundlage f&#252;r die heutige Digitalwirtschaft darstellen. Mariana
Mazzucato legt in ihrer Abhandlung zum Thema dar, dass die wesentlichen Basistechnologien des iPhones aus staatlichen, langfristigen
Innovationsprogrammen hervorgegangen sind, die finanzielle Anreize boten, bevor die Anwendungen gewinnbringend verwertet
werden konnten, vgl. Mazzucato (2014): Das Kapital des Staates.
295 Siehe dazu auch den Bericht der Projektgruppe &#8222;KI und Wirtschaft&#8220; in Kapitel C. II [K&#252;nstliche Intelligenz und Wirtschaft
(Projektgruppe 1)] und Kapitel 8 des Mantelberichts [KI und &#246;kologische Nachhaltigkeit].
296 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 7.4 des Mantelberichts
(&#8222;Handlungsempfehlungen &#8220; zu &#8222;KI und Gesellschaft &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen
Mitglieds Dr. Florian Butollo].
3. Zur Entwicklung einer sinnvollen Selbsteinsch&#228;tzung sollte &#252;ber eine KI-spezifische Version des European
Digital Competency Framework297 nachgedacht werden. Dieses erm&#246;glicht der Zielgruppe B&#252;rgerinnen und 
B&#252;rger bereits heute, ihre Digitalkompetenzen in f&#252;nf Kompetenzfeldern einzusch&#228;tzen. Es wird
beispielsweise im europ&#228;ischen Europass-Lebenslauf angewendet.298 
4. Um den Einsatz von KI-Systemen zu hinterfragen und davon zu profitieren, braucht es dar&#252;ber hinaus
entsprechendes Wissen und Kompetenzen. Hierf&#252;r sind Angebote notwendig wie der in Finnland entwickelte
kostenlose Online-KI-Kurs Elements of AI299, der theoretische Wissensvermittlung mit praktischen
&#220;bungen verbindet und so Grundlagen-Kompetenzen zu KI vermittelt. Ziel sollte es sein, 1 Prozent der
deutschsprachigen Bev&#246;lkerung zu schulen. Das Wissen in der Bev&#246;lkerung sollte inklusiv erweitert werden, das
hei&#223;t, die Heterogenit&#228;t der Gesellschaft sollte ebenso wie die verschiedenen Einsatzfelder ber&#252;cksichtigt
werden. Es wird die Entwicklung zielgruppenspezifischer Einstiegskurse als Erg&#228;nzung vorgeschlagen, die
st&#228;rker auf die Anwendungsfelder und gesellschaftlichen Wirkweisen abzielen. Denkbar sind diese z. B. f&#252;r 
die Einsatzfelder KI und soziale Medien, die ggf. einen guten Einstieg und Anreiz f&#252;r j&#252;ngere Generationen
bieten. Ebenso denkbar sind Einstiegskurse zu Mobilit&#228;t, Arbeit oder Gesundheit.300 
5. Die Bef&#228;higung &#252;ber die entsprechenden Kompetenzen ist eine Seite der M&#252;ndigkeit. Die andere bildet die
interessenad&#228;quate Transparenz. Dort, wo Menschen von den Folgen einer Entscheidung auf Basis eines
KI-Systems betroffen sind, m&#252;ssen sie gen&#252;gend Informationen erhalten, um ihre Rechte angemessen
wahrnehmen und die Entscheidung ggf. infrage stellen zu k&#246;nnen. Es wird empfohlen, eine einfache
Kennzeichnung im Kontext der Anwendung (z. B. bei Chatbots) und die Verwendung von einfacher Sprache bei
entsprechenden Hinweisen und Erl&#228;uterungen. Anbieter von KI-Systemen sollten eine interessenad&#228;quate
Transparenz &#252;ber die Entscheidungsfindung erm&#246;glichen.301 Zudem wird empfohlen, Beteiligungs- und
Meinungsbildungsprozesse zu initiieren. Beispiele finden sich zur betrieblichen Mitbestimmung im Bericht 
der Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220; in Kapitel C. V. [K&#252;nstliche Intelligenz und Arbeit
(Projektgruppe 4)] oder beim Einsatz von KI durch den Staat im Bericht der Projektgruppe &#8222;KI und Staat&#8220;
in Kapitel C. III. [K&#252;nstliche Intelligenz und Staat (Projektgruppe 2)].
6. Nachhaltiger und wohlstandsorientierter Einsatz von KI: KI bietet vielf&#228;ltige Potenziale zur L&#246;sung
dr&#228;ngender Zukunftsprobleme. Ob sich solche Potenziale realisieren, h&#228;ngt aber wesentlich davon ab, ob es eine
gezielte F&#246;rderung solcher Ans&#228;tze auf der Ebene der Forschung und der Wirtschaftsf&#246;rderung gibt,
insbesondere in Feldern, die noch nicht marktreif sind oder deren Anwendung bislang nicht durch
wettbewerbliche Anreize belohnt wird. Dies ist insbesondere hinsichtlich der zivilisatorischen Herausforderung des
Klimawandels oder des demografischen Wandels der Fall. Hier kann KI einen wesentlichen Beitrag zum Erfolg 
missionsorientierter Innovationsprojekte leisten. Im Bericht der Projektgruppe &#8222;KI und Wirtschaft&#8220; im
Kapitel C. II. [K&#252;nstliche Intelligenz und Wirtschaft (Projektgruppe 1)] und in den Kapiteln 8 [KI und
&#246;kologische Nachhaltigkeit] und 9 [KI und Forschung] des Mantelberichts werden diese M&#246;glichkeiten detailliert 
diskutiert und mit spezifischen Handlungsempfehlungen untermauert. 
8 KI und &#246;kologische Nachhaltigkeit302 
&#8222;KI ist alles andere als gr&#252;n&#8220;. Mit dieser zugespitzten &#220;berschrift titelte im Sommer 2019 ein
Technologiemagazin &#8211; und f&#252;hrte weiter aus, dass das einmalige Training eines sehr gro&#223;en neuronalen Netzwerks &#252;ber 300
Tonnen CO2303 verursachen k&#246;nne, wenn man den typischen Strommix von Amazon Web Services oder Microsoft
297 Vgl. Europ&#228;ische Kommission (2019): The Digital Competence Framework 2.0.
298 Weitere Informationen dazu unter: https://europass.cedefop.europa.eu/resources/digital-competences (zuletzt abgerufen am 7.
August 2020).
299 Weitere Informationen dazu unter: https://www.elementsofai.de/ (zuletzt abgerufen am 7. August 2020).
300 Siehe auch den Bericht der Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220; in Kapitel C. V. [K&#252;nstliche Intelligenz und Arbeit
(Projektgruppe 4)].
301 Zu Kennzeichnungsregelungen u. a. siehe auch den Bericht der Projektgruppe &#8222;KI und Staat&#8220; in Kapitel C. III. [K&#252;nstliche Intelligenz 
und Staat (Projektgruppe 2)], den Bericht der Projektgruppe &#8222;KI und Medien&#8220; in Kapitel C. VI. [K&#252;nstliche Intelligenz und Medien 
(Projektgruppe 6)] sowie das Kapitel 6 des Mantelberichts [Ethische Perspektiven auf KI].
302 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion der AfD vor [Sondervotum zu Kapitel 8 des Mantelberichts (&#8222;KI und 
&#246;kologische Nachhaltigkeit&#8220;) des Abgeordneten Dr. Marc Jongen sowie der Abgeordneten Joana Cotar und Peter Felser].
303 Nimmt man die Aussagen des Chip-Herstellers NVIDEA als Basis, betr&#228;gt die Stromaufnahme eines f&#252;r das Training gr&#246;&#223;ter
neuronaler Netze geeigneten Servers 10 MW (vgl. Nvidia (2018): Nvidia Tesla). Legt man dazu die CO2-Intensitit&#228;t des deutschen
Strommixes von 523 g CO2/KWh zugrunde, entstehen CO2-Emissionen in H&#246;he von 300 Tonnen bei einem Stromverbrauch von etwa 
573,6 MWh. Damit l&#228;sst sich 57 h 22 min auf dem Server rechnen. Kleine Netze lassen sich heute auf kleineren GPU-Servern in 
wenigen Minuten trainieren, w&#228;hrend bei extrem gro&#223;en neuronalen Netzen die Zahl von knapp 60 Serverstunden deutlich zu niedrig
zugrunde legt. Die verursachte Menge CO2 entspr&#228;che demnach in etwa der f&#252;nffachen Menge der Emissionen 
eines PKW im kompletten Lebenszyklus &#8211; oder mehr als der 30-fachen Menge dessen, was ein Mensch in
Deutschland j&#228;hrlich verursacht.304 Zu ber&#252;cksichtigen ist dabei auch das derzeitig sehr starke Wachstum des
Rechenbedarfs f&#252;r das Training sehr gro&#223;er neuronaler Netzwerke.305 
Keineswegs jede KI-Anwendung ben&#246;tigt &#228;hnlich viel Energie beim Training, und viele Anwendungen sind
bereits in wenigen Minuten mit einem relativ kleinen Speicher trainiert. Dennoch zeigt dieses Beispiel die Relevanz
von Fragen der Energieeffizienz und damit der &#246;kologischen Nachhaltigkeit von KI auf. Aus diesem Grund nahm
der Energieaspekt von KI auch in der 2018 vorgelegten franz&#246;sischen KI-Strategie &#8222;AI for humanity&#8220; einen 
gro&#223;en Raum ein.306 
Gleichzeitig sind die Erwartungen hinsichtlich der &#246;kologischen Chancen, die sich durch KI ergeben, gro&#223;,
beispielsweise bei der effizienteren (und damit auch klimafreundlicheren) Verkehrssteuerung (siehe auch Kapitel
4.1.1 des Berichts der Projektgruppe &#8222;KI und Mobilit&#228;t&#8220; [Vision KI und Mobilit&#228;t &#8211; Status quo]), im Bereich
bessere Netzintegration von Erneuerbaren Energien (siehe unten) oder auch in der Abfallwirtschaft, wo sich in
Pilotprojekten bereits der Anteil von Rezyklaten durch KI-Einsatz deutlich steigern l&#228;sst.307 
Auch im Bereich Landwirtschaft werden durch KI-Einsatz gro&#223;e Potenziale gesehen, beispielsweise bei der
besseren Prognose von Erntequalit&#228;t und -Mengen308 oder bei der Reduktion von chemischen Pflanzenschutzmitteln
durch den Einsatz KI-gesteuerter mechanischer oder elektrischer Unkrautvernichtung durch Roboter309 (siehe
den Bericht der Projektgruppe &#8222;KI und Wirtschaft&#8220; in Kapitel C. II. [K&#252;nstliche Intelligenz und Wirtschaft
(Projektgruppe 1)]).
Sowohl vorhandene Risiken als auch Chancen bed&#252;rfen einer umfassenden Analyse.
Definition, Abgrenzung, Forschungsstand
F&#252;r eine umfassende und gr&#252;ndliche Bearbeitung des Themas Nachhaltigkeit und KI w&#228;re eine Er&#246;rterung der
Chancen und Herausforderungen durch KI mit Blick auf die Erreichung der 17 Ziele f&#252;r eine nachhaltige
Entwicklung der Vereinten Nationen310 notwendig. Dies konnte die Enquete-Kommission in der K&#252;rze der Zeit
jedoch nicht leisten. Daher wird an dieser Stelle der Fokus auf wesentliche Aspekte der &#246;kologischen Dimension
der Nachhaltigkeit gelegt.311 Es sei jedoch darauf verwiesen, dass ausgew&#228;hlte soziale und &#246;konomische Aspekte 
der Nachhaltigkeit in den Projektgruppenberichten zu &#8222;KI und Arbeit&#8220; (siehe Kapitel 5.1.1 des Berichts der
Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220; [Entwicklung des Arbeitsmarktes (Prognosen,
Arbeitsmarktforschung)]) sowie &#8222;KI und Wirtschaft&#8220; (siehe Kapitel 5.1.4 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220;, 
[Nachhaltigkeit]) mit diskutiert wurden. Auch einzelne Aspekte der &#246;kologischen Dimension von Nachhaltigkeit
sind in den Projektgruppenberichten &#8222;KI und Wirtschaft&#8220; (siehe Kapitel 5.1.4 des Berichts der Projektgruppe &#8222;KI 
und Wirtschaft&#8220;, [Nachhaltigkeit]) sowie &#8222;KI und Mobilit&#228;t&#8220; (siehe Kapitel 4.1.1 des Berichts der Projektgruppe
&#8222;KI und Mobilit&#228;t&#8220; [Vision KI und Mobilit&#228;t &#8211; Status quo]) enthalten. 
angesetzt ist, da f&#252;r die Optimierung der Netze (sogenanntes Hyper-Parameter-Search) viele Trainingsl&#228;ufe notwendig sind. So
wurden 2016 f&#252;r das Training von AlphaGo mehrere Monate ben&#246;tigt und dabei mehr als 30 Millionen Partien Go gespielt, vgl.
Volkswagen AG (2019): Digitale Neuronen &#8222;fahren&#8220; autonom. Der Stromverbrauch des Trainings eines neuronalen Netzes kann sehr
variieren.
304 Vgl. Lobe (2019): KI ist alles andere als gr&#252;n, basierend auf Strubell et al. (2019): Energy and Policy Considerations for Deep 
Learning in NLP.
305 So hat sich im Zeitraum 2012 bis 2018 die f&#252;r das Training sehr gro&#223;er neuronaler Netze ben&#246;tigte Rechenleistung durchschnittlich 
alle 3 bzw. 4 Monate verdoppelt, w&#228;hrend sich f&#252;r den Zeitraum 1959 bis 2012 die durchschnittlich eingesetzte Rechenleistung nur
alle zwei Jahre verdoppelt hatte. Damit w&#228;chst der Bedarf an Rechenleistung durch gro&#223;e neuronale Netzwerke derzeit siebenmal
schneller als im Vergleichszeitraum. Vgl. Hao (2019): The computing power needed to train AI is now rising seven times faster than
ever before.
306 Weitere Informationen dazu unter: https://www.aiforhumanity.fr/en/ (zuletzt abgerufen am 19. August 2020) sowie Villani (2018):
For a Meaningful Artificial Intelligence &#8211; Towards a French and European Strategy.
307 Z. B. das Modellprojekt Kunststoffrecycling: Kammerer et al. (2020): Umweltpolitische Digitalagenda, S. 16 ff.
308 Vgl. Perry (2020): John Deere's quest to solve agricultures deep-learning problems &#8211; [Spectral Lines].
309 Vgl. Rayner (2018): Dieser Roboter braucht im Kampf gegen Unkraut 20-mal weniger Herbizide.
310 Weitere Informationen zu den 17 Nachhaltigkeitszielen unter: https://sustainabledevelopment.un.org/?menu=1300 (zuletzt abgerufen
am 7. August 2020).
311 Da zwischen der sozialen, der &#246;konomischen und der &#246;kologischen S&#228;ule von Nachhaltigkeit enge Wechselwirkungen bestehen,
bedingt ein derartiges Vorgehen das Risiko einer unvollst&#228;ndigen Bewertung, scheint aber mit Blick auf den vorgesehenen
Seitenumfang und im Sinne der Komplexit&#228;tsreduktion geboten.
Insbesondere konzentriert sich dieser Textabschnitt auf zentrale und &#252;bergreifende Fragen des Energie- und
Ressourcenverbrauchs, des Energiesystems sowie der Effizienzpotenziale und betrachtet dar&#252;ber hinaus die
Potenziale von KI-Anwendungen in ausgew&#228;hlten Bereichen wie der Klimawissenschaft sowie im Umwelt- und
Naturschutz.312 
Die wissenschaftliche Forschung zur Frage, welchen Einfluss KI &#8211; sowie auch Digitalisierung insgesamt &#8211; auf
die &#246;kologische Nachhaltigkeit hat, steht noch am Anfang. Dies ist wenig &#252;berraschend, da die Auswirkungen
der Digitalisierung auf die &#246;kologische Dimension der Nachhaltigkeit erst seit k&#252;rzerer Zeit breitere
wissenschaftliche Aufmerksamkeit genie&#223;t313 und zunehmend in den Fokus der &#246;ffentlichen Diskussion r&#252;ckt.314
Insbesondere zu KI-spezifischen Fragestellungen besteht noch grundlegender Forschungsbedarf, den die
Bundesregierung und relevante Forschungseinrichtungen zeitnah mit entsprechenden weiterf&#252;hrenden Studien und
Gutachten schlie&#223;en m&#252;ssen.
Energie- und Ressourcenverbrauch
Der hohe Stromverbrauch von KI-Prozessoren ist technologieinh&#228;rent, auch wenn es aktuelle Ans&#228;tze gibt, den
Stromverbrauch zu senken.315 Die Berechnung von gro&#223;en neuronalen Netzen ben&#246;tigt gro&#223;e Rechenkapazit&#228;ten.
So ben&#246;tigt nach derzeitigem Stand der Technik ein autonom fahrendes Auto rund 2 500 Watt f&#252;r die
Rechenleistung &#8211; und damit rund zehn bis 20 Prozent des Fahrbetriebs. Bei einem einzigen KI-gesteuerten
Haushaltsroboter ist von einer n&#246;tigen Rechenleistung auszugehen, die 100- bis 1 000-mal gr&#246;&#223;er ist als der Rechenbedarf
f&#252;r den Go-Champion316. Der durch den Rechenbedarf induzierte Energieaufwand wird so zum Problem. Nach
heutigem Wissensstand kann dabei eine energieeffiziente KI nur dann realisiert werden, wenn Algorithmen, 
Hardware-Architektur und Schaltungstechnik gemeinsam betrachtet und optimiert werden. Bei Hardware-
Komponenten ist dabei der gesamte Lebenszyklus &#8211; von der Produktion &#252;ber den Betrieb bis zur Entsorgung &#8211; zu
ber&#252;cksichtigen. Hier besteht noch erheblicher Forschungs- und Entwicklungsbedarf (siehe Kapitel 4.1.5 des
Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220; [&#214;kologie]). Aus Nachhaltigkeitssicht gilt es dabei auch, das
Suffizienzprinzip zu ber&#252;cksichtigen, konkret die Frage, welcher Technologieeinsatz f&#252;r die Bearbeitung welches
Problems aus Sicht der Nachhaltigkeit sinnvoll ist und welcher nicht. 
Wie bei jeder anderen digitalen Technologie ist Hardware die Basis von KI. Und f&#252;r jede IT-Hardware ist der
Einsatz verschiedener, teils knapper und wertvoller Ressourcen notwendig, teils auch von Ressourcen, deren
Beschaffung entlang der Wertsch&#246;pfungskette mit gro&#223;en Herausforderungen hinsichtlich &#246;kologischer und
sozialer Standards verbunden sein kann.317 Die Herausforderungen hinsichtlich der Einhaltung &#246;kologischer und
sozialer Standards in der Rohstoffbeschaffung sind dabei nicht KI-spezifisch, die Zunahme von KI-
Anwendungen erh&#246;ht aber prinzipiell den Bedarf an entsprechender IT-Hardware und hat somit auch einen Nachfrageeffekt.
Ein L&#246;sungsansatz ist die Verl&#228;ngerung der Lebenszyklen der Ger&#228;te sowie eine zirkul&#228;re, m&#246;glichst
r&#252;ckstandsfreie Wertsch&#246;pfungskette. 
Nach derzeitigem Stand der Marktentwicklung ist davon auszugehen, dass der Anteil von KI-Hardware von
derzeit 5 Prozent des gesamten Halbleitermarktes bis 2025 auf 15 Prozent anwachsen k&#246;nnte. Diese Zahlen machen
deutlich, dass KI-Hardware zwar nicht den Haupttreiber f&#252;r die Nachfrage nach Rohstoffen darstellt, die f&#252;r die
312 Die Potenziale f&#252;r KI in der Landwirtschaft wurden schon im Bericht der Projektgruppe &#8222;KI und Wirtschaft&#8220; (siehe Kapitel 4.1.3.2.4 
des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220; [Themenfeld Agrar&#246;konomie und Landwirtschaft]) diskutiert. Bei gezieltem
Einsatz der KI ergibt sich hier die Chance eines &#246;konomischen und eines &#246;kologischen Nutzens.
313 Vgl. Wissenschaftlicher Beirat der Bundesregierung Globale Umweltver&#228;nderungen (WBGU) (2019): Unsere gemeinsame digitale
Zukunft - Hauptgutachten.
314 Vgl. Wissenschaftlicher Beirat der Bundesregierung Globale Umweltver&#228;nderungen (WBGU) (2019): Unsere gemeinsame digitale
Zukunft - Zusammenfassung. Auf Seite 4 wird festgestellt, dass Digitalisierungsprozesse &#8222;heute eher als Brandbeschleuniger
bestehender nicht nachhaltiger Trends, also der &#220;bernutzung nat&#252;rlicher Ressourcen und wachsender sozialer Ungleichheit in vielen
L&#228;ndern&#8220; wirkten. Die Bundesumweltministerin sprach davon, dass die Digitalisierung zum Brandbeschleuniger f&#252;r den Klimawandel
werden k&#246;nne, vgl. zdf.de (2020): Klimawandel: Energieschleuder Digitalisierung. Der Deutsche Bundestag befasste sich in seiner
147. Sitzung am 14. Februar 2020 mit der &#246;kologischen Gestaltung der Digitalisierung und diskutierte dazu Antr&#228;ge mehrerer
Fraktionen, vgl. Plenarprotokoll 19/147, 18404A-18417D.
315 Z. B. Moore (2020): Huge chip smashes deep learning's speed barrier, S. 24&#8211;27. (Energy Reduction of 5x compared to todays&#8217; AI
Compute Clusters) oder das Programm &#8222;Future Information Technology&#8221; im Forschungszentrum J&#252;lich, vgl. Helmholtz: Das
Programm &#8222;Future Information Technology (FIT) &#8211; Fundamentals, Novel Concepts, and Energy Efficiency&#8220;.
316 Mit dem Erfolg von AlphaGo im Brettspiel Go im Jahr 2017 r&#252;ckte der technische Fortschritt bei KI in den Blick der breiteren
&#214;ffentlichkeit, vgl. B&#246;hm (2017): Aus dem Go-Olymp direkt in den Ruhestand.
317 Z. B. Debatte &#252;ber Konfliktmineralienverordnung, weitere Informationen dazu unter: https://www.bmwi.de/Redaktion/DE/Arti-
kel/Industrie/durchfuehrungsgesetz-europaeischen-konfliktminerale-verordnung-und-aenderung-bundesberggesetzes.html (zuletzt
abgerufen am 29. August 2020).
Hardware-Produktion notwendig sind, dass aber zuk&#252;nftig mit einem signifikanten Marktanteil bei insgesamt
steigender Halbleiter-Nachfrage zu rechnen ist (siehe Kapitel 4.1.5 des Berichts der Projektgruppe &#8222;KI und
Wirtschaft&#8220; [&#214;kologie]).
Potenziale von KI f&#252;r das Vorantreiben der Energiewende
Die gro&#223;en (gesellschaftlichen) Fragen der Energiewende kann KI nicht beantworten. Technologien wie KI
&#8211; oder auch Blockchain &#8211; k&#246;nnen aber dabei helfen, die Energiewende zu beschleunigen und innovativer zu 
machen, wenn dabei gleichzeitig m&#246;gliche negative Auswirkungen und Rebound-Effekte im Blick behalten
werden.318 F&#252;r die notwendige Reduktion von CO2-Emissionen muss die Nutzung von klimafreundlichen,
Erneuerbaren Energien vorangetrieben werden. Hierzu bedarf es passender Rahmenbedingungen. Technologien und
Regulierung m&#252;ssen ineinandergreifen, um der mit einem starken Ausbau Erneuerbarer Energien verbundenen
Dezentralit&#228;t und Volatilit&#228;t der Energieeinspeisung Rechnung zu tragen. KI kann, wie im Folgenden dargestellt
werden soll, einen wichtigen Beitrag dazu leisten, ein solch dezentrales und flexibles Energiesystem zu
organisieren. Hierf&#252;r sind zun&#228;chst eine erfolgreiche Digitalisierung des Energiesektors und der Zugang zu relevanten
Daten &#8211; wie Netzzustandsdaten, Liegenschaftskatasterdaten etc. sowie Verbrauchs- und Erzeugungsdaten &#8211;
notwendig. In den folgenden Bereichen kann KI eine klimafreundliche Energiepolitik bef&#246;rdern.
8.3.1 KI kann die Akzeptanz der Energiewende in der Bev&#246;lkerung st&#228;rken
Partizipation und Mitbestimmung sind wichtige Faktoren f&#252;r die Akzeptanz der Energiewende. Seit der
Einf&#252;hrung des Erneuerbare-Energien-Gesetzes im Jahr 2000 k&#246;nnen private Haushalte zwar Strom aus eigenen
Anlagen ins Netz einspeisen, aber nicht aktiv am Energiehandelssystem teilhaben, weil daf&#252;r viel Fachwissen
notwendig ist und Markteintrittsbarrieren (wie Mindesthandelsmengen) zu hoch sind. Au&#223;erdem wollen die meisten
B&#252;rgerinnen und B&#252;rger nicht selbst mit Energie handeln. Dezentrale, KI-gest&#252;tzte Agenten (z. B. als
Zusatzservice einer Smart-Meter-Infrastruktur) k&#246;nnten diese komplexen Handelsprozesse auf unterschiedlichen
Energiem&#228;rkten (wie Flexibilit&#228;ts-, Blindleistungs- oder Leistungsm&#228;rkten) zuk&#252;nftig im Auftrag ihrer Besitzerinnen und
Besitzer &#252;bernehmen. 
Insbesondere im Smart-Home-Bereich wurden in den letzten Jahren gro&#223;e Fortschritte erzielt. So gibt es etwa
zahlreiche nutzerfreundliche Messger&#228;te, die mithilfe von KI z. B. defekte oder ineffiziente Haushaltsger&#228;te
identifizieren k&#246;nnen und mehr Transparenz &#252;ber den eigenen Energieverbrauch schaffen. F&#252;r noch weiterreichende
KI-basierte Gesch&#228;ftsmodelle, die auch einen systemischen Nutzen bieten, muss ein einfacherer und
unb&#252;rokratischer Marktzugang f&#252;r kleine Akteure (Prosumer) gepr&#252;ft und eine dezentrale Entscheidungsfindung
erm&#246;glicht werden.319 Ein hohes Datenschutzniveau ist bei der Umsetzung durchgehend sicherzustellen. Auch muss der
Preis f&#252;r die intelligente Infrastruktur noch fallen, damit Endverbraucherinnen und -verbraucher im Ergebnis
einen Vorteil haben.320 
8.3.2 KI kann helfen, Erneuerbare Energien besser in das Energiesystem zu integrieren
Die Standortverf&#252;gbarkeit f&#252;r Windr&#228;der und Solaranlagen wird zunehmend zum Flaschenhals f&#252;r die
Energiewende. Viele standortspezifische Faktoren beeinflussen den Erfolg solcher Projekte &#8211; wie etwa
Windgeschwindigkeiten, die Stimmung der Bev&#246;lkerung vor Ort oder der Zugang zum Stromnetz. Die KI-gest&#252;tzte Analyse
solcher gro&#223;en, unstrukturierten, dynamischen Datenmengen kann helfen, geeignete Standorte f&#252;r die Errichtung
neuer Anlagen schneller zu identifizieren und diese zu erschlie&#223;en.321 
Zum anderen k&#246;nnen digitale Zwillinge mithilfe von KI den Einsatz von Erneuerbaren Energien optimieren. So
k&#246;nnen Erneuerbare Energien besser bedarfsgerecht und netzdienlich eingesetzt und Ausfallzeiten minimiert
werden. Verschiedene Unternehmen haben gezeigt, dass sie mithilfe von KI die eigene Energieproduktion
erheblich steigern und in das Energienetz einspeisen konnten. In einem Projekt mit mehreren Windparks mit einer
Gesamtkapazit&#228;t von 700 Megawatt im US-Bundesstaat Oklahoma konnte beispielsweise der Produktionswert
der Windparks durch pr&#228;zisere Vorhersagen um 20 Prozent gesteigert werden.322 In einem Modellprojekt der 
318 Vgl. Reetz (2019): Blockchain &amp; das Klima.
319 Vgl. Reetz (2017): Welche Chancen ein digitales Energie-Marktdesign bietet.
320 Vgl. Asendorf (2020): Intelligenz, die keinem hilft.
321 Vgl. ee-news.ch (2019): Verl&#228;ssliche Daten zum Ausbau Erneuerbarer: Kaiserwetter und SAP stellen KI-Ansatz zur
Risikominimierung von Investitionen vor.
322 Vgl. Shead (2019): DeepMind and Google Train AI To Predict Energy Output Of Wind Farms.
RTWH Aachen im schw&#228;bischen Wertachau konnte mithilfe des KI-Programms &#8222;Smart Operator&#8220; durch
optimiertes Lastmanagement die Netzeinspeisung Erneuerbarer Energien um 35 Prozent erh&#246;ht werden.323 &#220;ber ihren
Lebenszyklus hinweg k&#246;nnen diese Anlagen daher einen h&#246;heren Mehrwert f&#252;r das Energiesystem erbringen. 
8.3.3 KI kann helfen, Energiem&#228;rkte effizienter zu machen und damit Kosten zu reduzieren
Zwar sind die Kosten f&#252;r die Produktion von Strom durch Erneuerbare Energien gesunken, jedoch sind die
Gemeinkosten des Energiesystems in den letzten Jahren gestiegen &#8211; u. a. weil Schwankungen der volatilen
Erzeugung ausgeglichen werden m&#252;ssen. Daf&#252;r m&#252;ssen zum Teil Anlagen abgeregelt324 werden. Eine h&#246;here
Automatisierung von (Markt-)Prozessen in Verbindung mit immer besseren Prognosen kann helfen, Verbrauch,
Speicherung und Erzeugung besser zu synchronisieren. Gerade eine Vielzahl von elektrischen Fahrzeugen k&#246;nnte dazu
flexibel als Speicher genutzt werden (siehe auch den Bericht der Projektgruppe &#8222;KI und Mobilit&#228;t&#8220; in Kapitel
C. VI. [K&#252;nstliche Intelligenz und Mobilit&#228;t (Projektgruppe 5)]). Dadurch muss weniger Erzeugung abgeregelt
werden und Kosten k&#246;nnen reduziert werden. Erst KI macht solche signifikanten Steigerungen der Prognoseg&#252;te
m&#246;glich.325 Punktuelle Erzeugungsspitzen k&#246;nnen damit potenziell besser vorhergesagt werden als mit fr&#252;her
verwendeten Methoden.326 Dabei kann &#252;berlegt werden, inwieweit Verursachergerechtigkeit im Energiesystem 
gest&#228;rkt werden soll und kann, um prognosebasierte Gesch&#228;ftsmodelle zu erm&#246;glichen und damit die n&#246;tigen
Investitionen auszul&#246;sen. Aufbauend auf Prognosen oder anderen Daten, beispielsweise Netzzustandsdaten oder
Kraftwerksdaten, k&#246;nnen Strategien f&#252;r den Betrieb von Erzeugungsanlagen und Energienetzen abgeleitet
werden.327 Der Energiemarkt mit seiner komplexen Struktur (siehe auch Kapitel 4.1.1 des Berichts der Projektgruppe
&#8222;KI und Mobilit&#228;t&#8220; [Vision KI und Mobilit&#228;t &#8211; Status quo]) mit &#252;berregionalen Transport- und regionalen
Verteilnetzen und einer gro&#223;en Zahl unterschiedlich gro&#223;er Erzeuger erschwert derzeit &#8211; unter den Bedingungen
komplexer staatlicher Marktregulierung &#8211; die Etablierung KI-gest&#252;tzter Prognose-basierter Gesch&#228;ftsmodelle.
Ein Austausch &#252;ber eine zentrale europ&#228;ische Datenplattform k&#246;nnte hier ein noch genauer zu evaluierendes
Optimierungspotenzial bieten. 
KI in der Klimawissenschaft
KI kann einen entscheidenden Beitrag dazu leisten, das Klima und das Erdsystem besser zu verstehen.
Insbesondere die gro&#223;e Zahl zur Verf&#252;gung stehender Daten, die von zahlreichen Messpunkten weltweit erhoben werden,
sowie die gro&#223;e Zahl historischer Daten bieten eine geeignete Ausgangslage f&#252;r KI-Anwendungen im Bereich
Klimawissenschaft bzw. Klimainformatik.328 In wenigen anderen Forschungsfeldern d&#252;rften die Zahl und die
Qualit&#228;t der global zur Verf&#252;gung stehenden Daten &#8211; &#252;ber entsprechend lange Zeitr&#228;ume &#8211; &#228;hnlich gut sein. 
Insbesondere Deep Learning besitzt gro&#223;es Potenzial f&#252;r ein besseres Verst&#228;ndnis von komplexen dynamischen
Prozessen. So lassen sich Hurrikane, die Ausbreitung von Feuer und die Vegetationsdynamik mithilfe von KI
besser beschreiben. 
Mithilfe von KI-Anwendungen lassen sich Klima- und Erdsystemmodelle optimieren, wobei insbesondere
hybride Modelle, die KI mit physikalischer Modellierung329 verbinden, eine wichtige Rolle spielen werden.
Insbesondere die Erkennung von Extremereignissen und die entsprechende Fr&#252;hwarnung sowie die saisonale und
langfristige Vorhersage und Prognose von Wetter und Klima k&#246;nnten stark von den Deep-Learning- und Hybrid-
Modellierungsans&#228;tzen profitieren.330 Hierbei k&#246;nnen nicht nur jeweilige lokale Gegebenheiten, die
beispielsweise zum Entstehen eines Gro&#223;feuers gef&#252;hrt haben, sondern auch weltumspannende zeitliche und r&#228;umliche
Zusammenh&#228;nge, atmosph&#228;rische oder ozeanische Transportprozesse sowie Boden- und Vegetationsdynamiken 
ber&#252;cksichtigt werden.331 
323 Vgl. Zimmermann und Frank (2019): K&#252;nstliche Intelligenz f&#252;r die Energiewende: Chancen und Risiken, S. 30.
324 Eine Anlage &#8222;abregeln&#8221; bedeutet, dass der Anlage weniger Leistung (Energiefluss) entnommen wird, als sie technisch liefern k&#246;nnte.
325 Vgl. Str&#252;ker et al. (2019): European Energy Lab 2030.
326 Vgl. Vogel et al. (2019): K&#252;nstliche Intelligenz f&#252;r die integrierte Energiewende, S. 33.
327 Vgl. Vogel et al. (2019): K&#252;nstliche Intelligenz f&#252;r die integrierte Energiewende, S. 33.
328 Vgl. Weltwirtschaftsforum (2018): Harnessing Artificial Intelligence for the Earth, S. 13.
329 KI-Modelle sind allgemeine, von der Struktur her einfache und regul&#228;re Modelle, die aber eine Vielzahl von Rechenschritten
ben&#246;tigen, um ihre Aufgabe zu erf&#252;llen. Physikalische Modelle sind spezielle, an Gegebenheiten &#8211; z. B. unter Ber&#252;cksichtigung
physikalischer Gesetze &#8211; angepasste Modelle, die in der Regel auch weniger Rechenschritte ben&#246;tigen. KI-Modelle werden mit Daten
trainiert, physikalische Modelle brauchen einen nicht unerheblichen manuellen Mehraufwand, damit zuerst ihre Struktur festgelegt wird.
330 Vgl. Reichstein et al. (2019): Deep learning and process understanding for data-driven Earth system science; Max-Planck-Institut f&#252;r 
Meteorologie (2019): K&#252;nstliche Intelligenz f&#252;r das Erdsystem.
331 Vgl. Max-Planck-Institut f&#252;r Biogeochemie (2019): Mit k&#252;nstlicher Intelligenz das Erdsystem verstehen.
Die Berechnung von Klimamodellen mit klassischen Methoden der Informationstechnik ben&#246;tigt aufgrund der
Komplexit&#228;t der Modelle sehr gro&#223;e Rechenleistung. Auch wenn KI selbst Rechenleistung ben&#246;tigt, kann die
Kombination von KI mit klassischen Methoden der Informatik den Rechenaufwand insgesamt verringern,
beispielsweise durch das Erkennen neuer Zusammenh&#228;nge in Daten mittels KI. Auf diese Weise kann die Leistung 
der Wetter- wie auch der Klimamodellierung verbessert werden. So setzten &#246;ffentliche Stellen wie das britische
Met Office und die NASA oder private Akteure Maschinelles Lernen ein, um die Leistung und Effizienz von
Wetter- und Klimamodellen zu optimieren.332 KI-Techniken k&#246;nnen auch dabei helfen, m&#246;gliche bestehende
Verzerrungen in Klimamodellen zu korrigieren.333 Allerdings k&#246;nnen auch in der Klimawissenschaft fehlerhafte
oder qualitativ ungeeignete Daten &#8211; genau wie in anderen Anwendungszusammenh&#228;ngen &#8211; dazu f&#252;hren, dass KI-
Modelle zu falschen Schl&#252;ssen kommen. So waren in einer im Herbst 2019 publizierten Studie, die die
Vulnerabilit&#228;t k&#252;stennaher Gebiete dreimal h&#246;her als bislang angenommen angesetzt hatte334, die mittels eines
selbstlernenden Algorithmus korrigierten Satellitendaten &#8211; es sollte die H&#246;he von H&#228;usern und Baumkronen aus den
Daten herausgerechnet werden &#8211; fehlerhaft. Denn die aus den USA stammenden Trainingsdaten waren auf die
baulichen Strukturen in K&#252;stenregionen Asiens oder Afrikas nicht &#252;bertragbar.335
Einsatz von KI-Anwendungen im Naturschutz und im Umwelt-Monitoring
Das Erfassen von Bestandszahlen und Bestandsschwankungen oder die Dokumentation von
Wanderungsbewegungen von Tieren sind seit langer Zeit Kernbestandteil der Biologie, insbesondere der Wildtierbiologie, der
Insektenkunde oder der Zoogeografie. Mit dem fortschreitenden globalen Verlust der biologischen Vielfalt und
der zunehmenden Zahl von bedrohten Tier- und Pflanzenarten oder mit dem Insektensterben gewinnen Daten
&#252;ber die Ver&#228;nderungen von Tierpopulationen enorme Bedeutung &#8211; f&#252;r die Wissenschaft selbst, aber auch als
Grundlage f&#252;r regulatorische Entscheidungen im Bereich Natur- und Artenschutz.
Verschiedene Anwendungen der KI, insbesondere die Bilderkennung, bieten hierbei ein gro&#223;es Potenzial.
Bilderkennungsverfahren, beispielsweise durch visuelle Tierbiometrie, erm&#246;glichen es, mittels Drohnen oder
selbstausl&#246;sender Kamerafallen autonom Bild-, Video- oder Tonmaterial von Tieren zu erstellen, gro&#223;e Mengen
bestehenden Bildmaterials auszuwerten, Tiere automatisch zu erkennen, Spezies zu klassifizieren oder einzelne
Tiere zu identifizieren.336 So gibt es Tests an Windkraftanlagen, die mit der Erkennung von V&#246;geln arbeiten und
je nach Schutzstatus die Anlagen abriegeln.
Auch lassen sich die Wanderungsrouten von Walen oder Haien, die dank der jeweils individuellen Form ihrer
R&#252;cken- oder Schwanzflosse eindeutig identifizierbar sind, deutlich besser rekonstruieren.337 Zahlreiche andere
Tierarten lassen sich durch ihre individuelle Fellf&#228;rbungen, ihre spezifischen Laute oder andere Charakteristika
mittels Bild- oder Spracherkennung identifizieren. Entsprechende Verfahren werden bereits von Unternehmen in 
Kooperation mit Naturschutz-NGOs338 in verschiedenen Zusammenh&#228;ngen erfolgreich eingesetzt.339 
Die so gewonnenen Daten k&#246;nnen unsere Kenntnis &#252;ber die Lebensr&#228;ume oder das Sozialverhalten von Tieren 
verbessern, aber auch helfen, z. B. bessere und zielgerichtete Schutzma&#223;nahmen f&#252;r gef&#228;hrdete Tierarten zu
ergreifen oder Wilderei zu bek&#228;mpfen.340 Verschiedene Technologieunternehmen haben bereits in Kooperation mit
Naturschutzorganisationen entsprechende Technologien entwickelt. So sind Algorithmen derzeit in der Lage, gut
600 unterschiedliche Tierarten zu erkennen.341 
332 Vgl. Weltwirtschaftsforum (2018): Harnessing Artificial Intelligence for the Earth, S. 13.
333 Vgl. Weltwirtschaftsforum (2018): Harnessing Artificial Intelligence for the Earth, S. 13.
334 Vgl. Kulp und Strauss (2019): New elevation data triple estimates of global vulnerability to sea-level rise and coastal flooding.
335 Vgl. Fischer (2019): Wenn die KI daneben liegt.
336 Vgl. Loos (2019): K&#252;nstliche Intelligenz unterst&#252;tzt den Artenschutz.
337 Vgl. Best (2016): Scientists are using cloud computing and AI to track these mysterious, beautiful whale sharks sowie Johnson 
(2020): Google&#8217;s AI powers real-time orca tracking in Vancouver Bay.
338 Weitere Informationen dazu unter: https://www.worldwildlife.org/projects/wildlife-insights (zuletzt abgerufen am 7. August 2020).
339 Beispiel: Microsofts AI for Earth, weitere Informationen dazu unter: https://www.microsoft.com/en-us/ai/ai-for-earth (zuletzt
abgerufen am 7. August 2020).
340 Vgl. Dinerstein und Bethke: How do we use Artificial Intelligence (AI) cameras to save wildlife?
341 Vgl. Ians (2019): Google maps over 4.5 million animals in the wild.
KI erleichtert auch das Monitoring von Fischbest&#228;nden und kann so einen Beitrag zur nachhaltigen Fischerei
leisten. Auch hier arbeiten bereits Naturschutzorganisationen und Unternehmen zusammen, um entsprechende
Datenbanken zu Bild- und Standortdaten von Fischen zu erstellen. Langfristig k&#246;nnten solche Technologien
eingesetzt werden, um eine nachhaltige Bewirtschaftung von Fischbest&#228;nden zu unterst&#252;tzen.342 
Auch beim globalen Monitoring des aktuellen Zustands und der Entwicklungen von Waldgebieten kommt KI
schon heute zum Einsatz. So hat das Deutsche Zentrum f&#252;r Luft- und Raumfahrt (DLR) auf Basis von
Radarsatellitenmissionen mithilfe von KI die globale Waldkarte TanDEM-X erstellt. Diese Karte wurde f&#252;r verschiedene
Waldtypen anhand von Baumh&#246;hen, Dichte und Struktur optimiert und zeigt mit einer Aufl&#246;sung von 50 Metern
die Ausdehnung bewaldeter Fl&#228;chen. F&#252;r die Erstellung wurden &#252;ber 400 000 Datens&#228;tze verarbeitet. Die
Verarbeitung dieser riesigen Datenmengen war nur dadurch m&#246;glich, dass Algorithmen verschiedene Waldtypen
identifizieren und klassifizieren konnten.343 Diese Daten k&#246;nnen nun als Grundlage f&#252;r unterschiedliche
Anwendungen genutzt werden. 
Auch beim Kampf gegen illegale Abholzung in tropischen Regenw&#228;ldern kann KI eingesetzt werden. So l&#228;sst
sich beispielsweise durch bioakustisches Monitoring mittels KI in Echtzeit erkennen, ob in bestimmten
Regenwaldgebieten Kettens&#228;gen zum Einsatz kommen.344 
KI-L&#246;sungen in der Agrarwirtschaft k&#246;nnen zudem eine nachhaltige Ressourcennutzung durch weniger und
effizienteren Einsatz von Saatgut, D&#252;ngemitteln und anderen Substanzen erm&#246;glichen. Die Chancen von
Digitalisierung und KI sind hier enorm, aber es besteht auch die Gefahr einer Abh&#228;ngigkeit von monopolistischen
Unternehmen. Diese Aspekte wurden auch in der Projektgruppe &#8222;KI und Wirtschaft&#8220; er&#246;rtert.345 
Fazit
Als Ergebnis bleibt festzuhalten, dass es bei der nachhaltigen Gestaltung der Prozesse wichtig ist, dass der Einsatz
von KI-L&#246;sungen nicht per se wirtschaftlich, &#246;kologisch und sozial nachhaltig ist. Denn zum Teil steigen der
Strom- und Ressourcenverbrauch durch IT und KI enorm. Gleichzeitig bieten Digitalisierung und KI aber auch
zahlreiche Chancen. Hier m&#252;ssen klare Rahmenbedingungen daf&#252;r sorgen, dass nachhaltige Innovation gef&#246;rdert
und Rebound-Effekte vermieden werden.
Handlungsempfehlungen346 
Die Enquete-Kommission empfiehlt vor diesem Hintergrund
1. einen ambitionierten Ausbau und die Umsetzung der KI-Strategie der Bundesregierung vorgesehenen ersten
F&#246;rderungen von KI-Anwendungen zum Nutzen von Umwelt und Klima
2. die F&#246;rderung von nachhaltiger KI und entsprechende Weiterentwicklung sowohl der umweltpolitischen 
Digitalagenda als auch der KI-Strategie der Bundesregierung und dabei eine vertiefte Untersuchung des
nachhaltigkeitspolitischen Potenzials von KI, auch unter Beachtung von Suffizienzfragen, die Ableitung
und Entwicklung einer nachhaltigkeitspolitischen KI-Strategie sowie darauf aufbauend eine gezielte
F&#246;rderung der vielversprechendsten Ans&#228;tze und Monitoring ihres tats&#228;chlichen Beitrags zur Erreichung von 
Klima- und Nachhaltigkeitszielen
3. eine Verbesserung der Datenbasis zum Beitrag von KI-Anwendungen zur Entwicklung des
Energieverbrauchs (sowohl positive wie negative Effekte), wobei Gegenstand auch die Transparenz in Bezug auf den
Strom- und Ressourcenverbrauch von KI-basierten Technologien w&#228;hrend des gesamten Lebenszyklus sein 
muss
4. mehr Forschung zur systematischen Analyse des CO2-Minderungspotenzials durch KI-Anwendungen in
den Schl&#252;sselsektoren Energie, Industrie, Landwirtschaft, Wohnen und Mobilit&#228;t
342 Vgl. Bundesministerium f&#252;r Umwelt, Naturschutz und nukleare Sicherheit, 21. August 2019.
343 Vgl. Deutsches Zentrum f&#252;r Luft- und Raumfahrt (2019): Globale TanDEM-X-Waldkarte verf&#252;gbar.
344 Vgl. Grasel (2019): Dein altes Handy kann den Regenwald retten bzw. Rainforest Connection (2020): How our system helps preserve 
rainforests.
345 Siehe Kapitel 4.1.3.2.4 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220; [Themenfeld Agrar&#246;konomie und Landwirtschaft].
346 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 8.7 des Mantelberichts
(&#8222;Handlungsempfehlungen &#8220; zu &#8222;KI und &#246;kologische Nachhaltigkeit &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des
sachverst&#228;ndigen Mitglieds Dr. Florian Butollo].
5. eine st&#228;rkere F&#246;rderung von nachhaltiger IT einschlie&#223;lich einer besseren Nutzung von Abw&#228;rme in
Rechenzentren als infrastrukturelle Voraussetzung f&#252;r die Verringerung des &#246;kologischen Fu&#223;abdrucks von
KI
6. die F&#246;rderung von Projekten zur Identifikation und Umsetzung KI-basierter Ma&#223;nahmen zur Minderung
der CO2-Intensit&#228;t in der Produktion
7. eine Forschungsf&#246;rderung f&#252;r den Bereich &#8222;Sustainable Coding for AI&#8220; (Nachhaltige Codierung f&#252;r KI) und 
F&#246;rderung der Entwicklung eines entsprechenden Muster-Lehrplans f&#252;r die Hochschulen 
9 KI und Forschung347 
Einleitung und &#220;berblick
Auf vielen Teilgebieten der KI hat die Forschung in Deutschland international einen ausgezeichneten Ruf. Die
Plattform Lernende Systeme348, initiiert durch das Bundesministerium f&#252;r Bildung und Forschung (BMBF) im
Jahr 2017, stellt eine &#8222;KI-Landkarte&#8220; zur Verf&#252;gung, welche die KI-Schwerpunkte und 196 forschende
Institutionen in Deutschland349 abbildet. Ein Gro&#223;teil der Forschung findet an Hochschulen, prim&#228;r Universit&#228;ten, und
au&#223;eruniversit&#228;ren Forschungseinrichtungen statt.350 KI-Systeme werden unsere Gesellschaft innerhalb der
n&#228;chsten Jahre zunehmend im gesellschaftlichen, wirtschaftlichen, wissenschaftlichen und politischen Bereich
durchdringen. Dies stellt die Forschung vor neue Herausforderungen. Intelligente Maschinen und Roboter ebenso
wie autonome Systeme k&#246;nnen einen wichtigen Beitrag zur L&#246;sung zentraler gesellschaftlicher
Herausforderungen bieten. Forschung zu KI muss aktiv an L&#246;sungen f&#252;r die Zukunft von Arbeit, Bildung, Gesundheit, Mobilit&#228;t,
Wirtschaft und Energie arbeiten und gleichzeitig sicherstellen, dass das Wohl aller Menschen und das
demokratische, partizipative und gleichberechtigte Zusammenleben im Mittelpunkt dieser Anwendungen stehen. 
Der internationale Wettbewerb um die Partizipation an der gesamten Wertsch&#246;pfungskette im Markt der KI-
Systeme spannt sich vom Wettbewerb um die besten KI-Spezialistinnen und -Spezialisten bis zur Etablierung
international wettbewerbsf&#228;higer KI-Konzerne. Deutschland darf dieser Entwicklung nat&#252;rlich nicht nur aus
&#246;konomischer Motivation folgen, sondern muss aktiv und gestaltend eine eigene, breitere Position w&#228;hlen, um
globale Standards nach eigenen Ma&#223;st&#228;ben setzen zu k&#246;nnen. Der zentrale Erfolgsschl&#252;ssel hierzu ist die nationale
Forschung in einem europ&#228;isch stark vernetzten Kontext.
Der vorliegende Berichtsteil beginnt deshalb erstens mit vier zentralen Leitlinien, die der KI-Forschung in
Deutschland unter und mit europ&#228;ischer Perspektive &#8211; unabh&#228;ngig davon, ob die Forschung an Universit&#228;ten, 
Forschungsinstituten oder in Unternehmen stattfindet &#8211; zugrunde liegen sollten. Um die KI-Forschung in
Deutschland und ihre Vernetzung in Europa voranzubringen, werden zweitens strategische Gesamtziele
entwickelt. Drittens macht der Berichtsteil im Rahmen einer SWOT-Analyse anhand dieser Leitlinien und Ziele
deutlich, wo die KI-Forschung in Deutschland aktuell steht, wie sich ihre Kooperation mit europ&#228;ischen Partnern
gestaltet und wo zentrale Herausforderungen im Bereich der KI mit neuen Methoden der Forschungsf&#246;rderung
und -verortung gel&#246;st werden m&#252;ssten. Daraus ergeben sich viertens spezifische Herausforderungen und
Handlungsempfehlungen zur Verbesserung der Forschungsf&#246;rderung an den Staat. Unter den erarbeiteten
Voraussetzungen wird f&#252;nftens dargestellt, wie KI-Forschung und KI-Transfer k&#252;nftig aussehen und welche Schwerpunkte
gesetzt werden sollten, um global zukunftsf&#228;hig zu bleiben und den Forschungsstandort Deutschland im
europ&#228;ischen Kontext international richtungsweisend und wettbewerbsf&#228;hig zu gestalten.
Im Kern hat die &#246;ffentliche Hand drei Handlungsstr&#228;nge, entlang derer sie die strategische Forschungsf&#246;rderung
und -agenda zum Wohle der Gesellschaft betreiben kann.
&#8226; Erstens muss der Staat klare Werte artikulieren und definieren; diese Leitplanken sind von der KI-
Forschung einzuhalten. Er muss zudem einen eindeutigen Rahmen vorgeben, welcher die Forschung und vor
allem den darin anvisierten Erkenntnisgewinn bef&#246;rdern.
347 Zu diesem Kapitel liegen Sondervoten aus der Fraktion der AfD [Sondervotum zu Kapitel 9 des Mantelberichts (&#8222;KI und Forschung&#8220;) 
des Abgeordneten Dr. Marc Jongen sowie der Abgeordneten Joana Cotar und Peter Felser] sowie aus der Fraktion B&#220;NDNIS
90/DIE GR&#220;NEN vor [Sondervotum zu Kapitel 9 des Mantelberichts (&#8222;KI und Forschung &#8220;) die Abgeordneten Dr. Anna Christmann
und der Abgeordnete Dieter Janecek sowie der sachverst&#228;ndigen Mitglieder Prof. Dr. Hannah Bast und Dr. Stefan Heumann].
348 Weitere Informationen dazu unter: https://www.plattform-lernende-systeme.de/ueber-die-plattform.html (zuletzt abgerufen am
7. August 2020).
349 Stand: 19. August 2020.
350 Weitere Informationen dazu unter: https://www.plattform-lernende-systeme.de/ki-landkarte.html?FIT=1 (zuletzt abgerufen am
7. August 2020).
&#8226; Zweitens sollte der Staat vielversprechende Forschungs- und Transfereinrichtungen &#252;ber finanzielle
Investitionen bef&#246;rdern. 
&#8226; Drittens kann der Staat indirekt &#252;ber andere politische Steuerungsmittel, wie z. B. Wirtschafts-,
Innovations- oder Bildungspolitik, durch das Zusammenspiel der Ebenen die Entwicklung von KI-Forschung, die
an gesellschaftlichen Zielen orientiert ist, nicht nur beg&#252;nstigen, sondern nachhaltig in der Breite
erm&#246;glichen. In zeitlich besonders kritischen oder strategisch relevanten F&#228;llen sollte der Staat &#252;ber
Direktvergaben in die Forschung handlungsf&#228;hig gemacht werden. 
Die nationale Ebene ist Teil einer europ&#228;ischen Forschungsf&#246;rderlandschaft, die zu einem signifikanten Anteil
auch deutsche Forschung finanziert. Deshalb sollen die Forschungsschwerpunkte auf EU-Ebene im Folgenden
auch eine Referenz f&#252;r KI-Forschung in Deutschland darstellen, um eine gemeinsame strategische Ausrichtung
zu gew&#228;hrleisten.351 
Im Bereich KI nennt die Europ&#228;ische Union 2019 in ihrem Rahmenprogramm f&#252;r Forschung und Innovation 
(Horizon Europe352) vier Kernbereiche der europ&#228;ischen KI-Initiative. Strategische Autonomie f&#252;r Europa steht
in der Ausschreibung &#8222;Towards a vibrant European network of AI excellence centres&#8221;353 im Vordergrund,
kollaborative Projekte, idealerweise in Netzwerken organisiert, legen den technologischen Schwerpunkt auf
Folgendes:354 
1. Fortschritte im Bereich Grundlagen der KI (z. B. Lernen und Schlussfolgern) und Ans&#228;tze f&#252;r
vertrauensw&#252;rdige KI-L&#246;sungen (einschlie&#223;lich erkl&#228;rbarer KI, Vermeidung von Bias und Diskriminierung;
Sicherheit, Zuverl&#228;ssigkeit, &#220;berpr&#252;fbarkeit usw.)
2. die Entwicklung der n&#228;chsten Generation intelligenter Roboter
3. fortgeschrittene Wahrnehmung oder Interaktion mit Menschen (f&#252;r eine menschenzentrierte KI) und
Umgebungen
4. Hardware f&#252;r KI und KI-Edge-Computing, d. h. eine dezentrale Datenverarbeitung durch den Einsatz der
KI in Ger&#228;ten an der Schnittstelle der virtuellen zur realen Welt &#8211; z. B. in Autos, Industrieanlagen oder
portablen Diagnoseger&#228;ten 
Leitlinien
9.2.1 Leitlinie 1: Zugrundeliegende Werte
Gesellschaftliche Werte und das Wohlergehen der Menschen sowie der Erkenntnisgewinn m&#252;ssen im
Mittelpunkt der Bestrebungen von Wissenschaft und Forschung auch im Bereich der KI stehen. KI-Forschung soll
&#8211; unabh&#228;ngig davon, ob intrinsisch oder extrinsisch motiviert &#8211; erkenntnisorientiert sein und sich an
gesellschaftlichen Zielen orientieren. Die Ergebnisse und die darauf basierenden Anwendungen sollen nachhaltig,
vertrauensw&#252;rdig und ressourcenbewusst sein. Dazu z&#228;hlen auch immaterielle Ressourcen wie Daten und Zeit, mit
denen ebenfalls schonend umgegangen werden muss. Missionsbasierte355, am gesellschaftlichen Bedarf sowie
Nutzen orientierte Umsetzungen bef&#246;rdern, dass unsere Werte und Normen in der Forschung und bei der Translation
in marktreife Anwendungen ber&#252;cksichtigt werden. Sie richten ihre Ziele an den ethisch-moralischen Werten und
Vorstellungen der High-Level Expert Group on Artificial Intelligence der Europ&#228;ischen Kommission und an
diesem Bericht aus.
9.2.2 Leitlinie 2: F&#246;rderung von Leuchtturm-Institutionen in der Forschung
Die Umsetzung einer international langfristig wettbewerbsf&#228;higen Forschungsstrategie bedingt den Auf- und
Ausbau von Leuchtturm-Institutionen an international sichtbaren Standorten. Dies beinhaltet u. a. Investitionen
in Infrastruktur (wissenschaftlich-technisch, strukturell und lebensweltlich), die Fokussierung auf bereits
etablierte und international sichtbare Schwerpunktthemen (z. B. medizinische Diagnostik, Maschinelles Lernen,
intelligente Robotik etc.) sowie den Aufbau hinreichend vieler Expertinnen und Experten. Durch die Strahlkraft
351 Vgl. Europ&#228;ische Kommission (2019): Horizon 2020, S. 18 ff.
352 Weitere Informationen dazu unter: https://www.consilium.europa.eu/de/policies/horizon-europe/ (zuletzt abgerufen am 7. August
2020).
353 Europ&#228;ische Union: Open call: Towards a vibrant European network of AI excellence centres.
354 KI-Netzwerke werden stark durch die EU gef&#246;rdert. Bisher gilt dies insbesondere f&#252;r CLAIRE (Confederation of Laboratories for
Artificial Intelligence Research in Europe) und ELLIS (European Laboratory for Learning and Intelligent Systems).
355 Vgl. Mazzucato (2018): Mission-oriented research &amp; innovation in the European Union.
dieser Institutionen werden wiederum internationale Nachwuchs-Wissenschaftlerinnen und -Wissenschaftler
sowie etablierte Expertinnen und Experten angezogen und in ihrem Wirken in den jeweiligen &#214;kosystemen optimal
gef&#246;rdert. Die interdisziplin&#228;r eingebetteten Forschungsinstitutionen sind nicht nur national, sondern auch
europ&#228;isch mit gezielter Breitenwirkung vernetzt. Dabei sind nicht nur nationale Leuchtt&#252;rme wichtig und notwendig,
sondern es m&#252;ssen auch die europ&#228;ischen Bestrebungen der Zentrumsbildung, welche auf breiten Forschungs-
und Industrienetzwerken aufbauen, unterst&#252;tzt werden. 
9.2.3 Leitlinie 3: F&#246;rderung der Forschung in der Breite356 
Damit die gesamte Gesellschaft von den Fortschritten der KI-Forschung profitiert, sind der Aufbau und die
Vernetzung einer leistungsstarken und fl&#228;chendeckenden Forschungsinfrastruktur n&#246;tig. Die enge Interaktion von 
Forschenden in dezentralen Forschungsnetzwerken im europ&#228;ischen und internationalen Raum sowie
R&#252;ckkopplungen zwischen Grundlagenforschung, Anwendungsprojekten und der systematischen Reflexion &#252;ber
gesellschaftliche Zielsetzungen durch Wirkung von KI werden dadurch erm&#246;glicht. Neben der Fokussierung auf bereits
etablierte und international sichtbare Schwerpunktthemen soll KI-Forschung weitere neue und innovative
Anwendungsfelder erschlie&#223;en bzw. erschlie&#223;en helfen. Das gilt besonders f&#252;r Bereiche, in denen KI beispielsweise
durch &#8211; auch auf europ&#228;ischer Ebene &#8211; favorisierte missionsbasierte Forschung mit dem Ziel gesellschaftlich
orientierter &#8222;Grand Challenges in Research and Innovation&#8220; einen Beitrag leistet. Es braucht aber auch finanzielle
und strukturelle Spielr&#228;ume f&#252;r neue, kreative Ideen und Projekte au&#223;erhalb des Mainstreams.
Die konkrete Abw&#228;gung der relativen Priorisierung der Leitlinien 2 und 3, sofern die finanziellen Mittel eine
solche &#252;berhaupt n&#246;tig machen, ist mit Augenma&#223; und strategischer Weitsicht durchzuf&#252;hren.  
9.2.4 Leitlinie 4: Beziehung Wissenschaft &#8211; Wirtschaft &#8211; Zivilgesellschaft
Ebenso wichtig wie eine exzellente Grundlagenforschung ist der Transfer von Forschungsergebnissen zum
Wohle der Zivilgesellschaft und der Wirtschaft. Ein zentrales Thema hierbei ist das Bereitstellen von Daten und
Technologien, die f&#252;r die Forschung notwendig sind, sowohl vonseiten der Wirtschaft als auch vonseiten des
Staates. Die m&#246;glichst breite Verf&#252;gbarkeit und der weitere Transfer der Forschungsergebnisse sollte, soweit
sinnvoll, mitgedacht werden. Um einen m&#246;glichst breiten Nutzen zu erlangen, m&#252;ssen Unternehmen aller
Gr&#246;&#223;enordnungen, vor allem Start-ups, als Teil dieses Prozesses verstanden werden.357 Hochschulen, insbesondere
Universit&#228;ten, und Forschungseinrichtungen sollten sich Anforderungen der Gesellschaft &#246;ffnen und Br&#252;cken
zwischen Wissenschaft und Anwendung schaffen, wodurch dr&#228;ngende gesellschaftliche Probleme bearbeitet
werden k&#246;nnen. Dies erfordert auch den Ausbau von Transfer- und Kooperationsmechanismen zwischen
Wissenschaft, Wirtschaft, Politik und Zivilgesellschaft im Bereich der KI-Forschung, mithin auch eine
Zug&#228;nglichkeit von KI-Entwicklung im Rahmen von Citizen Sciences, Reallaboren und &#228;hnlichen inklusiven Ans&#228;tzen der
Innovation. 
Strategische Ziele
Die strategischen Ziele der KI-Forschung in Deutschland orientieren sich erstens an einer mittel- bis langfristigen
Perspektive, ber&#252;cksichtigen zweitens die entsprechenden Wechselwirkungen sowohl innerhalb als auch
au&#223;erhalb des Wissenschaftssystems und erweitern drittens die im Rahmen der KI-Strategie der Bundesregierung358 
schon hinsichtlich der Wissenschaft festgelegten Ziele um eine kontinuierliche Entwicklung. 
Es erscheint wesentlich festzustellen, dass die Konzentration auf das Themenfeld KI nat&#252;rlich bedeutet, dass
grunds&#228;tzlich abgewogen werden muss, ob die hierf&#252;r notwendigen Mittel aus den bestehenden
Wissenschaftsbudgets von Bund und L&#228;ndern gewonnen werden, oder ob es sich auch um zus&#228;tzliche, neue finanzielle und
strukturelle Ressourcen handelt &#8211; was aufgrund der herausragenden Bedeutung der KI f&#252;r nahezu alle
technologie- bzw. softwarebasierten Systeme stark zu bef&#252;rworten ist.
Dazu werden die folgenden strategischen Ziele formuliert: 
356 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 9.2.3 des Mantelberichts
(&#8222;Leitlinie 3: F&#246;rderung der Forschung in der Breite &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen 
Mitglieds Dr. Florian Butollo].
357 Hochschulen, Forschungsinstitute und der Staat haben derzeit nicht die Strukturen, Forschungsergebnisse in der Anwendung zu
skalieren.
358 Vgl. Bundesregierung (2018): Strategie K&#252;nstliche Intelligenz der Bundesregierung, insb. S. 12&#8211;20.
&#8226; Ziel 1: Bereitstellung von Sondermitteln f&#252;r eine international sichtbare und national wie international
strategisch vernetzte, missionsbasierte KI-Spitzenforschung, die eine europ&#228;ische Wissenschaftscluster-
Perspektive beinhaltet 
&#8226; Ziel 2: F&#246;rderung internationaler Leuchtturm-Institutionen in Deutschland, ebenfalls bef&#246;rdert durch
missionsbasierte Ziele und internationale Forschungsnetzwerke
&#8226; Ziel 3: An gesellschaftlichen Zielsetzungen orientierte KI-Forschung in und mit der Gesellschaft durch KI-
Missionen sowie sozial-, verhaltens- und kulturwissenschaftliche Forschung zu den Auswirkungen von KI
auf Mensch und Gesellschaft in europ&#228;ischer Dimension
&#8226; Ziel 4: St&#228;rkung der inter-/transdisziplin&#228;ren Forschung sowie Ber&#252;cksichtigung einer
anwendungsorientierten, translatorischen Perspektive
&#8226; Ziel 5: Nachhaltige Steigerung der Anziehungskraft f&#252;r internationale Nachwuchs-Wissenschaftlerinnen
und -Wissenschaftler durch eine Modernisierung und Modifikation der bestehenden Verg&#252;tungs- und
Gratifikationsmodelle, attraktive Forschungs- und Lebensbedingungen sowie die Sogwirkung eines an
gesellschaftlichen Zielsetzungen orientieren Forschungs&#246;kosystems sowie Angebote mit attraktiven Optionen zur
Bindung nationaler Kr&#228;fte beispielsweise &#252;ber Tenure-Track-Modelle
&#8226; Ziel 6: Grunds&#228;tzlich eine signifikante Steigerung der &#246;ffentlichen wie auch privatwirtschaftlichen
Forschungs- und Entwicklungsaufwendungen, die sich am f&#252;r Deutschland skalierten Benchmark der
f&#252;hrenden Nation in der KI-Forschung ausrichtet, den USA
Bei den Zielen muss man ber&#252;cksichtigen, dass es an zahlreichen Stellen Defizite gibt: Die Forschung,
insbesondere im Kontext lernender Systeme, ist limitiert durch den Mangel an nachhaltigen Forschungsmitteln,
hinreichend qualifizierten Wissenschaftlerinnen bzw. Wissenschaftlern auf unterschiedlichen Leistungsebenen sowie
durch eine gewisse Inflexibilit&#228;t des Wissenschaftssystems. Dar&#252;ber hinaus sind europ&#228;ische
Forschungsbem&#252;hungen teilweise durch die mangelnde Verf&#252;gbarkeit hinreichend gro&#223;er Realdatenbest&#228;nde, limitierte
Technologiesouver&#228;nit&#228;t sowie andere Rahmenbedingungen begrenzt. Schlie&#223;lich fehlen f&#252;r die gezielte Entwicklung
einer Forschungslandschaft strategische, langfristig angelegte Programme. Die Herausforderung des Staates liegt
also darin, die Forschung als zentralen Schl&#252;ssel zum Feld der KI zu akzeptieren, sie in geeigneter St&#228;rke zu
f&#246;rdern und gleichzeitig in einem &#8222;Sandbox&#8220;-Modell neue, interdisziplin&#228;r gepr&#228;gte Grundlagenforschung zu
erm&#246;glichen.
Umgekehrt muss der Staat im Rahmen seiner KI-Forschungs- und Wissenschaftspolitik daf&#252;r sorgen, die
Abh&#228;ngigkeiten von Dritten au&#223;erhalb Europas bzw. von finanzkr&#228;ftigen Technologieunternehmen zu minimieren. Das
Erreichen digitaler und damit auch einer gewissen technologischen Souver&#228;nit&#228;t durch die Umsetzung der oben
genannten strategischen Ziele ist ein zentraler Erfolgsfaktor f&#252;r eine nationale und europ&#228;isch stark vernetzte, auf
Forschung ausgerichtete KI-Strategie.
SWOT-Analyse der KI-Forschung in Deutschland
In der nachfolgenden St&#228;rken-, Schw&#228;chen-, Chancen- und Risiken-Analyse (SWOT) werden aus Sicht der
Forschung u. a. die im Rahmen der Leitlinien beschriebenen Grundlagen und strategischen Ziele bewertet und
gewichtet.
9.4.1 Welche St&#228;rken hat die KI-Forschung in Deutschland?359 
Deutschland ist in der Breite gut aufgestellt und verf&#252;gt &#252;ber zahlreiche gute und einige ausgezeichnete
Universit&#228;ten und Forschungsinstitutionen. In Bezug auf die absolute Anzahl der KI-Publikationen belegt Deutschland
im internationalen Vergleich allein eine gute, aber keine f&#252;hrende Position.360 Europa als Ganzes ist je nach
Datenlage auf Augenh&#246;he mit den USA und China oder nimmt ihnen gegen&#252;ber sogar eine F&#252;hrungsposition
359 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion der CDU/CSU vor [Sondervotum zu Kapitel 9.4.1 des Mantelberichts
(&#8222;Welche St&#228;rken hat die KI-Forschung in Deutschland? &#8220;) des sachverst&#228;ndigen Mitglieds Dr. Sebastian Wieczorek und der
Abgeordneten Marc Biadacz, Hansj&#246;rg Durz und Prof. Dr. Claudia Schmidtke sowie der sachverst&#228;ndigen Mitglieder Prof. Dr. Wolfgang
Ecker und Prof. Dr. Alexander Filipovi&#263;].
360 Basierend auf dem AI Index 2019 nach Perrault et al. (2019): The AI Index 2019 Annual Report belegt Deutschland beispielsweise
hinter den USA, China, Indien und Gro&#223;britannien den f&#252;nften Rang bei der Anzahl von wissenschaftlichen Ver&#246;ffentlichungen in
wissenschaftlichen Zeitschriften und bei Vortr&#228;gen auf Konferenzen, wobei die beiden f&#252;hrenden Nationen jeweils ca. die 5- bis 6-
fache Menge an Publikationen aufweisen.
ein.361 Dar&#252;ber hinaus haben sich in Deutschland beispielsweise durch die Identifikation und F&#246;rderung von
Spitzenclustern362 und Institutionen der Anwendungsforschung Schwerpunktzentren etabliert, die starke
Ankn&#252;pfungspunkte f&#252;r eine transferorientierte KI-Forschung an national relevante Anwendungsgebiete und
Industrien wie beispielsweise Medizin, Industrie und Elektromobilit&#228;t erm&#246;glichen. Hier spielen auch die
anwendungsnahe Ausbildung von Nachwuchskr&#228;ften an den Hochschulen sowie der industrienahe Transfer eine
zentrale Rolle. Insgesamt ist dies ist eine gute Grundlage, um im internationalen Vergleich eine Spitzenposition in
Bereichen der KI-Forschung einnehmen zu k&#246;nnen, die f&#252;r Deutschland strategisch wichtig sind. F&#252;r den
klassischen Transfer von Forschungsergebnissen in die Anwendung gibt es etablierte und funktionierende Konzepte.363 
Die nach wie vor hohe Attraktivit&#228;t Deutschlands als Studien- und Forschungsort, bietet theoretisch eine gute
Grundlage, um ausreichend viele KI-Forscherinnen bzw. -Forscher und Anwendende auszubilden. Diese
Attraktivit&#228;t gilt auch f&#252;r internationale Studierende, die in Deutschland hervorragende Studienbedingungen vorfinden
k&#246;nnen.
9.4.2 Welche Probleme hat die KI-Forschung in Deutschland?
Deutschland hat in der Spitzenforschung Nachholbedarf, sowohl im Verg&#252;tungssystem, den
Forschungsbedingungen (Personalpolitik, Ressourcen etc.) als auch bei der nachhaltigen Gewinnung von ausl&#228;ndischen
Forschenden. F&#252;hrende deutsche Forschungseinrichtungen sind im internationalen Vergleich wenig sichtbar.364 Folglich
wandern momentan mehr in Deutschland ausgebildete Forscherinnen bzw. Forscher ab, als aus anderen L&#228;ndern
zu uns kommen.365 In Deutschland ist die Anzahl von Frauen in der KI-Forschung generell sowie auch im
internationalen Vergleich gering und sollte signifikant erh&#246;ht werden.366 Diversit&#228;t in einem so zukunftsorientierten
Bereich ist nicht nur normativ w&#252;nschenswert, sondern erh&#246;ht auch die Wahrscheinlichkeit einer Wissenschaft,
die mehr Perspektiven zu bieten hat. Die schwierige Wohnsituation in den deutschen Ballungszentren, fehlende
Kinderbetreuung und internationale Schulen etc. sind zwar keine deutsche Besonderheit, tragen aber gekoppelt
mit den vergleichsweise schlechten Verg&#252;tungen in den Hochschulen und Forschungsinstitutionen nicht zur
Attraktivit&#228;t des Forschungsstandortes bei. Das gilt f&#252;r Frauen und M&#228;nner gleicherma&#223;en. Forschungsf&#246;rderung
wird in Deutschland aufgrund der ressortbezogenen und f&#246;deralen Strukturen, der limitierten M&#246;glichkeiten einer
Bundesfinanzierung und der prim&#228;r kurzfristig ausgerichteten Vergabe von Drittmitteln dar&#252;ber hinaus gehemmt. 
So f&#228;llt es vergleichsweise schwer, schnell und dynamisch neue Forschungsthemen anzugehen, worauf aber
insbesondere ein hochdynamischer und internationaler Forschungsbereich wie KI angewiesen ist. 
Auch im Bereich der Finanzierung von kapitalintensiven Ausgr&#252;ndungen hat Deutschland gro&#223;e Probleme.
Speziell private Investoren beteiligen sich, insbesondere in den USA, um ein Vielfaches st&#228;rker.367 Aber auch
beispielsweise Israel geht hier voran. Deutschlands Universit&#228;ten und Forschungsinstitutionen sind an vielen Stellen 
gerade im Falle der KI schwerf&#228;llig und aufgrund eines zu engmaschigen und komplexen Rechtsrahmens zu 
b&#252;rokratisch. Dies gilt auch f&#252;r den Transfer. Mit der Wirtschaft zu kooperieren oder Start-ups zu gr&#252;nden und
zu unterst&#252;tzen, ist weitaus schwieriger als notwendig. Damit der Transfer von Forschung funktionieren kann,
werden in den jeweiligen Anwendungsfeldern Expertinnen und Experten ben&#246;tigt. Derzeit ist aber der Markt f&#252;r 
Fachkr&#228;fte aus der Informatik, der Ingenieurswissenschaft und sozial-, wirtschafts- und rechtswissenschaftlichen
361 Vgl. elsevier.com (2018): Elsevier AI Ressource Center, wonach Europa im Jahr 2017 der Ursprungsort von 30 Prozent der
weltweiten KI-Publikationen im Vergleich zu China (24 Prozent) und den USA (17 Prozent) war.
362 Spitzenclusterinitiative des BMBF; Weitere Informationen dazu unter: https://www.spitzencluster.de/ (zuletzt abgerufen am 7.
August 2020).
363 Basierend auf Academic-Corporate Collaboration Data (Elsevier Skopus) war Deutschland nach den USA, China und Gro&#223;britannien
das Land mit den meisten wissenschaftlichen Ver&#246;ffentlichungen, an denen Forschungseinrichtungen und Industriepartner
gemeinsam gearbeitet haben.
364 Beispielsweise schafft es nach Chuvpilo (2019): AI Research Rankings 2019: Insights from NeurIPS and ICML, Leading AI
Conferences, das Publikationen f&#252;hrender KI-Konferenzen auswertet, im Gegensatz zu den USA, China, Gro&#223;britannien, Frankreich,
Kanada, der Schweiz, S&#252;dkorea, Israel und Japan keine deutsche Institution in die Liste der Top 40, obwohl Deutschland im
L&#228;ndervergleich vor vielen dieser L&#228;nder steht.
365 Der Global Talent Report 2019 (vgl. Chanler et al. (2019): Global Talent Trends 2019) weist aus, dass von 935 Personen mit
Promotion im Bereich KI 230 ins Ausland gehen, w&#228;hrend gleichzeitig nur 165 im Ausland ausgebildete Wissenschaftlerinnen bzw.
Wissenschaftler nach Deutschland wechseln. &#220;ber die H&#228;lfte (130) der Deutschland verlassenden Wissenschaftlerinnen bzw.
Wissenschaftler wechselten in die USA.
366 Laut Perrault et al. (2019): The AI Index 2019 Annual Report war nur an ca. 25 Prozent der deutschen Forschungspublikationen
mindestens eine Frau beteiligt. In f&#252;hrenden L&#228;ndern wie den Niederlanden und D&#228;nemark betr&#228;gt die Quote &#252;ber 40 Prozent, in
Gro&#223;britannien und Frankreich ca. 30 Prozent und auch die USA liegen mit 27 Prozent hier vor Deutschland. F&#252;r China liegen keine 
Zahlen vor.
367 Vgl. Perrault et al. (2019): The AI Index 2019 Annual Report.
Forschungsfeldern mit KI-Bezug hart umk&#228;mpft und die Hochschulen bilden bis dato zu wenige Spezialistinnen 
und Spezialisten aus, was den Transfer von KI von der Forschung in die Anwendung zus&#228;tzlich belastet. Die
Industrie, und hier vor allem die KMUs, Dienstleistungsunternehmen sowie Beh&#246;rden und Verb&#228;nde besitzen
zudem noch zu wenig KI-Know-how bzw. auch zu wenig qualifiziertes Personal, um effektiv und angemessen
agieren zu k&#246;nnen. 
9.4.3 Welche Potenziale k&#246;nnen erschlossen werden?
Das Potenzial der KI-Forschung wird im Vergleich zu anderen L&#228;ndern nicht voll ausgesch&#246;pft.368 Durch gezielte
zus&#228;tzliche Investitionen k&#246;nnte Deutschland eigene Schwerpunkte setzen, die einerseits an bestehenden St&#228;rken
ansetzen (z. B. autonomes Fahren, Industrie 4.0, KI in der Medizintechnik, Logistik, Chemie) und andererseits
ausgew&#228;hlte Kernthemen von gesamtgesellschaftlicher Relevanz besonders entwickeln (z. B. menschenzentrierte
KI in der Medizintechnik, KI im Staat, ethische und nachhaltige KI). Hierbei ist die B&#252;ndelung und St&#228;rkung
von Forschungsaktivit&#228;ten in Leuchtt&#252;rmen mit den Vorteilen einer starken und gut vernetzten
Forschungslandschaft in der Breite zu kombinieren. 
Die deutsche Industrie ist innovationsstark, und viele Unternehmen sind in ihrer Dom&#228;ne Weltmarktf&#252;hrer.
Dieses Potenzial sollte (besser) ausgenutzt werden. Es bietet sich beispielsweise die Fokussierung auf Innovationen 
im Bereich der KI-Methoden f&#252;r Maschinen- und Sensordaten an. Dadurch k&#246;nnten gro&#223;e und hochfrequente
Datens&#228;tze aus der Industrie bearbeitet werden, wo aktuelle Methoden des Deep Learnings an ihre Grenzen
sto&#223;en. Auch die Ressourcenbewusstheit in verschiedensten Dimensionen (z. B. Daten, Energie) und die Sicherheit
werden als zentrale Herausforderungen ausgemacht. Eine gro&#223;e Chance zur Entwicklung solcher Ans&#228;tze besteht
darin, dass sich bisher nicht zwingend inter- bzw. transdisziplin&#228;r zusammenarbeitende Wissenschaften in der
KI-Forschung neue Erkenntnisfelder erschlie&#223;en. KI-Methoden k&#246;nnen disziplin&#252;bergreifend zu umfassendem
Erkenntnisgewinn beitragen, was wiederum die Entwicklung neuartiger KI-Methoden als Reaktion auf die
Fragestellungen dieser Felder inspiriert. 
Au&#223;erdem sollte die Vernetzung und enge Kooperation mit Forschungszentren in Europa weiter ausgebaut
werden, um solche St&#228;rken zu skalieren und gemeinsame KI-Forschung aus Europa an die Weltspitze zu bringen.
Die Fokussierung auf eine menschenzentrierte und an gesellschaftlichen Zielsetzungen ausgerichtete KI kann auf
l&#228;ngere Sicht dazu f&#252;hren, dass die KI-Forschung in Deutschland und Europa eine besondere Anziehungskraft
auf Nachwuchs-Wissenschaftlerinnen und -Wissenschaftler aus&#252;bt und sich ein dynamisches und weltweit
f&#252;hrendes Forschungs&#246;kosystem um diese Themen bildet. Dank des hohen ethischen Anspruchs und der Ausbildung
von Schwerpunkten in der deutschen Forschungs- und Entwicklungslandschaft k&#246;nnen deutsche Unternehmen
ihre Position im Massenendkundengesch&#228;ft (z. B. in der Servicerobotik als absehbarem Zukunftsmarkt) wieder
verbessern. Eine hohe Aufmerksamkeit in Bezug auf menschenzentrierte und zukunftsrelevante Kernthemen
(aber auch f&#252;r andere KI-bezogene Technologien) macht es f&#252;r alle Beteiligten leichter, die gesellschaftlichen
Implikationen der Forschungsvorhaben hervorzuheben. 
9.4.4 Welche Risiken bestehen?
Die KI-Forschung l&#228;uft ohne den Ausbau von F&#246;rdermitteln, eine regionale und thematische Schwerpunkt- und 
Profilbildung und die Verbesserung des Transfers zwischen Forschung und Anwendung Gefahr, den Anschluss
zu verlieren und technologische Souver&#228;nit&#228;t einzub&#252;&#223;en. Global f&#252;hrende Technologieunternehmen werben mit
gro&#223;z&#252;giger Finanzierung und der Bereitstellung optimaler Bedingungen f&#252;hrende Forscherinnen und Forscher
an und entwickeln sich zu dynamischen Forschungszentren. Dadurch ist der Anspruch der &#246;ffentlich finanzierten,
den gesellschaftlichen Zielen verschriebenen Forschungslandschaft in Deutschland, inhaltlich-strukturell
federf&#252;hrend zu agieren, zunehmend gef&#228;hrdet.
Die St&#228;rkung von KI-Anwendungsfeldern in der Wirtschaft erfordert die St&#228;rkung der Innovationskraft von
Unternehmen und des Transfers von Forschungsergebnissen, den Zugang zu Daten und die gezielte finanzielle
F&#246;rderung (siehe hierzu Kapitel 5 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220; [Handlungsempfehlungen
und Perspektiven]). Eine rein reaktiv und kurzfristig ausgerichtete Strategie mit dem Ziel, den Anschluss in
bedrohten Anwendungsfeldern nicht zu verlieren, birgt umgekehrt die Gefahr, auf internationaler Forschungsebene
noch weiter zur&#252;ckzufallen. Die Fortsetzung einer solchen Strategie w&#252;rde zur fortgesetzten Abwanderung von
368 Setzt man beispielsweise die Menge der Forschungspublikation im Bereich KI in Relation zum Bruttoinlandsprodukt, so befindet
sich Deutschland im internationalen und europ&#228;ischen Vergleich nur im Mittelfeld.
Nachwuchs-Wissenschaftlerinnen und -Wissenschaftlern und Start-ups f&#252;hren, die bereits heute, wie
beschrieben, als Trend erkennbar ist. KI-Wissenschaftlerinnen und -Wissenschaftler finden zwar in Deutschland im
europ&#228;ischen Vergleich recht gute Arbeitsverh&#228;ltnisse vor, f&#252;r Spitzenkr&#228;fte ist das deutsche Hochschul- und
Wissenschaftssystem aber zu unattraktiv, um gegen die Top-Universit&#228;ten und wirtschaftlichen Akteure aus dem
definierten Referenzumfeld USA zu bestehen. Dies gilt insbesondere f&#252;r die Struktur und H&#246;he der Geh&#228;lter
sowie die M&#246;glichkeiten f&#252;r Wissenschaftlerinnen bzw. Wissenschaftler, Start-ups zu gr&#252;nden oder in bzw.
gemeinsam mit Unternehmen zu forschen.
Zentrale Handlungsempfehlungen f&#252;r den Staat369 
Abgeleitet aus den Leitlinien, den strategischen Zielen sowie deren Einordnungen gem&#228;&#223; der SWOT-Analyse
bieten sich dem Staat zentrale Aufgaben, die nachfolgend in kurzen Stichpunkten zusammengefasst werden:
&#8226; Um an der Gestaltung von KI mitwirken zu k&#246;nnen, muss Deutschland gemeinsam mit anderen
europ&#228;ischen Staaten deutlich mehr Ressourcen in die Forschung zu KI investieren und so die
Technologiesouver&#228;nit&#228;t sichern. Europa ist traditionell gerade in der Forschungsf&#246;rderung stark. Diese St&#228;rke sollte durch
kluge Zusammenarbeit f&#252;r einen Aufbau eines sichtbaren europ&#228;ischen Forschungsstandorts f&#252;r KI genutzt
werden, den gegebenenfalls zun&#228;chst auch einige Staaten gemeinsam mit vorhandenen Initiativen aus der
Wissenschaft wie ELLIS und CLAIRE vorantreiben k&#246;nnen.
&#8226; Der Staat muss die KI-Grundlagenforschung in Algorithmik, Systemen, Hardware und Software ausbauen
und nachhaltig in Universit&#228;ten und Forschungsinstitutionen verankern. Grunds&#228;tzlich sollte &#246;ffentlich
finanzierte Forschung auf Open-Source-Technologien setzen und Trainingsdatens&#228;tze zur
Nachvollziehbarkeit bereitstellen.
&#8226; Der Staat muss sich zentral auf die Schaffung von thematischen Leuchtturm-Initiativen und Institutionen 
als Vorreiterprojekten an Standorten mit hinreichend vorhandenen Strukturen konzentrieren. Durch die
F&#246;rderung von Netzwerken um diese Leuchtturmprojekte entsteht die notwendige Breitenwirkung und
Sichtbarkeit Deutschlands im Bereich der KI-Forschung. Zugleich ist es zentral, die Attraktivit&#228;t der
Forschungsstandorte Deutschland und Europa f&#252;r internationale Forschende und institutionelle Forschungspartner zu
erh&#246;hen.
&#8226; Der Staat sollte eine besondere Profilbildung im Bereich missionsbasierter, an gesellschaftlichen
Zielsetzungen orientierter Forschungscluster (z. B. im Bereich der Umwelttechnologien, der menschenzentrierten
Robotik oder des ethik- und wertorientierten Designs automatisierter Entscheidungsfindung) gew&#228;hrleisten.
Durch eine dynamische Entwicklung von Forschung und Transfer in solchen Zukunftsfeldern kann sich ein
robustes Forschungs&#246;kosystem herausbilden, das internationale Anziehungskraft entwickelt. Eine solche
Ausrichtung tr&#228;gt wesentlich zur St&#228;rkung der hiesigen KI-Forschung im internationalen Vergleich bei. Zur
Identifikation und strategischen Begleitung relevanter missionsbasierter Themen soll die Bundesregierung
einen u. a. mit den f&#252;hrenden deutschen KI-Forscherinnen und -Forschern besetzten nationalen Zukunftsrat
f&#252;r die KI-Forschung einrichten, welcher vor allem die Vernetzung in den Forschungsfeldern vorantreibt, 
um missionsgetriebene Forschung zu erm&#246;glichen.
&#8226; Dom&#228;nengetriebene Sonderforschungszonen370 erweitern diese Infrastruktur und erm&#246;glichen
anwendungsbezogene Forschung. Sie bieten den Forschenden mehr Freiheiten und eine gr&#246;&#223;ere Einflussnahme auf das
&#8222;Endprodukt&#8220;. Sie k&#246;nnen unter &#8222;realen&#8220; Gegebenheiten testen, m&#246;gliche Probleme erkennen und ihre
Projekte anpassen. Der technologische Entwicklungsprozess in solchen &#8222;Living Labs&#8220; orientiert sich dabei an
&#228;u&#223;eren Gegebenheiten, wird regelm&#228;&#223;ig angepasst und mit jenen Gegebenheiten konfrontiert, denen das
fertige Produkt letztlich auch standhalten muss. Solche Testfelder verbessern Technologie nicht nur, sie
erm&#246;glichen auch die schnellere Adaption und verk&#252;rzen das Zeitfenster hin zur Realanwendung und
Marktreife.
369 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 9.5 des Mantelberichts
(&#8222;Zentrale Handlungsempfehlungen f&#252;r den Staat &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen
Mitglieds Dr. Florian Butollo].
370 Sonderforschungszonen (SFZs) sind in Anlehnung an die Bundesautobahn 9 f&#252;r das autonome Fahren aufgebaut. Sie enthalten neben 
der Infrastruktur f&#252;r Forschungsarbeiten und Living Labs zur Kooperation mit der Industrie und Gesellschaft auch Field Labs zur
Erprobung der entwickelten Technologien im Realumfeld. Die SFZs sind au&#223;erdem Experimentierr&#228;ume im rechtlichen Bereich
(Legal Sandboxes), in denen Fragen der Sicherheit und Zertifizierung zuk&#252;nftiger KI-Technologien bearbeitet und gel&#246;st werden.
&#8226; Es ist zentral, die Attraktivit&#228;t des Forschungsstandortes Deutschland f&#252;r internationale Forschende zu
erh&#246;hen. Zudem bieten sie eine Andockm&#246;glichkeit f&#252;r &#8222;kleinere&#8220; Akteure und erm&#246;glichen diesen Teilhabe
an der ben&#246;tigten Infrastruktur. Gleichzeitig m&#252;ssen sie als Rahmen dienen, um neue
Nachwuchsforschergruppen und (Tenure-Track-)Professuren zu etablieren und die Attraktivit&#228;t f&#252;r weltweit f&#252;hrende
Wissenschaftlerinnen und Wissenschaftler zu steigern. Dies sollte zus&#228;tzlich weiter durch
Nachwuchsf&#246;rderprogramme unterst&#252;tzt werden.371 
&#8226; Es wird mehr Diversit&#228;t in der Forschung zu KI gebraucht. Diversit&#228;t sollte gef&#246;rdert und Hochschulen
darin unterst&#252;tzt werden, spezifische Programme zur Motivation von mehr Frauen sowie Menschen mit
unterschiedlichem sozialen Hintergrund zu entwickeln. Dazu k&#246;nnen z. B. Stipendien oder eine besonders
gestaltete Studien- oder Promotionseingangsphase geeignet sein. Damit begegnen wir sowohl dem
Fachkr&#228;ftebedarf als auch der Notwendigkeit, dass bereits bei der Erforschung und Entwicklung von KI
Perspektiven m&#246;glichst vieler verschiedener gesellschaftlicher Gruppen vorkommen sollten.
&#8226; Emerging Fields, also Felder mit hohem Entwicklungs- und Erfolgspotenzial, m&#252;ssen bereits jetzt aufgebaut
und stark gef&#246;rdert werden. Innovative, ungew&#246;hnliche und vielleicht auch riskante Ideen machen die
Wissenschaft der Zukunft aus. Sie zeichnen sich durch exzellente, meist interdisziplin&#228;re Forschung aus, passen
jedoch h&#228;ufig nicht in klassische F&#246;rderprogramme. F&#252;r diese Bereiche muss eine fr&#252;he, flexible und
mittelbis langfristige F&#246;rderung eingerichtet werden, um den n&#246;tigen Raum f&#252;r bahnbrechende Innovation jenseits
kurzlebiger und zu eng gefasster Drittmittelverfahren voranzubringen. Nur so kann schneller auf aktuelle
gesellschaftliche Herausforderungen reagiert werden.
&#8226; Die Zusammenarbeit zwischen Forschung, Wirtschaft und Gesellschaft ist essenziell, um Technologien aus
der Forschung heraus auf den Markt und in die Gesellschaft zu tragen. Klare Regeln sollen die starke
Unabh&#228;ngigkeit der Forschung mit der Vermarktung von Innovationen f&#252;r Unternehmen in Einklang bringen.
Dies ist in Bezug auf die Zusammenarbeit zwischen Forschung und Wirtschaft &#8211; und damit sind spezifisch
auch vor allem die Hightech-Start-ups aus der Wissenschaft gemeint &#8211; essenziell, um Technologien aus der
Forschung heraustragen zu k&#246;nnen. Vor allem muss f&#252;r Forscherinnen und Forscher auch die
Durchl&#228;ssigkeit zwischen universit&#228;rem Umfeld und Wirtschaft gr&#246;&#223;er werden. Zielf&#252;hrend, neben den genannten
Leuchtturm-Initiativen, sind dabei sogenannte Transferlabs (man k&#246;nnte sie als eine Art Graduiertenkolleg
mit besonderem Anwendungsbezug bezeichnen) zur F&#246;rderung von Promovierenden bzw. auch Post-
Doktorandinnen und -Doktoranden, die zwar an Grundlagen forschen, ihre Erkenntnisse aber im Kontext z. B. 
von Firmendaten/-problemstellungen und -technologien gewinnen. Eine Br&#252;cke in die Gesellschaft kann es
sein, die Einbindung von zivilgesellschaftlichen Organisationen in die Forschung zu f&#246;rdern, z. B. &#252;ber agile
und innovative F&#246;rderprogramme. Dadurch k&#246;nnen die Legitimit&#228;t und die gesellschaftliche Akzeptanz von
KI-Forschung gest&#228;rkt werden. 
&#8226; In den Universit&#228;ten und Forschungsinstitutionen sollten, um den Transfer zu erm&#246;glichen, Prozesse
vereinfacht und Sonderregeln f&#252;r die Zusammenarbeit mit Start-ups (Ausgr&#252;ndungen) entwickelt werden. Der
Staat sollte in allen relevanten Transferbereichen Investitionsprogramme und Inkubatoren372 in
angemessener Gr&#246;&#223;enordnung aufbauen und die Vergabegeschwindigkeit an die Entwicklungen anpassen. Daraus
folgt unmittelbar, dass der Staat neue Formen der Start-up-F&#246;rderung f&#252;r KI-spezifische Felder entwickeln
muss.
&#8226; Ein weiteres essenzielles Themenfeld ist die Bildungspolitik. Hier ist der Staat gefordert, umfangreiche
Ma&#223;nahmen schon im schulischen Bereich zu initiieren, die die Bildung im Feld der KI, insbesondere in
den MINT-F&#228;chern, aber auch im Sinne einer dom&#228;nen&#252;bergreifenden, interdisziplin&#228;ren Bildung
bef&#246;rdern, damit auch in der Folge gen&#252;gend junge Menschen die Lehrangebote an den Hochschulen
vollumf&#228;nglich nutzen k&#246;nnen. Nur dann kann mittel- bis langfristig eine hinreichend gro&#223;e Anzahl von KI-
Spezialistinnen und -Spezialisten, die in allen Bereichen ben&#246;tigt werden, an den Hochschulen ausgebildet
werden und sowohl f&#252;r die Forschung als auch f&#252;r die Anwendung in Wirtschaft und Staat zur Verf&#252;gung
stehen.
371 Es sei darauf hingewiesen, dass das Tenure-Track-Programm bereits mit 1 Milliarde Euro bis zum Jahr 2032 den wissenschaftlichen
Nachwuchs f&#246;rdert; dies zielt auf die allgemeine strukturelle F&#246;rderung im Wissenschaftsbereich und betrifft nicht ausschlie&#223;lich KI-
spezifische Forschung, vgl. Bundesministerium f&#252;r Bildung und Forschung: Das Tenure-Track-Programm.
372 (Start-up-)Inkubatoren stellen dem Start-up eine Umgebung bereit, welche die optimalen Bedingungen erf&#252;llt, um erfolgreich in das
Gesch&#228;ftsleben zu starten.
Zukunftsthemen
Die Chance und die Herausforderung f&#252;r die Forschungsf&#246;rderung im Bereich von KI bestehen darin, in den
Bereichen Grundlagenforschung und Anwendungen mittel- bis langfristige Themen zu identifizieren, die von
gro&#223;er strategischer, wirtschaftlicher und gesellschaftlicher Bedeutung sind. Gerade vor dem Hintergrund der
extrem hohen und beobachtbaren Dynamik im Feld der KI-Forschung und des Beitrags, den KI-Anwendungen
zu gesellschaftlichen Zukunftsfragen leisten, bedarf es eines solchen Blicks nach vorn. Allen KI-Anwendungen
&#8211; auch den Zukunftsthemen &#8211; inh&#228;rent ist die dringende Notwendigkeit einer fl&#228;chendeckenden, hocheffizienten
und skalierbaren digitalen Infrastruktur nach dem jeweils aktuellen Stand der Technik.
Eine wichtige Rolle spielen dabei Erkenntnisse, wie sich KI-Methoden systematisch weiterentwickeln und
anpassen lassen, um unter realen Einsatzbedingungen bestehen zu k&#246;nnen. Heute schon identifizierbare
Forschungsfelder wie Cyber-physische Systeme (CPS), &#8222;Physics/Model-informed Machine Learning&#8220;, die als
Br&#252;cke zwischen datengetriebenen und modellbasierten Methoden fungieren, KI-Prozessoren der Zukunft sowie
Anwendungen auf Nano- und Micro-Level sind wichtige Bereiche, auf die die Forschung k&#252;nftig setzen muss.
Ebenso stellt das Zusammenf&#252;hren von Lernen und Wissen eine zentrale Herausforderung dar. Auch die
Zusammenf&#252;hrung von Lernen und Wissen zu hybriden Software- und cyberphysischen Systemen geh&#246;rt zu den
zentralen Herausforderungen der KI. Diese Erkenntnisse tragen z. B. dazu bei, dass die nationalen
Maschinenbauunternehmen und produzierende Technologieplayer weiterhin Weltspitze sind oder dass gro&#223;e bauliche
Infrastrukturvorhaben bef&#246;rdert werden (Stichwort: KI im Bauwesen &#8211; BIM373). Auch die personalisierte Medizin, das
autonome Fahren und die Servicerobotik werden ma&#223;geblich profitieren. 
Eine mutige und vorw&#228;rtsgewandte Forschungsstrategie besteht allerdings auch darin, eine Zukunftsvision zu 
entwickeln, die erst einmal gar nicht die Technik in den Mittelpunkt stellt, sondern Anwendungsfelder mit hohem
Potenzial identifiziert, ohne dabei reine kurz- bis mittelfristige Anwendungsforschung zu forcieren. Dazu
geh&#246;ren der Klimawandel, die Energieversorgung, Verkehr und Logistik, Geb&#228;ude- und Quartiersmanagement,
Meteorologie, Land- und Forstwirtschaft, adaptives urbanes Management (KI-basierte Sensoranalyse von
Luftqualit&#228;tsdaten), E-Demokratie und gesellschaftlicher Diskurs, Bildung und Weiterbildung sowie soziale Inklusion
durch Assistenz- und Kommunikationssysteme. All diese Felder versprechen erhebliches Potenzial f&#252;r Forschung
und Entwicklung.
Auch zuk&#252;nftige Systeme werden voraussichtlich nicht, z. B. in Form einer &#8222;starken KI&#8220;, Probleme von sich aus
l&#246;sen, sondern die Menschen weiterhin dabei unterst&#252;tzen, indem sie in eng umrissenen Bereichen die St&#228;rken
von Computern ausspielen (Massen von Daten durchsuchen, Muster erkennen, Daten aggregieren etc.). Heute
schon gilt dies f&#252;r neue diagnostische Verfahren in der Medizin, bei der Industrieautomatisierung, bei
Kreativprozessen wie in den Bereichen der Unterhaltungsmedien etc. Hohe Priorit&#228;t haben dabei auch Anwendungen
zur Unterst&#252;tzung des Klima- und Umweltschutzes, der Epidemie- und Pandemiebek&#228;mpfung sowie insgesamt
der Verbesserung von Pr&#228;vention und Versorgung im Bereich Gesundheit. 
10 KI und SARS-CoV-2374 
Am 9. Januar 2020 berichtete die Weltgesundheitsorganisation WHO erstmals vom Ausbruch einer
grippe&#228;hnlichen Erkrankung aus dem chinesischen Wuhan. Die US-amerikanischen &#8222;Centers for Disease Control and
Prevention&#8220; (CDC) in Atlanta hatten dies einige Tage zuvor (am 6. Januar 2020) gemeldet. Aber bereits in den
letzten beiden Dezembertagen 2019 hatten der automatisierte HealthMap Service am Bostoner Krankenhaus und
die kanadische Gesundheitsplattform BlueDot vor Viren unbekannter Herkunft gewarnt.375 BlueDot verwendete
dazu einen Algorithmus auf der Basis von K&#252;nstlicher Intelligenz. Das Tool wertete fremdsprachige Nachrichten,
wissenschaftliche Netzwerke f&#252;r Tier- und Pflanzenkrankheiten und Meldungen offizieller Stellen aus. Anhand
dieser Quellen wurde die Empfehlung abgeleitet, Wuhan weitr&#228;umig zu meiden &#8211; zu einem Zeitpunkt, als noch
keine Quarant&#228;ne bekannt war. Auch andere Datenquellen erwiesen sich als &#228;u&#223;erst hilfreich, etwa der Zugriff
373 BIM: Abk&#252;rzung f&#252;r Building Information Modeling, das im Bauwesen zunehmend mit KI arbeitet, weitere Informationen dazu 
unter: https://www.kimeetsbim.org (zuletzt abgerufen am 7. August 2020).
374 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 10 des Mantelberichts (&#8222;KI
und SARS-CoV-2 &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti].
375 Vgl. Frohwitter (2020): How Artificial Intelligence Is Supporting Humanity in the Battle Against Coronavirus; Stellungnahme von 
Prof. Dr. Meyer-Hermann und Dr. Binder (Abteilung f&#252;r System-Immunologie, Helmholtz-Zentrum f&#252;r Infektionsforschung),
Kommissionsdrucksache 19(27)130 vom 6. Oktober 2020.
auf weltweite Ticketdaten von Fluggesellschaften, mit deren Hilfe sich ermitteln l&#228;sst, wohin und wann
Einwohner in n&#228;chster Zeit reisen.376 Dies hat es erm&#246;glicht, eine korrekte Vorhersage &#252;ber die Verbreitung des Corona-
Virus in den ersten Tagen nach dem Auftreten zu treffen.377 Nachdem das Programm alle Daten ausgewertet
hatte, pr&#252;ften Epidemiologen die Schlussfolgerungen auf ihre Wissenschaftlichkeit. Warnungen wurden erst nach
dieser Kombination von k&#252;nstlicher und menschlicher Intelligenz verschickt. &#196;hnliche Ans&#228;tze gab es in der
Vergangenheit bez&#252;glich SARS, Schweinegrippe oder Zika.378 Dieses Beispiel zeigt: KI ist nicht der &#8222;clear-cut
winner in the race&#8220;379, was die Covid-19-Pandemie betrifft, aber es ist zu erwarten, dass KI-gest&#252;tzte Systeme in
der Lage sein werden, ihren Vorsprung bei Vorhersagen durch noch gr&#246;&#223;ere Datens&#228;tze und fortschrittlichere
Technologie auszubauen. 
Auch in vielen anderen Bereichen des Gesundheitswesens spielen KI-Systeme bereits heute eine zentrale Rolle.
Auf der Basis von Daten, die entweder eigenst&#228;ndig von Patienten oder im Rahmen einer Therapie, via Studien
oder zentralen Meldungen erhoben werden, k&#246;nnen von Expertinnen und Experten Gesundheitszust&#228;nde noch
genauer ermittelt, Gef&#228;hrdungen fr&#252;her erkannt und Infektions- sowie Ausbruchsverl&#228;ufe miteinander verglichen
werden. Dies hat das vorrangige Ziel, die Gesundheit und damit das Leben von Menschen zu verbessern und zu
retten.
Die Enquete-Kommission hat sich in einer Projektgruppe bereits 2019 intensiv mit verschiedenen
Anwendungsgebieten von KI in Medizin und Pflege und ihrer Bedeutung f&#252;r die Zukunft des Gesundheitssystems befasst.380 
Sie hat sich entschieden, erg&#228;nzend dazu wissenschaftliche Erkenntnisse aus dem ersten Halbjahr 2020 bez&#252;glich
des Einsatzes von KI im Rahmen der Covid-19-Pandemie zusammenzutragen und die Potenziale von KI-
Systemen zur Bew&#228;ltigung von Pandemien aufzuzeigen sowie Handlungsempfehlungen zu geben.381 Dazu wurden
von folgenden Wissenschaftlerinnen und Wissenschaftlern sowie Institutionen Stellungnahmen eingeholt und
ausgewertet382:
&#8226; Prof. Dr. rer. nat. Dirk Brockmann, Institut f&#252;r Biologie, Epidemiologische Modellierung von
Infektionskrankheiten, Lebenswissenschaftliche Fakult&#228;t der Humboldt-Universit&#228;t zu Berlin
&#8226; Prof. Dr. Alice C. McHardy, Leiterin der Abteilung Bioinformatik der Infektionsforschung, Helmholtz
Zentrum f&#252;r Infektionsforschung, Braunschweig
&#8226; Prof. Dr. Michael Meyer-Hermann und Dr. Sebastian Binder, Abteilung f&#252;r System-Immunologie,
Helmholtz-Zentrum f&#252;r Infektionsforschung, Braunschweig
&#8226; Prof. Dr. Katharina Morik Lehrstuhl f&#252;r K&#252;nstliche Intelligenz, Fakult&#228;t f&#252;r Informatik, Technische
Universit&#228;t Dortmund
&#8226; Prof. Dr. med. Sylvia Thun, Direktorin Core Unit eHealth &amp; Interoperabilit&#228;t (CEI), Berliner Institut f&#252;r
Gesundheitsforschung (BIG)/Berlin Institute of Health (BIH)
&#8226; Bundesministerium f&#252;r Bildung und Forschung, Berlin
&#8226; Bundesministerium f&#252;r Gesundheit, Berlin
&#8226; Plattform Lernende Systeme, Berlin.
376 Weitere Informationen zum Hintergrund des Tools unter: https://bluedot.global/products (zuletzt abgerufen am 18. September 2020).
377 Aus Wuhan nach Bangkok, Seoul, Taipei und Tokyo.
378 Vgl. Niiler (2020): An AI Epidemiologist Sent the First Warnings of the Wuhan Virus.
379 Zitiert nach Frohwitter (2020): How Artificial Intelligence Is Supporting Humanity in the Battle Against Coronavirus.
380 Siehe auch den Bericht der Projektgruppe &#8222;KI und Gesundheit&#8220; in Kapitel C. IV. [K&#252;nstliche Intelligenz und Gesundheit
(Projektgruppe 3)].
381 Das Kapitel fokussiert dabei explizit nur auf medizinische und epidemiologische Fragen und behandelt die gesellschaftlichen
(wirtschaftlichen, kulturellen, famili&#228;ren etc.) Folgen der Pandemie nicht.
382 Vgl. Stellungnahmen der Expertinnen und Experten, Kommissionsdrucksache 19(27)130 vom 6. Oktober 2020.
Potenziale und Anwendungsbeispiele von KI zur Eind&#228;mmung und Beherrschung 
von Pandemien (insbesondere der Covid-19-Pandemie)383 
KI-Anwendungen wird ein hohes Potenzial zur Eind&#228;mmung und Beherrschung von Pandemien, wie der Corona-
Pandemie zuerkannt. 
Beispielhafte Einsatzgebiete von KI bei Pandemien sind384:
&#8226; Ausbruchsvorhersagen
&#8226; Visualisierungen
&#8226; Ansteckungsverfolgung385 
&#8226; Viruserkennung
&#8226; molekularbiologische Untersuchungen und Genomsequenzierung
&#8226; Krankenhausmanagement
&#8226; intelligente Robotik im klinischen Bereich und in der Pflege
&#8226; automatisierte mobile Teststationen f&#252;r die breite Datenakquise
Konkrete Anwendungsbereiche k&#246;nnten beispielsweise sein:
&#8226; Verfeinertes Tracking von Infektionen und Rekonstruktion der viralen Ausbreitung, mittels Kontakt-,
Mobilit&#228;ts- und genomischer Pathogendaten 
&#8226; auf dem Gebiet der Phylogeographie Zusammenfassung von Sequenzdiversit&#228;t (Erreger) mit r&#228;umlichen
Ausbreitungsmodellen und Mobilit&#228;tsnetzwerken (Wirt) und Analyse mit Hilfe von Methoden aus der
KI386
&#8226; Erkennen von neuen, f&#252;r die Eind&#228;mmung relevanten Eigenschaften (z. B. welche Orte, Konstellationen 
und Verhaltensweisen ein hohes Risikopotenzial haben f&#252;r &#220;bertragungen, welche Personen
Risikogruppen angeh&#246;ren) mit Hilfe von Verfahren der Merkmalsselektion und Mustererkennung.
&#8226; Clinical Risk Assessment basierend auf Pathogen- und Patientendaten387 etwa kann auf Basis von Daten
historischer Epidemieverl&#228;ufe (wie etwa SARS 2002/2003) &#8222;gelernt&#8220; werden, wie die globale Ausbreitung 
verl&#228;uft, und so klassische epidemiologische Modelle um evidenzbasierte Erkenntnisse erg&#228;nzt werden.
Dadurch k&#246;nnen weitere Wellen vorhergesagt werden oder kann die Bedarfsplanung von Intensivbetten 
und Krankenhauspersonal besser erfolgen388 
KI kann zudem beim sogenannten Crowd Sensing389 unterst&#252;tzen, das die Erfassung relevanter
Gesundheitsparameter, Kontaktverfolgung auf der Basis des DP-3T-Standards und Kommunikationsm&#246;glichkeiten unter
Wahrung von Privatsph&#228;re und Datenschutz vereint.
Mit Blick auf Covid-19 werden au&#223;erdem folgende Anwendungsbeispiele von KI-Systemen insbesondere im
medizinischen und immunbiologischen Bereich genannt390:
383 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 10.1 des Mantelberichts
(&#8222;Potenziale und Anwendungsbeispiele von KI zur Eind&#228;mmung und Beherrschung von Pandemien (insbesondere der Covid-19-
Pandemie)&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti].
384 Vgl. Stellungnahme von Frau Prof. Dr. Morik (Lehrstuhl f&#252;r K&#252;nstliche Intelligenz, Fakult&#228;t f&#252;r Informatik, Technische Universit&#228;t
Dortmund).
385 Bereits im Eingangsbeispiel wurde der Einsatz von KI in Form von Modellrechnungen zur Verbreitung und Entwicklung der
Infektionslagen skizziert. Hier k&#246;nnen gerade mit Blick auf die Ansteckungsverfolgung Korrelationen aufgezeigt werden, die klassische
Modellierungsverfahren nicht erkennen k&#246;nnen.
386 Ein hervorragendes Beispiel ist die interaktive Visualisierung der Covid-19-Phylogeographie, https://nextstrain.org/ncov/global; 
vgl. Stellungnahme von Prof. Dr. rer. nat. Dirk Brockmann (Institut f&#252;r Biologie, Epidemiologische Modellierung von
Infektionskrankheiten, Lebenswissenschaftliche Fakult&#228;t der Humboldt-Universit&#228;t zu Berlin), Kommissionsdrucksache 19(27)130 vom 6.
Oktober 2020.
387 Ans&#228;tze der ML-basierten personalisierten Infektionsmedizin; KI-basierte Prognosen.
388 Vgl. dazu die Stellungnahme von Frau Prof. Dr. McHardy (Leiterin der Abteilung Bioinformatik der Infektionsforschung, Helmholtz 
Zentrum f&#252;r Infektionsforschung), Kommissionsdrucksache 19(27)130 vom 6. Oktober 2020 und die Beispiele der Plattform
Lernende Systeme.
389 Unter Crowd Sensing versteht man die massenhafte Erhebung von Daten durch aus Smartphones gebildeten Sensornetzen.
390 Vgl. dazu Beispiele und Erl&#228;uterungen von Frau Prof. Dr. Thun (Direktorin Core Unit eHealth &amp; Interoperabilit&#228;t (CEI), Berliner
Institut f&#252;r Gesundheitsforschung (BIG)/Berlin Institute of Health (BIH)), Kommissionsdrucksache 19(27)130 vom 6. Oktober 2020.
&#8226; Bilderkennung der Thoraxaufnahmen
&#8226; Bilderkennung histopathologischer Befunde
&#8226; Aufbereitung von wissenschaftlicher Fachliteratur
&#8226; Diagnose vor PCR-Tests 
&#8226; KI auf gensequenzierten Daten
&#8226; Medikamente identifizieren, die f&#246;rderlich f&#252;r die Heilung sind
&#8226; Flankierende Symptome erkennen
&#8226; Pr&#228;dispositionen erkennen und Behandlungsergebnisse prognostizieren
&#8226; Auswertung der Daten von tragbaren Systemen (wearables)
&#8226; Auswertung der Selbsttriage391 (CovAPP) &#8211; Genauigkeit der Scores verbessern
&#8226; Vorhersage von Proteinstrukturen und Identifizierung von Epitopen392 
&#8226; Automatisierte Labore und KI-unterst&#252;tze robotische Laborassistenten 
So k&#246;nnen etwa Verfahren der Mustererkennung in CT-Bildern bei Covid-19-Pneumonie sowie die KI-gest&#252;tzte
Auswertung qualitativer und quantitativer Parameter zur Verlaufsbeurteilung bei der Einsch&#228;tzung des
Therapieerfolgs unterst&#252;tzen. Zudem kann das individuelle Erkrankungsrisiko unter Heranziehung multipler Parameter
durch KI-Unterst&#252;tzung ermittelt werden. KI kann auch dabei helfen, Medikamente und Impfstoffe vor einem
Test am Menschen zu pr&#252;fen &#8211; etwa auf toxische Reaktionen &#8211; und so die Zulassung beschleunigen und
Probandinnen und Probanden sch&#252;tzen.
In deutschen Kliniken werden bereits Systeme eingesetzt, die im Rahmen der Medizininformatik-Initiative
entwickelt wurden: Zum einen das Fr&#252;hwarnsystem SmICS, mithilfe dessen Infektionen, Verdachtsf&#228;lle und
m&#246;gliche &#220;bertragungswege aufgesp&#252;rt und fr&#252;hzeitig einged&#228;mmt werden k&#246;nnen.393 Zum anderen das System
ASIC, welches in der &#220;berwachung von Intensivpatienten mit akutem Lungenversagen eingesetzt wird.394 
Das RKI nutzt f&#252;r die Kurzzeitprognose und &#8222;Nowcasting&#8220; statistische Datenauswertungen, die auf gemeldete 
Fallzahlen basieren, hier kommen noch computerbasierte Simulationsverfahren zur Anwendung, nicht KI im
engeren Sinne. Das RKI entwickelt aber derzeit spezifische Algorithmen zur Fr&#252;herkennung.395 
Auch im deutschen Netzwerk f&#252;r Bioinformatik-Infrastruktur396 wird aktiv an Anwendungen f&#252;r die Covid-19-
Bek&#228;mpfung geforscht. Hier wird eine Software zur Risiko-Absch&#228;tzung anhand verschiedenster klinischer,
Labor- und Forschungsdaten entwickelt, Rechenkapazit&#228;ten f&#252;r die Corona-Forschung bereitgestellt397 sowie KI-
Methoden etwa im Bereich der Strukturvorhersage von viralen Proteinen und RNA398 eingesetzt, um die Wirk-
und Impfstoff-Entwicklung voranzubringen. 
391 Z. B. Einsatz von Chatbots, um Screenings von Patienten anhand ihrer selbst berichteten Symptome durchzuf&#252;hren.
392 Ein Epitop ist eine Struktur, gegen die im Zuge einer adaptiven Immunantwort Antik&#246;rper oder T-Zell-Rezeptoren gebildet werden.
Genauer sind Epitope umschriebene molekulare Strukturen bzw. Molek&#252;labschnitte eines Antigens, die eine spezifische
Immunantwort ausl&#246;sen k&#246;nnen.
393 SmICS: Abk&#252;rzung f&#252;r &#8222;Smart Infection Control System&#8220;, vgl. Bundesministerium f&#252;r Bildung und Forschung (2020): SmICS:
Smarte Software gegen SARS-CoV-2. Urspr&#252;nglich entwickelt, um bakterielle Erreger aufzusp&#252;ren, wurde es f&#252;r das Coronavirus
SARS-CoV2 angepasst. Es vereint Patienten-, Erreger- und Bewegungsdaten innerhalb einer Klinik und erm&#246;glicht, fr&#252;hzeitig
H&#228;ufungen und Erkrankungswege nachzuvollziehen. Vgl. dazu Stellungnahme des BMBF, Kommissionsdrucksache 19(27)130 vom
6. Oktober 2020.
394 Die ASIC-App konnte bereits als Medizinprodukt zertifiziert werden. Das System &#252;berwacht alle wesentlichen Parameter in der
Intensivbehandlung und kann die behandelnden &#196;rzte bei einer Verschlechterung des Zustandes des Patienten fr&#252;hzeitig alarmieren 
und Therapieempfehlungen anhand medizinischer Leitlinien geben. Sie wurde auf Covid-19 angepasst. Vgl. Dolling (2020): Pr&#228;zise
Diagnostik und Behandlung von akutem Lungenversagens. Vgl. auch Stellungnahme des BMBF, Kommissionsdrucksache 19(27)130 
vom 6. Oktober 2020.
395 Gef&#246;rdert durch das BMBF, vgl. Stellungnahme des BMG, Kommissionsdrucksache 19(27)130 vom 6. Oktober 2020.
396 Weitere Informationen dazu unter: https://www.ptj.de/projektfoerderung/gesundheitsforschung/denbi (zuletzt abgerufen am 18.
September 2020).
397 Nutzung der Kapazit&#228;ten der Hochleistungsrechenzentren wie J&#252;lich Supercomputing Centre.
398 RNA: Abk&#252;rzung f&#252;r Ribonukleins&#228;ure; ist bei bestimmten Virentypen Tr&#228;ger der Erbinformation.
Zudem wird in verschiedenen Einrichtungen an intelligenter Robotik f&#252;r Medizin und Pflege geforscht und
punktuell erprobt, ein gr&#246;&#223;erer Grad an Automatisierung in der Fl&#228;che konnte aber noch nicht realisiert werden.
Konkrete Fallbeispiele zeigt die Plattform Lernende Systeme auf, dazu geh&#246;ren399: 
&#8226; Intelligente Roboter, die pflegende Angeh&#246;rige und Fachkr&#228;fte etwa bei der Reinigung, dem Verteilen von
Essen, beim Desinfizieren oder dem Hin- und Herschieben von Betten oder der Dokumentation entlasten
k&#246;nnen400 
&#8226; Robotik f&#252;r Tests und Labore, die etwa Hochdurchsatzsequenzierung von Covid-19-Proben erm&#246;glichen
w&#252;rden; vorstellbar w&#228;re auch, dass intelligente Roboter Probenentnahmen (Abstriche) selbst vornehmen &#8211;
eine sichere Interaktion im Bereich gef&#228;hrdeter K&#246;rperteile vorausgesetzt401
&#8226; Robotik im klinischen Bereich, also mittels KI-gest&#252;tzter OP-Roboter
&#8226; Robotik in kritischen Bereichen auch au&#223;erhalb des Gesundheitswesens, also etwa bei intelligenten
Feldrobotern f&#252;r die Ernte oder Roboter zur Inspektion kritischer Infrastrukturen z. B. als Fern&#252;berwachung
Neue besonders feinf&#252;hlige kollaborative Roboter k&#246;nnen dar&#252;ber hinaus bereits jetzt eng mit Menschen
zusammenarbeiten. Sie k&#246;nnen auch besonders leicht mittels haptischer Kraftr&#252;ckkopplung und neuer Methoden der
Telepr&#228;senz aus der Ferne gesteuert werden. So k&#246;nnen &#196;rztinnen und &#196;rzte aber auch das Pflegepersonal bei
infekti&#246;sen Patientinnen und Patienten aus der Ferne kontrolliert z. B. Blutdruck und Temperatur messen, aber
auch Ultraschall- oder Stethoskop-Untersuchungen durchf&#252;hren.402 
Notwendige Entwicklungen in der KI sowie strukturelle Verbesserungen, um auf
zuk&#252;nftige Pandemien besser vorbereitet zu sein
In den Stellungnahmen wurden vielf&#228;ltige Verbesserungsm&#246;glichkeiten dargelegt, um auf k&#252;nftige
Infektionswellen oder Pandemien besser vorbereitet zu sein403: 
Daten systematisch erheben und datenschutzkonform zur Verf&#252;gung stellen
Als limitierend w&#228;hrend des derzeitigen Ausbruchsgeschehens haben sich weniger die Methoden in der KI selbst
sondern die begrenzten und unsystematisch erhobenen Daten erwiesen, insbesondere weil Daten international
divergent erhoben werden. Eine konsistente Art der Datenerhebung national und international und die &#246;ffentliche
Verf&#252;gbarkeit derselben ist von zentraler Bedeutung. Dies betrifft einfache Daten zur regionalen Struktur (z. B. 
Bildungseinrichtungen, Arbeitsplatz-Struktur, Mobilit&#228;t, etc.) bis hin zu pseudonymisierten oder aggregierten
Datens&#228;tzen zu individuellen Krankheitsverl&#228;ufen.
In Vorbereitung auf eine m&#246;gliche weitere Infektionswelle oder eine zuk&#252;nftige Pandemie wird geraten,
Meldewege, Datenbanken und deren Struktur, sowie den automatisierten Zugriff auf diese Daten (wegen Skalierbarkeit
f&#252;r eine Epidemie mit hohen Fallzahlen und exponentieller Dynamik) zu optimieren. Neben technischen
L&#246;sungen sind dabei vor allem auch rechtliche und ethische Grenzen in die &#220;berlegungen einzubeziehen, sofern sie
personenbezogene Daten betreffen. 404 
399 Vgl. Stellungnahme der Plattform Lernende Systeme, Kommissionsdrucksache 19(27)130 vom 6. Oktober 2020; weitere
Informationen dazu unter: https://www.plattform-lernende-systeme.de/corona.html (zuletzt abgerufen am 18. September 2020).
400 Siehe z. B. das vom BMBF gef&#246;rderte Projekt PfleKoRo, in dem kooperierende Robotik in der Pflege erforscht wird, etwa f&#252;r die
robotische Unterst&#252;tzung beim Umlagern von Intensivpatientinnen und -patienten. Vgl. Siebert (2019): Robotische Assistenz in der
Pflege.
401 Das Klinikum rechts der Isar in M&#252;nchen hat gemeinsam mit der Munich School of Robotics and Machine Intelligence an der
Technischen Universit&#228;t M&#252;nchen bereits einen funktionierenden Prototyp f&#252;r einen robotergest&#252;tzten Rachenabstrich entwickelt und im 
Fr&#252;hjahr 2020 erfolgreich getestet. Mit wenigen hundert Robotern k&#246;nnen mit diesem Verfahren bis zu 200 000 Rachenabstriche pro
Tag durchgef&#252;hrt werden &#8211; ohne medizinisches Personal einer Infektionsgefahr auszusetzen. In der Murnauer Unfallklinik konnten 
intelligente robotische Systeme so trainiert werden, dass sie binnen kurzer Zeit in der Lage waren, selbst&#228;ndig endoskopische
Instrumente zu reinigen, zu transportieren und zu trocknen.
402 Intelligente robotische Systeme dieser Art werden beispielsweise im Rahmen der Leuchtturm-Initiative Geriatronik in Garmisch-
Partenkirchen zur Entlastung und zum Schutz des medizinischen Personals und zur Erhaltung von Mobilit&#228;t und Unabh&#228;ngigkeit im
Alter entwickelt und getestet; weitere Informationen dazu unter: https://geriatronics.msrm.tum.de/de/startseite (zuletzt abgerufen am
18. September 2020).
403 Vgl. Stellungnahmen der Expertinnen und Experten,  Kommissionsdrucksache 19(27)130 vom 6. Oktober 2020.
404 Vgl. ausf&#252;hrlich die Stellungnahme von Prof. Dr. Meyer-Hermann und Dr. Binder (Abteilung f&#252;r System-Immunologie, Helmholtz-
Zentrum f&#252;r Infektionsforschung), Kommissionsdrucksache 19(27)130 vom 6. Oktober 2020.
Optimierungspotenzial im Rahmen datenschutzrechtlicher M&#246;glichkeiten wird bez&#252;glich der Meldeketten
gesehen. Bem&#228;ngelt wird, dass einerseits viele Daten erhoben und zentral gemeldet w&#252;rden, diese aber nicht immer
zug&#228;nglich oder unvollst&#228;ndig seien, was f&#252;r KI-Auswertungen nicht wirklich tauglich sei, etwa weil wichtige 
Informationen innerhalb der Meldeketten fehlten, wie z. B. Ma&#223;nahmen zur Kontaktbeschr&#228;nkungen in
Einrichtungen wie Schulen, oder Meldeverz&#252;ge vorl&#228;gen, die eine Zuordnung und Bewertung der Auswirkung von
Ma&#223;nahmen oder deren Aufhebung deutlich erschwerten. 
Im Bereich der Erhebung struktureller und demographischer Daten, die zur Auswertung von Infektionsdaten 
mittels KI und mathematischen Modellen entscheidend sein k&#246;nnen, wird zudem geraten, die Arbeit des
Statistischen Bundesamts weiter zu f&#246;rdern.405 
Es wird darauf hingewiesen, dass eine Evaluierung von ML-Verfahren und das Entwickeln von KI-Methoden 
derzeit nur begrenzt m&#246;glich sei, da die notwendigen Daten h&#228;ufig nur punktuell und nicht gekoppelt vorl&#228;gen.
Dank der Meldepflicht l&#228;gen beispielsweise Meldedaten zu allen bisher detektierten SARS-CoV2 Infektionen
vor, angesichts einer fehlenden Proben-Einsendepflicht h&#228;tten allerdings die dazugeh&#246;rigen molekularen Daten
trotz technischer M&#246;glichkeiten und hoher Fallzahlen in Deutschland nur f&#252;r sehr wenige F&#228;lle erzeugt werden
k&#246;nnen.406 Eine systematische Datenerhebung scheiterte bislang an datenschutzrechtlichen H&#252;rden, aber auch an
organisatorischen und systemischen Hemmnissen. 
Empfohlen wird der Aufbau einer genombasierten &#8222;Pathogen-Surveillance-Infrastruktur&#8220;. Bei Vorliegen eines
positiven Tests in einem diagnostischen Labor k&#246;nnte das Einsenden oder direkt das Sequenzieren von
Genomdaten f&#252;r meldepflichtige Krankheitserreger (Pathogene) verpflichtend sein und/oder entsprechend verg&#252;tet
werden. Pathogen-Genomdaten k&#246;nnten so routinem&#228;&#223;ig generiert und zusammen mit den Meldedaten an das RKI
&#252;bermittelt werden sowie zeitnah pseudonymisiert oder in aggregierter Form f&#252;r die Forschung ver&#246;ffentlicht
werden, idealerweise auch zusammen mit anderen Datentypen, wie Mobilit&#228;ts-, Kontakt- und klinischen
Daten.407 In Deutschland stehen hierf&#252;r mit der NFDI-Initiative408 bereits geeignete Datenspeicherungs-
Infrastrukturen oder Datenbanken409 bereit.
Synthetische Daten generieren
Auch hinsichtlich der Fr&#252;herkennung von Hotspots k&#246;nnte KI theoretisch noch gezielter eingesetzt werden. Das
w&#252;rde jedoch umfassende Informationen voraussetzen, etwa der Bewegungsdaten von B&#252;rgerinnen und B&#252;rgern, 
die in Deutschland nicht zur Verf&#252;gung stehen. Einerseits ist eine dichte und qualitativ hochwertige
Informationslage ein entscheidender Faktor zur Eingrenzung von Ausbr&#252;chen, andererseits ist diese Voraussetzung nur
durch Einschr&#228;nkung der individuellen Privatsph&#228;re realisierbar. 
Es ist eine zentrale gesellschaftliche und politische Abw&#228;gung, ob und inwieweit diese Voraussetzungen im Fall
von Pandemien in Deutschland und Europa geschaffen werden sollen, denn nicht alle Ma&#223;nahmen mit KI
erweisen sich als hilfreich.
Gerade weil bestimmte Daten aus gesetzlichen oder gesellschaftlichen Gr&#252;nden in Europa nicht erhoben werden,
wird angeregt, st&#228;rker zu erforschen, ob und wie im Rahmen der Pandemiebek&#228;mpfung mit weniger
verhaltensbasierten und personalisierten Daten gute Verfahren und Ergebnisse m&#246;glich w&#228;ren, hierbei wird auch auf die
st&#228;rkere Erzeugung synthetischer Daten verwiesen.
405 Vgl. dazu die Stellungnahme von Prof. Dr. Meyer-Hermann und Dr. Binder (Abteilung f&#252;r System-Immunologie, Helmholtz-
Zentrum f&#252;r Infektionsforschung), Kommissionsdrucksache 19(27)130 vom 6. Oktober 2020.
406 Detailliert dazu die Stellungnahme von Prof. Dr. McHardy (Leiterin der Abteilung Bioinformatik der Infektionsforschung, Helmholtz 
Zentrum f&#252;r Infektionsforschung), Kommissionsdrucksache 19(27)130 vom 6. Oktober 2020: Als forschungsrelevante Daten werden 
nicht nur die bereits erw&#228;hnten allgemeinen Daten der Betroffenen, wie z. B. Mobilit&#228;ts-, Kontakt-, und Meldedaten von Personen,
angesehen, sondern auch die molekularbiologischen Daten des Pathogens ebenso wie dessen Genomsequenz, das komplette
Mikrobiom bzw. Virom der entnommenen Probe und molekularbiologische Daten der Patientin bzw. des Patienten zusammen mit den
zugeh&#246;rigen klinischen Daten. 201 Virengenome aus Deutschland sind momentan in der GISAID Datenbank verf&#252;gbar, entsprechend 
0,1 Prozent der SARS-CoV2 positiven F&#228;lle (Stand Mai 2020). Die Pathogenproben der anderen 99,9 Prozent der Infektionen sind
vermutlich gr&#246;&#223;tenteils nicht mehr vorhanden und somit f&#252;r Analysen und einen Erkenntnisgewinn im Kampf gegen Covid-19
verloren gegangen.
407 Hierbei w&#228;ren aber datenschutzrechtliche Voraussetzungen zu pr&#252;fen.
408 Weitere Informationen zur Nationalen Forschungsdateninfrastruktur unter: https://www.dfg.de/foerderung/programme/nfdi/ und 
https://www.covid19dataportal.org/ (zuletzt abgerufen am 18. September 2020).
409 &#8222;The German Human Genome-Phenome Archive.&#8221; Weitere Informationen dazu unter: https://ghga.dkfz.de/ (zuletzt abgerufen am
18. September 2020).
Aktuelle KI-Modelle ben&#246;tigen nicht nur Daten, sondern auch eine enorme Rechenkapazit&#228;t und spezialisierte
Software und Hardware, insbesondere wenn sie f&#252;r die gesamte Bev&#246;lkerung mitsamt ihrer Diversit&#228;t berechnen
w&#252;rden. Momentan tun sie das h&#228;ufig nur f&#252;r relativ homogene Anwendergruppen, was nur begrenzte
R&#252;ckschl&#252;sse f&#252;r andere Gruppen erm&#246;glicht. Eine Verbesserung bez&#252;glich Kapazit&#228;ten k&#246;nnten
Modellkompressionen erbringen.
Digitalisierung des Gesundheitssektors vorantreiben
Die Digitalisierung und Standardisierung von Patientendaten sind nicht ausreichend fortgeschritten, um KI-
Systeme f&#252;r unterschiedliche Ma&#223;nahmen in Krankenh&#228;usern zur Kontrolle der Pandemie, zur Bewertung der
Auswirkung auf das Infektionsgeschehen und f&#252;r die Fr&#252;herkennung von Gefahren sowie f&#252;r die Identifikation von
Schwachpunkten in der Sicherheit einzusetzen.
Notwendig w&#228;re zudem die St&#228;rkung der lokalen Infrastruktur, insbesondere bei den lokalen
Gesundheitsbeh&#246;rden und eine Vereinheitlichung, Zentralisierung und Ausweitung der Meldewege, um Daten rasch verf&#252;gbar zu
machen. Zudem w&#228;ren Dokumentation und Meldung in direkt maschinenlesbarer Form hilfreich.410 Durch eine
verbesserte Dateninfrastruktur, etwa durch zentralisiertes und elektronisches Meldesystem am RKI, k&#246;nnten 
mehr Daten zum Training und Verifikation von Algorithmen zur Verf&#252;gung stehen.411 
Mehr (finanzielle) Unterst&#252;tzung sollte es kurzfristig f&#252;r sog. &#8222;Data Stewards&#8220; geben, welche die Daten kurieren
und in entsprechende Dateninfrastruktur einpflegen.412 
Erwogen wird zudem die Einrichtung eines Zentrums f&#252;r KI in der Public Health-Forschung, das mit dem RKI
assoziiert sein sollte.413 
Interoperabilit&#228;t international sicherstellen
Eine Auswertung &#252;ber die verschiedenen Gesundheitsversorger hinweg (Kliniken, Fach&#228;rzte) als Erg&#228;nzung
bzw. Erweiterung der Erkennung von Signalen zur Fr&#252;hwarnung aus den Meldedaten k&#246;nnte dazu beitragen, neu
aufkommende Erkrankungscluster zu erkennen. Die Auswertung von Registerdaten sowie strukturierter Daten
aus elektronischen Krankenakten k&#246;nnte dazu beitragen, Risikofaktoren zu erkennen und verschiedene
Behandlungsmethoden zu vergleichen. F&#252;r diese Analysen ist es aber unerl&#228;sslich, eine standardisierte und international
lesbare Dokumentation in den Kliniken vorzuhalten. Dies kann z. B. durch die bundesweite Einf&#252;hrung der
internationalen SNOMED-CT-Nomenklatur vorangebracht werden.414 
St&#228;rkung nationaler Produktion und Versorgung
Globale Abh&#228;ngigkeiten wurden in der Pandemie vor allem durch den Mangel an Schutzkleidung und
Medikamenten sichtbar, der trotz gro&#223;er Anstrengungen und hoher Kosten nicht vollst&#228;ndig ausgeglichen werden konnte.
Langfristig braucht es deshalb L&#246;sungen, die lokale, wirtschaftliche, unabh&#228;ngige und vor allem krisensichere
Produktionen vor Ort erm&#246;glichen &#8211; auch &#252;ber den Bereich der medizinischen Versorgung hinaus. Deutschland
hat hier gro&#223;es Potenzial im Bereich automatisierter Produktions- und Logistiksysteme (z. B. intelligente
Roboter, Fahrzeuge und andere autonome Systeme). Die Rahmenbedingungen f&#252;r lokale Produzierende m&#252;ssen
schnellstm&#246;glich angepasst und verbessert und Investitionen in neue intelligente Produktionssysteme erh&#246;ht
werden (z. B. durch gezielte F&#246;rderprojekte), um langfristig Unabh&#228;ngigkeit in diesem Bereich zu erreichen und so
eine sichere Versorgung der Bev&#246;lkerung gew&#228;hrleisten zu k&#246;nnen. Der Zukunftsrat der Bayerischen Wirtschaft
410 Vgl. einzelne Hinweise bez&#252;glich Interoperabilit&#228;t, FAIRe Daten, keine Daten via Fax oder als PDF zu versenden, Datenschnittstellen
aus Labor und Arztsystem an Gesundheitsamt via FHIR-Schnittstelle zu realisieren.
411 Seit einigen Jahren wird DEMIS &#8722; Deutsches Elektronisches Melde- und Informationssystem f&#252;r den Infektionsschutz, entwickelt;
vgl. Robert Koch Institut (2020): DEMIS &#8722; Deutsches Elektronisches Melde- und Informationssystem f&#252;r den Infektionsschutz. 
412 Beim Data Steward handelt es sich um eine Person innerhalb eines Unternehmens oder einer Institution, die f&#252;r die Qualit&#228;t der Daten
und Datenquellen verantwortlich ist. Im Rahmen der Data Stewardship k&#252;mmert sie sich um die fachliche Umsetzung der
strategischen Vorgaben der Data Governance zur Datenqualit&#228;t. Zusammen mit dem Data Owner (Dateneigner) &#252;bernimmt der Data Steward
eine wichtige Schl&#252;sselposition in der Umsetzung der Data Governance.
413 Wird nach Auskunft des BMG im Rahmen des Strukturst&#228;rkungsgesetzes gepr&#252;ft.
414 Auf die Interoperabilit&#228;t von Datenquellen und Formaten wird an mehreren Stellen ausdr&#252;cklich hingewiesen (FHIR, SNOMED,
LOINC). Und auch bez&#252;glich der F&#246;rderung von Forschungsprojekten wird auf die Einhaltung internationaler Standards des Joint-
InitiativeCouncil und Global Alliance for Genomics and Health (GA4GH) gedr&#228;ngt. Das BMBF hat in einer Testphase SNOMED
CTLizenzen f&#252;r Beteiligte und Kooperationspartner der Medizininformatik-Initiative &#8211; und somit f&#252;r alle deutschen
Universit&#228;tskliniken &#8211; erworben. Diese werden bereits im Rahmen des deutschlandweit vereinbarten standardisierten Datensatzes zu Covid-19 
(gecco) eingesetzt; weitere Informationen dazu unter: http://www.snomed.org/ (zuletzt abgerufen am 18. September 2020).
hat diese Thematik in einem umfangreichen Ma&#223;nahmenkatalog zur Steigerung der Resilienz von Wirtschaft und 
Gesellschaft aufgegriffen.415 
Chance in der Krise f&#252;r st&#228;rkere Translation und h&#246;here Akzeptanz von KI416 
Die KI-Einf&#252;hrung im Gesundheitswesen ist ein tiefgreifender Innovationsprozess. In der derzeitigen Krise liegt
aber eine Chance f&#252;r den st&#228;rkeren Transfer von KI-Anwendungen in die Versorgung und f&#252;r eine Steigerung
der Akzeptanz in der Bev&#246;lkerung, darin waren sich die befragten Expertinnen und Experten einig.
Voraussetzung daf&#252;r ist, dass sich die Politik entscheidet, die daf&#252;r ben&#246;tigten Rahmenbedingungen zu forcieren und
relevante Akteure, wie etwa Arbeitnehmervertretungen, Patientenverb&#228;nde und Ethikgremien in den Prozess
einzubeziehen.
Akzeptanz weiter f&#246;rdern
So wichtig die Diskussion um Datenschutz, IT-Sicherheit und Interoperabilit&#228;t auch ist, sie darf nicht den Blick
auf die vielen weiteren relevanten Fragen verstellen. So zeigt etwa die Debatte um die Corona-Warn-App, dass
neben einem geeigneten Technologiemanagement insbesondere der wahrgenommene Nutzen, die ad&#228;quate
Zielgruppe, die sozialen Normen und die Bedienungsfreundlichkeit wesentliche Erfolgsfaktoren sind.417 
Es zeigte sich in den vergangenen Monaten, dass mit zielgerichteter Kommunikation eine hohe
Teilnehmerbereitschaft erreicht werden kann, beispielsweise hat die Datenspende-App des RKI, die Daten von Fitnesstrackern 
auf freiwilliger Basis sammelt, bereits in sehr fr&#252;hen Stadien viel Unterst&#252;tzung erfahren. Entscheidend f&#252;r die
Akzeptanz sind eine fr&#252;hzeitige Einbeziehung von Datenschutzinteressen und die transparente Kommunikation 
der Notwendigkeit von Datenerhebungen. In diesem Zusammenhang sollte auch auf die Funktionsweise der
eingesetzten digitalen Hilfsmittel hingewiesen werden. Insbesondere auf die Notwendigkeit st&#228;ndiger Updates und 
Verbesserungen in iterativen Prozessen.
Entscheidend ist zudem, dass Apps als Schnittstelle verstanden und in andere funktionierende Infrastrukturen
eingebunden werden. Wenn beispielsweise eine App einen Verdacht anzeigt, m&#252;ssen schnelle, zuverl&#228;ssige
Testm&#246;glichkeiten zur Verf&#252;gung stehen. Ist dies nicht der Fall, so w&#252;rde eine Corona-App f&#252;r mehr Verunsicherung
als Sicherheit sorgen.
Pandemiebezogene Anpassungen zur besseren Anwendung von KI
Es sollte ein digitales Zentralregister f&#252;r Infektionskrankheiten eingerichtet werden, das tagesaktuelle Fallzahlen
und wichtige anonymisierte oder aggregierte Informationen aus Kliniken, niedergelassenen Praxen und
Gesundheits&#228;mtern (wie etwa Zeitdauer zwischen Infizierung und ersten Symptomen, Zeitdauer nach Abklingen der
Symptome) kombiniert. Damit st&#252;nde eine verl&#228;ssliche Datenbasis f&#252;r KI-Modelle und die Epidemiologie bereit.
Organisatorisch wird zudem empfohlen, Datenwissenschaftlerinnen und -wissenschaftlern, zum Beispiel aus der
&#8222;Deutschen COVID19 OMICS Initiative&#8220;, st&#228;rker in die Entwicklung von Pandemie- und F&#246;rderma&#223;nahmen
inkl. Mittelverteilung einzubeziehen.
In Anbetracht der konstanten Gefahr, dass in einer globalisierten Gesellschaft jederzeit Pandemien auftreten
k&#246;nnen, erscheint es sinnvoll, zur Wahrung des Vorsorgeprinzips eine Datenbasis auch bzgl. gew&#246;hnlicher
Erk&#228;ltungskrankheiten oder der saisonalen Grippe zu erheben und mittels KI auszuwerten. So lie&#223;en sich bereits auf
Basis dieser Erkrankungen viele allgemeine Daten beispielsweise &#252;ber die Rolle verschiedener
Kontaktnetzwerke des &#246;ffentlichen Lebens f&#252;r die Verbreitung von Erkrankungen in Abh&#228;ngigkeit von epidemiologischen 
und biologischen Eigenschaften ihres Erregers erheben, die dann im Falle einer Pandemie die Datenbasis der
Infektion erg&#228;nzen k&#246;nnten.
415 Diese Ma&#223;nahmen setzen auf neue Technologien und sind auch f&#252;r Gesamtdeutschland von hoher Relevanz; vgl. Vereinigung der
Bayerischen Wirtschaft (2020): Resilienz.
416 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 10.3 des Mantelberichts
(&#8222;Chance in der Krise f&#252;r st&#228;rkere Translation und h&#246;here Akzeptanz von KI &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti
sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo].
417 Vgl. Policy Brief des Sachverst&#228;ndigenrats f&#252;r Verbraucherfragen, Kommissionsmaterialie 19(27)27 vom 10. Juni 2020.
Fazit418 
Die Corona-Pandemie hat aufgezeigt, wie KI konkret helfen kann, um zu einer L&#246;sung akuter gesellschaftlicher
Problemlagen beizutragen. Die Grundvoraussetzung f&#252;r ihre Nutzung ist die datenschutzkonforme Verf&#252;gbarkeit
von Daten aus verschiedenen Sektoren. Klar ist aber auch, dass der europ&#228;ische Weg bei der Nutzung von KI zur
Pandemiebek&#228;mpfung und -vorbeugung nicht dem autorit&#228;ren Weg anderer Staaten gleichen kann, der tief in die
Privatsph&#228;re und individuelle Freiheit der Menschen eingreift. 
Es m&#252;ssen Konzepte entwickelt werden, wie mit den personenbezogenen, hochaufgel&#246;sten Daten verantwortlich 
umgegangen werden kann (verwalten, speichern etc.), damit sie unter h&#246;chsten Sicherheitsanspr&#252;chen gesch&#252;tzt
sind, aber gleichzeitig die wissenschaftliche Auswertung gew&#228;hrleistet ist. Zudem sollten verst&#228;rkt Vorschl&#228;ge
f&#252;r die Arbeit mit synthetischen Daten und mit Modellkompressionen einbezogen werden. Hierzu werden an
anderer Stelle des Berichts bereits Vorschl&#228;ge dargelegt, etwa bez&#252;glich Datentreuh&#228;nder oder Prozesse der
Anonymisierung und De-Anonymisierung.419 
Dar&#252;ber hinaus sind eine ausreichende digitale Infrastruktur und KI-Expertise im Gesundheitssektor
entscheidend, um KI kurzfristige f&#252;r neue Problemlagen nutzen zu k&#246;nnen. Apps k&#246;nnen helfen, Transparenz und
Akzeptanz f&#252;r KI-L&#246;sung zu schaffen, wenn sie freiwillig und nutzerfreundlich ausgestaltet sind. 
Ein einheitliches Vorgehen in ganz Europa, das den Gesamtschaden f&#252;r Gesundheit und Wirtschaft minimiert, 
st&#252;nde nicht im Widerspruch zu regional unterschiedlichen Ma&#223;nahmen, w&#252;rde aber eine gemeinsame
europ&#228;ischen Strategie zur Bek&#228;mpfung von Pandemien erm&#246;glichen.
W&#228;hrend der deutschen EU-Ratspr&#228;sidentschaft sollte sich Deutschland daf&#252;r einsetzen, dass ein europ&#228;ischer
Gesundheitsdatenraum geschaffen wird, der einen sicheren, schnellen und datenschutzkonformen Austausch von
Daten erm&#246;glicht.
Deutschland sollte zum starken Treiber f&#252;r gemeinsame europ&#228;ische Investitionen in die Voraussetzungen f&#252;r KI
im Gesundheitswesen werden, um die dargestellten Verbesserungen zur Nutzung von KI in einer Pandemie
schnell zu erreichen.
Nicht zu vernachl&#228;ssigen ist die Rolle der Medien und der Gefahr von Desinformation in einer Pandemie. Es
muss geregelt sein, unter welchen Umst&#228;nden und mit welchen Kontrollmechanismen Betreiber von
Intermedi&#228;ren Einfluss auf die Sortierung und Anzeige von Inhalten nehmen d&#252;rfen. Im Bericht der Projektgruppe &#8222;KI und
Medien&#8220; wird ausf&#252;hrlich erl&#228;utert, welche Regulierungsma&#223;nahmen die Enquete-Kommission empfiehlt, um
der algorithmisch getriebenen Verbreitung von Desinformation zu begegnen und auch, welche Qualit&#228;t
Inhaltefilter-Systeme haben und warum sie zur Erkennung von sensiblen Inhalten nicht geeignet sind.420 
II. K&#252;nstliche Intelligenz und Wirtschaft (Projektgruppe 1)
1 Kurzfassung des Projektgruppenberichts421 
KI ist eine Schl&#252;sseltechnologie, welche die Wirtschaft in Deutschland und in Europa vor gro&#223;e Ver&#228;nderungen
stellt. Das Thema entwickelt sich international in einem rasanten Tempo und erfordert auch hierzulande mehr
Dynamik und Geschwindigkeit: Wenn wir Zukunft gestalten wollen, dann m&#252;ssen sich Politik, Wissenschaft, 
Wirtschaft und Zivilgesellschaft noch st&#228;rker mit KI besch&#228;ftigen und sich &#252;ber ein schnelles, strategisches
Vorgehen verst&#228;ndigen. Leitziele sind, dass KI das Leben der Menschen verbessert, den gesellschaftlichen
Zusammenhalt st&#228;rkt sowie Teilhabe f&#246;rdert.
418 Zu diesem Kapitel liegen Sondervoten aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 10.4 des Mantelberichts (&#8222;Fazit&#8220; 
zu &#8222;KI und SARS-CoV-2 &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti und Sondervotum zu Kapitel 10.4 des Mantelberichts
(&#8222;Fazit&#8220; zu &#8222;KI und SARS-CoV-2 &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds
Dr. Florian Butollo].
419 Siehe auch Kapitel 2 des Mantelberichts [KI und Daten] und den Bericht der Projektgruppe &#8222;KI und Gesundheit&#8220; in Kapitel C. IV.
[K&#252;nstliche Intelligenz und Gesundheit (Projektgruppe 3)].
420 Siehe auch den Bericht der Projektgruppe &#8222;KI und Medien&#8220; in Kapitel C. VII. [K&#252;nstliche Intelligenz und Medien (Projektgruppe 6)].
421 Zu diesem Kapitel liegen Sondervoten aus der Fraktion der FDP [Sondervotum zu den Kapiteln 1 und 3.1 des Berichts der
Projektgruppe 1 &#8222;KI und Wirtschaft&#8220; (&#8222; Kurzfassung des Projektgruppenberichts &#8220; und &#8222;Grundlagen und Sachstandskl&#228;rung: KI hat gro&#223;es
Potenzial, ist aber kein Selbstl&#228;ufer &#8220;) der Abgeordneten Mario Brandenburg, Carl-Julius Cronenberg und Daniela Kluckert sowie
der sachverst&#228;ndigen Mitglieder Dr. Aljoscha Burchardt und Andrea Martin] sowie aus der Fraktion DIE LINKE. [Sondervotum zu
Kapitel 1 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220; (&#8222;Kurzfassung des Projektgruppenberichts &#8220;) der Abgeordneten
Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo] vor.
Die Projektgruppe &#8222;KI und Wirtschaft&#8220;422 stellt fest, dass Deutschland eine KI-Strategie hat, die eine
Orientierung f&#252;r die KI-Entwicklung in den n&#228;chsten Jahren gibt, und &#252;ber eine herausragende KI-Grundlagenforschung
verf&#252;gt, auf die erfolgreiche KI-Anwendungen aufbauen k&#246;nnen. Weiterhin gibt es diverse Plattformen und
Gremien, die sich interdisziplin&#228;r und teilweise branchen&#252;bergreifend &#252;ber Leitlinien, Standards und Aufgaben
verst&#228;ndigen. Auch treiben viele kleine und gro&#223;e Unternehmen KI-Innovationen durch eigene Investitionen voran;
KI ist jedoch in der Wirtschaft noch nicht in der Breite angekommen. Die Herausforderung f&#252;r die deutsche
Politik und Wirtschaft sieht die Projektgruppe in der agilen Umsetzung der Ma&#223;nahmen.
Aus Sicht der Mehrheit der Projektgruppe423 ist es notwendig, noch gezielter und mit starker staatlicher
Finanzkraft KI-F&#246;rderung zu betreiben &#8211; insbesondere mit Blick auf Start-ups, anwendungsnahe Forschung und
wissenschaftliche Expertise, Transfer in den Mittelstand sowie auf eine leistungsf&#228;hige KI-Infrastruktur. Dies k&#246;nnte
gerade den KMU gr&#246;&#223;ere Handlungsspielr&#228;ume er&#246;ffnen und mehr Mut f&#252;r h&#246;here Eigeninvestitionen im KI-
Bereich geben. Zudem wird angeraten, nach einem eigenst&#228;ndigen, europ&#228;ischen Weg zu suchen, um eine
nachhaltige424 KI in Deutschland und Europa zu etablieren, die sich gegen&#252;ber den gro&#223;en KI-Nationen &#8211; USA und 
China &#8211; behaupten kann. Gefordert werden: &#214;kosysteme, die Start-ups vorantreiben; &#8222;Sandboxes&#8220; (Sandk&#228;sten),
in denen Ideen schnell ausprobiert werden k&#246;nnen; Moonshot-Projekte, die Ambitionen verwirklichen;
Datenr&#228;ume, in denen Unternehmen viele qualitativ hochwertige Daten f&#252;r die KI-Entwicklung nutzen k&#246;nnen &#8211; um 
nur einige der &#220;berlegungen zu nennen, die in der Projektgruppe diskutiert wurden.
Anerkannt wird, dass die im Forschungs- und Wirtschaftsbereich geplanten Ma&#223;nahmen der deutschen KI-
Strategie vielschichtiger sind als die vieler anderer L&#228;nder und dass die geplanten finanziellen Aufwendungen
Deutschlands die Investitionen anderer europ&#228;ischer L&#228;nder, wie etwa Frankreichs oder Gro&#223;britanniens,
&#252;bertreffen.425 Im au&#223;ereurop&#228;ischen Vergleich zeigt sich indes, dass Deutschland mit der durch die KI-Strategie
vorgesehenen F&#246;rderung in H&#246;he von 3 Milliarden Euro bis 2025 vergleichsweise wenig Budget zur Verf&#252;gung
stellt.426 Was die Durchsetzungskraft von KI in der Wirtschaft anbelangt, so ist es nach Meinung der
Projektgruppe nicht nur eine Frage des Geldes, sondern vor allem auch des Bewusstseins &#8211; auf Anbieterseite wie auf
Anwenderseite. Ein gutes Design wird als Voraussetzung f&#252;r eine funktionierende KI-Technologie gesehen; es
wird nicht nur auf technologische L&#246;sungen gesetzt, sondern auf einen gesellschaftlichen Dialog und auf
Vertrauen.
Die Projektgruppe ist sich dar&#252;ber einig, dass kaum eine andere Technologie f&#252;r wirtschaftliche Disruption und
Modernisierung unserer Gesellschaft in den n&#228;chsten Jahren ein solches Potenzial bietet wie KI. Aber es gibt
gleichzeitig kaum eine Technologie, die derart grundlegende Fragen aufwirft, was u. a. ethische Vorstellungen,
Energieeffizienz oder rechtliche Prinzipien betrifft. Der Umgang mit KI erfordert einen klaren Kompass. Dazu
m&#246;chte diese Projektgruppe durch ihre Analysen und Handlungsempfehlungen einen Beitrag leisten.
In die Diskussion der Projektgruppe flossen zwei Narrative mit ein: W&#228;hrend einerseits das Thema KI
chancenorientiert mit Hinblick auf Produktivit&#228;t, Wertsch&#246;pfung, Nachhaltigkeit betrachtet und mit einem besseren
Leben verbunden wird, wird andererseits auf bedenkliche Entwicklungen durch Digitalisierung in der Gegenwart
hingewiesen, die durch den Einsatz von KI noch weiter verst&#228;rkt werden k&#246;nnten, etwa in den Bereichen soziale
Gerechtigkeit, Arbeitsmarkt und Teilhabe. Dissens herrschte dar&#252;ber, ob KI-Systeme als &#8222;leere H&#252;lle&#8220; gesehen
werden k&#246;nnen. Beide Positionen lassen sich mit Studien und Erhebungen belegen, eine allgemein anerkannte
Datenbasis mit verl&#228;sslichen Prognosen etwa hinsichtlich des Produktivit&#228;tswachstums oder mit einer klaren
422 Die vollst&#228;ndige Bezeichnung lautet: Projektgruppe 1 &#8211; KI und Wirtschaft (Industrie/Produktion, Finanzen, Dienstleistungen,
Innovationen).
423 Eine Minderheit der Projektgruppe vertritt die Meinung, dass nicht KI als solche f&#246;rderw&#252;rdig ist, sondern nur die Entwicklung und
der Einsatz gemeinwohlf&#246;rderlicher KI.
424 Unter Ber&#252;cksichtigung der &#246;konomischen, &#246;kologischen und sozialen Dimension.
425 Siehe dazu den vergleichenden &#220;berblick der Konrad-Adenauer-Stiftung &#252;ber die KI-Strategien wichtiger Volkswirtschaften
(Teil 1&#8211;3): Konrad-Adenauer-Stiftung (2018): Vergleich nationaler Strategien zur F&#246;rderung von K&#252;nstlicher Intelligenz &#8211; Teil 1; 
Konrad-Adenauer-Stiftung (2019): Bewertung der deutschen KI-Strategie &#8211; Teil 3; Konrad-Adenauer-Stiftung (2019): Vergleich
nationaler Strategien zur F&#246;rderung von K&#252;nstlicher Intelligenz &#8211; Teil 2. Es wurden zw&#246;lf L&#228;nder (USA, China, Gro&#223;britannien,
Frankreich, Finnland, S&#252;dkorea, Kanada, Israel, Japan, Vereinigte Arabische Emirate, Singapur und Indien) entlang von Indikatoren
bewertet, die im Zusammenhang mit den Voraussetzungen eines Landes, der Forschung und Entwicklung sowie der
Kommerzialisierung von KI stehen, und mit Deutschland verglichen.
426 Im Konjunkturprogramm im Rahmen der Corona-Pandemie wurde diese Summe auf 5 Milliarden Euro bis 2025 erh&#246;ht; weitere
Informationen dazu unter: https://www.bundesfinanzministerium.de/Content/DE/Standardartikel/Themen/Schlaglichter/Konjunktur-
paket/2020-06-03-konjunkturpaket-beschlossen.html (zuletzt abgerufen am 14. August 2020). Dagegen plant aber allein die
chinesische Stadt Tijan f&#252;r die KI-F&#246;rderung Ausgaben in H&#246;he von 12,8 Milliarden Euro und das chinesische Unternehmen Alibaba hat
bis zu 16 Milliarden Euro vorgesehen; vgl. Konrad-Adenauer-Stiftung (2019): Vergleich nationaler Strategien zur F&#246;rderung von 
K&#252;nstlicher Intelligenz &#8211; Teil 2.
Abgrenzung zwischen Auswirkungen von Digitalisierung allgemein und KI im Speziellen lag nicht vor. Insofern
startete die Projektgruppe mit sehr divergierenden Sichtweisen, die sich auch im allgemeinen politischen und
&#246;ffentlichen Diskurs wiederfinden: &#220;bersch&#228;tzung und zugleich Untersch&#228;tzung der systemischen
Auswirkungen von Digitalisierung, was durch die technologische Qualit&#228;t und Komplexit&#228;t von KI auf eine neue Stufe
gehoben wird. 
Es geh&#246;rt zu einem wichtigen Ziel dieser Projektgruppe, Fehleinsch&#228;tzungen entgegenzuwirken und eine
realistische Vision des KI-Einsatzes in der Wirtschaft zu f&#246;rdern. Daher hat sich die Projektgruppe zu Beginn auf eine
objektive Sachstandskl&#228;rung und eine gemeinsame Zielsetzung aus der Perspektive des Jahres 2030 geeinigt
sowie in Szenarien die Situation und Handlungsoptionen der drei Akteure &#8211; Start-ups, mittelst&#228;ndische
Unternehmen und Konzerne &#8211; beleuchtet (siehe Kapitel 3 dieses Projektgruppenberichts [Einf&#252;hrung:
Anwendungsfelder und Potenziale von KI in der Wirtschaft]).
Zentral war f&#252;r die Projektgruppe, eine St&#228;rken-Schw&#228;chen-Analyse zu erarbeiten und den Status quo in der KI-
Implementierung f&#252;r ausgew&#228;hlte Branchen (Industrie/Produktion, Handel, Finanz- und
Versicherungswirtschaft, Agrar&#246;konomie und Landwirtschaft) und f&#252;r die drei oben genannten Akteure festzustellen. Die
Erkenntnisse sind in Kapitel 4 diese Projektgruppenberichts [Thematischer Schwerpunkt] dargelegt.
Auf dieser Basis hat die Projektgruppe &#8222;KI und Wirtschaft&#8220; einen Katalog an Handlungsempfehlungen erarbeitet
(siehe Kapitel 5 dieses Projektgruppenberichts [Handlungsempfehlungen und Perspektiven]). Im Folgenden
werden die Handlungsempfehlungen vorgestellt, die f&#252;r die Mehrheit der Mitglieder besonders relevant oder
dringlich sind:427 
&#8226; KI-spezifische Datenbasis und Benchmarking aufbauen
Die wirkungsvolle strategische Steuerung des Zukunftsthemas KI durch Recht und Politik setzt voraus, dass eine
fundierte St&#228;rken-Schw&#228;chen-Analyse vorliegt und realistische technische wie wirtschaftliche Erwartungen
bestehen. Die Projektgruppe regt daher an, f&#252;r Deutschland (und Europa) eine valide, differenzierende Datenbasis
zu den &#246;konomischen Effekten des KI-Einsatzes als Entscheidungsgrundlage zu erstellen. Zudem sollte ein
dynamisches Ziel- und Monitoringsystem entworfen werden, welches in die Benchmarking-Initiativen der OECD,
EU, G20 etc. eingebunden ist und welches eine weisungsbefugte zentrale Steuerungsstruktur f&#252;r KI unterst&#252;tzt. 
Daf&#252;r m&#252;ssten Ziele und Ma&#223;nahmen der KI-Strategie mit qualitativen und quantitativen Indikatoren hinterlegt 
werden, die es erm&#246;glichen, Fortschritte zu messen.
&#8226; &#8222;KI made in Germany&#8220; und den europ&#228;ischen Weg als Erfolgsfaktor schaffen
Deutschland und Europa haben den Anspruch, einen eigenst&#228;ndigen Weg in der Daten&#246;konomie durchzusetzen,
verbunden mit qualitativ hochwertigen KI-Dienstleistungen und -Anwendungen und einer durchdachten
Regulierung. Ein Ethik-Vorreiter ohne technisch-wissenschaftliche F&#228;higkeiten, eine robuste Infrastruktur und
skalierbare Gesch&#228;ftsmodelle ist jedoch wenig erfolgsversprechend. Als Schl&#252;sselprobleme f&#252;r die
Durchsetzungsf&#228;higkeit der deutschen wie europ&#228;ischen Ans&#228;tze im KI-Bereich wurden die folgenden Punkte identifiziert: die
ausbleibende schnelle Skalierung von Ideen und Piloten zu wirkungsvollen Gro&#223;projekten und Akteuren, der
verz&#246;gerte digitale Infrastrukturausbau in der Fl&#228;che und die fehlende technologische Souver&#228;nit&#228;t etwa mit Blick 
auf die Entwicklung von Rechenleistungen (inkl. Hardware und Quanten-Computing), Cloud-Strukturen oder
Datenpooling. Weiterhin werden Hemmnisse f&#252;r die Sammlung und Verarbeitung personenbezogener Daten in
Europa und Deutschland sowie in der hohen Regulierungsdichte f&#252;r Medien- und Telekommunikationsdienste
gesehen.428 
Die Projektgruppe begr&#252;&#223;t daher Prozesse und Vereinbarungen auf nationaler wie auf europ&#228;ischer Ebene, die
insbesondere mit Blick auf Recht, Ethik und Daten verbindliche Standards f&#252;r KI-Technologien und ihre
Anwendung schaffen, dabei aber auch die inner- und au&#223;ereurop&#228;ische Skalierung erm&#246;glichen. Mit den im April
2019 ver&#246;ffentlichten Leitlinien der &#8222;High-Level Expert Group on Artificial Intelligence&#8220;429 wurde hierf&#252;r
bereits ein wichtiges Signal gesetzt.430 Zudem wird daran in internationalen Normungsgremien gearbeitet.431 
427 Abweichende Meinungen sind entsprechend gekennzeichnet.
428 Die Fraktionen SPD, DIE LINKE. und B&#220;NDNIS 90/DIE GR&#220;NEN teilen nicht die Auffassung, dass der Schutz personenbezogener
Daten in Europa und Deutschland ein Hindernis darstellt.
429 Vgl. Europ&#228;ische Kommission (2019): Schaffung von Vertrauen in eine auf den Menschen ausgerichtete k&#252;nstliche Intelligenz.
430 Die Leitlinien wurden auch deutlich kritisiert; vgl. z. B. Metzinger (2019): Nehmt der Industrie die Ethik weg!.
431 Weitere Informationen dazu unter: https://www.din.de/de/forschung-und-innovation/themen/kuenstliche-intelligenz/kuenstliche-in-
telligenz-ohne-normen-und-standards-geht-es-nicht-320492 (zuletzt abgerufen am 29. Juli 2020).
Die Zusammenarbeit zwischen Forschungseinrichtungen, Start-ups und Unternehmen auf europ&#228;ischer Ebene
sollte weiter intensiviert werden, hierbei werden die deutsch-franz&#246;sischen Initiativen als wichtiger Motor
gesehen. Wichtig erscheint der Projektgruppe auch, dass der Aufbau und Betrieb eines europ&#228;isch eingebundenen
&#214;kosystems aus vertrauensvollen Daten- und Analyseinfrastrukturen inklusive Cloud-Plattform(en) auf Basis 
offener und interoperabler Standards forciert wird. Das BMWi hat hierzu das Projekt GAIA-X aufgesetzt, das in
der Projektgruppe noch nicht abschlie&#223;end beurteilt werden konnte.432
&#8226; Vertrauen durch eine vertrauensw&#252;rdige KI erreichen
Die Haltung gegen&#252;ber KI-Technologien ist in Deutschland noch ambivalent. Aspekte wie Sicherheit,
Datenschutz, Datensouver&#228;nit&#228;t, soziale und &#246;kologische Verantwortung, Transparenz oder Diskriminierungsfreiheit
spielen dabei eine wichtige Rolle. Die Projektgruppe kam &#252;berein, dass Bedenken der Bev&#246;lkerung dann
ausger&#228;umt werden k&#246;nnen, wenn zum einen &#252;ber Anwendungen von KI informiert und zum anderen m&#246;glichen
Fehlentwicklungen wirksam vorgebeugt wird. Empfohlen wird eine Aufkl&#228;rungskampagne, die Kenntnisse
vermitteln, Best Practices aufzeigen und Sorgen nehmen kann. Das im Jahr 2019 vom KI-Verband entwickelte &#8222;KI-
G&#252;tesiegel&#8220; erscheint geeignet, Transparenz und Vertrauen auf dem deutschen KI-Markt zu schaffen, sofern es
auf eine breitere Grundlage gestellt und mit noch konkreteren Kriterien belegt wird. Auch ein internationales
Klassifizierungsmodell f&#252;r KI-Produkte und -Dienstleistungen, vergleichbar dem Prinzip der
Energieverbrauchskennzeichnung von Elektroger&#228;ten, k&#246;nnte eine gute Verbraucherorientierung bieten. Als weiteres Instrument
wird vorgeschlagen, gesellschaftlich w&#252;nschenswerte &#8222;KI-Moonshot-Projekte&#8220; zu f&#246;rdern und umzusetzen. Die
Projektgruppe regt an, daf&#252;r Vorschl&#228;ge im Rahmen des Beteiligungsverfahrens der Enquete-Kommission
einzuholen.433 
&#8226; Eine Marke &#8222;Sustainable AI&#8220; etablieren
Die Projektgruppe empfiehlt, das politisch-strategische Handeln im Bereich KI an den Prinzipien einer
nachhaltigen Entwicklung ausrichten, wie sie in der Deutschen Nachhaltigkeitsstrategie enthalten sind, und dies auch in
F&#246;rder- und Forschungsvorhaben entsprechend zu ber&#252;cksichtigen. Au&#223;erdem wird in einer Marke &#8222;Sustainable
AI&#8220; (Nachhaltige KI) ein gro&#223;es Potenzial gesehen, sofern es gelingt, daf&#252;r konkrete Merkmale bzw.
Anforderungen zu definieren und durchzusetzen. Es wird darauf hingewiesen, dass mit aktuellen und kommenden KI-
Anwendungen ein hoher Energieverbrauch einhergeht und die weiteren Entwicklungen noch schwer
abzusch&#228;tzen sind. Insofern erscheint es geboten, die strategischen Ans&#228;tze bei KI und Energie miteinander zu verzahnen.
Die Entwicklung energieeffizienter KI-Systeme sollte gef&#246;rdert und es sollten Anreize f&#252;r eine
ressourcenschonende Nutzung gesetzt werden. 
&#8226; Transfer und &#214;kosysteme vorantreiben
Beim Transfer wissenschaftlicher Erkenntnisse tun sich deutsche Akteure noch schwer. International ist zu
beobachten, dass KI in der Wirtschaft von gro&#223;en Datenunternehmen wie auch Start-ups vorangetrieben wird. F&#252;r
Deutschland wird es daher als besonders wichtig angesehen, die Rahmenbedingungen f&#252;r Start-ups weiter zu
verbessern. Zudem muss der Transfer von KI-Ans&#228;tzen in KMU weiter vorangebracht werden. Hierf&#252;r schl&#228;gt
die Projektgruppe verschiedene Einzelma&#223;nahmen vor, die von dem Aufbau eines Start-up-&#214;kosystems durch
regionale und thematische Cluster, &#252;ber innovationsf&#246;rdernde Vergabe und B&#252;rokratieabbau bis hin zur
F&#246;rderung von Venture Capital durch Dachfonds reichen. Mit Blick auf den Mittelstand empfiehlt sie vor allem, die
Beratung und konkrete Unterst&#252;tzung durch Kompetenzzentren, KI-Trainerinnen und -Trainer, Technologie-
Scouting434 und Qualifizierungsma&#223;nahmen zu intensivieren. Wesentlich erscheint die Schaffung von
Datenpools, etwa in Form interdisziplin&#228;rer Datengenossenschaften, sowie die weitere F&#246;rderung regionaler Cluster
und Hubs. 
Als zentrale Ma&#223;nahme f&#252;r den schnelleren Transfer wird vorgeschlagen &#8222;Regulatory Sandboxes&#8220;
(regulatorische Sandk&#228;sten), z. B. ein bestimmtes Krankenhaus, einen Lehrbetrieb, eine Autobahn, bzw. freie
Experimentierr&#228;ume einzurichten, die Forscherinnen und Forschern unter geeigneten Voraussetzungen dazu dienen k&#246;nnen,
Realexperimente durchzuf&#252;hren. Da diese weniger reguliert sind, k&#246;nnten sie dort kontrolliert die Ergebnisse aus
der theoretischen Forschung testen und so Best Practices f&#252;r weitere Forschung und Entwicklung bieten.
432 Die Projektgruppe konnte das Projekt GAIA-X nicht abschlie&#223;end beurteilen, da die Vorstellung durch das BMWI nach Abschluss
der Arbeit der Projektgruppe stattfand. Die Notwendigkeit starker Partner aus Wirtschaft und &#246;ffentlicher Hand wurde aber gesehen;
weitere Informationen dazu unter: https://www.bmwi.de/Redaktion/DE/Dossier/gaia-x.html (zuletzt abgerufen am 17. August 2020).
433 Weitere Informationen dazu finden sich im Gutachten zur Online-Beteiligung der Enquete-Kommission in der Anlage zum Bericht.
434 Technologie-Scouting ist ein systematischer Ansatz, in dem ein Unternehmen das technologische Umfeld beobachtet, neue
Technologien bewertet und gegebenenfalls die Akquise von Technologien oder technologie-orientierten Start-ups vorbereitet.
Weiterhin regt die Projektgruppe an, ein F&#246;rderprogramm einzurichten, das die Forschung zu Grundlagen und
zur praxisorientierten Anwendung besser verzahnt. Zudem empfiehlt sie, dass der Staat selbst st&#228;rker als Enabler
voranschreitet (Daten bereitstellt, Best Practices in der Verwaltung vorantreibt etc.) und die f&#252;r Kooperationen
notwendigen Vereinbarungen f&#252;r Hochschulen, Forschungseinrichtungen und Unternehmen vereinfacht.
Konkret wurde dazu ein deutschlandweiter Standardvertrag vorgeschlagen, der die Akteure bei der Rechte- und
Patentverwertung unterst&#252;tzt.  
&#8226; Datenmanagement und Vernetzung von Daten optimieren
F&#252;r die Entfaltung von KI-Anwendungen in Deutschland und Europa wird es als ma&#223;geblich erachtet, dass der
Zugang zu Daten optimiert wird und vorhandene Datenbest&#228;nde und vorhandenes Know-how in der
Datenanalyse besser vernetzt werden; daf&#252;r werden verschiedene Modelle vorgeschlagen. Wichtig ist der Projektgruppe,
dass Anreize zum Datenteilen gesetzt werden, um Datensilos zu &#246;ffnen, dezentrale Datenbest&#228;nde st&#228;rker
interoperabel zu vernetzen, Synergien zu heben etc. Hierf&#252;r sollten Leitinitiativen zur Datenvernetzung, wie die
International Data Spaces435 oder die Nationale Forschungsdateninfrastruktur436, weiter gef&#246;rdert werden und
neue sektorspezifische sowie partizipatorische Datenplattformen aufgebaut werden. 
Zudem sieht die Projektgruppe die Notwendigkeit, im Wettbewerbs-/Kartellrecht Anpassungen vorzunehmen,
um insbesondere die praktische und tats&#228;chliche Verf&#252;gungsgewalt &#252;ber eigene Daten zu verbessern, klare
Verhaltensregeln f&#252;r marktbeherrschende Plattformen einzuf&#252;hren und die Rechtssicherheit f&#252;r Kooperationen in der
Digital&#246;konomie zu erh&#246;hen. Hierzu wurden im September 2019 von der Kommission Wettbewerbsrecht 4.0
bereits umfangreiche Ma&#223;nahmen empfohlen.437 In der Projektgruppe wurden ebenfalls die M&#246;glichkeiten
diskutiert, zum einen Datentreuh&#228;nder einzurichten, zum anderen Unternehmen bei der &#246;ffentlichen
Auftragsvergabe zur Bereitstellung und Weitergabe von Daten (im Rahmen der Open-Data-Gesetzgebung) zu
verpflichten, sofern diese mit Aufgaben der Daseinsvorsorge betraut werden oder &#252;ber einen privilegierten Zugang zu
Daten verf&#252;gen. Die Projektgruppe sieht es als dringlich an, neue Rechtsfragen auf europ&#228;ischer Ebene zu kl&#228;ren,
die durch Unternehmenskooperationen im digitalen Bereich beispielsweise durch Datenaustausch oder
Datenpooling entstehen.
Mit Blick auf die Datenschutz-Grundverordnung (DSGVO) wird empfohlen, auf Grundlage des Berichts der EU-
Kommission &#252;ber die Bewertung und &#220;berpr&#252;fung der DSGVO sowie R&#252;ckmeldungen von Branchen- und
Verbraucherschutzverb&#228;nden dar&#252;ber zu entscheiden, ob und ggf. welche Reformen notwendig sind, um
Unternehmen und Start-ups bei der rechtskonformen Umsetzung der DSGVO zu unterst&#252;tzen. Als m&#246;gliche Ma&#223;nahmen
wurden einheitliche Kriterien f&#252;r die Datenschutzaufsicht und branchenspezifische Musterdokumente
identifiziert.
Die Projektgruppe &#8222;KI und Wirtschaft&#8220; weist darauf hin, dass weitere wichtige Wirtschaftsthemen im Bereich
KI wie Bildung, Fachkr&#228;fte und &#214;kologie in anderen Projektgruppen intensiviert werden sowie &#252;bergreifende
Themen wie Recht, Forschung und Daten im Mantelbericht zusammengef&#252;hrt werden.
Die Projektgruppe ist &#252;berzeugt, dass die in diesem Bericht dargelegten Handlungsempfehlungen umgesetzt
werden m&#252;ssen, um KI in der deutschen Wirtschaft richtig zu gestalten. Auf diese Weise kann KI auch dazu
beitragen, die soziale Marktwirtschaft und den gesellschaftlichen Zusammenhalt in Deutschland zu st&#228;rken.
2 Vorbemerkungen
Im Einsetzungsbeschluss der Enquete-Kommission &#8222;K&#252;nstliche Intelligenz &#8211; Gesellschaftliche Verantwortung
und wirtschaftliche, soziale und &#246;kologische Potenziale&#8220; (Bundestagsdrucksache 19/2978) nimmt der
Themenkomplex Wirtschaft eine zentrale Rolle ein. KI wird als einer der gr&#246;&#223;ten Treiber der Digitalisierung und als
zunehmend wichtiger Wirtschaftsfaktor angesehen. Es wird davon ausgegangen, dass der Einsatz von KI zu
einem entscheidenden Wettbewerbsfaktor von Unternehmen im deutschen, europ&#228;ischen und globalen Kontext
wird und f&#252;r die Wirtschaft gro&#223;e Chancen, aber auch Herausforderungen bedeutet. Dabei wird die Enquete-
Kommission im Einsetzungsbeschluss beauftragt, folgende Aspekte zu bearbeiten, die die Wirtschaft betreffen:
435 Weitere Informationen dazu unter: https://www.fraunhofer.de/de/forschung/fraunhofer-initiativen/international-data-spaces.html
(zuletzt abgerufen am 17. August 2020).
436 Weitere Informationen dazu unter: https://www.bmbf.de/de/nationale-forschungsdateninfrastruktur-8299.html (zuletzt abgerufen am
17. August 2020).
437 Vgl. Schallbruch et al. (2019): Ein neuer Wettbewerbsrahmen f&#252;r die Digitalwirtschaft. Bericht der Kommission Wettbewerbsrecht
4.0. Die Projektgruppe konnte aus Zeitgr&#252;nden diese Ma&#223;nahmen nicht er&#246;rtern und bewertet die Vorschl&#228;ge daher nicht im
Einzelnen, siehe aber auch die Ausf&#252;hrungen im Kapitel 5 des Mantelbericht [KI und Recht].
&#8226; wirtschaftliche Rahmenbedingungen, damit Deutschland und die Europ&#228;ische Union im weltweiten
Wettbewerb die Innovationsf&#252;hrerschaft bei KI &#252;bernehmen k&#246;nnen
&#8226; Identifikation strategischer Wirtschaftsbereiche f&#252;r Deutschland und Europa
&#8226; Bedeutung der Kombination von KI, dem Internet der Dinge, der Robotik und dem Maschinenbau und
weiterer Schl&#252;sseltechnologien f&#252;r den Wirtschaftsstandort Deutschland, insbesondere auch im Hinblick auf
den Mittelstand
&#8226; notwendige Infrastruktur zur weitr&#228;umigen und sicheren Nutzung von KI und zum Schutz vor Cybercrime
&#8226; Ver&#228;nderungen der Arbeitswelt durch KI
&#8226; Ver&#228;nderung von Wertsch&#246;pfungsketten durch KI
&#8226; F&#228;higkeiten von KI-Systemen in der Kooperation und Kollaboration mit dem Menschen im beruflichen 
Umfeld
&#8226; Auswirkungen des technologischen Wandels auf die soziale Marktwirtschaft und auf die
Sozialpartnerschaften
&#8226; rechtliche Rahmenbedingungen f&#252;r eine erfolgreiche KI in Deutschland und Europa, insbesondere Konzepte
zum Ausbau der Dateninfrastruktur, zum Datenschutz und zur IT-Sicherheit, die sowohl dem technischen
Fortschritt als auch dem Schutz der Privatsph&#228;re des Individuums gerecht werden
&#8226; verbesserte Verf&#252;gbarkeit von (nicht-personenbezogenen) Daten als Voraussetzung f&#252;r die Erforschung und
Entwicklung von KI und Weiterentwicklung von Open-Data- und Open-Science-Ans&#228;tzen
(Forschungsdaten)
&#8226; Analyse der rechtlichen und wirtschaftlichen Rahmenbedingungen in anderen Regionen der Welt,
Strategien zur Sicherung eines Level Playing Fields f&#252;r deutsche und europ&#228;ische Unternehmen
&#8226; Potenziale von KI f&#252;r Umwelt- und Klimaschutz sowie f&#252;r eine ressourcenschonende Produktionsweise
Vor dem Hintergrund der Einrichtung weiterer Projektgruppen wurden einige KI-Themen, die die Wirtschaft
betreffen, hier nicht im Detail betrachtet, da sie schwerpunktm&#228;&#223;ig in anderen Projektgruppen behandelt werden
sollen. Das betrifft insbesondere die Ver&#228;nderung der Arbeitswelt durch den KI-Einsatz und etwaige
Auswirkungen auf Tarifbindung und Mitbestimmung durch KI, mit der sich die Projektgruppe &#8222;KI und Arbeit&#8220;
auseinandersetzen wird, die IT-Sicherheitsthemen und die Modernisierung der Verwaltung, die in der Projektgruppe &#8222;KI
und Staat&#8220; behandelt werden, sowie das autonome Fahren, das in der Projektgruppe &#8222;KI und Mobilit&#228;t&#8220; vertieft 
werden soll. Weiterhin wurden &#252;bergreifende Themen wie Daten, Ethik, Recht und &#246;kologische Aspekte auf
Ebene der Gesamt-Enquete besprochen und werden im Mantelbericht zusammengefasst.
Um das dennoch sehr breitgef&#228;cherte Thema &#8222;KI und Wirtschaft&#8220; im Rahmen verh&#228;ltnism&#228;&#223;ig weniger
Projektgruppensitzungen zu erschlie&#223;en, w&#228;hlte diese Projektgruppe den Ansatz, zun&#228;chst den Status quo von KI und 
Wirtschaft zu ermitteln und Zielstellungen und Visionen f&#252;r die Entwicklung der deutschen Wirtschaft durch KI
zu formulieren. Zus&#228;tzlich zur Auswertung von Studien und zu den eigenen Beitr&#228;gen der
Projektgruppenmitglieder hat sich die Projektgruppe mit zahlreichen externen Sachverst&#228;ndigen ausgetauscht. 
Die ersten beiden Sitzungen am 11. Februar 2019 und am 11. M&#228;rz 2019 dienten einer Analyse der
Positionierung der deutschen Wirtschaft im internationalen Vergleich und der Frage, welches Wirtschaftswachstum f&#252;r
Deutschland zu erwarten ist. Dazu waren als externe Sachverst&#228;ndige geladen:
&#8226; J&#246;rg Bienert, aiso-lab und KI Bundesverband
&#8226; Iris Pl&#246;ger, Bundesverband der Deutschen Industrie e. V. (BDI)
&#8226; Prof. Dr. Emmanuel M&#252;ller, Fraunhofer-Institut f&#252;r Intelligente Analyse- und Informationssysteme (IAIS)
&#8226; Prof. Dr. Svenja Falk, Accenture GmbH, Plattform Lernende Systeme / acatech
Darauf aufbauend wurden in der Sitzung vom 1. April 2019 einzelne Akteure in der Wirtschaft (Start-ups,
Mittelstand sowie gro&#223;e Konzerne) n&#228;her betrachtet und die Verbesserung des Transfers von Forschung und
Entwicklung in neue Produkte und Gesch&#228;ftsmodelle thematisiert. Zu diesen Themen wurden angeh&#246;rt:
&#8226; Alexandra Horn, Bundesverband mittelst&#228;ndische Wirtschaft (BVMW)
&#8226; Prof. Dr. Philipp Staab, Humboldt-Universit&#228;t zu Berlin und Einstein Center Digital Future
&#8226; Alexander Waldmann, appliedAI-Initiative von UnternehmerTUM
Ein ganzt&#228;giger Workshop am 8. April 2019 erm&#246;glichte es, die Potenziale und Herausforderungen von KI in 
einzelnen ausgew&#228;hlten Branchen (Industrie und Produktion, Handel, Versicherungen, Finanzen) genauer zu
analysieren. Dabei trugen vor:
&#8226; Prof. Dr. Patrick van der Smagt, Volkswagen AG, Data Lab M&#252;nchen
&#8226; Prof. Dr. Volker Tresp, Siemens AG
&#8226; Dr. Michael M&#252;ller-W&#252;nsch, OTTO-Group
&#8226; Dr. Mikio Braun, Zalando SE
&#8226; Dr. Ramin Assadollahi, ExB Labs GmbH
&#8226; Michael Bruch und Dr. Henning Schult, Allianz SE
&#8226; Nicolas Kipp, RatePay GmbH
&#8226; Oliver Fu&#223;winkel und Dr. Thomas Decker, Bundesanstalt f&#252;r Finanzdienstleistungsaufsicht (BaFin)
Zudem wurden die Voraussetzungen f&#252;r die Schaffung eines erfolgreichen Start-up-&#214;kosystems und die daf&#252;r
erforderliche Finanzierung vertieft diskutiert. Dazu eingeladen waren:
&#8226; Michael B&#252;ltmann, Here Deutschland GmbH
&#8226; Patrick Bunk, ubermetrics Technologies GmbH
&#8226; Prof. Dr. Heiner Lasi, Ferdinand-Steinbeis-Institut (FSTI)
&#8226; Fabian Westerheide, Asgard Capital Verwaltung GmbH
&#8226; Dr. Kathrin Leonhardt, Kreditanstalt f&#252;r Wiederaufbau (KfW)
Dar&#252;ber hinaus konnten auf dem ganzt&#228;gigen Workshop die &#252;bergreifenden Themen Datenmanagement sowie
Verbraucherschutz und Nachhaltigkeit mit externen Sachverst&#228;ndigen diskutiert werden:
&#8226; Christin Sch&#228;fer, acs plus und Datenethikkommission
&#8226; David Kriesel, Datenwissenschaftler
&#8226; Dr. Reinhard Messerschmidt, Wissenschaftlicher Beirat der Bundesregierung Globale
Umweltver&#228;nderungen (WBGU)
&#8226; Dr. Daniel Halmer, LexFox GmbH
&#8226; Lina Ehrig, Verbraucherzentrale Bundesverband (vzbv)
In der Sitzung am 6. Mai 2019 r&#252;ckten schlie&#223;lich rechtliche Fragen in den Vordergrund, wie etwa, ob die
bestehende Rechtslage mit Blick auf KI und Wirtschaft ausreichend oder eine gesetzliche Weiterentwicklung
erforderlich ist. Ihre Expertise brachten ein:
&#8226; Prof. Dr. Axel Metzger, Humboldt-Universit&#228;t zu Berlin
&#8226; Michael Teigeler und Dr. Sebastian Hallensleben, Verband der Elektrotechnik, Elektronik und
Informationstechnik (VDE)
&#8226; Matthis Eicher, DIN-Arbeitsausschuss &#8222;K&#252;nstliche Intelligenz&#8220; und Sibylle Gabler, DIN e. V.
&#8226; Martin Schallbruch, Digital Society Institute der ESMT Berlin und Kommission Wettbewerbsrecht 4.0 des
BMWi
Ausgehend von diesen gesammelten Beitr&#228;gen und der Erarbeitung des Status quo hat die Projektgruppe ihre
Handlungsempfehlungen formuliert. Die Sitzungen am 3. und 24. Juni 2019 sowie am 2. September 2019 dienten
der Erarbeitung des Projektgruppenberichtes sowie der intensiven Diskussion &#252;ber die abzugebenden
Handlungsempfehlungen. Das Ziel bestand darin, einen m&#246;glichst breiten Konsens unter den Projektgruppenmitgliedern 
herzustellen. Dieser konnte nicht in allen Bereichen erzielt werden. Beispielsweise zeigten sich bereits bei der
anf&#228;nglichen Formulierung von Zielstellungen und Visionen unterschiedliche Herangehensweisen. W&#228;hrend
einige Projektgruppenmitglieder den Fokus auf die St&#228;rkung der Wirtschaftsstandorte Deutschland und Europa
sowie den Erhalt der Wettbewerbsf&#228;higkeit legen wollten, waren andere Projektgruppenmitglieder bestrebt, die
Frage der k&#252;nftigen Ausgestaltung der Wirtschaft und die Rolle, die KI dabei spielen soll, zu thematisieren. 
Dieses vorhandene Meinungsspektrum spiegelt sich in der Aufnahme von Sondervoten wider.
An der Projektgruppe und ihrem Bericht wirkten mit
f&#252;r die Fraktion der CDU/CSU:
&#8226; der Abgeordnete Hansj&#246;rg Durz
&#8226; Prof. Dr. Wolfgang Ecker als sachverst&#228;ndiges Mitglied
&#8226; die Abgeordnete Ronja Kemmer als Vorsitzende der Projektgruppe
&#8226; Dr. Tina Kl&#252;wer als sachverst&#228;ndiges Mitglied
&#8226; der Abgeordnete Jan Metzler
f&#252;r die Fraktion der SPD:
&#8226; der Abgeordnete Arno Klare
&#8226; der Abgeordnete Falko Mohrs
&#8226; Lothar Schr&#246;der als sachverst&#228;ndiges Mitglied
f&#252;r die Fraktion der AfD:
&#8226; die Abgeordnete Joana Cotar
&#8226; Prof. Dr. Knut L&#246;schke als sachverst&#228;ndiges Mitglied
f&#252;r die Fraktion der FDP:
&#8226; Dr. Aljoscha Burchardt als sachverst&#228;ndiges Mitglied
&#8226; der Abgeordnete Mario Brandenburg als stellvertretendes Mitglied
f&#252;r die Fraktion DIE LINKE.:
&#8226; die Abgeordnete Jessica Tatti
&#8226; Dr. Florian Butollo als sachverst&#228;ndiges und stellvertretendes Mitglied
und f&#252;r die Fraktion B&#220;NDNIS 90/DIE GR&#220;NEN:
&#8226; der Abgeordnete Dr. Danyal Bayaz
&#8226; der Abgeordnete Dieter Janecek als stellvertretendes Mitglied
3 Einf&#252;hrung: Anwendungsfelder und Potenziale von KI in der Wirtschaft
Grundlagen und Sachstandskl&#228;rung: KI hat gro&#223;es Potenzial, ist aber kein
Selbstl&#228;ufer438 
Im Bereich Wirtschaft wird KI als Erweiterung des digitalen Wandels betrachtet. KI ohne Digitalisierung kann
es naturgem&#228;&#223; nicht geben. Der Anteil von KI-Systemen wird auf l&#228;ngere Sicht voraussichtlich steigen.
Aufgrund der aktuellen Fortschritte in der Entwicklung k&#246;nnen KI-Anwendungen zu einer Basistechnologie
werden, die wirtschaftlichen Akteuren in Deutschland und weltweit neue Wertsch&#246;pfungspotenziale er&#246;ffnet.
Grundlegend daf&#252;r sind nicht nur die Fortschritte im Bereich der Informatik selbst (aktuell vor allem im Bereich des 
Maschinellen Lernens), sondern auch die neuen M&#246;glichkeiten, Handlungsfelder umfassend mit Sensoren und
Prozessoren auszustatten und daraus Daten zu gewinnen. Die M&#246;glichkeiten reichen von der Produktion,
beispielsweise von Kameras und Sensoren in einer Presse, bis hin zu den Produkten selbst, wie z. B. einem
Werkst&#252;ck, welches etwa seine Lagertemperatur erfasst und speichert.
Die &#246;konomische Anwendung von KI basiert insofern auf einer spezifischen &#8222;KI-Wertsch&#246;pfungskette&#8220; aus 
Hardware, Datengenerierung, Datenbereinigung und -aufbereitung sowie der Datenanalytik. Die &#220;berg&#228;nge
zwischen statistischen Verfahren der Datenanalyse und KI im engeren Sinne sind in der Praxis flie&#223;end, weshalb die
438 Zu diesem Kapitel liegen Sondervoten aus der Fraktion der FDP [Sondervotum zu den Kapiteln 1 und 3.1 des Berichts der
Projektgruppe 1 &#8222;KI und Wirtschaft&#8220; (&#8222; Kurzfassung des Projektgruppenberichts &#8220; und &#8222;Grundlagen und Sachstandskl&#228;rung: KI hat gro&#223;es
Potenzial, ist aber kein Selbstl&#228;ufer &#8220;) der Abgeordneten Mario Brandenburg, Carl-Julius Cronenberg und Daniela Kluckert sowie
der sachverst&#228;ndigen Mitglieder Dr. Aljoscha Burchardt und Andrea Martin] sowie aus der Fraktion DIE LINKE. [Sondervotum zu
Kapitel 3.1 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220; (&#8222;Grundlagen und Sachstandskl&#228;rung: KI hat gro&#223;es Potenzial, ist 
aber kein Selbstl&#228;ufer &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo]
vor.
Ausf&#252;hrungen in diesem Kapitel allgemein die Verbindung von Datengenerierung und der algorithmischen
Auswertung im &#246;konomischen Feld in den Mittelpunkt stellen. 
Algorithmische Entscheidungssysteme sind in der Finanzbranche schon lange im Einsatz, ebenso wie Methoden
der automatischen Qualit&#228;tssicherung in der industriellen Fertigung, die auf Maschinellem Lernen beruhen.
Insofern wird heute eigentlich weniger &#252;ber eine neue Art von Technologie, sondern vielmehr &#252;ber einen breiteren
Einsatz und h&#246;here Leistungsf&#228;higkeit von Technologien gesprochen, die so oder so &#228;hnlich schon bekannt und
teilweise im Einsatz sind. Aufgrund der zunehmenden Verf&#252;gbarkeit von Daten &#8211; seien es Nutzerdaten aus der
privaten Nutzung von Telekommunikationsger&#228;ten oder Daten aus eigens daf&#252;r installierten Sensoren &#8211; werden 
Unternehmen zunehmend von KI-Technologien Gebrauch machen, um Gesch&#228;ftsprozesse zu rationalisieren und
neue, datenbasierte Gesch&#228;ftsmodelle aufzusetzen.
Dem allgemeinen Potenzial zur Anwendung von KI-Technologien steht eine bislang noch geringe
Implementierungsrate in Unternehmen gegen&#252;ber. Nur 5 Prozent aller Unternehmen geben laut einer Studie des BMWi439 
derzeit an, KI-Technologien selbst einzusetzen. Zudem geben 75 Prozent der befragten Unternehmen an, dass KI
f&#252;r sie nicht relevant sei.440 
&#8226; Herausforderungen f&#252;r Unternehmen durch KI
W&#228;hrend diese Zahlen sicherlich auch Ausdruck der Neuheit von KI-Anwendungen sind, die bislang nur von
Pionieranwendern, meist in Gro&#223;unternehmen und einigen Start-ups umgesetzt werden, weisen sie auf
Anwendungshindernisse hin:
1. KI-Systeme funktionieren nur so gut, wie sie gemacht werden. Im Ausgangszustand sind KI-Systeme erst
einmal eine leere H&#252;lle.441 Unabh&#228;ngig davon, ob sie auf Daten oder expliziter Wissensmodellierung oder
einer Mischung daraus beruhen, liegt die Herausforderung der Transformation zur KI zun&#228;chst darin,
Gesch&#228;ftsprozesse zu identifizieren, die sich digitalisieren lassen. Dann m&#252;ssen entsprechende Daten
aufbereitet oder erzeugt und das im Betrieb vorhandene Prozesswissen auf die KI-Systeme &#252;bertragen werden.
2. Unternehmen stehen vor der Herausforderung, rentable Anwendungsfelder von KI im Regelbetrieb,
d. h. jenseits von experimentellen Pilotprojekten, zu entwickeln. Vorreiterunternehmen befinden sich
derzeit in einem Suchprozess, in dessen Rahmen Verwertungsm&#246;glichkeiten f&#252;r Verfahren der Datenanalytik
erkundet werden. Die Eingangsinvestition kann dabei hoch sein und oftmals ist es vor einer Pilotphase, in
der erste Testdaten verarbeitet wurden, kaum m&#246;glich, konkrete Aussagen &#252;ber die erreichbare
Funktionalit&#228;t und Qualit&#228;t des Systems zu machen.
3. Projekte zur Digitalisierung und Einf&#252;hrung von KI k&#246;nnen von internen Rationalisierungsma&#223;nahmen bis
hin zum Erschlie&#223;en neuer Gesch&#228;ftsfelder auf Basis von Kundendaten gehen. Eine Herausforderung
besteht gerade f&#252;r den Mittelstand darin, die richtige L&#252;cke zu finden,442 eine Bedarfsanalyse durchzuf&#252;hren443 
und die Mitarbeiterinnen und Mitarbeiter auf die anstehenden Ver&#228;nderungen vorzubereiten. 
4. Unternehmen stehen vor der Herausforderung, &#8222;das Schiff auf offener See umzubauen&#8220;, d. h. potenziell
zukunftstr&#228;chtige Technologien zu erproben, w&#228;hrend sie zugleich Ertr&#228;ge aus dem Regelbetrieb erzielen
m&#252;ssen. W&#228;hrend es in einigen Feldern durchaus zu disruptiven Prozessver&#228;nderungen kommt, liegt in der
Fl&#228;che ein inkrementeller, weniger risikobehafteter Wandlungsprozess n&#228;her.444 Neue Gesch&#228;ftsmodelle
werden daher auch von neuen Marktteilnehmern (Start-ups, Quereinsteigern) angesto&#223;en, die jedoch
ihrerseits vor der Schwierigkeit stehen, sich Kapital, Managementkompetenz und das dom&#228;nenspezifische
Wissen anzueignen, das f&#252;r den dauerhaften Erfolg ebenso notwendig ist wie ein Binnenmarkt. Dies geht nicht
439 Vgl. Bundesministerium f&#252;r Wirtschaft und Energie (2018): Monitoring-Report Wirtschaft DIGITAL 2018, S. 64; Vortrag von Iris
Pl&#246;ger (Mitglied der Hauptgesch&#228;ftsf&#252;hrung des BDI e. V.), Projektgruppendrucksache 19(27)PG 1-2 vom 11. M&#228;rz 2020.
440 Vgl. Bundesministerium f&#252;r Wirtschaft und Energie (2018): Monitoring-Report Wirtschaft DIGITAL 2018, S. 64; Vortrag von Iris
Pl&#246;ger (Mitglied der Hauptgesch&#228;ftsf&#252;hrung des BDI e. V.), Projektgruppendrucksache 19(27)PG 1-2 vom 11. M&#228;rz 2020. Diese
Aussage bezieht sich in erster Linie auf bestehende Unternehmen, welche auch im Fokus dieser Einf&#252;hrung stehen. Die Situation von 
Start-ups wird in einem eigenen Kapitel beleuchtet (siehe Kapitel 4.1.3.1.1 dieses Projektgruppenberichts [Themenfeld Start-ups]).
441 Die Fraktion DIE LINKE. kann dieser Aussage in dieser Form nicht zustimmen. Sie ist umstritten und f&#252;r die Aussage irrelevant
(KI-Systeme weisen auch materielle und soziale Aspekte auf, k&#246;nnen daher keine &#8222;leeren H&#252;llen&#8220; sein).
442 Darstellung Prof. Dr. Philipp Staab (Humboldt-Universit&#228;t zu Berlin und Einstein Center Digital Future) in der Sitzung der
Projektgruppe &#8222;KI und Wirtschaft&#8220; am 1. April 2019.
443 Darstellung von Prof. Dr. Svenja Falk (Leiterin von Accenture Research, Mitglied der Plattform Lernende Systeme / acatech) in der
Sitzung der Projektgruppe &#8222;KI und Wirtschaft&#8220; am 11. M&#228;rz 2019.
444 Vgl. Hirsch-Kreinsen (2018): Arbeit 4.0: Pfadabh&#228;ngigkeit statt Disruption.
nur aus dem theoretischen Wissen &#252;ber Innovationsprozesse445, sondern auch aus der aktuellen
Marktentwicklung hervor.
5. KI-Projekte stellen auch aus diesen Gr&#252;nden hohe Anforderungen an den Wissensaustausch. Im
Unternehmen m&#252;ssen verschiedene Akteure involviert sein, wie z. B. die Entwicklungsabteilung, die
Fachabteilungen (prozessspezifisches Wissen / Daten), die Rechtsabteilung (Datenschutz), die IT (Datenverarbeitung)
und die Gesch&#228;ftsleitung. Zugleich stellen sich neue Herausforderungen in der interdisziplin&#228;ren
Zusammenarbeit und der unternehmens&#252;bergreifenden Kooperation etwa zwischen Start-ups und etablierten
Unternehmen oder zwischen Software-Entwicklerinnen bzw. -Entwicklern, Plattformbetreibern und
branchenspezifischen Anwendern. 
6. W&#228;hrend die international erfolgreichen innovativen Gesch&#228;ftsmodelle im Bereich KI bisher gr&#246;&#223;tenteils
auf Dienstleistungen (Mobilit&#228;tsangebote, E-Commerce, Social Media etc.) beruhen, liegt die
Kernkompetenz der deutschen Wirtschaft in der Anwendung digitaler Technologien eher im Bereich Industrie 4.0.446 
Es ist derzeit unklar, ob deutsche Unternehmen &#228;hnliche Erfolge im Bereich der KI-basierten
Dienstleistungen erzielen k&#246;nnen wie die f&#252;hrenden Technologieunternehmen bzw. in welchem Umfang die Erfahrung
der j&#252;ngsten KI-Durchbr&#252;che wegweisend f&#252;r den industriellen Sektor sein k&#246;nnen.
7. Bei dem Versuch, neue Gesch&#228;ftsmodelle in Deutschland einzuf&#252;hren, die sich etwa in den USA etabliert
haben, wie Mobilit&#228;tsdienstleistungen oder Angebote zur Gensequenzierung, stie&#223; man dar&#252;ber hinaus in
der Vergangenheit an gesetzliche Grenzen. Unternehmen m&#252;ssen daher die notwendigen Kompetenzen
entwickeln, die Entwicklung technischer Anwendungen fr&#252;hzeitig mit den gesellschaftlich formulierten
Anforderungen und dem regulatorischen Kontext zu vereinbaren. 
Angesichts der Ausgangslage, der potenziell hohen Relevanz von KI-Anwendungen einerseits und bestehender
Hindernisse f&#252;r die Implementierung andererseits, ist es von hoher politischer Bedeutung,
1. vision&#228;re Perspektiven in Bezug auf KI mit einer n&#252;chternen Einsch&#228;tzung &#252;ber ihre konkreten
&#246;konomischen Potenziale zu verkn&#252;pfen (z. B.: Welche Anforderungen des Marktes k&#246;nnten heute durch KI bedient
werden? Welcher traditionelle Prozess &#8211; oder welches Produkt &#8211; k&#246;nnte durch KI zum differenzierenden
Marktfaktor werden?),
2. auf eine sich rasch &#228;ndernde Wettbewerbssituation hinzuweisen, in der sich durch schnelle
Paradigmenwechsel ganze Branchen in kurzer Zeit erheblich ver&#228;ndern k&#246;nnen,
3. eine strategische F&#246;rderung von KI-Anwendungsfeldern zu betreiben, die gesellschaftlichen Nutzen
versprechen oder nachhaltige Wertsch&#246;pfungspotenziale beinhalten,
4. Digitalisierung als Gestaltungsaufgabe zu verstehen; so kann KI auch einen Anreiz darstellen, den Schritt
in die Digitalisierung gleich mit dem Er&#246;ffnen neuer Gesch&#228;ftsfelder und -modelle zu verbinden, wenn
Gesch&#228;ftsprozesse oder Produkte und Dienstleistungen noch nicht digitalisiert sind,
5. den aktuellen Suchprozess zur Anwendung von KI als eine Chance f&#252;r gesellschaftliche Weichenstellungen
zu begreifen, in deren Folge speziell Anwendungen gef&#246;rdert werden, die gesellschaftlichen Mehrwert
versprechen, insbesondere in Bezug auf eine Beschr&#228;nkung neuer Monopolisierungstendenzen in der
Digitalwirtschaft und die Umsetzung sozialer und &#246;kologischer Ziele.
&#8226; Neue Gesch&#228;ftsmodelle und Rationalisierung durch intelligente Datennutzung
KI kann in Unternehmen zun&#228;chst dazu eingesetzt werden, Gesch&#228;ftsprozesse zu rationalisieren und neue
Gesch&#228;ftsmodelle zu entwickeln.
In ihrer Rationalisierungsfunktion kn&#252;pft die KI-Anwendung meist an bestehende Ans&#228;tze an bzw. f&#252;gt sich in
etablierte Wertsch&#246;pfungsmodelle ein, z. B. Lean Production447, Computer Integrated Manufacturing (CIM)448, 
445 Vgl. Schumpeter (2006): Theorie der wirtschaftlichen Entwicklung; Dolata (2011): Wandel durch Technik; Fagerberg (2004): A
guide to the literature.
446 Darstellung von Alexandra Horn (Konsortialleiterin des Mittelstand-4.0-Kompetenzzentrums Berlin und Leiterin
Verbandskooperation und Projekte des Bundesverbands mittelst&#228;ndische Wirtschaft) in der Sitzung der Projektgruppe &#8222;KI und Wirtschaft&#8220; am 1. April 
2019.
447 Fertigung von Industrieerzeugnissen bei weitgehender Einsparung von Arbeitskr&#228;ften, Kosten und Material (deutsch: schlanke
Produktion).
448 Oberbegriff f&#252;r alle Computertechnologien, die den betrieblichen Produktionsablauf unterst&#252;tzen (deutsch: rechnerintegrierte
Produktion).
Verfahren der datenbasierten Prozesssteuerung durch ERP-/MES-Systeme449 etc. Aufgrund einer h&#246;heren
Datendichte sowie neuer Ans&#228;tze der Datenanalyse k&#246;nnen jedoch Effizienzsteigerungen durch eine bessere
Koordination der Abl&#228;ufe sowie der Neugestaltung von Prozessen erzielt werden. 
Solche Ans&#228;tze werden in Deutschland vor allem unter dem Begriff &#8222;Industrie 4.0&#8220; diskutiert. Viele
Unternehmen haben erfolgreich Digitalisierungsma&#223;nahmen im Bereich 4.0 umgesetzt, wobei die Implementierung
ungleich verl&#228;uft zwischen gro&#223;en, kapitalintensiven Unternehmen und KMU, unter denen sich wiederum einige
technologieaffine Unternehmen von der Masse abheben. Industrie 4.0 hat sich zudem erfolgreich zu einem Label
f&#252;r den Export des deutschen Maschinenbaus entwickelt. 
W&#228;hrend die Technologieadaption in Unternehmen voranschreitet, ist sie zugleich als ein Suchprozess mit
offenem Ausgang zu charakterisieren, insbesondere in Bezug auf die Implementierung von neuen KI-Anwendungen
im engeren Sinn, z. B. Predictive Analytics450, KI-basierte Steuerungssysteme etc. Es ist stark prozess- und
branchenspezifisch, inwieweit sich Potenziale zu Effizienzsteigerungen erschlie&#223;en lassen bzw. ob die
Rationalisierungsertr&#228;ge die Investitionskosten rechtfertigen. Neben Produktion und Dienstleitungen, z. B. Einkauf und
Kundenberatung, kann KI beispielsweise auch Forschungs- und Entwicklungsaktivit&#228;ten unterst&#252;tzen wie &#8222;Patent-
Scouting&#8220; (Identifizierung von Patentpotenzialen) und individualisierte Produkte. Unternehmen stehen zudem
vor der Aufgabe, sich selbst Kompetenzen im Bereich der Softwareentwicklung und der Datenanalyse
anzueignen oder Kooperationen mit spezialisierten Datenanalystinnen und -analysten einzugehen. 
Es zeichnet sich ab, dass Industrial-Internet-Plattformen451 eine wichtige Rolle dabei spielen werden,
Unternehmen entsprechende Services zur Verf&#252;gung zu stellen. Verschiedene Anbieter, darunter f&#252;hrende
Industrieunternehmen wie Siemens, Bosch, Trumpf, aber auch Softwareunternehmen wie SAP, haben Plattformen auf den
Markt gebracht, die KI-basierte Angebote zur intelligenten Steuerung und zur Prozessoptimierung enthalten.
Perspektivisch k&#246;nnten solche Plattformen eine bedeutende Rolle als Enabler452 digitalisierter Wertsch&#246;pfung
einnehmen und zu wichtigen Akteuren in Wertsch&#246;pfungsnetzwerken aufsteigen.
Das Potenzial f&#252;r neue Gesch&#228;ftsmodelle ergibt sich oft aus der Verkn&#252;pfung von KI-Technologien mit Modellen 
der Sharing Economy453 und der M&#246;glichkeit einer st&#228;rkeren Individualisierung von Produkt- und
Serviceangeboten. 454 Grundlegend daf&#252;r ist die Aneignung von Daten, welche ausgewertet werden, um zielgerichtete
Angebote zu entwickeln. E-Commerce-Unternehmen, &#8222;Fintechs&#8220; (Finanztechnologieunternehmen) oder neue
Mobilit&#228;tsanbieter fordern etablierte Unternehmen ihrer Branche aufgrund ihrer Kompetenz, Schnittstellen zwischen
Kundinnen und Kunden sowie Unternehmen datenbasiert bearbeiten zu k&#246;nnen, heraus. Diese geraten dadurch
in Zugzwang, ihre Gesch&#228;ftsmodelle entsprechend anzupassen. 
Die im Einsatz entstehenden Daten und daraus mit Maschinellem Lernen erzeugte Modelle sind dann wiederum
Teil der Daten&#246;konomie, k&#246;nnen also ihrerseits weitere Einnahmequellen darstellen. KI-Systeme wie die
maschinelle &#220;bersetzung sind heute schon ein wichtiger Baustein der Globalisierung, wie man bei den gro&#223;en
Internetplattformen beobachten kann. Die Sprachgrenzen sind dennoch im europ&#228;ischen Binnenmarkt noch immer
sp&#252;rbar und auch f&#252;r KI und Datenverarbeitung stellt Vielsprachigkeit noch immer eine Herausforderung dar,
wie etwa beim Erzeugen von Nutzermodellen im E-Commerce. Sprachbarrieren werden teils als die gr&#246;&#223;ten
449 Enterprise Resource Planning (ERP) bezeichnet eine Softwarel&#246;sung zur Ressourcenplanung eines Unternehmens bzw. einer
Organisation. ERP integriert eine Vielzahl von Gesch&#228;ftsanwendungen und Betriebsdaten, die in einer zentralen Datenbank verarbeitet
und gespeichert werden. Ein Manufacturing Execution System (MES) ist ein Teil eines Fertigungsmanagementsystems, operiert als
prozessnahe Ebene und ist somit f&#252;r die Produktionssteuerung verantwortlich. Es ist direkt an die Betriebsprozesse angebunden und 
erm&#246;glicht die Fertigungskontrolle in Echtzeit. Zudem werden mit dem MES Daten von Fertigungsprozessen erfasst, welche dazu
genutzt werden k&#246;nnen, die Prozesse zu optimieren und Fehler im Ablauf zu erkennen.
450 Predictive Analytics ist ein Verfahren, in dem Datenanalysen verwendet werden, um Vorhersagen anhand von Daten zu treffen.
Dieser Prozess verwendet Daten zusammen mit Analysen, Statistiken und Techniken des Maschinellen Lernens, um ein pr&#228;diktives
Modell zu erstellen, um zuk&#252;nftige Ereignisse vorhersagen zu k&#246;nnen.
451 Plattformen des &#8222;Industrial Internet&#8220; stellen ihren Kundinnen und Kunden Angebote zur Auswertung von Daten zur Verf&#252;gung, die
durch die umfassende Vernetzung der Fertigungsprozesse entstehen. Diese Daten erleichtern beispielsweise das Monitoring der
Abl&#228;ufe, die Identifizierung von Optimierungspotenzialen, Prognosen &#252;ber Materialfl&#252;sse und die Wartung der Maschinen.
452 Gemeint ist damit, dass die Plattformen in Kombination mit KI-Technologie bedeutende Spr&#252;nge in Leistung und F&#228;higkeit der
Partner erzeugen k&#246;nnen.
453 Der Begriff Sharing Economy bezeichnet das systematische Ausleihen von Gegenst&#228;nden und das gegenseitige Bereitstellen von 
R&#228;umen und Fl&#228;chen, insbesondere durch Privatpersonen und Interessengruppen &#252;ber digitale Plattformen, die mit hohen Profiten
f&#252;r diese vermittelnden Plattformen verbunden sind.
454 Darstellung von Iris Pl&#246;ger (Mitglied der Hauptgesch&#228;ftsf&#252;hrung des BDI e. V.) in der Sitzung der Projektgruppe &#8222;KI und Wirtschaft&#8220;
am 11. M&#228;rz 2019.
Handelshemmnisse beschrieben. Hier kann die Wirtschaft von einer konsequenten Digitalisierung stark
profitieren. Ma&#223;nahmen zur Reduzierung von Sprachbarrieren sind bereits in der Erprobung und sollten auch auf
politischer Ebene bzw. von staatlicher Seite vorangetrieben werden, z. B. &#220;bersetzung von Kundenanfragen und
Produktbeschreibungen in leicht verst&#228;ndliche Sprache.455 
Technologisch st&#252;tzen sich die derzeit &#246;konomisch erfolgreichen gro&#223;en Internet-Unternehmen in den USA und
in China weitgehend auf dem Maschinellen Lernen auf Basis gro&#223;er Datenmengen (Big Data). Die
Gesch&#228;ftspraktiken in diesen Endkundengesch&#228;ften (B2C456) stehen teilweise in der Kritik, kommerzielle
Alleinstellungen voranzutreiben und Unternehmen (bzw. mittelbar auch dem Staat) umfassenden Zugang zu
Nutzerdaten und darauf basierenden Potenzialen zu Macht und Machtmissbrauch zu gew&#228;hren.457 Davon ausgehend gibt
es international eine lebhafte Diskussion dar&#252;ber, wie ein ethisch fortschrittlicher Ansatz aussehen k&#246;nnte, der
die immer pr&#228;senter werdende KI &#246;konomisch nutzbar macht &#8211; ohne diese Machtkonzentration zu verfestigen. 
Hier gilt es, den Zeitpunkt jetzt zu nutzen und eine internationale Vorreiterrolle insbesondere im Bereich
industrieller Anwendungen anzustreben.
Eine Technologie kann mit guten oder schlechten Absichten entwickelt und benutzt werden.458 So k&#246;nnen gerade
bei KI technisch bedingte Eigenschaften wie Intransparenz (fehlende Erkl&#228;rbarkeit der Ergebnisse) ein Grund
daf&#252;r sein, die Technologie nicht einzusetzen bzw. nur in engen Grenzen als Unterst&#252;tzung eines Menschen. Hier
gilt es, weiter an &#8222;Explainable AI&#8220; (Erkl&#228;rbarkeit von KI)459 zu forschen und gleichzeitig immer auch zu pr&#252;fen,
welche Aufgaben sich mit anderen Methoden der Informatik und symbolischer KI l&#246;sen lassen, bei der
Transparenz leichter zu erzeugen ist. Hybride Systeme, die z. B. Entscheidungsb&#228;ume460 lernen, weisen einen Weg in die
Zukunft. 
Der Aspekt der Datensicherheit betrifft nicht nur KI, aber durch KI gewinnt das Thema noch mehr Wichtigkeit
und muss bei jedem Projekt ber&#252;cksichtigt werden. Dies gilt ebenso f&#252;r die ethischen Aspekte der Datennutzung,
die einen viel diskutierten Komplex darstellen. Hierf&#252;r verweist die Projektgruppe auf die Ergebnisse der von
der Bundesregierung eingesetzten Datenethikkommission.461 
Die Sicherheit bei der Mensch-Maschine-Interaktion ist ein weiterer relevanter Aspekt. Durch Innovationen wie
Exoskelette werden k&#246;rperlich schwere Aktivit&#228;ten k&#252;nftig erleichtert. Dies bedeutet, dass die Sicherheit von
Menschen gew&#228;hrleistet sein muss, die mit KI-Systemen wie Robotern interagieren, die z. B. schwere
Werkst&#252;cke heben oder Fahrzeuge steuern. W&#228;hrend vollautomatisierte Systeme, wie z. B. eine rein robotergesteuerte
Produktionshalle, unproblematisch erscheinen, ist gerade die Situation, in der sich Menschen und Maschinen
zusammen bewegen, besonders herausfordernd. Hier muss die Mensch-Maschine-Interaktion nicht nur
reibungslos funktionieren, sondern die Unversehrtheit der Menschen muss oberste Priorit&#228;t haben. Dazu geh&#246;rt auch eine
eindeutige Kommunikation zwischen Mensch und Maschine, bei der Missverst&#228;ndnisse ausgeschlossen sind,
beispielsweise bei der &#220;bergabe.
KI in einf&#252;hrenden Szenarien462 
Die Chancen, welche sich durch den Einsatz von KI ergeben, ver&#228;ndern die heutige Welt der Wirtschaft. Es
werden neue Unternehmen gegr&#252;ndet, die Produkte auf KI-Basis entwickeln und sich im internationalen
Wettbewerb durchsetzen m&#252;ssen. Aber auch mittelst&#228;ndische Unternehmen und gro&#223;e Konzerne m&#252;ssen zun&#228;chst
verschiedene Herausforderungen meistern, um die M&#246;glichkeiten von KI f&#252;r sich in positiver Weise nutzen zu
455 Weitere Informationen dazu unter: https://www.iais.fraunhofer.de/de/forschung/bereiche/deep-learning/anwendungsbei-
spiele/spracherkennung (zuletzt abgerufen am 6. August 2019); vgl. auch Gr&#228;vemeyer (2019): Simultan&#252;bersetzer und Dialogsysteme
aus deutschen KI-Schmieden.
456 Die Abk&#252;rzung B2C steht f&#252;r Business-to-Consumer und beschreibt Gesch&#228;ftsbeziehungen zwischen einem Unternehmen und einer
Privatperson (einer Konsumentin / einem Konsumenten, einer Kundin / einem Kunden).
457 Vgl. Zuboff (2018): Das Zeitalter des &#220;berwachungskapitalismus.
458 Abweichend von der Mehrheitsmeinung haben sich die AfD- und die FDP-Fraktion sowie ihre sachverst&#228;ndigen Mitglieder daf&#252;r
ausgesprochen, Technologie als grunds&#228;tzlich wertneutral zu bezeichnen.
459 Siehe hierzu auch Kapitel 3 des Mantelberichts [KI und Umgang mit Bias/Diskriminierung].
460 Entscheidungsb&#228;ume sind geordnete, gerichtete B&#228;ume, die der Darstellung von Entscheidungsregeln dienen. Die grafische
Darstellung als Baumdiagramm veranschaulicht hierarchisch aufeinanderfolgende Entscheidungen. Sie haben eine Bedeutung in zahlreichen 
Bereichen, in denen automatisch klassifiziert wird oder aus Erfahrungswissen formale Regeln hergeleitet oder dargestellt werden.
461 Vgl. Datenethikkommission der Bundesregierung (2019): Gutachten der Datenethikkommission der Bundesregierung.
462 Hier wurden bisherige Erfahrungen und Praxisbeispiele in drei fiktive Szenarien integriert, es besteht jedoch kein Anspruch auf
Vollst&#228;ndigkeit oder einen repr&#228;sentativen Status quo; N&#228;heres dazu in Kapitel 4. Zu diesem Kapitel liegt ein Sondervotum aus der
Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 3.2 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220; (&#8222;KI in einf&#252;hrenden 
Szenarien &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo].
k&#246;nnen. Um diese drei wirtschaftlichen Akteursgruppen &#8211; neu gegr&#252;ndete Unternehmen bzw. Start-ups, KMU
und Konzerne &#8211; und darum, wie sie unterschiedlich und teils doch &#228;hnlich mit KI umgehen, geht es in den
folgenden Abschnitten. Anhand jeweils eines fiktiven Beispiels werden die Bedeutung von KI sowie die m&#246;glichen 
Herausforderungen f&#252;r Unternehmen dargestellt. Die nachfolgenden Szenarien sollen f&#252;r Probleme
sensibilisieren, die bei der KI-Einf&#252;hrung auftreten k&#246;nnen.
&#8226; Das Start-up &#8222;Smart Intelligence&#8220; im internationalen Wettbewerb
Das erste Szenario stellt ein fiktives junges Unternehmen vor, das den Namen &#8222;Smart Intelligence&#8220; tr&#228;gt. Es hat
sich vor zweieinhalb Jahren aus der Hochschule ausgegr&#252;ndet. Mitgenommen hat es eine neuartige KI-
Technologie zur Erkennung von manipulierten Fotos und Videos, an denen die drei Gr&#252;ndungsmitglieder vorher in
einem Forschungsprojekt mehrere Jahre geforscht hatten. Auf Basis dieser Technologie haben sie ein Produkt
gebaut, das genutzt werden kann, um die Authentizit&#228;t und Qualit&#228;t von Angeboten zu analysieren. Dieses Angebot
entwickeln auf der ganzen Welt noch knapp 20 andere Start-ups. 
Um die rechtliche Basis zu haben, die technische Innovation f&#252;r ihr Unternehmen nutzen zu k&#246;nnen, haben die
Gr&#252;nder mehrere Monate mit dem Gr&#252;ndungszentrum ihrer Universit&#228;t &#252;ber die Rechte am geistigen Eigentum
verhandelt. Nach nur sechs Monaten einigten sie sich auf eine Umsatzbeteiligung der Universit&#228;t von 5 Prozent
&#252;ber die n&#228;chsten drei Jahre.
Mithilfe mehrerer Investitionen von mehreren &#8222;Business Angels&#8220;, d. h. Privatpersonen, die ihr eigenes Kapital
in junge Unternehmen investieren, konnten die Gr&#252;nder das Unternehmen mit Infrastruktur und den ersten
Mitarbeiterinnen und Mitarbeitern st&#228;rken. Den Kontakt zu den &#8222;Business Angels&#8220; herzustellen und sie zu
&#252;berzeugen, hat die Gr&#252;nder &#252;ber ein halbes Jahr besch&#228;ftigt. Dazu haben sie auf Messen und Veranstaltungen ihre Idee
&#8222;gepitcht&#8220;463. 
Erste Pilotkunden, die das Produkt nutzen, hat das Unternehmen gefunden, die Markt-R&#252;ckmeldung ist
grunds&#228;tzlich gut. Ihr Produkt erm&#246;glicht es ihrer Zielgruppe, einen bisher manuellen Vorgang viel effizienter zu
gestalten. Aber das Produkt ist auch komplex und die Unsicherheit der Kunden bez&#252;glich KI gro&#223;. Diese Art der
Software ist unbekannt. Vor allem die Vorab-Investitionen, die f&#252;r ein KI-Projekt get&#228;tigt werden m&#252;ssen,
schrecken viele Kunden ab. Auch ist die Zur&#252;ckhaltung gro&#223;, mit einem Start-up zusammenzuarbeiten. 
Um weitere Kundenbeziehungen aufzubauen, muss das Unternehmen deshalb massiv in Vertrieb und Marketing
investieren. Daf&#252;r suchen die Gr&#252;nder nun nach neuem Kapital, in Summe etwa 10 Millionen Euro. Sie haben
ihr Unternehmen bereits bei mehr als 20 Venture-Capital-Fonds464 (VC-Fonds) vor allem in Berlin und M&#252;nchen
vorgestellt. Viele fanden ihre Idee gut, den Markt auch interessant, aber die Technologie unter
Sicherheitsaspekten mit Blick auf die Anwender noch nicht ausgereift genug. Eine Investition ist ihnen daher noch zu riskant. 
Eine &#246;ffentliche F&#246;rderung kommt aber aufgrund der Sicherheiten bzw. Eigenanteile, die gestellt werden m&#252;ssen, 
ebenfalls aktuell nicht infrage. Sollten die Jungunternehmer allerdings nicht in der Lage sein, das Kapital in den
n&#228;chsten sechs Monaten zu beschaffen, k&#246;nnen sie ihre Gesch&#228;ftst&#228;tigkeit nicht weiterf&#252;hren und ihre
Mitarbeiterinnen und Mitarbeiter nicht weiter besch&#228;ftigen. Die gute Entwicklung der ersten Jahre w&#228;re damit gestoppt.
Die internationale Konkurrenz, vor allem in den USA, in China und Israel hat besseren Zugang zu Kapital und 
kann deutlich gr&#246;&#223;ere Summen einwerben. Um nicht an Geschwindigkeit zu verlieren, spielen die Gr&#252;nder daher
mit der Idee, auch auf internationale VCs zuzugehen, wenn sie in Deutschland das Geld nicht einwerben k&#246;nnen.
Hierf&#252;r w&#252;rden sie auch die Verlegung ihres Sitzes ins Ausland in Kauf nehmen.
&#8226; Neue Chancen mit KI f&#252;r die Edel Manufaktur GmbH
Das zweite Szenario besch&#228;ftigt sich mit der &#8222;Edel Manufaktur GmbH&#8220; &#8211; ein fiktives, in den 1950er Jahren
gegr&#252;ndetes mittelst&#228;ndisches Unternehmen, das stolz auf seine Unternehmensgeschichte zur&#252;ckblickt. Da in der
Nachkriegszeit hoher Bedarf an neuen Produktionsanlagen existierte, entschloss sich das Ingenieurspaar Hans
und Hilde Edel damals, spezialisierte Sondermaschinen f&#252;r Unternehmen zu entwickeln und zu produzieren. Im
Lauf der Zeit hat sich die Firma auf zwei Kern-Industrien fokussiert, weil dort ihre Kompetenzen am st&#228;rksten 
wahrgenommen und nachgefragt wurden. In diesen beiden M&#228;rkten existieren heute nur wenige Wettbewerber,
da das hochspezialisierte Fachwissen &#252;ber den Entwicklungs- und Produktionsprozess selten bei anderen
Unternehmen zu finden ist. Die Edel Manufaktur GmbH ist Weltmarktf&#252;hrerin. 
463 Ein Pitch bezeichnet eine sehr kurze Pr&#228;sentation einer Gesch&#228;ftsidee vor einem m&#246;glichen Investor &#8211; oder auch vor Kunden,
Mitarbeiterinnen und Mitarbeitern, Partnern.
464 Venture-Capital bezeichnet ein Investment, das unter Verlustrisiko zur Finanzierung eines jungen Unternehmens eingesetzt wird.
Allerdings nimmt die heutige Gesch&#228;ftsf&#252;hrerin Heike Edel seit einiger Zeit wahr, dass im bislang
hochprofitablen Gesch&#228;ft der Wartung und Instandhaltung ausl&#228;ndische Firmen mittlerweile qualitativ gute und im Vergleich 
deutlich g&#252;nstigere Ersatzteile an ihre Gro&#223;kunden liefern. Daneben steigen auch die Anforderungen der Kunden
bei Ausschreibungen. W&#228;hrend die Maschinen fr&#252;her prim&#228;r zur Produktion von fest definierten Komponenten 
angefragt wurden, so wollen Kunden heute flexiblere Anlagen und Dienstleistungen. Diese sollen beispielsweise 
schnelle Umr&#252;st- und geringe Wartungszeiten aufweisen, eine konstante Fertigungsqualit&#228;t zusichern oder Daten
an integrierte Produktionsmanagement-Plattformen anliefern. Gerade der letzte Punkt stellt Edel Manufaktur vor
neue Herausforderungen, da sie mit anderen gr&#246;&#223;eren Herstellern von Maschinen und Industriesoftware, welche
teilweise auch Konkurrenten sind, viel st&#228;rker zusammenarbeiten m&#252;ssen, um Maschinendaten auszutauschen
und zu verwerten.
Das Thema Digitalisierung einschlie&#223;lich KI ist f&#252;r die Mitarbeiterinnen und Mitarbeiter und F&#252;hrungskr&#228;fte
kein grunds&#228;tzlich neues Thema. So existiert ein zentrales Finanz- und Warenwirtschaftssystem; auch ein kleines
spezialisiertes Team, welches die Software f&#252;r die Produktionsanlagen entwickelt, ist seit &#252;ber 30 Jahren
vorhanden. Die F&#252;hrungskr&#228;fte kennen das Thema KI und sind sich dessen prinzipieller M&#246;glichkeiten im Umfeld des
Maschinen- und Anlagenbaus bewusst. Allerdings sind vorhandene Ressourcen aufgrund des Tagesgesch&#228;fts
knapp, sodass man beschlossen hat, eine kleine Innovationsabteilung aufzubauen, welche KI-basierte
Neuerungen in interne Prozesse, aber auch produzierte Anlagen bringen soll. 
Auf die seit l&#228;ngerer Zeit ausgeschriebenen Stellen sind jedoch bislang kaum Bewerbungen eingegangen. Von
Gespr&#228;chen mit anderen Unternehmen in der Region wei&#223; Heike Edel, dass auch sie gro&#223;e Schwierigkeiten
haben, Personal im Bereich Entwicklung und Datenmanagement bzw. &#8211;analyse zu finden. Durch die Industrie- und
Handelskammer erf&#228;hrt sie, dass derzeit in der Fachhochschule der nahegelegenen Gro&#223;stadt ein
Innovationslabor aufgebaut wird. Beim geplanten Er&#246;ffnungsevent pr&#228;sentieren sich auch einige Technologie-Start-ups sowie
die involvierten Lehrst&#252;hle. Durch die Teilnahme an der Er&#246;ffnung kann Heike Edel einige Kontakte zu jungen
Gr&#252;nderinnen und Gr&#252;ndern, aber auch zum Professor eines Lehrstuhls f&#252;r angewandte KI herstellen.
Mit dem Professor vereinbart sie ein Forschungsprojekt f&#252;r das kommende Semester. Dabei sollen in einem
Modellversuch spezielle Sensoren an einen neuen Maschinentyp angebracht und zur Steuerung &#252;ber
Produktionsmanagement-Plattformen genutzt werden. Aber auch mit den Gr&#252;nderinnen und Gr&#252;ndern geht es nach dem
ersten Kennenlernen schnell voran. Die Mitarbeiterschaft von Edel Manufaktur ist erstaunt &#252;ber die schnelle
Zusammenarbeit und Umsetzung von verschiedensten Ideen zur Nutzung der heute bereits vorliegenden Daten.
Einige urspr&#252;ngliche Ans&#228;tze liefern zwar nicht sofort die erhofften Ergebnisse, aber es entwickeln sich nach
einigen Iterationen465 die ersten Szenarien, die der Mitarbeiterschaft bei Edel Manufaktur helfen werden, die
Qualit&#228;t ihrer heutigen schon sehr hochwertigen Arbeit weiter zu steigern. Die Zusammenarbeit mit den jungen
Gr&#252;nderinnen und Gr&#252;ndern f&#252;hrt auch dazu, dass sich einige erfahrene Mitarbeiterinnen und Mitarbeiter mit
bislang IT-fernen Arbeitsprofilen stark in die KI-Projekte einbringen und selbstst&#228;ndig den Wunsch entwickeln,
sich in den Themen weiterzubilden. Heike Edel und ihr Team haben es somit geschafft, in ihrer Firma den ersten
wichtigen Impuls zu geben, das Thema KI aktiv, gemeinschaftlich und offen anzugehen.
&#8226; Der Konzern &#8222;Move&#8220; und seine KI-Transformation
Das dritte fiktive Unternehmen, der Automobilkonzern &#8222;Move&#8220;, hat KI ebenfalls ganz oben auf die Agenda
gesetzt. Das kommt nicht von ungef&#228;hr. KI ist zu einer disruptiven Technologie angewachsen, ein &#8222;Game-
Changer&#8220;466, der die etablierten Gesch&#228;ftsmodelle infrage stellt und der den Newcomern einen alternativen
Markteintritt erm&#246;glicht. Zwei gro&#223;e Automobilunternehmen haben mit ihrer Gr&#252;ndung eines &#8222;Car Sharing&#8220;-Joint-
Ventures, mit dem sie auf neue KI-initiierte Markttrends reagieren, den Konzern &#8222;Move&#8220; darin best&#228;tigt, die
Anstrengungen auf dem KI-Gebiet noch weiter zu verst&#228;rken.
Die Macht der KI, potenziell jede Arbeit im Konzern positiv zu ver&#228;ndern, d. h. Arbeitsschritte effizienter zu
gestalten, eine h&#246;here Qualit&#228;t zu erm&#246;glichen und neue KI-Produkte zu entwickeln, gibt den Anstrengungen zur
Einf&#252;hrung von KI bei Move zus&#228;tzlichen Antrieb. Jedoch wird die Aufteilung der Arbeiten zwischen KI-
Innovationstechniken und laufenden Aktivit&#228;ten mit etablierten Technologien sorgf&#228;ltig ausbalanciert. Das Geld f&#252;r
die KI-Transformation muss verdient werden. Deshalb werden auch nicht alle m&#246;glichen KI-Anwendungen
gleichzeitig angegangen.
465 Iteration beschreibt allgemein einen Prozess mehrfachen Wiederholens gleicher oder &#228;hnlicher Handlungen zur Ann&#228;herung an eine 
L&#246;sung oder ein bestimmtes Ziel.
466 Ein Game-Changer ist eine Person, ein Unternehmen, ein Produkt oder eine Technologie, die starken Einfluss auf ein Spiel, eine
Branche oder einen Markt hat.
Die ersten Anwendungen von KI bei Move haben gezeigt, dass KI ein neues Werkzeug darstellt, das f&#252;r sich
allein nicht wirkt. Eine Mischung von KI- und Anwendungs-Know-how ist notwendig, um erfolgreich KI-
basierte Innovationen zu erarbeiten und in die Anwendung zu bringen. Dazu werden konzernweit KI-
Weiterbildungsaktivit&#228;ten gestartet, um in gro&#223;er Breite ein grundlegendes Verst&#228;ndnis von KI zu etablieren. Auch deshalb
wurden die KI-Aktivit&#228;ten nicht zentral definiert, sondern es wurde eine gemischt zentrale-dezentrale KI-
Einf&#252;hrung organisiert. Dar&#252;ber hinaus werden durch einen Inkubator gemeinsam mit Start-ups immer wieder
Innovationen ins Unternehmen transferiert. 
Bei der Herausforderung, Zugang zu den notwendigen Daten zu erhalten, sah sich Move aufgrund des etablierten
elektronischen Datenaustauschs und der Datenversionierung467 gut ger&#252;stet. Jedoch zeichnete sich schnell ab,
dass die verf&#252;gbaren Daten nicht f&#252;r das Anlernen der KI verwendet werden konnten. Die Daten mussten
restrukturiert und verkn&#252;pft, ein komplett neues Konzept der Datenspeicherung musste etabliert und ein Zugang
zu KI-Hardware aufgesetzt werden.
Obwohl KI-Techniken im Konzern bereits erfolgreich eingef&#252;hrt wurden, m&#252;ssen in der nahen Zukunft mehrere
grundlegende Probleme gel&#246;st werden, um die breite Einf&#252;hrung der KI nicht zu gef&#228;hrden. Es m&#252;ssen
Regelungen f&#252;r die Einbindung von KI in Prozesse und Produkte entwickelt werden, um ohne juristisches Risiko deren
Anwendung vorantreiben zu k&#246;nnen. Dringend werden Analyseverfahren ben&#246;tigt, um das Wirken der KI-
Technik zu verstehen, da viel Zeit auf ein &#8222;Trial-and-Error-Vorgehen&#8220; aufgewendet wird. Die Ausbildung darf nicht
nur KI isoliert sehen, sondern muss KI in einen Anwendungskontext setzen. Auch die Einstellung von KI-
Expertinnen und -Experten sowie -Spezialistinnen und -Spezialisten, die zudem in einem oder mehreren
Anwendungsbereichen versiert sind, stellt f&#252;r Move ein Problem dar. Denn die Entwicklerin bzw. der Entwickler einer
KI-basierten L&#246;sung f&#252;r eine energieeffiziente Motorsteuerung muss sowohl Expertise auf dem Gebiet KI als
auch auf den Gebieten Motor und Motorsteuerung besitzen.
Die bisherigen KI-Erfahrungen im Konzern best&#228;tigen, dass sich KI noch immer nahe dem H&#246;hepunkt der Hype-
Kurve befindet. Sie zeigen auf, dass noch ein weiter Weg f&#252;r eine komplette KI-Durchdringung des Konzerns
gegangen werden muss. Jedoch zeigen sich schon jetzt M&#246;glichkeiten f&#252;r neue Gesch&#228;fte und eine bessere
Position im weltweiten Wettbewerb. Auch oder gerade deshalb ist KI bei Move einer der strategischen Schwerpunkte.
Die Szenarien wurden gew&#228;hlt, um Anregungen f&#252;r die Zielsetzung und eine weitergehende Status-quo-
Betrachtung zu geben. Nach Darlegung der Zielstellung werden in den folgenden Kapiteln die Voraussetzungen und
Herausforderungen sowohl auf Akteursebene als auch branchenspezifisch anhand von repr&#228;sentativen Aussagen
betrachtet.
Zielstellungen: Deutschland im Jahr 2030 &#8211; eine Vision468 
Im Folgenden soll eine Vision f&#252;r Deutschland im Jahr 2030 aufzeigen, dass KI viele Wirtschafts- und
Lebensbereiche pr&#228;gen wird. Ob autonome Fahrzeuge auf den Stra&#223;en, kollaborative Roboter in der Produktion oder
innovative Diagnostik beim Arztbesuch &#8211; es ist davon auszugehen, dass sich diese Entwicklung in den
kommenden zehn Jahren enorm beschleunigen wird, weil Entwicklerinnen und Entwickler sowie Anwenderinnen und
Anwender rasante Fortschritte machen und immer ausgereiftere Konzepte f&#252;r KI kreieren. Im Jahr 2030 sollte
Folgendes erreicht sein:
Es haben sich vor allem solche KI-Technologien und Gesch&#228;ftsmodelle in Europa durchgesetzt, die einem
rechtlich und ethisch akzeptierten Standard folgen. Die Mehrheit der Bev&#246;lkerung konnte Vertrauen in KI fassen, da
KI das Leben der Menschen verbessert hat und so eine neue Aufbruchsstimmung in der Gesellschaft entstanden
ist.
467 Versionierung bedeutet hier, dass die Historie der &#196;nderungen von Daten gespeichert wird.
468 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 3.3 des Berichts der
Projektgruppe &#8222;KI und Wirtschaft&#8220; (&#8222;Zielstellungen: Deutschland im Jahr 2030 &#8211; eine Vision &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica 
Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo].
3.3.1 Angestrebte Gesellschafts- und Politikziele: Die Wirtschaft setzt KI unter Einhaltung 
ethisch vereinbarter Normen ein469 
Orientierung f&#252;r die F&#246;rderung und Regulierung des KI-Einsatzes in der Wirtschaft gaben die im Grundgesetz
niedergelegten Grundrechte, das Prinzip der Rechtsstaatlichkeit, die Prinzipien der sozialen Marktwirtschaft, die
gesellschaftlichen Vorstellungen des Gemeinwohls sowie die in den Jahren 2019 und 2020 in verschiedenen
Gremien auf nationaler und europ&#228;ischer Ebene diskutierten ethischen Prinzipien. Der in Europa verfolgte Ansatz
bei der KI-Implementierung zeichnet sich durch die intensive Kooperation aller zentralen wirtschaftlichen und
gesellschaftlichen Akteure aus. Unternehmen und staatliche Akteure haben klare Ethik-Leitlinien f&#252;r den Einsatz
von KI-Systemen definiert und kontrollieren Ergebnisse stetig. 
Durch Normierung und Klassifizierung von Aspekten ethischen Verhaltens werden KI-Entscheidungen f&#252;r den
Menschen nachvollziehbar und transparent gestaltet. KI-basierte Automatisierung hat die Souver&#228;nit&#228;t der
Nutzerinnen und Nutzer im Sinne einer &#8222;augmented human intelligence&#8220;470 erh&#246;ht, anstatt sie zu unterminieren. 
Auf diese Weise entwickeln und vertreiben deutsche Unternehmen jeder Gr&#246;&#223;e erfolgreich KI-Produkte und
-Dienstleistungen im In- und Ausland und tragen zur erfolgreichen Transformation der deutschen und
europ&#228;ischen Wirtschaft sowie zur digitalen Souver&#228;nit&#228;t der Menschen im Jahr 2030 bei. Sie setzen KI erfolgreich dazu
ein, Prozesse effektiver zu gestalten, die Arbeitsproduktivit&#228;t zu erh&#246;hen und neue Gesch&#228;ftsmodelle zu
entwickeln, um international wettbewerbsf&#228;hig zu sein.
Weiterhin erm&#246;glicht der Einsatz von KI auch eine effizientere Organisation von M&#228;rkten und hilft, irrationale
Marktentscheidungen zu verhindern, die auf einem Mangel an Informationen beruhen bzw. auf der Unf&#228;higkeit,
Informationen zielgerichtet auszuwerten. Dadurch wird das Risiko von Marktversagen reduziert und externe
Kosten wie Risiken k&#246;nnen bei Marktentscheidungen besser ber&#252;cksichtigt werden.
&#8226; Entwicklung von KI-Anwendungskompetenzen
Durch gezielte Aus- und Weiterbildung wurden Menschen dazu bef&#228;higt, KI-Systeme zu verstehen und zu
kontrollieren: Sie sind in der Lage, KI-Resultate nachzuvollziehen und einzuordnen, da sie sich theoretisches und
anwendungsorientiertes Wissen aneignen konnten. Zugleich wurde es ihnen erm&#246;glicht, F&#228;higkeiten und
Kompetenzen auszubauen, die Menschen auch in absehbarer Zukunft von Robotern unterscheiden. Aus- und
Weiterbildungsoffensiven haben entscheidend dazu beigetragen, dass Deutschland seinen Bedarf an Fachkr&#228;ften decken
konnte. Informatik und Data-Science sind l&#228;ngst als Schulf&#228;cher etabliert.
Um dar&#252;ber hinaus Fachkr&#228;fte in Deutschland auszubilden, die KI-Technologien erweitern, entwickeln und
gestalten k&#246;nnen, wurde ein &#214;kosystem geschaffen, das exzellente Grundlagenforschung und angewandte
Forschung in relevanten KI-Themenfeldern an Universit&#228;ten, Fachhochschulen und Unternehmen erm&#246;glicht. Starke
Kompetenzen in der Breite der Anwendungsfelder wie Robotik, Sprach- und Bildverarbeitung, smarte Sensoren
oder Edge-Computing471 runden die deutsche Exzellenz im KI-Themenfeld ab. Daneben werden in fast allen
Studieng&#228;ngen KI-Grundlagen vermittelt, w&#228;hrend in IT-Studieng&#228;ngen auch die gesellschaftlichen
Implikationen des Technologieeinsatzes gelehrt werden. Der EU- und der weltweite Fachkr&#228;fteaustausch tragen dazu bei,
dass deutsche Unternehmen Fachkr&#228;fte finden, die ausreichend qualifiziert sind.
&#8226; Auswirkungen auf den Arbeitsmarkt: KI und Menschen arbeiten Hand in Hand 
Digitalisierung und KI konnten die Arbeitswelt im positiven Sinne dynamisch ver&#228;ndern. Es wurden nicht
Menschen ersetzt, sondern T&#228;tigkeiten und dadurch wurden neue Freir&#228;ume und Arbeitsfelder geschaffen. Arbeits-
und Gesch&#228;ftsprozesse sowie Arbeitsstrukturen und -formen wurden vielerorts neu gestaltet und haben zur
Entlastung und Unterst&#252;tzung von Menschen gef&#252;hrt. Die Besch&#228;ftigten und ihre Betriebe sch&#228;tzen das neue Ma&#223;
an Autonomie bei der Wahl der Arbeitszeit und des Arbeitsortes. KI-Systeme haben dazu beigetragen, Familie 
und Beruf besser in Einklang zu bringen und Belastungen f&#252;r Umwelt und Mensch durch das Pendeln zur
Arbeitsst&#228;tte deutlich zu verringern.
469 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 3.3.1 des Berichts der
Projektgruppe &#8222;KI und Wirtschaft&#8220; (&#8222;Angestrebte Gesellschafts- und Politikziele: Die Wirtschaft setzt KI unter Einhaltung ethisch
vereinbarter Normen ein &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo].
470 Augmented human intelligence bedeutet die Erweiterung menschlicher Intelligenz und Handlungsf&#228;higkeit mit Unterst&#252;tzung durch
technische Hilfsmittel.
471 Edge-Computing bezeichnet im Gegensatz zum Cloud-Computing die dezentrale Datenverarbeitung, die am Rand des Netzwerkes
stattfindet.
Bei der Mitarbeiterschaft sto&#223;en KI-Anwendungen mittlerweile auf breite Akzeptanz. Daf&#252;r sorgen auch
Mitbestimmungsrechte bei der Konzeptionierung und Implementierung von KI-Anwendungen. Im gemeinschaftlichen
Diskurs werden die Algorithmen neu trainiert und ausgerichtet, um flexibel auf interne und externe
Anforderungen zu reagieren, etwa um die Arbeitsbelastung zu verringern, die Nachhaltigkeit zu steigern oder die Produktion 
passgenau auf die Nachfrage einzustellen.
Somit gelingt es durch KI, die Autonomie im Arbeitsalltag zu f&#246;rdern und Entscheidungen zu unterst&#252;tzen.
Weiterhin konnte die Inklusion von Menschen mit motorischen und kognitiven Einschr&#228;nkungen in den Arbeitsmarkt
durch KI-Anwendungen verbessert werden.
&#8226; Akzeptanz in der Gesellschaft / Auswirkungen f&#252;r Verbraucherinnen und Verbraucher: KI als akzeptierter
Begleiter des Menschen
Politische Akteure, Unternehmen sowie Vertreterinnen und Vertreter der Zivilgesellschaft haben sich bis zum
Jahr 2030 in einem offenen Diskurs auf ethische, soziale und &#246;kologische Leitplanken zum Einsatz von KI
verst&#228;ndigt. Dabei haben sich die Prinzipien der sozialen Marktwirtschaft bew&#228;hrt, wodurch der gesellschaftliche
Zusammenhalt gest&#228;rkt und Teilhabe gef&#246;rdert wurde.
Damit einhergehend wurde der Begriff KI in der Bev&#246;lkerung entmystifiziert und wird nun im Allgemeinen als
intelligente Software verstanden, die Menschen bei verschiedensten Aufgaben entlastet und dadurch f&#252;r
Anwenderinnen und Anwender Nutzen stiftet. Dies geschah auf der einen Seite insbesondere durch KI-Anwendungen,
die gem&#228;&#223; gesetzlichen Standards flexibel auf die Anforderungen der Menschen bei den Themen Ethik,
Datensouver&#228;nit&#228;t, Sicherheit und Transparenz eingegangen sind, und auf der anderen Seite mittels eines gestiegenen
Verst&#228;ndnisses von KI durch frei verf&#252;gbare Weiterbildungsangebote.
Negativen Effekten beim KI-Einsatz, wie beispielsweise Preisdiskriminierungen oder ungewollten
Beschr&#228;nkungen der Wahlfreiheit von Verbraucherinnen und Verbrauchern, konnte entgegengewirkt werden. Die Politik hat
durch Regulierung des Marktes dazu beigetragen, dass Verbraucherinnen und Verbraucher weiterhin von einem
global funktionierenden Wettbewerb der Unternehmen profitieren. Besonders positiv hat sich der Zugewinn an
Lebenszeit durch die verk&#252;rzten Arbeitszeiten und -wege ausgewirkt. Der trotz demografischer Ver&#228;nderungen
nun verf&#252;gbare menschliche Freiraum macht sich von der Pflege bis hin zum Vereinsleben und der Kultur
bemerkbar. 
Die flexiblen Mobilit&#228;tsangebote werden sowohl im st&#228;dtischen als auch l&#228;ndlichen Raum als Zugewinn an
Freiheit und Lebenszeit wahrgenommen. Durch die Verbindung von Mobilit&#228;t und Logistik konnte das
Versorgungsnetz in beiden Bereichen noch engmaschiger gekn&#252;pft werden. 
Die Anwendung von KI ist auch deshalb in der Gesellschaft akzeptiert, weil KI nicht dazu beigetragen hat, dass
die Einkommens- und Verm&#246;gensverteilung in Deutschland gemessen am Gini-Koeffizienten472 signifikant
ungleicher geworden ist. Stattdessen hat sich der Gini-Koeffizient verringert.
&#8226; Auswirkungen auf die &#214;kologie: KI f&#252;r eine ressourcenschonende Wirtschaftsweise
Der Einsatz von KI hat bis zum Jahr 2030 dazu beigetragen, die Energie- und Ressourceneffizienz in der
Wirtschaft zu erh&#246;hen und den Energie- und Ressourcenverbrauch in Deutschland und Europa im Einklang mit den
Zielen f&#252;r nachhaltige Entwicklung (SDGs) der Vereinten Nationen zu senken.473 Damit wurde nicht nur die
Wettbewerbsf&#228;higkeit von deutschen und europ&#228;ischen Unternehmen weiter gest&#228;rkt, sondern auch ein Beitrag
zur Bearbeitung &#246;kologischer Herausforderungen weltweit geleistet. KI-basierte Umwelt- und
Effizienztechnologie &#8222;made in Europe&#8220; wurde zum Exportschlager.
Innovative Anwendungen in den Bereichen der Umwelt- und Effizienztechnologie sowie staatliche Anreize f&#252;r
Green IT474 haben zur Begrenzung des Energie- und Ressourcenverbrauchs der IT beigetragen. Ein B&#252;ndel aus
politischen Ma&#223;nahmen, wie die Festsetzung des Preises f&#252;r den Energieverbrauch im Hinblick auf &#246;kologische
Notwendigkeiten, hat Anteil daran, dass das Einsparpotenzial an Ressourcen durch den Einsatz von KI nicht
472 Der Gini-Koeffizient ist ein statistisches Ma&#223;, das &#252;ber die Verteilung von Einkommen in einer Volkswirtschaft Auskunft gibt. Er
kann Werte zwischen 0 und 1 annehmen, wobei ein Wert von 0 einer totalen Gleichheit der Einkommensverh&#228;ltnisse entspricht &#8211;
alle verdienen somit gleich viel. Der Wert 1 w&#252;rde einen Zustand totaler Ungleichheit widerspiegeln, wobei sich das Einkommen
einer Volkswirtschaft auf eine Einzelperson konzentriert.
473 Weitere Informationen dazu unter: http://www.bmz.de/de/themen/2030_agenda/ (zuletzt abgerufen am 17. August 2020).
474 Green IT bezeichnet die ressourcenschonende Verwendung von Energie und Einsatzmaterialen in der Informations- und
Kommunikationstechnologie.
durch den Energiebedarf f&#252;r Rechenkapazit&#228;ten aufgehoben wurde. Bis zum Jahr 2030 ist es gelungen, eine
&#246;kologisch und sozial nachhaltige Beschaffung von Ressourcen aufzubauen, die f&#252;r Informations- und
Kommunikationstechnologie notwendig sind. 
3.3.2 Angestrebte Forschungsziele: KI-Forschung ist in Unternehmen etabliert
Durch KI- und Innovationsf&#246;rderung wurde wissenschaftliche Exzellenz ebenso gest&#228;rkt wie der Prozess der
Transformation von Wirtschaft und Gesellschaft in das digitale Zeitalter. F&#246;rdergelder und
Unterst&#252;tzungsleistungen der &#246;ffentlichen Hand werden im Einklang mit den Zielen der EU und der Vereinten Nationen vergeben.
Die in Deutschland angesiedelte KI-Forschung ist im Jahr 2030 ein Kraftzentrum der europ&#228;ischen KI-Forschung 
und ein bedeutsamer Teil einer globalen Forschungs-Community. Der gesellschaftliche Nutzen von KI konnte
durch den intensiven Austausch sowie das Teilen von Forschungsergebnissen erh&#246;ht werden. Es werden sowohl
Grundlagen f&#252;r neuartige KI-Methoden als auch anwendungsorientierte Forschung gef&#246;rdert, wobei
Unternehmen ihre Beitr&#228;ge f&#252;r Forschung und Entwicklung signifikant erh&#246;ht haben. Dies geschieht insbesondere
innerhalb von Technologie-Clustern, welche den Einsatz von KI-Anwendungen in Verbindung mit
Schl&#252;sseltechnologien, wie z. B. KI-Hardware, Sensorik, Quanten-Computing475 oder Blockchain, voranbringen.
Dabei konnten F&#246;rderprogramme in ihrer Umsetzung und Anwendung messbar beschleunigt und in ihrer Qualit&#228;t
verbessert werden. Es gibt zentrale Anlaufstellen f&#252;r eine vereinfachte Suche und f&#252;r Empfehlungen von
F&#246;rderprogrammen. Zudem werden Forschungsergebnisse besser in die praktische Anwendung &#252;bersetzt. 
Die Aktivit&#228;ten von Start-ups bei der Forschung und Entwicklung von KI-Anwendungen werden st&#228;rker
gef&#246;rdert. Auch wurde die B&#252;rokratie im Zusammenhang mit der Beantragung und Durchf&#252;hrung von F&#246;rderungen
abgebaut sowie die F&#246;rderrichtlinien so optimiert, dass sich Start-ups besser beteiligen k&#246;nnen.
3.3.3 Angestrebte Wirtschaftsziele: &#8222;KI made in Germany&#8220; als internationales G&#252;tesiegel476 
&#8226; Deutschland ist als KI-Standort im internationalen Wettbewerb f&#252;hrend
Deutschland hat sich auch und gerade durch eine erfolgreiche europ&#228;ische Zusammenarbeit im Bereich KI im
internationalen Wettbewerb erfolgreich eine starke Position im KI-Markt erarbeitet und vertreibt weltweit
gewinnbringend hochqualitative KI-Produkte und Dienstleistungen &#8222;made in Germany&#8220;. Die deutsche Wirtschaft 
hat insbesondere davon profitiert, dass es gelungen ist, einen einheitlichen europ&#228;ischen Rahmen f&#252;r KI zu
schaffen und vor allem in Zusammenarbeit mit Frankreich, aber auch anderen europ&#228;ischen Partnern die Potenziale
von KI-Anwendungen zu b&#252;ndeln.
Durch die konsequente Weiterf&#252;hrung der deutschen Ingenieurskunst ist KI-Technologie aus Deutschland zu
einem Markenzeichen geworden, das sowohl von KI-schaffenden Konzernen als auch von innovativen KMU
und KI-Start-ups gest&#252;tzt und gepr&#228;gt wird. Deutschland hat eine eigenst&#228;ndige wirtschaftliche Rolle im
internationalen Markt und ist nicht gezwungen, KI-Anwendungen und Infrastruktur allein aus dem Ausland
einzukaufen. 
Deutsche KI-Unternehmen entwickeln und vertreiben KI-Infrastruktur sowie KI-Anwendungen in allen
relevanten Bereichen und Industrien, wie u. a. in den Bereichen Mobilit&#228;t, Maschinenbau, Chemie, Gesundheit und
Landwirtschaft. Die entwickelten Anwendungen zeichnen sich dabei nicht nur durch technische Exzellenz,
sondern auch durch die in Standards und G&#252;tesiegeln ausgedr&#252;ckten ethischen Normen, wie den Datenschutz, sowie
den Einsatz von Green IT aus. Auch Medien- und private Bildungsanbieter haben durch den Umstieg ihre
Kundenbasis erweitern k&#246;nnen und sind mit neuen Gesch&#228;ftsmodellen erfolgreich.
Der Industrieanteil der deutschen Wirtschaftsleistung hat sich gegen&#252;ber dem Jahr 2020 erh&#246;ht. Durch die
Einf&#252;hrung von KI-Anwendungen in der industriellen Fertigung wurden Innovationen geschaffen. Die Anzahl
gemeinsamer Projekte von Industrie- und KI-Unternehmen hat sich gegen&#252;ber dem Jahr 2020 vervielfacht.477 
475 Quantencomputer interpretieren und verarbeiten Informationen anders als herk&#246;mmliche Computer. Der klassische PC arbeitet mit
einem bin&#228;ren System &#8211; die Daten werden in Bits gespeichert. Diese Bits k&#246;nnen lediglich zwei Zust&#228;nde annehmen: 1 (an) und
0 (aus). Im Quantumcomputing wird dagegen mit Quantenbits (Qubits) gearbeitet. Diese k&#246;nnen nicht nur einen Zustand, sondern
auch zwei zugleich &#8211; 1 und 0 &#8211; annehmen.
476 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 3.3.3 des Berichts der
Projektgruppe &#8222;KI und Wirtschaft&#8220; (&#8222;Angestrebte Wirtschaftsziele: &#8222;KI made in Germany&#8220; als internationales G&#252;tesiegel &#8220;) der
Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo].
477 Zwar liegt kein aktuelles Zahlenmaterial zur Zusammenarbeit von KI-Unternehmen und traditioneller Industrie vor. Die Anzahl der
KI-Start-ups, die im industriellen Sektor t&#228;tig sind, hat sich jedoch von 3,8 Prozent im Jahr 2018 auf 5,6 Prozent im Jahr 2019 erh&#246;ht.
Unterst&#252;tzt werden die in Deutschland agierenden Unternehmen durch vorhandene kooperative digitale
Datenplattformen, die an ethischen Leitbildern orientiert sind und unter Ber&#252;cksichtigung von Gesch&#228;ftsgeheimnissen 
und geistigem Eigentum entwickelt wurden. Auf ihnen k&#246;nnen Unternehmen und andere Akteure freiwillig
nichtpersonenbezogene Daten und KI-Erkenntnisse austauschen. Diese Plattformen bieten Unternehmen und anderen
Akteuren einmalige M&#246;glichkeiten in der Forschung und Entwicklung, die erfolgreich im Sinne der
Innovationskraft, der Wettbewerbsf&#228;higkeit und des Gemeinwohls eingesetzt werden. Sie sorgen insbesondere daf&#252;r, den
Konzentrations- und Monopolisierungstendenzen durch global agierende Digitalkonzerne wie den GAFAM-
Unternehmen478 entgegenzuwirken.
&#8226; Deutschland ist ein hochinnovatives KI-Land 
Es existiert eine gro&#223;e Innovationskraft von &#246;ffentlicher Verwaltung und von Unternehmen &#252;ber alle Branchen
hinweg, die die Gesellschaft dazu bef&#228;higt, mit der Geschwindigkeit des digitalen Wandels Schritt zu halten und
diesen zu gestalten.
So hat sich in vielen Absatzm&#228;rkten der Fokus vom klassischen Produktverkauf hin zu innovativen
Gesch&#228;ftsmodellen wie z. B. dem &#8222;Pay-per-Use&#8220;479 gewandelt. Dabei bieten viele Unternehmen intelligente Produkte und
intelligente Dienstleistungen an, welche sich in entsprechende &#252;bergreifende Plattformen und &#214;kosysteme
integrieren lassen. Daten bilden dabei die Grundlage f&#252;r unternehmerische Entscheidungen.
Unternehmen in Deutschland haben die Anpassung an eine Welt der exponentiellen Entwicklung digitaler
Technologie bereits vollzogen oder sich auf den Weg gemacht. Auch Mehrsprachigkeit und Barrierefreiheit sind durch
die Digitalisierung und durch KI-Technologien selbstverst&#228;ndlich geworden.
Ausdruck der Innovationskraft in Deutschland ist die signifikant gestiegene Anzahl und Qualit&#228;t von Patenten,
Ver&#246;ffentlichungen und Gr&#252;ndungen. Dabei leisten auch Best Practices zum &#246;ffentlichen Teilen von Patenten
unter Open-Source-Rahmenbedingungen und Open Data einen wesentlichen Beitrag f&#252;r kontinuierliche
Verbesserungen. Die Innovationskraft wird jedoch auch dadurch erh&#246;ht, dass in Erwerbsbiografien der Wechsel
zwischen der Wirtschaft, der &#246;ffentlichen Verwaltung und der Wissenschaft zur Regel geworden ist. Dies hilft allen 
Akteuren, ihr Wissen zu vernetzen und sich weiterzubilden.
In Deutschland ist man auf zwei erfolgreiche &#8222;Moonshot-Projekte&#8220;480 stolz. M&#246;gliche Moonshot-Projekte
k&#246;nnten die reibungslose Simultan&#252;bersetzung und eine qualit&#228;tsvolle Steigerung der Lebenserwartung aufgrund
gezielter Diagnose- und Therapieverfahren sein. Den Anwendungsfeldern ging eine &#246;ffentliche Beteiligung voraus,
in der erfragt wurde, in welchen Bereichen der gr&#246;&#223;te Bedarf gesehen wird. Dabei arbeiten verschiedene
Unternehmen aus Deutschland zusammen, die offen f&#252;r europ&#228;ische Kooperationen sind und bei der Umsetzung ihrer
Ideen vom Staat gef&#246;rdert wurden. Dabei haben sie gezeigt, wie sich durch die Verbindung von KI mit
jahrelangem Industriewissen gro&#223;e gesellschaftliche Probleme und Herausforderungen l&#246;sen lassen.
&#8226; Deutschland und Europa beherbergen ein attraktives KI-&#214;kosystem
Der KI-Standort Deutschland zeichnet sich als Teil und Kern eines europ&#228;ischen &#214;kosystems durch ein
funktionierendes Netzwerk von Wissenschaft, etablierten Unternehmen, Start-ups und Investoren aus, die
Datenpartnerschaften und Experimentierr&#228;ume geschaffen haben. Es existieren Zentren, welche Gr&#252;ndungen und die
Verzahnung von Forschung und Entwicklung neuer Produkte und Dienstleistungen f&#246;rdern und den Austausch zwischen
verschiedenen wirtschaftlichen Akteuren (Start-ups, KMU und Konzerne) und zwischen Wirtschaft und anderen
Akteuren, wie der Verwaltung, aktiv unterst&#252;tzen. Hieraus sind vertikale und horizontale Industrieplattformen 
mit den weltweit gr&#246;&#223;ten sicheren Datenpools f&#252;r segmentspezifische Daten entstanden. So werden
beispielsweise im international vernetzten Maschinen- und Anlagenbau die Prozess- und Betriebsdaten auf europ&#228;ischen
Plattformen geteilt.
Mehr Informationen dazu unter: https://www.unternehmertum.de/announcement/view/71875/62-mehr-ki-start-ups-in-deutsch-
land?lang=en (zuletzt abgerufen am 30. Juli 2020).
478 GAFAM steht f&#252;r die f&#252;nf gro&#223;en Konzerne der Tech-Branche: Google, Amazon, Facebook, Apple und Microsoft.
479 &#8222;Pay-per-Use&#8220; ist ein Abrechnungsmodell, bei dem die Kundin oder der Kunde nur die Leistung zahlt, die sie bzw. er tats&#228;chlich
nutzt.
480 Als Moonshot-Projekte werden besonders ehrgeizige, vision&#228;re und bahnbrechende Projekte bezeichnet.
Diese Plattformen sind somit von Coopetition481 gepr&#228;gt, sodass konkurrierende Unternehmen in einer
strategischen Kooperation im Sinne des Allgemeinwohls zusammenarbeiten. Diese intensivere Zusammenarbeit wird
ferner durch einen st&#228;rkeren Fokus auf Open-Source-Technologien und offene Standards als wesentliche
Infrastrukturelemente vorangetrieben. Weitere &#246;ffentliche Plattformen werden als Alternative zu
privatwirtschaftlichen Angeboten insbesondere in sensiblen Bereichen wie der Daseinsvorsorge oder der Kommunikation
vorangetrieben. 
In gezielt aufgebauten Experimentierr&#228;umen (&#8222;Sandboxes&#8220;) konnten Unternehmen leichter
Einsatzm&#246;glichkeiten von KI testen und diese weiterentwickeln.
&#8226; Eine innovationsfreundliche europ&#228;ische Datenstrategie ist etabliert
Deutschland hat sich in die Erarbeitung einer innovationsoffenen europ&#228;ischen Datenstrategie aktiv eingebracht.
Die Freiheit der Daten&#252;bertragung wurde als f&#252;nfte Freiheit des europ&#228;ischen Binnenmarktes etabliert. Daneben
wurden wettbewerbsrechtlich M&#246;glichkeiten geschaffen, die es Unternehmen erlauben, nicht-personenbezogene
Daten &#252;ber vertrauensw&#252;rdige Dritte auszutauschen, um mithilfe von KI neue Innovationen entwickeln zu
k&#246;nnen. Eine wichtige Rolle dabei spielen Datenplattformen, Datenpools bzw. Datengenossenschaften, mit denen
Unternehmen und andere Akteure freiwillig nicht-personenbezogene Daten oder anonymisierte Daten und KI-
Erkenntnisse austauschen. Um den Aufbau von neutralen und am Gemeinwohl orientierten Plattformen zu
erm&#246;glichen, wurden europaweit die regulatorischen Rahmenbedingungen geschaffen sowie genormte
Trainingsverfahren und einheitliche Standards f&#252;r Daten und Schnittstellen eingef&#252;hrt, die den
Monopolisierungstendenzen in der Technologiepolitik der digitalen &#214;konomie aktiv entgegenwirken und auf kooperative Modelle setzen.
Im Bereich des eng mit KI verbundenen notwendigen Datenmanagements nimmt Deutschland eine F&#252;hrungsrolle
ein. So erm&#246;glichen die intelligente (Meta-)Datenmodellierung, Methoden der zentralen und dezentralen
Datenverarbeitung sowie die nachvollziehbare L&#246;schung von nicht relevanten Daten eine Bandbreite an
unterschiedlichen KI-Methoden. Diese helfen besonders KMU, Daten ihres Produktionsprozesses zu erheben, zu analysieren
und Innovationen voranzutreiben. 
Hierdurch lassen sich auch in den jeweiligen Anforderungsgebieten spezifische Datenschutzziele einbeziehen,
die den erh&#246;hten Anforderungen an den Schutz personenbezogener Daten gerecht werden. Je nach kontextuellen
Bedingungen, die an Datenschutz und Datensicherheit gestellt werden, werden unterschiedliche KI-Methoden 
eingesetzt. So kann es je nach Kontext Ziel sein, mittels m&#246;glichst geringer Datenbest&#228;nde Erkenntnisse zu
gewinnen und umzusetzen. Es existieren klare rechtliche Rahmenbedingungen f&#252;r die maschinelle Verarbeitung
von Daten.
F&#252;r den KI-Einsatz gibt es europaweit einheitliche datenschutzrechtliche Rahmenbedingungen, die sowohl
staatliche &#220;berwachung als auch privatwirtschaftlichen Missbrauch personenbezogener Daten effektiv unterbinden.
Auf internationaler Ebene hat Deutschland entscheidend dazu beigetragen, dass die Normung von KI-Produkten
und dass Schnittstellen zum Datenaustausch vorangetrieben wurden und somit international anerkannte KI-
Normen bestehen.
&#8226; Deutschland f&#246;rdert innovative KI-Start-ups
Deutschland geh&#246;rt im Jahr 2030 im internationalen Vergleich zu den drei L&#228;ndern, die die h&#246;chste Anzahl von
qualitativ hochwertigen Gr&#252;ndungen von KI-Start-ups vorweisen k&#246;nnen. Darunter sind auch einige
Unternehmen, die mit mehr als 1 Milliarde Euro bewertet werden (sogenannte Einh&#246;rner). Dabei profitierten die
Gr&#252;nderinnen und Gr&#252;nder von den deutlich verbesserten staatlichen Rahmenbedingungen. 
481 Kooperation von Wettbewerbern im Sinne der Bildung von strategischen Allianzen, um durch die Bildung von Wertsch&#246;pfungsnetzen
Ertr&#228;ge zu stabilisieren bzw. zu optimieren. Coopetition verhindert einen ruin&#246;sen Preiswettbewerb und f&#252;hrt damit zu
Wettbewerbsvorteilen f&#252;r beide Anbieter (Win-win-Strategie).
So fand eine Vergr&#246;&#223;erung der Netzwerke zwischen Inkubatoren482, Investoren, Technologieanbietern sowie
Akteuren aus der Digitalwirtschaft unterschiedlicher Branchen und Gr&#246;&#223;en statt. Dabei wurden verst&#228;rkt
&#214;kosysteme f&#252;r Gr&#252;nderinnen und Gr&#252;nder geschaffen. Au&#223;erdem gibt es ein zentrales Monitoring von Start-ups und 
eine Zusammenarbeit in Clustern483, um die Akteure gezielt zu vernetzen.
Die &#246;ffentliche Verwaltung hat einen Transformationsprozess bew&#228;ltigt, der der innovativen Wirtschaft in
vielerlei Hinsicht zugutekommt: So wurden zum einen Zutrittsh&#252;rden im Vergabeprozess f&#252;r junge Unternehmen 
abgebaut, sodass der Zutritt f&#252;r die Gruppe der Start-ups als potenzielle Bieter vereinfacht ist. Zum anderen nutzt
die Verwaltung den Ideenreichtum der Start-ups f&#252;r sich selbst, indem sie Digitalisierungs- und KI-Projekte,
welche Verfahren vereinfachen und Transparenz st&#228;rken, mit Start-ups realisiert sowie digitale
Experimentierr&#228;ume innerhalb der Verwaltung eingerichtet hat, in denen neue Prozesse mit KI initiiert und implementiert
werden. Der Staat geht damit als Enabler f&#252;r KI-Anwendungen voran. 
Eine gro&#223;e Anzahl von Finanzierungsm&#246;glichkeiten gibt Gr&#252;nderinnen und Gr&#252;ndern die M&#246;glichkeit, ihre KI-
basierte Gesch&#228;ftsidee zu verwirklichen und ihr Unternehmen zu entwickeln. Die Anzahl privater
Risikokapitalgeber hat sich erh&#246;ht. In Deutschland beteiligen sich zwei oder mehr gro&#223;e Wachstumsfonds daran, dass sich der
prozentuale Anteil von Venture-Capital-Investitionen zum Bruttoinlandsprodukt (BIP) im Vergleich zum Jahr
2017 mehr als verdreifacht hat und somit Gr&#252;nderinnen und Gr&#252;ndern deutlich mehr lokale M&#246;glichkeiten haben,
Geld f&#252;r Wachstumsfinanzierungen aufzunehmen.484 Daneben existieren jedoch auch alternative
F&#246;rderm&#246;glichkeiten wie z. B. genossenschaftliche Fonds. Deutschland hat gemeinsam mit anderen Staaten einen europ&#228;ischen
Fonds initiiert.
&#8226; Benchmarks
Im Jahr 2030 ist es &#252;blich, auf verschiedene Benchmarking-Systeme zuzugreifen, um die Qualit&#228;t, den
regelgerechten Einsatz und die Ethikkonformit&#228;t der vielf&#228;ltigen auf dem Markt erh&#228;ltlichen KI-Anwendungen zu
beurteilen und zu vergleichen. Verbraucherberatungen nutzen diese beispielsweise, um das Ma&#223; an Transparenz und
die N&#252;tzlichkeit f&#252;r unterschiedliche Anforderungsfelder zu beurteilen. Arbeitnehmervertretungen nutzen
Benchmarking-Systeme, um sich ein Urteil dar&#252;ber zu bilden, ob eine KI-Anwendung die Gestaltungsans&#228;tze &#8222;Privacy 
by Design&#8220; und &#8222;Gute Arbeit by Design&#8220; unterst&#252;tzt. Der Wirtschaft stehen Beurteilungsma&#223;st&#228;be zur
Verf&#252;gung, um die Leistungsg&#252;te und die Wirkung auf Effizienz und Effektivit&#228;t f&#252;r Unternehmensprozesse zu
beurteilen sowie Einsch&#228;tzungen treffen zu k&#246;nnen, wie sich die verschiedenen KI-Anwendungen auf die
Qualifikationsanforderungen und das Besch&#228;ftigungsvolumen der eigenen Mitarbeiterinnen und Mitarbeiter auswirken.
In Anlehnung an den im Jahr 2020 verbreiteten &#8222;Corporate-Governance-Kodex&#8220;485 f&#252;r gute
Unternehmensf&#252;hrung wurde ein System ethischer Ma&#223;st&#228;be bereits als Instrument der Selbstregulierung der Wirtschaft
implementiert. Die Unternehmen haben sich dabei selbst Regeln gegeben, unter welchen ethischen Bedingungen KI
eingesetzt wird. Dazu z&#228;hlt beispielsweise der Anspruch, Kunden mitzuteilen, wenn sie mit einem KI-System
kommunizieren. Dazu z&#228;hlen aber auch Leitgedanken zur Diskriminierungsfreiheit, der Letztentscheidung und
Letztverantwortung des Menschen und der Anspruch an eine Folgenabsch&#228;tzung. Im DAX und MDAX haben
alle Firmen Erkl&#228;rungen abgegeben, dass sie mit dem Ethikkodex &#252;bereinstimmen.
4 Thematischer Schwerpunkt
Status quo von KI im Bereich der Wirtschaft
Dieses Kapitel analysiert den Status quo von KI im Bereich der Wirtschaft in Deutschland. Es werden zun&#228;chst
der Stand der Gesellschaft und der Stand der Forschung dargestellt. Der Schwerpunkt der Projektgruppe &#8222;KI und 
Wirtschaft&#8220; lag jedoch darauf, den Status quo des Marktes zu analysieren. Hierbei werden insbesondere einzelne
Marktakteure sowie f&#252;r KI besonders relevante Branchen thematisiert. Dar&#252;ber hinaus werden relevante Aspekte
482 Die Bezeichnung &#8222;Inkubator&#8220; im Rahmen der Unternehmensgr&#252;ndung kommt urspr&#252;nglich aus der Medizin. Hier wird eine Art
Brutkasten f&#252;r Fr&#252;hgeborene als Inkubator bezeichnet, der daf&#252;r sorgt, dass ein optimales Klima geschaffen wird, in dem die
Neugeborenen in Ruhe heranwachsen k&#246;nnen. Im &#252;bertragenen Sinne &#252;bernehmen Inkubatoren auch f&#252;r Unternehmensgr&#252;nder eine solche
Funktion. Denn Inkubatoren stellen dem Start-up eine Umgebung bereit, welche die optimalen Bedingungen erf&#252;llt, um erfolgreich 
in das Gesch&#228;ftsleben zu starten.
483 Als Cluster bezeichnet man die r&#228;umliche Konzentration miteinander verbundener Unternehmen und Institutionen innerhalb eines
bestimmten Wirtschaftszweiges.
484 In Deutschland betrug der Anteil von Venture-Capital-Investitionen im Jahr 2017 nur 0,035 Prozent des BIP, w&#228;hrend dies in den
USA ca. 0,37 Prozent waren (vgl. Bundesverband Deutscher Kapitalbeteiligungsgesellschaften e. V; Internet Economy Foundation;
Roland Berger GmbH (2018): Treibstoff Venture Capital, S. 20.) Diesen Wert gilt es auf &#252;ber 0,1 Prozent des BIPs zu erh&#246;hen.
485 Weitere Informationen dazu unter: https://www.dcgk.de/de/ (zuletzt abgerufen am 30. Juli 2020).
im Zusammenhang mit einer st&#228;rkeren Nutzung von KI in der Wirtschaft aufgegriffen, wie Datenmanagement
und Datenzugang, Hardware und Infrastruktur sowie &#214;kologie. Schlie&#223;lich wird analysiert, welche rechtlichen 
Rahmenbedingungen f&#252;r die Nutzung von KI vorhanden sind und wo gegebenenfalls Handlungsbedarf besteht.
4.1.1 Stand der Gesellschaft: Akzeptanz und Erwartungen
Deutschland befindet sich derzeit mitten in einer Transformation der Wirtschaft und Gesellschaft, die auch durch
gro&#223;en technischen Fortschritt gepr&#228;gt wird. Wie bei jedem Umbruch mit disruptiven Elementen werden auch
im Zuge von KI Chancen und Risiken intensiv diskutiert.
KI birgt ein gro&#223;es Potenzial f&#252;r die Wirtschaft, die Gesellschaft und das Individuum. KI kann betr&#228;chtliche
Ver&#228;nderungen ausl&#246;sen, auf die die Menschen ausreichend vorbereitet werden m&#252;ssen, damit sie sich rechtzeitig
darauf einstellen, aber auch mitgestalten k&#246;nnen. Die Zusammenarbeit zwischen Mensch und Computer definiert
sich neu und st&#246;&#223;t neue Wechselwirkungen innerhalb der Wirtschaft und Gesellschaft an. Im &#246;ffentlichen Diskurs
stehen Themen wie gesellschaftlicher Nutzen, Besch&#228;ftigung, Pers&#246;nlichkeitsrechte, Qualifikation, Privatsph&#228;re,
die Durchsetzung von ethischen Werten und vieles mehr.
Die zunehmende Nutzung von Daten und Algorithmen im Lebens- und Arbeitsalltag ver&#228;ndert auch ohne KI
bereits die Rahmenbedingungen des gesellschaftlichen Zusammenlebens. KI ist eine weitere Stufe dieser
Entwicklung. Diese kann sowohl dazu beitragen, dass die Chancengerechtigkeit, soziale Teilhabe und der
gesellschaftliche Zusammenhalt gest&#228;rkt werden486, als auch negative Effekte hervorrufen.487 
Die grundlegende Technologieakzeptanz in der Bev&#246;lkerung ist ambivalent. Sie dr&#252;ckt sich einerseits z. B. in
der verbreiteten individuellen Nutzung von Smartphones, Navigationssystemen, sozialen Medien oder im
Online-Shopping aus.488 Dies wird andererseits von einer Skepsis bez&#252;glich der gesamtgesellschaftlichen
Auswirkungen auch von KI begleitet.489 W&#228;hrend diese Skepsis teils einer Unkenntnis &#252;ber den technologischen
Sachstand geschuldet ist, speist sie sich auch aus tats&#228;chlichen Missst&#228;nden, die mit dem bisherigen Einsatz digitaler
Technologien einhergehen. Eine gesellschaftliche Vision und allgemein akzeptierte Orientierungswerte sind
nicht verbreitet. Immer deutlicher wird jedoch: Die gewinnbringende Anwendung von KI erfordert nicht nur eine
passive Akzeptanz, sondern eine aktive, inklusive Gestaltung durch alle gesellschaftlichen Akteure.
Daraus erw&#228;chst ein Gestaltungsauftrag, der in die Wirkungsmechanismen der Wirtschaft &#252;bersetzt werden muss.
Denn KI-Systeme allein aus &#246;konomischen Motiven zu forcieren, w&#252;rde grundlegende Leitlinien, die das
Gemeinwesen bisher getragen haben, in eine nachrangige Rolle dr&#228;ngen. Deshalb ist es wichtig, dass sich die
F&#246;rderung und Regulierung des KI-Einsatzes in der Wirtschaft insbesondere an den im Grundgesetz normierten 
Grundrechten, wie der Menschenw&#252;rde, der Selbstbestimmung, der Unversehrtheit, der Gewissensfreiheit oder
der Privatheit, orientieren und dass die gesellschaftlichen Ideale des Gemeinwohls, unsere demokratischen
Prinzipien und Grundwerte der sozialen Marktwirtschaft sowie die auf nationaler und europ&#228;ischer Ebene er&#246;rterten
ethischen Prinzipien zum Tragen kommen. 
Mit Blick auf den KI-Einsatz in Unternehmen werden insbesondere die folgenden drei Entwicklungen kritisch
reflektiert:
&#8226; Datenbasierte Gesch&#228;ftsmodelle
Es ist ein Trend zu beobachten, bei dem die Wertsch&#246;pfung erfolgreicher Unternehmen weniger auf &#8222;fixen
Assets&#8220;, sondern immer mehr auf &#8222;digitalen Assets&#8220; wie Software, Plattformen, Algorithmen und Daten basiert.490 
Erkennbar ist, dass KI-Technologien ein Katalysator f&#252;r datenbasierte Gesch&#228;ftsmodelle sind. In Deutschland 
entwickeln sich in diesem Zusammenhang neue technologiebasierte Start-ups z. B. in den Sektoren Handel, Lo-
486 Vgl. Dinklage et al. (2018): KI-Szenarien: Potenziale und Herausforderungen; McKinsey Global Institute (2018): Notes from the AI
frontier &#8211; Insights from hundreds of use cases; D64 &#8211; Zentrum f&#252;r Digitalen Fortschritt (2018): Der Einfluss K&#252;nstlicher Intelligenz 
auf Freiheit,Gerechtigkeit und Solidarit&#228;t.
487 Vgl. O'Neil (2016): Angriff der Algorithmen.
488 Vgl. aktuelle Zahlen dazu: Initiative D21 e. V. (2019): Digital Index 2018/2019. J&#228;hrliches Lagebild zur Digitalen Gesellschaft.
489 Vgl. verschiedene Umfragen wie Bitkom e. V. (2018): K&#252;nstliche Intelligenz &#8211; Von der Strategie zum Handeln; Inhoffen (2018):
K&#252;nstliche Intelligenz: Deutsche sehen eher die Risiken als den Nutzen; Digital Business Cloud (2019): Jeder zweite Deutsche ist
gegen&#252;ber KI skeptisch; Fischer und Petersen (2018): Was Deutschland &#252;ber Algorithmen wei&#223; und denkt &#8211; Ergebnisse einer
repr&#228;sentativen Bev&#246;lkerungsumfrage.
490 Das englische Wort &#8222;asset&#8220; bedeutet so viel wie Verm&#246;gensgegenstand oder Verm&#246;genswert, wie z. B. Aktien, Immobilien oder
Policen. Unter &#8222;fixen Assets&#8220; versteht man Anlageverm&#246;gen, also in der Regel greifbare betriebliche Sachanlagen, dagegen sind
&#8222;digitale Assets&#8220; eben Dateien, wie Bilder, Videos oder Pr&#228;sentationen, die f&#252;r ein Unternehmen einen Wert darstellen.
gistik, Gesundheit oder Mobilit&#228;t. Mithilfe von KI lassen sich Daten noch besser zusammenf&#252;hren und in
innovative und individualisierte Produkte und Dienstleistungen &#252;bersetzen. Allerdings ist es dabei f&#252;r
Verbraucherinnen und Verbraucher h&#228;ufig nicht transparent, an welcher Stelle Daten gesammelt und zur Zweitnutzung
weitergegeben bzw. verkauft werden sowie nach welchen Kriterien daraus Entscheidungen abgeleitet werden.
&#8222;Privacy by Design&#8220; und &#8222;Privacy by Default&#8220;491 in der &#8222;Daten&#246;konomie&#8220;492 richtig umzusetzen, ist mit Blick
auf die DSGVO eine herausfordernde Aufgabe.493 Unternehmen sind dabei, sich zu positionieren und Konzepte
zu entwickeln, wie sie KI f&#252;r ihre Prozesse, Produkte und Dienstleistungen einsetzen wollen. Datenschutz,
Datensouver&#228;nit&#228;t und soziale Verantwortung spielen dabei eine wichtige Rolle. Nur so l&#228;sst sich auf Dauer das
notwendige Vertrauen bei den Kundinnen und Kunden sowie den Mitarbeiterinnen und Mitarbeitern aufbauen.
Die Gestaltungsarbeit tr&#228;gt dem Umstand Rechnung, dass datenethische Aspekte nicht in allen
Anwendungsf&#228;llen gleicherma&#223;en relevant sind. Hier muss gerade mit Blick auf den KI-Einsatz eine st&#228;rkere Differenzierung
vermittelt werden. Denn es macht einen Unterschied, ob Daten genutzt werden, um einen Fertigungsprozess in
einer Maschine zu optimieren oder um z. B. eine medizinische Diagnose zu erstellen.494 
Die Ziele, die Pers&#246;nlichkeit zu sch&#252;tzen und das Vertrauen von Anwenderinnen und Anwendern sowie
Nutzerinnen und Nutzern zu gewinnen, erfordern transparente Mechanismen zur Erhebung, Verarbeitung und Nutzung
von Daten. Damit wird die Basis geschaffen, um ad&#228;quate Regulierungsbedingungen u. a. durch kollektive
Normung, Betriebsvereinbarungen und Benchmarking-Systeme aufzubauen. Dies kann gesetzgeberische
Normsetzung erg&#228;nzen und tr&#228;gt dem Differenzierungsanspruch Rechnung. 
&#8226; Die Konzentration von Wertsch&#246;pfungsertr&#228;gen
KI entwickelt sich zunehmend zum relevanten Wirtschaftsfaktor. Erkennbar ist: Der Einsatz von KI-Systemen
wird in vielen Branchen eine pr&#228;gende Rolle einnehmen und die Wettbewerbschancen von Unternehmen
beeinflussen. Die Treiber f&#252;r den Einsatz von KI sind f&#252;r Unternehmen vorrangig qualitative, organisatorische und
wirtschaftliche Ziele, wie Kosteneffizienz, Produktivit&#228;t und Leistung, Analyse- und Planungssicherheit, Qualit&#228;t
und Zuverl&#228;ssigkeit, bessere Arbeitsteilung sowie Innovationsf&#228;higkeit und Skalierbarkeit. Wirtschaftliche
Prosperit&#228;t verkn&#252;pft sich aber auch mit neuen Gesch&#228;ftsmodellen.495 
Die Wissensextraktion ist an die Verf&#252;gbarkeit gro&#223;er Datenmengen gebunden. Dadurch werden gro&#223;e
Datenkonzerne &#252;berproportional bevorzugt &#8211; wodurch die Gefahr besteht, dass es zu einer erheblichen Konzentration
von Einfluss oder gar zur Monopolisierung von M&#228;rkten kommt. Auch aufgrund von Defiziten bei der
Besteuerung von GAFAM-Unternehmen innerhalb der EU f&#252;hrt dies bereits heute zu Verzerrungen von
Wettbewerbschancen und der Ungleichverteilung von Wertsch&#246;pfungsertr&#228;gen.
&#8226; Ver&#228;nderung der Arbeitswelt durch KI
Die Vorstellung einer starken KI, die den Menschen g&#228;nzlich ersetzt, weil sie ihm in allen Belangen &#252;berlegen 
ist, ist heute Science-Fiction. Aktuelle Umfragen zeigen, dass die Menschen mehrheitlich noch kein vertieftes
Verst&#228;ndnis von KI haben, aber dem Einsatz von KI zur Unterst&#252;tzung in vielen Lebensbereichen wie
Gesundheitsversorgung, Mobilit&#228;t oder Verwaltung &#252;berwiegend positiv gegen&#252;berstehen und sich der Tragweite von
KI-Anwendungen f&#252;r die Wettbewerbsf&#228;higkeit von Unternehmen bewusst sind.496 
491 &#220;bersetzt hei&#223;t Privacy by Design &#8222;Datenschutz durch Technikgestaltung&#8220; und greift den Grundgedanken auf, dass sich der
Datenschutz am besten einhalten l&#228;sst, wenn er bereits technisch bei Erarbeitung eines Datenverarbeitungsvorgangs integriert ist. Privacy 
by Default hei&#223;t &#252;bersetzt &#8222;Datenschutz durch datenschutzfreundliche Voreinstellungen&#8220; und bedeutet, dass die Werkeinstellungen
datenschutzfreundlich auszugestalten sind. So sollen nach dem Grundgedanken insbesondere die Nutzerinnen und Nutzer gesch&#252;tzt
werden, die weniger technikaffin sind.
492 Vgl. Spiekermann (2019): Chancen und Herausforderungen in der Daten&#246;konomie, S. 16.
493 Die Fraktion B&#220;NDNIS 90/DIE GR&#220;NEN stellt hierzu fest, dass es &#8211; ein Jahr nach Inkrafttreten der DSGVO &#8211; noch keine
hinreichende Datengrundlage f&#252;r die l&#228;ngerfristigen Auswirkungen auf KMU gibt.
494 Hierbei muss allerdings ber&#252;cksichtigt werden, dass auch Industriedaten (Maschinen- und Prozessdaten) unter Umst&#228;nden
personenbezogene Daten enthalten k&#246;nnen, vgl. Darstellung von David Kriesel (Datenwissenschaftler) in der Sitzung der Projektgruppe &#8222;KI 
und Wirtschaft&#8220; am 8. April 2019 &#252;ber das Projekt &#8222;SpiegelMining&#8220;, das verdeutlicht, dass der Inhalt von Metadaten nicht
untersch&#228;tzt werden darf; vgl. auch Schwemmle und Wedde (2018): Alles unter Kontrolle? Arbeitspolitik und Arbeitsrecht in digitalen 
Zeiten &#8211; WISO Diskurs 2/2018.
495 F&#252;r deutsche Unternehmen wird es zunehmend wichtiger, KI nicht auf operative Einsatzszenarien zu beschr&#228;nken, sondern st&#228;rker
im Kontext der Digitalisierung anzuwenden; vgl. International Data Corporation (2019): IDC Studie: Deutsche Unternehmen nutzen 
KI zur Prozessoptimierung, Innovation wird vernachl&#228;ssigt.
496 Vgl. Bitkom e. V. (2018): K&#252;nstliche Intelligenz &#8211; Von der Strategie zum Handeln.
Verschiedenste Studien zur grunds&#228;tzlichen Wirkung der Digitalisierung werden verallgemeinernd der Wirkung 
von (schwachen) KI-Systemen zugeschrieben und best&#228;rken eine skeptische Grundhaltung in Teilen der
Bev&#246;lkerung.497 Thematisiert werden u. a. der m&#246;gliche Verlust von Arbeitspl&#228;tzen, Qualifikationsniveau und
Anschlussf&#228;higkeit. Es bestehen zwar berechtigte Zweifel an der Aussagekraft vieler verf&#252;gbarer Prognosen, da es
eine Vielzahl von Einflussgr&#246;&#223;en und offenen Entscheidungen &#252;ber den KI-Einsatz gibt. Es ist jedoch
unbestreitbar, dass der Einsatz von KI in Unternehmen einen wirtschaftlichen Strukturwandel mit offenem Ausgang in
Gang setzt. Die Geschwindigkeit der Ver&#228;nderung verst&#228;rkt die Wahrnehmung, dass der digitale Wandel eine
Unab&#228;nderlichkeit ist mit der Folge, dass die Gesellschaft sich anpassen und die Wirtschaft sich Sachzw&#228;ngen
beugen m&#252;sse. Dabei ist gesellschaftliche Einflussnahme ebenso erw&#252;nscht wie notwendig.
Die gemeinwohlorientierte Nutzung von KI ist kein Selbstl&#228;ufer, sondern eine gesellschaftliche
Gestaltungsaufgabe. Dabei gilt es, die KI-Prozesse in den Unternehmen so zu gestalten, dass Arbeitgeber- und
Arbeitnehmerinteressen bestm&#246;glich miteinander vereinbart werden k&#246;nnen. Bereits im Jahr 2013 hat die Enquete-
Kommission des Deutschen Bundestages &#8222;Internet und digitale Gesellschaft&#8220; Problemfelder f&#252;r die Mitbestimmung
ermittelt, die aus der Digitalisierung erwachsen, etwa die Entbetrieblichung der Arbeit498, die Steigerung der
Verlagerungsf&#228;higkeit von Arbeitsvolumen und Standorten, die Herausforderungen f&#252;r Pers&#246;nlichkeitsrechte im
Betrieb und die Erosion der Wirkung der herk&#246;mmlichen Mitbestimmungsrechte zu maschineller Leistungs- und 
Verhaltenskontrolle.499 KI-Systeme als eine erweiterte Erscheinungsform der Digitalisierung, die
Arbeitsprozesse selbst steuern, werden auch Einfluss auf die von Arbeitnehmerinnen und Arbeitnehmern zu erbringende
Arbeitsleistung haben. Zudem wird erwartet, dass der Einsatz von KI-Systemen zu ver&#228;nderten
Qualifikationsanforderungen im Betrieb f&#252;hren wird. In diesem Zusammenhang wird darauf verwiesen, dass wirksame
Mitbestimmungsrechte, der Zugang von Mitbestimmungstr&#228;gerinnen und -tr&#228;gern zu Expertenwissen und Instanzen
sowie erweiterte Initiativrechte bei der Ein- und Durchf&#252;hrung der betrieblichen Berufsausbildung notwendig
sind.500 
Aus diesen &#220;berlegungen wird deutlich, dass mit KI ein breites Spektrum an M&#246;glichkeiten erschlossen werden
kann, somit auch eine h&#246;here Arbeits- und Lebensqualit&#228;t und hochwertige Besch&#228;ftigungsm&#246;glichkeiten auf
Basis passender Aus- und Weiterbildung (&#8222;Gute Arbeit by design&#8220;).501 
In einem integrierenden Prozess ist es die Aufgabe, gemeinsame Antworten auf Basis unserer gesellschaftlichen
Grundwerte f&#252;r die skizzierten Problemfelder und Potenziale zu finden.
4.1.2 Stand der Forschung
4.1.2.1 Die Herausforderungen einer holistischen KI-Forschung und -Entwicklung
Technologische Durchbr&#252;che im Bereich der Hardware und der Informatik sind das Fundament einer
erfolgreichen KI-Forschung. Als moderne Schl&#252;sseltechnologie findet KI au&#223;erordentlich vielf&#228;ltige Anwendungsfelder,
wodurch besondere Anforderungen an eine holistische Herangehensweise und an disziplin&#252;bergreifende
Entwicklungsprozesse entstehen:
&#8226; KI-Anwendungen bauen auf Komponenten auf, die von vielf&#228;ltigen Akteuren entlang der gesamten &#8222;KI-
Wertsch&#246;pfungskette&#8220; aus Hardware, den Techniken und Methoden zur Bereitstellung und Verarbeitung
497 Vgl. Fischer und Petersen (2018): Was Deutschland &#252;ber Algorithmen wei&#223; und denkt &#8211; Ergebnisse einer repr&#228;sentativen
Bev&#246;lkerungsumfrage; Grzymek und Puntschuh (2019): Was Europa &#252;ber Algorithmen wei&#223; und denkt &#8211; Ergebnisse einer repr&#228;sentativen
Bev&#246;lkerungsumfrage.
498 Der Begriff &#8222;Entbetrieblichung&#8220; beschreibt die Verlagerung von Wertsch&#246;pfung &#252;ber das Netz auf Personen und Leistungsprozesse,
die au&#223;erhalb des herk&#246;mmlichen, r&#228;umlich fixierten Betriebes, ans&#228;ssig sind, beziehungsweise Telearbeiterinnen und Telearbeiter,
Freiberuflerinnen und Freiberufler, Crouwdsourcees, Arbeitsvermittlungsplattformen.
499 Vgl. Achter Zwischenbericht der Enquete-Kommission &#8222;Internet und digitale Gesellschaft&#8220; &#8211; Wirtschaft, Arbeit, Green IT,
Bundestagsdrucksache 17/12505.
500 Vgl. Deutscher Gewerkschaftsbund (2018): Stellungnahme zu den Eckpunkten der Bundesregierung f&#252;r eine Strategie K&#252;nstliche
Intelligenz vom 18. Juli 2018. F&#252;r weitere Ausf&#252;hrungen zur Mitbestimmung siehe den Bericht der Projektgruppe &#8222;KI und Arbeit,
Bildung, Forschung&#8220;.
501 Vgl. Deutscher Gewerkschaftsbund (2019): K&#252;nstliche Intelligenz und die Arbeit von morgen; vgl. ebenfalls die Darstellung von 
Chris Boos (arago GmbH) in der Sitzung der gesamten Enquete-Kommission am 1. April 2019: Die Ver&#228;nderungen durch KI w&#252;rden 
den Menschen Zeit und Freir&#228;ume zur&#252;ckgeben. Es gebe aber Bereiche, in denen KI nie so gut sein werde wie der Mensch. Dazu
geh&#246;ren laut Boos die Feinmotorik, Kreativit&#228;t und alle Interaktionen von Mensch zu Mensch, die auf Empathie und Emotionen 
basieren.
von Daten, den allgemeinen KI-Anwendungen (wie z. B. Algorithmen zur Bilderkennung, der
Nachverfolgung usw.) und den spezifischen KI-L&#246;sungen, die f&#252;r bestimmte Dom&#228;nen entwickelt wurden.502 Hieraus
entstehen besondere Herausforderungen der Kooperation unterschiedlicher Akteure zwischen
Grundlagenforschung und Praxis in komplexen Wertsch&#246;pfungsnetzwerken.
&#8226; Auch innerhalb eines Betriebes sind bei KI-Projekten typischerweise eine ganze Reihe von Akteuren
involviert, um die Prozesse, die Technologieentwicklung und ggf. die Forschungsf&#246;rderung zu begleiten
(Fachabteilung, Rechtsabteilung, IT, Gesch&#228;ftsleitung). H&#228;ufig k&#246;nnen am Anfang des Projektes die Erwartungen
und Anforderungen an das oder die KI-Systeme von keinem der Akteure klar formuliert werden. Oft ist
auch noch Forschungsarbeit n&#246;tig, um eine passende L&#246;sung zu finden. Hier sind Pilotphasen zur
Kommunikation mit den Entwicklerinnen und Entwicklern in Workshops, Think Tanks503 o. &#196;. hilfreich.
&#8226; Aufgrund der Charakteristika des Maschinellen Lernens h&#228;ngt die Qualit&#228;t von KI-Anwendungen nicht nur
von Innovationen der technologischen Schl&#252;sselkomponenten ab, sondern vom Zugang zu
dom&#228;nenspezifischen Datens&#228;tzen und der Anpassung der Anwendungen an die jeweiligen Aufgabenbereiche. KI-
Technologien stellen f&#252;r sich keine universellen L&#246;sungen bereit. Der Erfolg der wirtschaftlichen Verwertung
von KI- Forschungsergebnissen h&#228;ngt vielmehr wesentlich davon ab, dass diese iterativ auf spezifische
Aufgabenbereiche zugeschnitten werden. Dies erfordert zum einen die F&#228;higkeit zum interdisziplin&#228;ren Dialog;
zum anderen muss es Wechselwirkungen zwischen Grundlagenforschung und Anwendungsgebieten geben.
KI-Forschung muss somit holistisch betrieben werden, von den mathematischen Grundlagen bis hin zu den
angewandten Technologien, Medizin und Sozialwissenschaften, die den Unterbau f&#252;r die Anwendung
liefern.
&#8226; KI, die ethischen Anforderungen gen&#252;gen soll, muss die Interessen verschiedener Stakeholder und
normative Anforderungen fr&#252;hzeitig in den Entwicklungsprozess mit einbeziehen. Dies erfordert einerseits
Fortschritte im Bereich der erkl&#228;rbaren KI (&#8222;explainable AI&#8220;) und andererseits die Sensibilit&#228;t der an Forschung
und Entwicklungen beteiligten Akteure gegen&#252;ber den gesellschaftlichen Anspr&#252;chen an KI-Entwicklung.
&#8226; Schlie&#223;lich ist auf die bereits erw&#228;hnte Problematik hinzuweisen, dass Unternehmen sich im permanenten
Spannungsfeld zwischen innovativen und etablierten Produkten befinden. Dies erschwert die Forschung an
Anwendungen, die erst in mittlerer Zukunft Ertr&#228;ge abwerfen. Unternehmen vergeben infolgedessen
vermehrt Forschungsauftr&#228;ge an Universit&#228;ten. KI verst&#228;rkt diesen Trend und die Transferproblematik &#8211;
letztlich die Umsetzung von Forschungsergebnissen in die Anwendung &#8211; weiter und stellt somit h&#246;here
Anforderungen an die Governance504 von Kooperationen zwischen Unternehmen und Forschungseinrichtungen.
&#8226; Im Vergleich zu &#8222;klassischer&#8220; Forschung an real existierenden Objekten (Werkstoffen, Bakterien usw.)
unterscheidet sich die Forschung an Algorithmen und Daten auch in der Umsetzung der Ergebnisse. L&#246;sungen
oder Durchbr&#252;che in der Grundlagenforschung sind oft auch relativ zeitnah globale Produkte ohne
Reproduktions- oder Lagerkosten. Dies erh&#246;ht den Druck auf das klassische Patentwesen und den Wissenstransfer,
da Geschwindigkeit an sich bereits eine Art Patent geworden ist.
Die immer komplexer werdende Technik mit KI als einer Spitze des Eisbergs erfordert also Entscheidungen und
Aktionen in einer neuen Sph&#228;re ohne exakte Kenntnis der Folgen und mit oftmals unklaren Zust&#228;ndigkeiten. Wie
sieht es mit dem Transfer aus der Forschung in die Wirtschaft aus?
4.1.2.2 Diversit&#228;t als St&#228;rke? Die deutsche Akteurslandschaft in Forschung und Entwicklung
&#220;ber lange Zeit war KI ein Nischenthema. Das Interesse der Industrie am Transfer durch etwaige
Technologiesch&#252;be entwickelte sich wellenf&#246;rmig, auch durch zum Teil entt&#228;uschte Erwartungen. W&#228;hrend beispielsweise
Mitte der 1980er Jahre noch verschiedene Industrie-Labs bei gro&#223;en Firmen existierten, wurden diese
kontinuierlich, schlie&#223;lich fast vollst&#228;ndig abgebaut. Erst die neue Welle der KI hat dazu gef&#252;hrt, dass derzeit viele
Firmen versuchen, wieder eigene Labs zu installieren. Dabei kommt es zu gro&#223;en Schwierigkeiten, da es an
Fachkr&#228;ften mangelt.
502 Vgl. Vortrag Roy Uhlmann (Bundesverband Deutsche Startups e. V.), Kommissionsdrucksache 19(27)37 vom 1. April 2019.
503 Als Thinktank (Denkfabrik) werden Institute bezeichnet, die durch Erforschung, Entwicklung und Bewertung von politischen,
sozialen und wirtschaftlichen Konzepten und Strategien Einfluss auf die &#246;ffentliche Meinungsbildung nehmen und sie so im Sinne von 
Politikberatung f&#246;rdern.
504 Der Begriff &#8222;Governance&#8220; umfasst die Art und Weise, wie Entscheidungen getroffen und Inhalte formuliert und umgesetzt werden.
Da KI-Projekte, wie bereits beschrieben, oft nicht eindeutig der Forschung oder Entwicklung zuzurechnen sind,
ist auch die Art und Anzahl der Akteure in Transferaktivit&#228;ten relativ heterogen. Diese reichen von der
Grundlagenforschung etwa bei Max-Planck-Instituten &#252;ber die angewandte Grundlagenforschung und den Transfer am
Deutschen Forschungszentrum f&#252;r K&#252;nstliche Intelligenz (DFKI) bis hin zur rein anwendungsorientierten
Entwicklung bei den Fraunhofer-Instituten und den Industrie-Labs. Einen &#220;berblick gibt die KI-Landkarte der
Plattform Lernende Systeme.505 Als F&#246;rderinstrumente zum Transfer dienen z. B. verschiedene regionale Cluster, 
Kompetenzzentren f&#252;r KI-Forschung, Digital Hubs506 oder Mittelstand-4.0-Kompetenzzentren. Eine &#220;bersicht
&#252;ber die Transferprogramme bietet die Plattform &#8222;German Digital Technologies&#8220;. 507 Diese sind teilweise
themenspezifisch, regional oder betreffen den Mittelstand.
Der wissenschaftliche Output und das damit verbundene Potenzial f&#252;r den Transfer in die Wirtschaft werden
gemeinhin als sehr gut eingesch&#228;tzt. Gleichzeitig ist der Transfer im internationalen Vergleich nicht so
erfolgreich. Die Gr&#252;nde liegen allerdings h&#228;ufig nicht nur in der unzureichenden Kooperation von Forschung und
Industrie, sondern auch in fehlendem Kapital (Start-ups), fehlender Innovationskultur (z. B. Rapid Prototyping508),
Fachkr&#228;ftemangel und allgemeiner Skepsis gegen&#252;ber dem digitalen Wandel.
Ein Problem der beschriebenen heterogenen F&#246;rder- und Akteurslandschaft liegt darin, dass oft anstelle eines
gemeinsamen nationalen Auftretens eher wechselseitige Missgunst zwischen regionalen Akteuren im Kampf um
F&#246;rdermittel oder aufgrund lokalpolitischer Alleing&#228;nge die treibende Kraft ist. Das ist ein Argument daf&#252;r, dass
das internationale Forschungsmarketing f&#252;r deutsche KI unterentwickelt ist. Eine Ausnahme bildet das Thema
&#8222;Industrie 4.0&#8220;, f&#252;r das Deutschland international eine hohe Reputation genie&#223;t.
Durch die industrielle Konkurrenz insbesondere internationaler Player f&#228;llt es der universit&#228;ren und
au&#223;eruniversit&#228;ren Forschung zunehmend schwer, Personal zu rekrutieren und zu halten. W&#228;hrend das aus wirtschaftlicher
Sicht vielleicht kurzfristig nicht problematisch ist, besteht mittelfristig die Gefahr, dass Deutschland seinen Platz
in der Spitzenforschung nicht mehr behaupten kann. 
Weitere Hindernisse, die auch, aber nicht nur den Transfer behindern, sind fehlende (Forschungs-)
Dateninfrastrukturen, fehlende oder zu b&#252;rokratische F&#246;rderbedingungen und anderes.509 
4.1.2.3 Bestehende Ans&#228;tze zur F&#246;rderung von KI in Forschung und Entwicklung
Mit der im Dezember 2018 ver&#246;ffentlichen Strategie der Bundesregierung zur Umsetzung von KI, der finalen
Fassung des Berichts der Datenethikkommission, der neuen Agentur f&#252;r Sprunginnovationen sowie der
Industriestrategie des Bundeswirtschaftsministeriums und erg&#228;nzenden europ&#228;ischen Initiativen liegen
unterschiedliche politische Ans&#228;tze und Handlungsanweisungen f&#252;r den Umgang mit KI sowie f&#252;r deren F&#246;rderung vor. Das
Ziel &#8222;KI made in Germany&#8220; erh&#228;lt dadurch einen deutlichen R&#252;ckhalt.
&#8226; Die Datenethikkommission hat wichtige Fragen rund um das komplexe Themenfeld &#8222;Datennutzung,
Datenbeschaffung, Datenrecht&#8220; behandelt und ihre Ergebnisse im Abschlussgutachten ver&#246;ffentlicht.510 
&#8226; Weiterhin gibt die nationale &#8222;Strategie K&#252;nstliche Intelligenz&#8220; der Bundesregierung seit Ende des Jahres
2018 einen Rahmen f&#252;r alle Bestrebungen in Forschung, Gesellschaft und Wirtschaft vor.511 Forschung und 
die F&#246;rderung sowie Entwicklung von (mittelst&#228;ndischen) Unternehmen haben einen hohen Stellenwert. So
will die Bundesregierung ein starkes, wettbewerbsf&#228;higes &#214;kosystem f&#252;r die Forschung aufbauen, indem
sie mit Ma&#223;nahmen wie zus&#228;tzlichen 100 Professuren (die ersten 30 sind gerade ausgeschrieben512) bis hin
zu zw&#246;lf sogenannten KI-Zentren und Anwendungshubs erfolgreich sein will. Auch f&#252;r Unternehmen 
m&#246;chte die Bundesregierung laut Strategie einiges umsetzen. Neben der Verdoppelung des Etats f&#252;r EXIST-
505 Weitere Informationen dazu unter: https://www.plattform-lernende-systeme.de/ki-landkarte.html (zuletzt abgerufen am
30. Juli 2020).
506 Ein Hub beschreibt ein Zentrum, an dem verschiedene Unternehmen, Organisationen bzw. Personen mit unterschiedlichen
Kompetenzen und Hintergr&#252;nden an einem Themenkomplex, h&#228;ufig im Bereich digitale Innovation, zusammenarbeiten.
507 Weitere Informationen dazu unter: https://germandigitaltechnologies.de/digital-landscape/transfer-and-initiatives (zuletzt abgerufen
am 30. Juli 2020).
508 Rapid Prototyping bezeichnet eine Methode zur schnellen Herstellung eines Prototypen.
509 Siehe hierzu auch das Kapitel 9 des Mantelberichts [KI und Forschung].
510 Vgl. Datenethikkommission der Bundesregierung (2019): Gutachten der Datenethikkommission der Bundesregierung.
511 Die Fortschreibung der KI-Strategie der Bundesregierung ist f&#252;r Herbst 2020 angek&#252;ndigt.
512 Vgl. Schubert (2019): Bis zu 30 neue KI-Professuren.
Existenzgr&#252;ndungen aus der Wissenschaft will sie das Angebot f&#252;r Venture Capital erweitern oder durch
Leuchtturmprojekte bessere Anreize f&#252;r innovative Unternehmen schaffen.513 
&#8226; Zus&#228;tzlich ist die Nationale Industriestrategie 2030514 aus dem BMWi an einer modernen Industriepolitik
ausgerichtet und muss sowohl auf nationaler wie auf europ&#228;ischer Ebene im Einklang mit den bew&#228;hrten 
Prinzipien der sozialen Marktwirtschaft stehen als auch die richtigen Rahmenbedingungen f&#252;r die
Wirtschaft setzen, gezielt auf Schl&#252;sseltechnologien wie die KI eingehen und sich auf globaler Ebene f&#252;r freien
Handel und gleichberechtigte Regeln beim Marktzugang einsetzen.515 
&#8226; Die Agentur f&#252;r Sprunginnovationen verfolgt einen personenzentrierten Ansatz. Sie setzt auf
hochkompetente und kreative K&#246;pfe, die zeitlich befristet in der Agentur t&#228;tig sind und besondere Handlungsfreir&#228;ume
genie&#223;en. Sie k&#246;nnen Forschungs- und Entwicklungsvorhaben mit hohem Potenzial von der Idee m&#246;glichst
bis hin zur Anwendung ausw&#228;hlen, steuern und &#8211; je nach Projektverlauf &#8211; beenden oder fortsetzen.
Hochschulen, au&#223;eruniversit&#228;re Forschungseinrichtungen und Unternehmen setzen die Vorhaben um. Gef&#246;rderte
Ideen werden &#252;ber Ausgr&#252;ndungen, durch Unternehmen oder auch durch den Staat selbst im Rahmen der
&#246;ffentlichen Beschaffung verwertet und in den Markt eingef&#252;hrt.516 
&#8226; Die europ&#228;ische KI-Initiative CLAIRE zielt auf die europ&#228;ische Exzellenz in der KI-Forschung und bei KI-
Innovationen. CLAIRE m&#246;chte das mit einem paneurop&#228;ischen B&#252;ndnis von KI-Forschungslaboren &#228;hnlich 
dem CERN &#8211; dem CLAIRE-Hub &#8211; schaffen. Dieser soll neue und bestehende Nachwuchskr&#228;fte f&#246;rdern und
einen Schwerpunkt f&#252;r den Austausch und die Interaktion von Forscherinnen und Forschern bilden. Das soll
den Wissenstransfer zwischen europ&#228;ischen Forscherinnen und Forschern erleichtern und st&#228;rken.517 
&#8226; Die europ&#228;ische Initiative AI4EU baut seit Mitte des Jahres 2019 eine zentrale Plattform f&#252;r KI in Europa
auf. AI4EU zielt darauf ab, die europ&#228;ische Exzellenz und eine weltweit f&#252;hrende Position in wichtigen 
Bereichen der KI-Forschung und -Anwendung zu st&#228;rken. Das Projekt bietet Orientierung f&#252;r die KI-
Forschung, ist Impulsgeber f&#252;r technologische Innovation und liefert ethische Leitlinien f&#252;r die Entwicklung in
den n&#228;chsten Jahrzehnten in Europa.518 
Fakt ist, dass unterschiedliche nationale Umsetzungsstrategien, Plattformen und Agenturen, die die
(forschungsorientierte) Wirtschaft um KI in den Fokus r&#252;cken, bereits bestehen. Wie diese harmonieren und welche
Synergieeffekte die notwendigen Bem&#252;hungen erzielen, bleibt bis zur ersten Evaluation dieser Konzepte offen. 
4.1.3 Stand des Marktes519 
KI ist eine Querschnittsdisziplin, weshalb eine stringente Eingrenzung einer globalen &#8222;Marktgr&#246;&#223;e f&#252;r KI&#8220;
grunds&#228;tzlich schwierig ist. W&#228;hrend eine IDC-Studie von einem globalen Marktvolumen von 37,5 Milliarden 
US-Dollar im Jahr 2019 f&#252;r Software im Bereich kognitiver Systeme und KI ausgeht520, wird in einer Bitkom-
Studie mit Blick auf Europa der Markt f&#252;r Deep-Learning-Anwendungen und Dienstleistungen auf ein Volumen
von 3 Milliarden US-Dollar f&#252;r das Jahr 2019 beziffert.521 Dabei gibt es neben Anbietern, welche ihre
hochskalierbaren KI-Cloud-Infrastrukturen zur Verf&#252;gung stellen, eine Vielzahl von KI-Dienstleistungsunternehmen,
anwendungsorientieren Software- und IT Firmen, Entwicklungsplattformen und KI-Hardwareherstellern.
Insgesamt ist ersichtlich, dass diese Segmente starkes Wachstum aufweisen.
513 Weitere Informationen dazu unter: https://www.ki-strategie-deutschland.de/home.html (zuletzt abgerufen am 30. Juli 2020).
Bedauerlicherweise ist seit Ende des Jahres 2018 nicht viel umgesetzt worden. Die angek&#252;ndigten 3 Milliarden Euro, die f&#252;r die Umsetzung
bis zum Jahr 2025 investiert werden sollten, hat der Bundesfinanzminister schnell nach unten korrigiert. Bis zum Jahr 2023 sind es
nun nur noch 1 Milliarde Euro (vgl. Gillmann (2019): Die Bundesregierung st&#252;mpert bei der KI-F&#246;rderung).
514 Vgl. Bundesministerium f&#252;r Wirtschaft und Energie (2019): Industriestrategie 2030.
515 Die finale Fassung der Industriestrategie 2030 wurde nach Abschluss der Arbeit der Projektgruppe ver&#246;ffentlicht. Daher konnte die 
Projektgruppe nicht abschlie&#223;end beurteilen, wie sich die Industriestrategie 2030 in das Gesamtkonstrukt der bestehenden Konzepte 
um die Schl&#252;sseltechnologie KI einf&#252;gt.
516 Weitere Informationen dazu unter: https://www.bmbf.de/de/agentur-fuer-sprunginnovationen-9677.html (zuletzt abgerufen am
18. August 2020).
517 Weitere Informationen dazu unter: https://claire-ai.org/?lang=de (zuletzt abgerufen am 30. Juli 2020).
518 Weitere Informationen dazu unter: https://www.ai4eu.eu/ (zuletzt abgerufen am 30. Juli 2020).
519 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 4.1.3 des Berichts der
Projektgruppe &#8222;KI und Wirtschaft&#8220; (&#8222;Stand des Marktes &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen
Mitglieds Dr. Florian Butollo].
520 Vgl. International Data Corporation, 4. September 2019.
521 Vgl. European Information Technology Observatory (2018): AI in Europe &#8211; Ready for Take-off.
Auch f&#252;r den deutschen Markt gibt es hohe Erwartungen, wie KI-Anwendungen die Entwicklung von Industrien 
und Branchen beeinflussen werden: Im Jahr 2019 k&#246;nnte bei rund 221 Milliarden Euro Umsatz in Deutschland
KI im Spiel sein &#8211; davon allein 45,4 Milliarden Euro in der Automobilproduktion.522 
In der &#246;ffentlichen Wahrnehmung dominieren die gro&#223;en (internationalen) Digitalunternehmen, welche sowohl
KI-Infrastruktur zum Betrieb von KI-Standardl&#246;sungen, aber auch KI-Entwicklungsumgebungen bereitstellen. 
Heute dominieren den Markt f&#252;r Cloud- und KI-Infrastrukturen in Europa und (Nord-)Amerika insbesondere die
amerikanischen Technologie-Unternehmen wie Microsoft, Google und die Amazon-Tochter Amazon Web
Services. Dies zeigt auch der sogenannte GAFAM-Index der amerikanischen B&#246;rse. Alle f&#252;nf GAFAM-
Unternehmen zusammen erreichten im Mai 2019 eine Marktkapitalisierung von 4,2 Billionen US-Dollar &#8211; in Summe das
Vierfache aller DAX-Konzerne. Dabei sind alle diese gigantischen Unternehmen erst wenige Jahrzehnte alt. Dies
sagt zwar wenig &#252;ber die eigentliche Unternehmensgr&#246;&#223;e aus; gemessen am Umsatz schafft es aus der Reihe der
GAFAM nur Apple in die Top 20 der weltweit gr&#246;&#223;ten Unternehmen. Es macht aber deutlich, welches
Entwicklungspotenzial diesen Unternehmen &#8211; auch aufgrund ihrer Agilit&#228;t im Bereich KI &#8211; zugesprochen wird.
Mit ihrer Cloud-Infrastruktur teilen sich Amazon, Google und Microsoft &#252;ber 50 Prozent des Marktes.523 Allein
auf Amazon Web Services entf&#228;llt dabei rund ein Drittel. Allerdings ist eine Differenzierung in Bezug auf reine
KI-Anwendungen auch hier schwierig, da verschiedenste Angebote von Speicherplatz, Rechenkapazit&#228;ten und
KI-Komponenten h&#228;ufig gemeinsam vertrieben werden. Solche Produktb&#252;ndelungen, die Cloud-Infrastrukturen
sowie verschiedene KI-Dienstleistungen als Paket mitbringen, sind f&#252;r viele Unternehmen in diesem Bereich der
schnellere und deutlich kostensparendere Weg. Im Bereich der Cloud- und KI-Dienstleistungen ist in den letzten
Jahren ein neues Marktsegment entstanden, welches eine hohe Wachstumsdynamik aufweist. Kunden k&#246;nnen
dabei lediglich auf die Cloud- und Speicherdienstleistungen der Anbieter, f&#252;r die reine Programmierung von KI
aber auch auf Inhouse-L&#246;sungen zur&#252;ckgreifen. 
Der Anwendung von KI wird in existierenden und neuen Prozessen, Produkten und Dienstleistungen innerhalb
aller Branchen eine strategische Rolle zugesprochen. Viele Firmen nutzen KI als Erg&#228;nzung ihres
Kerngesch&#228;ftsmodells bzw. ihrer Kerndienstleistung. Auch deshalb gilt: Es ist schwierig ein bestimmtes Segment- bzw.
Marktwachstum direkt der KI zuzuschreiben. KI gilt zudem als Beschleuniger f&#252;r neue Felder und M&#228;rkte. So spielt
KI in allen Gesch&#228;ftsfeldern, sei es im Maschinenbau durch die intelligente Vernetzung im Rahmen von Industrie
4.0, in der Mobilit&#228;tsindustrie mit dem autonomen Fahren oder dem intelligenten Management von
Leihfahrzeugen bis hin zu intelligenten Haushaltsger&#228;ten jeglicher Form, eine tragende Rolle in der Umsetzung.
Der chinesische Markt ist neben dem amerikanischen der dynamischste im Bereich KI. Das Land plant bis zum
Jahr 2030 die f&#252;hrende KI-Nation der Welt zu werden und laut seinem ver&#246;ffentlichten &#8222;New Generation of
Artificial Intelligence Development Plan&#8220; durch KI &#252;ber 59 Milliarden US-Dollar zus&#228;tzliche &#246;konomische
Wertsch&#246;pfung zu generieren.524 Global sind insbesondere Alibaba und Tencent bereits unter den Top 10 der
Cloud-Infrastruktur-Anbieter vertreten. Parallel ist Baidu einer der am schnellsten wachsenden Anbieter auf dem
chinesischen Markt und h&#228;lt mittlerweile mehr Patente im Feld der Deep-Learning-Anwendungen als alle
anderen Unternehmen weltweit.525 Der grunds&#228;tzliche Ansatz im chinesischen Markt unterscheidet sich dabei von 
dem in den USA: W&#228;hrend jenseits des Atlantiks im Bereich KI allgemein auf die freie Entwicklung des Marktes
gesetzt wird, versucht der chinesische Staat mittels aktiver Regulierung und gezielter wirtschaftspolitischer
Steuerung eher die Entwicklung zu kontrollieren und zu lenken. 
In der Betrachtung der Relevanz von KI f&#252;r die Wertsch&#246;pfung und das Wachstumspotenzial kann bei
grunds&#228;tzlicher Betrachtung unterschieden werden zwischen KI-Anwendungen zu Effizienzsteigerungen der laufenden
Prozesse &#8211; der sogenannten Prozessinnovation &#8211; und zum anderen der Nutzung von KI zur sogenannten
Gesch&#228;ftsmodellinnovation.
522 Vgl. Brandt (2019): K&#252;nstliche Intelligenz rechnet sich; Auch einige neuere Studien gehen von einem Wachstum durch KI aus
(vgl. eco &#8211; Verband der Internetwirtschaft e. V und Arthur D. Little (2020): K&#252;nstliche Intelligenz &#8211; Potenzial und nachhaltige
Ver&#228;nderung der Wirtschaft in Deutschland). Die Folgen der Corona-Pandemie auf das Wirtschaftswachstum sind in diesen Studien nicht
untersucht.
523 Vgl. Synergy research group (2019): Chasing Pack Gain Market Share in Q1 but Amazon Maintains a Clear Lead.
524 Vgl. Webster et al.: China&#8217;s Plan to &#8216;Lead&#8217; in AI: Purpose, Prospects, and Problems; European Chamber of Commerce in China 
(2017): China Manufacturing 2025 &#8211; Putting Industrial Policy Ahead of Market Forces; Konrad-Adenauer-Stiftung (2018): Vergleich
nationaler Strategien zur F&#246;rderung von K&#252;nstlicher Intelligenz &#8211; Teil 1.
525 Vgl. Weltorganisation f&#252;r Geistiges Eigentum (2019): Artificial intelligence.
Prozessinnovation zielt meist auf Produktivit&#228;tssteigerungen ab: KI-Anwendungen werden eingesetzt, um
bislang manuell vorzunehmende, sich wiederholende Aufgaben zu ersetzen oder Anwenderinnen und Anwender bei
der Erbringung ihrer Aufgaben intelligent zu unterst&#252;tzen. Beispiele hierf&#252;r sind neue Formen der flexiblen
Automatisierung (modulare Fertigung, &#8222;intelligente&#8220; Steuerung von Fertigung und Logistik, Automatisierung von
sich wiederholender geistiger Arbeit (Sachbearbeitung, Chatbots etc.), der Einsatz cyberphysischer Systeme526 
sowie Verfahren des Maschinellen Lernens zur Mustererkennung (Predictive Maintenance527,
Qualit&#228;tskontrolle). Insgesamt setzen deutsche Unternehmen im internationalen Vergleich &#252;berdurchschnittlich oft Process-
Robotic-Automation-Anwendungen&#8220; (robotergesteuerte Prozessautomatisierung) ein, um vorhandene Abl&#228;ufe,
welche heute noch manuelle Dateneingaben von Menschen erfordern, intelligenter zu automatisieren.528 Dies 
wird u. a. durch die deutlich erh&#246;hte Verf&#252;gbarkeit von Rechenleistung und Durchbr&#252;chen im Bereich der
intelligenten Mustererkennungen erm&#246;glicht, beispielsweise bei Sprache oder Bilderkennung. Hierdurch werden
einzelne bestehende Prozesse bereits heute deutlich effektiver gestaltet.
Parallel arbeiten Unternehmen daran, datenbasierte und intelligente Gesch&#228;ftsmodellinnovationen
voranzubringen. Insbesondere reicht es nicht mehr aus, blo&#223; Daten zu sammeln; diese m&#252;ssen strukturiert und ausgewertet
werden, um zu einem &#8222;digitalen Asset&#8220; f&#252;r ein Unternehmen zu werden. Nur so k&#246;nnen tragf&#228;hige
Gesch&#228;ftsmodelle aus der Analyse der Daten entstehen. Dies erfordert Kooperationen der Tr&#228;ger des jeweiligen
sektorspezifischen Spezialwissens und der spezialisierten Unternehmen im Feld der Datenanalyse, oft auch in Form einer
Kooperation oder einer Akquise von Start-ups.
Allerdings ist die Annahme verbreitet, dass KI-F&#228;higkeit ein wesentliches Kriterium der Konkurrenzf&#228;higkeit
werden wird. Zur Frage, welches Potenzial KI in welchem Zeitrahmen wirklich entfalten kann, gibt es noch keine
aussagekr&#228;ftigen Prognosen.529 Kritische Stimmen setzen dem &#8222;Hype&#8220; um KI entgegen, dass Potenziale
&#252;bertrieben dargestellt w&#252;rden, da es diese entweder so nicht gebe bzw. nie geben werde. Grunds&#228;tzlich besteht bei
einer &#252;berhitzten Diskussion immer auch die Gefahr von unproduktiven Investitionen. Es ist somit fraglich, ob 
sich die theoretisch denkbaren Produktivit&#228;tssteigerungen auch vollst&#228;ndig realisieren lassen, da zudem in vielen 
Betrachtungen Investitionskosten und grundlegende praktische Schwierigkeiten der Anpassung an konkrete
Prozesse nicht ber&#252;cksichtigt werden. Somit liegt es nahe, dass in naher Zukunft im Bereich KI nicht alles umgesetzt 
wird, was sich theoretisch umsetzen lie&#223;e, weil es &#246;konomisch nicht vielversprechend sein k&#246;nnte. So m&#252;ssen
Potenziale z. B. im Bereich des Maschinellen Lernens aufgrund fortbestehender Entwicklungshemmnisse,
Grenzen bei der Mustererkennung sowie hoher Ressourcen- und Datenanforderungen realistisch eingesch&#228;tzt werden.
Unabh&#228;ngig davon bewirkt allein die Diskussion um KI selbst, dass sich Wirtschaft, Arbeitnehmerinnen und
Arbeitnehmer sowie Politik gesamtheitlich nicht nur intensiv mit den technologischen Aspekten von KI, sondern
auch mit dem Thema &#8222;Verteilungsgerechtigkeit und Gestaltungsoptionen f&#252;r faire digitale M&#228;rkte&#8220; besch&#228;ftigen.
4.1.3.1 Akteure im Markt: Start-ups, KMU und Konzerne
Im Folgenden werden die drei bereits in den einf&#252;hrenden Szenarien fiktiv dargestellten Akteure &#8211; Start-ups, 
Mittelstand und gro&#223;e Konzerne &#8211; n&#228;her betrachtet. Es wird erl&#228;utert, in welchem Ausma&#223; die Nutzung von KI
durch die jeweiligen Akteure derzeit verbreitet ist und mit welchen besonderen Gegebenheiten und
Herausforderungen die drei Akteure konfrontiert sind.
526 Ein cyber-physisches System bezeichnet den Verbund informatischer, softwaretechnischer Komponenten mit mechanischen und 
elektronischen Teilen, die &#252;ber eine Dateninfrastruktur, wie z. B. das Internet, kommunizieren.
527 Predictive Maintenance (deutsch: vorausschauende Instandhaltung) verfolgt als eine der Kernkomponenten von Industrie 4.0 einen 
vorausschauenden Ansatz und wartet Maschinen und Anlagen proaktiv, um Ausfallzeiten niedrig zu halten. Das Verfahren nutzt
hierf&#252;r Messwerte und Daten, die von Sensoren erfasst werden.
528 Vgl. Deloitte (2019): Deutsche Unternehmen setzen bei K&#252;nstlicher Intelligenz auf clevere L&#246;sungen &#8222;von der Stange&#8220;.
529 Darstellung von Prof. Dr. Philipp Staab (Humboldt-Universit&#228;t zu Berlin und Einstein Center Digital Future) in der Sitzung der
Projektgruppe &#8222;KI und Wirtschaft&#8220; am 1. April 2019.
4.1.3.1.1 Themenfeld Start-ups530 
Start-ups kommt eine wichtige Rolle beim Transfer von Innovationen in tragf&#228;hige Gesch&#228;ftsmodelle und damit
bei der Kommerzialisierung von technischen Innovationen zu. Dies gilt ganz besonders auch f&#252;r den Bereich
KI.531 
F&#252;r ein Start-up ist die Finanzierung einer der wichtigsten Faktoren f&#252;r den Erfolg. Die Standardfinanzierung
eines klassischen Start-ups ist das Venture-Capital (VC). Dabei verkauft das Start-up Unternehmensanteile im 
Gegenzug zu einer Investition, die sp&#228;ter bei einem Verkauf (Exit) oder B&#246;rsengang des Unternehmens eine
Rendite erwirtschaften. W&#228;hrend seines Lebenszyklus wird ein erfolgreiches VC-Start-up mehrere
Finanzierungsrunden durchlaufen, von der Seed-Finanzierung532 &#252;ber die Series-A-, Series-B- und Series-C-Runden, in
denen die Investition aufgrund der Gr&#246;&#223;e und des Kapitalbedarfs des Unternehmens jeweils steigt. Seed-
Finanzierungen k&#246;nnen bereits mit einem Volumen unter 100 000 Euro beginnen und bis zu 2 Millionen Euro gehen,
Series-A-Finanzierungen sind etwa in der Gr&#246;&#223;enordnung 3 bis 10 Millionen Euro, Series-B ab etwa 10 bis
30 Millionen Euro anzusetzen usw.
Es gibt aber auch Alternativen zu der VC-Finanzierung. So k&#246;nnen vor allem in der Seedphase und der Fr&#252;hphase
auch einzelne Privatpersonen, sogenannte Business Angels, das Unternehmen unterst&#252;tzen. Auch staatliche
F&#246;rderung kann gerade in den fr&#252;hen Phasen eines Start-ups ein wichtiges Finanzierungsinstrument sein. Als letzte
Form sei noch das sogenannte Bootstrapping genannt, bei dem sich Gr&#252;nderinnen und Gr&#252;nder komplett ohne
fremde Hilfe finanzieren und das Unternehmen aus eigener Kraft w&#228;chst.
&#8226; Aktuelle Situation
Sowohl weltweit als auch in Deutschland hat die Zahl der KI-Start-ups in den letzten Jahren kontinuierlich
zugenommen. Eine Studie von Roland Berger zusammen mit dem VC-Fond &#8222;Asgard&#8220; aus dem Jahr 2017533 kommt
zu dem Ergebnis, dass die USA bei Neugr&#252;ndungen im Bereich KI f&#252;hrend sind, China aufholt, Israel
verh&#228;ltnism&#228;&#223;ig viele Start-ups im Bereich KI aufzuweisen hat und Europa hinterher ist. Andere Studien zeigen ein
vergleichbares Bild. In Deutschland steigt die Zahl der KI-Gr&#252;ndungen moderat; so berichtet der KI-
Bundesverband aktuell von &#252;ber 250 Mitgliedern.534 
Zur Finanzierung k&#246;nnen KI-Start-ups in Deutschland &#246;ffentliche F&#246;rdermittel f&#252;r Existenzgr&#252;nderinnen und
-gr&#252;nder nutzen, die in Deutschland vom Bund oder den L&#228;ndern f&#252;r Unternehmensgr&#252;ndungen vergeben
werden. Auch wenn es z. B. mit der Initiative &#8222;appliedAi &#8211; UnternehmerTUM&#8220;535 eine KI-Startup-F&#246;rderung an der
TU M&#252;nchen gibt, ist eine breite Gr&#252;ndungsf&#246;rderung von KI-Start-ups nicht vorhanden. F&#252;r KI-Gr&#252;ndungen
sind aber vor allem Programme f&#252;r die F&#246;rderung von Ausgr&#252;ndungen aus der Forschung relevant. Wichtige
F&#246;rdermittel sind beispielsweise das EXIST-Programm des BMWi536 und der High-Tech Gr&#252;nderfonds
(HTGF)537. Private Geldgeber, die in Start-ups investieren m&#246;chten, werden durch das INVEST-Programm des 
Bundesamts f&#252;r Wirtschaft und Ausfuhrkontrolle unterst&#252;tzt. Nach der Gr&#252;ndung stehen den KI-Start-ups die
gleichen F&#246;rderma&#223;nahmen wie KMU zur Verf&#252;gung, beispielsweise das &#8222;Zentrale Innovationsprogramm
Mittelstand (ZIM)&#8220;538 und &#8222;KMU innovativ&#8220;539 oder auf L&#228;nderebene F&#246;rderprogramme wie beispielsweise das Pro-
FIT-Programm der Investitionsbank Berlin.540 Als Teil eines Konsortiums k&#246;nnten sich Start-ups auch auf
gr&#246;&#223;ere Ausschreibungen auf Bundesebene oder sogar der EU, beispielsweise Horizont 2020, bewerben. 
530 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion der AfD vor [Sondervotum zu den Kapiteln 4.1.3.1.1 und 5.2.1 des Berichts
der Projektgruppe 1 &#8222;KI und Wirtschaft&#8220; (&#8222;Themenfeld Start-ups&#8220; und &#8222;Innovation und Start-ups: Start-up-&#214;kosysteme, Start-up-
F&#246;rderungen&#8220;) der Abgeordneten Joana Cotar sowie der Abgeordneten Peter Felser und Dr. Marc Jongen].
531 Jedes dritte Start-up nutzt KI schon, ebenso viele denken &#252;ber den Einsatz nach. Gro&#223;es Interesse besteht an Datenanalyse und 
Blockchain-Technologien; vgl. Bitkom e. V. (2019): K&#252;nstliche Intelligenz ist die Top-Technologie f&#252;r Startups.
532 Als Seed-Finanzierung wird die fr&#252;he Investition in ein Start-up bezeichnet in der Phase der Vorgr&#252;ndung oder in der Gr&#252;ndungphase.
533 Vgl. Roland Berger GmbH und Asgard Capital Verwaltung GmbH (2018): Artificial Intelligence &#8211; A strategy for European startups; 
kritisch ist anzumerken, dass eine Studie des Londoner Kapitalgebers MMC Ventures (vgl. MMC Ventures (2019): The State of AI:
Divergence) ergab, dass bei rund 40 Prozent aller KI-Start-ups zwar der Begriff verwendet, aber die Technologie nicht genutzt wird.
Nur bei 60 Prozent der KI-Start-ups ist die Technologie &#8222;wesentlich&#8220; f&#252;r das angebotene Produkt.
534 Weitere Informationen dazu unter: https://ki-verband.de/ (zuletzt abgerufen am 18. August 2020).
535 Weitere Informationen dazu unter: https://appliedai.de/ (zuletzt abgerufen am 30. Juli 2020).
536 Weitere Informationen dazu unter: https://www.exist.de/DE/Home/inhalt.html (zuletzt abgerufen am 30. Juli 2020).
537 Weitere Informationen dazu unter: https://high-tech-gruenderfonds.de/de/#netzwerk-events (zuletzt abgerufen am 30. Juli 2020).
538 Weitere Informationen dazu unter: https://www.zim.de/ZIM/Navigation/DE/Home/home.html (zuletzt abgerufen am 30. Juli 2020).
539 Weitere Informationen dazu unter: https://www.bmbf.de/de/kmu-innovativ-561.html (zuletzt abgerufen am 30. Juli 2020).
540 Weitere Informationen dazu unter: https://www.ibb.de/de/foerderprogramme/pro-fit-projektfinanzierung.html(zuletzt abgerufen am
30. Juli 2020).
Start-ups kritisieren teilweise, dass F&#246;rderrichtlinien und Konditionen zu abschreckend gestaltet seien und dazu 
f&#252;hren w&#252;rden, auf eine Beantragung einer Gr&#252;ndungsf&#246;rderung zu verzichten. Der b&#252;rokratische Aufwand bei
der Beantragung, die oft gegebene lange Wartezeit auf ein Ergebnis, der unterstellte Verwaltungsaufwand
w&#228;hrend der Laufzeit, unklare Regelungen des Urheberrechts und der Richtlinien, nach denen Sicherheiten
erforderlich sind, die ein Unternehmen, das weniger als drei Jahre existiere, nicht bieten k&#246;nne, w&#252;rde viele Gr&#252;nderinnen
und Gr&#252;nder von der Beantragung &#246;ffentlicher F&#246;rdermittel abschrecken.541 Ungeachtet der innovativen Arbeit
in Forschung und Entwicklung, die viele Start-ups erbringen, ist ihnen damit der Weg zur F&#246;rderung ihrer
Projekte verwehrt.
Im Bereich des Venture Capital ist zu beobachten, dass bei den deutschen Venture-Capital-Gebern ein Umdenken
stattgefunden hat. Wo bisher quasi ausschlie&#223;lich risikoarme Gesch&#228;ftsmodelle im E-Commerce finanziert
wurden, wird nun mehr auch in komplexere Technologien und Gesch&#228;ftsmodelle investiert.542 Das Volumen der
insgesamt in Deutschland get&#228;tigten Investitionen in Start-ups bleibt aber weiterhin zur&#252;ck. In Deutschland und
Europa wird weitaus weniger in Start-ups investiert als beispielsweise in Israel, China und den USA. Der
Unterschied ist dabei vor allem in den sp&#228;teren Phasen eines Start-ups und in Finanzierungsrunden ab etwa 10
Millionen Euro eklatant, wie eine Anfang 2019 ver&#246;ffentlichte Studie der Deutschen B&#246;rse zusammen mit acatech und
der KfW zeigte.543 Ung&#252;nstig ist daran, dass Unternehmen in diesen Phasen dann darauf angewiesen sind, sich
notwendige Finanzierungen aus dem Ausland zu holen und damit eventuell ihren Firmensitz zu verlegen.544
Dasselbe gilt f&#252;r den Verkauf, der nur in seltenen F&#228;llen an ein deutsches Unternehmen gelingt.545 Durch die
Abwanderung der Unternehmen in dieser Phase verlieren die europ&#228;ischen L&#228;nder Know-how, die Technologie und
auch die vorausgegangenen F&#246;rderungen der Steuerzahlerinnen und Steuerzahler f&#252;r diese Start-ups.
Die von der DSGVO gesetzten hohen Datenschutzstandards k&#246;nnen im internationalen Wettbewerb um das
Vertrauen der Nutzerinnen und Nutzer einen Vorteil f&#252;r deutsche KI-Start-ups bedeuten. Die DSGVO wird au&#223;erdem
daf&#252;r gelobt, dass sie hilfreiche Grunds&#228;tze aufgestellt habe, um technologieneutral &#252;ber neue Gesch&#228;ftsmodelle
nachdenken zu k&#246;nnen.546 
Umfangreiche Regelungen und damit verbundene rechtliche Unklarheiten k&#246;nnen den Zugang zu Daten zwecks
wissenschaftlicher und wirtschaftlicher Nutzung erschweren, diese sind aber Voraussetzung f&#252;r eine
wettbewerbsf&#228;hige Anwendung des Maschinellen Lernens. Manche Start-ups in der Werbebranche geben an, die
DSGVO habe zu einer deutlichen Minderung der Reichweite kleinerer Unternehmen im Vergleich zu ihren
bereits etablierten Plattform-Konkurrenten gef&#252;hrt.547 
Auch rechtlich neue Anforderungen, wie die j&#252;ngste Urheberrechtsreform auf EU-Ebene (DSM-Richtlinie) und
die damit verbundenen Anpassungen, die im deutschen Urheberrechtsgesetz (UrhG) n&#246;tig werden, namentlich 
zur Plattformverantwortlichkeit (Artikel 17 der Richtlinie) und zur Neufassung des Leistungsschutzrechts f&#252;r
Presseverleger (Artikel 15 der Richtlinie), haben zur Folge, dass sich kleinere Unternehmen mit
Rechtsunsicherheiten auseinandersetzen m&#252;ssen und gegen&#252;ber den gro&#223;en Plattform-Konkurrenten in eine deutlich schw&#228;chere
Position geraten.548 
541 Darstellung von Fabian Westerheide (Asgard Capital) in der Sitzung der Projektgruppe &#8222;KI und Wirtschaft&#8220; am 8. April 2019.
542 Vgl. Ernst &amp; Young (2019): Start-Up-Barometer Deutschland.
543 Vgl. Achleitner et al. (2019): Innovationskraft in Deutschland verbessern: &#214;kosystem f&#252;r Wachstumsfinanzierung st&#228;rken (acatech 
STUDIE).
544 Darstellungen von Fabian Westerheide (Asgard Capital) und Dr. Katrin Leonhardt (KfW) in der Sitzung der Projektgruppe &#8222;KI und
Wirtschaft&#8220; am 8. April 2019.
545 Vgl. Rondinella (2017): Warum Deutschland ein Entwicklungsland ist.
546 Darstellung Patrick Bunk (Ubermetrics Technologies GmbH) in der Sitzung der Projektgruppe &#8222;KI und Wirtschaft&#8220; am 8. April 2019.
547 Darstellung Patrick Bunk (Ubermetrics Technologies GmbH) in der Sitzung der Projektgruppe &#8222;KI und Wirtschaft&#8220; am 8. April 2019.
548 Die Reform des EU-Urheberrechts folgt diesem Muster; auch sie hat zu einer unbeabsichtigten St&#228;rkung von gro&#223;en Plattform-
Anbietern gef&#252;hrt, da diese Unternehmen von den Nutzerinnen und Nutzern zun&#228;chst einmal die Lizenzen pauschal &#252;bereignet
bekommen und es dadurch auch bei ung&#252;ltigen Lizenzen in jedem Fall zu Wettbewerbsnachteilen f&#252;r kleinere Unternehmen kommt;
Darstellung Patrick Bunk (Ubermetrics Technologies GmbH) in der Sitzung der Projektgruppe &#8222;KI und Wirtschaft&#8220; am 8. April 2019.
4.1.3.1.2 Themenfeld Mittelstand549 
Kleine und mittelst&#228;ndische Unternehmen (KMU)550 sind der Erfolgsfaktor der deutschen Wirtschaft: &#220;ber
99 Prozent aller Unternehmen in Deutschland sind mittelst&#228;ndische Unternehmen. Sie erwirtschaften derzeit
mehr als die H&#228;lfte der Wertsch&#246;pfung, stellen fast 60 Prozent aller Arbeitspl&#228;tze und &#252;ber 80 Prozent der
betrieblichen Ausbildungspl&#228;tze bereit.551 Eine besondere Rolle kommt dabei dem industriellen Mittelstand zu, den
sogenannten Hidden Champions, den mehr als 1 000 mittelgro&#223;en, aber oftmals weitgehend unbekannten
Unternehmen, die in ihren Branchen mit meist hochspezialisierten Produkten und Dienstleistungen Weltmarktf&#252;hrer
sind.552 Daraus ergibt sich die Notwendigkeit, dass KMU auch weiterhin stark sind und in Schl&#252;sselbereichen
wie Digitalisierung oder KI voranschreiten. 
Viele Analysen kommen jedoch zu dem Ergebnis, dass in Deutschland die Expertise sowie die
Innovationsbereitschaft und -t&#228;tigkeit von KMU im Bereich KI noch nicht ausreichend ausgepr&#228;gt sind. Diese Einsch&#228;tzung
wurde von den hinzugezogenen Expertinnen und Experten best&#228;tigt.553 Dabei ist zu ber&#252;cksichtigen, dass
Erhebungen und Umfragen h&#228;ufig die KI-Nutzung in Unternehmen nicht isoliert betrachten, sondern sie in der
Gesamtschau mit einem nicht ausreichenden Digitalisierungsgrad und einer insgesamt zu geringen
Innovationst&#228;tigkeit des deutschen Mittelstands in Verbindung bringen. 
Nach einer vom BMWi in Auftrag gegebenen Studie aus dem Jahr 2018 mit Schwerpunkt KI554 setzen in
Deutschland erst 5 Prozent der Unternehmen KI ein. Immerhin hat sich der Anteil im Jahr 2018 im Vergleich 
zum Jahr 2017 verdoppelt. Dar&#252;ber hinaus zeigt sich, dass sich bislang erst 25 Prozent der Unternehmen mit KI
besch&#228;ftigt haben; 75 Prozent der befragten Unternehmen erachten das Thema KI f&#252;r ihr Unternehmen als nicht
relevant. Dies steht im Gegensatz zur Einsch&#228;tzung der angeh&#246;rten Expertinnen und Experten sowie der
Verb&#228;nde, die eine fl&#228;chendeckende Relevanz des KI-Themas erwarten und darauf hinweisen, dass hier eine
deutliche Diskrepanz herrsche.555 Zu ber&#252;cksichtigen ist dabei, dass sich das KI-Bewusstsein von Branche zu Branche
unterscheidet: Unternehmen in den Bereichen der Informations- und Kommunikationstechnologie und Handel
sind in der KI-Nutzung weiter fortgeschritten, und auch die Unternehmen in der Finanz- und
Versicherungsbranche trauen sich im Bereich KI mehr zu.556 
Ein Grund f&#252;r die geringe bzw. noch nicht fl&#228;chendeckende KI-Nutzung im mittelst&#228;ndischen Bereich wird darin
gesehen, dass Vorteile durch KI f&#252;r viele Entscheiderinnen und Entscheider nicht greifbar genug sind:557 Anstelle
leicht umsetzbarer Anwendungen, wie der Fehlererkennung bei Produkten, Chatbots oder der automatisierten 
Erkennung von E-Mails im Kundendienst, wird h&#228;ufig in komplizierte Forschungsprojekte investiert, sodass der
&#8222;Return-on-Investment558&#8222; nicht &#252;berzeugend ist. In vielen Unternehmen fehlen ausreichende KI-Kompetenzen
sowohl auf Ebene der Gesch&#228;ftsf&#252;hrung als auch in Fachbereichen, entsprechende Fachkr&#228;fte k&#246;nnen h&#228;ufig nur
549 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 4.1.3.1.2 des Berichts der
Projektgruppe &#8222;KI und Wirtschaft&#8220; (&#8222;Themenfeld Mittelstand &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des
sachverst&#228;ndigen Mitglieds Dr. Florian Butollo].
550 Die Projektgruppe &#8222;KI und Wirtschaft&#8220; folgt der KMU-Definition der Europ&#228;ischen Kommission. Danach z&#228;hlt ein Unternehmen zu
den KMU, wenn es nicht mehr als 249 Besch&#228;ftigte hat und einen Jahresumsatz von h&#246;chstens 50 Millionen Euro erwirtschaftet oder
eine Bilanzsumme von maximal 43 Millionen Euro aufweist (Empfehlung der EU-Kommission 2003/361/EG).
551 Vgl. Bundesministerium f&#252;r Wirtschaft und Energie (2019): Wirtschaftsmotor Mittelstand &#8211; Zahlen und Fakten zu den deutschen
KMU.
552 Eine Auflistung der Unternehmen findet sich in Rau (2018): Das sind Deutschlands geheime Weltmarktf&#252;hrer.
553 Darstellungen verschiedener angeh&#246;rter Personen in den Sitzungen der Projektgruppe &#8222;KI und Wirtschaft&#8220; am 11. M&#228;rz, 1. April und
8. April 2019.
554 Vgl. Bundesministerium f&#252;r Wirtschaft und Energie (2018): Monitoring-Report Wirtschaft DIGITAL 2018; PricewaterhouseCoopers
(2019): K&#252;nstliche Intelligenz in Unternehmen.
555 Der Innovationsindikator des Bundesverbands der Deutschen Industrie e. V. kommt zum Ergebnis, dass die Innovationsdynamik der
Wirtschaft derzeit von den mittelst&#228;ndischen Unternehmen gebremst wird; vgl. dazu Bundesverband der Deutschen Industrie e. V.
(2018): Innovationsindikator 2018. Eine hohe Relevanz von KI f&#252;r die internationale Wettbewerbsf&#228;higkeit des deutschen
Mittelstands ergab auch die Expertenbefragung von Mittelstand-Digital; vgl. dazu Begleitforschung Mittelstand-Digital (2019): K&#252;nstliche
Intelligenz im Mittelstand.
556 Vgl. PricewaterhouseCoopers (2019): K&#252;nstliche Intelligenz in Unternehmen.
557 Im Folgenden werden die Darstellungen verschiedener angeh&#246;rter Personen wiedergegeben: J&#246;rg Bienert (Gr&#252;nder und CEO
aisolab, Vorsitzender KI-Bundesverband) und Iris Pl&#246;ger (Mitglied der Hauptgesch&#228;ftsf&#252;hrung des BDI e. V.) in der Sitzung der
Projektgruppe &#8222;KI und Wirtschaft&#8220; am 11. M&#228;rz 2019 sowie Alexandra Horn (Konsortialleiterin des Mittelstand-4.0-Kompetenzzentrums
Berlin sowie Leiterin Verbandskooperation und Projekte des Bundesverbands mittelst&#228;ndische Wirtschaft) in der Sitzung der
Projektgruppe &#8222;KI und Wirtschaft&#8220; am 1. April 2019.
558 Die Errechnung des Return-on-Investment(ROI) zeigt, ob sich eine Investition gelohnt hat. Die Kennziffer des ROI beschreibt das
prozentuale Verh&#228;ltnis zwischen dem investierten Kapital und dem Gewinn, den das Unternehmen erwirtschaften konnte.
schwer rekrutiert werden.559 So k&#246;nnen das Risiko-Chancen-Potenzial von KI vielerorts nicht richtig eingesch&#228;tzt 
und konkrete Projekte nicht in Gang gesetzt werden. Zudem h&#228;lt die starke Auftragslage viele Unternehmen
davon ab, sich mit der Erschlie&#223;ung neuer Gesch&#228;ftsfelder oder &#196;nderungen in ihren Gesch&#228;ftsprozessen zu
besch&#228;ftigen. Die angeh&#246;rten Expertinnen und Experten raten vor allem dazu, auf eine niedrige Eintrittsschwelle
bei den KI-Angeboten f&#252;r den Mittelstand zu achten, damit Mittelst&#228;ndler nicht das Gef&#252;hl einer &#220;berforderung
haben. So sollten stets die L&#246;sung und der Nutzen einer konkreten Anwendung in den Vordergrund gestellt
werden und es sollte unternehmensspezifisch beraten werden, um die Skepsis zu nehmen. 
Beratungen in den Kompetenzzentren zeigen, dass eine Mehrheit der KMU bereits &#252;ber Mehrwerte im
Allgemeinen informiert ist, aber f&#252;r ihr Unternehmen den konkreten Mehrwert durch KI f&#252;r die Verbesserung eigener
Prozesse oder f&#252;r die Unterst&#252;tzung bzw. Entlastung der Besch&#228;ftigten noch nicht ausreichend einsch&#228;tzen kann.
Von einem unzureichend entwickelten KI-Bewusstsein im deutschen Mittelstand kann nach Sondierung der
Marktsituation nicht generell gesprochen werden. Es gibt auch einige sehr innovative Unternehmen unter den
mittelst&#228;ndischen, die mit Blick auf KI beweisen, wie technikaffin und zukunftsorientiert der deutsche
Mittelstand ist. Viele KMU kooperieren bereits intensiv mit Start-ups, um sich Zukunftsthemen zu erschlie&#223;en.560
Au&#223;erdem werden Netzwerke geschlossen, um den Kulturwandel in einzelnen Branchen voranzutreiben. Ein
Beispiel daf&#252;r ist die &#8222;Hinterland-Allianz&#8220; in der Region Ostwestfalen-Lippe, die mit dem Spitzencluster &#8222;It's OWL&#8220;
zusammenarbeitet, um ein nachhaltiges &#214;kosystem mit Technikfokus zu schaffen.561 Zu beobachten ist auch,
dass viele KMU bereits eng mit Dienstleistern wie Amazon oder Google zusammenarbeiten. Somit verf&#252;gen sie 
nicht selbst &#252;ber die KI-Technologie, k&#246;nnen sie aber zumindest nutzen. Ein eigener KI-Einsatz erscheint f&#252;r
viele (noch) mit einem zu hohen Aufwand verbunden, da KI eine Menge an Daten braucht, um zu lernen.
Um mehr Dynamik zu erreichen und KI in die Fl&#228;che zu bringen, hat der Staat bereits neue Anreize f&#252;r Transfer
und Kooperation geschaffen, wie z. B. den &#8222;Innovationswettbewerb KI&#8220;562, durch den KI-Ans&#228;tze und Transfer
in wichtigen Sektoren gef&#246;rdert werden, oder die &#8222;Mittelstand-4.0-Kompetenzzentren&#8220;563, die vor Ort mit
Expertenwissen, Demonstrationszentren, Netzwerken zum Erfahrungsaustausch, Veranstaltungen und praktischen
Beispielen helfen und beraten. Zudem existieren im Rahmen der Transferinitiative der Bundesregierung diverse
F&#246;rderprogramme, die den Mittelstand bei Innovationen allgemein unterst&#252;tzen.564 Weiterhin wurden bereits
diverse Kooperationen zwischen und innerhalb der Wissenschaft und Wirtschaft eingegangen, die gute Impulse f&#252;r
Wissens-, Datentransfer und Experimentierr&#228;ume schaffen, wie der &#8222;International Data Space&#8220;, in welchem
Unternehmen abgesichert Daten teilen und nutzen k&#246;nnen565, oder die Initiative des Ferdinand-Steinbeis-Instituts,
die ein &#8222;Micro Testbed&#8220; ins Leben gerufen hat, um KMU und das Handwerk zusammenzubringen.566 
In diesem Zusammenhang ist zu erw&#228;hnen, dass es heute schon im Handwerk erste beachtliche KI-basierte
Anwendungen gibt und eine Forcierung der Aktivit&#228;ten auch &#252;ber die Mittelstand-4.0-Kompetenzzentren sowie &#252;ber
das Kompetenzzentrum Digitales Handwerk (KDH) angestrebt wird.567 Dabei wird eine der gr&#246;&#223;ten
Herausforderungen darin gesehen, den Zugang zu Daten f&#252;r Handwerksbetriebe datenschutzkonform und zugleich
handhabbar zu regeln, da ohne geeignete, dezentrale Schnittstellen eine Wartungs- und Service-Dienstleistung von
559 Fehlendes Know-how bzw. fehlende Fachkr&#228;fte werden als sehr starkes Hemmnis f&#252;r die Implementierung von KI-L&#246;sungen im
Mittelstand gesehen. Dies spiegelt das Ausma&#223; des allgemeinen Fachkr&#228;ftemangels im Mittelstand wider. KMU k&#246;nnen hier h&#228;ufig
bei den von Gro&#223;unternehmen bezahlten Geh&#228;ltern f&#252;r IT-/KI-Fachleute nicht mithalten; vgl. dazu Begleitforschung Mittelstand-
Digital (2019): K&#252;nstliche Intelligenz im Mittelstand.
560 Vgl. Bundesverband der Deutschen Industrie e. V., Deutsche Bank AG (2018): Die gr&#246;&#223;ten Familienunternehmen in Deutschland; 
Bundesministerium f&#252;r Wirtschaft und Energie (2019): Wirtschaftsmotor Mittelstand &#8211; Zahlen und Fakten zu den deutschen KMU.
561 Zu den Gr&#252;ndern geh&#246;ren u. a.: Miele, Dr. Oetker, Dr. Wolff, B&#246;llhoff, Goldbeck, Wago, Wortmann, Phoenix Contact, Sch&#252;co oder
CLAAS. Weitere Informationen dazu unter: https://www.its-owl.de/home/ (zuletzt abgerufen am 18. August 2020).
562 Vgl. Bundesministerium f&#252;r Wirtschaft und Energie (2019): Innovationswettbewerb &#8222;K&#252;nstliche Intelligenz als Treiber f&#252;r
volkswirtschaftlich relevante &#214;kosysteme&#8220;.
563 Weitere Informationen dazu unter: https://www.mittelstand-digital.de/MD/Navigation/DE/Home/home.html (zuletzt abgerufen am
30. Juli 2020).
564 Einen &#220;berblick dazu gibt Bundesministerium f&#252;r Wirtschaft und Energie (2019): Von der Idee zum Markterfolg.
565 Weitere Informationen dazu unter: https://www.fraunhofer.de/de/forschung/fraunhofer-initiativen/industrial-data-space.html (zuletzt
abgerufen am 30. Juli 2020).
566 Weitere Informationen dazu: https://steinbeis-fsti.de/de/micro-testbed/ (zuletzt abgerufen am 30. Juli 2020).
567 Informationen zu Praxisbeispielen unter https://handwerkdigital.de/ (zuletzt abgerufen am 30. Juli 2020); vgl. auch Future
ManagementGroupAG (2018): Smartes Handwerk: Zwischen Tradition und Technologie.
intelligenten Anlagen, wie z. B. KI-gesteuerten Heizungsanlagen, Kraftfahrzeugen oder einem mit Sensoren
ausgestatteten Bodenbelag, nicht m&#246;glich erscheint.568 
Der Zugang zu geeigneter Finanzierung wird als ma&#223;gebliche Voraussetzung daf&#252;r gesehen, dass der Mittelstand
investitions- und innovationsf&#228;hig und damit wettbewerbsf&#228;hig bleiben kann. Die Mittelstandsfinanzierung durch
Kredite ist in Deutschland besonders weit verbreitet und spielt auch bei KI-Investitionen eine wichtige Rolle.569 
4.1.3.1.3 Themenfeld Konzerne: Konzerne in der KI-Transformation
Global f&#252;hrende Technologieunternehmen wie die GAFAM-Unternehmen in den USA, deren Kerngesch&#228;ft die
Entwicklung und Bereitstellung von KI-Software- und -Dienstleistungen darstellt, existieren bislang in
Deutschland nicht. Deutsche Unternehmen spielen hingegen eine starke Rolle bei der Implementierung KI-basierter
Technologien in industrielle Prozesse, beispielsweise bei Industriesoftware, Automatisierungsanlagen oder im
sich formierenden Feld des Industrial Internets.570 SAP integriert beispielsweise KI in alle cloudbasierten
L&#246;sungen, um technologisch u. a. das Management von Gesch&#228;ftsprozessen zu erm&#246;glichen. Siemens wiederum
vermarktet seine &#8222;intelligente Maschinencloud&#8220;, um Maschinen und Anlagen zu vernetzen. Nicht zuletzt hat auch
Bosch angek&#252;ndigt, bis zum Jahr 2025 seine Produkte mit Zusatzfunktionen zu versehen oder KI in der
Produktion einzusetzen. Dass insbesondere Bosch und Siemens sehr stark im industriellen KI-Kontext vertreten sind, 
zeigt sich auch dadurch, dass sie unter den Top-20-Unternehmen der Welt mit KI-Patentanmeldungen sind.571 
Um neue M&#228;rkte und Wachstumsfelder zu erschlie&#223;en, die sich durch die zunehmende Datenverf&#252;gbarkeit
auftun, arbeiten Konzerne und Gro&#223;unternehmen daran, datenbasierte Innovationen f&#252;r Gesch&#228;ftsmodelle
voranzubringen. Die Relevanz des reinen Produktverkaufs nimmt in einigen Branchen ab oder es werden digitale,
intelligente Zusatzservices als Bestandteil der Produkte erwartet. So entwickeln bzw. betreiben mittlerweile neben
Automobilherstellern auch &#246;ffentliche und private Verkehrsunternehmen sowie neu gegr&#252;ndete
Mobilit&#228;tsunternehmen und Start-ups digitale Mobilit&#228;tsplattformen. Bekannte &#8222;Mobility as a Service&#8220;-Angebote werden durch
selbst lernende Algorithmen zu &#8222;Mobility as a Smart Service&#8220;-Angeboten, die auf individuelle Bed&#252;rfnisse und
Voraussetzungen ihrer Nutzerinnen und Nutzer eingehen. Anstatt ein Auto oder ein anderes Fahrzeug zu kaufen,
wird f&#252;r die Mobilit&#228;tsdienstleistung bezahlt. Im Vordergrund stehen minutenbasierte oder nach definierten
Zeitr&#228;umen geteilte Fahrzeuge, andere Gef&#228;hrte oder reine Fahrten.572 Allen Anbietern ist gemeinsam, dass in diesen 
neuen Dienstleistungen KI als technologisches Steuerungsinstrument die m&#246;glichst optimale Nutzung und
Bereitstellung der Flotte erm&#246;glicht. &#196;hnliche Beispiele lassen sich in vielen Sektoren finden, wie beispielsweise
&#8222;Pay-as-you-drive&#8220;573-Tarife im Versicherungswesen oder im produzierenden Sektor durch die Bereitstellung 
von Maschinen mit vertraglich vereinbarten Output-Raten und kontinuierlich optimierten Laufzeiten.574 
Die f&#252;hrenden Unternehmen geraten unter Druck, sich durch den Einsatz von KI ihre Branchenf&#252;hrerschaft in
etablierten Gesch&#228;ftsfeldern zu sichern, sich also um den Umsatz in der Gegenwart zu k&#252;mmern, und zugleich
neue Verfahren zu erproben, um nicht von neuen, technologiegetriebenen Herausforderern ausgestochen zu
werden. Oft droht die Disruption einer etablierten Branche nicht durch bisherige Wettbewerber, sondern durch neue
Marktteilnehmer, wie beispielsweise geschehen im Hotelgewerbe mit Airbnb, in der Automobilbranche mit Tesla
oder im Musikmarkt mit neuen Streaming-Diensten wie Spotify. Die Restrukturierung von Wirtschaftssektoren
aufgrund der neuen technologischen Potenziale im Bereich von KI steht dabei in Wechselwirkung zu weiteren
Technologiebr&#252;chen, wie Robotik oder Quanten-Computing.
568 Vgl. Zentralverband des deutschen Handwerks (2019): Positionspapier &#8211; Anforderungen des Handwerks an eine faire
Daten&#246;konomie.
569 Zur St&#228;rkung des Venture-Capital-Marktes stellt das BMWi insgesamt rund 2 Milliarden Euro &#252;ber verschiedene Instrumente zur
Verf&#252;gung, darunter die ERP/EIF-Wachstumsfazilit&#228;t in H&#246;he von 500 Millionen Euro, der Ko-Investmentfonds coparion mit einem
Fondsvolumen von 225 Millionen Euro und der auf 1,7 Milliarden Euro aufgestockte ERP/EIF-Dachfonds (umfasst den European
Angels Fonds).
570 Vgl. Begleitforschung PAiCE; iit-Institut f&#252;r Innovation und Technik in der VDI / VDE Innovation + Technik GmbH (2018):
Potenziale der K&#252;nstlichen Intelligenz im produzierendem Gewerbe in Deutschland; vgl. auch Ranking der Top-500-Unternehmen des
Internets der Dinge in IoTOne (2019): 2019 Top 500 Industrial IoT Companies.
571 Vgl. Weltorganisation f&#252;r Geistiges Eigentum (2019): Artificial intelligence.
572 F&#252;r weitere Ausf&#252;hrungen wird auf den Bericht der Projektgruppe &#8222;KI und Mobilit&#228;t&#8220; in Kapitel C. VI. [K&#252;nstliche Intelligenz und 
Mobilit&#228;t (Projektgruppe 5)] verwiesen.
573 &#8222;Pay-as-you-drive&#8220; ist eine spezielle Autoversicherung, bei der die Pr&#228;mienh&#246;he aus der Art und Weise der Fahrzeugnutzung
errechnet wird.
574 Vgl. Schnell (2018): Start-ups Emil und Friday bieten Kfz-Tarife f&#252;r Wenigfahrer an; Oswald und Krcmar (2018): Digitale
Transformation.
Es zeigt sich bereits, dass auch deutsche Konzerne strategische Kooperationen eingehen und gemeinschaftlich
an digitalen Plattformen und &#214;kosystemen bauen, welchen allen Teilnehmenden Vorteile in Bezug auf
Datengewinnung, Skalierung und Zugang zu Kundinnen und Kunden erm&#246;glichen. Somit wird das von der IT-Branche
bereits seit Langem gelebte Modell der Coopetition kontinuierlich in weitere Industrien &#252;bertragen. Neben den
technischen und organisatorischen Herausforderungen existieren hier auch rechtliche Herausforderungen, die
sich insbesondere aus dem Kartellrecht und dem Verbraucherschutz ergeben. So durfte der deutsche Stahlh&#228;ndler
Kl&#246;ckner seine digitale Plattform erst offiziell in den Markt einf&#252;hren, nachdem sichergestellt war, dass es
zwischen den anbietenden Plattformteilnehmern keinen wettbewerbsd&#228;mpfenden Informationsaustausch &#252;ber Preise
oder Verf&#252;gbarkeiten gibt.575 
Der Suchprozess in Bezug auf die Innovation von Gesch&#228;ftsmodellen ist allerdings h&#228;ufig von Unsicherheit und
Risiko gekennzeichnet, welche Verfahren und Modelle sich schlie&#223;lich als erfolgreich erweisen. Konzerne gehen
dieses Thema entsprechend vielf&#228;ltig an. So haben &#252;ber 90 Prozent aller DAX-Konzerne mittlerweile
Innovationsprogramme und Start-up-Inkubatoren aufgesetzt, um neue Methoden und Innovation mit Bezug auf ihr
Kerngesch&#228;ft aufzubauen.576 F&#252;r ein m&#246;glichst breit angelegtes &#8222;Scouting&#8220;577 von Technologie- und
Gesch&#228;ftsmodellen investieren dabei viele deutsche Konzerne auch in Fonds, wie den High-Tech-Gr&#252;nderfonds, oder gr&#252;nden
eigene Fonds-Gesellschaften.578 
4.1.3.2 Branchen
Im Folgenden werden die Branchen Industrie und Produktion, Handel und Dienstleistungen, wie Finanzmarkt
und Versicherungen, sowie die Landwirtschaft genauer betrachtet, weil KI dort bereits heute verst&#228;rkt eingesetzt
wird oder besondere Wachstumsm&#246;glichkeiten und ein Wandel der Branche erwartet werden.
4.1.3.2.1 Themenfeld Industrie und Produktion: Daten als Produktkomponente in der
produzierenden Industrie579 
Das produzierende Gewerbe ist die Industrie, in der die Wachstumsm&#246;glichkeiten durch KI-basierte
Prozessoptimierung, aber auch Gesch&#228;ftsmodellinnovationen im Vergleich zu anderen Industriesektoren als hoch
eingesch&#228;tzt werden.580 Die KI-Umsetzung ist hier meist eingebettet in die Themenfelder und die Technologie aus
dem Kontext von &#8222;Industrie 4.0&#8220;. So wird KI eine tragende Rolle bei der Umsetzung von Szenarien in den
Bereichen intelligenter Automatisierungs- und Assistenzsysteme, vorausschauender Analyse und intelligenter
Sensorik zugesprochen.581 Obwohl die heutigen Investitionen im produzierenden Gewerbe im Vergleich zu anderen 
Industrien hoch sind, ist die Anzahl der Unternehmen, welche KI bereits produktiv oder auch nur in
prototypischen Szenarien einsetzen, bislang &#252;berschaubar. Dies hat mehrere Gr&#252;nde.
Eine Herausforderung ist die Herstellung einer f&#252;r KI qualitativ hochwertigen und zugleich ausreichend gro&#223;en
Datenbasis. Aufgrund der heterogenen Produktionsprozesse der Unternehmen sind gut aufbereitete Daten selten
sofort in gro&#223;en Mengen verf&#252;gbar. 582 Entsprechend lassen sich die heute popul&#228;ren Anwendungen aus dem
Bereich des Maschinellen Lernens mit Massendaten in vielen F&#228;llen nur begrenzt anwenden.
Hierzu nutzen die Unternehmen h&#228;ufig symbolische KI-Expertensysteme, welche beispielsweise auf
Wenndann-Regeln und Wissens-Ontologien basieren und deren Grundlagen bereits in den 1970er und 1980er Jahren
entwickelt wurden. Teilweise kommt auch klassisches, statistisches Maschinelles Lernen zum Einsatz, welches
im Vergleich zu den aktuellen Methoden der neuronalen Netze mit deutlich kleineren Datenmengen auskommt
575 Vgl. Bundeskartellamt (2018): Kl&#246;ckner darf digitale Plattform f&#252;r Stahlprodukte starten.
576 Vgl. mm1 (2019): DAX 30 Startup- und Innovationsmonitor: Update 2019.
577 Das Auskundschaften von Technologie- und Gesch&#228;ftsmodellen.
578 Vgl. Ernst &amp; Young (2019): Fast growth beyond borders: Tech start-ups reshaping the economy.
579 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 4.1.3.2.1 des Berichts der
Projektgruppe &#8222;KI und Wirtschaft &#8220; (&#8222;Themenfeld Industrie und Produktion: Daten als Produktkomponente in der produzierenden 
Industrie &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo].
580 Vgl. Begleitforschung PAiCE; iit-Institut f&#252;r Innovation und Technik in der VDI / VDE Innovation + Technik GmbH (2018):
Potenziale der K&#252;nstlichen Intelligenz im produzierendem Gewerbe in Deutschland ; Purdy und Daugherty (2017): How AI boosts industry
profits and innovation; Plattform Industrie 4.0 (2019): Digitale Gesch&#228;ftsmodelle f&#252;r die Industrie 4.0.
581 Vgl. Begleitforschung PAiCE; iit-Institut f&#252;r Innovation und Technik in der VDI / VDE Innovation + Technik GmbH (2018):
Potenziale der K&#252;nstlichen Intelligenz im produzierendem Gewerbe in Deutschland.
582 Vgl. Fraunhofer-Gesellschaft zur F&#246;rderung der angewandten Forschung e. V. (2018): Maschinelles Lernen &#8211; Eine Analyse zu
Kompetenzen, Forschung und Anwendung.
und bei dem die Ergebnisse auch besser interpretierbar sind. Methoden der &#8222;hybriden KI&#8220;, welche nun die
aktuellen M&#246;glichkeiten des Maschinellen Lernens mit den symbolischen regel- und modellbasierten KI-Methoden 
verbinden, besitzen zwar gro&#223;es wirtschaftliches Potenzial, befinden sich allerdings derzeit noch in einem fr&#252;hen 
Forschungs- und Anwendungsstadium.583 
Zudem setzt sich in der Industrie erst seit wenigen Jahren die Erkenntnis durch, dass der Wert eigener Daten
durch zus&#228;tzliche Daten von anderen Unternehmen deutlich gesteigert werden kann. Hier existieren noch viele
&#196;ngste von Unternehmen und Entscheiderinnen und Entscheidern, dass durch die Freigabe von Daten
Gesch&#228;ftsgeheimnisse &#246;ffentlich gemacht werden. 
Auch ist die Verbreitung von vollautonomen KI-gest&#252;tzten Produkten, wie intelligenten Produktionsanlagen,
autonomen Robotern oder Automobilen, im Endkundenmarkt noch gering. Die meisten der heute hergestellten
Maschinen sind meist nur teilautomatisiert oder mit Assistenzfunktionen ausgestattet, dabei aber noch nicht
selbstlernend. Gerade in Produktionsbereichen, die sich heute durch einen hohen manuellen Aufwand, eine hohe
Komplexit&#228;t und Varianz auszeichnen, er&#246;ffnet der Einsatz von KI-basierter Technik neue M&#246;glichkeiten. Auch
k&#246;nnen hochkomplexe und heute verkettete Fertigungen (z. B. Fahrzeugmontage) zuk&#252;nftig in dezentralen,
autonomen und intelligent gesteuerten Produktionszellen erfolgen. Somit k&#246;nnen selbst komplexe Produkte in
geringen Losgr&#246;&#223;en wirtschaftlicher hergestellt werden, als dies heute m&#246;glich ist.584 
Weitere Gr&#252;nde f&#252;r eine noch geringe Durchdringung von vollautonomen Produktionen sind neben technischen
Herausforderungen, wie beispielsweise Standards zur Interoperabilit&#228;t, vor allem rechtliche Fragestellungen.585 
Grunds&#228;tzlich zeichnet sich dennoch ab, dass durch die intelligenten Produkte und Anlagen neben neuen
Produktionsprozessen auch verst&#228;rkt neue Produkte und Gesch&#228;ftsmodelle aufkommen, welche das Potenzial haben,
die existierenden M&#228;rkte stark zu ver&#228;ndern. So zeigte nicht zuletzt die Hannover Messe im Jahr 2019 mit dem
Leitthema &#8222;Integrated Industry &#8211; Industrial Intelligence&#8220;, dass eine gro&#223;e Anzahl an deutschen
Industrieunternehmen daran arbeitet, neue Produkte und Dienstleistungen auf Basis von KI anzubieten.586 
4.1.3.2.2 Themenfeld Handel
Der Handel ist besonders geeignet f&#252;r die Nutzung von KI &#8211; dank seiner N&#228;he zu den Konsumentinnen und
Konsumenten und dank der Datensammlungen, &#252;ber die der Handel verf&#252;gt. Viele Einzelh&#228;ndler steuern bereits
seit Jahren ihre Wertsch&#246;pfungskette mithilfe von Daten, die sie &#252;ber ihre Kundinnen und Kunden und deren
Transaktionen sammeln.587 Darauf aufbauend werden vielseitige und relevante Einsatzfelder f&#252;r KI gesehen:588 
Sei es zur Verbesserung der Kundenberatung durch intelligente Einkaufshilfen oder Chatbots, die im Callcenter
assistieren, sei es zur Verbesserung der Produktangebote und Produktdarstellung in Onlineshops, etwa wenn KI
eine intelligente Preisgestaltung oder eine Relevanzsteigerung von Suchergebnissen erm&#246;glicht, oder sei es durch
die Optimierung von Prozessen, die z. B. durch intelligente Bedarfsprognosen f&#252;r Lagerbest&#228;nde oder intelligente
Lieferrouten erreicht werden k&#246;nnen.589 
583 Vgl. High-Level Expert Group on Artificial Intelligence (2019): Policy and Investment Recommendations for Trustworthy AI; 
Wrobel (2019): Wohin geht die Reise bei K&#252;nstlicher Intelligenz? Deep Learning and Beyond.
584 Vgl. Spath (2013): Produktionsarbeit der Zukunft &#8211; Industrie 4.0.
585 Siehe das Kapitel 4.1.6 dieses Projektgruppenberichts [Stand der Administration/Politik &#8211; rechtliche Fragen].
586 Vgl. Hannover Messe (2019): Hannover Messe boomt mit Industrie 4.0, K&#252;nstlicher Intelligenz und 5G.
587 Branchenf&#252;hrend in Big-Data-Prozessen ist der Lebensmittelhandel: Die Metro-Gruppe verarbeitet t&#228;glich Informationen von mehr
als 21 Millionen Kundinnen und Kunden; beim britischen Wettbewerber Tesco sind es mehr als 350 Millionen. Kundendaten, die 
ausgewertet werden, vgl. McKinsey &amp; Company (2017): K&#252;nstliche Intelligenz im Handel &#8211; Appetit auf den Algorithmus.
588 Zum Thema KI und Handel wurden in der Sitzung der Projektgruppe &#8222;KI und Wirtschaft&#8220; am 8. April 2019 Dr. Michael M&#252;ller-
W&#252;nsch (OTTO-Group) und Dr. Mikio Braun (Zalando) angeh&#246;rt. F&#252;r Informationen zur &#220;bersicht der KI-Einsatzfelder im Handel
vgl. Handelsverband Deutschland (2017): Handel 4.0 &#8211; Algorithmische Entscheidungen und K&#252;nstliche Intelligenz im Handel.
589 Mit KI im Handel verkn&#252;pft ist die gro&#223;e Erwartung in der Logistik, hier wird KI als gro&#223;er Game-Changer gesehen: So wird erwartet,
dass bis 2030 KI viele Aufgaben &#252;bernehmen wird, etwa die Planung von Routen, den Warentransport mit autonomen Lieferwagen 
zwischen Unternehmen oder autonomen Drohnen bis zur Endkundin oder zum Endkunden (vgl. Bitkom e. V. (2019): Logistik muss
Digitalisierung weiter beschleunigen). Da KI und Logistik im Bericht der Projektgruppe &#8222;KI und Mobilit&#228;t&#8220; in Kapitel C. VI. [
K&#252;nstliche Intelligenz und Mobilit&#228;t (Projektgruppe 5)] n&#228;her betrachtet werden, konzentriert sich diese Darstellung auf den Handel.
Viele Unternehmen im Handel gehen davon aus, dass ihr Gesch&#228;ft k&#252;nftig nur durch KI-Einsatz im Wettbewerb
bestehen kann, denn die gro&#223;en amerikanischen Handelsunternehmen setzen bereits entlang der gesamten
Wertsch&#246;pfungskette auf KI, unterst&#252;tzt durch KI-basierte Tools wie Alexa, Cortana oder Google Home.590
Insbesondere eine vorausschauende Datenanalyse (Predictive Analytics) ist f&#252;r den Online- wie den station&#228;ren Handel
relevant, um das richtige Produkt zur richtigen Zeit am richtigen Ort und zum marktgerechten Preis anbieten zu
k&#246;nnen. Auch viele H&#228;ndler in Deutschland testen bereits in Pilotprojekten neue M&#246;glichkeiten zur
Personalisierung, Kommunikation, Warenauslieferung und zu dynamischen Preisdifferenzierungen (Dynamic Pricing) durch
KI.591 
Verbrauchersch&#252;tzer f&#252;rchten, dass Dynamic Pricing, das nicht nur im Handel, sondern auch in anderen Branchen
wie Versicherungen, Hotelgewerbe oder im Sharing-Bereich zum Einsatz kommt, vor allem den Unternehmen
hilft, Kundinnen und Kunden zu &#252;bervorteilen, um gr&#246;&#223;tm&#246;glichen Profit zu erlangen.592 Rechtlich ist Dynamic
Pricing in Deutschland nicht greifbar, denn grunds&#228;tzlich steht es in der sozialen Marktwirtschaft dem H&#228;ndler
frei, seinen Preis f&#252;r ein Produkt zu gestalten.
Die &#246;konomischen Chancen, die sich aus dem Einsatz von KI im Handel ergeben, sind vielf&#228;ltig:
Unternehmensvertreterinnen und -vertreter &#228;u&#223;ern die Erwartung, dass sich durch KI in Zukunft Nachfrage und Wertsch&#246;pfung
optimal steuern lassen und dass ressourcenschonender agiert werden kann &#8211; beispielsweise um Retouren zu
verringern oder die Menge von verdorbenen Waren deutlich zu reduzieren &#8211; oder dass die Mitarbeiterinnen und
Mitarbeiter in ihren Arbeitsprozessen k&#252;nftig besser unterst&#252;tzt werden k&#246;nnen.593 Auch im Backend-594 und 
Backoffice-Bereich595 wird KI im Handel k&#252;nftig eine tragende Rolle prognostiziert, z. B. bei der
Personalplanung, wenn KI den Mitarbeiterbedarf in Echtzeit ermittelt und alle relevanten Einflussfaktoren, wie aktuelle
Besucherstr&#246;me, das Wetter und geplante Rabattaktionen, ber&#252;cksichtigt oder zeitraubende Routineaufgaben &#8211;
etwa das Anlegen von Stammdaten oder die Pr&#252;fung von Rechnungen &#8211; erledigen kann.596 Im station&#228;ren Handel
k&#246;nnen Roboter etwa zur Verr&#228;umung von Waren und zur Inventur genutzt werden. Diese Robotik-Plattformen
erlauben ebenfalls die effiziente Verkn&#252;pfung von Online- und station&#228;ren Handelsprozessen, wenn Roboter im
Supermarkt w&#228;hrend der &#214;ffnungszeiten Eink&#228;ufe f&#252;r Online-Kundinnen und -Kunden zusammenstellen. 
W&#228;hrend der KI-Einsatz im Handel aus Unternehmersicht somit einen hohen Effizienz- und Flexibilit&#228;tsgewinn 
bringen kann, wird aus Arbeitnehmersicht auch auf potenziell negative Effekte durch Digitalisierung und KI
hingewiesen, wie hoher Arbeitsdruck, Kurzarbeit und sinkende Arbeitsqualit&#228;t.597 
Gleichwohl ist zu ber&#252;cksichtigen, dass eine fl&#228;chendeckende Verbreitung von KI-Technologien im deutschen
Handel zurzeit noch nicht feststellbar ist: Laut einer aktuellen Studie ist KI erst bei einem Drittel der H&#228;ndler im
Einsatz, ein weiteres Drittel hat konkrete Umsetzungspl&#228;ne f&#252;r die n&#228;chsten drei Jahre, w&#228;hrend die restlichen
H&#228;ndler noch nicht aktiv geworden sind. Bislang sind es in Deutschland vor allem die gro&#223;en Handelsketten, die
590 F&#252;r problematisch halten Teile der Projektgruppe, dass die genannten Tools den Verbraucherinnen und Verbrauchern als pers&#246;nliche
Assistenten des Alltags verkauft werden, w&#228;hrend sie gleichzeitig als Datensammler und Verkaufsagenten der Datenkonzerne
eingesetzt werden k&#246;nnten.
591 Neben Saturn mit seinem k&#252;nstlichen Verkaufsassistenten Paul testete auch das Schwesterunternehmen Media Markt den Einsatz 
von intelligenten Maschinen: Ein Lieferroboter soll k&#252;nftig die Zustellung auf der &#8222;letzten Meile&#8220; &#252;bernehmen. Versandh&#228;ndler Otto 
erprobt in seinem Onlineshop ein neues Feature, das Produktbewertungen mithilfe K&#252;nstlicher Intelligenz nach Themen filtert (&#8222;F&#228;llt 
das Kleid gr&#246;&#223;er aus?&#8220;, &#8222;Wie ist der Tragekomfort?&#8220;) und so f&#252;r die Kundschaft besser nutzbar macht; vgl. Darstellung von Dr.
Michael M&#252;ller-W&#252;nsch (OTTO-Group) in der Sitzung der Projektgruppe &#8222;KI und Wirtschaft&#8220; am 8. April 2019; vgl. auch McKinsey
&amp; Company (2017): K&#252;nstliche Intelligenz im Handel &#8211; Appetit auf den Algorithmus.
592 Vgl. Verbraucherzentrale Brandenburg e. V. (2018): Dynamische Preisdifferenzierung im Online-Handel.
593 Darstellung von Dr. Michael M&#252;ller-W&#252;nsch (OTTO-Group) in der Sitzung der Projektgruppe &#8222;KI und Wirtschaft&#8220; am 8. April 2019.
594 Als Backend wird der Teil eines IT-Systems bezeichnet, der sich mit der Datenverarbeitung im Hintergrund besch&#228;ftigt.
595 Das Backoffice umfasst diejenigen Organisationseinheiten eines Unternehmens, die keine Schnittstelle zu Kunden aufweisen.
Gegensatz ist das &#8222;Frontoffice&#8220;.
596 Vgl. E-Tailment &#8211; Das Digital Commerce Magazin von Der Handel (2018): Whitepaper &#8222;KI im Handel&#8220;.
597 Die Arbeitsqualit&#228;t im Handel ist, bezieht man alle Sektoren ein, bereits heute laut Institut DGB-Index Gute Arbeit (vgl. Institut
DGB-Index Gute Arbeit (2018): DGB-Index Gute Arbeit &#8211; Der Report 2018) im unteren Mittelfeld zu verorten. In Bereichen, in
denen die Digitalisierung bereits weit fortgeschritten ist und teilweise KI eingesetzt wird, sinkt die Arbeitsqualit&#228;t eher (vgl. Daum
(2018): Digitaler Wandel in Call- und Service-Centern: Aktuelle Trends und ihre Folgen f&#252;r Arbeitsorganisation und Besch&#228;ftigte) 
und es tritt &#8222;digitaler Stress&#8220; auf, der die Arbeitnehmerinnen und Arbeitnehmer zus&#228;tzlich belastet (vgl. Gimpel et al. (2018): Digitaler
Stress in Deutschland).
den KI-Einsatz erproben.598 Teilweise geschieht dies in Kooperation mit Forschungsreinrichtungen, wie z. B. 
dem Innovative Retail Laboratory des DFKI.599 
Was die Akzeptanz durch Kundinnen und Kunden anbelangt, so zeigt eine repr&#228;sentative Studie, dass der Einsatz
von KI im Handel in Deutschland noch polarisiert: W&#228;hrend Assistenzfunktionen, wie die Online-Bestellung und
Lieferung von Waren oder die Begleitung von Robotern beim Einkaufen, begr&#252;&#223;t werden, &#252;berwiegt die Skepsis
bei KI-Anwendungen, die st&#228;rker in den Pers&#246;nlichkeitsbereich eingreifen, wie Einkaufen durch Smart Lock600 
oder Scans am Gesch&#228;ftseingang. Bef&#252;rchtet werden eine zu gro&#223;e Fremdbestimmung und Defizite gegen&#252;ber
der pers&#246;nlichen Beratung im Einzelhandel, wobei sich j&#252;ngere Menschen deutlich offener f&#252;r pers&#246;nlich
zugeschnittene KI-Anwendungen im Handel zeigen.601 
4.1.3.2.3 Themenfeld Finanzmarkt und Versicherungen
Der technologische Fortschritt, die zunehmende Optimierung von Gesch&#228;ftsmodellen durch Verwendung gro&#223;er
Datenmengen und das steigende Interesse der Verbraucherinnen und Verbraucher an digitalen Produkten sind
Treiber eines tiefgreifenden Wandels in der Finanzwirtschaft.602 Im deutschen Branchenvergleich z&#228;hlt die
Finanz- und Versicherungsbranche zu den Vorreitern der Digitalisierung603 und eine Umfrage des Center for
Financial Studies an der Frankfurter Goethe-Universit&#228;t ergab, dass die deutsche Finanzbranche KI-Technologien
als ein zuk&#252;nftiges Kernthema der Finanzbranche sieht.604 Auch der FinTechRat des Bundesministeriums der
Finanzen unterstreicht in seinem k&#252;rzlich erschienenen Positionspapier die Bedeutung effizienter
Informationstechnologie und einer nachhaltig leistungsf&#228;higen digitalen Infrastruktur f&#252;r die Leistungs- und
Wettbewerbsf&#228;higkeit der Unternehmen. Er fordert attraktive Rahmenbedingungen sowie die Etablierung und die
kontinuierliche Wahrung hoher Datenschutz- und Sicherheitsstandards f&#252;r den Finanzplatz Deutschland.605 Dieser Wandel
zeigt sich u. a. an dem in Deutschland stark wachsenden Markt von FinTech-Start-ups, die klassische
Finanzmodelle modernisieren und die Branche mit neuen Angeboten aufbrechen. Diese potenziell weitreichenden
Auswirkungen von KI auf die Finanz- und Versicherungsbranche bieten sowohl Chancen als auch Risiken f&#252;r
Unternehmen sowie Verbraucherinnen und Verbraucher, weswegen eine enge Begleitung durch Aufsicht und
Regulierung unabdingbar ist.
Die Unternehmen der Finanz- und Versicherungsbranche erwarten enorme Potenziale im Bereich der fachlichen
Kernprozesse, im Vertrieb und im Kundenservice. Banken nutzen KI u. a. im Bereich des Risikomanagements.606 
Aufgrund schnellerer Prozesse und erweiterter M&#246;glichkeiten einer Personalisierung der Dienstleistungen ist eine
zunehmende Spezialisierung der Gesch&#228;ftsmodelle und das Entstehen neuer Marktteilnehmer m&#246;glich, welche
sich auf Teile der Wertsch&#246;pfungskette spezialisieren anstatt ein vollst&#228;ndiges bankfachliches Produkt
anzubieten.607 Versicherungen erwarten ebenfalls hohe Wertsch&#246;pfungszuw&#228;chse und nutzen KI-Anwendungen speziell
im Bereich des Betrugs- und Schadenmanagements.608 Daneben sind auch disruptive Ver&#228;nderungen denkbar.
So k&#246;nnten Versicherungen durch KI-Systeme anhand von Aufnahmen eingetretener Naturkatastrophen den
entstandenen Schaden vorhersagen. Dadurch k&#246;nnen Sch&#228;den ohne Schadensmeldungen durch die Betroffenen im
Vorweg kalkuliert werden.609 Die Versicherungswirtschaft entwickelt sich damit auch zu einem Gesch&#228;ft der
Risikokalkulierung und der Vorhersagen.610 
598 Vgl. EHI Retail Institute e. V. (2019): KI &#8211; wichtigster Zukunftstrend im Handel; E-Tailment &#8211; Das Digital Commerce Magazin von 
Der Handel (2018): Whitepaper &#8222;KI im Handel&#8220;.
599 Weitere Informationen dazu unter: http://innovative-retail.de (zuletzt abgerufen am 30. Juli 2020).
600 Durch ein intelligentes Schlie&#223;system k&#246;nnen der Eintritt in die Wohnung und der Zugriff auf bestimmte Ger&#228;te f&#252;r einen gewissen 
Zeitraum und f&#252;r bestimmte Personen freigeschaltet werden.
601 Vgl. Bundesverband Digitale Wirtschaft e. V (2018): K&#252;nstliche Intelligenz im Handel &#8211; Vom Professional Butler zur DSGVO; 
PricewaterhouseCoopers (2018): Handel im Wandel.
602 Vgl. Bundesanstalt f&#252;r Finanzdienstleistungsaufsicht (2018): Big Data trifft auf K&#252;nstliche Intelligenz &#8211; Herausforderungen und
Implikationen f&#252;r Aufsicht und Regulierung von Finanzdienstleistungen, S. 8.
603 Vgl. Bundesministerium f&#252;r Wirtschaft und Energie (2018): Monitoring-Report Wirtschaft DIGITAL 2018, S. 13.
604 Vgl. Center for Financial Studies (2018): CFS-Umfrage: K&#252;nstliche Intelligenz wird zuk&#252;nftig zu den Kernthemen der
Finanzindustrie z&#228;hlen &#8211; Mehr Initiative zur Information und Aufkl&#228;rung der Bev&#246;lkerung sinnvoll.
605 Vgl. FinTechRat (2019): Cloud for the financial industry, S. 2.
606 Darstellung Nicolas Kipp (RatePay) in der Sitzung der Projektgruppe &#8222;KI und Wirtschaft&#8220; am 8. April 2019.
607 Vgl. Bundesanstalt f&#252;r Finanzdienstleistungsaufsicht (2018): Big Data trifft auf K&#252;nstliche Intelligenz &#8211; Herausforderungen und
Implikationen f&#252;r Aufsicht und Regulierung von Finanzdienstleistungen, S. 9.
608 Vgl. Finkenzeller (2019): K&#252;nstliche Intelligenz soll Versicherungsbetrug aufdecken.
609 Vgl. Balasubramania et al. (2018): Insurance 2030&#8212;The impact of AI on the future of insurance.
610 Darstellung Michael Bruch (Allianz SE) in der Sitzung der Projektgruppe Wirtschaft am 8. April 2019.
Im Bereich der Betrugserkennung gibt es sowohl f&#252;r die Finanzaufsichtsbeh&#246;rden, den Staat insgesamt sowie die
Steuerzahlerinnen und -zahler als auch f&#252;r die Compliance-Prozesse611 der Unternehmen gro&#223;es Potenzial.612 
Dank KI lassen sich Muster und Anomalien besser erkennen, was zu einer effektiveren Pr&#228;vention gegen
verschiedene Arten der Wirtschaftskriminalit&#228;t wie Geldw&#228;sche, Insiderhandel, Steuerbetrug und
Terrorismusfinanzierung f&#252;hren kann.613 Dies k&#246;nnte auch im Bereich der Informationssicherheitsrisiken genutzt werden. Den
Aufsichtsbeh&#246;rden w&#228;re es durch den Einsatz von KI m&#246;glich, sehr viel schneller Risiken einzelner Institute
anhand von Echtzeit-Daten zu erkennen.
Chancen bietet KI auch, um nicht-finanzielle Indikatoren, beispielsweise in den Bereichen Anti-Korruption,
Diversit&#228;t, CO2-Fu&#223;abdruck oder Lieferkettenmanagement, st&#228;rker bei Investitionsentscheidungen und
Unternehmensbewertungen zu ber&#252;cksichtigen. Mit der Berichterstattung &#252;ber nicht-finanzielle Indikatoren im
Lagebericht, mit der zunehmenden Standardisierung im Bereich &#8222;Corporate-Responsibility-Reporting&#8220;
(Berichterstattung zur unternehmerischen Verantwortung) und den vorhandenen Ratings und Rankings im Bereich 
&#8222;Sustainable Finance&#8220; (nachhaltige Finanzen) st&#252;nde hierf&#252;r eine umfassende und weitgehend standardisierte
Datenbasis nicht-finanzieller Indikatoren zur Verf&#252;gung. 
F&#252;r Verbraucherinnen und Verbraucher kann durch die Nutzung von KI und den sich daraus ergebenden
effektiveren Prozessen im Kundenservice und den personalisierbaren Angeboten der Finanz- und
Versicherungsdienstleister ein Mehrwert geschaffen werden. So kann ein individualisierbares (Risiko-)Profil Verbraucherinnen
und Verbrauchern eine bessere Entscheidungsgrundlage bieten. Dadurch k&#246;nnen sie es beispielsweise leichter
vermeiden, vom Abschluss von Zusatzangeboten &#252;berzeugt zu werden, die f&#252;r sie unn&#246;tig oder ineffizient sind.
Au&#223;erdem k&#246;nnte sich durch ein personalisierbares Profil tendenziell die Notwendigkeit von Vertriebsstrukturen
er&#252;brigen, sodass teure oder verdeckte Provisionen entfallen. Ebenso sind eine bessere Vergleichbarkeit und
Transparenz unterschiedlicher Anbieter und eine h&#246;here Benutzerfreundlichkeit, z. B. durch eine Nutzung per
Handy-App, m&#246;glich und w&#252;nschenswert. 
Gleichwohl k&#246;nnte der Einsatz von KI in der Finanz- und Versicherungsbranche auch zu einer Reihe nicht
akzeptabler Konsequenzen f&#252;r Verbraucherinnen und Verbraucher f&#252;hren, etwa zu Diskriminierung,
Marktausschluss oder einer unverh&#228;ltnism&#228;&#223;igen Benachteiligung von K&#228;uferinnen und K&#228;ufern durch personalisierte,
erh&#246;hte Preise. Die bereits g&#228;ngige Praxis personalisierter Angebote durch den Menschen kann durch die
M&#246;glichkeiten von KI versch&#228;rft werden, da die Summe der einbezogenen Kriterien zunimmt und die technischen
M&#246;glichkeiten einer fl&#228;chendeckenden Implementierung personalisierter Preise bereits gegeben sind.614 Es
besteht die Gefahr einer automatisierten Ungleichbehandlung aufgrund von Herkunft, Geschlecht oder anderer
Diskriminierungsmerkmale gem&#228;&#223; der EU-Grundrechtecharta, z. B. durch Ausschluss oder h&#246;here Zinsen bei der
Kreditvergabe.
Die Entwicklung in China im Bereich elektronischer Zahlungsdienstleistungen kann Aufschluss dar&#252;ber geben,
welche Herausforderungen in diesem Bereich vor uns liegen, denn dort sind sowohl die Marktkonzentration als 
auch der mangelnde Datenschutz beim Bezahlverhalten von Verbraucherinnen und Verbrauchern
hochproblematisch; sie sind gerade angesichts der steigenden Beliebtheit digitaler W&#228;hrungen im internationalen Raum ernst
zu nehmen.615 
Aus diesem Grund sind Daten- und Verbraucherschutz sowie Marktkonzentration in den Bereichen elektronische
Zahlungsdienstleistungen und digitale W&#228;hrungen eine grunds&#228;tzliche Regulierungsaufgabe, die eine strenge
Kontrolle durch Aufsichtsbeh&#246;rden erforderlich macht.  
Ohne eine angemessene Aufsicht und Kontrolle drohen durch den Einsatz von KI in der Finanzwirtschaft auch
erhebliche systemische Risiken f&#252;r die Finanzmarktstabilit&#228;t. So kann sich der Effekt einer algorithmischen
Fehlentscheidung potenzieren und sich eine Krise ausbreiten, wenn mehrere &#8222;Trading Bots616&#8222; oder Institutionen die
611 Der Begriff Compliance bezeichnet die Einhaltung gesetzlicher Bestimmungen, regulatorischer Standards sowie die Erf&#252;llung
weiterer, wesentlicher und in der Regel vom Unternehmen selbst gesetzter ethischer Standards und Anforderungen.
612 Vgl. Bundesanstalt f&#252;r Finanzdienstleistungsaufsicht (2018): Big Data trifft auf K&#252;nstliche Intelligenz &#8211; Herausforderungen und
Implikationen f&#252;r Aufsicht und Regulierung von Finanzdienstleistungen, S. 14.
613 Siehe hierzu auch den Bericht der Projektgruppe &#8222;KI und Staat&#8220; in Kapitel C. III. [K&#252;nstliche Intelligenz und Staat (Projektgruppe 2)].
614 Vgl. Zander-Hayat et al. (2016): Personalisierte Preise.
615 Das Land hat im Jahr 2019 ein gesch&#228;tztes Gesamttransaktionsvolumen im Segment &#8222;Mobile POS Payments&#8220; (Zahlungen an mobilen
Verkaufsstellen) von 514.874 Millionen Euro, das sich auf gut 500 Millionen Nutzerinnen und Nutzer verteilt (vgl. Statista (2020):
Mobile POS Payments &#8211; China) Der Markt wird von zwei Unternehmen dominiert (vgl. Nitsche (2018): Alipay, WeChat &amp; UnionPay
&#8211; Chinas Big Three). Durch die online erfassten Zahlvorg&#228;nge ist eine Kontrolle des Einkaufs- und Konsumverhaltens von
B&#252;rgerinnen und B&#252;rgern sowie Verbraucherinnen und Verbrauchern m&#246;glich (vgl. Shi (2018): Die KP liest immer mit). 
616 Trading Bots sind Computerprogramme, die den automatisierten Handel erm&#246;glichen.
gleichen Algorithmen oder Daten verwenden. Falschmeldungen, auf die Algorithmen in Bruchteilen einer
Sekunde reagieren, k&#246;nnen reichen, um massive Verk&#228;ufe und Preisst&#252;rze in Gang zu setzen. Auch eine bewusste
Manipulation von Algorithmen ist nicht ausgeschlossen. Probleme, die sich z. B. im Bereich des
Hochfrequenzhandels gezeigt haben, k&#246;nnten durch den Einsatz leistungsf&#228;higerer Algorithmen und KI noch verst&#228;rkt werden.
Zudem erweitert die neue Zahlungsdiensterichtlinie PSD2 durch global agierende Technologieunternehmen den
Kreis der Anbieter, welche bislang &#252;berwiegend nicht unter die Aufsicht fallen. Hierf&#252;r muss die Finanzaufsicht
kontinuierlich weiterentwickelt und &#252;berpr&#252;ft werden, um auf der einen Seite mit den neuen Akteuren auf dem
Finanzmarkt auf Augenh&#246;he agieren zu k&#246;nnen, auf der anderen Seite unbekannte und innovative Produkte nicht
von vornherein auszuschlie&#223;en. 
4.1.3.2.4 Themenfeld Agrar&#246;konomie und Landwirtschaft617 
Ein gro&#223;es &#246;konomisches wie &#246;kologisches Potenzial f&#252;r Produktinnovationen durch KI besteht im Bereich
Landwirtschaft. KI-Einsatz in der Landwirtschaft wird dabei vorrangig in der breiter angelegten Debatte &#252;ber die
Digitalisierung dieser Branche diskutiert.618 
Bereits heute wird KI dort eingesetzt, beispielsweise um Satellitenaufnahmen von landwirtschaftlichen Fl&#228;chen
auszuwerten, die Bodenfeuchte zu bestimmen, Prognosen zum Ernteertrag zu erstellen oder Sch&#228;dlingsbefall zu
erkennen.619 Weitere sehr n&#252;tzliche KI-Anwendungen k&#246;nnten k&#252;nftig in der Landwirtschaft verst&#228;rkt eingesetzt
werden. So k&#246;nnten Roboter, die Kulturpflanzen von Unkraut unterscheiden und letztere mechanisch oder
elektrisch vernichten k&#246;nnen, Industriesch&#228;tzungen zufolge den Herbizideinsatz in Reinkulturen wie Mais oder
Zuckerr&#252;ben um bis zu 90 Prozent reduzieren.620 In der Tierhaltung k&#246;nnten besser messbare Futterausgaben,
Sensorik bei der Haltung und Produktion, Video&#252;berwachung oder Fitness-Tracker in der Milchviehhaltung
helfen, die Tiergesundheit zu verbessern und Medikamentengabe wie Futtermittelmengen zu reduzieren.621 
Konventionelle und biologische Produkte k&#246;nnten mit weniger menschlichem Aufwand kosteng&#252;nstiger
produziert werden. Perspektivisch k&#246;nnte in vollautomatischen 3-D-Farmen mit weniger Fl&#228;chenbedarf ohne
Insektenvernichtungsmittel und im besten Fall als Teil der st&#228;dtischen Bebauung mehr Ertrag erreicht und mehr
Nahrung f&#252;r mehr Menschen auf kleinerem Raum erzeugt werden.622 Erh&#246;hte Transparenz bei der Erzeugung,
insbesondere bei der Tierhaltung, k&#246;nnte die Absatzchancen f&#252;r Landwirtinnen und Landwirte verbessern. KI k&#246;nnte
somit die Landwirtschaft &#246;kologischer und effizienter machen und gleichzeitig neue Gesch&#228;ftsideen
erm&#246;glichen.  
KI-Innovation im Landmaschinenbau und ihre Nutzung f&#252;r eine umweltfreundlichere Landwirtschaft ben&#246;tigen
die enge Zusammenarbeit von Forschungsinstituten, kleinen und gro&#223;en Agrarbetrieben und
Landmaschinenherstellern. Leider scheitert dies heute insbesondere an der Bandbreite der kleineren Partner.
617 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 4.1.3.2.4 des Berichts der
Projektgruppe &#8222;KI und Wirtschaft&#8220; (&#8222;Themenfeld Agrar&#246;konomie und Landwirtschaft &#8220;) der Abgeordneten Dr. Petra Sitte und
Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo].
618 Vgl. z. B. die Anh&#246;rung &#8222;Chancen und Risiken der Digitalisierung in der Landwirtschaft&#8220; des Ausschusses f&#252;r Ern&#228;hrung und 
Landwirtschaft des Deutschen Bundestages am 11. Februar 2019, weitere Informationen dazu unter: https://www.bundestag.de/do-
kumente/textarchiv/2019/kw07-pa-landwirtschaft-digitalisierung-589806 (zuletzt abgerufen am 30. Juli 2020); und die
Stellungnahme von Prof. Dr. Hansj&#246;rg Dittus, Mitglied des Vorstands des Deutschen Zentrums f&#252;r Luft- und Raumfahrt e. V., f&#252;r das
&#246;ffentliche Fachgespr&#228;ch am 11. Februar 2019, Informationen dazu unter: https://www.bundestag.de/re-
source/blob/592032/29e03ac4a5d417d83f10c2ba51792493/Stn_von_Prof_Dittus-data.pdf (zuletzt abgerufen am 30. Juli 2020).
619 Vgl. die Stellungnahme von Prof. Dr. Hansj&#246;rg Dittus, Mitglied des Vorstands des Deutschen Zentrums f&#252;r Luft- und
Raumfahrt e. V., f&#252;r das &#246;ffentliche Fachgespr&#228;ch am 11. Februar 2019, weitere Informationen dazu unter: https://www.bundestag.de/re-
source/blob/592032/29e03ac4a5d417d83f10c2ba51792493/Stn_von_Prof_Dittus-data.pdf (zuletzt abgerufen am 30. Juli 2020).
620 Vgl. Rayner (2018): Dieser Roboter braucht im Kampf gegen Unkraut 20-mal weniger Herbizide. 
621 Vgl. z. B. das Horizon-2020-Projekt &#8222;The AI-based intelligent assistant for dairy farmers&#8220;, Informationen dazu unter: https://cor-
dis.europa.eu/project/rcn/216748/factsheet/en (zuletzt abgerufen am 30. Juli 2020); vgl. auch Lu et al. (2017): Estimating Sheep Pain
Level Using Facial Action Unit Detection.
622 So sammelten die US-amerikanischen Start-ups Plenty, Bowery, AeroFarms und 80 Acres Farms, die mit Gesch&#228;ftsmodellen
basierend auf &#8222;Vertical Indoor Farming&#8220; (Vertikaler Landwirtschat) in denen KI zum Einsatz kommt, an den Markt gehen, bis zu
dreistellige Millionensummen an Venture Capital ein; vgl. dazu Lee (2019): U.S. vertical farms are racing against the sun; Patel (2019):
Vertical Indoor Farming &#8212; AI revolution in Agriculture.
Die Digitalisierung der Landwirtschaft birgt aber auch die Gefahr einer weiteren Marktkonzentration und eines
zunehmenden Kontrollverlusts sowie einer steigenden Abh&#228;ngigkeit der Landwirtinnen und Landwirte von
Agrarunternehmen.623 Vertrauensw&#252;rdige Datensysteme, ein Fokus auf Datenhoheit bei Landwirtinnen und
Landwirten und anderen Anwenderinnen und Anwendern sowie Open Data und Open Source sind wichtige
Voraussetzungen f&#252;r den Erhalt und die Prosperit&#228;t von mittelst&#228;ndischen Betrieben der Agrarwirtschaft.
4.1.4 Hardware/Infrastruktur
F&#252;r den Einsatz und die Weiterentwicklung von KI sind an KI angepasste Prozessoren notwendig. Souver&#228;nit&#228;t
auf dem Markt der KI-Technologien h&#228;ngt entscheidend von der Kompetenz bei Hardware und Infrastruktur in
Deutschland und Europa ab. Der globale Markt f&#252;r KI-Infrastruktur und Hardware wird f&#252;r das Jahr 2020 auf
36 Milliarden US-Dollar und f&#252;r das Jahr 2025 auf 127 Milliarden US-Dollar gesch&#228;tzt.624 F&#252;r die Jahre 2016
bis 2020 wird mit j&#228;hrlichen Wachstumsraten von 75 Prozent, f&#252;r die gesamte Dekade von 2016 bis 2025 mit
einer j&#228;hrlichen Wachstumsrate von 51 Prozent gerechnet.625 
Bei den eingekauften Produkten und Dienstleistungen dominieren mit 77 Prozent (98 Milliarden US-Dollar)
integrierte KI-Service-Angebote, bei denen Software, Hardware, Trainingsdaten und weitere Komponenten als
Komplett-Dienstleistung bereitgestellt werden, mit gro&#223;em Abstand den Markt. Die wichtigsten Anbieter sind
dabei die gro&#223;en IT-Unternehmen aus den USA und China &#8211; Amazon Web Services, Microsoft, Google Cloud
Platform und Baidu.626 
Rund 16 Prozent Marktanteil (rund 20 Milliarden US-Dollar) entfallen auf den eigentlichen Hardware-Markt,
also den Verkauf von KI-Hardware. Weitere 7 Prozent (9 Milliarden US-Dollar) auf Software, Dienstleistungen
und Beratung rund um KI-Infrastruktur, beispielsweise f&#252;r Architekturentwicklungen, die Implementierung von 
Interface-Systemen f&#252;r die Kommunikation zwischen Hard- und Software und die Modellierung von
Trainingsdaten.627 Hier findet besonders viel Grundlagenforschung statt.628 In diesem Bereich spielen Open-Source-
L&#246;sungen eine gro&#223;e Rolle, wodurch auf der einen Seite die Vermarktung von KI-Software begrenzt ist, auf der
anderen Seite der viel gr&#246;&#223;ere Markt der integrierten KI-Service-Angebote befruchtet wird. Durch die Open-
Source-L&#246;sungen k&#246;nnen Start-ups schneller und g&#252;nstiger KI-Ideen umsetzen. 629 
F&#252;r KI-Anwendungen kommt, abh&#228;ngig von der Komplexit&#228;t der KI-L&#246;sung, sehr unterschiedliche Hardware
zum Einsatz. Das Spektrum reicht vom Kleinstprozessor im Preisbereich von 1 Euro630 &#252;ber Komponenten einer
KI-Infrastruktur f&#252;r PCs631 im Preisbereich von rund 1 000 Euro bis zu Rechenzentren mit mehreren Schr&#228;nken
von Rechnern mit Anschaffungskosten im Bereich von weit &#252;ber 1 Million Euro (Preise Mitte des Jahres 2019).632 
F&#252;r besonders komplexe und rechenintensive Anwendungen wird auf KI-Services zur&#252;ckgegriffen, die &#252;ber
weltweit verteilte Rechenzentren angeboten werden.633 Rechenzeit und Speichervolumen f&#252;r diese heute
leistungsf&#228;higsten KI-Systeme m&#252;ssen bei Benutzung der Services bezahlt werden.634 
Die dominierenden Marktakteure stammen aus den USA und aus China. Im Bereich KI-Services sind die gro&#223;en 
IT-Unternehmen aus den USA und China f&#252;hrend. Den Hardware-Markt f&#252;r gro&#223;e Prozessoren f&#252;r KI-Systeme
623 Vgl. Wissenschaftlicher Beirat der Bundesregierung Globale Umweltver&#228;nderungen (WBGU) (2019): Unsere gemeinsame digitale
Zukunft &#8211; Empfehlungen; Dieser Aspekt wurde ebenfalls in der Anh&#246;rung von Sachverst&#228;ndigen des Ausschusses f&#252;r Ern&#228;hrung und 
Landwirtschaft des Deutschen Bundestages am 11. Februar 2019 zum Thema &#8222;Chancen und Risiken der Digitalisierung in der
Landwirtschaft&#8220; thematisiert, weitere Informationen dazu unter: https://www.bundestag.de/dokumente/textarchiv/2019/kw07-pa-land-
wirtschaft-digitalisierung-589806 (zuletzt abgerufen am 30. Juli 2020).
624 Vgl. Batra et al. (2018): Artificial-intelligence hardware: Artificial-intelligence hardware: New opportunities for semiconductor
companies.
625 Vgl. Bank of America; Merrill Lynch (2016): Global Semiconductors Deep Learning and the processor chips fueling the AI
revolution &#8211; a primer.
626 Vgl. PricewaterhouseCoopers (2019): Opportunities for the global semiconductor market.
627 Vgl. Batra et al. (2018): Artificial-intelligence hardware: Artificial-intelligence hardware: New opportunities for semiconductor
companies.
628 Vgl. Statista (2020): Revenues from the artificial intelligence (AI) software market worldwide from 2018 to 2025.
629 Vgl. Garbade (2018): Top 8 open source AI technologies in machine learning.
630 Weitere Informationen dazu unter: https://www.hackster.io/ML/projects (zuletzt abgerufen am 6. August 2020).
631 Vgl. Dettmers (2016): A Full Hardware Guide to Deep Learning.
632 Sch&#228;tzung des sachverst&#228;ndigen Mitglieds Prof. Dr. Wolfgang Ecker. Dieser Wert ist nat&#252;rlich stark ausstattungsabh&#228;ngig. Ein GPU-
Rackserver mit 64 GPUs und entsprechendem Speicherausbau kosten etwa 200 000 Euro.
633 Vgl. PricewaterhouseCoopers (2019): Opportunities for the global semiconductor market.
634 Vgl. GoogleWachtBlog.de (2018): Milliarden-Investition in die Infrastruktur: Google baut neues Rechenzentrum in Singapur.
dominieren die Hersteller aus dem Silicon Valley635.636 So teilen sich die beiden US-amerikanischen Hersteller
Nvidia und Intel den Markt f&#252;r PCs und Gro&#223;rechner f&#252;r KI-Anwendungen mit Marktanteilen von 72 bzw.
28 Prozent untereinander auf. Die Fertigung erfolgt, wie in der Halbleiterindustrie &#252;blich, weitgehend in Ost-
und S&#252;dostasien.
Derzeit ist ein Wandel der Infrastruktur f&#252;r KI-Anwendungen zu beobachten. Grafikprozessor-basierte L&#246;sungen
sind zwar nach wie vor vorherrschend,637 die Bedeutung von unterschiedlichen Speziall&#246;sungen638 und
programmierbaren Hardware-Strukturen steigt aber stark an,639 sodass Entwickler von programmierbarer Hardware, wie 
das Unternehmen Xilinx aus dem Silicon Valley, an Bedeutung gewinnen d&#252;rften.640 
Der Markt f&#252;r KI in Endger&#228;ten, beispielsweise in Sensoren oder Motorsteuerungen, wird sich bis zum Jahr 2023
voraussichtlich &#252;berdurchschnittlich entwickeln. Der Marktanteil f&#252;r die hier eingesetzten kleinen und g&#252;nstigen
Prozessoren soll von zuletzt 6 Prozent im Jahr 2017 auf 43 Prozent im Jahr 2023 wachsen.641 Bezogen auf die
St&#252;ckzahl werden kleine und g&#252;nstige Prozessoren die Zahl der gro&#223;en KI-Prozessoren um den Faktor 1 000 
&#252;bersteigen.642 Da hier auch viel mehr anwendungsorientierte und spezialisierte L&#246;sungen ben&#246;tigt werden, wird
die Anzahl der zu entwickelnden Produkte weit mehr als um den Faktor 1 000 &#252;ber der Anzahl der gro&#223;en
Prozessoren liegen. Hierf&#252;r wird es entscheidend sein, diese effizient entwickeln zu k&#246;nnen. F&#252;r die deutsche
Wirtschaft ist der Bereich KI in Endger&#228;ten von zentraler Bedeutung, insbesondere in Branchen wie dem
Maschinenbau, der Automatisierungstechnik und dem Automobilbau. 
Im Bereich der kleineren KI-Prozessoren sind aktuell das Unternehmen NXP Semiconductors (mit Sitz in den 
Niederlanden) und das franz&#246;sisch-italienisch-schweizerisch-niederl&#228;ndische Unternehmen STMicroelectronics
die wichtigsten Hersteller. Bei Lizenzen von vorentwickelten KI-Prozessoren sind ARM Limited (mit Sitz in
Gro&#223;britannien) und Cadence aus dem Silicon Valley die Marktf&#252;hrer.643.
Zus&#228;tzlich ist zu beachten, dass das j&#228;hrliche Marktwachstum f&#252;r KI-Hardware vom Branchenverband
Semiconductor Industry Association (SIA)644 mit 59 Prozent angegeben wird. Auf diesem Gebiet investieren laut SIA
die USA auch viel mehr als Asien und insbesondere Europa. Dar&#252;ber hinaus hat DARPA, die Forschungsagentur
des US-amerikanischen Verteidigungsministeriums,645 mehrere in Summe milliardenschwere
Forschungsprojekte gestartet, um den Entwurf von Hardware effizienter zu gestalten. Zusammenfassend kann man sagen, dass
die USA bei der Hardware und Infrastruktur f&#252;r hoch- und mittelkomplexe KI-Aufgaben mit Abstand f&#252;hren. Im
Bereich der kleineren KI-Prozessoren ist Europa heute konkurrenzf&#228;hig. 
4.1.5 &#214;kologie646 
Die Frage, welche Auswirkungen KI auf die &#214;kologie, etwa auf den Energie- und Ressourcenverbrauch hat, ist
komplex. Durch Digitalisierung im Allgemeinen647 wie durch KI im Besonderen ergeben sich gro&#223;e Chancen, 
durch komplexe Verarbeitung von Echtzeitdaten und intelligente Steuerungen erhebliche Potenziale im Bereich
635 Als Silicon Valley wird die Region bei der Stadt San Francisco  bezeichnet, in der die meisten und gr&#246;&#223;ten amerikanischen Elektronik-
und Computer-Unternehmen ihren Sitz haben.
636 Vgl. Bank of America; Merrill Lynch (2016): Global Semiconductors Deep Learning and the processor chips fueling the AI
revolution &#8211; a primer.
637 Graphic Processing Units (GPU) sind heute in jedem Spiele-PC eingebaut. Sie k&#246;nnen KI-Anwendungen beschleunigen, da KI und
Grafik &#228;hnlich strukturierte Rechenvorschriften einsetzen; vgl. auch Deloitte (2017): Hitting the accelerator: the next generation of
machine-learning chips. 
638 Ein Beispiel f&#252;r Speziall&#246;sungen ist die Tensor Processing Unit (TPU) von Google. Die TPU ist f&#252;r KI-Anwendungen optimiert und
f&#252;r diese Anwendung GPUs &#252;berlegen.
639 Field Programmable Gate Arrays (FPGA) erlauben es, die Hardware an einzelne KI-Anwendungen anzupassen. Die Flexibilit&#228;t wird
mit h&#246;herem Programmieraufwand erkauft.
640 Vgl. PricewaterhouseCoopers (2019): Opportunities for the global semiconductor market.
641 Vgl. Schreier (2018): KI wandert von der Cloud an die Edge.
642 Gleiches Marktvolumen bei einem Tausendstel Kosten bedeutet eine um tausend h&#246;here St&#252;ckzahl.
643 Vgl. PricewaterhouseCoopers (2019): Opportunities for the global semiconductor market.
644 Vgl. Yinug (2018): Semiconductors: A Strategic U.S. Advantage in the Global Artificial Intelligence Technology Race.
645 Vgl. Giles (2018): DARPA has an ambitious $1.5 billion plan to reinvent electronics.
646 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 4.1.5 des Berichts der
Projektgruppe &#8222;KI und Wirtschaft &#8220;  (&#8222; &#214;kologie &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds
Dr. Florian Butollo].
647 Vgl. Villani (2018): For a Meaningful Artificial Intelligence &#8211; Towards a French and European Strategy.
der Energie- und Ressourceneffizienz zu heben.648 Mit diesen &#246;kologischen Potenzialen ergeben sich f&#252;r
Unternehmen, insbesondere f&#252;r Start-ups mit innovativen Gesch&#228;ftsideen, neue Marktchancen. Dem gegen&#252;ber stehen
Herausforderungen, insbesondere durch den steigenden Stromverbrauch bei einem zunehmenden Bedarf an
Rechenleistungen. Die Prognosen &#252;ber die Auswirkungen von Digitalisierung und KI auf den Stromverbrauch
schwanken dabei stark. So rechnet die franz&#246;sische Regierung in ihrer KI-Strategie &#8222;AI for Humanity&#8220; damit,
dass im Jahr 2030 zwischen 20 (moderates Szenario) und 50 Prozent (pessimistisches Szenario) des globalen
Stromverbrauchs durch digitale Anwendungen verursacht sein k&#246;nnten.649 Nach Industriestudien k&#246;nnte bei
linearer Fortsetzung gegenw&#228;rtiger Wachstumstrends im Jahr 2040 gar die gesamte globale Energieproduktion f&#252;r
Rechenleistung ben&#246;tigt werden.650 
Die vom BMWi in Auftrag gegebene Studie &#8222;Langfristszenarien f&#252;r die Transformation des Energiesystems in 
Deutschland&#8220; rechnet mit einem Anstieg des Stromverbrauchs von Daten- bzw. Rechenzentren von heute
14 Terawattstunden (TWh) auf 17 TWh bis zum Jahr 2030.651 
&#8226; Herausforderung: Stromverbrauch von KI-Prozessoren
Der hohe Stromverbrauch von KI-Prozessoren ist technologieinh&#228;rent. Die Berechnung von gro&#223;en neuronalen
Netzen &#8211; daher auch der Name &#8222;Deep Learning&#8220; &#8211; ben&#246;tigt gro&#223;e Rechenkapazit&#228;ten.
Ein Grafikprozessor (GPU) ben&#246;tigt heute 250 Watt652 bis &#252;ber 1 000 Watt653, ein autonom fahrendes Auto um
die 2 500 Watt654, sprich 10 und 20 Prozent der Fahrenergie, und das Computerprogramm AlphaGo von Google
DeepMind 1 Megawatt;655 aus heutiger Sicht ist eine Erh&#246;hung der Rechenleistung um mindestens den Faktor
100 bis 1 000 n&#246;tig, um aus einem Go-Champion einen Haushaltsroboter656 zu machen.
Im Gegenzug soll KI in die Endger&#228;te wandern, um den Datentransfer zu reduzieren. Hier sind 1 Mikrowatt
&#8211; sprich ein Millionstel Watt &#8211; im Stand-by-Modus und 1 Milliwatt &#8211; sprich ein Tausendstel Watt &#8211; im Betrieb
das Ma&#223; der Dinge.657 
Der Energiebedarf von KI wird zunehmend als Problem angesehen und es werden Ma&#223;nahmen getroffen, um die
Energieaufnahme zu reduzieren. Im Gro&#223;en sind dies rechenzentrumspezifische Optimierungen, im Kleinen
Optimierungen an der Halbleitertechnologie, Schaltungstechnik, Hardware-Architektur und Algorithmik. Auch
k&#246;nnte ein Mix von klassischen Ans&#228;tzen und KI-Ans&#228;tzen zu energieeffizienteren L&#246;sungen f&#252;hren.
Nach heutigem Wissensstand kann eine energieeffiziente KI nur dann realisiert werden, wenn Algorithmen,
Hardware-Architektur und Schaltungstechnik gemeinsam betrachtet und optimiert werden. Dies erfordert eine
kooperative Herangehensweise, da alle Kompetenzen oft nicht an einer Stelle vorhanden sind. 
&#8226; Chancen: Energie- und Ressourceneinsparung durch KI in der Produktion
Wie gezeigt bedarf die Ausf&#252;hrung von KI-Anwendungen auf Computern einer beachtlichen Energie. Im
Gegenzug erm&#246;glicht die KI auch eine nicht unerhebliche Einsparung der Energie in der Produktion. Dies l&#228;sst sich 
auf drei Faktoren aufteilen: Einsparungen bei der Energieversorgung, beim direkten Energieeinsatz und beim
Transport der Waren.
648 So rechnet die Industriestudie &#8222;Smarter 2030+&#8220; damit, dass durch Effizienzgewinne von IT-Anwendungen die globalen CO2-
Emissionen um 12,08 Gigatonnen reduziert werden k&#246;nnen, wobei der Einspareffekt durch IT 9,7-mal h&#246;her beziffert wird als die
Emissionen, die durch den Energieverbrauch von IT zus&#228;tzlich verursacht werden. Mehr Informationen dazu unter: http://smar-
ter2030.gesi.org/the-opportunity/ (zuletzt abgerufen am 30. Juli 2020).
649 Vgl. Villani (2018): For a Meaningful Artificial Intelligence &#8211; Towards a French and European Strategy.
650 Vgl. Semiconductor Industry Association; Semiconductor Research Corporation (2015): Rebooting the IT Revolution: A call to action.
651 Weitere Informationen zu Langfristszenarien f&#252;r die Transformation des Energiesystems in Deutschland unter:
https://www.bmwi.de/Redaktion/DE/Artikel/Energie/langfrist-und-klimaszenarien.html (zuletzt abgerufen am 30. Juli 2020).
652 Vgl. Schmelzle (2018): Nvidia Geforce RTX 2080 &amp; 2080 Ti im Test: Schnell, innovativ &amp; teuer.
653 Vgl. Dettmers (2016): A Full Hardware Guide to Deep Learning.
654 Vgl. Vaish (2018): Self-driving Cars and Power Consumption &#8212; New Chip Designs.
655 Vgl. Wu (2018): Google&#8217;s New AI Is a Master of Games, but How Does It Compare to the Human Mind?
656 Pers&#246;nliche Diskussion des sachverst&#228;ndigen Mitglieds Prof. Dr. Wolfgang Ecker im Rahmen der Plattform Lernende Systeme.
657 Vgl. Flamand et al. (2018): GAP-8: A RISC-V SoC for AI at the Edge of the IoT; der Artikel berichtet &#252;ber ein KI-Design, das im
Stand-by-Modus 30 Mikrowatt (30 &#956;W, das sind 0,03 mW) und im Betrieb 75 Milliwatt (75 mW) Energie ben&#246;tigt.
Manche Studien658 prognostizieren f&#252;r den deutschen Energiesektor durch effizientere Verfahren, die auf KI
basieren, ein Einsparpotenzial von ca. 30 Milliarden Euro. Zus&#228;tzlich identifizieren Anwenderinnen und Anwender
der KI f&#252;r Energiemanagement-Systeme659 ein Einsparungspotenzial von 20 bis 30 Prozent.
Oft zitiert wird die Energieeinsparung von Google-Rechenzentren basierend auf KI-Techniken: Demnach
konnten durch KI pro Rechenzentrum 40 Prozent der Energie zur K&#252;hlung reduziert werden.660 Allerdings entfallen
nur rund 20 Prozent des Energieaufwands eines Rechenzentrums auf die K&#252;hlung, sodass die
Gesamteinsparungen durch KI hier nur 8 Prozent betrugen.661 Dennoch ist das Energieeinsparungspotenzial in der Prozessenergie
erheblich, schlie&#223;lich verbrauchten die Rechenzentren von Google im Jahr 2016 rund 4,4 Millionen
Megawattstunden (MWh) Strom.662 Das entspricht dem Verbrauch von rund 1,4 Millionen Privathaushalten, die
Einsparung dem Stromverbrauch von immerhin 114 000 Privathaushalten in Deutschland. Trotz der Einsparungen
w&#252;rde aufgrund des prognostizierten Anstiegs des Bedarfs an Rechenkapazit&#228;ten in den n&#228;chsten Jahren das
Gesamtvolumen des Energieverbrauchs deutlich steigen.663 
Der Energieverbrauch in der Produktion wird auch in erheblichem Ma&#223;e von der Lieferkette beeinflusst. Laut
McKinsey664 kann die Lieferkette durch KI um etwa 1,2 bis 2,0 Billionen US-Dollar weltweit optimiert werden.
Geht man von 20 Prozent Anteil der Kosten f&#252;r die Lieferkette an den Fertigungskosten aus,665 ergibt sich ein
sehr gro&#223;es Gesch&#228;fts-, aber auch ein sehr gro&#223;es Einsparpotenzial.
&#8226; Herausforderung: Ressourcenverbrauch 
Bei der Digitalisierung f&#228;llt zum einen viel Elektronikschrott an, zum anderen werden selten vorkommende
Elemente bei der Fertigung von Halbleitern verwendet.666 Vergleicht man man die Zahlen und Prognosen des
Hardware-KI-Markts667 mit denen des gesamten Halbleiter-Markts, so wird klar, dass der KI-Halbleiter-Markt668
derzeit lediglich 5 Prozent des Gesamtmarkts ausmacht. Damit ist der Ressourcenverbrauch durch KI-Hardware
relativ gesehen noch gering.
Ber&#252;cksichtigt man aber, dass der Anteil der KI-Hardware bis zum Jahr 2025 auf ca. 15 Prozent anwachsen soll,
dann wird deutlich, dass eine ressourcenschonende KI erhebliches Marktpotenzial besitzt und unter dem Namen
&#8222;Gr&#252;ne KI&#8220; (Green AI) eine neue Marke f&#252;r &#8222;KI made in Germany&#8220; werden k&#246;nnte. 
&#8226; Chancen: Nachhaltige Produktinnovationen mit KI
Selbstlernende Verfahren und andere Formen automatisierter Informations- und Entscheidungssysteme k&#246;nnen
Basis f&#252;r innovative Produkte und Dienstleistungen sein, die der Anwenderin oder dem Anwender helfen, den
Energie- und Ressourcenverbrauch zu reduzieren. KI kann in vielen unterschiedlichen Branchen zu nachhaltigen
Produktinnovationen und Effizienztechnologien beitragen und neue Gesch&#228;ftschancen erm&#246;glichen.
Unter Ber&#252;cksichtigung aktueller Wetterprognosen und Energiepreise k&#246;nnen beispielsweise KI-Anwendungen
die Heizung, K&#252;hlung und L&#252;ftung moderner H&#228;user und Anlagen in Echtzeit optimieren und geb&#228;udeseitig
vorhandene Energiespeicher zur vorausschauenden Bereitstellung von Regelenergie zur Verf&#252;gung stellen.669 
Gerade f&#252;r den starken deutschen Mittelstand im Bereich Anlagenbau, Energie- und Umwelttechnik ergeben sich
hier erhebliche Gesch&#228;ftschancen, die allerdings nur realisiert werden k&#246;nnen, wenn die passenden
Rahmenbedingungen und Anreizstrukturen f&#252;r Einbau und Nutzung von Effizienztechnologie etabliert sind.
658 Vgl. PricewaterhouseCoopers (2018): Auswirkungen der Nutzung von k&#252;nstlicher Intelligenz in Deutschland.
659 Mehr Informationen dazu unter: https:// www.energycortex.com/ (zuletzt abgerufen am 30. Juli 2020); vgl. auch Ingsoft GmbH
(2017): Hoher Qualit&#228;tsanspruch: gute Lebensmittel, gute Energieeffizienz.
660 Vgl. Evans und Gao (2016): DeepMind AI Reduces Google Data Centre Cooling Bill by 40%.
661 Vgl. Hintemann (2016): Rechenzentren &#8211; Energiefresser oder Effizienzwunder?
662 Vgl. Rixecker (2016): Google senkt Stromverbrauch im Rechenzentrum &#8211; mittels k&#252;nstlicher Intelligenz.
663 Vgl. Villani (2018): For a Meaningful Artificial Intelligence &#8211; Towards a French and European Strategy; Deutsche Energie Agentur
(2017): Analyse der mit erh&#246;htem IT-Einsatz verbundenen Energieverbr&#228;uche infolge der zunehmenden Digitalisierung.
664 Vgl. McKinsey Global Institute (2018): Notes from the AI frontier &#8211; Insights from hundreds of use cases.
665 Vgl. Emporias Management Consulting (2017): Supply-Chain-Management in Industrieunternehmen 2017: Zwischen Wunsch und
Wirklichkeit.
666 Vgl. Wissenschaftlicher Beirat der Bundesregierung Globale Umweltver&#228;nderungen (WBGU) (2019): Unsere gemeinsame digitale
Zukunft &#8211; Empfehlungen; Marscheider-Weidemann et al. (2016): Rohstoffe f&#252;r Zukunftstechnologien 2016; The Shift Project (2019):
Lean ICT: Towards digital sobriety, S. 30 ff.
667 Vgl. Batra et al. (2018): Artificial-intelligence hardware: Artificial-intelligence hardware: New opportunities for semiconductor
companies.
668 Vgl. Statista (2017): Semiconductor industry revenues forecast worldwide, from 2016 to 2024.
669 Weitere Informationen dazu unter: https://www.bigdata.fraunhofer.de/de/geschaeftsfelder/energie_umwelt/ki-projekte-energie-um-
welt.html (zuletzt abgerufen am 30. Juli 2020).
4.1.6 Stand der Administration/Politik &#8211; rechtliche Fragen670 
Bei KI handelt es sich um Technologien, die selbst noch im Werden sind. Gelenkt und beeinflusst werden die
Entwicklung und der Einsatz von KI bereits jetzt durch bestehendes Recht und politische Strategien. Der
existierende Rechts- und Ordnungsrahmen bietet eine stabile Grundlage. Die im November 2018 vorgelegte &#8222;Strategie
K&#252;nstliche Intelligenz&#8220; der Bundesregierung671 gibt eine weitergehende Orientierung f&#252;r KI-Innovationen und
damit auch f&#252;r vorhandene und neue Gesch&#228;ftsmodelle. Die Bundesregierung hat darin zugesagt, den
Rechtsrahmen hinsichtlich Algorithmen- und KI-basierter Entscheidungen, Dienstleistungen und Produkte auf L&#252;cken zu
&#252;berpr&#252;fen und ihn gegebenenfalls anzupassen. Dabei kann als Vorbild auf existierenden Standards aufgebaut
werden, wie z. B. die ISO-Norm ISO 26262, die &#8222;Automotive Safety Integrity Levels&#8220;672 einf&#252;hrt.
Hierzu ist der politische und &#246;ffentliche Diskurs kontrovers: W&#228;hrend einerseits vor m&#246;glichen
Investitionshemmnissen durch weitergehende Regulierungen gewarnt wird, werden andererseits Neuregelungen gefordert,
insbesondere mit Blick auf Transparenz, Nachvollziehbarkeit und &#220;berpr&#252;fbarkeit von KI-Systemen sowie auf 
das Haftungs- und Urheberrecht.
KI tangiert, wie alle anderen informationstechnischen Systeme, sehr unterschiedliche Rechtsgebiete und
Interessen, die in der Enquete-Kommission diskutiert wurden. Die Projektgruppe hat sich auf wirtschaftsrelevante
Rechtsfragen konzentriert und verschiedene Akteure673 in die Beratungen eingebunden. Dabei standen im
Vordergrund: der Schutz von KI-Entwicklungen bzw. Investitionen, haftungs- und zivilrechtliche
Herausforderungen sowie Fragestellungen im Verbraucher-, Datenschutz- und Wettbewerbsrecht. Zudem ging die Projektgruppe
den M&#246;glichkeiten nach, im KI-Bereich mit Selbstregulierung sowie Normung und Standards zu agieren.674 
&#8226; Haftungsrecht
F&#252;r die Herstellung und das Betreiben von KI-Systemen gibt es derzeit keine speziellen Haftungsregelungen.
Grunds&#228;tzlich ist anzumerken, dass Menschen KI-Systeme entwickeln und f&#252;r ihre Zwecke einsetzen. Damit
muss die Verantwortlichkeit f&#252;r den Einsatz von KI und dessen Folgen auch immer bei den Menschen bleiben
und nicht auf die Technik &#252;bergehen. Wird dieser Grundsatz gewahrt, k&#246;nnen die Erstellung und der Einsatz von
KI juristisch nach den gleichen Ma&#223;st&#228;ben bewertet werden wie u. a. die Herstellung anderer Hard- und Software.
Das allgemeine Haftungsrecht wird angewendet: Wer KI entwickelt und auf den Markt bringt, haftet nach der
allgemeinen Produkt- und Produzentenhaftung.675 Wer eine Maschine, einen Roboter, autonome Fahrzeuge oder
eine Software einsetzt, haftet nach den Vorschriften der Betreiberhaftung.676 
Des Weiteren existiert die Haftung f&#252;r Hersteller und Betreiber von unsicheren Produkten bereits umfassend in
Form der Gef&#228;hrdungshaftung. Grunds&#228;tzlich wird davon ausgegangen, dass &#167; 823 Absatz 1 des B&#252;rgerlichen
Gesetzbuchs (BGB) auch die Komplexit&#228;t von KI, wie wir sie heute haben, ausreichend rechtlich abdeckt. 
Grundlegend bei der Haftungsfrage ist, dass eine rein unk&#246;rperliche KI letztlich nur mittelbar durch &#8222;Werkzeuge&#8220;
eine Verletzung der genannten Rechtsg&#252;ter in der realen Welt bewirken kann, z. B. im Rahmen des Internets der
Dinge oder als &#8222;Embedded Software&#8220;.677 Somit ist der Hersteller des Produkts zun&#228;chst der Haftende.678 
670 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 4.1.6 des Berichts der
Projektgruppe &#8222;KI und Wirtschaft &#8220;  (&#8222;Stand der Administration/Politik &#8211; rechtliche Fragen &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica 
Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo].
671 Vgl. Bundesregierung (2018): Strategie K&#252;nstliche Intelligenz der Bundesregierung Die Fortschreibung der KI-Strategie der
Bundesregierung wird f&#252;r Herbst 2020 erwartet.
672 Weitere Informationen dazu unter: https://www.iso.org/standard/43464.html (zuletzt abgerufen am 30. Juli 2020).
673 Sie waren externe Sachverst&#228;ndige in den Sitzungen der Projektgruppe &#8222;KI und Wirtschaft&#8220; am 1. und 8. April sowie am 6. Mai 2019.
674 Diese Themen wurden in den Sitzungen der Projektgruppe &#8222;KI und Wirtschaft&#8220; am 8. April und am 5. Mai 2019 behandelt.
675 Zu den einschl&#228;gigen Pflichten bzw. Haftung bei Pflichtverletzungen nach dem Produkthaftungsgesetz (ProdHaftG) vom 15.
Dezember 1989 und Produzentenhaftung nach &#167; 823 Absatz 1 BGB.
676 Vgl. S&#246;bbing (2019): Fundamentale Rechtsfragen zur k&#252;nstlichen Intelligenz, S. 37 f.
677 Embedded Software bedeutet &#8222;eingebettete Software&#8220; und bezeichnet Programme, die f&#252;r eine spezifische Hardware entwickelt
wurden. Die Anwendungen laufen dabei vom Nutzer weitestgehend unbemerkt im Hintergrund ab und k&#252;mmern sich um die Steuerung,
Regelung und &#220;berwachung der Funktionen.
678 Es wurde dargelegt, dass in der Praxis die Grenzen f&#252;r haftungsrechtliche Verantwortlichkeiten bei KI schwerer zu bestimmen sein 
k&#246;nnten als bei herk&#246;mmlichen Produkten. Ebenso erscheint auch die Zurechnung von Schadensursachen schwieriger. Jedoch wurde 
derzeit keine unmittelbare Veranlassung daf&#252;r gesehen, einen besonderen Gef&#228;hrdungshaftungstatbestand f&#252;r KI zu schaffen.
Vgl. Plattform Industrie 4.0 (2019): K&#252;nstliche Intelligenz und Recht im Kontext von Industrie 4.0.
Bei folgenden Aspekten besteht Unsicherheit, ob mit den neuen KI-Technologien, insbesondere durch
selbstlernende Systeme, neue Haftungsrisiken entstehen k&#246;nnen, die vom bestehenden System nicht mehr ausreichend
erfasst sind.
Der Hersteller einer KI haftet nur insoweit, als das System bereits beim Inverkehrbringen den Fehler beinhaltet
hat oder er ihn nach dem Stand der Wissenschaft und Technik h&#228;tte erkennen k&#246;nnen. Sowohl in &#167; 823 Absatz 1
BGB als auch im Produkthaftungsgesetz (ProdHaftG) ist der Pr&#252;fungsma&#223;stab somit eine retrospektive
Betrachtung. Jedoch legt die Rechtsprechung hohe Ma&#223;st&#228;be an: Hersteller m&#252;ssen bereits bei Konzeption und Planung
von Produkten alle Ma&#223;nahmen treffen, die zur Vermeidung von Gefahren erforderlich und zumutbar sind. Das
ist mit Blick auf komplexe KI-Systeme, aber auch bei anderen technologischen Entwicklungen ein sehr
ambitioniertes Ziel. Denn Hersteller von KI-Systemen m&#252;ssten demnach schon heute wissen, was erforderlich ist und
welche Sch&#228;den nach einem KI-Lernprozess auftreten k&#246;nnen.679 
Hierf&#252;r wird bereits &#252;ber die Entwicklung eines &#8222;Super Codes680&#8220; 681 nachgedacht, mithilfe dessen Risiken der
KI begrenzt oder ausgeschlossen werden: Wenn KI einen neuen Verwendungszweck schaffen kann, wie das bei
selbst lernenden Systemen der Fall ist, so muss ein Hersteller eine Grenze ziehen k&#246;nnen. Das w&#252;rde in der Praxis 
bedeuten, dass bei der Herstellung von KI, die sich neue Gebiete erschlie&#223;en kann, konstruktive Mechanismen
eingebaut werden m&#252;ssten, um die &#220;berschreitung von Grenzen zu verhindern. 
Weitere &#220;berlegungen beziehen sich auf Qualit&#228;tsstandards f&#252;r Trainingsdaten, da Fehler bei der Herstellung
von KI nicht nur in der Programmierung der Algorithmen, sondern auch in unzureichenden Lerndaten liegen
k&#246;nnen. Es gibt derzeit kaum allgemein anerkannte Regelungen und Best Practices, nach denen sich bestimmen 
l&#228;sst, ob Algorithmen und Lerndatenbest&#228;nde ausreichend und angemessen sind. Nach herrschender Auffassung
w&#228;re der Hersteller f&#252;r die Datenreife verantwortlich und m&#252;sste f&#252;r daraus entstehende Sch&#228;den (also f&#252;r nicht
valides Datenmaterial) haften.682 
Da das Produkthaftungsrecht nach &#252;berwiegender Meinung zwar softwaregest&#252;tzte oder -gesteuerte Ger&#228;te
umfasst, nicht aber die Software selbst, besteht die Tendenz, mit Blick auf KI Nachbesserungen zu fordern.683 
Schlie&#223;lich bleibt die Frage offen, ob schon jedes Softwareupdate f&#252;r KI ein neues Inverkehrbringen des mit der
KI ausgestatteten Ursprungsproduktes darstellt, was zu einer Ausweitung der Produkthaftung f&#252;hren w&#252;rde.
Hierbei ist aber zu ber&#252;cksichtigen, dass bei KI in der Regel relevante Sch&#228;den nicht allein durch fehlerhafte Software
hervorgerufen werden, sondern, dass meist mehrere Faktoren zusammen kommen.
Wenn man in die Zukunft blickt, k&#246;nnte eine technische Entwicklung so schnell ablaufen, dass man diese ohne
Hilfsmittel nicht mehr begreifen kann. Diese &#8222;Seed AI&#8220;684, also eine sich selbst optimierende KI, existiert derzeit 
nicht. Selbst dann gehen aber viele Juristinnen und Juristen davon aus, dass die KI mit den genannten Prinzipien
noch rechtlich beherrschbar w&#228;re und gegebenenfalls vertragsrechtlich nachgebessert werden m&#252;sste, aber nicht
im allgemeinen Haftungsregime. 685 Dar&#252;ber hinaus wurde als wichtig angesehen, dass alle Haftungstatbest&#228;nde
im Zusammenhang mit Pflichtversicherungssystemen diskutiert werden. Dies bedeutet, dass im Fall einer
(Gef&#228;hrdungs-)Haftung eine Versicherung dahinterstehen m&#252;sste, analog etwa zur Kfz-Versicherung. Zu
ber&#252;cksichtigen ist, dass eine KI-spezifische Erg&#228;nzung bei der Haftung und bei Pflichtversicherungen einerseits bei
Unternehmen wie bei Nutzerinnen und Nutzern zu mehr Vertrauen f&#252;hren kann, sich auf die KI-Technologie
einzulassen, andererseits aber auch unn&#246;tig Skepsis hervorrufen kann.
679 Vgl. Urteil des Bundesgerichtshofs vom 16. Juni 2009 (Az. VI ZR 107/08). Hier besteht Zweifel in Bezug auf die M&#246;glichkeiten,
weil im Bereich KI noch kein Minimalstandard definiert ist.
680 Der Super Code ist berechtigt, Ergebnisse des Deep Learning Prozesses zu unterdr&#252;cken, zu ver&#228;ndern, zu l&#246;schen und im Zweifel 
eine Entscheidung durch einen Menschen anzufordern. Quellen f&#252;r den Super Code sind Verbotsgesetze, Verordnungen,
Gerichtsentscheidungen und eigene juristische Auslegungen (z. B. Artikel 6 Absatz 1 Buchstabe f DSGVO).
681 Vgl. S&#246;bbing (2019): Fundamentale Rechtsfragen zur k&#252;nstlichen Intelligenz, S. 38.
682 Vgl. Plattform Industrie 4.0 (2019): K&#252;nstliche Intelligenz und Recht im Kontext von Industrie 4.0; Handlungsempfehlungen von
Prof. Dr. Axel Metzger (Humboldt-Universit&#228;t zu Berlin), Projektgruppendrucksache 19(27)PG1-18 vom 2. Mai 2019.
683 In der Reform der Produkthaftungsrichtlinie (85/374/EWG) und der Produktsicherheitsrichtlinie (2001/95/EG) der EU; vgl. auch
Rott (2018): Rechtspolitischer Handlungsbedarf im Haftungsrecht, insbesondere f&#252;r digitale Anwedungen.
684 Elizier Yudkowsky: Theorie von der Technischen Singularit&#228;t &#8211; der Zeitpunkt, ab dem der technische Fortschritt so schnell abl&#228;uft,
dass ihn ein durchschnittlicher Mensch ohne Hilfsmittel nicht mehr begreifen kann; vgl. S&#246;bbing (2019): Fundamentale Rechtsfragen 
zur k&#252;nstlichen Intelligenz, S. 38.
685 Die Diskussion ist inzwischen weiter fortgeschritten; vgl. Europ&#228;ische Kommission (2020): Wei&#223;buch zur K&#252;nstlichen Intelligenz &#8211;
ein europ&#228;isches Konzept f&#252;r Exzellenz und Vertrauen; Europ&#228;ische Kommission (2020): Bericht &#252;ber die Auswirkungen k&#252;nstlicher
Intelligenz, des Internets der Dinge und der Robotik in Hinblick auf Sicherheit und Haftung; siehe hierzu auch das Kapitel 5 des
Mantelbericht [KI und Recht].
Es ist auch darauf hinzuweisen, dass angesichts der Vielf&#228;ltigkeit von KI unterschiedliche Anwendungsf&#228;lle
betrachtet werden m&#252;ssen. KI ist eine Technologie, die in vielen Bereichen genutzt werden kann, zum Teil
verbunden mit gro&#223;em Risiko (wie im Gesundheitsbereich, im Verkehr oder in der Industrie), zum Teil ohne
bedeutsames Risiko. Hierf&#252;r br&#228;uchte es dann entsprechend abgestufte Regelungen.686 
Im Ergebnis ist festzuhalten, dass beim gegenw&#228;rtigen KI-Einsatz die Rechtslage keine Regelungsl&#252;cken im
zivil- und haftungsrechtlichen Bereich aufweist, die ein sofortiges Handeln des Gesetzgebers erforderlich machen 
w&#252;rden. Allerdings ist zu erwarten, dass neue Ans&#228;tze, beispielsweise aus dem Bereich des Maschinellen
Lernens, rasch voranschreiten werden und daher eine kontinuierliche Beobachtung der KI-Entwicklungen aus
gesetzgeberischer Sicht erforderlich ist, um etwaigen Anpassungsbedarf von rechtlichen Regelungen fr&#252;hzeitig zu
erkennen.687 
&#8226; Schutz von KI: Patent- und Urheberrecht
Weiterhin geht es f&#252;r Akteure im KI-Bereich um die Frage, ob ihre Investitionen in KI ausreichend gesch&#252;tzt
sind, also um das Thema &#8222;KI und Immaterialg&#252;terrecht&#8220;, und die Frage, ob jenseits des Urheber- und Patentrechts
Schutzrechte erforderlich sind.
Patente werden in Deutschland f&#252;r Erfindungen auf allen Gebieten der Technik erteilt, sofern sie neu sind, auf
einer erfinderischen T&#228;tigkeit beruhen und gewerblich anwendbar sind.688 KI als reine Computersoftware oder
ein vom Menschen oder einer Maschine selbst erstellter Algorithmus l&#228;sst sich nicht patentieren, jedoch greift
das Patentrecht nach dem deutschen Patentrecht und dem Europ&#228;ischen Patent&#252;bereinkommen, wenn KI Teil
einer Maschine ist, also z. B. bei einem Roboter.689 
Auf dieser Grundlage erteilen das Europ&#228;ischen Patentamt und das Deutsche Patent- und Markenamt bereits
heute zahlreiche Patente auf technische Innovationen im Bereich KI. Dabei liegt derzeit die Innovation eher im
Bereich KI selbst und weniger beim Einsatz von KI, um Erfindungen in anderen Bereichen zu erm&#246;glichen.
Patentanmeldungen in diesem Bereich nehmen nach Statistiken insgesamt zu &#8211; von &#196;mtern und Unternehmen
sind keine bedeutsamen Klagen &#252;ber Schwierigkeiten bei der Anmeldung von Patenten im KI-Bereich bekannt.
Zudem hat das Europ&#228;ische Patentamt seine Pr&#252;frichtlinien in Bezug auf KI erg&#228;nzt.690 Zusammenfassend wird
festgestellt, dass im Patentrecht hinreichender Rechtsschutz f&#252;r technische Innovation im Bereich KI gegeben
ist.
Hinzu kommt der Urheberrechtsschutz, der f&#252;r verschiedene Aspekte von KI greift, etwa f&#252;r Programmcodes
von Computerprogrammen;691 er umfasst dabei aber nur die konkrete Ausformulierung des Programms, nicht
aber die mathematische Methode, die etwa hinter einem lernf&#228;higen System steht; dies ist f&#252;r die
Grundlagenforschung hilfreich.
Sofern die f&#252;r das Training erforderlichen Daten urheberrechtlich gesch&#252;tzt sind und damit die Investitionen f&#252;r
Datenbankhersteller,692 bieten die Urheberrechtsschranken f&#252;r Text und Data-Mining die Grundlage daf&#252;r, dass
686 Das sachverst&#228;ndige Mitglied Dr. Tina Kl&#252;wer wies darauf hin, dass die Gef&#228;hrdungshaftung zutreffend f&#252;r autonom fahrende
Fahrzeuge sei, bei anderen Anwendungsgebieten, wie etwa Bilderkennungstools oder Tools zur Generierung von Texten, liefere der
Hersteller hingegen die Software in einem &#8222;leeren Zustand&#8220;. Diese werde dann durch die Nutzerin oder den Nutzer trainiert.
Beispielsweise k&#246;nne sie oder er rassistische Texte verwenden, um das System zu trainieren. Der Microsoft-Chatbot Tay sei innerhalb 
von 24 Stunden zum Rassisten geworden. In diesem Fall bestehe die eigentliche Gefahr in der Weiterentwicklung des Systems durch
die Nutzerin oder den Nutzer. Der Sachverst&#228;ndige Dr. Florian Butollo kommentierte dazu, dass aus Sicht der
sozialwissenschaftlichen Technikforschung Technik immer sozial konstruiert sei. Somit sei auch KI nicht als &#8222;leere H&#252;lle&#8220; anzusehen, da das Design von
KI-Systemen wesentlich durch die damit verfolgten Ziele gepr&#228;gt sei.
687 Vgl. Plattform Industrie 4.0 (2019): K&#252;nstliche Intelligenz und Recht im Kontext von Industrie 4.0, S. 19. Es wurde dargelegt, dass
in der Praxis die Grenzen f&#252;r haftungsrechtliche Verantwortlichkeiten bei KI schwerer zu bestimmen sein k&#246;nnten als f&#252;r
herk&#246;mmliche Produkte. Ebenso erscheint auch die Zurechnung von Schadensursachen schwieriger. Jedoch wurde keine unmittelbare
Veranlassung f&#252;r die Schaffung eines besonderen Gef&#228;hrdungshaftungstatbestands f&#252;r KI gesehen.
688 &#167; 1 Absatz 1 des Patentgesetzes.
689 Ausf&#252;hrlich dazu S&#246;bbing (2019): Fundamentale Rechtsfragen zur k&#252;nstlichen Intelligenz.
690 Darstellung von Prof. Dr. Axel Metzger (Humboldt-Universit&#228;t zu Berlin) in der Sitzung der Projektgruppe &#8222;KI und Wirtschaft&#8220; am 
6. Mai 2019: Das Patentrecht zeige, &#228;hnlich wie bei Software, Grenzen bei KI-Systemen als reinen mathematischen Methoden, die
nicht unmittelbar in Technik eingebunden seien. Unternehmen sowie Patentanw&#228;ltinnen und Patentanw&#228;lten gelinge es aber in der
Regel, mathematische Methoden so in eine Technologie einzubetten, dass diese patentf&#228;hig w&#252;rden. Vgl. auch Europ&#228;isches
Patentamt (2017): Patents and the Fourth Industrial Revolution, S. 11. sowie die Richtlinien des Europ&#228;ischen Patentamts f&#252;r die
Pr&#252;fung: Teil G-II, 3.3.1 (K&#252;nstliche Intelligenz und Maschinelles Lernen); weitere Informationen dazu unter: https://www.epo.org/law-
practice/legal-texts/html/guidelines/d/g_ii_3_3_1.htm (zuletzt abgerufen am 3. August 2020).
691 Vgl. &#167; 369a UrhG.
692 Schutz f&#252;r Datenbankhersteller nach &#167; 387a UrhG.
KI-Systeme die Daten f&#252;r wissenschaftliche Zwecke verwenden. Die Einf&#252;hrung dar&#252;berhinausgehender
Leistungsschutzrechte f&#252;r Trainingsdaten- oder Trainingsergebnisse von KI-Systemen oder f&#252;r Inhalte, die durch KI-
Systeme geschaffen wurden, wird nach gegenw&#228;rtigem Stand nicht empfohlen.693 
Festzuhalten ist, dass im Urheberrecht die gro&#223;en werthaltigen G&#252;ter durch Schutzrechte ausreichend abgedeckt
sind. Dort, wo L&#252;cken vorhanden sind, gibt es derzeit keine empirische Grundlage f&#252;r ein m&#246;gliches
Marktversagen. Zu der Frage, wann eine KI einer anderen KI so &#228;hnlich ist, dass von einer Urheberrechtsverletzung
ausgegangen werden kann, gibt es jedoch keine einheitliche Auffassung.694 
&#8226; Normierung und Standardisierung bei KI
Normen und Standards haben eine hohe strategische Bedeutung: Sie stellen einen wesentlichen Erfolgsfaktor f&#252;r
die deutsche (Export-)Wirtschaft dar. Sie sind Treiber f&#252;r Innovationen und &#246;ffnen Unternehmen M&#228;rkte. Denn
Standardisierungs- und Normungsprozesse sind in vielen Wirtschaftssektoren bew&#228;hrte Mittel, um den
Austausch von Unternehmen zu f&#246;rdern und Produkte und Dienstleistungen schnell und unkompliziert am Markt zu
etablieren.695 Auch gelingt es dadurch h&#228;ufig, Technologien &#252;ber Branchengrenzen hinweg zu verbinden.696
Entsprechend hoch sind auch die Erwartungen, im Bereich KI mit Standardisierung und Normung erfolgreich zu
agieren.697 
Das Zusammenwirken von Gesetzgebung und Normung hat sich auf europ&#228;ischer Ebene bew&#228;hrt. So macht der
Gesetzgeber in EU-Verordnungen und -Richtlinien keine detaillierten technischen Produkt- und Designvorgaben,
sondern verweist auf technische Normung. Diese Vorgehensweise entlastet den Gesetzgeber von technischer
Detailarbeit sowie von der Pflicht, permanent gesetzliche Anpassungen vorzunehmen, was gerade bei
schnelllebigen Technologien von Vorteil ist.698 In vielen technischen Bereichen findet die Normsetzung inzwischen
ausschlie&#223;lich international statt, da national begrenzte Normung nicht sinnvoll erscheint.
Auf internationaler und europ&#228;ischer Ebene sind das Deutsche Institut f&#252;r Normung (DIN)699 f&#252;r allgemeine
Normierung und der DKE/VDE700 f&#252;r Elektrotechnik, IT und Telekommunikation legitimiert, die Interessen der
deutschen Wirtschaft in den Normungsorganisationen zu vertreten.701 Dabei ist festzustellen, dass Deutschland
international einen gro&#223;en Einfluss in der Normung aus&#252;bt. So besteht auch bei der Normsetzung f&#252;r KI
potenziell die Chance, international eine Themenf&#252;hrerschaft zu &#252;bernehmen. Zu beobachten ist aber, dass andere
L&#228;nder, wie z. B. China, hier eine einflussreichere Rolle anstreben.702 
693 KI braucht f&#252;r das Trainieren von Systemen Datenbest&#228;nde. Diese Datenbest&#228;nde haben f&#252;r Unternehmen gro&#223;en wirtschaftlichen 
Wert. Hierf&#252;r gibt es im Urheberrechtsgesetz den Datenbankschutz, der grunds&#228;tzlich f&#252;r die Datengesamtheiten (Datensatz) passt.
Schwieriger zu beurteilen sind daraus generierte Ergebnisse, etwa ein Heimassistenzsystem, das aus einem gro&#223;en Datensatz
bestimmte Trainingsergebnisse im Hinblick auf das Nutzerverhalten generiert.
694 Zu diskutieren ist, ob und inwieweit KI-Systeme selbst urheberrechtlich sch&#252;tzbare Werke produzieren k&#246;nnen. Momentan sind
Arbeitsergebnisse von KI-Systemen, die &#252;ber eine reine Assistenzfunktion menschlicher Sch&#246;pfungs- bzw. Erfindungsprozesse
hinausgehen, mit den Instrumenten des gewerblichen Rechtsschutzes oder des wettbewerblichen Leistungsschutzes nur selten
schutzf&#228;hig. Arbeitsergebnisse einer KI, bei denen die KI nicht nur als Werkzeug im Rahmen eines menschlichen Erfindungs- oder
Sch&#246;pfungsprozesses t&#228;tig war, sind mit dem aktuellen Instrumentarium des gewerblichen Rechtsschutzes lediglich in Ausnahmef&#228;llen als
Know-how oder im Rahmen des erg&#228;nzenden wettbewerblichen Leistungsschutzes schutzf&#228;hig. Vgl. auch Plattform Industrie 4.0 
(2019): K&#252;nstliche Intelligenz und Recht im Kontext von Industrie 4.0, S. 26 f.
695 Weitere Informationen zum Unterschied zwischen Standards und Normen und zu deren Effekten unter: https://www.din.de/de/ueber-
normen-und-standards/basiswissen (zuletzt abgerufen am 3. August 2020). Zu den Potenzialen vgl. auch Deutsches Institut f&#252;r
Normung e. V. (2019): K&#252;nstliche Intelligenz &#8211; Mit Normung und Standardisierung innovationsfreundliche Rahmenbedingungen f&#252;r die
Technologie der Zukunft schaffen.
696 Dies ist etwa im Energiebereich oder bei der IT-Sicherheit der Fall. Normung bildet zudem die Grundlage f&#252;r Pr&#252;fung und
Zertifizierung; das CE-Kennzeichen ist ein Beispiel daf&#252;r; vgl. auch Verband der Elektrotechnik Elektronik Informationstechnik e. V.
(2016): Die deutsche Normungsroadmap &#8211; E-Energy / Smart Grid.
697 Die Projektgruppe &#8222;KI und Wirtschaft&#8220; hat sich in der Sitzung am 6. Mai 2019 intensiv damit auseinandergesetzt.
698 Durch Normung kann agiler vorgegangen werden und auch h&#228;ufig schneller Konsens erreicht werden, so etwa die Erfahrungen im
Bereich der Elektro- und Informationstechnik; entsprechende Darstellungen von Michael Teigeler und Dr. Sebastian Hallensleben
(Verband der Elektrotechnik, Elektronik und Informationstechnik VDE) in der Sitzung der Projektgruppe &#8222;KI und Wirtschaft&#8220; am
6. Mai 2019.
699 Weitere Informationen dazu unter: https://www.din.de/de (zuletzt abgerufen am 3. August 2020).
700 Weitere Informationen dazu unter: https://www.dke.de/de (zuletzt abgerufen am 3. August 2020).
701 Die Pendants zum DKE sind auf europ&#228;ischer Ebene das Europ&#228;ische Komitee f&#252;r elektrotechnische Normung (CENELEC) und auf
internationaler Ebene die Internationale Elektrotechnische Kommission (IEC). Dies ergibt insgesamt ein Netzwerk von mehr als
100 000 technischen Expertinnen und Experten.
702 Gerade die deutsche elektrotechnische Industrie hat sich &#252;ber Jahrzehnte eine F&#252;hrungsrolle erarbeiten k&#246;nnen, die einen
Standortfaktor f&#252;r Deutschland darstellt; entsprechende Darstellungen von Michael Teigeler und Dr. Sebastian Hallensleben (VDE) sowie
Matthis Eicher und Sibylle Gabler (DIN e. V.) in der Sitzung der Projektgruppe &#8222;KI und Wirtschaft&#8220; am 6. Mai 2019.
Das Interesse an einer grundlegenden Strukturierung der KI-Landschaft durch Normen und Standards ist in
Wirtschaft, Wissenschaft und Politik gro&#223;. Im Rahmen der KI-Strategie der Bundesregierung wurde Standardisierung
als ein zentrales Handlungsfeld benannt und es wurde eine Roadmap zur Pr&#252;fung bestehender Normen und
Standards auf ihre KI-Tauglichkeit angek&#252;ndigt.703 Anfang des Jahres 2018 haben Vertreterinnen und Vertreter von
KMU, Start-ups, Konzernen, Universit&#228;ten, Forschungseinrichtungen, Zertifizierungsstellen und des
Bundesamtes f&#252;r Sicherheit in der Informationstechnik (BSI) sowie Ethikexpertinnen und -experten einen interdisziplin&#228;ren
Arbeitsausschuss &#8222;K&#252;nstliche Intelligenz&#8220; bei DIN gegr&#252;ndet.704 Solche Gremien arbeiten intensiv an
grundlegenden offenen Normen und Standards f&#252;r ein fach&#252;bergreifendes Verst&#228;ndnis von KI. Dadurch soll eine breite
Interoperabilit&#228;t zwischen den verschiedenen Disziplinen, die an der Weiterentwicklung und Nutzung von KI
beteiligt sind, sichergestellt und es sollen Anforderungen an den Umgang mit KI, beispielsweise mit Blick auf
das Risikomanagement, festgelegt werden.705 
So ist etwa die pr&#228;zise Definition von Fachbegriffen, z. B. was KI ist und was nicht, f&#252;r Produktangebote auf
dem Markt essentiell. Au&#223;erdem richten sich die Normungsbestrebungen im Bereich KI auf Daten und
Algorithmen, da bei KI-L&#246;sungen schwerlich Skaleneffekte zu erreichen sind, wenn Trainingsverfahren und
Schnittstellen von Algorithmen nicht genormt sind.706 
Weitere Themen, die gerade in den internationalen Normungsgremien diskutiert werden, sind geeignete
Pr&#252;fverfahren und ethische Standards. Im Bereich Ethik werden verschiedene Ans&#228;tze diskutiert. Am
vielversprechendsten erscheint es derzeit, Skalen zur Klassifizierung von Aspekten ethischen Verhaltens zu schaffen, z. B. zum
Schutz der Privatsph&#228;re, zur Diskriminierungsfreiheit oder Transparenz, &#228;hnlich einer Energieeffizienzskala, um
eine nachvollziehbare &#220;berpr&#252;fbarkeit zu gew&#228;hrleisten. Dieser Ansatz bietet den Vorteil, dass ein transparenter
Wettbewerb geschaffen, regionale Mindeststandards festgesetzt und Entscheidungsfreiheit f&#252;r Verbraucherinnen
und Verbraucher hergestellt werden k&#246;nnte. Es deutet sich an, dass ein solcher Ansatz auf europ&#228;ischer und
internationaler Ebene konsensf&#228;hig sein k&#246;nnte.707 
4.1.7 Zugang zu Daten f&#252;r KI-Anwendungen
F&#252;r die Nutzung von KI ist der Zugang zu Daten essentiell. Wie der Zugang zu Daten ausgestaltet werden kann,
wird f&#252;r eine erfolgreiche Nutzung von KI eine der Schl&#252;sselfragen sein, die es zu beantworten gilt. Im Folgenden
wird diese Frage aus rechtlicher, &#246;konomischer und infrastruktureller Sichtweise beleuchtet.
&#8226; Rechtliche Perspektive
Mit Blick auf den Datenzugang f&#252;r KI-Anwendungen sind besonders die datenschutzrechtlichen und
wettbewerbsrechtlichen Rahmenbedingungen relevant.
703 Vgl. Bundesregierung (2018): Strategie K&#252;nstliche Intelligenz der Bundesregierung, S. 41; DKE.de (2019): Normungs-Roadmap zu
Ethik und KI geplant.
704 Der Arbeitsausschuss &#8222;K&#252;nstliche Intelligenz&#8220; bei DIN ist u. a. f&#252;r die Konsolidierung der Meinungen deutscher Expertinnen und 
Experten sowie deren Vertretung in internationalen Gremien (wie ISO/IEC JTC 1/SC 42) zust&#228;ndig. Weitere Informationen dazu
unter: https://www.din.de/de/forschung-und-innovation/themen/kuenstliche-intelligenz/arbeitsauschuss-ki (zuletzt abgerufen am
3. August 2020).
705 Es wird national bereits an konkreten Standards im Bereich KI gearbeitet, z. B. an der technischen Regel &#8222;DIN SPEC 92 001&#8220;, bei
der sich verschiedene Partner aus Industrie und Forschung mit der Frage auseinandersetzen, welche Aspekte notwendig sind, um die
Qualit&#228;t von KI sicherzustellen. Ein erster Teil ist bereits Anfang des Jahres 2019 ver&#246;ffentlicht worden. Dieser zeigt den
Lebenszyklus auf, innerhalb dessen sich KI bewegt. Zudem wurde die Notwendigkeit einer Risikobewertung aufgezeigt und es wurden KI-
Qualit&#228;tsaspekte herausgearbeitet, etwa zu Leistung und Funktionalit&#228;t, zur Robustheit und zur Verst&#228;ndlichkeit. Eine zweite
nationale Aktivit&#228;t beim DKE betrifft Anwendungsregeln, die sich mit kognitiven Systemen besch&#228;ftigen. Der Fokus liegt dabei auf der
Prozessebene der KI-Entwicklung; entsprechende Darstellung von Matthis Eicher (DIN e. V.) in der Sitzung der Projektgruppe &#8222;KI 
und Wirtschaft&#8220; am 6. Mai 2019.
706 Es zeigt sich, dass die gro&#223;en Player wie Google, Amazon und Facebook hier schon sehr erfolgreich agieren. Daher sollen auch in 
Europa und Deutschland die dezentralen KI-Ressourcen durch genormte Trainingsverfahren, Schnittstellen und Trainingsdatens&#228;tze
zusammengef&#252;hrt werden. Derzeit laufen Verhandlungen unter Stakeholdern wie VDE und dem KI-Bundesverband, um dazu eine 
neutral betriebene Plattform einzurichten; vgl. die entsprechenden Darstellungen von Michael Teigeler und Dr. Sebastian
Hallensleben (VDE) in der Sitzung der Projektgruppe &#8222;KI und Wirtschaft&#8220; am 6. Mai 2019.
707 Im Jahr 2019 hat der DKE einige Schl&#252;sselgremien besetzen k&#246;nnen, damit Deutschland seinen Einfluss bei der KI-Normung
international geltend machen kann. Auf internationaler Ebene teilt sich Deutschland den Vorsitz des entsprechenden Gremiums mit China 
und auf europ&#228;ischer Ebene mit Frankreich. Das seit 2017 daf&#252;r gegr&#252;ndete Gremium ist ein Zusammenschluss der Internationalen
Organisation f&#252;r Normung und der Internationalen Elektrotechnischen Kommission. Nach einer Anfangsphase werde inzwischen in 
den Arbeitsgruppen intensiv gearbeitet, es sei erkennbar, dass sich die ersten Standards etablierten, im Bereich Nomenklatur,
Taxonomie und auf Managementebene. Produktstandards w&#252;rden derzeit noch nicht erarbeitet; vgl. die entsprechenden Darstellungen von 
Michael Teigeler und Dr. Sebastian Hallensleben (VDE) sowie Matthis Eicher und Sibylle Gabler (DIN e. V.) in der Sitzung der
Projektgruppe &#8222;KI und Wirtschaft&#8220; am 6. Mai 2019.
Die DSGVO hat die Grundlage f&#252;r ein hohes Schutzniveau f&#252;r Emittenten von Daten geschaffen. Im
internationalen Wettbewerb kann sich dies als wesentlicher Vorteil europ&#228;ischer KI-Anwendungen herausstellen. Jedoch
stellt die Umsetzung der Datenschutzvorgaben insbesondere KMU vor Herausforderungen.708 Diese sollten bei
der Umsetzung besser unterst&#252;tzt werden, damit der Datenschutz nicht ungewollt zur Beg&#252;nstigung gro&#223;er
Konzerne f&#252;hrt.
Nach Vorgabe der DSGVO m&#252;ssen Verantwortliche technische und organisatorische Ma&#223;nahmen ergreifen, um
eine rechtm&#228;&#223;ige Datenverarbeitung sicherzustellen. Dabei sind die Grunds&#228;tze des Datenschutzes durch
Technikgestaltung (Privacy by Design) und datenschutzfreundlicher Voreinstellungen (Privacy by Default) zu
beachten. Eine Gef&#228;hrdungshaftung f&#252;r die Hersteller von KI-Systemen besteht derzeit jedoch nicht.
Um Lock-in-Effekten709 entgegenzutreten, enth&#228;lt Artikel 20 DSGVO das Recht der Verbraucherinnen und
Verbraucher auf Datenportabilit&#228;t. Dies beinhaltet jedoch kein Recht auf einen Echtzeit-Datenzugang und lediglich 
rudiment&#228;re Vorgaben zur Dateninteroperabilit&#228;t. Um diese Punkte zu erm&#246;glichen, m&#252;sste die DSGVO
erweitert werden. Dem stehen aber wettbewerbsrechtliche Bedenken entgegen. Eine solche Verpflichtung aller
datenverarbeitenden Unternehmen k&#246;nnte nach Expertenmeinung insbesondere f&#252;r die kleinen Anbieter die Kosten 
eines Marktzutritts erh&#246;hen und dadurch die Position der gro&#223;en Anbieter st&#228;rken. Bei marktbeherrschenden
Unternehmen ist eine st&#228;rkere Verpflichtung zur Datenoperabilit&#228;t und -interoperabilit&#228;t sinnvoll. Dies gilt
unabh&#228;ngig von marktm&#228;chtigen Stellungen auch f&#252;r die Schaffung von Anreizen zum Teilen von Daten. Die
Nutzung von Daten der &#246;ffentlichen Hand sollte in einer umfassenden Open-Data-Strategie adressiert werden.
Wichtige Impulse daf&#252;r ergeben sich aus dem Bericht der Wettbewerbskommission 4.0.
Die Erhebung von Daten setzt das Einverst&#228;ndnis der Betroffenen voraus. Bisher bestehen allerdings f&#252;r
Unternehmen, die eine gro&#223;e Zahl von Daten verarbeiten wollen, wenige M&#246;glichkeiten, einer Vielzahl von Personen
ein Angebot zur Datenverarbeitung zu machen. Auf der anderen Seite fehlen Datenemittenten die M&#246;glichkeit,
an einem Ort die Nutzungsbedingungen f&#252;r ihre Daten unternehmens&#252;bergreifend festzulegen. Die (Weiter-)
Entwicklung von Intermedi&#228;ren &#8211; wie z. B. Datentreuh&#228;ndern oder Datengenossenschaften &#8211; kann diese L&#252;cke
f&#252;llen.
&#8226; &#214;konomische Perspektive
Der Zugang zu Daten sowie zu datenverarbeitenden Algorithmen ist f&#252;r die Nutzung von KI elementar. Um
Daten f&#252;r KI bereitzustellen, m&#252;ssen nicht nur die Daten innerhalb von Unternehmen in digitaler Form vorliegen, 
sondern diese m&#252;ssen unternehmens- und branchen&#252;bergreifend geteilt werden. 
Grundlage f&#252;r den Zugang zu Daten ist die Bereitschaft der Unternehmen, diese zu teilen. Daf&#252;r muss
Vertrauen710 zwischen den Unternehmen sowie Vertrauen von Unternehmen in die Funktionsweise von KI gest&#228;rkt
werden. Denn grunds&#228;tzlich verf&#252;gt die deutsche Wirtschaft &#252;ber umfangreiche, aber teilweise ungenutzte
Datenressourcen. &#214;konomische Anreize zum Teilen der Daten bestehen derzeit kaum.
Politische und wirtschaftliche Akteure experimentieren deshalb mit einer Vielzahl von Ans&#228;tzen, um diesen
Datenzugang im Einklang mit rechtsstaatlichen Standards zu erm&#246;glichen. Dabei k&#246;nnen sich mehrere Modelle f&#252;r
einen umfassenden Datenzugang711 herauskristallisieren, die parallel existieren und je nach Bereich (B2B/B2C)
auf die Bed&#252;rfnisse von Menschen und Unternehmen abgestimmt sind. 
Zum einen kann der Zugang zu Daten &#252;ber Datenpools sichergestellt werden. Unternehmen k&#246;nnen solche
Plattformen f&#252;r verschiedene Zwecke der Datennutzung errichten und entwickeln. Dabei teilen sie ihre Daten mit
anderen Unternehmen.712 
Daneben entwickeln sich Datenm&#228;rkte, auf denen Datenbest&#228;nde von Unternehmen k&#228;uflich erworben werden
k&#246;nnen. F&#252;r den Zugang zu Daten haben auch Datengenossenschaften ihren Anteil daran, dass Unternehmen
Daten f&#252;r die Nutzung von KI zur Verf&#252;gung gestellt werden. Im &#220;brigen erscheinen f&#246;derale Konzepte f&#252;r die
708 Die Fraktion B&#220;NDNIS 90/DIE GR&#220;NEN teilt nicht die Ansicht, dass die DSGVO zus&#228;tzliche Herausforderungen in Sachen
&#8222;Privacy by Design and Default&#8220; darstellt. Vielmehr liefere sie entscheidende Weichenstellungen f&#252;r deren Umsetzung.
709 Lock-in-Effekte beschreiben eine enge Bindung von Verbraucherinnen und Verbrauchern an ein Produkt, welche ihnen das Wechseln
zu einem Konkurrenzanbieter erschwert. In der Digital&#246;konomie geschieht dies oft auf Grundlage der Auswertung von Nutzerdaten.
Dadurch k&#246;nnen Produkte individualisiert und somit die Wechselkosten f&#252;r Verbraucherinnen bzw. Verbraucher erh&#246;ht werden.
710 Vgl. die Darstellung von Prof. Dr. Norbert Pohlmann (Institut f&#252;r Internet-Sicherheit, Westf&#228;lische Hochschule Gelsenkirchen) in
der Sitzung der gesamten Enquete-Kommission am 3. Juni 2019.
711 Vgl. die Darstellung des sachverst&#228;ndigen Mitglieds Dr. Stefan Heumann in der Sitzung der gesamten Enquete-Kommission am
3. Juni 2019
712 Vgl. Handlungsempfehlungen Prof. Dr. -Ing. Boris Otto (Fraunhofer ISST), Kommissionsdrucksache 19(27)55 vom 31. Mai 2019;
Darstellung des sachverst&#228;ndigen Mitglieds Dr. Stefan Heumann in der Sitzung der gesamten Enquete-Kommission am 3. Juni 2019.
Etablierung einer dezentralen KI sinnvoll. Dabei k&#246;nnen nicht nur Prim&#228;rdaten (Raw Data) geteilt, sondern es
k&#246;nnen auch die Ergebnisse verschiedener KI-Anwendungen zusammengef&#252;hrt werden.
&#8226; Infrastruktur
Mit dem zunehmenden Einsatz von KI nimmt auch das Thema der Verf&#252;gbarkeit und Nutzung von
Dateninfrastrukturen eine immer wichtigere Rolle ein. Ein europ&#228;isches oder gar deutsches Pendant zu den gro&#223;en KI-
Technologieanbietern wie Amazon, Microsoft oder Alibaba existiert bislang nicht, sodass viele Unternehmen 
mit hohen Anforderungen an Daten und Rechenkapazit&#228;t selten passende alternative Anbieter im hiesigen
Wirtschaftsraum finden. Dennoch: Der Vorsprung dieser amerikanischen Anbieter ist zwar gro&#223;, allerdings k&#246;nnen
Unternehmen durch diverse Technologien verschiedene Cloud-Anbieter parallel nutzen, bei sich &#228;nderndem
Bedarf zu anderen Anbietern wechseln oder auf eigene Technologie-Infrastrukturen zur&#252;ckgreifen.
Ob es gelingt, gro&#223;e europ&#228;ische KI- und Cloud-Anbieter zu etablieren, h&#228;ngt davon ab, in welchen Industrien
und Anwendungskontexten Deutschland bzw. Europa seine Daten- und Wissenshoheit behalten m&#246;chte. So sehen
Studien heute bereits die Gefahr einer Abh&#228;ngigkeit der deutschen Industrie von ausl&#228;ndischen
Softwarekonzernen.713 Sie k&#246;nnten sich beispielsweise durch h&#246;here Datensicherheit und Transparenz sowie h&#246;heren
Datenschutz durch die DSGVO von den nicht-europ&#228;ischen Wettbewerbern unterscheiden.
Zuletzt zeigen sich auch erste KI-L&#246;sungen am Markt, welche die Daten nicht an zentrale Server zur Analyse 
und Verarbeitung durch KI-Methoden zur&#252;cksenden, sondern bei denen diese T&#228;tigkeiten direkt am erfassenden 
Ger&#228;t bzw. Sensor erledigt werden. So werden dann nur bei Bedarf die entsprechenden Ergebnisse und Modelle
an &#252;berlagerte Server und an Netzwerkteilnehmer gesendet. Dies erm&#246;glicht beispielsweise im Maschinenbau
verteiltes Lernen. Hersteller werden in die Lage versetzt, smarte Services f&#252;r ihre Maschinen anzubieten, ohne
dass sie hierf&#252;r auf die Rohdaten ihrer Kunden zugreifen m&#252;ssen. Weitere Anwendungsfelder existierten im
biomedizinischen Bereich bei der Tumorerkennung, wo zwar verschiedene Kliniken ein gemeinsames Modell zur
Tumorerkennung nutzen, die sensiblen Patientendaten die jeweilige Klinik jedoch nicht verlassen.714 
SWOT-Analyse
F&#252;r den Sektor Wirtschaft zeigt sich nach Einsch&#228;tzung der Kommission ein durchaus ausgewogenes Bild
zwischen St&#228;rken und Chancen auf der einen sowie Schw&#228;chen und Risiken auf der anderen Seite. Quintessenz ist,
dass eine erfolgreiche Entwicklung im Bereich KI als technisches Nischendasein nicht funktionieren kann,
sondern als gesamtgesellschaftliche Aufgabe gesehen und angegangen werden muss. Deshalb m&#252;ssen insbesondere
im Hinblick auf die allgemeine Akzeptanz der Technologie sowie vorhandene Skepsis und &#196;ngste Aufkl&#228;rung
und notwendige Regulierungsarbeit geleistet werden. Deutschland und Europa k&#246;nnen ihre Vorteile klug
einsetzen, um im Hinblick auf den starken Wettbewerb insbesondere aus den USA und China zu bestehen.
St&#228;rken
Zusammenarbeit von Industrie und KMU mit
Technologie-Start-ups sowie Bildung von regionalen
Netzwerken und Clustern hat sich in den letzten
Jahren positiv entwickelt 715 
Gute Patentdynamik in der Anwendung von KI im
Segment des autonomen Fahrens und von
autonomen Systemen in menschenfeindlichen
Umgebungen716 
In Deutschland keine allgemeinen Regelungsl&#252;cken 
im zivil- und haftungsrechtlichen Bereich, um KI
Schw&#228;chen
Sehr geringe Anzahl von KMU setzt KI-
Technologien bereits ein720 
Mit Ausnahme einiger Innovationschampions droht
eine geringe Adaption von KI in KMU eine Bremse
in der Innovationsdynamik der deutschen Wirtschaft
zu werden721 
Fehlendes Know-how und eine geringe Anzahl an 
Fachkr&#228;ften hemmen die Implementierung von KI in 
die Prozesse und Produkte von KMU 722 
713 Vgl. Expertenkommission Forschung und Innovation (2018): Studie &#8222;Autonome Systeme&#8220;.
714 Vgl. Sicking et al. (2019): Maschinelles Lernen &#8222;On the Edge&#8220;.
715 Vgl. Kapitel 4.1.3.1.2 dieses Projektgruppenberichts [Themenfeld Mittelstand].
716 Vgl. Expertenkommission Forschung und Innovation (2018): Gutachten 2018.
720 Vgl. Kapitel 4.1.3.1.2 dieses Projektgruppenberichts [Themenfeld Mittelstand]; Fraunhofer-Gesellschaft zur F&#246;rderung der
angewandten Forschung e. V. (2018): Maschinelles Lernen &#8211; Eine Analyse zu Kompetenzen, Forschung und Anwendung. 
721 Vgl. Kapitel 4.1.3.1.2 dieses Projektgruppenberichts [Themenfeld Mittelstand]. 
722 Vgl. Kapitel 4.1.3.1.2 dieses Projektgruppenberichts [Themenfeld Mittelstand]; Verein Deutscher Ingenieure e. V. (2018): VDI-
Statusreport K&#252;nstliche Intelligenz.
Anwendungen in Verkehr zu bringen bzw. zu
betreiben717 
Hinreichender Rechtsschutz im Patentrecht f&#252;r
technische KI-Innovationen718 
Berlin ist europ&#228;isches KI-Innovationzentrum mit
zweitgr&#246;&#223;tem KI-Start-up-Hub in Europa719 
Mangelnde Anzahl an jungen ausgebildeten KI-
Fachkr&#228;ften, u. a. dadurch, dass wenige
Studieng&#228;nge explizite Fokussierung auf Big Data und Data
Science beinhalten 723 
Hoher Aufwand f&#252;r KI-Start-ups, sich f&#252;r
F&#246;rdermittel zu bewerben, sowie teils nicht realistische bzw.
zeitgem&#228;&#223;e Anforderungen bez&#252;glich der Sicherheit
des Gesch&#228;ftsmodells724 
Im internationalen Vergleich schlechte (digitale)
Infrastruktur (Verf&#252;gbarkeit Breitband, Cloud-
Computing, Open Data etc.) erschwert die Implementierung 
von KI-Innovationen in Unternehmen / in der
Wirtschaft
Chancen
Je nach Studie und Urheber wird f&#252;r KI ein
Wachstumspotenzial des Bruttoinlandsprodukts von 160 bis
480 Milliarden Euro in Summe bis zum Jahr 2030 
prognostiziert725 
KI-basierte Produkte von deutschen und
europ&#228;ischen Anbietern mit potenziellem
Wettbewerbsvorteil aufgrund eines h&#246;heren Anbietervertrauens726 
Zwar bereits stark umk&#228;mpfter, aber noch sehr
junger Markt f&#252;r KI-Software, -Hardware und -
Dienstleistungen mit extrem hohen Wachstumsraten727 
Risiken
Verl&#228;ssliche, KI-spezifische Datenbasis fehlt zum
Teil; ein zu optimistischer Diskurs &#252;ber Chancen 
durch KI k&#246;nnte zu nicht zielgerichteten
Investitionen f&#252;hren734 
M&#246;glichkeit der &#220;berwachung von Mitarbeiterinnen 
und Mitarbeitern am Arbeitsplatz und M&#246;glichkeit 
der Arbeitsverdichtung735 
Unsachlicher Diskurs &#252;ber KI beeinflusst
&#246;ffentliches Meinungsbild &#252;ber KI-basierte autonome
Software- und Hardwareanwendung negativ und
verringert Nutzerakzeptanz736 
717 Vgl. Kapitel 4.1.6 dieses Projektgruppenberichts [Stand der Administration/Politik &#8211; rechtliche Fragen].
718 Vgl. Kapitel 4.1.6 dieses Projektgruppenberichts [Stand der Administration/Politik &#8211; rechtliche Fragen].
719 Vgl. Fraunhofer-Gesellschaft zur F&#246;rderung der angewandten Forschung e. V. (2018): Maschinelles Lernen &#8211; Eine Analyse zu
Kompetenzen, Forschung und Anwendung.
723 Vgl. Fraunhofer-Gesellschaft zur F&#246;rderung der angewandten Forschung e. V. (2018): Maschinelles Lernen &#8211; Eine Analyse zu
Kompetenzen, Forschung und Anwendung.
724 Vgl. Kapitel 4.1.3.1.1 dieses Projektgruppenberichts [Themenfeld Start-ups].
725 Vgl. Fraunhofer-Allianz Big Data (2017): Zukunftsmarkt K&#252;nstliche Intelligenz &#8211; Potenziale und Anwendungen; Verein Deutscher
Ingenieure e. V. (2018): VDI-Statusreport K&#252;nstliche Intelligenz; Accenture (2018): Weg ohne Ziel? Wie Deutschland ein
Spitzenstandort f&#252;r K&#252;nstliche Intelligenz werden kann; McKinsey &amp; Company (2017): Smartening up with Artificial Intelligence (AI) &#8211;
What&#8217;s in it for Germany and its Industrial Sector?; PricewaterhouseCoopers (2018): Auswirkungen der Nutzung von k&#252;nstlicher
Intelligenz in Deutschland.
726 Vgl. Begleitforschung PAiCE; iit-Institut f&#252;r Innovation und Technik in der VDI / VDE Innovation + Technik GmbH (2018):
Potenziale der K&#252;nstlichen Intelligenz im produzierendem Gewerbe in Deutschland.
727 Vgl. Kapitel 4.1.4 dieses Projektgruppenberichts [Hardware/Infrastruktur]; Fraunhofer-Gesellschaft zur F&#246;rderung der angewandten 
Forschung e. V. (2018): Maschinelles Lernen &#8211; Eine Analyse zu Kompetenzen, Forschung und Anwendung.
734 Die Prognosen f&#252;r Wachstumspotenziale im KI-Bereich st&#252;tzen sich &#252;berwieKapgend auf die Studien gro&#223;er
Unternehmensberatungen wie Accenture (2018): Weg ohne Ziel? Wie Deutschland ein Spitzenstandort f&#252;r K&#252;nstliche Intelligenz werden kann; McKinsey
&amp; Company (2017): Smartening up with Artificial Intelligence (AI) &#8211; What&#8217;s in it for Germany and its Industrial Sector?;
PricewaterhouseCoopers (2018): Auswirkungen der Nutzung von k&#252;nstlicher Intelligenz in Deutschland. Der Bericht bezieht sich aber
ausdr&#252;cklich auch auf weitere Quellen wie u. a. Elsevier (2018): ArtificiaI Intelligence: How knowledge is created, transferred, and used; 
Begleitforschung PAiCE; iit-Institut f&#252;r Innovation und Technik in der VDI / VDE Innovation + Technik GmbH (2018): Potenziale
der K&#252;nstlichen Intelligenz im produzierendem Gewerbe in Deutschland; Statista (2020): Revenues from the artificial intelligence 
(AI) software market worldwide from 2018 to 2025.
735 Vgl. Institut DGB-Index Gute Arbeit (2016): DGB- Index Gute Arbeit &#8211; Der Report 2016; Daum (2018): Digitaler Wandel in Call-
und Service-Centern: Aktuelle Trends und ihre Folgen f&#252;r Arbeitsorganisation und Besch&#228;ftigte; Gimpel et al. (2018): Digitaler Stress
in Deutschland; Kornwachs (2018): Arbeit 4.0 &#8211; People Analytics &#8211; F&#252;hrungsinformationssysteme; Schwemmle und Wedde (2018):
Alles unter Kontrolle? Arbeitspolitik und Arbeitsrecht in digitalen Zeiten &#8211; WISO Diskurs 2/2018.
736 Vgl. Expertenkommission Forschung und Innovation (2018): Studie &#8222;Autonome Systeme&#8220;.
Deutsche Wirtschaftsstruktur erm&#246;glicht viele
Einsatzszenarien von KI mit nicht-personenbezogenen 
Daten und Segmenten wie dem Industrial Internet of
Things728 
Deutschland und die EU k&#246;nnen Vorreiterrolle bei
der Entwicklung und Umsetzung von Governance-
Modellen zum Data-Sharing einnehmen729 
KI erm&#246;glicht h&#246;here Arbeits- und Lebensqualit&#228;t
sowie hochwertige Besch&#228;ftigungsm&#246;glichkeiten bei
kontinuierlicher Aus- und Weiterbildung730 
Hohe Potenziale von KI-Methoden im Bereich der
Bek&#228;mpfung von Wirtschaftskriminalit&#228;t731 
Gro&#223;e &#246;kologische Potenziale von KI in der Hebung 
von Energie- und Ressourceneffizienzpotenzialen in 
den Bereichen Strom und Energie732 
F&#252;hrende Position bei der Erstellung von
internationalen Normen und Standards im elektrotechnischen 
Bereich erm&#246;glicht Deutschland auch f&#252;hrende
Positionen bei KI-Anwendungen in diesen Feldern733 
Gefahr der Abh&#228;ngigkeit von ausl&#228;ndischen
Software- und Hardwarekonzernen im Bereich
Maschinelles Lernen, KI- und Cloud-Infrastruktur, da keine
gro&#223;en europ&#228;ischen Anbieter vorhanden sind737 
Die Umsetzung von neuen KI-basierten
Gesch&#228;ftsmodellen bedarf heute meist gro&#223;er Datenmengen, 
was gro&#223;e Unternehmen bevorteilt und die Bildung 
von Monopolen erleichtert738
M&#246;gliche Steigerung der Wirtschaftskriminalit&#228;t,
z. B. durch automatisierte Preisabsprachen,
sch&#228;dliche Betrugs-Bots oder KI-gesteuerte
&#8222;Steueroptimierungen&#8220;
H&#246;herer Ressourcen- und Energieverbrauch (Strom)
durch KI sowie KI-getriebene Gesch&#228;ftsmodelle 
(z. B. Versandhandel)
KI erm&#246;glicht die Automatisierung und Substitution 
auch von komplexen und hochqualifizierten
Berufsfeldern, sodass fr&#252;hzeitige Weiterbildung auch hier
immer wichtiger wird739 
Skepsis in der Bev&#246;lkerung &#252;ber die
gesamtgesellschaftlichen Auswirkungen von KI740 
5 Handlungsempfehlungen und Perspektiven741 
Die Projektgruppe hat mehrheitlich die folgenden Handlungsempfehlungen beschlossen. Dort, wo abweichende
Positionen und Meinungen bestehen, ist dies entsprechend gekennzeichnet.
Wachstum, Wertsch&#246;pfung und Nachhaltigkeit mit und durch KI
Vieles spricht daf&#252;r, dass KI, insbesondere Teilgebiete wie das Maschinelle Lernen, zu einer der Leittechnologien
des n&#228;chsten Jahrzehnts werden wird. Die Expertinnen und Experten, die in die Beratungen der Projektgruppe
einbezogen wurden, sch&#228;tzen die mittel- und langfristige Bedeutung von KI-Technologien f&#252;r das weitere
wirtschaftliche Wachstum in Deutschland und Europa insgesamt und f&#252;r die betrachteten Branchen im Speziellen als
au&#223;erordentlich hoch ein. Diese Sichtweise wird auch durch viele aktuelle Studien untermauert, die f&#252;r den
Bericht herangezogen wurden.742 Dass mittels KI-Anwendungen eine enorme Wertsch&#246;pfung realisiert werden
728 Vgl. McKinsey &amp; Company (2017): Smartening up with Artificial Intelligence (AI) &#8211; What&#8217;s in it for Germany and its Industrial
Sector?; Accenture (2018): Weg ohne Ziel? Wie Deutschland ein Spitzenstandort f&#252;r K&#252;nstliche Intelligenz werden kann.
729 Vgl. Fraunhofer-Gesellschaft zur F&#246;rderung der angewandten Forschung e. V. (2018): Maschinelles Lernen &#8211; Eine Analyse zu
Kompetenzen, Forschung und Anwendung.
730 Vgl. Kapitel 4.1.1 dieses Projektgruppenberichts [Stand der Gesellschaft: Akzeptanz und Erwartungen].
731 Vgl. Kapitel 4.1.3.2.3 dieses Projektgruppenberichts [Themenfeld Finanzmarkt und Versicherungen].
732 Vgl. Kapitel 4.1.5 dieses Projektgruppenberichts [&#214;kologie].
733 Vgl. Kapitel 4.1.6. dieses Projektgruppenberichts [Stand der Administration/Politik &#8211; rechtliche Fragen].
737 Vgl. Kapitel 4.1.4 dieses Projektgruppenberichts [Hardware/Infrastruktur]; Expertenkommission Forschung und Innovation (2018):
Studie &#8222;Autonome Systeme&#8220;.
738 Vgl. Kapitel 4.1.3 dieses Projektgruppenberichts [Stand des Marktes]; Fraunhofer-Gesellschaft zur F&#246;rderung der angewandten
Forschung e. V. (2018): Maschinelles Lernen &#8211; Eine Analyse zu Kompetenzen, Forschung und Anwendung.
739 Vgl. Susskind und Susskind (2017): The future of the professions.
740 Vgl. Kapitel 4.1.1 dieses Projektgruppenberichts [Stand der Gesellschaft: Akzeptanz und Erwartungen].
741 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 5 des Berichts der Projektgruppe
&#8222;KI und Wirtschaft &#8220;  (&#8222;Handlungsempfehlungen und Perspektiven &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des
sachverst&#228;ndigen Mitglieds Dr. Florian Butollo].
742 Beispielhaft sollen hier genannt werden: Fraunhofer-Allianz Big Data (2017): Zukunftsmarkt K&#252;nstliche Intelligenz &#8211; Potenziale und 
Anwendungen; McKinsey Global Institute (2018): Notes from the AI frontier &#8211; Insights from hundreds of use cases;
PricewaterhouseCoopers (2018): Auswirkungen der Nutzung von k&#252;nstlicher Intelligenz in Deutschland; European Information Technology 
Observatory (2018): AI in Europe &#8211; Ready for Take-off; Begleitforschung PAiCE; iit-Institut f&#252;r Innovation und Technik in der VDI
kann, lassen zudem die hohen Gewinne gro&#223;er internationaler Unternehmen vermuten, die bereits mit KI-
Anwendungen arbeiten. Entsprechend optimistisch sind die Erwartungen und Prognosen zum
Produktivit&#228;tswachstum auf nationaler und internationaler Ebene.743 
Jedoch ist zu ber&#252;cksichtigen, dass die Datenbasis zu dem tats&#228;chlichen Leistungsverm&#246;gen von KI-
Technologien in vielen Bereichen (noch) nicht auf standardisierte statistische Indikatoren aufsetzen kann. Prognosen
basieren h&#228;ufig auf anderen Kenngr&#246;&#223;en oder Hochrechnungen, wobei es teilweise schwerf&#228;llt, zwischen KI-
Einsatz und herk&#246;mmlichen IT-Anwendungen in Unternehmen zu differenzieren. Um valide Aussagen zu den
&#246;konomischen Effekten des KI-Einsatzes treffen zu k&#246;nnen, empfiehlt die Projektgruppe daher, eine KI-spezifische,
wissenschaftliche Datenbasis zu entwickeln. Denn f&#252;r die richtige Weichenstellung von Recht und Politik ist es
wichtig, realistische technische wie wirtschaftliche Erwartungen an KI zu stellen.
Die Projektgruppe regt mit diesem Bericht an, die St&#228;rken und Schw&#228;chen von KI in Deutschland und Europa
weiter wissenschaftlich untersuchen zu lassen, um Zielsetzung und Handlungsfelder bzw. -ma&#223;nahmen noch 
besser ausrichten zu k&#246;nnen. Dar&#252;ber hinaus r&#228;t die Projektgruppe dazu, Haushaltsmittel bereitzustellen, um ein 
Monitoring und Benchmarking f&#252;r den Bereich KI aufzubauen. Das setzt voraus, dass die strategischen Ziele und
Ma&#223;nahmen von KI mit qualitativen und quantitativen Indikatoren hinterlegt werden, die eine
Fortschrittsmessung erm&#246;glichen, ggf. auch im internationalen Vergleich. Damit k&#246;nnte erstens die erfolgreiche Umsetzung der
KI-Strategie nachvollzogen werden, zweitens die Entwicklung des deutschen KI-&#214;kosystems im Vergleich zu
globalen KI-Trends kontinuierlich gepr&#252;ft werden, drittens die gesellschaftspolitische Diskussion &#252;ber KI in
Deutschland auf eine empirisch fundierte Grundlage gestellt werden.744 
In der Debatte um das wirtschaftliche Potenzial von KI zeichnete sich in der Projektgruppe schnell ab, dass sich
die Betrachtung von Wettbewerbschancen nicht von der Debatte &#252;ber Werte, Prinzipien und Regularien f&#252;r die
KI von morgen trennen l&#228;sst. 
Die Projektgruppe einigte sich auf den Ansatz, durch den transparenten und zielgerichteten Einsatz von KI-
Technologien eine hohe wirtschaftliche Dynamik und erfolgreiche Unternehmen anzustreben und damit eine starke
Gesellschaft und eine hohe Lebensqualit&#228;t in Deutschland sicherzustellen. Das setzt voraus, dass sich
Deutschland im Bereich KI in der Forschung und Entwicklung (FuE) sowie im Transfer der Ergebnisse von der
Entwicklung in die Anwendung stark aufstellt, um sich gemeinsam mit anderen europ&#228;ischen L&#228;ndern international &#8211;
insbesondere gegen&#252;ber den gro&#223;en Akteuren USA und China &#8211; wirtschaftlich behaupten zu k&#246;nnen. Dank des
vertrauensw&#252;rdigen Einsatzes von KI-Technologien wird eine hohe wirtschaftliche Dynamik f&#252;r Unternehmen
erm&#246;glicht, die zur Lebensqualit&#228;t der Menschen und dem Schutz der Umwelt beitr&#228;gt.
Ein Instrument hierf&#252;r sollte auch die Findung, F&#246;rderung und Umsetzung von gesellschaftlich w&#252;nschenswerten
&#8222;KI-Moonshot-Projekten&#8220; sein. Die Durchf&#252;hrung solcher Projekte mit m&#246;glichst unterschiedlichen Akteuren
aus &#246;ffentlicher Forschung, Wirtschaft und Gesellschaft verspricht den Wissensaustausch zwischen allen
Beteiligten zu f&#246;rdern und stellt eine vielversprechende Basis f&#252;r die Erfindung von neuen revolution&#228;ren Produkten
und Dienstleistungen im europ&#228;ischen Raum dar. 
5.1.1 &#8222;KI made in Germany&#8220; und der europ&#228;ische Weg
Die Projektgruppe sieht die Notwendigkeit einer nationalen KI-Strategie verbunden mit qualitativ hochwertigen 
KI-Anwendungen und Dienstleistungen im Sinne von &#8222;KI made in Germany&#8220;. Ebenso wird als zentrale
Handlungsoption anerkannt, dass Deutschland nicht im Alleingang, sondern gemeinsam mit den europ&#228;ischen Partnern
eine Wertebasis f&#252;r KI-Systeme entwickeln muss, die in Forschung, Entwicklung und Nutzung von KI-Systemen
/ VDE Innovation + Technik GmbH (2018): Potenziale der K&#252;nstlichen Intelligenz im produzierendem Gewerbe in Deutschland; 
Statista (2020): Revenues from the artificial intelligence (AI) software market worldwide from 2018 to 2025. Die Gegenmeinung 
vertrat vor allem Prof. Dr. Philipp Staab (Humboldt-Universit&#228;t zu Berlin und Einstein Center Digital Future) in der Sitzung der
Projektgruppe &#8222;KI und Wirtschaft&#8220; am 1. April 2019. Nach Abschluss der Arbeit der Projektgruppe wurden keine weiteren Studien
ber&#252;cksichtigt. Inwiefern die wirtschaftlichen Prognosen vor dem Hintergrund der Auswirkungen der Corona-Pandemie noch aktuell
sind, ist in Frage zu stellen.
743 Einige Expertinnen und Experten bef&#252;rchten, dass diese Prognosen jedoch nicht eintreten werden. Bef&#252;rchtet wird zum einen, dass
es sich bei KI um einen erneuten Hype-Zyklus handeln k&#246;nnte, wie er beim Thema KI bereits mehrfach eintrat. Andere Expertinnen
und Experten warnen davor, dass der Einsatz von KI nicht zu einem Produktivit&#228;tswachstum auf volkswirtschaftlicher Ebene f&#252;hren
werde, sondern lediglich zu einer Neuverteilung von Gewinnen und Marktanteilen (vgl. etwa Gordon (2016): The rise and fall of
American growth; Staab (2016): Falsche Versprechen).
744 Zu den M&#246;glichkeiten von Benchmarks und Indikatoren sowie zum Ansatz eines KI-Indexes vgl. Heumann und Zahn (2018):
Erfolgsmessung von KI-Strategien.
erfolgreich eingesetzt wird. Der Anspruch ist dabei, dass Deutschland und Europa im internationalen
Transformationsprozess pr&#228;gend sind und die internationale Entwicklung beeinflussen, die derzeit stark von den
asiatischen und US-amerikanischen Playern dominiert wird. 
Die Chance f&#252;r Europa, bei KI einen solchen eigenst&#228;ndigen Weg zu finden, der sich vom staatskapitalistischen
Ansatz Chinas und dem stark am Markt orientierten Ansatz des Sillicon Valley positiv abgrenzt, wird von der
Projektgruppe optimistisch bewertet, da dieser Anspruch schon in anderen Feldern, wie bei der Etablierung von 
Normen und Standards in der Industrie oder beim Datenschutz, international umgesetzt werden konnte.
Zudem wurde mit den im April 2019 ver&#246;ffentlichten Leitlinien der &#8222;High-Level Expert Group on Artificial 
Intelligence&#8220; (AI HLEG)745 bereits ein wichtiges Signal gesetzt. Dabei bieten die drei von der AI HLEG
aufgestellten Prinzipien eine gute Orientierung im weiteren Prozess.
Indes sieht die Projektgruppe noch Anpassungsbedarf mit Blick auf einzelne Forderungen und Leitlinien sowie
die Notwendigkeit, deren Praxistauglichkeit zu &#252;berpr&#252;fen.746 
Mit Blick auf die Zielsetzung, in Deutschland die teils vorherrschende Skepsis und Zur&#252;ckhaltung in der
Gesellschaft gegen&#252;ber dem KI-Einsatz abzubauen, bef&#252;rwortet die Projektgruppe die Absicht der Europ&#228;ischen
Kommission747 und der Bundesregierung748, Vertrauen durch eine vertrauensw&#252;rdige KI aufzubauen, die den
Menschen in den Mittelpunkt stellt. Aus der dargelegten Unternehmenspraxis und aus Umfragen wurde deutlich, dass
Vertrauen ein wichtiger Erfolgsfaktor f&#252;r Unternehmen ist. Bei der Transformation m&#252;ssen sie darauf achten,
Nachvollziehbarkeit und Transparenz f&#252;r Verbraucherinnen und Verbraucher sowie Besch&#228;ftigte zu schaffen und
Standards etwa im Datenschutz einzuhalten.749 
Die Projektgruppe kam &#252;berein, dass Bedenken aus der Bev&#246;lkerung aktiv angesprochen und durch geeignete
Schutzmechanismen und Verpflichtungen ausger&#228;umt werden m&#252;ssen. Hierbei sollten Staat, Zivilgesellschaft, 
Verb&#228;nde und Unternehmen zusammenwirken. Zudem muss darauf geachtet werden, dass eine angemessene
Balance zwischen Verbraucher- und Unternehmensinteressen gefunden wird &#8211; Ma&#223;gaben m&#252;ssen f&#252;r beide
Seiten transparent und handhabbar sein, um nicht innovationshemmend zu wirken. 
Empfehlenswert w&#228;re eine Aufkl&#228;rungskampagne f&#252;r den Mittelstand und letztlich f&#252;r die gesamte Wirtschaft. 
Ziel sollte es sein, Kenntnisse zu vermitteln, positive Beispiele f&#252;r den Einsatz von KI aufzuzeigen und m&#246;gliche
Bedenken anzusprechen, um Vertrauen aufzubauen.750 
Eine Chance, die Bev&#246;lkerung m&#246;glichst aktiv mit eigenen Ideen einzubeziehen und Vertrauen aufzubauen,
besteht dabei auch in einer B&#252;rgerbeteiligung, um die bereits erl&#228;uterten &#8222;KI-Moonshot-Projekte&#8220; zu finden und
auszuw&#228;hlen. Projektvorschl&#228;ge, welche m&#246;glichst hoch-skalierenden gesamtgesellschaftlichen Nutzen
schaffen, sollten von allen B&#252;rgerinnen und B&#252;rgern eingereicht werden k&#246;nnen und in einem transparenten Verfahren
ausgew&#228;hlt und weiterverfolgt werden.
Der im Sommer 2019 angesto&#223;ene Prozess auf EU-Ebene, in dem Unternehmen, &#246;ffentliche Verwaltungen,
Forschung und Organisationen der Zivilgesellschaft in der Pilotierung zusammenarbeiten sollen, wird begr&#252;&#223;t und
sollte daher von Deutschland aktiv begleitet werden.751 
Unternehmenseigene Kodizes sind ein erster Schritt, bieten aber Nutzerinnen und Nutzern h&#228;ufig noch keine
ausreichende Orientierung. Eine Vereinheitlichung erscheint aus Sicht vieler Projektgruppenmitglieder
vielversprechender. Gemeinsame (freiwillige) Selbstverpflichtungen der Unternehmen haben sich bereits in anderen 
745 Vgl. Europ&#228;ische Kommission (2019): Schaffung von Vertrauen in eine auf den Menschen ausgerichtete k&#252;nstliche Intelligenz.
746 Die Arbeit der High Level Expert Group on Artificial Intelligence war zum Zeitpunkt der Arbeit der Projektgruppe noch nicht
beendet. Angek&#252;ndigt war bis Anfang 2020 in einer Pilotphase zu &#252;berpr&#252;fen, wie sich die Handlungsempfehlungen in der Praxis
umsetzen lassen, vgl. Europ&#228;ische Kommission (2019): K&#252;nstliche Intelligenz: Kommission treibt Arbeit an Ethikleitlinien weiter voran.
747 Vgl. Europ&#228;ische Kommission (2020): Wei&#223;buch zur K&#252;nstlichen Intelligenz &#8211; ein europ&#228;isches Konzept f&#252;r Exzellenz und
Vertrauen.
748 Vgl. Bundesregierung (2018): Strategie K&#252;nstliche Intelligenz der Bundesregierung.
749 Vgl. Fujitsu Future Insights (2019): Global Digital Transformation Survey Report 2019.
750 In diesem Zusammenhang wird auch auf die Aktivit&#228;ten in Finnland hingewiesen; vgl. Konrad-Adenauer-Stiftung (2018): Vergleich
nationaler Strategien zur F&#246;rderung von K&#252;nstlicher Intelligenz &#8211; Teil 1.
751 Zu den sieben Voraussetzungen f&#252;r eine vertrauensw&#252;rdige KI siehe Europ&#228;ische Kommission (2019): K&#252;nstliche Intelligenz:
Kommission treibt Arbeit an Ethikleitlinien weiter voran. Im Sommer 2019 hat die Kommission eine Pilotphase eingeleitet, an der ein 
breites Spektrum von Interessentr&#228;gern beteiligt sind; weitere Informationen dazu unter: https://ec.europa.eu/digital-single-mar-
ket/en/european-ai-alliance (zuletzt abgerufen am 19. August 2020).
Bereichen bew&#228;hrt und k&#246;nnten auch bei KI ein geeigneter Weg sein, um ein &#252;bergeordnetes Werte- und
Prozessverst&#228;ndnis zu schaffen.752 Eine positive Ma&#223;nahme wird in dem &#8222;KI-G&#252;tesiegel&#8220; gesehen, das im Fr&#252;hjahr
2019 vom KI-Bundesverband vorgestellt wurde.753 Mit dem KI-G&#252;tesiegel haben vor allem deutsche
Unternehmen die M&#246;glichkeit, sich gegen&#252;ber den Kunden auf die Einhaltung grundlegender Qualit&#228;tsparameter zu
berufen. Das G&#252;tesiegel ersetzt zwar keine anerkannten Vorgehensmodelle oder Zertifizierungen, soll aber an
Mindeststandards, wie BIAS, IT-Grundschutz etc., binden. Es wird daher vorgeschlagen, ein solches G&#252;tesiegel auf
eine breite Grundlage zu stellen und konkrete Kriterien zu definieren.
Dar&#252;ber hinaus ist die Projektgruppe der Meinung, dass es &#252;ber internationale Gremien, in denen DIN e. V. und 
seine Partner f&#252;r die Interessen deutscher Unternehmen arbeiten, gelingen kann, die KI-Landschaft auch
international gut zu strukturieren und einen klaren Handlungsrahmen f&#252;r Unternehmen zu schaffen.754 In den
Beratungen wurden zudem verschiedene Ans&#228;tze diskutiert, die eine gute Verbraucherorientierung bieten k&#246;nnen,
beispielsweise ein Klassifizierungsmodell f&#252;r KI-Produkte und -Dienstleistungen, anhand dessen Aspekte wie
Privatsph&#228;re oder Transparenz gekennzeichnet werden, vergleichbar dem Prinzip der
Energieverbrauchskennzeichnung von Elektroger&#228;ten. 
5.1.2 Unternehmerischer Mut und Transferf&#246;rderung
Die Projektgruppe ist der Auffassung, dass es f&#252;r die Unterst&#252;tzung wettbewerbsf&#228;higer Digitalunternehmen in
Deutschland eine innovationsf&#246;rdernde Politik und einen Rechtsrahmen braucht, der die Unternehmen im
Transformationsprozess unterst&#252;tzt und Anreize f&#252;r erfolgreiche Gr&#252;ndungen und Innovationst&#228;tigkeit im KI-Bereich
schafft. Wichtig ist, darauf zu achten, dass KI nicht nur kurzfristig gewinnorientiert, sondern langfristig und mit
positiven gesellschaftlichen Visionen umgesetzt wird. Nicht nur ethische Leitlinien, sondern auch
unternehmerischer Mut und Tatkraft werden als wichtig bewertet. Der Gesetzgeber muss hier entsprechend unterst&#252;tzen.
Diskussionen &#252;ber rechtliche Bestimmungen, die Unsicherheiten erzeugen, wie sie sich beispielsweise durch die
EU-Urheberrechtsreform ergeben haben, werden in diesem Prozess als kontraproduktiv eingesch&#228;tzt. Gefordert
wird vielmehr die aktive Arbeit an realen Problemstellungen der KI. Au&#223;erdem sollte der Staat selbst mit gutem 
Beispiel vorangehen, also etwa Abl&#228;ufe oder Prozesse wie die Gewerbeanmeldung digitalisieren und damit
transparenter machen. Dadurch k&#246;nnte der Staat beziehungswiese die Verwaltung auch als Auftraggeber zur
Entwicklung neuer KI-L&#246;sungen beitragen.
Die Projektgruppe sieht Deutschland aufgrund seiner exzellenten Forschungslandschaft und der breiten
industriellen Voraussetzung gut positioniert, um KI zu entwickeln. In vielen Bereichen erfordert der Transfer
wissenschaftlicher Forschungsergebnisse eine h&#246;here unternehmerische Risikobereitschaft und mehr Know-how in den 
Unternehmen. Die Gespr&#228;che ergaben, dass die Verwertung von Forschungsergebnissen immer noch nicht in der
Breite ankommt, obwohl das Transferdefizit seit Jahren erkannt und viele Ma&#223;nahmen ergriffen worden sind. 
In vielen Bereichen der Wirtschaft erfordert die Weiterentwicklung und Anwendung von KI neben Zentren und
Hubs auch eine breite Expertise (thematisch, geografisch, anwendungsbezogen) sowie Portfolios mit relativ
kleinen, aber sehr fokussierten Projekten. Es sollten daher F&#246;rderinstrumente gest&#228;rkt und neu entwickelt werden,
die Reibungsverluste und Overhead minimieren, die Zusammenarbeit von Forschenden sowie Anwenderinnen
und Anwendern in der Wirtschaft flexibilisieren und entb&#252;rokratisieren sowie Gr&#252;ndungen auf der Basis
wissenschaftlicher Erkenntnisse und Zusammenarbeit von innovativen Jungunternehmen und Verwertern unterst&#252;tzen.
Als Instrumente werden daf&#252;r empfohlen: Doktorandenstipendien, Innovationspreise, Forschungsanreize gerade
f&#252;r KMU wie Gutscheine speziell f&#252;r KI-Forschung755 oder die breitere, offene Begutachtung und transparentere
Auswahl von F&#246;rderprojekten.756 Au&#223;erdem sollte in F&#246;rderrichtlinien die Verbindlichkeit zum nachhaltigen 
Transfer und zur Verwertung von Forschungsergebnissen durch Unternehmen, Organisationen, Open-Source-
Initiativen und anderen Akteuren weiter ausgebaut werden, z. B. durch die verpflichtende Aufnahme eines
Verwertungspartners in ein Konsortium, geplante Ausgr&#252;ndungen oder Open-Source-Ver&#246;ffentlichungen.
752 Vgl. beispielsweise die Vereinbarung zum Geodatenkodex (Weimann und Nagel (2011): Unterzeichnung des Geodaten-Kodex &#8211;
Mehr als reiner Aktionismus); oder Informationen zum Umweltbereich unter: https://www.bundestag.de/re-
source/blob/480084/7a54deeee5135d82f7df678d8456b1ea/wd-5-079-16-pdf-data.pdf (zuletzt abgerufen am 3. August 2020).
753 Vgl. KI Bundesverband e. V. (2019): KI G&#252;tesiegel.
754 Vgl. dazu verschiedene Aktivit&#228;ten von DIN, DKE und VDE; so erarbeitet u. a. der interdisziplin&#228;re Arbeitsausschuss KI eine
Normungsroadmap f&#252;r KI (Gabler (2019): KI-Normung und -Standardisierung auf nationaler, europ&#228;ischer und internationaler Ebene). 
755 &#196;hnlich dem Modell in Baden-W&#252;rttemberg, Informationen dazu unter: http://www.foerderdatenbank.de/Foerder-DB/Naviga-
tion/Foerderrecherche/suche.html?get=views;document&amp;doc=9812 (zuletzt abgerufen am 3. August 2020).
756 Z. B. &#228;hnlich der Crowdfunding-Plattform Kickstarter.com.
Damit sich die angestrebte Verbreitung von KI-Systemen in der deutschen Wirtschaft durchsetzen kann, bedarf
es einer sicheren, leistungsstarken und robusten digitalen Infrastruktur. Die Projektgruppe sieht es daf&#252;r
mehrheitlich als geboten an, dass in Deutschland ein hochleistungsf&#228;higes Breitbandnetz, Mobilfunksysteme inklusive
5G, aber auch gut gesch&#252;tzte Infrastruktur gegen Hacking und Angriffe auf Systeme und Daten zur Verf&#252;gung
stehen. Daf&#252;r m&#252;ssen entsprechende Haushaltsmittel und Ma&#223;nahmen auf allen Ebenen zur Verf&#252;gung gestellt
werden.
5.1.3 Technologische Souver&#228;nit&#228;t
Angesichts der &#246;konomischen Bedeutung von KI gibt es einen anhaltenden Diskurs dar&#252;ber, ob und wie sehr 
Deutschland technologisch abh&#228;ngig ist &#8211; insbesondere von amerikanischen und chinesischen Unternehmen. Auf
europ&#228;ischer wie nationaler Ebene werden verschiedene Modelle und Ansatzpunkte vorgeschlagen, um die
technologische Souver&#228;nit&#228;t bei Schl&#252;sseltechnologien wie KI abzusichern bzw. aufzubauen.757 
Die Projektgruppe stellt fest, dass durchschlagende Innovationen in der Regel ein ganzes wirtschaftliches
&#214;kosystem voraussetzen: die Symbiose von staatlicher Forschung, neuer Infrastruktur, unternehmerischem Handeln,
einer qualifizierten Mitarbeiterschaft und gesellschaftlicher beziehungsweise wirtschaftlicher Nachfrage. Diese
Symbiose muss beim Thema KI verbessert werden, damit Deutschland an der Spitze mithalten kann. Daher sieht
die Projektgruppe Vorteile in einem aktivierenden und langfristig gestaltenden Staat.758 Dar&#252;ber hinaus gibt es
Stimmen daf&#252;r, dass eine aktive Industriepolitik betrieben werden m&#252;sste, einerseits um junge Unternehmen zu
sch&#252;tzen und junge Technologieunternehmen in die starken Felder der alten Industrie zu &#252;berf&#252;hren, andererseits
um f&#252;r KI wichtige Komponenten und Infrastrukturen sicherzustellen. 
Die Projektgruppe hat verschiedene Bereiche ausgemacht, in denen sie eine hohe technologische Souver&#228;nit&#228;t
als elementar und von hoher strategischer Bedeutung erachtet und daher einen h&#246;heren Aufwand f&#252;r ihren Erhalt
empfiehlt.
So r&#228;t die Projektgruppe dazu, bei KI-Hardware eine europ&#228;ische L&#246;sung anzustreben, da die Investitionen f&#252;r
Fertigungsst&#228;tten von Hoch- und H&#246;chstleistungsrechnern f&#252;r Deutschland zum einen im Alleingang nicht
realisierbar erscheinen und diese zum anderen durch den deutschen Bedarf allein nicht ausgelastet werden k&#246;nnen.
Bereits gestartete europ&#228;ische Anstrengungen, um bei Hoch- und H&#246;chstleistungsrechnern aufzuholen, wie dem
European High-Performance Computing (HPC)759, sollten dabei forciert werden.
Dabei m&#252;ssen auch die F&#228;higkeiten in Europa gest&#228;rkt werden, Plattformen solch komplexer KI-Hardware
effizient und skalierbar zu entwickeln. Verfolgt man n&#228;mlich die permanent steigenden Entwicklungskosten von
hochkomplexen Chips, besteht die Gefahr, dass die Entwicklung jedes h&#246;chstleistungsf&#228;higsten KI-Chips
750 Millionen Euro und mehr kosten wird.760 
Bei KI-Endger&#228;ten wird die Notwendigkeit gesehen, dass deutsche Unternehmen schnell im Markt aufholen, da
diese Technik das Fundament f&#252;r Innovationen im Maschinenbau, in der Automatisierungstechnik und im
Automobilbau darstellt. Aus diesem Grund empfiehlt die Projektgruppe, neue Aktivit&#228;ten zu starten, um die
Kompetenzen und Methoden bei Plattformen f&#252;r KI-Endger&#228;te zu st&#228;rken.
Die Projektgruppenmitglieder sehen weiterhin die Notwendigkeit, die Forschung im Bereich KI-Services und
KI-Hardwareplattformen zu verst&#228;rken, denn dies sind KI-Gebiete, in deren Umfeld der gr&#246;&#223;te Markt zu erwarten
ist.761 Die Verteilung und Ausschreibung der neuen 100 KI-Professuren auf Grundlage der KI-Strategie der
Bundesregierung und die entsprechende Ausstattung der Lehrst&#252;hle bieten dazu eine gute Gelegenheit.
757 Vgl. Altmeier (2018): Wirtschaftsminister Altmaier sieht k&#252;nstliche Intelligenz als &#8222;Schl&#252;sselfrage f&#252;r Deutschland und Europa&#8220;; 
L&#246;hr und Wieduwilt (2019): FDP und CDU werben f&#252;r europ&#228;ische Cloud-L&#246;sungen.
758 Ein solcher Staat ist ein Staat, der aktiv die Forschung und Reifung von langfristig ausgelegten Zukunftstechnologien f&#246;rdert und
begleitet (analog dem Gr&#252;ndungsziel der DARPA Ende 1960 mit dem Ziel Eisenhowers, die USA technologisch f&#252;hrend im
Vergleich zur UdSSR zu machen).
759 Weitere Informationen dazu unter: https://eurohpc-ju.europa.eu/ (zuletzt abgerufen am 19. August 2020).
760 Mit Bailey (vgl. Bailey (2018): The Impact Of Moore&#8217;s Law Ending) wird Bezug auf eine IBS-Studie genommen, die f&#252;r 5-nm-
Designs Kosten in H&#246;he von 542,2 Millionen US-Dollar prognostiziert. F&#252;r zus&#228;tzliche Ma&#223;nahmen zur Erh&#246;hung der
Betriebssicherheit, der funktionalen Sicherheit und der Datensicherheit wurden basierend auf Erfahrungen noch ca. 50 Prozent aufgeschlagen.
761 Bis zum Jahr 2030 wird etwa im Mobilit&#228;tsbereich das Marktpotenzial f&#252;r Hardware auf 40 Milliarden US-Dollar und f&#252;r Software
auf 20 Milliarden US-Dollar prognostiziert, vgl. Fraunhofer-Allianz Big Data (2017): Zukunftsmarkt K&#252;nstliche Intelligenz &#8211;
Potenziale und Anwendungen, S. 22.
Zudem wurde in den von der Projektgruppe betrachteten Branchen deutlich, dass die Dominanz der sogenannten
Hyperscaler am Cloud-Computing-Markt &#8211; den Anbietern, die gro&#223;e Datenmengen schnell skalierbar verarbeiten 
k&#246;nnen, also derzeit Amazon, Microsoft, Google und Alibaba &#8211; zu einseitigen Abh&#228;ngigkeiten der deutschen KI-
Akteure f&#252;hren kann. Das F&#252;r und Wider einer &#8222;deutschen bzw. europ&#228;ischen Cloud&#8220; konnte in der Projektgruppe
nicht abschlie&#223;end diskutiert werden, da konkrete Umsetzungsvorschl&#228;ge dazu (noch) nicht vorlagen. Ob und
wie das technisch wie finanziell funktionieren k&#246;nnte, ob es gen&#252;gend Interessenten geben w&#252;rde, die sich am
Infrastrukturaufbau beteiligen und das Cloud-Angebot sp&#228;ter nutzen w&#252;rden, wird sich in den n&#228;chsten Monaten
im &#246;ffentlichen Diskurs zeigen. Das BMWi hat hierzu die Initiative GAIA-X vorgestellt.762 
Schon allein aus der Perspektive der Energieeffizienz erscheint der Projektgruppe eine europ&#228;ische Kooperation
bez&#252;glich Cloud-Services sinnvoller als ein nationaler Alleingang, etwa eine Kooperation mit skandinavischen 
L&#228;ndern, da diese aufgrund der geografischen Lage die Rechenzentren leichter mit nat&#252;rlichen Mitteln k&#252;hlen
und mit einem g&#252;nstigen &#214;kostrom anbieten k&#246;nnen. 
Zusammenfassend wird empfohlen, den Aufbau und Betrieb einer zentralen, nationalen, vertrauensvollen,
allgemein zug&#228;nglichen Daten- und Analyseinfrastruktur inklusive des Aufbaus einer zugrundeliegenden
europ&#228;ischen Cloud-Plattform mit skalierbarer Speicher- und Rechenkapazit&#228;t durch Politik und Wirtschaft gemeinsam
&#8211; auf Basis offener und interoperabler Standards &#8211; zu forcieren, damit Europa aus Deutschland heraus als starker
Wirtschaftsstandort gesichert ist.
5.1.4 Nachhaltigkeit
In dem Diskurs der Projektgruppe um die Zukunftssicherung der deutschen Wirtschaft spielte die Nachhaltigkeit
eine wichtige Rolle. Das betrifft einerseits die Frage, wie ein ressourcenschonender Transformationsprozess in
der Wirtschaft forciert werden kann, anderseits wie gerade durch KI ein &#246;kologisch nachhaltiges Wirtschaften
erreicht werden kann, also KI-gest&#252;tzte L&#246;sungen, die beispielsweise zu Verbesserungen beim Gew&#228;sserschutz,
bei der Nutzung Erneuerbarer Energien oder der landwirtschaftlichen Produktion f&#252;hren.
Zur Nachhaltigkeitsfrage z&#228;hlen dar&#252;ber hinaus auch die Auswirkungen einer KI-Nutzung auf die soziale und
politische Teilhabe sowie auf die Lebensqualit&#228;t der Menschen.763 
Fest steht: KI und Digitalisierung haben potenziell starke Auswirkungen auf alle UN-Nachhaltigkeitsziele
(Sustainable Development Goals, SDGs) der Agenda 2030 des Pariser Klima&#252;bereinkommens, zu deren
Einhaltung sich Deutschland verpflichtet hat.764 Die Projektgruppe ist daher der Auffassung, dass die wirtschaftliche
Entwicklung, die Sicherung des Wohlstands und die wirtschaftliche Wertsch&#246;pfung grunds&#228;tzlich mit
Ma&#223;nahmen zur Erreichung der Klimaschutzziele und der UN-Nachhaltigkeitsziele in Einklang gebracht werden m&#252;ssen.
Da zu den Unw&#228;gbarkeiten aktueller und kommender KI-Anwendungen der sich exponentiell entwickelnde
Energieverbrauch z&#228;hlt, r&#228;t die Projektgruppe dazu, die Nationale KI-Strategie mit einer Nationalen Energiestrategie
zu verzahnen, die neben den oben genannten Zielen der Nachhaltigkeit auch jene einer stabilen Stromversorgung 
verfolgt und gew&#228;hrleistet. Hier sollte auch eine europaweite Abstimmung erfolgen.
Empfohlen wird des Weiteren, das Marktpotenzial einer Marke &#8222;Sustainable AI&#8220;, also von KI-Anwendungen,
die hinsichtlich Energie- und Ressourceneinsatz und Effizienzpotenzial im Einsatz optimiert sind, bei der
Weiterentwicklung der KI-Strategie zentral zu ber&#252;cksichtigen.
Gesetzgeber und &#246;ffentliche Verwaltung k&#246;nnen durch gezielte, auch regulatorische Ma&#223;nahmen die
Durchsetzung von &#8222;Sustainable AI&#8220; ma&#223;geblich bef&#246;rdern, etwa durch eine Ber&#252;cksichtigung im Vergaberecht. Das setzt
voraus, dass daf&#252;r konkrete Merkmale bzw. Anforderungen definiert und umgesetzt werden.
Erfahrungen von Unternehmen und neue Forschungsergebnisse zeigen, dass KI in den unterschiedlichsten
Wirtschaftssektoren und Branchen eingesetzt werden kann, um die &#214;kobilanz zu verbessern &#8211; ohne Beeintr&#228;chtigung
762 Weitere Informationen hierzu unter: https://www.bmwi.de/Redaktion/DE/Dossier/gaia-x.html (zuletzt abgerufen am 19. August
2020).
763 Durch die zunehmenden Digitalisierungsprozesse ver&#228;ndern sich Arbeitsprozesse und es stellen sich neue Verteilungseffekte ein.
Dies gilt f&#252;r Unternehmen wie f&#252;r Arbeitnehmerinnen und Arbeitnehmer. &#214;konomen sehen das Hauptmerkmal dieser Entwicklung 
im Anstieg der Bedeutung immaterieller Wirtschaftsg&#252;ter wie Markenrechten, Software und Design (vgl. Haskel und Westlake
(2018): Capitalism without capital). Die steigende Bedeutung von KI wird diese Entwicklung noch verst&#228;rken. Da die Steuer- und 
Sozialsysteme der Bundesrepublik in der Zeit der Industrialisierung und analogen Wirtschaft entwickelt wurden, halten einige
Projektgruppenmitglieder hier eine Anpassung an die neuen Entwicklungen f&#252;r notwendig.
764 U. a. sollen zur nationalen Umsetzung der Klimaschutzverpflichtungen die Treibhausgasemissionen der gesamten Volkswirtschaft
bis zum Jahr 2030 um mindestens 55 Prozent, bis 2040 um mindestens 70 Prozent und bis 2050 um 80 bis 95 Prozent unter das
Niveau von 1990 reduziert werden.
der wirtschaftlichen Dynamik.765 Einige Unternehmen nutzen KI auch gerade, um sich angesichts knapper
Ressourcen und steigender Kosten neu aufzustellen. Hier sieht die Projektgruppe interessante Ankn&#252;pfungspunkte
und r&#228;t, dies in der Enquete-Kommission&#8220;766 genauer zu betrachten.767 
Grunds&#228;tzlich erscheint es geboten, die F&#246;rderpolitik und Forschungsvorhaben des Bundes st&#228;rker auf KI-
Innovationen auszurichten, welche sich konkret an den UN-Nachhaltigkeitszielen orientieren. Es bedarf somit neben
dem bestehenden BMU-F&#246;rderungsprogramm zur Schaffung von KI-Leuchtturmprojekten im Bereich Umwelt,
Klima und Natur768 weiterer zus&#228;tzlicher Programme zur L&#246;sung von gesellschaftlichen Herausforderungen.
Diese sollten beispielsweise darauf abzielen, eine beschleunigte Verbesserung von Chancengleichheit in der
Bildung oder der Verf&#252;gbarkeit von &#246;ffentlichen Infrastrukturen in unterschiedlichen Lebensr&#228;umen durch KI-
Innovationen zu erm&#246;glichen. Hierf&#252;r sollten entsprechende Haushaltsmittel in den Einzelpl&#228;nen der
verantwortlichen Ressorts bereitgestellt werden.
Auch k&#246;nnten die Erforschung und Entwicklung von energieeffizienten KI-Systemen gef&#246;rdert und Anreize f&#252;r
eine st&#228;rkere Abw&#228;rmenutzung aus Rechenzentren geschaffen werden. Vorgeschlagen wird, eine Abnahme- bzw.
Nutzungspflicht f&#252;r Abw&#228;rme aus Rechenzentren zu pr&#252;fen.
Unterst&#252;tzung der KI-Akteure
In den Beratungen der Projektgruppe wurde deutlich: KI ist mehr als nur eine Technologie, die dadurch bewirkten
Ver&#228;nderungen wirken bereits in einigen Branchen und M&#228;rkten disruptiv, in anderen Bereichen sind (disruptive
oder inkrementelle) Ver&#228;nderungen mit hoher Wahrscheinlichkeit zu erwarten. Unternehmensvertreterinnen und
-vertreter berichteten, in welcher Weise Wertsch&#246;pfungsketten und Gesch&#228;ftsmodelle angepasst bzw. neu
entwickelt werden m&#252;ssen und welche Herausforderungen es gibt, sich in einer Daten- und KI-getriebenen &#214;konomie
(neu) zu positionieren. Dass Politik und Staat diese Transformation mitgestalten, Akteure unterst&#252;tzen oder
vernetzen m&#252;ssen, war unbestritten. Es ist vielen Projektgruppenmitgliedern aber auch wichtig, darauf hinzuweisen,
dass es in der unternehmerischen Verantwortung liegt, hier rechtzeitig die richtigen Weichen zu stellen. 
Im Allgemeinen empfiehlt die Projektgruppe, die Beratung f&#252;r Unternehmen zur Transformation der eigenen
Gesch&#228;ftsprozesse und -modelle und den Austausch von Best Practices (bspw. &#252;ber Kammern sowie
Kompetenzzentren) weiter auszubauen.
Vorhandene dezentrale KI-Ressourcen sollten auf einer Plattform unter neutraler, nicht-kommerzieller
Federf&#252;hrung und mit politischer Flankierung zusammengef&#252;hrt werden. 
Es wird angeraten, &#8222;Regulatory Sandboxes&#8220; (regulatorische Sandk&#228;sten) (z. B. ein bestimmtes Krankenhaus,
einen Lehrbetrieb, eine Autobahn) bzw. freie Experimentierr&#228;ume einzurichten, die Forscherinnen und Forschern
unter geeigneten Voraussetzungen zur Durchf&#252;hrung von Realexperimenten dienen k&#246;nnen. Da diese weniger
reguliert sind, k&#246;nnten sie dort kontrolliert die Ergebnisse aus der theoretischen Forschung testen und so Best
Practices f&#252;r weitere Forschung und Entwicklung bieten.
Spezifisch f&#252;r die einzelnen Akteure empfiehlt die Projektgruppe Folgendes:
5.2.1 Innovation und Start-ups: Start-up-&#214;kosysteme, Start-up-F&#246;rderungen769 
Start-ups werden als wesentlicher Treiber f&#252;r die KI-Transformation gesehen. Laut den vorliegenden Zahlen 
entwickelt sich die KI-Start-up-Landschaft in Deutschland positiv, im internationalen Vergleich ist das
Wachstum aber relativ, sodass die Projektgruppe hier Handlungsbedarf sieht.770 
Die Konzentration auf die St&#228;dte Berlin und M&#252;nchen unterstreicht die zentrale Rolle eines lokalen &#214;kosystems
f&#252;r die Gr&#252;ndung und Entwicklung von KI-Start-ups. Wissenstransfer, Kooperation, Sichtbarkeit und
Verbindungen zu potenziellen Kundinnen und Kunden spielen hier eine entscheidende Rolle. Vor diesem Hintergrund
765 Vgl. Microsoft; PricewaterhouseCoopers (2019): How AI can enable a Sustainable Future.
766 Siehe hierzu Kapitel 8 des Mantelberichts [KI und &#246;kologische Nachhaltigkeit].
767 Siehe das Beispiel in Shaw (2019): The Future Computed &#8211; K&#252;nstliche Intelligenz in der Industrie, S. 123 ff.
768 Weitere Informationen dazu unter: https://www.bmu.de/themen/forschung-foerderung/foerderung/foerdermoeglichkeiten/details/25/
(zuletzt abgerufen am 3. August 2020).
769 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion der AfD vor [Sondervotum zu den Kapiteln 4.1.3.1.1 und 5.2.1 des Berichts
der Projektgruppe 1 &#8222;KI und Wirtschaft&#8220; (&#8222;Themenfeld Start-ups&#8220; und &#8222;Innovation und Start-ups: Start-up-&#214;kosysteme, Start-up-
F&#246;rderungen&#8220;) der Abgeordneten Joana Cotar sowie der Abgeordneten Peter Felser und Dr. Marc Jongen].
770 Die Zahl der Gr&#252;ndungen/Ausgr&#252;ndungen stieg laut UnternehmerTUM, dem Zentrum f&#252;r Innovation und Gr&#252;ndung an der TU
M&#252;nchen, dieses Jahr im Vergleich zum Jahr 2018 um 62 Prozent von 132 auf 214 an.
empfiehlt die Projektgruppe die systematische Unterst&#252;tzung und den Ausbau verschiedener deutscher und
europ&#228;ischer Start-up-&#214;kosysteme. Die F&#246;rderung sollte in regionalen und thematischen Clustern strukturiert
werden. So k&#246;nnten Cluster zu Teilbereichen der KI wie Mobilit&#228;t, Nachhaltigkeit, Gesundheit oder Finanzen
aufgebaut oder gest&#228;rkt werden, um zielgerichtet Ressourcen einzusetzen, einen Austausch zwischen Forscherinnen
und Forschern sowie Gr&#252;nderinnen und Gr&#252;ndern zu erleichtern sowie Verkn&#252;pfungen zu Industrie und
Mittelstand leichter herzustellen. Gleichzeitig bietet sich so die M&#246;glichkeit, auf bestehende Strukturen aufzusetzen
und statt einer Konzentration auf einige wenige Cluster mehrere f&#246;derale Cluster mit jeweils eigenen St&#228;rken zu
bilden. Ein florierendes und gut funktionierendes Start-up-&#214;kosystem wird Wissenschaftlerinnen und
Wissenschaftler sowie andere potenzielle Entrepreneurinnen und Entrepreneure motivieren, den Schritt in die Gr&#252;ndung
zu wagen, und es w&#228;re gew&#228;hrleistet, dass Deutschland in Zukunft ein f&#252;hrender Standort f&#252;r Start-up-
Gr&#252;ndungen wird.
Die Entwicklung von KI und das zugeh&#246;rige KI-Start-up-&#214;kosystem sollten dar&#252;ber hinaus durch eine
entsprechende Nachfrage f&#252;r gesellschaftliche Anwendungen durch die &#246;ffentliche Hand gest&#228;rkt werden. Hierf&#252;r ist es
notwendig, dass H&#252;rden zur Teilnahme an Vergabeprozessen weiter gesenkt und diese Start-up-freundlich
gemacht werden, z. B. durch weiteren B&#252;rokratieabbau, schnelle Vergabeentscheidungen und innovationsf&#246;rdernde
Vergabeverfahren, angelehnt an den &#8222;wettbewerblichen Dialog&#8221; und an &#8222;Innovationspartnerschaften&#8220; nach
europ&#228;ischem Vergaberecht.
Eine Vergabe von Auftr&#228;gen der &#246;ffentlichen Verwaltung an deutsche Start-ups und Aufkl&#228;rungsarbeit zu dem
Thema w&#252;rde nach Einsch&#228;tzung vieler Projektgruppenmitglieder au&#223;erdem dazu f&#252;hren, dass auch
Unternehmen der Privatwirtschaft ermutigt werden, mit KI-Start-ups in Gesch&#228;ftsbeziehungen zu treten. Das w&#252;rde
sowohl die Start-ups st&#228;rken als auch gleichzeitig die Durchdringung des Mittelstandes mit KI f&#246;rdern. 
Dar&#252;ber hinaus erscheint es der Projektgruppe wichtig, eine ausreichende Anzahl von M&#246;glichkeiten zur
Kapitalakquise von Jungunternehmen zu schaffen. Nur durch eine gesunde Venture-Capital-Szene mit entsprechenden
Fonds und F&#246;rderm&#246;glichkeiten durch EU, Bund und L&#228;nder haben Start-ups die Chance, in Deutschland und
Europa ebenso zu wachsen wie in anderen Teilen der Welt. Besonders in sp&#228;teren Phasen des Lebenszyklus eines
Start-ups mangelt es in Deutschland und Europa an Instrumenten und gro&#223;en Venture-Capital-Fonds, welche
Investitionen von 10 bis 100 Millionen Euro in einzelne Start-ups vornehmen k&#246;nnen. Daher sollte der Aufbau
eines oder mehrerer Dachfonds771 beschleunigt werden. In diesem bzw. diesen soll privates und staatliches
Kapital angelegt werden und damit deutschen Start-ups mehr Venture Capital zur Verf&#252;gung gestellt werden.772 
Die St&#228;rkung des Start-up-&#214;kosystems w&#252;rde zudem dem Transfer aktueller Forschung in neue
Gesch&#228;ftsmodelle durch Spin-off-Prozesse773 und Forschungsausgr&#252;ndungen dienen. Der verbesserte Austausch k&#246;nnte eine
zielgerichtete und anwendungsnahe Forschung an Hochschulen und au&#223;eruniversit&#228;ren Forschungseinrichtungen
erm&#246;glichen, was die Projektgruppe als erforderlich ansieht, um der Dynamik des KI-Marktes gerecht zu werden.
Auch w&#252;rde dies die deutsche Start-up-Landschaft attraktiver f&#252;r internationale KI-Spitzenforscherinnen und
-Spitzenforscher als auch f&#252;r dringend ben&#246;tigte KI-Fachkr&#228;fte machen &#8211; was unerl&#228;sslich erscheint, um im
Wettbewerb um Fachpersonal mit Konzernen und dem Mittelstand mithalten zu k&#246;nnen. Um die Attraktivit&#228;t
von Start-ups f&#252;r Fachkr&#228;fte zu erh&#246;hen, wird dringend ein Ausbau der Mitarbeiterbeteiligung empfohlen (siehe 
Kapitel 5.5 dieses Projektgruppenberichts [Fachkr&#228;fte]).
In der Projektgruppe wurde diskutiert, ob die europ&#228;ischen Datenschutzanforderungen f&#252;r die KI-Start-ups, die
naturgem&#228;&#223; intensiv mit Daten arbeiten, vor- oder nachteilig sind. Unternehmensvertreterinnen und -vertreter
berichteten, dass die Sensibilisierung der Kunden f&#252;r Fragen des Datenschutzes in den letzten Jahren stark
angestiegen sei, sodass teilweise bewusst nach Anbietern gesucht werde, die sich f&#252;r den Schutz ihrer Daten und deren
transparente Verwendung einsetzen. Grunds&#228;tzlich ist die Projektgruppe daher der Auffassung, dass f&#252;r
Startups in der Phase des Markteintritts ein Wettbewerbsvorteil gerade dadurch entsteht, dass sie Fragen des
Datenschutzes die gleiche Aufmerksamkeit widmen wie der Akquise von Kapital und der Rekrutierung von Personal.
Gleichzeitig wird aber auch der hohe Aufwand f&#252;r kleine, junge Unternehmen gesehen.
Deshalb empfiehlt die Projektgruppe, auf Grundlage des Berichts der EU-Kommission &#252;ber die Bewertung und
&#220;berpr&#252;fung der DSGVO vom 25. Mai 2020 und von Folgeberichten (Artikel 97 DSGVO) sowie
R&#252;ckmeldungen von Branchen- und Verbraucherschutzverb&#228;nden dar&#252;ber zu entscheiden, welche Reformen notwendig sind, 
771 Dachfonds sind Investmentfonds, mit denen das Geld der Anleger wiederum in Anteilen an anderen Investmentfonds angelegt wird.
772 Dar&#252;ber hinaus regt die AfD-Fraktion die Schaffung steuerlicher Erleichterungen f&#252;r Gr&#252;nderfinanziers an, um den Kreis potenzieller
F&#246;rderer f&#252;r Start-ups zu erweitern.
773 Ausgliederung einer Organisationseinheit aus bestehenden Unternehmensstrukturen durch die Gr&#252;ndung eines eigenst&#228;ndigen
Unternehmens.
um Unternehmen im Allgemeinen und Start-ups im Besonderen bei der rechtskonformen Umsetzung der
DSGVO zu unterst&#252;tzen. Die Projektgruppe ist der Ansicht, dass die Landesdatenschutzbeh&#246;rden einheitliche
Kriterien f&#252;r die Datenschutzaufsicht ermitteln sollten. Auf dieser Grundlage empfiehlt die Projektgruppe, dass
die Datenschutzbeh&#246;rden in Zusammenarbeit mit Branchen- und Verbraucherschutzverb&#228;nden von der
Entwicklung branchenspezifischer Musterdokumente (nach Artikel 40 DSGVO) Gebrauch machen. In diesem
Zusammenhang empfiehlt die Projektgruppe zu pr&#252;fen, welche Vorteile und Risiken es f&#252;r Unternehmerinnen und
Unternehmer sowie Verbraucherinnen und Verbraucher hat, diese Musterdokumente mit einer Gesetzesfiktion zu
versehen.
Nachdem f&#252;r das Sammeln und Aufbereiten von Daten ca. 80 Prozent des Aufwands einer KI-L&#246;sung notwendig
sind, sollten zur Unterst&#252;tzung der Gr&#252;ndung von Start-ups auch Dateninvestitionen vorgesehen werden. Als
Gegenzug f&#252;r hochwertige Daten bekommt der Datenlieferant einen Anteil an dem Start-up, das Start-up spart
sich hingegen erhebliche Aufw&#228;nde und gewinnt Zeit. Daf&#252;r m&#252;ssten ein rechtlicher und ein technischer Rahmen
vorgegeben werden. 
Die Abschaffung der Sozialversicherungs-Vorf&#228;lligkeit in den ersten zwei Jahren nach Gr&#252;ndung sollte ebenfalls
gepr&#252;ft werden, damit Gr&#252;nderinnen und Gr&#252;nder die Sozialversicherungsbeitr&#228;ge nur einmal im Monat abf&#252;hren
m&#252;ssen. Nach derzeitiger Rechtslage m&#252;ssen Unternehmen die Sozialversicherungsbeitr&#228;ge ihrer
Mitarbeiterinnen und Mitarbeiter einmal vorab auf Basis einer Sch&#228;tzung und dann ein zweites Mal auf Basis der tats&#228;chlich
geleisteten Arbeitsstunden abrechnen. Diese Regelung f&#252;hrt vor allem f&#252;r kleinere und neu gegr&#252;ndete
Unternehmen zu einem hohen b&#252;rokratischen Aufwand.
Um den b&#252;rokratischen Aufwand noch weiter zu verringern und die Gr&#252;ndung neuer Firmen zu beschleunigen,
sollte ein Best-Practice-Modell oder eine Plattform angeboten werden, wo die Antwort auf zentrale Fragen, wie 
Umgang mit Daten, Finanzf&#246;rderung, Gesch&#228;ftsform, Rechte f&#252;r Forscherinnen und Forscher bei
Ausgr&#252;ndungen und vieles mehr, schnell und einfach zu finden sind. Zu &#252;berlegen ist, ob eine M&#246;glichkeit staatlicher
Startup-F&#246;rderung die &#220;bernahme der Sozialversicherungsbeitr&#228;ge von Mitarbeiterinnen und Mitarbeitern (sowie
Gr&#252;nderinnen und Gr&#252;ndern) f&#252;r z. B. die ersten Monate bzw. das erste Jahr sein k&#246;nnte.
5.2.2 KMU
Zur F&#246;rderung des Transfers von KI in den Mittelstand empfiehlt die Projektgruppe , vor allem Best Practices
aufzuzeigen, KI-Trainer einzusetzen, Beratungsangebote, etwa zur Umsetzung der DSGVO, anzubieten sowie
Qualifizierungsma&#223;nahmen durchzuf&#252;hren. Aufgrund der bereits aufgebauten Kompetenz im
Mittelstandstransfer erscheinen die Mittelstand-4.0-Kompetenzzentren hierf&#252;r als geeignete Ankerpunkte. Die Projektgruppe
schl&#228;gt vor, die Arbeit der Kompetenzzentren zu st&#228;rken und weitere Zentren aufzubauen, denn sie tragen dazu
bei, dass Gesch&#228;ftsmodellinnovation in KMU entwickelt und das fehlende Know-how aufgebaut werden kann.
Dabei sollte einerseits gro&#223;er Wert darauf gelegt werden, passgenaue Beratungsangebote zu entwickeln und
Unternehmen durch geeignete Weiterbildungsangebote dazu zu bef&#228;higen, KI selbst zu verstehen; andererseits
sollten neutrale Intermedi&#228;re, wie Verb&#228;nde, Kammern oder wissenschaftliche Einrichtungen, st&#228;rker eingebunden
werden, um das notwendige Vertrauen zu schaffen.
Weiterhin r&#228;t die Projektgruppe dazu, dass f&#252;r KMU st&#228;rkere Anreize geschaffen und M&#246;glichkeiten aufgezeigt
werden, wie nicht personenbezogene bzw. anonymisierte Daten sicher und gemeinschaftlich mit anderen
Unternehmen und Organisationen geteilt werden k&#246;nnen, um hieraus f&#252;r alle Beteiligten Mehrwerte zu generieren,
z. B. durch Trust-Center f&#252;r den Datenaustausch. Der &#8222;International Data Space&#8220; stellt aus der Sicht der
Projektgruppe ein gutes Beispiel dar und kann eine L&#246;sung f&#252;r den Mittelstand sein. 
Die Schaffung interdisziplin&#228;rer Datengenossenschaften, um experimentell Nutzenpotenziale zu testen, erscheint
aus Sicht der Projektgruppe zielf&#252;hrend. Mit diesem Ansatz k&#246;nnten der Mittelstand und das Handwerk in die
Lage versetzt werden, an der Wertsch&#246;pfung auf digitaler Ebene teilzuhaben. Dazu muss die notwendige
Unterst&#252;tzung geschaffen werden. Ein gutes Beispiel f&#252;r solche Ans&#228;tze sind &#8222;Micro Testbeds&#8220;774. Bei der Umsetzung
sollte darauf geachtet werden, vor allem Open-Source-Software einzusetzen bzw. zu entwickeln. Die
Projektgruppe empfiehlt, auch durch Forschungsauftr&#228;ge f&#252;r die Ausgestaltung von Datengenossenschaften die
Unterst&#252;tzung der Politik zu zeigen. 
774 Auf Best Practices verwies z. B. Prof. Dr. Heiner Lasi (Ferdinand-Steinbeis-Institut) in der Sitzung der Projektgruppe &#8222;KI und
Wirtschaft&#8220; am 8. April 2019.
Zudem ist aus Sicht der Projektgruppe eine genaue Bedarfsanalyse erforderlich, um zu verstehen, in welchen
Branchen KI zur zus&#228;tzlichen Wertsch&#246;pfung im Mittelstand beitragen kann und wo wichtiger
Optimierungsbedarf besteht. Etwa erscheint Computing Power vor allem f&#252;r KMU schwierig, da sie sich die notwendigen
Computer-Infrastrukturen h&#228;ufig nicht leisten k&#246;nnen. Hier w&#228;re es aus Sicht der Projektgruppe w&#252;nschenswert, wenn
der Aufbau dieser Infrastrukturm&#246;glichkeiten unterst&#252;tzt wird. Die steuerliche Forschungsf&#246;rderung, die im
Fr&#252;hjahr 2019 auf den Weg gebracht wurde, sieht die Projektgruppe als wichtigen Schritt, um die
Innovationsf&#228;higkeit von KMU auch im KI-Bereich zu st&#228;rken.
Zudem sollte f&#252;r mittelst&#228;ndische Unternehmen eine (neutrale) Plattform geschaffen werden, sodass diese sich
mit unabh&#228;ngigen Partnern austauschen und eine Art Technologie-Scouting als Unterst&#252;tzung erhalten k&#246;nnen.
Wichtig ist hier, dass immer Branchenwissen mit neuer Technologiekompetenz den Weg in die Unternehmen
findet, denn da es nicht &#8222;die eine&#8221; KI-Technologie gibt, sind der Einstieg in m&#246;gliche KI-Technologien und deren
Evaluation f&#252;r Mittelst&#228;ndlerinnen und Mittelst&#228;ndler die gr&#246;&#223;ten Herausforderungen.775 
5.2.3 Konzerne im Spannungsfeld zwischen etablierten und neuen Gesch&#228;ftsmodellen
Konzerne und Gro&#223;unternehmen befinden sich im permanenten Spannungsfeld zwischen innovativen und
etablierten Produkten, Prozessen und Gesch&#228;ftsmodellen. Dieses Spannungsfeld durchzieht den Konzern vom
Marketing und der Vorentwicklung &#252;ber die Entwicklung und Fertigung bis hin zu Sales und Support. Dies hat dazu 
gef&#252;hrt, dass von den Unternehmen vermehrt Forschungsauftr&#228;ge an Universit&#228;ten vergeben werden, was aus
Konzernsicht bei der &#220;bernahme der Ergebnisse zu Problemen f&#252;hren kann. Der Innovationsdruck bei KI
verst&#228;rkt diesen Trend und die Transferproblematik &#8211; letztlich die Umsetzung von Forschungsergebnissen in die
Anwendung &#8211; bei Konzernen weiter.
Die Projektgruppe weist darauf hin, dass der Transfer von Forschungsergebnissen in die Anwendung ebenso zu
den Aufgabenbereichen von Hochschulen geh&#246;rt wie etwa Forschung und Lehre. Ausgr&#252;ndungen aus der
Wissenschaft sind ein Weg, dies zu erreichen, der weiter gef&#246;rdert werden sollte. Sinnvoll f&#252;r Forschungsprojekte ist
die Durchf&#252;hrung des Projekts in interdisziplin&#228;ren, cross-funktionalen Teams, die parallel sowohl technische
als auch organisatorische Problemstellungen bearbeiten und die den Transfer in die Unternehmen mit einem
Kompetenzaufbau der Beteiligten verbinden. Theorie und Praxis sind wichtig und erg&#228;nzen sich, um auf
relevante Ergebnisse zu kommen. Um einen besseren Transfer zu erreichen, m&#252;ssen alle Akteure und Prozesse besser
verzahnt werden, d. h. Gesch&#228;ftsmodelle, Organisationsstrukturen sowie Mitarbeiterinnen und Mitarbeiter.
Gemeinsame Workspaces, wie sie f&#252;r Hochschulen und Start-ups &#252;blich sind, sollten im unternehmerischen Umfeld 
verst&#228;rkt angelegt werden.
Au&#223;erdem ist es empfehlenswert, Trusted-Rechenzentren einzurichten, um flexibel ausreichend Rechenleistung
zur Verf&#252;gung zu stellen und f&#252;r die Unternehmen Alternativen zu schaffen. 
Ein weiteres Handlungsfeld sieht die Projektgruppe in Regelungen oder Standards, die f&#252;r die Einf&#252;hrung von
KI in die Prozesse und in die Produkte gegeben werden, um Rechtssicherheit f&#252;r die Entwicklung zu schaffen.
Derzeit gibt es KI-zentrierte Ans&#228;tze z. B. in ISO-Standards wie ISO/IEC JTC 1/SC 42.776 Diese werden von
Teilen der Industrie als jedoch nicht zielf&#252;hrend erachtet, da &#8211; wie oben erw&#228;hnt &#8211; die KI aus ihrer
Anwendungssicht heraus betrachtet werden muss. Die Projektgruppe fordert deshalb, dass zus&#228;tzlich viel mehr der
existierenden Standards (wie z. B. ISO 26262 f&#252;r Automobile) um KI erg&#228;nzt werden.
Auch die immer komplexer werdende Technik mit KI als einer Spitze des Eisbergs erfordert Entscheidungen und
Aktionen ohne exakte Kenntnis der Folgen. Das Agieren in unsicheren Umgebungen, eine agile Vorgehensweise,
ein positiv-realistisches Umgehen mit dem Scheitern und die statistische Bewertung von Sachverhalten werden
in Konzernen &#8211; ebenso wie in der gesamten Gesellschaft &#8211; immer wichtiger. Die Politik muss mit Blick auf
diesen kulturellen Wandel die Vermittlung dieser Schl&#252;sself&#228;higkeiten st&#228;rker im Bildungssystem sowie im
Bereich des lebenslangen Lernens verankern.
Bei Konzernen wie auch bei kleineren Unternehmen zeigt sich deutlich: Die komplexe Technologie KI ben&#246;tigt
gut ausgebildete Spezialistinnen und Spezialisten sowie Expertinnen und Experten f&#252;r die Beherrschung und
Anwendung. Da es starke Anzeichen daf&#252;r gibt, dass die Hochschulen und Unternehmen in Deutschland auf
absehbare Zeit nicht gen&#252;gend Nachwuchs f&#252;r diesen Bereich ausbilden k&#246;nnen, wird geraten, dass Aus- und
775 Ein Best-Practice-Beispiel ist die fortiss GmbH, die als unabh&#228;ngige Forschungseinrichtung eine technisch neutrale Bewertung von 
L&#246;sungen und die individuelle Identifikation von KI-Potenzialen f&#252;r Mittelst&#228;ndler durchf&#252;hren kann; weitere Informationen dazu 
unter: https://www.fortiss.org/ (zuletzt abgerufen am 3. August 2020).
776 Weitere Informationen dazu unter: https://www.iso.org/committee/6794475.html (zuletzt abgerufen am 3. August 2020).
Weiterbildungsaktivit&#228;ten verst&#228;rkt betrieben werden sowie die jetzt schon angepasste Einwanderungspolitik f&#252;r
Spitzenkr&#228;fte weiter an den Fachkr&#228;ftebedarf angepasst wird. Unterst&#252;tzung der MINT-Ausbildung im
Allgemeinen und nat&#252;rlich der KI-Ausbildung im Speziellen ist daher angeraten.
Erkenntnisse zu Branchen
5.3.1 Industrie und Produktion 
Die Industrie mit ihrer Vielfalt an Branchen, Unternehmen und Gesch&#228;ftsmodellen konnte in der K&#252;rze der Zeit
von der Projektgruppe nur in Ans&#228;tzen betrachtet werden, hier verweist die Projektgruppe auch auf die
tiefergehenden Analysen von Industrieexpertinnen und -experten, wie sie beispielsweise im Rahmen des Netzwerks
Plattform Industrie 4.0 stattfinden.777 
Aus den Studien und Erfahrungsberichten, die in der Projektgruppe diskutiert wurden, wurde jedenfalls deutlich,
dass es beim KI-Einsatz in der Industrie und Produktion nicht nur um Produktivit&#228;t geht, sondern auch darum, 
Unternehmen neu zu gestalten.778 Intelligente Wertsch&#246;pfungsketten, Sicherheit und Gesundheit am Arbeitsplatz,
vorausschauende Wartung und Logistik, effiziente Gestaltung von Abl&#228;ufen sollen wichtige Faktoren f&#252;r KI-
Planung und -Implementierung werden. Wie bereits zuvor bei den Konzernen dargestellt, ist der Mangel an
kompetenten Arbeitskr&#228;ften ein gro&#223;es Risiko f&#252;r diese Branche. Insofern r&#228;t die Projektgruppe, die bereits
entstehenden Partnerschaften f&#252;r Qualifikation und Personalentwicklung zwischen Technologieanbietern, Industrie,
Regierungen, Bildungseinrichtungen und Arbeitnehmervertretungen zu forcieren. Dabei kommt es im
Industriebereich besonders darauf an, die ben&#246;tigten Kompetenzen richtig zu definieren.
Das zweite wichtige Handlungsfeld im industriellen Kontext bezieht sich auf Sicherheit und Zuverl&#228;ssigkeit,
etwa wenn intelligente Produktionsstra&#223;en gebaut oder autonome Roboter eingesetzt werden. Hier wird auf die
ausf&#252;hrlich dargelegten Anforderungen, Regularien und Vorschl&#228;ge der Plattform Industrie 4.0 verwiesen.779 
Aus Sicht der Projektgruppe ist u. a.780 von Bedeutung, 
&#8226; dass die Beteiligten aus der Industrie ihre Best Practices teilen, etwa zu wirksamen Tests und zum Aufbau
von Controllingsystemen, 
&#8226; dass die zuvor geforderten Regularien zu Ethik und Nachhaltigkeit im Industriesektor umgesetzt werden
und 
&#8226; dass bereits geltende Gesetze &#8211; vom Datenschutz &#252;ber Produkthaftungsgesetze bis zu sektorspezifischen
Gesetzen &#8211; eingehalten werden. 
Hier sind die im Status quo, Kap. 4.1.6, dargelegten &#220;berlegungen zum Datenschutz als auch die Zukunft des
Verbraucher- und Produkthaftungsrechts elementar, damit Verbraucherinteressen und Pers&#246;nlichkeitsrechte
ausreichend gesch&#252;tzt sind, aber gleichzeitig Innovationen nicht gehemmt werden. Die Schaffung von
Industriestandards kann ein guter Ausgangspunkt sein.781 
Eine verschuldensunabh&#228;ngige Haftung sollte gepr&#252;ft werden. Bei KI-Systemen f&#252;hrt sie nicht immer zu
sachgerechten Ergebnissen, da an der Entwicklung und am Einsatz von KI-Systemen in der Regel mehrere Akteure
beteiligt sind. Daher muss aus Sicht der Projektgruppe erstens perspektivisch eine vern&#252;nftige Aufteilung der
Haftung f&#252;r etwaige Sch&#228;den oder M&#228;ngel gefunden werden, zweitens muss eine entsprechende Zusammenarbeit
zwischen Industrieunternehmen und Versicherungen stattfinden. 
Drittens werden die Datenverf&#252;gbarkeit und Datenqualit&#228;t im industriellen Sektor als entscheidend angesehen.
Unternehmen ben&#246;tigen Zugang zu relevanten und qualitativ hochwertigen Datenbest&#228;nden sowie dazu passende
Modelle, die sie mit wenig Aufwand f&#252;r die Optimierung und zum Training ihrer KI-L&#246;sungen nutzen k&#246;nnen.
Hier fordert die Projektgruppe einerseits, dass (nicht-personenbezogene) Daten aus dem &#246;ffentlichen Sektor
777 Weitere Informationen dazu unter: https://www.plattform-i40.de/PI40/Navigation/DE/Home/home.html (zuletzt abgerufen am
3. August 2020).
778 Vgl. Shaw (2019): The Future Computed &#8211; K&#252;nstliche Intelligenz in der Industrie, S. 63 ff.
779 Weitere Informationen dazu: https://www.plattform-i40.de/PI40/Navigation/DE/Home/home.html (zuletzt abgerufen am 3. August
2020); hier Plattform Industrie 4.0 (2019): K&#252;nstliche Intelligenz (KI) in Sicherheitsaspekten der Industrie 4.0.
780 Die Mehrheit der Projektgruppe verweist auf die ausf&#252;hrlich dargelegten Anforderungen, Regularien und Vorschl&#228;ge der Plattform
Industrie: https://www.plattform-i40.de/PI40/Navigation/DE/Home/home.html (zuletzt abgerufen am 3. August 2020).
781 Zu den Aktivit&#228;ten siehe Mangelsdorf (2019): Normen und Standards in der KI.
&#8211; wie Statistiken, Geo- oder Mobilit&#228;tsdaten &#8211; und aus &#246;ffentlich gef&#246;rderten Forschungsprojekten f&#252;r
Maschinelles Lernen zur Verf&#252;gung gestellt werden.782 Andererseits ermuntert sie die Unternehmen, das vorherrschende
System von Datensilos aufzubrechen und sich untereinander besser zu vernetzen.783 
Ein gro&#223;er Vorteil dabei ist: Jedes Unternehmen besitzt und beh&#228;lt die vollst&#228;ndige Kontrolle &#252;ber seine Daten,
profitiert aber von den jeweiligen Modellen und Erkenntnissen der anderen Unternehmen.  
Die Projektgruppe spricht sich daf&#252;r aus, ein europ&#228;isches Innovationscluster KI im Rahmen der deutschen
Ratspr&#228;sidentschaft 2020 zu starten, das im Schwerpunkt Industrieanwendungen vor allem im Bereich Automobile
und Industrie 4.0 forciert.
5.3.2 Handel
F&#252;r Unternehmen im Handel ergeben sich durch den Einsatz von KI verkn&#252;pft mit einer gro&#223;en Datenbasis viele 
M&#246;glichkeiten, ihren Absatz zu steigern sowie ihre Prozesse zu optimieren. Auch er&#246;ffnet KI verschiedene
M&#246;glichkeiten, Verbraucherinnen und Verbraucher zu st&#228;rken, etwa durch intelligente Suchmaschinen und
Assistenzfunktionen, die beispielsweise Pr&#228;ferenzen, wie Vermeidung von Inhaltsstoffen wegen Allergien u. v. m.
ber&#252;cksichtigen. Dennoch d&#252;rfen die Gefahren nicht untersch&#228;tzt werden, die etwa durch eine unvorteilhafte
Beeinflussung durch Dritte entstehen k&#246;nnten, falls Kundinnen und Kunden durch individualisierte Inhalte,
Produktvorschl&#228;ge oder Preissysteme benachteiligt werden. KI sollte daher auch im Handel niemals als Selbstl&#228;ufer
betrachtet werden, sondern muss konstant kontrolliert werden. Das Risikobewusstsein muss immer in die Entscheidung
&#252;ber eine Einf&#252;hrung von KI mit einflie&#223;en. Zudem sollten Vorhaben gef&#246;rdert werden, die den station&#228;ren
Einzelhandel st&#228;rken und aufzeigen, ob und wie innovative KI-Anwendungen implementiert werden k&#246;nnten, wie
es z. B. im Bereich der Digitalisierung allgemein im Modellprojekt &#8222;Digitale Einkaufsstadt Bayern&#8220; angestrebt
wird. 
5.3.3 Finanzmarkt und Versicherungen
Die Projektgruppe empfiehlt, eine ganzheitliche Strategie f&#252;r den digitalen Finanzplatz und
Versicherungsstandort zu erarbeiten, die neue oder verbesserte Produkte, Prozesse und IT-Infrastrukturen, wie beispielsweise
Kryptow&#228;hrungen, Trading Bots, Cloud Computing und Betrugserkennung, f&#246;rdert und gleichzeitig Risiken abf&#228;ngt,
um einen digitalen, nachhaltigen, sicheren und im Sinne von Verbraucherinnen und Verbrauchern gestalteten
Finanzmarkt zu erm&#246;glichen.
Um die Implementierung von KI in der Finanz- und Versicherungswirtschaft zum Erfolg zu machen, ist das
Vertrauen der Verbraucherinnen und Verbraucher ein entscheidender Faktor. Datensouver&#228;nit&#228;t und technische
M&#246;glichkeiten, welche eine anonymisierte Datenanalyse erm&#246;glichen, sind hierf&#252;r essentiell. Die Erkl&#228;rbarkeit
von Modellen und Analyseprozessen ist zu gew&#228;hrleisten, um Blackbox-Verweise zu vermeiden und ein
wirksames, angemessenes Kontrollsystem (teil-)automatisierter Prozesse im Bereich der Gesch&#228;ftsorganisation
einzuf&#252;hren. 
Die Projektgruppe ist der Meinung, dass Verbraucherinnen und Verbraucher vor Diskriminierung durch eine
effektive und angemessene Regulation gesch&#252;tzt werden m&#252;ssen, beispielsweise durch Ausschluss eines
Kreditoder Versicherungsvertrages oder bei unverh&#228;ltnism&#228;&#223;iger Benachteiligung durch personalisierte, erh&#246;hte Preise.
Hierf&#252;r ist sicherzustellen, dass die Kriterien der Preisbildung offengelegt werden und personalisierte Preise
erkennbar sind. Um Transparenz herzustellen, muss Verbraucherinnen und Verbrauchern die M&#246;glichkeit gegeben
werden, durch den Einsatz vorvertraglicher, standardisierter Produktinformationen verst&#228;ndliche und
vergleichbare Informationen zu allen digitalen Finanz- und Versicherungsprodukten und Dienstleistungen zu erhalten,
u. a. um versteckte Geb&#252;hren oder die ungewollte Preisgabe sensibler pers&#246;nlicher Informationen zu vermeiden.
Zudem ist es wichtig, die Tech-Kompetenzen innerhalb der Unternehmen, besonders bei Mitarbeiterinnen und
Mitarbeitern, die in kritischen Prozessen arbeiten, durch regelm&#228;&#223;ige Schulungen zu st&#228;rken. 
782 Hierf&#252;r gibt es bereits entsprechende Ans&#228;tze; zur EU-Politik f&#252;r Open Data; vgl. Europ&#228;ische Kommission (2019): Digitaler
Binnenmarkt: EU-Verhandlungsf&#252;hrer einigen sich auf neue Regeln f&#252;r die gemeinsame Nutzung der Daten des &#246;ffentlichen Sektors.
783 Beispiele daf&#252;r sind die Open Data Initiative (ODI) von Microsoft, SAP und Adobe oder die Open Manufacturing Platform von 
Microsoft und BMW; vgl. Shaw (2019): The Future Computed &#8211; K&#252;nstliche Intelligenz in der Industrie, S. 113 ff.
Weiterhin empfiehlt die Projektgruppe, &#246;ffentliche Institutionen wie den Zoll oder die Bundesanstalt f&#252;r
Finanzdienstleistungsaufsicht (BaFin), Polizei, Staatsanwaltschaften und Steuerbeh&#246;rden technisch und personell zu
bef&#228;higen, den Herausforderungen des zunehmend komplexen Finanzmarktes durch Nutzung von KI, neuen
Gesch&#228;ftsmodellen und mehr Marktteilnehmern gerecht zu werden und die sich ergebenden Chancen der KI zu 
nutzen. 
So sind z. B. Schnelligkeit und die Analyse von verd&#228;chtigen Finanztransaktionen immens wichtig. Da pro Tag
bei den zust&#228;ndigen Beh&#246;rden &#252;ber 200 Verdachtsmeldungen im Zusammenhang mit m&#246;glicher Geldw&#228;sche
oder Terrorismusfinanzierung eingehen, regt die Projektgruppe an, mithilfe von KI eine systematische und
effizientere Erfassung der Meldungen und einen entsprechend verbesserten Datenabgleich zwischen den
ermittelnden Beh&#246;rden herbeizuf&#252;hren.784 
Auch Technologieunternehmen, die als Akteure im Finanzmarkt auftreten, sind unter Aufsicht zu stellen, sobald
sie als systemrelevant eingestuft werden.785 
5.3.4 Landwirtschaft
Die Projektgruppe sieht im Bereich KI-Einsatz in der Landwirtschaft ein gro&#223;es &#246;konomisches wie &#246;kologisches
Potenzial, sieht aber auch das Risiko weiterer Marktkonzentration und einer steigenden Abh&#228;ngigkeit der
Landwirtinnen und Landwirte von Agrarunternehmen. Die Projektgruppe misst deshalb der Schaffung von
vertrauensw&#252;rdigen Datensystemen mit einem Fokus auf Open Data und Open Source gerade im Bereich der
Landwirtschaft eine zentrale Bedeutung zu. Sie empfiehlt, vertieft zu untersuchen, welchen Beitrag der KI-Einsatz in der
Landwirtschaft zur &#246;konomischen St&#228;rkung l&#228;ndlicher Regionen leisten kann und wie die &#246;kologischen
Potenziale des KI-Einsatzes auch tats&#228;chlich gehoben werden k&#246;nnen.
Handlungsempfehlungen zu Daten und Plattformen 
Die gro&#223;en internationalen Akteure (insb. GAFAM) haben aufgrund ihrer umfangreichen Datenbest&#228;nde und
Daten-Expertise einen Wettbewerbsvorteil im KI-Markt. Momentan sind Konzentrationseffekte und
Monopolisierungstendenzen in der Daten&#246;konomie zu beobachten. Wichtige &#8222;Taker&#8220;, d. h. Daten-Plattformen, deren
Gesch&#228;ftsmodelle vor allem auf der Vermarktlichung der pers&#246;nlichen Daten ihrer Nutzerinnen und Nutzer beruhen,
wie zum Beispiel GAFAM/BAT786, ziehen zunehmend Renditen von den &#8222;Makern&#8220;, d. h. produzierenden
Unternehmen, ab und agieren nach dem wettbewerbszerst&#246;renden &#8222;The winner takes it all&#8220;-Prinzip. Daher sieht es
die Projektgruppe f&#252;r die Entfaltung von KI-Anwendungen in Deutschland und Europa als ma&#223;geblich an, dass
ein europ&#228;isches Modell einer Daten&#246;konomie entwickelt wird und Datenbest&#228;nde und Know-how in der
Datenanalyse besser miteinander vernetzt werden. Diese Vernetzung kann z. B. durch neutrale Intermedi&#228;re erm&#246;glicht
werden, die nicht prim&#228;r der eigenen Rendite verpflichtet sind (Genossenschaftsmodelle etc.). Gerade deutsche
Unternehmen w&#252;rden von einer St&#228;rkung der Position der &#8222;Maker&#8220; profitieren. Neben den bereits
angesprochenen Punkten werden hierf&#252;r folgende Empfehlungen gegeben:
Die Projektgruppe regt an, dass der Staat f&#252;r Unternehmen weitere M&#246;glichkeiten er&#246;ffnet, verschiedene Wege
des Datenzugangs auszuprobieren und kooperative Modelle zu entwickeln. Daf&#252;r sind sowohl &#246;konomische
Anreize f&#252;r das Teilen von Unternehmensdaten zu schaffen als auch Rechtssicherheit f&#252;r verschiedene
Betreibermodelle von Datenzugangsapplikationen. 
&#8226; Erleichterungen im Wettbewerbs-/Kartellrecht
Insbesondere ist zu kl&#228;ren, unter welchen Bedingungen heute marktf&#252;hrende Unternehmen einer Branche
gemeinsam digitale Plattformen aufbauen d&#252;rfen, denn Skalierbarkeit und grenz&#252;bergreifende Kooperationen sind
regelm&#228;&#223;ig kritische Faktoren, die den Erfolg digitaler Gesch&#228;ftsmodelle sowie damit verbundene Investitions-
und Innovationsanreize bestimmen. 
784 Hier wird insbesondere das Zusammenspiel zwischen Bundeskriminalamt (BKA) und der Financial Intelligence Unit (FIU)
angesprochen; siehe dazu auch den Bericht der Projektgruppe &#8222;KI und Staat&#8220; in Kapitel C. III [K&#252;nstliche Intelligenz und Staat
(Projektgruppe 2)]; vgl. auch Generalzolldirektion &#8211; Financial Intelligence Unit (FIU) (2019): Jahresbericht 2018 &#8211; Financial
Intelligence Unit.
785 Systemrelevant sind Institute, deren Bestandsgef&#228;hrdung aufgrund ihrer Gr&#246;&#223;e, der Intensit&#228;t ihrer Interbankenbeziehungen und ihrer
engen Verflechtung mit dem Ausland erhebliche negative Folgeeffekte bei anderen Kreditinstituten ausl&#246;sen und zu einer Instabilit&#228;t
des Finanzsystems f&#252;hren k&#246;nnte. Die Einstufung als systemrelevantes Institut erfolgt einvernehmlich zwischen BaFin und
Bundesbank.
786 Die Abk&#252;rzung BAT steht f&#252;r die chinesischen Unternehmen Baidu, Alibaba und Tencent.
Daten sind im Gegensatz zu anderen Rohstoffen unbegrenzt wiederverwertbar, da sie nicht im klassischen Sinn
&#8222;verbraucht&#8220; werden k&#246;nnen. Der Besitz von Daten kann deshalb zu sogenannten Feedback-Loops787 f&#252;hren:
Durch den Besitz von Daten k&#246;nnen Verbraucherw&#252;nsche besser analysiert und vorhergesagt werden, was zu
Wettbewerbsvorteilen f&#252;hrt. Diese Wettbewerbsvorteile f&#252;hren in der Regel dazu, dass der Zugriff auf weitere
Daten erlangt wird und erneut &#8211; markt&#252;bergreifend &#8211; Wettbewerbsvorteile entstehen. Dieser Effekt ist
insbesondere bei plattformbasierten Gesch&#228;ftsmodellen zu beobachten. Aufgrund von Netzwerkeffekten788 weisen
Plattformm&#228;rkte insbesondere im B2C-Bereich Monopolisierungstendenzen auf. 
Damit diese Machtpositionen im Markt gegen&#252;ber Konkurrenten zuk&#252;nftig nicht unangreifbar sind und die
Wahlfreiheit von Konsumentinnen und Konsumenten auch in der digitalen &#214;konomie gesichert werden kann,
empfiehlt die Projektgruppe &#196;nderungen im Wettbewerbsrecht. Diese dienen der Sicherung des Datenzugangs f&#252;r
KI-Anwendungen &#8211; sowohl f&#252;r Unternehmen als auch f&#252;r Verbraucherinnen und Verbraucher. Die Projektgruppe
verweist in diesem Zusammenhang auf die Ergebnisse der vom BMWi eingesetzten
Wettbewerbskommission 4.0.
Um den digitalen europ&#228;ischen Binnenmarkt zu st&#228;rken, empfiehlt die Projektgruppe, die Umsetzung der in
diesem Unterkapitel formulierten Handlungsempfehlungen m&#246;glichst auf europ&#228;ischer Ebene zu forcieren.
Die DSGVO kennt bereits ein Recht auf Datenportabilit&#228;t (Artikel 20 DSGVO). Die Projektgruppe empfiehlt zu 
pr&#252;fen, ob und inwiefern die Verankerung einer wettbewerbsrechtlichen Pflicht zur Datenweitergabe in Echtzeit
und in einem interoperablen Datenformat f&#252;r marktm&#228;chtige Unternehmen an konkurrierende Marktteilnehmer
geeignet ist, die Wettbewerbsf&#228;higkeit von Start-ups und KMU im Bereich von KI-Technologien sowie den
Wettbewerb im Bereich KI-Technologien und Gesch&#228;ftsmodelle insgesamt zu verbessern.
Die Projektgruppe empfiehlt dar&#252;ber hinaus, die Rechtssicherheit f&#252;r Kooperationen von Unternehmen im KI-
Sektor dadurch zu st&#228;rken, dass Unternehmen im Vorfeld einer Kooperation eine Einsch&#228;tzung der EU-
Kommission bez&#252;glich der Rechtm&#228;&#223;igkeit ihres Kooperationsvorhabens erlangen k&#246;nnen.
&#8226; Datenpooling/Datenvernetzung
Ausgangslage in Deutschland ist, dass es keine gro&#223;en Datenpools gibt, sondern dass eine fragmentierte
Datenlandschaft &#252;ber viele Unternehmen hinweg zu beobachten ist. Die Stiftung Neue Verantwortung789 hat im Jahr
2019 rund 60 verschiedene Sharing-Initiativen ermittelt, die von Forschungspools zu Industrie-Plattformen
reichen und vorwiegend &#246;ffentlich finanziert sind. Die verschiedenen Initiativen sind teilweise durch ihre f&#252;hrenden
Akteure oder durch gemeinsame Infrastrukturen untereinander verbunden, auch wurden Datenzentren
ausgemacht, wie z. B. die International Data Spaces; es fehlt aber eine Gesamtstrategie f&#252;r Datensharing oder ein
zentraler Marktplatz im Sinne eines &#8222;Amazons f&#252;r Daten&#8220;790, das den deutschen bzw. europ&#228;ischen Unternehmen
einen Wettbewerbsschub geben k&#246;nnte. 
Die Projektgruppe empfiehlt daher, die dezentralen Datenbest&#228;nde, z. B. in Wertsch&#246;pfungsketten,
Forschernetzwerken und &#246;ffentlichen Verwaltungen, st&#228;rker interoperabel zu vernetzen. Hierf&#252;r sollten Leitinitiativen zur
dezentralen Datenvernetzung, wie die International Data Spaces, die Nationale Forschungsdateninfrastruktur
oder die Open Knowledge Foundation791, durch entsprechende gesetzliche Rahmenbedingungen und gezielte
F&#246;rderung unterst&#252;tzt werden.
Weiterhin r&#228;t die Projektgruppe dazu, sektorspezifische Modelle bzw. Ausgestaltungsm&#246;glichkeiten f&#252;r
partizipatorische Datenplattformen (digitale Genossenschaften oder &#196;hnliches) zu entwickeln, bei denen die
Teilnehmenden Daten sicher teilen und nutzen k&#246;nnen.
Es existieren bereits Modellvorhaben, die den Weg aufzeigen, wie dadurch neue Gesch&#228;ftsmodelle im KI-
Bereich entstehen bzw. etablierte Gesch&#228;ftsmodelle weiterentwickelt werden k&#246;nnen. Solche Best Practices sollten
787 Feedback-Loop bedeutet R&#252;ckkopplungsschleife. Feedback-Loops nutzen die Interaktionen des Nutzenden mit dem Dienst, um den 
Dienst selbst zu verbessern oder Input f&#252;r neue Angebote zu schaffen.
788 An dieser Stelle sind positive Netzwerkeffekte gemeint. Dieser Begriff beschreibt das Ph&#228;nomen, dass der Nutzen einer Plattform 
mit zunehmender Nutzerzahl steigt (Vgl. Schallbruch et al. (2019): Ein neuer Wettbewerbsrahmen f&#252;r die Digitalwirtschaft. Bericht 
der Kommission Wettbewerbsrecht 4.0, S. 16).
789 Vgl. Heumann und Jentzsch (2019): Wettbewerb um Daten &#8211; &#220;ber Datenpools zu Innovationen.
790 Vgl. Heumann und Jentzsch (2019): Wettbewerb um Daten &#8211; &#220;ber Datenpools zu Innovationen, S. 12.
791 Beispielhaft genannt werden hier &#8211; ohne Anspruch auf Vollst&#228;ndigkeit &#8211; Initiativen, die in der Enquete-Kommission besprochen 
wurden: https://www.fraunhofer.de/de/forschung/fraunhofer-initiativen/industrial-data-space.html (zuletzt abgerufen am 3. August
2020); https://www.dfg.de/foerderung/programme/nfdi/ (zuletzt abgerufen am 3. August 2020); https://okfn.de/ (zuletzt abgerufen
am 3. August 2020); vgl. auch Plattform Industrie 4.0 (2019): Technologieszenario &#8222;K&#252;nstliche Intelligenz in der Industrie 4.0&#8220;.
st&#228;rker gef&#246;rdert werden. Die Projektgruppe pl&#228;diert daf&#252;r, ganzheitliche Ans&#228;tze zu f&#246;rdern und eine Art
&#8222;Testautobahn A 9&#8220; f&#252;r KI und Datenr&#228;ume einzurichten, um Freir&#228;ume f&#252;r Experimente zu schaffen.792 
Dass ein &#8222;Daten-Amazon&#8220; entstehen kann, wird in der Projektgruppe skeptisch gesehen, einerseits mit Blick auf
die rechtliche Unsicherheit (Datenschutzrecht, Wettbewerbsrecht), andererseits weil aus Unternehmersicht auch
Anreizprobleme bestehen, da die Teilnahme an einem Pool f&#252;r ein Unternehmen nicht nur Vorteile bringt,
sondern auch Risiken in Bezug auf Sicherheit, Vertrauen etc. birgt.
&#8226; &#214;ffentlicher Datenzugang
Betrachtet wurden in der Projektgruppe verschiedene Instrumente, um den &#246;ffentlichen Zugang zu Daten neu zu
regeln. Zwar gibt es kein anerkanntes Eigentumsrecht an Daten, es gibt aber verschiedene rechtliche
Zuordnungen, etwa zum Datenschutzrecht, Urheberrecht oder Datenbankschutz. Ob ein solches Eigentumsrecht an Daten 
sinnvoll ist, wurde kontrovers diskutiert und skeptisch betrachtet, da dies erstens die Komplexit&#228;t bei der
Vollziehbarkeit digitaler Vorg&#228;nge exponentiell erweitern w&#252;rde und da zweitens die Diskussion von
Datenzuordnungsregeln je nach Sektor sehr unterschiedlich gef&#252;hrt wird. Fest steht, dass die Bereitstellung von Daten
&#228;u&#223;erst sorgf&#228;ltig abgewogen werden muss.793 
Daher schl&#228;gt die Projektgruppe vor, verschiedene Modelle f&#252;r eine Neuregelung des Datenzugangs zu pr&#252;fen,
etwa die Beschr&#228;nkung auf bestimmte Wertsch&#246;pfungsketten, z. B. nur in M&#228;rkten, in denen keine hohe
Konzentration (Mono-/Oligopole) zu beobachten ist. Denkbar ist auch die F&#246;rderung kleinerer Unternehmen aus
innovationspolitischen Gr&#252;nden oder besondere Datenzugangsrechte beim Zugang zu Daten des &#246;ffentlichen
Sektors zu schaffen.794 
Auch wird empfohlen, dass sektorspezifische Regelungen zur Nutzung von personenbezogenen Daten von
solchen Anwendungen getroffen werden, die nicht das Ziel haben, durch die Daten Microtargeting oder
Personalisierung von Angeboten durchzuf&#252;hren.
&#8226; Datenverwendung
Bei der Datenverwendung und dem Ziel von Datenverarbeitungen sollte es nach Auffassung der Projektgruppe
stets auf das entsprechende Risiko ankommen (risikobasierter Ansatz) und nicht auf bestimmte Prozesse, da dies
zu unw&#228;gbaren Abgrenzungsschwierigkeiten f&#252;hren w&#252;rde.
Die Projektgruppe erwartet, dass durch die Verbreitung von vertrauensschaffenden Konzepten zur
Anonymisierung und Pseudonymisierung von Daten die Menge verf&#252;gbarer Trainingsdaten steigen k&#246;nnte.795 Daher
empfiehlt sie, Trust-Strukturen zum interdisziplin&#228;ren, vertrauensw&#252;rdigen Austausch nicht personenbezogener
Daten aufzubauen.796 
Fachkr&#228;fte
F&#252;r alle Generationen ist es von stets zunehmender Bedeutung, digitale Prozesse besser zu verstehen, um
Herausforderungen gezielter zu meistern. Digitale Kenntnisse werden immer mehr zu einer unverzichtbaren
Schl&#252;sselkompetenz f&#252;r die Teilhabe in allen Bereichen und f&#252;r die Sicherheit die oder des Einzelnen wie auch der
ganzen Gesellschaft im Sinne eines selbstst&#228;ndigen und m&#252;ndigen Lebens in der digitalen Welt. Dazu geh&#246;rt
auch zu verstehen, wie KI in den Grundz&#252;gen funktioniert. 
792 Vgl. die Best-Practice-Beispiele wie die Aktivit&#228;ten des Ferdinand-Steinbeis-Instituts oder des Mittelstand-4.0-Kompetenzzentrums
Stuttgart unter: https://digitales-kompetenzzentrum-stuttgart.de/geschaeftsmodellentwicklung (zuletzt abgerufen am 3. August 2020).
793 Vgl. Nahles (2018): Die Tech-Riesen des Silicon Valleys gef&#228;hrden den fairen Wettbewerb.
794 Ein Beispiel daf&#252;r ist die Stadt San Francisco, in der alle Dienste, die Fahrgemeinschaften anbieten, Daten &#252;ber jede gefahrene Fahrt
zur Verf&#252;gung stellen m&#252;ssen, damit die Stadt diese f&#252;r die Verkehrsplanung nutzen kann beziehungsweise damit andere
Unternehmen darauf aufbauende Dienste anbieten k&#246;nnen. Bei den Anh&#246;rungen der Kommission Wettbewerbsrecht 4.0 hat z. B. ein
Unternehmen berichtet, dass es, um Mobilit&#228;tsdienstleistungen anbieten zu k&#246;nnen, Daten von amerikanischen Unternehmen kaufen
m&#252;sste, da diese bessere Daten zur Mobilit&#228;t in deutschen Kommunen h&#228;tten.
795 Viele Expertinnen und Experten halten es f&#252;r fraglich, ob eine Anonymisierung oder Pseudonymisierung von personenbezogenen 
Daten wirksam m&#246;glich ist. Hier ist noch Forschung notwendig; vgl. J&#228;schke et al. (2018): F&#252;r immer anonym: Wie kann De-
Anonymisierung verhindert werden?
796 Wichtig ist dar&#252;ber hinaus die Verbesserung der M&#246;glichkeiten zum Datenaustausch auch innerhalb eines Unternehmens. Es gibt
viele n&#252;tzliche Daten, f&#252;r die die Zuordnung zu einer Person nicht erforderlich ist. Es muss &#252;berlegt werden, wie die Anonymisierung
von Daten verbessert werden kann, z. B. durch eine zentrale Institution zur Anonymisierung von Daten.
Die Projektgruppe sieht es daher als essentiell an, das deutsche Bildungssystem z&#252;gig darauf auszurichten, dass
von Anfang an und &#252;ber alle Bildungswege hinweg digitale Kompetenzen vermittelt werden. Dies schlie&#223;t ein
Grundverst&#228;ndnis der Funktionsweise von Algorithmen und selbstlernenden Systemen mit ein. 
Formen der Mitarbeiterbeteiligung k&#246;nnen ein geeignetes Instrument sein, um qualifiziertes Personal zu
gewinnen, langfristig zu motivieren und an sich zu binden. Im europ&#228;ischen Vergleich ist die steuerliche Attraktivit&#228;t 
von Beteiligungsmodellen allerdings sehr gering. Um Abhilfe zu schaffen, sollte der Steuerfreibetrag f&#252;r
Mitarbeiterbeteiligungen deutlich erh&#246;ht sowie die Besteuerung und F&#246;rderung EU-weit harmonisiert werden. Dar&#252;ber
hinaus bedarf es insbesondere der Verschiebung des Zeitpunktes der Besteuerung. Nach aktueller Gesetzeslage
muss der geldwerte Vorteil mit dem Einkommensteuersatz versteuert werden, obwohl noch keine Auszahlung
der aus der Mitarbeiterbeteiligung entstandenen Dividende erfolgte.
Dringenden Bedarf sieht die Projektgruppe auch bei der Ausbildung von Fachkr&#228;ften, die KI-Systeme entwickeln
und einrichten k&#246;nnen. Je st&#228;rker KI in die Arbeitsprozesse eingebunden wird, umso wichtiger werden
Probleml&#246;sungs- und Handlungskompetenzen der Besch&#228;ftigten. Sie sichern die Basis von Innovationen in den
Unternehmen und Betrieben. Deshalb empfiehlt die Projektgruppe hier eine bessere Vernetzung, etwa den
Austausch von Mitarbeiterinnen und Mitarbeitern zwischen Abteilungen zu erleichtern oder den Austausch von
Verwaltung und Wirtschaft aktiv zu f&#246;rdern, z. B. durch Fellowships, um auch hier den Wissensaustausch und
-aufbau voranzutreiben.
Die KI selbst unterst&#252;tzt die bedarfsgerechte und flexible Gestaltung beruflicher Weiterbildung, erzeugt aber 
zugleich einen hohen Bedarf an notwendigen Bildungsinvestitionen. Die Projektgruppe ist daher der Meinung,
dass Weiterbildungskonzepte zeitnah auf den Wandel durch KI-Technologien ausgerichtet werden m&#252;ssen.
Dabei wird auf die berufliche Weiterbildung als passendes Instrument hingewiesen, um schnell, flexibel und
bedarfsgerecht Fachkr&#228;fte auf technologische Herausforderungen hin zu qualifizieren, die mit Digitalisierung und
KI verbunden sind. Auch staatliche Bildungskonzepte m&#252;ssen vom Einmal-und-nie-wieder-Gedanken hin zum
lebenslangen Lernen weiterentwickelt werden. Diese Ma&#223;nahmen wurden in die Projektgruppe aber nicht weiter
konkretisiert, da dazu eine eigene Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220; eingerichtet wurde und
viele Fragen auch in der parallel laufenden Enquete-Kommission &#8222;Berufliche Bildung in der digitalen
Arbeitswelt&#8220;797 beraten werden.
Rechtsentwicklung und Politik
Die Projektgruppe ist &#252;berzeugt, dass Regularien spezifisch f&#252;r die unterschiedlichen Auspr&#228;gungen von KI
gesetzt werden sollten und nicht allgemein f&#252;r die gesamte KI, damit eine praxistaugliche Regulierung gefunden
wird, die auf einer realistischen Einsch&#228;tzung fu&#223;t. So ist etwa der Wunsch nach Interpretierbarkeit der
Ergebnisse von KI-Anwendungen nicht in allen Bereichen gleich relevant. So ist sie z. B. relevant bei der Entscheidung
&#252;ber Kreditw&#252;rdigkeit, aber weniger relevant bei Empfehlungssystemen (&#8222;Kunden, die dieses Produkt kauften,
kauften auch&#8220;).798 
Grunds&#228;tzlich wird von der Projektgruppe empfohlen, die durch KI auftretenden neuen Risiken nicht komplett
mit neuer Gesetzgebung l&#246;sen zu wollen, sondern sich vor allem auf die Durchsetzung bestehender Regeln zu
konzentrieren, etwa mit Blick auf die DSGVO. Hier sollten f&#252;r die tats&#228;chliche Durchsetzung der bestehenden
Regeln die zust&#228;ndigen Datenschutzbeh&#246;rden so ausgestattet werden, dass sie moderne Datenverarbeitung auch
pr&#252;fen k&#246;nnen. Anstelle der Unterst&#252;tzung der Beh&#246;rden durch eine externe Einheit bef&#252;rwortet die
Projektgruppe die bessere Ausstattung der Datenschutzbeh&#246;rden, damit diese auch das notwendige Know-how erlangen.
Zus&#228;tzlich zu den gesetzlichen Vorgaben sollten Ans&#228;tze zur Selbstregulierung gef&#246;rdert und nach dem Beispiel
der DSGVO gesetzlich verortet werden, also durch &#8222;Codes of Conduct&#8220;, die die bestehenden gesetzlichen
Regelungen konkretisieren. Dieser Ansatz erm&#246;glicht es dem Gesetzgeber, weiterhin technikneutrale Gesetzgebung
zu erlassen.
797 Weitere Informationen dazu unter: https://www.bundestag.de/ausschuesse/weitere_gremien/enquete_bb (zuletzt abgerufen am 3.
August 2020).
798 Siehe hierzu den Bericht der Projektgruppe &#8222;KI und Mobilit&#228;t&#8220; in Kapitel C. VI. [K&#252;nstliche Intelligenz und Mobilit&#228;t
(Projektgruppe 5)], in dem Empfehlungssysteme umfassend diskutiert werden.
Die Projektgruppe empfiehlt au&#223;erdem, einen regelm&#228;&#223;igen Dialog zwischen der Politik und den
Normungsinstanzen von KI einzurichten, insbesondere auch zu Fragen der Ethik. Dies gilt &#252;ber alle Anwendungsbereiche
hinweg, darunter Industrie, Mobilit&#228;t, Gesundheit, Arbeitswelt, Medien, Staat etc. Sinnvoll erscheint auch,
Ressourcen in die Pr&#252;fung und Zertifizierung von KI-Systemen auf Basis von Normen zu investieren &#8211; sowohl f&#252;r
die Erforschung von Pr&#252;fmethoden als auch f&#252;r den Aufbau von Pr&#252;finfrastruktur.
Zur Wahrung von Einflussm&#246;glichkeiten von Arbeitnehmerinnen und Arbeitnehmern beim Schutz ihrer
Pers&#246;nlichkeitsrechte, der Vermeidung von &#220;berlastung, der Bew&#228;ltigung von betrieblicher Transformation und der
Gestaltung von Besch&#228;ftigungsbedingungen ist ein Update der Mitbestimmung erforderlich, das der technischen
Entwicklung Rechnung tr&#228;gt und die bisherige Balance zwischen Arbeitnehmerrechten und Eigentumsrechten
fortentwickelt.799 
Die Projektgruppe bef&#252;rwortet die Bestrebungen, die in Deutschland und Europa vorhandenen dezentralen KI-
Ressourcen auf einer Plattform unter neutraler, nicht-kommerzieller Federf&#252;hrung und mit politischer
Flankierung zusammenzuf&#252;hren. 
Die &#246;ffentliche Verwaltung sollte mit gutem Beispiel vorangehen und Erfahrungen wie Daten teilen. Prozesse
der &#246;ffentlichen Verwaltung k&#246;nnen Vorreiter sein, z. B. mit einem durchg&#228;ngigen, unternehmensbezogenen 
&#8222;Identifier&#8220; (Kennung) f&#252;r das Handelsregister, die Gewerbeanmeldung oder die Steuernummer. 
Die Projektgruppe empfiehlt eine zentrale B&#252;ndelung der KI-Kompetenzen in der Bundesregierung, um bei
Querschnittsaufgaben die Weisungsbefugnis &#252;ber Ministerien zu verbessern.
Die 3 Milliarden Euro, die gem&#228;&#223; KI-Strategie der Bundesregierung bereitgestellt werden, sollten vorrangig so 
eingesetzt werden, dass sie zahlreiche private Investitionen nach sich ziehen.800 
KI-Forschung
Um die praktische Relevanz der Forschung zu KI zu f&#246;rdern, sollte gezielt in anwendungsorientierte KI-
Technologien investiert werden, also in das L&#246;sen realer Probleme durch Forschung an echten Daten. Hierf&#252;r sollten
Unternehmen ermutigt werden, fr&#252;hzeitig mit dem Sammeln von Daten zu beginnen. Damit dieser
interdisziplin&#228;re Prozess gelingt, sollte zum einen der Wissensaustausch erleichtert (z. B. steuerlich) und zum anderen auch
Zusammenarbeit zwischen Forschung, Wirtschaft und &#246;ffentlicher Verwaltung gef&#246;rdert werden (z. B. durch 
Stipendien, Praktika und Patenschaften). Das kann durch Anreize und einen entsprechenden rechtlichen Rahmen 
geregelt werden. 801 
Bei Hochschulen sollte der Aufwand f&#252;r die Rechteverwertung reduziert werden, damit interdisziplin&#228;re
Kooperationen und der daraus entstehende Forschungstransfer nicht im Keim ersticken. Die Projektgruppe regt einen
deutschlandweiten Standardvertrag an, der z. B. im Rahmen von &#246;ffentlichen Auftr&#228;gen und Projekten zu
verwenden ist, damit Forschungsinstitute und Hochschulen bei der Rechte- und Patentverwertung unterst&#252;tzt
werden. Dabei sollte ber&#252;cksichtigt werden, dass zu starre Regelungen an den Universit&#228;ten und den
Forschungsinstituten den Forschungstransfer und die Innovation verlangsamen und sogar blockieren k&#246;nnen. Eine M&#246;glichkeit
der Unterst&#252;tzung ist die Sammlung von Best-Practice-Beispielen, aus denen Blaupausen f&#252;r erfolgreiche
Kooperationsmodelle abgeleitet werden k&#246;nnen, die insbesondere f&#252;r den Mittelstand attraktiv sind.
F&#252;r eine starke Substanz sind auch starke Forschungszentren notwendig. Es gibt bereits gute Beispiele, die auf
der Internetseite der Plattform Lernende Systeme einsehbar sind.802 Dieser hohe Stand muss auch kulturell in die
restliche Forschungslandschaft eingebunden werden. Auch in Unternehmen ist ein kultureller Wandel notwendig,
799 Der Sachverst&#228;ndige Lothar Schr&#246;der weist f&#252;r die SPD-Fraktion darauf hin, dass die gesetzlichen Grundlagen der betrieblichen 
Mitbestimmung und der Unternehmensmitbestimmung in Deutschland vor mehr als sechs Jahrzehnten gelegt wurden. Der Einsatz 
von KI-Systemen wird nach ersten Erkenntnissen Erscheinungsformen der Digitalisierung verst&#228;rken, die nach ad&#228;quaten
M&#246;glichkeiten f&#252;r Mitbestimmungsakteure verlangen, damit diese die Chancen von KI-Systemen erschlie&#223;en, indem sie die Risiken
bearbeiten k&#246;nnen. Die Instrumente der kollektiven Selbstorganisation durch Mitbestimmung und der Tarifautonomie sollten in die Lage
versetzt werden, Ver&#228;nderungen Rechnung zu tragen, die sich aus der technischen Entwicklung ergeben. Denn der Gesetzgeber kann
sich nicht jeder betrieblichen Auspr&#228;gung des KI-Einsatzes annehmen. Siehe hierzu die Ausf&#252;hrungen zum Thema Mitbestimmung
im Bericht der Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220; in Kapitel C. V. [K&#252;nstliche Intelligenz und Arbeit
(Projektgruppe 4)]. 
800 Im Konjunkturprogramm im Rahmen der Corona-Pandemie wurde diese Summe auf 5 Milliarden Euro bis 2025 erh&#246;ht; weitere
Informationen dazu unter: https://www.bundesfinanzministerium.de/Content/DE/Standardartikel/Themen/Schlaglichter/Konjunktur-
paket/2020-06-03-konjunkturpaket-beschlossen.html (zuletzt abgerufen am 14. August 2020).
801 Siehe hierzu auch Kapitel 9 des Mantelberichts [KI und Forschung].
802 Weitere Informationen dazu unter: https://www.plattform-lernende-systeme.de/ki-landkarte.html?FIT=1 (zuletzt abgerufen am
3. August 2020).
um neue Technologien ernst zu nehmen. Hierzu w&#228;re es w&#252;nschenswert, eine Systematik f&#252;r die angewandten
KI-Technologien in der Forschung zu entwickeln, die die L&#246;sungen f&#252;r die Industrie besser planbar machen,
etwa durch Benchmarks und Standardisierung.
Die Projektgruppe empfiehlt, ein F&#246;rderprogramm einzurichten, das sich prim&#228;r auf die Entwicklung von KI-
basierten Anwendungen auf Basis vorhandener Grundlagen fokussiert, um ein besseres Verh&#228;ltnis der Forschung 
zu Grundlagen und zu praxisorientierter Anwendungen zu schaffen. Die Einrichtung von Transferlabs und
Graduiertenkollegs zur Ausbildung von Doktorandinnen und Doktoranden in enger Kooperation mit
Wirtschaftspartnern sind hierzu ein wirksames Mittel. In strukturierten Promotionsprogrammen arbeiten KI-
Doktorandinnen und -Doktoranden mit realen Daten, die Wirtschaftspartner zur Verf&#252;gung stellen. Im Gegensatz zu
herk&#246;mmlichen Kooperationen zwischen Industrie und Forschung sind diese Programme auf l&#228;ngere Zeit angelegt
(z. B. 3 + 1 Jahr) und erlauben es der Forschung, zu grundlegenden Fragestellungen zu arbeiten, wobei sie
konkrete Anwendungsperspektiven ber&#252;cksichtigen kann. In der praktischen Ausrichtung der Forschung sind vor
allem ein holistischer Blick auf die Herausforderungen im jeweiligen Feld sowie die F&#228;higkeit zur
interdisziplin&#228;ren Zusammenarbeit gefragt. Entsprechend sollten diese F&#228;higkeiten sowohl bei den wissenschaftlichen
Ausbildungswegen als auch in der Forschungsf&#246;rderung betont werden. Zudem sollte die wirtschafts-, sozial-, und 
gesellschaftswissenschaftliche Begleitforschung gef&#246;rdert werden, um die gesellschaftliche Einbettung zu
gew&#228;hrleisten und m&#246;gliche Effekte des KI-Einsatzes zu untersuchen.
Gleichzeitig w&#228;re eine engere Zusammenarbeit von Verwaltung und Wirtschaft w&#252;nschenswert, damit der Staat
selbst als gutes Beispiel die Digitalisierung vorantreibt, d. h. Daten bereitstellt, Best Practices f&#246;rdert usw.
Hierf&#252;r w&#228;re eine zentrale B&#252;ndelung der Kompetenzen im Bereich KI auf ministerialer Ebene w&#252;nschenswert. Es
w&#228;re gut, von staatlicher Seite daf&#252;r zu sorgen, dass die f&#252;r die Kooperation notwendigen Vereinbarungen
(Patente, Verwertung, etc.) m&#246;glichst so weit vereinheitlicht werden (&#8222;Baukastensystem&#8220;), dass Forschung und
Industrie hier agil agieren k&#246;nnen. 
Auch sollte Deutschland attraktiver f&#252;r Fachkr&#228;fte aus dem Ausland werden, da Expertinnen und Experten in
diesem Bereich auch mittelfristig noch Mangelware sein werden und die Besetzung von Stellen schwierig bleiben 
wird. Hierzu geh&#246;ren auch Faktoren wie beispielsweise die Einf&#252;hrung von multilingualen Chatbots, die die
Formularverarbeitung erleichtern und damit internationalen Fachkr&#228;ften (bzw. Gr&#252;nderinnen und Gr&#252;ndern) den
Wechsel nach oder die Kooperation mit Deutschland erm&#246;glichen. Ferner sollten F&#246;rdergelder (an
Hochschulen/Forschungszentren und in der Industrie) auch dazu eingesetzt werden k&#246;nnen, Expertinnen und Experten zu
gewinnen und angemessen zu finanzieren. 
Von besonderer Bedeutung f&#252;r die Nutzung des Innovations-Potenzials von KI ist die digitale Transformation
der Wissenschaft selbst. Dazu m&#252;ssen wir die seit Jahrzehnten auf PDF-Artikeln basierenden Informationsfl&#252;sse
in den Wissenschaften in einen st&#228;rker daten- und wissensbasierten Informationsaustausch transformieren. Die
Transformation wissenschaftlicher Informationsfl&#252;sse sollte unter starker Beteiligung wissenschaftlicher
Bibliotheken und durch ein F&#246;rderprogramm &#228;hnlich der Nationalen Forschungsdateninfrastruktur (NFDI)
vorangetrieben werden.
III. K&#252;nstliche Intelligenz und Staat (Projektgruppe 2)803 
Allgemeiner Teil
1 Kurzfassung des Projektgruppenberichts804 
Die Projektgruppe &#8222;KI und Staat&#8220; hat sich mit staatlichem Einsatz von KI, vor allem im Hinblick auf Verwaltung,
Smart City und Open Data, Innere Sicherheit, &#196;u&#223;ere Sicherheit und IT-Sicherheit befasst.
Aufgrund der breiten Anwendungsbereiche und der hohen Bedeutung einer ausf&#252;hrlichen Debatte und
vielseitigen Betrachtung von KI durch den Staat hat sich die Projektgruppe in drei Arbeitsgruppen (AGs) gegliedert. Die
803 Zu diesem Kapitel liegen Sondervoten aus der Fraktion der SPD [Sondervotum zu Kapitel C. III. &#8222;K&#252;nstliche Intelligenz und Staat
(Projektgruppe 2)&#8220; der Abgeordneten Daniela Kolbe, Elvan Korkmaz-Emre, Falko Mohrs, Ren&#233; R&#246;spel und Jessica Tatti sowie der
sachverst&#228;ndigen Mitglieder Prof. Dr.-Ing. Sami Haddadin, Jan Kuhlen, Lena-Sophie M&#252;ller und Lothar Schr&#246;der] sowie aus der 
Fraktion DIE LINKE. [Sondervotum zu Kapitel C. III. &#8222;K&#252;nstliche Intelligenz und Staat (Projektgruppe 2) &#8220; der Abgeordneten
Dr. Petra Sitte und Jessica Tatti] vor.
804 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion der CDU/CSU vor [Sondervotum zu Kapitel 1 des Berichts der
Projektgruppe 2 &#8222;KI und Staat&#8220; (&#8222;Kurzfassung des Projektgruppenberichts &#8220;) der Abgeordneten Ronja Kemmer und der Abgeordneten Marc 
Biadacz, Hansj&#246;rg Durz, Jan Metzler, Stefan Sauer, Prof. Dr. Claudia Schmidtke, Andreas Steier und Nadine Sch&#246;n sowie der
sachverst&#228;ndigen Mitglieder Susanne Dehmel, Prof. Dr. Wolfgang Ecker, Prof. Dr. Antonio Kr&#252;ger, Prof. Dr. J&#246;rg M&#252;ller-Lietzkow und
Dr. Sebastian Wieczorek].
AGs haben gemeinsam unterschiedliche Themenbl&#246;cke bearbeitet, die jeweils den staatlichen Einsatz von KI
betreffen:
&#8226; AG 1: KI in der &#246;ffentlichen Verwaltung, gemeinwohlorientierte Anwendungen, Teilhabe
&#8226; AG 2: Smart City und Open Data
&#8226; AG 3: Innere Sicherheit, &#196;u&#223;ere Sicherheit/Verteidigung/Milit&#228;r, IT-Sicherheit
W&#228;hrend der Bearbeitung und Debatte der drei Themenbl&#246;cke hat die Projektgruppe festgestellt, dass es f&#252;r alle
drei Bereiche stets wiederkehrende Empfehlungen gibt, wie der Staat KI-Systeme planen, einsetzen und
evaluieren sollte. Diese Empfehlungen ber&#252;cksichtigen, dass der Staat insbesondere bei der Nutzung von
teilhaberelevanten KI-Systemen aufgrund seiner hoheitlichen Aufgaben einer besonderen Sorgfaltspflicht unterliegt, wenn
die Entscheidung f&#252;r den Einsatz von KI-Systemen getroffen wird und Anforderungen an Transparenz- und 
Nachvollziehbarkeit erf&#252;llt sein m&#252;ssen. Damit wird ein informierter Umgang erm&#246;glicht, es k&#246;nnen
Anpassungen vor dem Hintergrund gesellschaftlicher Werte und Normen vorgenommen werden und es kann eine
Wahlfreiheit f&#252;r B&#252;rgerinnen und B&#252;rger entstehen. Das gilt insbesondere dann, wenn ein KI-System in der
entscheidungsvorbereitenden oder der Entscheidungsphase angewendet wird.
Als Ergebnis enth&#228;lt dieser Bericht einen umfassenden Katalog an themen&#252;bergreifenden
Handlungsempfehlungen und dar&#252;ber hinaus einzelne AG-spezifische Handlungsempfehlungen.
Zu den wichtigsten Handlungsempfehlungen f&#252;r alle AGs geh&#246;ren:
Systematische Identifizierung von Einsatzgebieten f&#252;r KI
Beh&#246;rden sollten den Einsatz von KI-Systemen f&#252;r Verwaltungsvorg&#228;nge bzw. Prozesse systematisch pr&#252;fen. In
den Ministerien des Bundes sollten ein Monitoring und ein strukturierter Erfahrungsaustausch unter den
Beh&#246;rden stattfinden, die KI einsetzen.
Kompetenzen aufbauen
Ziel sollte es sein, m&#246;glichst vielen Mitarbeiterinnen und Mitarbeitern in der Verwaltung ein Verst&#228;ndnis f&#252;r die
Funktionsweisen, Vorteile und Herausforderungen von KI-Systemen und f&#252;r m&#246;gliche Risiken in Bezug auf
unerw&#252;nschte Diskriminierung aufzuzeigen. Bereits die Ausbildung und das Studium im Bereich der Verwaltung 
m&#252;ssen ein breites Wissen zu Digitalisierung und KI- Systemen vermitteln.
Transparenz schaffen und Risiken systematisch klassifizieren
F&#252;r staatlich genutzte KI-Systeme, die auf einem durch Methoden des Maschinellen Lernens gelernten
statistischen Modell basieren, ist immer eine Risikoklassifikation durchzuf&#252;hren. Basierend auf der Risikoklassifikation 
sind die entsprechenden Transparenz- und Nachvollziehbarkeitsforderungen zu bestimmen.
KI-gest&#252;tzte Entscheidungen regelm&#228;&#223;ig auf Diskriminierungsfreiheit &#252;berpr&#252;fen
Es muss sichergestellt werden, dass staatlich entwickelte und genutzte KI-Systeme in ihrer Nutzung (unter
Umst&#228;nden also im Zusammenwirken mit menschlichen Entscheiderinnen und Entscheidern) nicht diskriminierend 
wirken.  
Partizipation f&#246;rdern
Beh&#246;rden sollten beim Einsatz von KI-Systemen durch die Verwaltung einen partizipativen, b&#252;rgernahen Ansatz
verfolgen. Die Gesellschaft sollte jedenfalls immer dann einbezogen werden, wenn der einzelne Mensch in seinen
Grundrechten ber&#252;hrt werden k&#246;nnte. Dar&#252;ber hinaus ist es notwendig, die Bev&#246;lkerung breit und umf&#228;nglicher
zu KI aufzukl&#228;ren, damit die Menschen verstehen und erkennen k&#246;nnen, welche Vor- und Nachteile spezifische 
Anwendungen haben.
AG 1: KI in der Verwaltung und internationale Vorbilder
Die AG 1 befasste sich schwerpunktm&#228;&#223;ig mit Fragen der Beschaffung und des Einsatzes von KI-Systemen und 
algorithmischen Entscheidungssystemen (ADM-Systeme805) im administrativen Bereich. Welche Vorbilder und
805 ADM: Abk&#252;rzung f&#252;r algorithmic decision making.
Potenziale gibt es f&#252;r die Verwendung von KI in der &#246;ffentlichen Verwaltung und bei der Erbringung &#246;ffentlicher
Dienstleistungen? Wie k&#246;nnen Widerspruchs-, Antrags- und Formularverfahren mithilfe von KI automatisiert
werden? Welche gemeinwohlorientierten Anwendungen lassen sich auf der Grundlage von KI durch den Staat
oder mittels staatlicher F&#246;rderung (Fonds f&#252;r soziale Innovationen &#8211; Social-Innovation-Fonds806, smarte
Antragsstellung und -bearbeitung) entwickeln? Des Weiteren untersuchte die AG, wie eine bessere Partizipation und
Teilhabe von B&#252;rgerinnen und B&#252;rgern durch und mit KI gelingen kann und wie die B&#252;rgerinnen und B&#252;rger
sich in den Einsatzprozess von KI einbringen k&#246;nnen. Dabei wurde auch in den Blick genommen, welche
Anwendungen und Projekte es hierzulande bereits gibt, welche internationalen Anwendungen und Konzepte bei der
Digitalisierung der Verwaltung als Vorbild dienen k&#246;nnen und wie Deutschland gezielt von diesen Vorbildern
lernen kann.
Die AG konzentrierte sich bei ihrer Untersuchung vor allem auf die Potenziale, die der Einsatz von KI f&#252;r
Verwaltung und Gesellschaft bietet, leitete daraus Empfehlungen f&#252;r den Umgang mit der Technologie ab und
definierte Leitlinien f&#252;r den Einsatz von KI-Systemen in der Verwaltung.
Einigkeit bestand in der Projektgruppe dar&#252;ber, dass KI-Anwendungen in der &#246;ffentlichen Verwaltung stets am
Menschen orientiert sein und auf Verwaltungsprinzipien basieren m&#252;ssen. F&#252;r B&#252;rgerinnen und B&#252;rger muss
transparent und nachvollziehbar sein, bei welchen Verwaltungsvorg&#228;ngen KI-Systeme eingesetzt werden,
insbesondere dann, wenn KI-Systeme in der entscheidungsvorbereitenden oder der Entscheidungsphase
angewendet werden. Lernende k&#252;nstliche Systeme d&#252;rfen jedoch keine Ermessens- oder Beurteilungsspielr&#228;ume
f&#252;llen. Die Unabh&#228;ngigkeit von Drittanbieter-Plattformen ist anzustreben.
Es wurde festgestellt, dass Digitalisierung und Automatisierung in der &#246;ffentlichen Verwaltung Vorteile f&#252;r
B&#252;rgerinnen und B&#252;rger, Zivilgesellschaft, Organisationen und Unternehmen ebenso wie f&#252;r die Besch&#228;ftigten in
der Verwaltung haben. So k&#246;nnen Assistenzsysteme dabei eine deutliche Steigerung von Qualit&#228;t und Effizienz
von Verwaltungsvorg&#228;ngen bewirken und die Daseinsvorsorge st&#228;rken. Sie k&#246;nnen Anfrageprozesse und
Bearbeitungsvorg&#228;nge transparenter und schneller machen, Verwaltungsentscheidungen unterst&#252;tzen und eine h&#246;here
B&#252;rgerzufriedenheit erm&#246;glichen. Durch die Entlastung der Mitarbeiterinnen und Mitarbeiter von monotonen
Aufgaben und hin zu mehr individueller und pers&#246;nlicher Beratung kann sich der Aufgabenbereich verschieben.
Ein weiterer gesellschaftlicher Vorteil des Einsatzes von KI in der Verwaltung kann eine Kostenersparnis sein.
Es werden Qualit&#228;tskriterien ben&#246;tigt, nach denen eine kontinuierliche Evaluation von KI-Systemen m&#246;glich ist
und nach denen &#252;ber den staatlichen Einsatz von KI-Systemen entschieden wird. Es bestand Dissens dar&#252;ber, ob
KI-Systeme der h&#246;chsten Risikoklasse807 eingesetzt werden d&#252;rfen. 
Auch f&#252;r die Verwaltung gilt, dass es bei den Anforderungen an die Transparenz und Nachvollziehbarkeit von 
KI-Systemen ebenso wie bei der Vermeidung von Diskriminierung in erheblichem Ma&#223;e auf die Qualit&#228;t und die
Integrit&#228;t der eingesetzten Daten und ihrer Struktur ankommt. M&#246;glichst vollst&#228;ndige und durchgehende Open-
Data-Best&#228;nde sind daf&#252;r eine Voraussetzung. Durch eine einheitliche Open-Data-Plattform werden sowohl
personelle Ressourcen effizienter eingesetzt als auch leistungsf&#228;higere KI-basierte Algorithmen und Analysen
erm&#246;glicht.
Der Staat kann dar&#252;ber hinaus als innovativer Treiber f&#252;r die Entwicklung gemeinwohlorientierter KI-Systeme
agieren. Die Einrichtung eines Social-Innovation-Fonds hat auch f&#252;r den Bereich der Verwaltung das Potenzial,
die Entwicklung gemeinwohlorientierter L&#246;sungen zu erm&#246;glichen.
Die Projektgruppe ist der Ansicht, dass die Zivilgesellschaft von mehr Transparenz des Verwaltungshandelns,
vereinfachter Partizipation und auch von einer h&#246;heren Teilhabe durch einen barrierefreieren und schnelleren
Zugang zu Informationen, Angeboten und Leistungen der &#246;ffentlichen Verwaltung profitieren kann, und
empfiehlt weitere Pilotprojekte von KI in der Verwaltung. 
Die Projektgruppe empfiehlt im Besonderen, dass KI-Systeme in der Verwaltung f&#252;r teilhaberelevante KI-
Anwendungen genutzt werden. Im Mittelpunkt sollen dabei vor allem sprachlich barrierefreie Angebote stehen, die
Verringerung von Zugangsh&#252;rden, die Beschleunigung von Verwaltungsprozessen sowie die Entlastung von
Verwaltungsmitarbeiterinnen und -mitarbeitern.
806 Mit Social Innovation sind solche Konzepte und Innovationen gemeint, die gezielt auf das L&#246;sen sozialer Probleme und Handeln im
Sinne des Gemeinwohls setzen.
807 Siehe auch Kapitel 4.4. des Mantelberichts [KI-spezifisches Risikomanagement].
Weiterhin empfiehlt die Projektgruppe einen Rechtsanspruch auf Widerspruch gegen KI-Empfehlungen in
Verwaltungsprozessen, sodass B&#252;rgerinnen und B&#252;rger im Zweifel Anspruch auf Bearbeitung durch einen Menschen
geltend machen k&#246;nnen. 
Eine weitere Betrachtung der gesetzlichen Grundlagen ergab, dass ein Screening zu m&#246;glichen Anpassungen von
Rechtsnormen oder Pr&#252;fungen sinnvoll sind.
AG 2: Smart City und Open Data
Der vorliegende Teilbericht besch&#228;ftigt sich mit zwei eng zusammenh&#228;ngenden Themenfeldern, die zun&#228;chst
unabh&#228;ngig voneinander betrachtet werden. Zum einen werden (kontextspezifisch) Ausf&#252;hrungen zum Thema
Open Data gemacht. Zum anderen wird das Thema Smart Cities eingef&#252;hrt. In diesem Teilabschnitt geht es um
einen konzeptionellen Ansatz (Open Data) sowie einen konkreten, &#228;u&#223;erst komplexen Anwendungsfall (Smart
City), die beide im Kern insofern verbunden sind, als dass Smart Cities als eine sehr zentrale Quelle f&#252;r Open
Data gesehen werden m&#252;ssen und andererseits wiederum davon nachhaltig profitieren.
Unter dem Open-Data-Ansatz wird verstanden, dass grunds&#228;tzlich nicht-personenbezogene Daten &#246;ffentlich, frei
verf&#252;gbar und ohne jegliche Nutzungseinschr&#228;nkung bereitgestellt werden. Im spezifischen Kontext smarter
Metropolregionen, St&#228;dte und l&#228;ndlicher Gebiete geht es dabei prim&#228;r um Government-Daten (z. B.
Verwaltungsdaten), also Daten aus den Kontexten der staatlichen Hoheit sowie vom Staat gemessene, freie Daten (z. B.
Wetterdaten).
Bei &#8222;Smart City&#8220; handelt es sich &#8211; ebenso wie bei KI &#8211; um eine Art Oberbegriff. Vor allem sind damit
Lebensr&#228;ume der Menschen gemeint (Stadt, Gemeinde, l&#228;ndliches Leben), die im Kontext der Digitalisierung ganz
anders oder neu gestaltet werden. Entgegen dieser weit umfassenden Beschreibung sind Smart Cities im engeren
Sinne St&#228;dte oder Metropolregionen (z. B. Berlin oder Hamburg), die als konzentriert urbane Lebensr&#228;ume das
Handlungsfeld f&#252;r Digitalisierung darstellen. 
Die Verbindung von Open Data, Smart Cities und KI liegt darin, dass gerade der st&#228;dtische Raum als
Aggregationsraum f&#252;r Daten (Internet of Things, E-Government, Mobility, Smart Living etc.), dienen kann, diese
insbesondere im Rahmen des Trainings von KI-Systemen eingesetzt werden k&#246;nnen und somit neue Anwendungen
entstehen bzw. Anwendungsfelder der KI im urbanen Lebensraum erschlossen werden. Hieraus k&#246;nnen eine
h&#246;here Sicherheit, bessere Resilienz, &#246;kologisch nachhaltigere Lebensr&#228;ume sowie &#246;konomisch neuartige
Konzepte entstehen, inklusive junger Unternehmen und Start-ups.808 Wesentlicher erscheint noch, dass diese
Anwendungen dazu beitragen, dass die Lebensqualit&#228;t und die Partizipationsm&#246;glichkeiten f&#252;r die Gemeinschaft
deutlich gesteigert werden k&#246;nnen.
Wichtige Voraussetzungen f&#252;r ein Absch&#246;pfen dieser Potenziale sind:
&#8226; Schaffung eines operativ umsetzbaren Rechtsrahmens f&#252;r KI-Anwendungen in der Stadt als legitimes
System zur Unterst&#252;tzung bei Entscheidungen (insbesondere Harmonisierung der Rechtsebenen). Dieser
Rechtsrahmen muss dabei sowohl hinsichtlich der Nutzungsoptionen der Daten als auch der Einsatzfelder
der KI Rechtssicherheit bieten, da sonst abgeleitete Systeme keine hinreichende Planungsbasis erhalten.
Dar&#252;ber hinaus muss der Rechtsrahmen auch klar regeln, welche Kompetenzen hier Bundesrecht,
Landesrecht oder ggf. auch regionale Rechtsfelder809 betreffen;
&#8226; Sicherstellung der rechtm&#228;&#223;igen Bereitstellung von anonymisierten Daten, die (lizenzfrei) in einem
maschinenlesbaren Format (hohe Datenqualit&#228;t) zur Verf&#252;gung gestellt werden. Au&#223;erdem ist das Open-
Data-Gesetz auszuweiten. Hierbei ist zu &#252;berlegen, ob neben der Bereitstellung von Open Data auch
geeignete Auswertungsinstrumente als Open Source mit bereitgestellt werden m&#252;ssten bzw. sollten;
&#8226; hohe Priorit&#228;t f&#252;r die Qualit&#228;ts&#252;berpr&#252;fung der Daten hinsichtlich Konsistenz, Integrit&#228;t und m&#246;glicher
Verzerrungen. Dabei bedarf es qualifizierter Vertrauenszentren bzw. Personen. Auf der operativen Ebene
w&#228;re zu &#252;berlegen, ob an die st&#228;dtischen Rechenzentren &#246;ffentliche Datenzentren verpflichtend
angeschlossen werden sollten;
808 Gerade aus &#246;konomischer Sicht scheinen dabei Verbindungen zur Mobilit&#228;t, zur Umwelt&#246;konomie etc. sinnvoll. Etwas verk&#252;rzt
formuliert greifen hier Kreislaufwirtschaft und Digitalisierung mit dem Schwerpunkt Open Data und KI ineinander.
809 So kann beispielsweise die Messung von Hafendaten in K&#252;stenst&#228;dten sowie ihre Bereitstellung als Open Data grunds&#228;tzlich zwar
sogar internationales Recht ber&#252;hren, im Regelfall wird dies aber nur den spezifischen Rechts- und Interessenkreis einzelner St&#228;dte
betreffen, sodass keine generelle bundesrechtliche Regelung vonn&#246;ten ist.
&#8226; Sicherstellung der Kontinuit&#228;t der Speicherung, Verf&#252;gbarkeit und regelm&#228;&#223;igen Erhebung der
Daten auf Basis einer funktionsf&#228;higen robusten digitalen Infrastruktur sowie Weiterentwicklung der
notwendigen Portale und Datenbanken;
&#8226; F&#246;rderung und finanzielle Unterst&#252;tzung von Pilotvorhaben f&#252;r neuartige KI-basierte Anwendungen
im Smart-City-Kontext, die die Besonderheiten deutscher St&#228;dte und Regionen hinsichtlich deren
Rahmenparameter, wie Gr&#246;&#223;e, Fl&#228;che, Lage, Wirtschaftskraft etc., ber&#252;cksichtigen.810 
Als generelle Zielstellung der Open-Data- sowie Smart-City-Strategie im Zusammenhang mit dem leitenden
Thema KI muss dabei gelten, dass der Einsatz von Open Data dazu beitr&#228;gt, dass die Lebensqualit&#228;t durch den
Einsatz von KI-Systemen, die mithilfe dieser Daten trainiert wurden, mittel- und langfristig in den umbauten
Lebensr&#228;umen, vor allem den St&#228;dten, nachhaltig ansteigt. 
Smart Cities sind insofern zumeist noch keine Einzelsysteme, die hier im Mittelpunkt gegenw&#228;rtiger oder
zuk&#252;nftiger KI-Systeme stehen, sondern vielmehr ist es das breite Anwendungsspektrum verschiedenster
Systeme.811 
Der Nutzwert f&#252;r die Menschen in den Smart Cities ist, je nach strategischer Ausrichtung der jeweiligen
Kommunen, vor allem dann gegeben, wenn sich die Lebensqualit&#228;t erh&#246;ht und dabei die Freiheitsrechte gewahrt
werden. Dabei wird unter Erh&#246;hung der Lebensqualit&#228;t nicht nur die individuelle Lebensqualit&#228;t verstanden (bessere
Mobilit&#228;t, angenehmeres Leben im Alter etc.), sondern auch die kollektive Lebensqualit&#228;t (saubere Umwelt,
bessere Luft, weniger Verschmutzung). KI-Systeme k&#246;nnen dabei im Rahmen von Smart-City-Konzepten vor allem
dazu beitragen, insgesamt die Steuerung des sozio-technischen komplexen Systems eines urbanen Lebensraums
zu verbessern.
Schwierig ist die Bewertung wirtschaftlicher Rahmendaten, wie z. B. gesch&#228;tzte Energieeinsparungen in der
Smart City durch intelligente Verteilungssysteme, oder auch, ob z. B. Umwelteffekte durch die Systeme oder ein
ge&#228;ndertes Nutzungsverhalten eintreten bzw. eingetreten sind. Im ersten Fall gilt, dass nat&#252;rlich zu erwarten ist,
dass intelligente Verteilungssysteme eine entsprechend effizientere Energienutzung erm&#246;glichen. Allerdings sind
vielfach die in Studien publizierten Daten reine Sch&#228;tzwerte (eher grobe N&#228;herungswerte).812 
AG 3: Innere Sicherheit, &#196;u&#223;ere Sicherheit, IT-Sicherheit
Die AG 3 befasste sich mit der Bedeutung von KI im Sicherheitsbereich. Dabei wurden die drei Themenbereiche
Innere Sicherheit, &#196;u&#223;ere Sicherheit und IT-Sicherheit getrennt voneinander untersucht, um den spezifischen
Implikationen, die KI f&#252;r diese jeweils aufweist, angemessen Rechnung zu tragen. Vorangestellt werden kann,
dass sich insbesondere in den Bereichen der Inneren und &#196;u&#223;eren Sicherheit gro&#223;e Konfliktlinien innerhalb der
Projektgruppe abzeichneten. Zu einzelnen Aspekten der Inneren Sicherheit und zum Bereich der &#196;u&#223;eren
Sicherheit wurden u. a. von den Fraktionen AfD und DIE LINKE. Sondervoten verfasst, in denen die Fraktionen
ihre Positionen zu diesen Bereichen ausf&#252;hrlich darlegen. Die Sondervoten sind in Kapitel D [Sondervoten zum
Gesamtbericht] dieses Berichts zu finden.
Themenbereich Innere Sicherheit
Die Projektgruppe ist sich einig, dass KI-Systeme auch im Bereich der Inneren Sicherheit Chancen und Risiken
f&#252;r B&#252;rgerinnen und B&#252;rger bieten. Die Chancen sollten f&#252;r Staat und Gesellschaft unter Rechtskonformit&#228;t
nutzbar gemacht werden. Bei allen Ma&#223;nahmen und so auch beim Einsatz von KI-Systemen im Bereich der Inneren
Sicherheit muss eine Abw&#228;gung zwischen dem Recht auf Sicherheit und der m&#246;glichen Einschr&#228;nkung von
B&#252;rger- und Grundrechten vorgenommen werden. Wie in der Verwaltung muss auch hier in besonderer Weise bei
810 Die bisherigen Konzepte und Forschungen in dem Zusammenhang beziehen sich sehr h&#228;ufig auf den asiatischen Raum, der
vollkommen andere Rahmenbedingungen hat und bietet. Selbst Fallbeispiele aus Europa, hier insbesondere das vielzitierte Beispiel Estland,
k&#246;nnen nur schlecht und selten vollumf&#228;nglich mit den Herausforderungen eines souver&#228;nen Staates, wie Deutschland in seinem
europ&#228;ischen Gesamtgef&#252;ge, verglichen werden.
811 Genau vor dem Hintergrund erscheint die F&#246;rderung eines breiten Open-Data-Ansatzes inklusive der Schaffung entsprechender
Infrastruktur ein wesentlicher Schl&#252;ssel, um die Potenziale einer Smart City als Erm&#246;glichungsstrategie zu erschlie&#223;en.
812 Vor dem Hintergrund wird eine Befassung mit der amtlichen Wirtschafts- und Sozialstatistik empfohlen. Die bisherigen Konzepte 
erscheinen aufgrund der gegenseitigen Abh&#228;ngigkeit der Einzelbereiche, die gemessen und erhoben werden, nicht schl&#252;ssig. Bei der
Weiterentwicklung des Open-Data-Gesetzes sollten &#214;ffnungsklauseln entwickelt werden, die z. B. neue Erhebungs-, Erfassungs- und 
Auswertungsmethoden erlauben sowie die Publikation von Daten auch in Form verarbeitbarer Rohdaten erm&#246;glichen.
den hoheitlichen Aufgaben des Staates darauf geachtet werden, dass in und durch die Ma&#223;nahmen keine
Diskriminierung entsteht. Die Systeme der Inneren Sicherheit m&#252;ssen dementsprechend auch besonderen
Anforderungen an Nachvollziehbarkeit und Transparenz entsprechen.
Bearbeitet und diskutiert wurden in der Projektgruppe verschiedene Projekte und der aktuelle Stand beim Einsatz
von KI-Systemen im Bereich der Inneren Sicherheit, einschlie&#223;lich der damit verbundenen Risiken und
Potenziale. Darunter finden sich Pilotprojekte in Deutschland, wie das Projekt zur Gesichtserkennung am Berliner
Bahnhof S&#252;dkreuz, EU-Projekte wie &#8222;Roborder&#8220; oder der Einsatz von Predictive Policing in Deutschland. 
Zu den wichtigsten Handlungsempfehlungen der Projektgruppe im Bereich der Inneren Sicherheit geh&#246;rt eine
breite gesellschaftliche Debatte zum Einsatz von KI-Systemen im Bereich der Inneren Sicherheit. Eine
Ausweitung von Investitionen in KI-Technologien, die einen Mehrwert und Fortschritt f&#252;r den Sicherheitsbereich
bedeuten, wird ebenfalls empfohlen. Dabei sollte jedoch jedes KI-System auch im Bereich der Inneren Sicherheit
m&#246;glichst nach einem Risikoklassenmodell einer Risikoklasse zugeordnet werden und folglich entsprechenden
den Anforderungen gen&#252;gen.
Themenbereich &#196;u&#223;ere Sicherheit
Auch im Bereich der &#196;u&#223;eren Sicherheit und Verteidigung sieht die Projektgruppe eine Vielzahl von KI-
Anwendungen, deren Einsatz positive Effekte bringen kann und die allgemein nicht umstritten sind. Bei dem kritischen 
Bereich der t&#246;dlichen autonomen Waffensysteme (Lethal Autonomous Weapon Systems &#8211; LAWS) erzielte die
Projektgruppe den Konsens, dass diese Waffen international ge&#228;chtet werden sollen. Uneinigkeit bestand
allerdings in der Frage, ob die Verhandlungen mit dem Ziel eines Verbots gef&#252;hrt werden sollten. Bislang fehlt eine
international allgemein anerkannte Definition von &#8222;autonomen Waffensystemen&#8220;, was die Befassung mit dem
Thema erschwerte.
Die Mehrheit der Projektgruppe einigte sich darauf, dass bei Regulierungsfragen die LAWS im Zentrum stehen
m&#252;ssen und dass die Bundesregierung sich auch in Zukunft auf internationaler Ebene r&#252;stungskontrollpolitisch 
f&#252;r eine &#196;chtung von t&#246;dlichen autonomen Waffensystemen einsetzen soll. Dabei soll ein Weg verfolgt werden,
mit dem eine m&#246;glichst gro&#223;e Gruppe von Staaten eingebunden werden kann, um einer &#196;chtung eine starke
Wirkung zu verschaffen. Eine ausschlie&#223;lich nationale Regulierung ist auch mit Blick auf zuk&#252;nftige,
gegenw&#228;rtig noch nicht absehbare sicherheitspolitische Bedrohungen f&#252;r die Mehrheit der Projektgruppe nicht zielf&#252;hrend.
Damit eine wirksame &#196;chtung gelingen kann, m&#252;ssen nach Meinung der Projektgruppe alle Anstrengungen
unternommen werden, um zu einer international anerkannten Definition und v&#246;lkerrechtlichen Einordnung von 
t&#246;dlichen autonomen Waffensystemen zu kommen. Die Konvention &#252;ber bestimmte konventionelle Waffen 
(Convention on Conventional Weapons &#8211; CCW) bleibt daf&#252;r auch in Zukunft das richtige Forum. 
Die Mehrheit der Projektgruppe sprach sich auch daf&#252;r aus, dass bei der sicherheitsrelevanten KI-Forschung eine
starke Kooperation im Rahmen der EU vorangetrieben werden soll, um die europ&#228;ische Position zu st&#228;rken und
die Technologief&#252;hrerschaft bei schnellen Innovationen nicht anderen Staaten, beispielsweise den USA oder
China, zu &#252;berlassen. Die Chancen, die f&#252;r KI im Bereich Sicherheit und Verteidigung entstehen, sollen immer
im Einklang mit v&#246;lkerrechtlichen und ethischen Ma&#223;st&#228;ben &#8211; umfassend betrachtet und wo sinnvoll &#8211; genutzt
werden.
Themenbereich IT-Sicherheit
Die Integrit&#228;t und Sicherheit digitaler Strukturen, Technologien und Produkte ist zunehmend Grundlage allen 
&#246;ffentlichen und gesellschaftlichen Lebens. Die IT-Sicherheit wird daher in immer mehr Bereichen auch zur
staatlichen Aufgabe und Verantwortung, f&#252;r deren Wahrnehmung u. a. auf L&#246;sungen aus dem Bereich lernender
KI-Systeme zur&#252;ckgegriffen werden kann. 
Die Projektgruppe kommt &#252;berein, dass auch bei lernenden k&#252;nstlichen Systemen die Herausforderung besteht,
Sicherheitsimplikationen der Technologie m&#246;glichst fr&#252;hzeitig zu ermitteln und Ma&#223;nahmen zur Erh&#246;hung der
Sicherheit des Maschinellen Lernens zu erh&#246;hen. Ein Spezifikum bei lernenden k&#252;nstlichen Systemen besteht
darin, dass zur Erkennung von unautorisierten Manipulationen Abweichungen von der manipulationsfreien
Funktionsweise des Systems festgestellt werden m&#252;ssen. Das setzt ein hohes Ma&#223; an Transparenz und
Nachvollziehbarkeit des Systems voraus &#8211; ein Kernproblem bei vielen Ans&#228;tzen der lernenden k&#252;nstlichen Systeme.
Angesichts der Verbreitung lernender k&#252;nstlicher Systeme ist es nach Ansicht der Projektgruppe umso wichtiger, sich 
fr&#252;hzeitig mit der Sicherheit derartiger Systeme bzgl. m&#246;glicher Angriffe von au&#223;en zu befassen und Strategien
zur Erh&#246;hung des Schutzniveaus dieser Systeme zu entwickeln. 
        
 
 
 
  
   
  
   
        
  
 
  
     
   
 
  
    
     
       
 
   
   
 
 
    
 
  
  
    
 
   
  
  
  
  
    
  
   
   
 
   
  
 
                                               
             
2
Um sich Fragen nach politischen Handlungsempfehlungen zur Erh&#246;hung der IT-Sicherheit von lernenden
k&#252;nstlichen Systemen ann&#228;hern zu k&#246;nnen, sind Mapping und Kategorisierung der Angriffsoberfl&#228;chen erste Schritte,
die die Projektgruppe empfiehlt. Ziel ist es hierbei, eine umfassende Analyse in der Art durchzuf&#252;hren, dass das
Resultat auf m&#246;glichst viele lernende k&#252;nstliche Systeme zutrifft. Angesichts der Vielfalt der Ans&#228;tze innerhalb
des lernenden k&#252;nstlichen Systems wird man wahrscheinlich weitere Ausdifferenzierungen nach
unterschiedlichen Modell-Klassen und technischen Ans&#228;tzen ben&#246;tigen. Eine solche erste &#220;bersicht erm&#246;glicht es, die
konkreten Angriffsvektoren f&#252;r lernende k&#252;nstliche Systeme zu abstrahieren und darauf aufbauend Empfehlungen
f&#252;r IT-Sicherheit und -Resilienz zu entwickeln.
Die Projektgruppe ist &#252;berzeugt, dass der gr&#246;&#223;te Teil der Anwendungsm&#246;glichkeiten beim Einsatz von KI-
Systemen durch den Staat zum Wohle des Menschen gestaltet werden kann, wenn die empfohlenen Voraussetzungen
erf&#252;llt sind. Gleichzeitig ist man sich einig, dass weiterhin intensive Forschung und auch eine breite Debatte zum
Einsatz von KI notwendig sind, um diesen Einsatz verantwortungsvoll und effizient zu begleiten.
Vorbemerkungen (AG-unabh&#228;ngig)
Im Einsetzungsbeschluss der Enquete-Kommission &#8222;K&#252;nstliche Intelligenz &#8211; Gesellschaftliche Verantwortung
und wirtschaftliche, soziale und &#246;kologische Potenziale&#8220; (Bundestagsdrucksache 19/2978) nimmt das Thema KI
und Staat eine wichtige Rolle ein. Die zuk&#252;nftigen Einsatzm&#246;glichkeiten von KI in Ministerien, Beh&#246;rden und
Verwaltungen haben einen tiefgreifenden Einfluss auf das t&#228;gliche Leben der Menschen und bedeuten f&#252;r den
Staat gro&#223;e Chancen, aber auch Herausforderungen. Aufgrund seiner Monopolstellung trifft den Staat hier eine 
besondere Verantwortung bei der differenzierten Abw&#228;gung des Einsatzes von KI. Von Bedeutung sind dabei
vor allem die Fragen, wie mit KI umgegangen werden soll und ob und in welcher Form nationale, aber auch
europ&#228;ische und internationale Regeln gebraucht werden, damit die Technik dem Menschen und dem
Gemeinwohl dient. 
Mit dem Einsetzungsbeschluss wird die Enquete-Kommission beauftragt, folgende Aspekte des
Themenkomplexes Staat, Gesellschaft und Demokratie zu bearbeiten:
&#8226; Chancen und Herausforderungen von KI f&#252;r den einzelnen Menschen, die Gesellschaft, den Staat, die
Wirtschaft und die Arbeitswelt
&#8226; Auswirkungen von KI auf einzelne Lebens- und Politikbereiche, wie beispielsweise auf die &#246;ffentliche
Verwaltung, Mobilit&#228;t, Gesundheit, Pflege, selbstbestimmtes Altern, Bildung, Verteidigung, Umwelt,
Klimaoder Verbraucherschutz
&#8226; Ans&#228;tze von KI, um wirtschaftlichen, sozialen und &#246;kologischen Fortschritt zu generieren
&#8226; Auswirkungen der KI auf demokratische Prozesse
&#8226; Auswirkungen auf Gleichstellung und Geschlechtergerechtigkeit
&#8226; Strategien f&#252;r einen m&#246;glichen Rechtsrahmen
Vor dem Hintergrund der Einrichtung weiterer Projektgruppen wurden einige auch den Staat betreffende KI-
Themen hier nicht im Detail betrachtet, da sie schwerpunktm&#228;&#223;ig in anderen Projektgruppen behandelt werden
sollten. Beispielsweise setzte sich die Projektgruppe &#8222;KI und Medien&#8220; eingehend mit den Auswirkungen von KI
auf demokratische Prozesse auseinander. Des Weiteren wurden &#252;bergreifende Themen wie Daten, Ethik, Recht
u. a. nochmals auf Ebene der Gesamt-Enquete behandelt.813 
Um das sehr umfangreiche Thema &#8222;KI und Staat&#8220; im Rahmen verh&#228;ltnism&#228;&#223;ig weniger Projektgruppensitzungen
angemessen zu erschlie&#223;en, legte die Projektgruppe den Fokus auf drei Themenkomplexe, die im Rahmen der
drei nachfolgend aufgef&#252;hrten AGs bearbeitet wurden. Zu den Themenbereichen s&#228;mtlicher AGs er&#246;rterten
sowohl Abgeordnete und Sachverst&#228;ndige der Enquete-Kommission als auch ausgesuchte externe Sachverst&#228;ndige
einzelne Gesichtspunkte in Vortr&#228;gen und anschlie&#223;enden Diskussionen mit der Projektgruppe. 
813 Siehe auch Kapitel 2 [KI und Daten], Kapitel 5 [KI und Recht] und Kapitel 6 [Ethische Perspektiven auf KI] des Mantelberichts.
Arbeitsgruppe 1:
KI in der Verwaltung, Gemeinwohlorientierung, Gerichtsbarkeit, Verbraucherschutz, Teilhabe, Qualit&#228;t
und Integrit&#228;t von Daten
Themen:
&#8226; Einsatz von KI-Systemen innerhalb der &#246;ffentlichen Verwaltung und bei der Erbringung &#246;ffentlicher
Dienstleistungen, z. B. E-Government bei G2G814 und G2C815 (ohne Innere Sicherheit und Verteidigung)
&#8226; Automatisierung von Widerspruchs-, Antrags- und Formularverfahren und Entwicklung
gemeinwohlorientierter Anwendungen durch den Staat oder mittels staatlicher F&#246;rderung (Social-Innovation-Fonds, smarte
Antragstellung und Bearbeitung)
&#8226; Partizipation und Teilhabe durch und mit KI, B&#252;rgerbeteiligung im Zusammenhang mit dem Einsatz von
KI durch den Staat
&#8226; Welche L&#228;nder und Konzepte k&#246;nnen bei der Digitalisierung der Verwaltung als Vorbild dienen? Wie kann
Deutschland gezielt von diesen Vorbildern lernen?
Impulsvortr&#228;ge von Mitgliedern der Enquete-Kommission:
&#8226; Vortrag von Anke Domscheit-Berg, MdB (DIE LINKE.): &#8222;Automatisierung von Widerspruchs-, Antrags-
und Formularverfahren&#8220;
&#8226; Vortrag von Saskia Esken, MdB (SPD): &#8222;Datenqualit&#228;t und -integrit&#228;t&#8220;
&#8226; Vortrag des sachverst&#228;ndigen Mitglieds Jan Kuhlen: &#8222;Partizipation und Teilhabe&#8220;
&#8226; Vortrag des sachverst&#228;ndigen Mitglieds Prof. Dr. Katharina Zweig: &#8222;Beschaffung von ADM-Systemen in
der &#246;ffentlichen Verwaltung&#8220; und &#8222;Erkennung und Verhinderung von Diskriminierung,
Algorithmentransparenz und -&#252;berpr&#252;fbarkeit bei staatlichen und nicht-staatlichen Anwendungen (Regulierungsbedarfe)&#8220;
&#8226; Vortrag des sachverst&#228;ndigen Mitglieds Dr. Sebastian Wieczorek: &#8222;Einsatz von KI innerhalb der
&#246;ffentlichen Verwaltung&#8220;
Impulsvortr&#228;ge von externen Anh&#246;rpersonen:
&#8226; Vortrag von Matthias Fl&#252;gge (Fraunhofer FOKUS): &#8222;Beh&#246;rden auf Autopilot? KI in der &#246;ffentlichen
Verwaltung&#8220;
&#8226; Vortrag von Dr. J&#246;rg Dr&#228;ger (Mitglied des Vorstands der Bertelsmann Stiftung): &#8222;Zivilgesellschaftliches
Engagement und KI&#8220;
Arbeitsgruppe 2:
Smart City, Smart Country, Daseinsvorsorge, Open Data, Zugang zu Daten
Themen:
&#8226; Bereitstellung von Open-Government-Data als Open-Access-Trainingsdaten f&#252;r KI-Anwendungen, Ausbau
einer Open-AI-Dateninfrastruktur, Regulierungsbedarf im Zusammenhang mit Daten. Einsatz von KI zur
Gew&#228;hrleistung gleichwertiger Lebensbedingungen in Stadt und Land mit Steuerungsm&#246;glichkeiten f&#252;r
Lebensbereiche. Welchen Nutzen bringen Smart City / Smart Region f&#252;r B&#252;rgerinnen und B&#252;rger?
&#8226; Voraussetzungen und Auswirkungen staatlicher Einflussnahmen zur Verwirklichung von Smart
City / Smart Country / Smart Region
&#8226; Zivilgesellschaftliches Engagement und KI
814 G2G bezeichnet die Interaktion und die Prozesse, die innerhalb des &#246;ffentlichen Sektors ablaufen. Dies schlie&#223;t die Interaktion
zwischen zwei Beh&#246;rden ebenso ein wie die Daten&#252;bermittlung innerhalb einer Verwaltung.
815 G2C bzw. C2G bezeichnet die Interaktion zwischen B&#252;rgerinnen und B&#252;rgern (C: Abk&#252;rzung f&#252;r Citizen bzw. B&#252;rgerinnen und 
B&#252;rger) und der &#246;ffentlichen Verwaltung (G: Abk&#252;rzung f&#252;r Government bzw. Verwaltung).
Impulsvortr&#228;ge:
&#8226; Vortrag des sachverst&#228;ndigen Mitglieds Prof. Dr. J&#246;rg M&#252;ller-Lietzkow zusammen mit der externen
Sachverst&#228;ndigen Christiane Boschin-Heinz (Leiterin der Stabsstelle &#8222;Digitalisierung&#8220; der Stadt Paderborn):
&#8222;Smart City / Smart Regions und Open Data unter besonderer Ber&#252;cksichtigung der Erfahrungen der Stadt
Paderborn&#8220;
Arbeitsgruppe 3:
KI in Innerer Sicherheit und Verteidigung, IT-Sicherheit
Themen:
&#8226; Potenziale und Risiken des Einsatzes von KI f&#252;r die Innere Sicherheit, Strafverfolgung, Gefahrenabwehr,
Verteidigung und milit&#228;rische Zwecke sowie damit zusammenh&#228;ngende Fragen des Exports,
Grundrechtsschranken beim Einsatz von KI f&#252;r diese Themenbereiche
&#8226; Nationale und internationale Regulierungsoptionen zur Minimierung von Risiken durch den staatlichen
Einsatz von KI im Bereich Sicherheit und Verteidigung; welche Rolle spielen supranationale und internationale
Organisationen wie die EU oder die UN?
&#8226; St&#228;rkung der Forschungskompetenzen f&#252;r KI im Bereich Cybersicherheit
&#8226; Gew&#228;hrleistung der IT-Sicherheit bei KI-Systemen, Feststellung von Manipulationen, einschlie&#223;lich
Regulierungsbedarf
&#8226; Potenziale von und Gef&#228;hrdungen durch KI f&#252;r IT-Sicherheit, u. a. im Hinblick auf verbesserten Schutz
kritischer Infrastrukturen
Impulsvortr&#228;ge von externen Sachverst&#228;ndigen:
&#8226; Vortrag von Andreas K&#246;nen (Bundesministerium des Innern, f&#252;r Bau und Heimat, BMI): &#8222;KI und innere
Sicherheit&#8220;
&#8226; Vortrag von Lorena Jaume-Palasi (The Ethical Tech Society): &#8222;KI als immaterielle Infrastruktur &#8211; Der
besondere Auftrag des Staates&#8220;
&#8226; Vortrag von Prof. Dr. Hans-J&#246;rg Kreowski (Forum InformatikerInnen f&#252;r Frieden und gesellschaftliche
Verantwortung e. V.): &#8222;KI, Milit&#228;rtechnik und Frieden&#8220;
&#8226; Vortrag von R&#252;diger Bohn (Ausw&#228;rtiges Amt): &#8222;KI, &#196;u&#223;ere Sicherheit und Verteidigung&#8220;
&#8226; Vortrag des sachverst&#228;ndigen Mitglieds Dr. Stefan Heumann und des externen Sachverst&#228;ndigen Dr. Sven 
Herpig (Stiftung Neue Verantwortung): &#8222;Gew&#228;hrleistung der IT-Sicherheit bei KI-Systemen, Feststellung
von Manipulationen, einschlie&#223;lich Regulierungsbedarf&#8220;
Ausgehend von diesen Inputvortr&#228;gen und den intensiven Diskussionen in der Projektgruppe haben Teams aus
Autorinnen und Autoren Textbausteine f&#252;r den vorliegenden Projektgruppenbericht verfasst. Darauf aufbauend
wurde dieser Bericht im Zuge einer intensiven Feedback- und Konsolidierungsphase unter Einbeziehung der
gesamten Projektgruppe verfasst, um einen m&#246;glichst breiten Konsens unter den Mitgliedern herzustellen. Ein
Konsens konnte jedoch nicht in allen Bereichen erzielt werden.
Handlungsempfehlungen
Auswirkungen von KI-Empfehlungen auf die Entscheidungsautonomie untersuchen
Es ist ungekl&#228;rt, welchen Einfluss die Empfehlungen von KI-Systemen auf die abschlie&#223;ende Entscheidung des
Menschen haben. So ist fraglich, ob und inwieweit Besch&#228;ftigte in der Verwaltung im Arbeitsalltag einer KI-
Empfehlung widersprechen und so zur Fehlervermeidung beitragen. Deshalb m&#252;ssen die soziologischen und
psychologischen Auswirkungen von KI-Empfehlungen auf den Menschen in seiner Entscheidungsautonomie
untersucht werden. KI-Systeme sollten stets so gestaltet sein, dass sie der Autonomie der oder des Einzelnen nicht
entgegenstehen. Hier besteht eindeutiger Bedarf an interdisziplin&#228;rer Forschung, weshalb Untersuchungen zu
dieser Thematik aktiv gef&#246;rdert werden m&#252;ssen.
3
Soziale Innovationen f&#246;rdern
Dar&#252;ber hinaus soll ein Social-Innovation-Fonds eingerichtet werden, um einen finanziellen Anreiz f&#252;r die
Entwicklung gemeinwohlorientierter KI-Anwendungen zu schaffen und so L&#246;sungen sowohl im Bereich der
&#246;ffentlichen Verwaltung als auch in den Bereichen Nachhaltigkeit, Bildung, Gesundheit, Umwelt, Mobilit&#228;t oder
Verbraucherschutz zu f&#246;rdern.
Einsatzgebiete f&#252;r KI systematisch identifizieren
Beh&#246;rden sollten den Einsatz von KI-Systemen f&#252;r Verwaltungsvorg&#228;nge bzw. -prozesse systematisch pr&#252;fen,
um dadurch z. B. eine Verbesserung der Qualit&#228;t, Bek&#228;mpfung von Missbrauch, Senkung der Kosten oder
Erh&#246;hung der Sicherheit zu erreichen. Des Weiteren sollte es in den Ministerien des Bundes ein Monitoring bez&#252;glich
des Einsatzes von KI in anderen Beh&#246;rden und Staaten geben und es sollte ein strukturierter Erfahrungsaustausch
unter den KI-einsetzenden Beh&#246;rden im In- und Ausland stattfinden. Dies sollte vom Bundeskanzleramt
koordiniert werden. In diesem Zuge sollte bei der Umsetzung des Onlinezugangsgesetzes (OZG) bereits jetzt der Einsatz
eines KI-Systems systematisch gepr&#252;ft werden.
Standardprozesse f&#252;r Beschaffung, Einkauf, Implementierung und Betrieb etablieren
Es ist n&#246;tig, einen Standardprozess f&#252;r die Entscheidung, den Einkauf, die Implementierung und den Betrieb von
KI-Anwendungen in der Verwaltung zu entwickeln und zu etablieren. Hierf&#252;r gilt es zu pr&#252;fen, inwiefern in der
Wirtschaft etablierte Standardprozesse f&#252;r die Implementierung von KI-Anwendungen im &#246;ffentlichen Sektor
geeignet sind. Die Perspektiven von Nutzerinnen und Nutzern sowie Mitarbeiterinnen und Mitarbeitern in den
betroffenen Verwaltungen sollten dabei einbezogen werden. Der Prozess sollte basierend auf einem
Risikoklassifizierungsmodell u. a. folgende Schritte beinhalten: die Definition von Zweck, Qualit&#228;tszielen und
Fairnessma&#223;en, Technikfolgenabsch&#228;tzung, Transparenz, Rechtskonformit&#228;t, zugrundeliegende Daten, Bedingungen und
Grenzen der Wirksamkeit, stete Evaluation, Revision, ggf. Anpassung bzw. Redesign oder Beendigung des
Einsatzes. Zudem m&#252;ssen Beh&#246;rden mit den erforderlichen Ressourcen und Befugnissen ausgestattet werden, um
den Einsatz von KI-Systemen in der Verwaltung besser bewerten und implementieren zu k&#246;nnen. Es ist zu pr&#252;fen,
inwiefern das Vergabe- und Beschaffungsrecht in seiner jetzigen Form ausreichend ist und inwiefern eine
staatliche oder unabh&#228;ngige Aufsicht in besonders sensiblen Bereichen der Verwaltung notwendig ist.
Kompetenzen aufbauen
Es sollte Ziel sein, m&#246;glichst vielen Verwaltungsmitarbeiterinnen und -mitarbeitern ein Verst&#228;ndnis f&#252;r die
Funktionsweisen, Vorteile und Herausforderungen von KI-Systemen aufzuzeigen, damit sie das Potenzial von KI-
Systemen zur Steigerung der Prozessqualit&#228;t und Produktivit&#228;t und m&#246;gliche Risiken in Bezug auf unerw&#252;nschte 
Diskriminierung und Verfehlung erwarteter Qualit&#228;tskriterien nachvollziehen und dem rechtzeitig
entgegenwirken k&#246;nnen. Die Mitarbeiterinnen und Mitarbeiter, die mithilfe von algorithmischen Entscheidungssystemen
Entscheidungen mit nicht trivialem Schadenspotenzial treffen, m&#252;ssen zur generellen Wirkweise von Methoden des
Maschinellen Lernens, der statistischen Natur des Ergebnisses und seiner m&#246;glichen Interpretation geschult
werden. Weitere Weiterbildungsangebote sollten u. a. auf die Bereiche Prozess- und Changemanagement,
Datenanalyse und Ethik abzielen. Bereits die Verwaltungsausbildung und das Studium f&#252;r angehende
Verwaltungsbesch&#228;ftigte m&#252;ssen ein breites Wissen zu Digitalisierung und KI-Systemen vermitteln. Gleichzeitig muss der
Innovationstransfer in die &#246;ffentliche Verwaltung institutionalisiert werden, indem Fachrollen eingerichtet werden.
Es muss &#8211; bei sensiblen oder systemrelevanten KI-Systemen &#8211; zudem dar&#252;ber diskutiert werden, ob die
notwendige Entwicklung durch eigenes Fachpersonal erstellt wird, um Abh&#228;ngigkeiten von externen Anbietern zu
vermeiden und Verifizierbarkeit sowie Auditierbarkeit und Nachnutzbarkeit durch andere Beh&#246;rden zu erh&#246;hen
(Open AI816).
Transparenz schaffen und Risiken systematisch klassifizieren
F&#252;r staatlich genutzte KI-Systeme, die auf einem durch Methoden des Maschinellen Lernens gelernten
statistischen Modell basieren, ist immer eine Risikoklassifikation durchzuf&#252;hren. Beh&#246;rden und Verwaltungen sollten 
die Ziele, die Funktionsweise und die Qualit&#228;tskriterien der von ihnen eingesetzten KI-Systeme (mit nicht-
trivialem Schadenspotenzial) auf ihren jeweiligen Webseiten der &#214;ffentlichkeit zug&#228;nglich machen und ein
Kontaktformular f&#252;r R&#252;ckfragen zur Verf&#252;gung stellen. Basierend auf einer Risikoklassifikation sind die entsprechenden
816 Mit &#8222;Open AI&#8220; ist an dieser Stelle frei zug&#228;ngliche KI analog zu Open Source gemeint.
Anforderungen an Transparenz und Nachvollziehbarkeit817 zu bestimmen und es ist anzugeben, welchen
Adressatenkreis sie jeweils haben &#8211; bei sensitiven Anwendungen k&#246;nnte dieser also bspw. auf unabh&#228;ngige,
akkreditierte Expertengruppen beschr&#228;nkt sein. F&#252;r KI-Systeme mit hohem Risiko sollten Transparenzpflichten zur
Datengrundlage, Eingabeart, Qualit&#228;t der Eingabedaten und Qualit&#228;tskriterien bestehen. Die Frage, wer was
nachvollziehen k&#246;nnen muss, kann besonderen Restriktionen (Milit&#228;rgeheimnis, Staatsgeheimnis) unterliegen und es
bedarf gegebenenfalls einer Kontrolle. 
Sollte ein KI-System f&#252;r einen anderen Zweck eingesetzt werden als f&#252;r den, f&#252;r den es urspr&#252;nglich entwickelt,
trainiert und eingesetzt wurde, so muss dies angezeigt und es m&#252;ssen bei einer h&#246;heren Risikoklasse die
entsprechenden Ma&#223;nahmen ergriffen werden. Im Allgemeinen sollten die B&#252;rgerinnen und B&#252;rger so viele
Informationen wie m&#246;glich bekommen, und diese Informationen sollten so weit wie m&#246;glich verst&#228;ndlich sein.
KI-gest&#252;tzte Entscheidungen regelm&#228;&#223;ig auf Diskriminierungsfreiheit &#252;berpr&#252;fen
Es muss sichergestellt werden, dass staatlich entwickelte und genutzte KI-Systeme in ihrer Nutzung (also auch
im Zusammenwirken mit menschlichen Entscheiderinnen und Entscheidern) nicht diskriminieren. Es muss
gepr&#252;ft werden, ob die Daten in dem algorithmischen Entscheidungssystem in einem der Anwendungsfelder zum
Einsatz kommen, die grundrechtlich besonders gesch&#252;tzt sind und in denen es in besonderem Ma&#223;e auf
Gleichbehandlung ankommt (z. B. Zugang zu Sozialleistungen). Dann muss das Ergebnis der maschinellen
Entscheidung und &#8211; falls diese nur unterst&#252;tzend eingesetzt wird &#8211; das der finalen Entscheidung durch den Menschen
regelm&#228;&#223;ig daraufhin untersucht werden, ob die Entscheidung diskriminierend ist.
Datenkonzepte erarbeiten und umsetzen
Die Projektgruppe regt ein rechtlich verbindliches Regelwerk an, das die Modalit&#228;ten der Erhebung,
Aufbereitung, Pflege, Nutzung und ggf. Ver&#246;ffentlichung von Daten der &#246;ffentlichen Verwaltung auff&#252;hrt (Data-
Governance). Aufbauend auf diesem verbindlichen Regelwerk sollten Datenkonzepte die Datenbasis der jeweiligen
Beh&#246;rde erfassen, Datenhandhabung und die Beachtung von Prozessen darlegen, Trainings- und
Verwendungszwecke und Transparenzerfordernisse beschreiben. Auch die Zust&#228;ndigkeit f&#252;r die Evaluierung des trainierten 
Modells und die Zust&#228;ndigkeit f&#252;r die fortlaufende Entscheidungsg&#252;te des trainierten Modells m&#252;ssen im
Datenkonzept der entsprechenden Beh&#246;rde bestimmt werden. Das Datenkonzept sollte so weit wie m&#246;glich transparent
gemacht werden, mit dem Ziel Anwenderinnen und Anwender sowie Betroffene in die Lage zu versetzen, ihr
Verhalten anzupassen, um Entscheidungen zu beeinflussen. Es m&#252;ssen Fehlerraten der Eingangsdaten
verzeichnet und es muss auf Verzerrungen bzgl. sensitiver Daten hingewiesen werden. F&#252;r die Daten soll ein
Balancierungskonzept vorgelegt werden, das es erlaubt, Entscheidungsregeln auch f&#252;r durch sensible Daten definierte
Minderheiten zu erlernen. Datenintegrit&#228;t ist ein essentielles Qualit&#228;tsmerkmal und sollte stets gegeben sein.
Hohe und konstant &#252;berpr&#252;fte Sicherheitsvorgaben f&#252;r Daten k&#246;nnten den missbr&#228;uchlichen Zugriff oder die
Manipulation von Datens&#228;tzen erschweren. Entsprechende Vorgaben sollten in den Datenkonzepten von
Beh&#246;rden definiert werden.
Partizipation f&#246;rdern
Beh&#246;rden sollten beim Einsatz von KI-Systemen durch die Verwaltung einen echten partizipativen, b&#252;rgernahen
Ansatz verfolgen, um KI-Systeme zu entmystifizieren und der Zivilgesellschaft die M&#246;glichkeit zu bieten,
m&#246;gliche Bedenken auszur&#228;umen. Beteiligte gesellschaftliche Gruppen, z. B. B&#252;rger-, Sozial- und
Behindertenverb&#228;nde sowie Interessengemeinschaften, sollten fr&#252;hzeitig in die Debatte &#252;ber die Entwicklung und insbesondere
die Festlegung von Kriterien sowie die Datenauswahl staatlich eingesetzter KI-Systeme einbezogen werden. Die
Gesellschaft sollte jedenfalls immer dann einbezogen werden, wenn Einzelne in Grundrechten ber&#252;hrt werden
k&#246;nnten. Dar&#252;ber hinaus ist es notwendig, die Bev&#246;lkerung breit und umf&#228;nglicher &#252;ber KI aufzukl&#228;ren, damit
die Menschen verstehen und erkennen k&#246;nnen, welche Vor- und Nachteile spezifische Anwendungen haben.
Hierzu bedarf es geeigneter kommunikativer Ma&#223;nahmen und Formate.
817 In diesem Zusammenhang wird darauf hingewiesen, dass die Begriffe &#8222;Transparenz&#8220; und &#8222;Nachvollziehbarkeit&#8220; verschiedene
Dimensionen haben, die aktuell noch nicht abschlie&#223;end definiert werden k&#246;nnen. Siehe auch Kapitel 4.2. des Mantelberichts [
Transparenz, Nachvollziehbarkeit und Erkl&#228;rbarkeit].
AG-Berichte
1 AG 1: KI in der Verwaltung und internationale Vorbilder
Einf&#252;hrung
KI-Systeme kommen trotz ihres Potenzials f&#252;r die &#246;ffentliche Verwaltung dort bislang nur in geringem Ma&#223;e
zum Einsatz. Um die Technologie erfolgreich zu nutzen, m&#252;ssen insbesondere die Anforderungen an
Datenqualit&#228;t und -integrit&#228;t, Transparenz und Partizipation hinreichend ber&#252;cksichtigt werden.
Grunds&#228;tzlich bietet die &#246;ffentliche Verwaltung gro&#223;es Potenzial f&#252;r Digitalisierung und Automatisierung. Dies
liegt im Charakter der Verwaltungsprozesse begr&#252;ndet, die per se durch Regeln gesteuert werden. Elektronische
Datenverarbeitung ist dem technischen Charakter nach ebenfalls regelbasiert (If This Then That).
Durch die Durchbr&#252;che im Bereich der lernenden k&#252;nstlichen Systeme k&#246;nnte die Verwaltung &#8211; bei einer
konsequenten Digitalisierung &#8211; gro&#223;en Nutzen aus dem Verwaltungswissen ziehen, einem bislang ungehobenen
Datenschatz. Basierend auf der Praxis der Vergangenheit w&#228;ren Automatisierungen insbesondere von
Verwaltungsvorg&#228;ngen mit hoher Fallzahl mithilfe von KI-Systemen m&#246;glich. Es gilt zu beachten, dass der
Anwendung von KI-Systemen in der Verwaltung eine umfassende Digitalisierung vorausgeht. Hier sind die
Verwaltungen der skandinavischen L&#228;nder beispielhaft.818 
Der Fachkr&#228;ftemangel und der demografische Wandel setzen den &#246;ffentlichen Sektor von zwei Seiten unter
Druck und dr&#228;ngen ihn zur effizienteren Prozessgestaltung. Mit der Gesetzgebung zur E-Akte819 wird der
Umstieg von analogen zu digitalen Informationen Geschwindigkeit aufnehmen und es besteht die M&#246;glichkeit,
Informationen zuk&#252;nftig &#252;ber KI-Systeme inhaltsgesteuert in der Akte zusammenflie&#223;en zu lassen.
Das vorrangige Arbeiten mit Informationen und Wissen in der &#246;ffentlichen Verwaltung bietet f&#252;r lernende KI-
Systeme eine wichtige Grundvoraussetzung: Im Wesentlichen geht es an vielen Stellen des Verwaltungshandelns
um das Aufnehmen von Informationen, das Kombinieren von Wissen und das Schlussfolgern aus diesem Wissen.
Auch Kompetenzen wie kognitive F&#228;higkeiten, Nutzung von Erfahrungswissen oder Probleml&#246;sungsans&#228;tze
werden lernenden KI-Systemen zugeschrieben.
Dar&#252;ber hinaus sind in der Kommunikation und Interaktion zwischen B&#252;rgerinnen und B&#252;rgern und Staat
positive Auswirkungen durch den Einsatz von KI-Systemen zu erwarten &#8211; sowohl aufseiten der B&#252;rgerinnen und
B&#252;rger als auch aufseiten der Mitarbeiterinnen und Mitarbeiter der &#246;ffentlichen Verwaltung. Ein Potenzial ist
dabei der bessere Informationszugang. Mithilfe von automatisierten &#220;bersetzungen und bedarfsgerechten
Erkl&#228;rungen durch KI-Systeme k&#246;nnen die Zugangsh&#252;rden zu &#246;ffentlichen Informationen f&#252;r B&#252;rgerinnen und
B&#252;rger verringert und damit Teilhabe erh&#246;ht werden. Neben dem Abbau sprachlicher Barrieren haben KI-
Systeme au&#223;erdem die M&#246;glichkeit, auf gro&#223;e Datenmengen zur&#252;ckzugreifen sowie auf menschliche R&#252;ckfragen
zu reagieren. Dadurch k&#246;nnen Informationen nicht nur einfacher vermittelt werden, sondern ein KI-System kann
au&#223;erdem eine gr&#246;&#223;ere Bandbreite an Informationen f&#252;r B&#252;rgerinnen und B&#252;rger bereitstellen. Um die Chancen
der Nutzung von KI-Systemen zu verwirklichen, braucht es innovative KI-Systeme sowie eine
datenschutzkonforme Vernetzung der Datenmengen der &#246;ffentlichen Verwaltung.
Aktuell gibt es erst einige gemeinwohlorientierte Pilotprojekte, die das Potenzial von KI-Systemen sowohl in
Anwendungsbreite als auch Anwendungstiefe noch lange nicht aussch&#246;pfen. Gemeinwohlorientierte
Anwendungen kann es sowohl innerhalb des staatlichen Handelns als auch in allen anderen Bereichen des
zivilgesellschaftlichen Lebens geben. Hier gibt es nach momentanem Sachstand weiterhin einen Bedarf an Social-Innovation-
Fonds zur F&#246;rderung dieser gemeinwohlorientierten Systeme. Der Einsatz von KI-Systemen birgt somit gro&#223;e
Potenziale, bringt jedoch auch Schadenspotenzial mit sich. Letzteres ist vor allem in der besonderen Stellung der
&#246;ffentlichen Verwaltung begr&#252;ndet.820 So hat der Gesetzgeber 2016 den normativen Rahmen f&#252;r das vollautoma-
818 Vgl. Wangler und Botthof (2019): E-Governance: Digitalisierung und KI in der &#246;ffentlichen Verwaltung, S. 128.
819 Bis zum Jahr 2020 muss jede deutsche Beh&#246;rde mit der Umsetzung der E-Akte begonnen haben.
820 Als Teil der Exekutive nimmt die Verwaltung &#246;ffentliche Aufgaben wahr, also Aufgaben, die explizit dem Gemeinwohl dienen. Das
k&#246;nnen Kernaufgaben sein, die der Staat selbst vollzieht (z. B. Verteidigung, Innere Sicherheit, Polizei, Finanzverwaltung) oder
Gew&#228;hrleistungsaufgaben, deren Erbringung der Staat gew&#228;hrleistet, die er aber nicht zwingend selbst erbringen muss (z. B. Schulen,
Universit&#228;ten, Kinderg&#228;rten etc.). Durch eine Entscheidung, die ein Verfahren abschlie&#223;t, verpflichtet die Verwaltung die Betroffenen 
rechtsverbindlich zum Tun, Dulden oder Unterlassen (Verwaltungsakt), beispielsweise durch einen beh&#246;rdlichen Baubescheid oder
einen Strafzettel. Da sie entsprechend weitgehende Eingriffe in Rechte Dritter vornehmen kann, unterliegt sie nicht nur der
Gesetzm&#228;&#223;igkeit, sondern auch der Verfassungsm&#228;&#223;igkeit. Das hei&#223;t, Verwaltungshandeln bedarf einer Gesetzesgrundlage (Vorbehalt des
Gesetzes) und darf nicht gegen Gesetze versto&#223;en (Vorrang des Gesetzes).
tisierte Erlassen, z. B. von Steuerbescheiden und Sozialverwaltungsakten, abgesteckt. Das erm&#246;glicht es,
Steuerbescheide nun &#8222;schneller, emotionsfreier und effizienter, als dies einem Menschen m&#246;glich w&#228;re&#8220;,821 zu
erlassen. Sobald die Erkl&#228;rbarkeit und Begr&#252;ndung einer Entscheidung zu gew&#228;hrleisten ist oder ein
Ermessensspielraum existiert, gibt es im Moment jedoch keine M&#246;glichkeit, KI-Systeme mit einer lernenden Komponente zu
verwenden.822 
Bislang werden KI-Systeme nur punktuell in der deutschen Verwaltungslandschaft eingesetzt, die bestehenden
Potenziale also noch lange nicht genutzt. Mit dem Einsatz von KI-Systemen betritt die Verwaltung ein f&#252;r sie
bisher wenig erschlossenes Feld. Der Wissenstransfer in diesem Gebiet muss deutlich schneller und strukturierter
erfolgen als in der Vergangenheit zu anderen Themen der Verwaltungsmodernisierung. Dies gilt insbesondere
f&#252;r die bessere Erschlie&#223;ung des Erfahrungswissens der europ&#228;ischen Partner sowie die Vorbereitung auf
paneurop&#228;ische Verfahren im Rahmen des Single Digital Gateway (EU-Verordnung).
Der Staat sollte demnach systematisch pr&#252;fen, inwiefern Einsatzfelder f&#252;r KI-Systeme in anderen Staaten auch
im &#246;ffentlichen Sektor in Deutschland denkbar w&#228;ren, z. B. durch die Analyse des Einsatzes von KI-Systemen
in anderen L&#228;ndern.
Vorbilder und Potenziale f&#252;r den internen Einsatz von KI-Systemen in der Verwaltung
In den Beh&#246;rden k&#246;nnten Assistenzsysteme eine deutliche Effizienzsteigerung von Verwaltungsvorg&#228;ngen
bewirken, Anfrageaufkommen und Themen nachvollziehbarer machen, eine h&#246;here Nutzerzufriedenheit
gew&#228;hrleisten und zur Kostensenkung beitragen. Konkrete Anwendungsbeispiele finden sich u. a. in folgenden
Bereichen der Verwaltung:
A: Ordnungsverwaltung
&#8226; Automatisiertes Fr&#252;hwarnsystem f&#252;r Steuerhinterziehung: Ein KI-System kann entsprechende
Verhaltenstrends erkennen, fr&#252;hzeitige Kontaktaufnahme und b&#252;rgerspezifische Ansprache erm&#246;glichen (Beispiele:
Steuerbeh&#246;rde Queensland, LVA Berlin, Finanzamt Kassel / Panama Papers)
B: Dienstleistungsverwaltung
&#8226; Automatisierung der Bearbeitung von eingehenden E-Mails/Anfragen an die Verwaltung: Ein KI-System
versteht Inhalte von E-Mails, Dokumenten und Terminen und hilft bei der internen Organisation
(Postkorbsortierung des Bundesamtes f&#252;r Migration und Fl&#252;chtlinge, BAMF823)
C: Organisationsverwaltung
&#8226; Beschaffungswesen:824 
Ein KI-System erm&#246;glicht automatisiertes Bestellwesen f&#252;r Beh&#246;rden.
&#8226; Liegenschaftsverwaltung- und Baumanagement:
Durch die Erkennung von Unregelm&#228;&#223;igkeiten kann ein KI-System bei der Analyse von &#246;ffentlichen
Immobiliendaten &#252;ber wichtige Sachverhalte informieren und Erkl&#228;rungen f&#252;r ungew&#246;hnliche Situationen, 
z. B. widerspr&#252;chliche Angaben in Antr&#228;gen, geben.825 
&#8226; Intelligentes Personalwesen:
Ein KI-System kann bei Personalbeschaffung und Entwicklung unterst&#252;tzen, z. B. bei der Vorauswahl von
Bewerberinnen und Bewerbern oder im Zuge von automatischen Fort- und Weiterbildungsvorschl&#228;gen f&#252;r
Mitarbeiterinnen und Mitarbeiter.826 
821 Vgl. Martini (2019): Blackbox Algorithmus &#8211; Grundfragen einer Regulierung K&#252;nstlicher Intelligenz, S. 17.
822 Vgl. Herold (2019): Algorithmisierung von Ermessensentscheidungen durch Machine Learning.
823 Weitere Informationen dazu unter: http://ankommenapp.de/DE_nvam/Service/Top/Presse/Interviews/20190401-kuenstliche-intelli-
genz-bamf-nl-behoerden-spiegel/kuenstliche-intelligenz-bamf-nl-behoerden-spiegel-node.html (zuletzt abgerufen am 1. September
2020).
824 Bezieht ein Tr&#228;ger der &#246;ffentlichen Verwaltung Leistungen von Dritten, die f&#252;r die eigene T&#228;tigkeit ben&#246;tigt werden, spricht man
von Beschaffung (zum Teil auch von Einkauf), vgl. Einmahl (2019): Einf&#252;hrung in die &#246;ffentliche Beschaffung.
825 Darstellung des sachverst&#228;ndigen Mitglieds Dr. Sebastian Wieczorek in der Sitzung der Projektgruppe &#8222;KI und Staat&#8220; am 18. M&#228;rz 
2019.
826 Der Bericht der Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220; in Kapitel C. V. [K&#252;nstliche Intelligenz und Arbeit
(Projektgruppe 4)] geht auf Chancen und Risiken von KI im Personalwesen detailliert ein.
Vorbilder und Potenziale f&#252;r den Einsatz von KI-Systemen bei der Interaktion mit der Gesellschaft
Positive Erfahrungen im Hinblick auf die Nutzung von KI-Systemen gibt es bisher insbesondere mit Chatbot-
Anwendungen827, die dabei helfen, den Informationsaustausch sowie das Antragswesen effizienter zu gestalten,
indem sie die Kommunikation vereinfachen.
Es zeigt sich also, dass mittels Chatbots b&#252;rokratische H&#252;rden durch KI-Systeme erheblich gesenkt und damit
der Informationsaustausch sowie das Antragswesen vereinfacht und die Antragsstellenden entlastet werden
k&#246;nnen. Es kann jedoch f&#252;r die &#246;ffentliche Verwaltung auch zu einem starken Mehraufwand kommen, wenn nur
b&#252;rgerseitig KI-Systeme zur Antragsbearbeitung eingesetzt werden. F&#252;r B&#252;rgerinnen und B&#252;rger m&#252;ssen analog
zu Artikel 22 Absatz 1 der Datenschutz-Grundverordnung (DSGVO) immer auch M&#246;glichkeiten geschaffen
werden, bei Bedarf in einen direkten Kontakt mit der Beh&#246;rde zu treten, ohne ausschlie&#223;lich auf eine automatisierte
Bearbeitung angewiesen zu sein. 
Neben der Verbesserung der Kommunikation und des Leistungszugangs durch Chatbots gibt es dar&#252;ber hinaus
die M&#246;glichkeit, aktuell bereits genutzte digitale B&#252;rgerbeteiligungsinstrumente mit KI-Systemen zu verbinden.
Beispielsweise lie&#223;en sich E-Petitionen sowie Online-Konsultationen durch KI-gest&#252;tzte
Informationsaufbereitung unterst&#252;tzen. Somit l&#228;sst sich ein KI-System also auch als Werkzeug einsetzen, um die Partizipation
von B&#252;rgerinnen und B&#252;rgern zu erh&#246;hen und ein besseres Verh&#228;ltnis zwischen Staat und B&#252;rgerinnen und
B&#252;rgern zu schaffen. Neben der Partizipation l&#228;sst sich auch die Teilhabe erh&#246;hen. KI-Anwendungen k&#246;nnen die
Barrierrefreiheit erh&#246;hen, indem sie z. B. multilinguale, automatisierte Untertitelung oder Spracheingabe
verwenden. Des Weiteren besteht die M&#246;glichkeit, mittels KI-Systemen die Meinungen von B&#252;rgerinnen und
B&#252;rgern im breiten Format zu analysieren und Erkenntnisse daraus zu ziehen.
Zielsetzung
Beim Einsatz von KI-Systemen in der &#246;ffentlichen Verwaltung m&#252;ssen eine Reihe unterschiedlicher
Gesichtspunkte ber&#252;cksichtigt und miteinander in Einklang gebracht werden. Neben institutionellen und
organisatorischen Erw&#228;gungen spielen dabei auch die Rechte, Bed&#252;rfnisse und Interessen von Mitarbeiterinnen und
Mitarbeitern sowie B&#252;rgerinnen und B&#252;rgern eine Rolle.
&#220;bergreifendes Ziel, neben der Effizienzsteigerung beim Verwaltungshandeln, ist die Gew&#228;hrleistung von
Nachvollziehbarkeit und Transparenz f&#252;r B&#252;rgerinnen und B&#252;rger und andere Stakeholder (z. B. NGOs,
Unternehmen) beim Einsatz von bestimmten algorithmischen Systemen in der &#246;ffentlichen Verwaltung. Die
Funktionsweise sollte &#252;ber eine zielgruppenspezifische Aufbereitung (z. B durch verst&#228;ndliche Sprache) und technisch
&#252;ber eine entsprechende Dokumentation nachvollziehbar sein. Verwaltungsvorg&#228;nge mit h&#246;heren Risikoklassen,
bei denen KI-Systeme mit lernenden Komponenten eingesetzt werden, m&#252;ssen kontrollierbar bleiben. 
Leitlinien f&#252;r KI-Systeme in der Verwaltung
&#8226; Das Design der eingesetzten KI-Systeme sollte h&#246;chsten Qualit&#228;tsanspr&#252;chen entsprechen, sicher und
zuverl&#228;ssig ausgestaltet werden. Die jeweiligen Transparenz- und Nachvollziehbarkeitsforderungen werden
dabei durch die Eingruppierung in eine Risikoklasse vorgegeben. 
&#8226; ADM-Systeme staatlicher Einrichtungen m&#252;ssen technisch robust sein und hohen Anforderungen an die IT-
Sicherheit (Security by Design) erf&#252;llen.
&#8226; KI-Systeme sollten sowohl zur Entlastung von B&#252;rgerinnen und B&#252;rgern in der Informationsbeschaffung
und Antragstellung f&#252;hren als auch zur Entlastung von Verwaltungsmitarbeiterinnen und -mitarbeitern bei
der Bearbeitung.
&#8226; B&#252;rokratische H&#252;rden sollten gezielt mittels KI-Systemen gesenkt werden, wodurch der
Informationszugang und das Antragswesen grundlegend vereinfacht werden k&#246;nnen. Dadurch gibt es einen besseren
Leistungszugang f&#252;r B&#252;rgerinnen und B&#252;rger. 
827 Chatbot-Anwendungen sind digitale Dialogprogramme, die schriftlich oder per Sprachverarbeitung mit B&#252;rgerinnen und B&#252;rgern
(zum Teil auch mehrsprachig) kommunizieren und ihnen Antworten in Form von Informationen oder Unterst&#252;tzung beim Ausf&#252;llen
von Antragsdokumenten geben k&#246;nnen. Chatbots k&#246;nnen KI-gest&#252;tzte Sprachverarbeitung nutzen, um die nat&#252;rliche Sprache der
Nutzerinnen und Nutzer bedarfsgerecht zu interpretieren und den b&#252;rokratischen Sprachgebrauch zu erkl&#228;ren.
&#8226; Je nach Regelspielraum k&#246;nnen eigenst&#228;ndige KI-Bescheidung oder KI-Empfehlungen die
Verwaltungsmitarbeiterinnen und -mitarbeiter entlasten. Dadurch haben diese mehr Zeit f&#252;r pers&#246;nliche Beratung, was
positive Auswirkungen auf die Arbeitsqualit&#228;t haben kann.
&#8226; KI-Systeme sollten dabei unterst&#252;tzen, den Serviceumfang um ein jederzeit zug&#228;ngliches, mehrsprachiges
sowie barriere- und kostenfreies Leistungsangebot zu erweitern. KI-Systeme k&#246;nnen Barrierefreiheit
erh&#246;hen und Anspruch auf Teilhabe erf&#252;llen.
&#8226; Anhand quantifizierbarer Parameter sollte die Zielverwirklichung gemessen werden. Dazu geh&#246;ren:
Messung von gesteigerter Anzahl von Informationsbeschaffungen und Antragstellungen sowie in Relation
dazu die Genehmigungsquote und die Quote erfolgreicher Einspr&#252;che gegen Verwaltungsentscheidungen,
sowie die
&#8226; Ver&#228;nderungen in der Bearbeitungsdauer vom Erstkontakt bis zur Auskunft bzw. bis zum Bescheid sowie
&#8226; Ver&#228;nderung der Widerspruchsquote
&#8226; Die Qualit&#228;t von Resultaten, die unter Mitwirkung von KI-Systemen entstehen, sollte langfristig signifikant 
h&#246;her sein als bei ausschlie&#223;lich menschlicher Mitwirkung. Relevante Ver&#228;nderungen sollten beobachtet
werden, um bei negativen Entwicklungen die Ursachen zu untersuchen und ggf. den Einsatz von KI-
Systemen zu ver&#228;ndern oder sogar zu beenden.
Thematischer Scherpunkt
Status quo
KI-Systeme werden vermehrt in Verwaltung, Wirtschaft und grunds&#228;tzlich im Alltag eingesetzt. Daher muss die
Gesellschaft (zumindest) &#252;ber den teilhaberelevanten Einsatz selbstbestimmt urteilen k&#246;nnen, damit die
Menschen (als Verbraucherinnen und Verbraucher) Rechte wahrnehmen k&#246;nnen. Au&#223;erdem m&#252;ssen mehr Menschen
&#252;ber die entsprechenden Kenntnisse und F&#228;higkeiten verf&#252;gen, damit die Gesellschaft die Potenziale von KI-
Systemen zur Gestaltung aussch&#246;pfen kann. Bisher geben 52 Prozent der deutschen Wohnbev&#246;lkerung ab 14
Jahren an, den Begriff KI erkl&#228;ren zu k&#246;nnen oder in etwa zu wissen, was er bedeutet.828 Dabei zeigt sich jedoch,
dass viele ein falsches oder unzureichendes Verst&#228;ndnis des Begriffs haben. Zudem existieren gro&#223;e
gesellschaftliche Unterschiede: Bei der Bev&#246;lkerungsgruppe der digital Abseitsstehenden (ca. 13 Millionen Menschen in
Deutschland) verf&#252;gt nur eine von zehn Personen &#252;ber ein Verst&#228;ndnis des Begriffs, bei den digitalen Vorreitern 
(ca. 24 Millionen Menschen) im Land sind es ca. acht von zehn Personen.829 Diese Zahlen sind ein Hinweis, dass
Staat und Verwaltung einerseits Ma&#223;nahmen ergreifen sollten, um den selbstbestimmten Umgang mit KI-
Systemen als Grundlage f&#252;r die Wahrnehmung von Rechten zu unterst&#252;tzen. Andererseits sollten Ma&#223;nahmen
gef&#246;rdert werden, die das gesellschaftliche Innovationspotenzial bei der Gestaltung von KI-Systemen heben. Finnland
hat sich beispielsweise zum Ziel gesetzt, dass sich m&#246;glichst viele Menschen mit KI befassen, und hat dazu
kostenlose Online-Kurse entwickelt. Die Zielmarke ist, einem Prozent der finnischen Bev&#246;lkerung die
Grundlagen von KI-Systemen zu vermitteln.830 
KI-Systeme und Transparenz in der &#246;ffentlichen Verwaltung
Die &#246;ffentliche Verwaltung als b&#252;rokratische Organisation unterliegt den Prinzipien der Regelgebundenheit,
Schriftlichkeit und Aktenm&#228;&#223;igkeit. Damit soll die Berechenbarkeit von Entscheidungen, Unpers&#246;nlichkeit
(Behandlung &#8222;ohne Ansehen der Person&#8220;) sowie Kontrollierbarkeit der Verfahren garantiert werden. Als Teil der
Exekutive kann die Verwaltung weitgehende positive oder negative Eingriffe in Rechte Dritter vornehmen und
unterliegt daher auch anders als die Privatwirtschaft besonderen Anforderungen hinsichtlich der
Kontrollierbarkeit durch die B&#252;rgerinnen und B&#252;rger (Verfassungsm&#228;&#223;igkeit).
Transparenz ist eine grundlegende Voraussetzung f&#252;r nachvollziehbare und erkl&#228;rbare Entscheidungen, die
notwendig sind, um das Vertrauen der B&#252;rgerinnen und B&#252;rger in den Staat aufrechtzuerhalten und staatliches
Handeln kontrollierbar zu machen. Ziele von Transparenz sind z. B. nach Hustedt831 u. a.
828 Vgl. Initiative D21 e. V.: D21 Digital Index 2018/2019.
829 Vgl. Darstellung des sachverst&#228;ndigen Mitglieds Lena-Sophie M&#252;ller in der Sitzung der Enquete-Kommission am 11. Februar 2019.
830 Weitere Informationen dazu unter: https://www.elementsofai.com/ (zuletzt abgerufen am 22. Juli 2020).
831 Vgl. Darstellungen von Carla Hustedt (Senior Project Manager bei der Bertelsmann Stiftung) in der Sitzung der gesamten Enquete-
Kommission am 6. Mai 2019.
&#8226; B&#252;rgerinnen und B&#252;rger sowie andere Stakeholder (z. B. NGOs, Unternehmen) in die Lage zu versetzen,
ihr Verhalten anzupassen, um Entscheidungen zu beeinflussen oder Rechtsverletzungen zu identifizieren 
und damit die Grundlage zu schaffen, um Rechte durchzusetzen,
&#8226; Wahlfreiheit zwischen Optionen zu erm&#246;glichen sowie
&#8226; eine nachvollziehbare Bewertung des KI-Einsatzes vor dem Hintergrund von gesellschaftlichen Werten und
Normen zu erm&#246;glichen. 
Transparenz liegt insbesondere dann in der Verantwortung des Staates, wenn ein KI-System teilhaberelevant
ist.832 Die Anerkennung der besonderen Verantwortung der &#246;ffentlichen Verwaltung spiegelt sich in den
etablierten Verwaltungsprinzipien wider.833 Der Einsatz von KI-Systemen wird das &#8222;Wie&#8220; der Umsetzung dieser
Prinzipien ver&#228;ndern. So werden beispielsweise texterkennende und schlussfolgernde KI-Systeme beim
Posteingang in einer Verwaltung dazu f&#252;hren, dass Eing&#228;nge k&#252;nftig inhaltsbezogen verteilt werden statt per
&#8222;Umlaufmappe&#8220; entsprechend einem allgemeinen, vorab festgelegten Verteilungsplan. Beim Einsatz von KI-
Systemen ist darauf zu achten, dass die Funktionen und Ziele, die b&#252;rokratischen Prinzipien innewohnen, n&#228;mlich
Garant zu sein f&#252;r eine gemeinwohlorientierte Verwaltung, gewahrt oder ausgebaut werden.
Es empfehlen sich verschiedene Stufen der Transparentmachung von algorithmischen Entscheidungssystemen in
der Verwaltung, die sich an dem Schweregrad m&#246;glicher Fehlurteile eines KI-Systems orientieren. Bei kritischen
KI-Systemen (ab nicht-trivialem Schadenspotenzial) ergeben sich auch Transparenzpflichten zur
Datengrundlage, Eingabeart, Qualit&#228;t der Eingabedaten und Qualit&#228;tskriterien.834 
Gesetzliche Grundlagen
&#8226; Der rechtliche Rahmen f&#252;r die Anwendung von KI-Systemen in der Verwaltung ist bislang grob gesteckt
und in &#167; 155 Absatz 4 der Abgabenordnung (AO), &#167; 35a des Verwaltungsverfahrensgesetzes
(VwVfG), 31a des Zehnten Buches Sozialgesetzbuch (SGB X) und Artikel 22 DSGVO geregelt.
Voraussetzung ist, dass kein Ermessensspielraum vorliegt, keine Opt-out-Regelung besteht835, das Recht auf
Neubewertung gewahrt wird und die Entscheidung einer transparenten Logik folgt. 
&#8226; Mit der Regelung im Verwaltungsverfahrensgesetz wurde im Gegensatz zur Regelung im
Sozialgesetzbuch836 eine Verbotsnorm mit Erlaubnisvorbehalt eingef&#252;gt. Das bedeutet einerseits, dass f&#252;r jede
automatisierte Entscheidung eine neue Gesetzesgrundlage geschaffen werden muss, welche die Kriterien der
Verbotsnorm umsetzt. Hiervon wurde bisher nur in &#167; 155 Absatz 4 AO Gebrauch gemacht. Andererseits wird 
in der Rechtswissenschaft die Frage diskutiert, ob die speziellere Erlaubnisnorm auch Entscheidungen
erlaubt, denen ein Ermessens- oder Beurteilungsspielraum zukommt. Problematisch erscheint, dass der
Erlaubnisvorbehalt keine Ma&#223;gaben f&#252;r die Erstellung einer Erlaubnisnorm bereith&#228;lt. Die Schaffung von
Erlaubnisnormen ist dringend zu empfehlen. 
&#8226; In &#167; 155 Absatz 4 AO wird davon ausgegangen, dass eine Entscheidung voll automatisiert getroffen werden
kann, wenn kein Anlass besteht, den Einzelfall durch einen Amtstr&#228;ger zu bearbeiten. Die Norm geht somit
davon aus, dass nur regelbasierte Entscheidungen voll automatisiert werden d&#252;rfen und Abweichungen nicht
automatisiert eingelesen, verarbeitet und bewertet werden d&#252;rfen.
832 Bez&#252;glich der Teilhaberelevanz gibt es unterschiedliche Ans&#228;tze der Bewertung. Carla Hustedt berichtete in der Enquete-
Kommission vom Ansatz von Vieth/Wagner, die die gesamtgesellschaftliche Relevanz betonen und daher auf Fragen wie &#8222;Werden Menschen 
durch das algorithmische System bewertet?&#8220;, &#8222;Wie abh&#228;ngig sind die Bewerteten vom Ergebnis?&#8220;, &#8222;Wie viel politische und
&#246;konomische Macht hat der Betreiber?&#8220; &#8222;Wie gro&#223; ist die Reichweite des Systems?&#8220; abstellen. Ein weiterer Ansatz ist in der Risikomatrix
des sachverst&#228;ndigen Mitglieds Prof. Dr. Katharina Zweig zu sehen. Vgl. hierzu Hustedt (2019): Algorithmen-Transparenz. Was
steckt hinter dem Buzzword? und Zweig (2019): Algorithmische Entscheidungen: Transparenz und Kontrolle.
833 Verwaltungshandeln ist in der Praxis in hohem Ma&#223;e durch b&#252;rokratische Prinzipien gepr&#228;gt, die Fachkompetenz, Berechenbarkeit
und Unpers&#246;nlichkeit garantieren und Willk&#252;r verhindern sollen. Sie dienen als Grundlage f&#252;r rechtstaatliche und demokratische
F&#252;hrung sowie Kontrolle. Dazu geh&#246;rt z. B., dass das Handeln nach schriftlich fixierten Regeln erfolgt (Regelgebundenheit) und 
Verfahrensschritte dokumentiert werden (Aktenprinzip). Verfahren sollen dadurch &#252;berpr&#252;fbar, unabh&#228;ngig vom Ansehen der Person
und berechenbar werden.
834 Vgl. Zweig (2019): Algorithmische Entscheidungen: Transparenz und Kontrolle.
835 Wenn keine Opt-out-M&#246;glichkeit besteht, bedeutet dies, dass man keine M&#246;glichkeit hat, sich gegen eine Anwendung zu entscheiden 
und z. B. kein Verfahren ohne KI w&#228;hlen kann.
836 &#167; 31a SGB X erlaubt grunds&#228;tzlich vollautomatisierte Verwaltungsakte ohne einen Erlaubnisvorbehalt (vgl. Luthe (2017): Der
vollst&#228;ndig automatisierte Erlass eines Verwaltungsakts nach &#167; 31a SGB X, S. 253; Martini und Nink (2017): Wenn Maschinen
entscheiden &#8230;, S. 3; Littmann (2017), insb. Rn. 9).
Datenqualit&#228;t/-integrit&#228;t
F&#252;r die G&#252;te und die Nachvollziehbarkeit algorithmischer Entscheidungen sind die Verf&#252;gbarkeit, aber auch die
Qualit&#228;t, Integrit&#228;t und Transparenz von Trainingsdaten und Datenmerkmalen, die der Entscheidung zugrunde
liegen, von entscheidender Bedeutung. Die Entstehung von Diskriminierung837 ist dabei sowohl in der
&#8222;analogen&#8220; als auch in der digitalen Verwaltung eine Herausforderung. Es gilt also, Ma&#223;nahmen zu treffen, um Daten
in hoher und gesicherter Qualit&#228;t verf&#252;gbar zu machen und gleichzeitig einer m&#246;glichen Diskriminierung
entgegenzuwirken.
Die Daten der &#246;ffentlichen Verwaltung liegen derzeit noch nicht &#252;berall gut strukturiert und in maschinenlesbarer
Form vor. Eine durchgehende Data-Governance-Strategie f&#252;r alle Beh&#246;rden w&#252;rde bestehende Vorgaben zur
&#214;ffnung von Verwaltungsdaten unterst&#252;tzen und gleichzeitig f&#252;r eine hohe Qualit&#228;t der Daten als Grundlage f&#252;r
KI-Systeme sorgen.
Partizipation beim Einsatz von KI
Partizipation dient insbesondere der Akzeptanz beh&#246;rdlicher Entscheidungen838, der Transparenz839, sofern die
&#214;ffentlichkeit fr&#252;hzeitig einbezogen wird, sowie der Kontrolle bzw. Kontrollm&#246;glichkeit von Entscheidungen
und Entscheidungsprozessen. Damit wird zudem der Schutz von B&#252;rgerrechten durch Einwirkungsm&#246;glichkeiten
w&#228;hrend des Entscheidungsverfahrens gest&#228;rkt. Daneben kann auch die demokratische Legitimation einer
Entscheidung gest&#228;rkt werden.
Wenn sich eine Verwaltung f&#252;r den Einsatz einer KI-Technologie mit entsprechender Datenauswahl oder -
erstellung entscheidet, dann kann das weitreichende Auswirkungen bis hin zum Grundrechtseingriff haben. Dadurch
ergeben sich weitergehende Notwendigkeiten f&#252;r die fr&#252;hzeitige Einbindung der Zivilgesellschaft durch
Instrumente der B&#252;rgerbeteiligung. Die OECD840 schl&#228;gt f&#252;r Partizipationsverfahren, die von staatlicher Seite initiiert
werden, die drei Ebenen Information, Konsultation und Zusammenarbeit vor. F&#252;r den Einsatz von KI-Systemen
in der Verwaltung empfiehlt sich eine Orientierung an einer Risikoklassifizierung, wobei die Verwaltung
B&#252;rgerinnen und B&#252;rger fr&#252;hzeitig einbeziehen sollte, indem sie sie ab einem nicht-trivialen Schadenspotenzial
informiert und ab einem mittleren Schadenspotenzial konsultiert oder mit ihnen zusammenarbeitet.
Interaktion von Gesellschaft und Verwaltung
Neben der Schaffung eines besseren Zugangs zu Informationen ist es auch n&#246;tig, die Potenziale von KI-Systemen 
f&#252;r ein einfacheres und b&#252;rgerorientiertes sowie individuelleres Antragswesen zu nutzen. In der &#246;ffentlichen
Verwaltung fallen j&#228;hrlich Millionen von Antr&#228;gen zu routinem&#228;&#223;igen Prozessen an, die oft nach einfachen Regeln
beschieden werden. Beispielsweise beziehen in Deutschland ca. 3,9 Millionen Menschen Hartz IV (Stand 2019),
ca. 1,6 Millionen Menschen Sozialgeld (Stand 2017)841 und &#252;ber 590 000 Menschen Wohngeld (Stand 2017)842. 
Weitere Beispiele sind &#252;ber 780 000 Sch&#252;lerinnen und Sch&#252;ler und Studierende (Stand 2017)843, die BAf&#246;G
erhalten, sowie &#252;ber 3,3 Millionen Kinder in Kindertageseinrichtungen (Stand 2019)844. Dabei ist zu beachten, 
dass all diese Fallzahlen nur jene Antr&#228;ge widerspiegeln, die bewilligt wurden. Mithilfe von KI-Systemen
k&#246;nnten sowohl die Stellung als auch die Bearbeitung dieser Massenantr&#228;ge verbessert werden. 
Ein Problem zeigt sich momentan darin, dass es an gemeinwohlorientieren KI-Anwendungen mangelt. Damit
sind Anwendungen gemeint, die explizit gesellschaftliche Probleme l&#246;sen m&#246;chten und dies im Vergleich zu
profitorientieren L&#246;sungen priorisieren. Eine L&#246;sung f&#252;r diese Problematik ist die Idee der Social-Innovation-
Fonds, mit denen Geldmittel bereitgestellt werden k&#246;nnen. Diese unterst&#252;tzen gezielt die Entwicklung von ge-
837 Diskriminierung wird verstanden als ungerechtfertigte Ungleichbehandlung von Gleichen oder ungerechtfertigte Gleichbehandlung
von Ungleichen basierend auf sensitiven Eigenschaften in definierten Anwendungen (siehe Grundgesetz, Allgemeines
Gleichbehandlungsgesetz).
838 Bspw. Begr&#252;ndung zum Entwurf eines Gesetzes zur Verbesserung der &#214;ffentlichkeitsbeteiligung und Vereinheitlichung von
Planfeststellungsverfahren, Bundestagsdrucksache 17/9666, S. 13.
839 Bspw. Begr&#252;ndung zum Gesetzentwurf Standortauswahlgesetz, Bundestagsdrucksache 17/13471, S. 19 ff.
840 Vgl. OECD (2001): Citizens as Partners, S. 15 ff.
841 Vgl. Statista (2020): Hartz IV: Anzahl der Leistungsempf&#228;nger von Arbeitslosengeld II und Sozialgeld im Jahresdurchschnitt von 
2010 bis 2020.
842 Vgl. Statista (2018): Anzahl der Haushalte mit Bezug von Wohngeld in Deutschland von 1991 bis 2017.
843 Vgl. Statista (2019): Anzahl der mit BAf&#246;G gef&#246;rderten Studierenden und Sch&#252;ler von 1991 bis 2018.
844 Vgl. Statista (2020): Anzahl der Kinder in Kindertageseinrichtungen in Deutschland nach Bundesl&#228;ndern am 1. M&#228;rz 2019.
meinwohlorientierten KI-L&#246;sungen und schaffen Anreize f&#252;r die Entwicklung gemeinwohlorientierter KI-
Systeme. Dadurch k&#246;nnen KMU und NGOs gemeinwohlorientierte KI-Systeme entwickeln und so z. B. im Bereich
der Mobilit&#228;ts-, Gesundheits-, Bildungs- oder Umweltverbesserung f&#252;r gesellschaftlich relevante Fortschritte 
sorgen. Nat&#252;rlich w&#252;rden solche Social-Innovation-Fonds auch die Entwicklung von gemeinwohlorientieren KI-
Anwendungen f&#252;r die Interaktion mit der &#246;ffentlichen Verwaltung f&#246;rdern. 
Open Data845 f&#252;r Gemeinwohl
Die zweite Herausforderung, die zu einer Hemmung von innovativen Entwicklungen beitr&#228;gt, ist der mangelnde
Zugang zu entwicklungsrelevanten Datens&#228;tzen. Die &#246;ffentliche Verwaltung verf&#252;gt &#252;ber viele relevante Daten,
jedoch stehen diese f&#252;r die externe Entwicklung oft nicht zur Verf&#252;gung. Um Innovationen zu f&#246;rdern, ist es
deshalb wichtig, umfassende Open-Data-Angebote in datenschutzkonformer Art und Weise bereitzustellen. Mit
diesen k&#246;nnen Entwicklerinnen und Entwickler eigene KI-Anwendungen schaffen, ohne auf teure eigene oder
Drittanbieter-Datens&#228;tze angewiesen zu sein. Daf&#252;r m&#252;ssen schon vorhandene Open-Data-Portale weiter
ausgebaut und zentrale Schnittstellen geschaffen werden; auf diesen Portalen werden Daten der &#246;ffentlichen
Verwaltung in maschinenlesbaren und g&#228;ngigen Formaten bereitgestellt. In die Daten m&#252;ssen ebenfalls die
Rechtsprechung und Sachbearbeitungsurteile in anonymisierter Form mit einbezogen werden, um schon w&#228;hrend der
Antragstellung automatisiert auf die Erfolgswahrscheinlichkeit hinweisen zu k&#246;nnen.846 F&#252;r gemeinwohlorientierte
Innovationen muss daher also ein umfassendes Open-Data-Angebot geschaffen werden.847 
Beispiele
KI-Systeme als Unterst&#252;tzung f&#252;r die Kommunikation und Interaktion von B&#252;rgerinnen und B&#252;rgern mit Staat
und Verwaltung im internationalen Vergleich
Einige KI-Systeme unterst&#252;tzen schon interne Prozesse in der deutschen Verwaltung. So klassifiziert das
Deutsche Patent- und Markenamt neue Patentanmeldungen und gleicht diese mit bestehenden Patentrechten ab. Dabei
wird es durch ein System unterst&#252;tzt, das auf einer schwachen KI aufbaut.848 Das Bundesamt f&#252;r Sicherheit in
der Informationstechnik (BSI) nutzt algorithmische Entscheidungssysteme, automatisierte Mustererkennung und
lernende k&#252;nstliche Systeme, um Schadprogramme zu identifizieren.849 Das Deutsche Arch&#228;ologische Institut
setzt auf algorithmenbasierte Entscheidungen und ein KI-System, um digitale Texte auf Stichw&#246;rter oder
Textpassagen hin zu durchsuchen (Textmining).850 Das Bundeszentralamt f&#252;r Steuern durchsucht mit einer speziell
entwickelten Suchsoftware (XPIDER) verschiedene Online-Plattformen, u. a. auch Ebay. Damit kann es
m&#246;gliche Steuerdelikte von H&#228;ndlerinnen und H&#228;ndlern identifizieren. Die Einstellung des Suchmechanismus und die
Ergebnispr&#252;fung finden durch Mitarbeiterinnen und Mitarbeiter der Beh&#246;rde statt.851 
In Anlehnung an die 115-Hotline, die erster Ansprechpartner f&#252;r jegliche verwaltungsspezifische Fragen ist, wird
in der Verwaltung der Hansestadt Hamburg momentan der 115-Bot (&#8222;Frag den Michel&#8220;) erprobt. Dieser Chatbot
analysiert Anfragen von B&#252;rgerinnen und B&#252;rgern an die Verwaltung und interpretiert die sprachliche Struktur
der Formulierungen, um passende Vorschl&#228;ge inklusive Erl&#228;uterung an die B&#252;rgerinnen und B&#252;rger
zur&#252;ckzuliefern. Aus diesen Vorschl&#228;gen k&#246;nnen sie w&#228;hlen und dem Chatbot Feedback zu seinem Ergebnis liefern,
sodass dieser sich st&#228;ndig verbessern kann. B&#252;rgerinnen und B&#252;rger profitieren dabei von einem Service rund um
845 Open (Government) Data: Unter Open Data versteht man das Konzept der Ver&#246;ffentlichung von nicht-personenbezogenen Daten
(unter Government Data die Daten der &#246;ffentlichen Verwaltung) in strukturierter und maschinenlesbarer Form, wobei offene
Nutzungsrechte verwendet werden, die lediglich durch Quellennennung beschr&#228;nkt werden d&#252;rfen.
846 Vgl. Larson (2020): How a chatbot is helping homeless people find housing.
847 Siehe auch Kapitel 2.4 [Zugang zu Daten], Kapitel 2.6 [Politischer Handlungsrahmen bez&#252;glich KI und Daten] des Mantelberichts
und AG-Bericht 2 dieses Projektgruppenberichts [AG 2: Smart City und Open Data].
848 Vgl. Antwort der Bundesregierung auf die Schriftliche Fragen 7, 8, 9 und 10 der Abgeordneten Saskia Esken auf
Bundestagsdrucksache 19/605.
849 Vgl. Antwort der Bundesregierung auf die Schriftliche Fragen 7, 8, 9 und 10 der Abgeordneten Saskia Esken auf
Bundestagsdrucksache 19/605.
850 Vgl. Th&#228;nert und Unger (2019): Linked Data in der iDAI.world.
851 Vgl. Antwort der Bundesregierung auf die Schriftliche Fragen 7, 8,9 und 10 der Abgeordneten Saskia Esken auf
Bundestagsdrucksache 19/605.
die Uhr und ohne Wartezeiten. Momentan ist dieses Angebot nur in deutscher Sprache verf&#252;gbar, jedoch ist eine
multilinguale Anwendung geplant.852 
Verwaltungsbeh&#246;rden setzen KI-Systeme und algorithmische Entscheidungssysteme derzeit f&#252;r spezifische
Anwendungsf&#228;lle ein. Es ist davon auszugehen, dass der Einsatz in naher Zukunft deutlich ansteigen wird. Derzeit
f&#246;rdern etliche Bundesministerien Pilotprojekte und Machbarkeitsstudien im Bereich KI. Die Strategie
K&#252;nstliche Intelligenz der Bundesregierung ber&#252;cksichtigt ebenfalls Anwendungsf&#228;lle in der Verwaltung.
Internationale Vorbilder
Gro&#223;britannien &#8211; Chatbot bei drohender Obdachlosigkeit
Ein Chatbot, der in Gro&#223;britannien von Joshua Browder entwickelt und kostenfrei zur Verf&#252;gung gestellt wurde,
erm&#246;glicht es B&#252;rgerinnen und B&#252;rgern, bei drohender Obdachlosigkeit per Chatbot einen Antrag auf staatliche
Unterst&#252;tzung zu stellen. Zuvor war daf&#252;r ein Rechtsbeistand in einem langwierigen Prozess n&#246;tig. Als
Datengrundlage dienten hier Antragsdaten aus einem 15-j&#228;hrigen Zeitraum, die dank eines Antrags auf
Informationsfreiheit anonymisiert als Open Data bereitgestellt wurden und dabei halfen, die Erfolgswahrscheinlichkeit f&#252;r die
antragstellenden Personen zu ermitteln. Hier zeigt sich, wie essentiell der Einfluss von Open Data als
Datengrundlage f&#252;r das Finden gemeinwohlorientierter KI-L&#246;sungen ist.853 
USA/Kanada &#8211; Chatbots f&#252;r Greencard- und Einwanderungs-Antr&#228;ge
Eine weitere Chatbot-Anwendung ist der &#8222;Visabot&#8220; in den USA. Gegen eine Geb&#252;hr von 150 Dollar werden
B&#252;rgerinnen und B&#252;rger beim Stellen ihres Greencard-Antrags unterst&#252;tzt, indem der Chatbot ihre Antworten
auswertet und in ein passendes Format umwandelt.854 Einen &#228;hnlichen Ansatz verfolgt der kanadische Chatbot 
&#8222;Destin.ai&#8220;, der bei der Einwanderung nach Kanada unterst&#252;tzen soll. Das System beantwortet Fragen rund um
die Einwanderung und hilft B&#252;rgerinnen und B&#252;rgern dabei, den f&#252;r sie passenden Antrag zu stellen.855 Dabei ist 
kritisch zu beachten, dass diese beiden Chatbots, die jeweils von privaten Unternehmen angeboten werden, einen
kommerziellen Messenger als Basisplattform f&#252;r die Kommunikation nutzen und damit auf die Infrastruktur von 
Drittanbietern angewiesen sind.
USA/Gro&#223;britannien &#8211; Chatbot f&#252;r Widerspr&#252;che bei Bu&#223;geldbescheiden
Ebenfalls von Joshua Browder wurde der Chatbot &#8222;DoNotPay&#8220; entwickelt, der es jeder Person in den USA und
im Vereinigten K&#246;nigreich kostenfrei und ohne gro&#223;en Aufwand erm&#246;glicht, Bu&#223;geldbescheiden beim
Falschparken automatisiert zu widersprechen. Dabei entsteht mit wenig Aufwand f&#252;r die Nutzerinnen und Nutzer ein
gro&#223;er Mehraufwand f&#252;r die Verwaltung, weshalb entsprechende verwaltungsinterne Effizienzsteigerungen,
z. B. &#252;ber automatisierte Antragsbearbeitung, notwendig sind. Dar&#252;ber hinaus lassen sich mit DoNotPay in den
USA auch individuelle und automatisierte Schadensersatzklagen erstellen, die wiederum f&#252;r Mehraufwand in der
Justiz sorgen. Nutzerinnen und Nutzer folgen dabei einem einfachen Dialogablauf, mit dem der Bot herausfindet,
um was f&#252;r einen Rechtsfall es sich jeweils handelt. Dabei liegt nach Angabe des Entwicklers die Erfolgsrate der
Klagen bei ca. 50 Prozent mit einem durchschnittlichen Schadensersatz in H&#246;he von 7 000 Dollar.856 
Schweden &#8211; Erh&#246;hung der Effizienz von Anfragen beim Grundbuchamt
Das schwedische Grundbuchamt (SLR) hat Ma&#223;nahmen mit dem Ziel eingeleitet, seine Effizienz bei der
Bearbeitung von Grundbuchanfragen zu steigern.
Die Sachbearbeiterinnen und -bearbeiter des SLR erhalten von den B&#252;rgerinnen und B&#252;rgern zahlreiche
Anfragen zu Eigentum und Eigentumsrechten. Um Entscheidungen treffen zu k&#246;nnen, m&#252;ssen historische
Informationen zu Objekten &#252;berpr&#252;ft werden, die h&#228;ufig bis in die 1850er Jahre zur&#252;ckreichen.
852 Vgl. Antwort des Senats der B&#252;rgerschaft der Freien und Hansestadt Hamburg auf die Schriftliche Kleine Anfrage der
Abgeordneten Andr&#233; Trepoll und Carsten Ovens (CDU) auf Drucksache 21/16288, abrufbar unter: https://www.buergerschaft-
hh.de/parldok/dokument/65804/.pdf (zuletzt abgerufen am 1. September 2020).
853 Vgl. Triola (2016): Chatbots offers free legal aid to the homeless; Larson (2020): How a chatbot is helping homeless people find
housing.
854 Vgl. Lumb (2017): Immigration chat bot now helps you apply for a green card.
855 Vgl. Destin AI, abrufbar unter: https://destin.ai/about (zuletzt abgerufen am: 14. Juli 2020).
856 Vgl. Haskins (2018): New App Lets You &#8222;Sue Anyone By Pressing a Button&#8220;.
Die Sachbearbeiterinnen und -bearbeiter verbrachten insgesamt ungef&#228;hr 48 000 Stunden pro Jahr damit, die
handschriftlichen Dokumente manuell lesbar zu machen und zu bewerten. Die Regierung berechnete den
B&#252;rgerinnen und B&#252;rgern die Anzahl der Stunden, die f&#252;r die Bearbeitung ihrer Anfragen erforderlich war.
Die alten handschriftlichen Dokumente waren von geringer Qualit&#228;t und Aufl&#246;sung, was die Analyse schwierig 
machte. Um dies zu beheben, f&#252;hrte das Grundbuchamt Vorverarbeitungsprozesse an den handschriftlichen
Dokumenten durch, um die Qualit&#228;t der Eingabedaten zu verbessern. Das SLR verwendete dann die handschriftliche 
Texterkennung (HTR), um Informationen aus den handschriftlichen Dokumenten zu extrahieren.
Anschlie&#223;end wurde ein neuronales Netz f&#252;r Wortkorrekturen und -assoziationen verwendet, damit m&#246;glichst 
alle S&#228;tze mit W&#246;rtern sinnvoll vervollst&#228;ndigt werden, die nicht von der HTR erfasst wurden. Nachdem der Text
extrahiert wurde, wird ein KI-Modell genutzt, um wichtige Funktionen im Dokument hervorzuheben, z. B.
Position, Name und Zusammenfassung.857 
Das Modell erm&#246;glicht es den Sachbearbeiterinnen und -bearbeitern nun, schnell auf B&#252;rgeranfragen zu reagieren
und sich mehr auf dringende Entscheidungen zu konzentrieren.
Dieses Beispiel zeigt die M&#246;glichkeiten auf, die bei internen Verwaltungsprozessen vorhanden sind, wenn ein
KI-System eingesetzt wird. Auch wird sehr deutlich, wie die interne Anwendung von KI-Systemen in der
Verwaltung zur Erh&#246;hung des Leistungsniveaus f&#252;hrt.
Zeit und Kosten werden gespart, bei gleichzeitiger Erh&#246;hung der Effizienz und B&#252;rgerfreundlichkeit. Die
Mitarbeiterinnen und Mitarbeiter beim Grundbuchamt k&#246;nnen mehr Zeit f&#252;r den pers&#246;nlichen Kontakt zu den
B&#252;rgerinnen und B&#252;rgern aufwenden.
USA &#8211; &#8222;EMMA&#8220;
Ein Beispiel, das zeigt, wie sich die Nutzerfreundlichkeit von Beh&#246;rdenwebsites erh&#246;hen l&#228;sst, kommt aus den 
USA.
Die US-amerikanischen Beh&#246;rden f&#252;r Staatsb&#252;rgerschaft und Einwanderung (&#8222;USCIS&#8220;) haben am 2.
Dezember 2015 eine virtuelle Assistentin mit dem Namen &#8222;EMMA&#8220; eingef&#252;hrt. &#8222;EMMA&#8220; bietet ihren Nutzerinnen und
Nutzern eine Hilfe, die das Navigieren auf der USCIS-Webseite und das Auffinden von Informationen
erleichtert.858 
&#8222;EMMA&#8220; wurde als Antwort auf den wachsenden Bedarf an Selbsthilfetools und zur Verbesserung des
Kundendienstes entwickelt. Derzeit sind USCIS-Callcenter der zentrale Mechanismus f&#252;r Kundenanfragen zu
allgemeinen Informationen, die auch &#252;ber das Internet abgerufen werden k&#246;nnen. Aufgrund der zunehmenden Anzahl
von Anruferinnen und Anrufern wurde &#8222;EMMA&#8220; entwickelt, um Kundenfragen zu rationalisieren und diese
Informationen online mithilfe der virtuellen Assistentin bereitzustellen.
&#196;hnlich wie SIRI von Apple kann &#8222;EMMA&#8220; Fragen empfangen und Nutzerinnen und Nutzer durch die USCIS-
Website f&#252;hren, um Antworten zu finden. &#8222;EMMA&#8220; beantwortet Fragen basierend auf eingetippten W&#246;rtern und
kann sofort Antworten geben. &#8222;EMMA&#8220; kann auch auf der uscis.gov-Website navigieren und Informationen 
basierend auf den eingegebenen Fragen und der eingegebenen Suchsprache (Englisch/Spanisch) suchen. 
Nach aktuellem Kenntnisstand nutzt keine deutsche Beh&#246;rdenwebsite ein KI-System, um die
Nutzerfreundlichkeit der teilweise sehr komplexen Internetseiten zu erh&#246;hen. Dabei ist von solchen Anwendungen auch
verwaltungsintern eine enorme Entlastung zu erwarten. Die Mitarbeiterinnen und Mitarbeiter k&#246;nnten sich in der
aufgewendeten Zeit anderen Aufgaben und komplexeren Vorg&#228;ngen widmen. Dies spart Zeit und Kosten und schafft
Akzeptanz bei den B&#252;rgerinnen und B&#252;rgern.
Estland &#8211; Kontrolle der staatlich subventionierten Heuanbaufl&#228;chen
In Estland nutzen die Beh&#246;rden ein KI-System, um die Ernte staatlich subventionierter Heub&#228;uerinnen und
Heubauern zu kontrollieren. Um &#252;ber den Fortschritt und das Wachstum der Ernte informiert zu sein, werden
Satellitenbilder der Europ&#228;ischen Weltraumorganisation ESA w&#246;chentlich von Mai bis Oktober aufgenommen und 
mit einem Deep-Learning-Algorithmus analysiert, den die Sternwarte von Tartu (Tartu Observatoorium)
entwickelt hat. Die Bilder werden w&#246;chentlich auf einer topografischen Karte platziert und jedes einzelne Pixel wird
857 Vgl. Government Digital Service; Office for Artificial Intelligence (2019): Natural language processing for Land Registry
documentation in Sweden.
858 Weitere Informationen dazu unter: https://www.uscis.gov/emma (zuletzt abgerufen am 14. Juli 2020).
analysiert.859 Die Beh&#246;rden schicken den Landwirtinnen und Landwirten eine automatisierte E-Mail, wenn die
Ernte zwei Wochen &#252;berf&#228;llig ist. Dieses System hat bereits im ersten Jahr zu Einsparungen in H&#246;he von 665 000 
Euro gef&#252;hrt, da es viel weniger Ortsbesuche geben musste, um Kontrollen durchzuf&#252;hren.860 
Singapur &#8211; Beispiel f&#252;r ein Governance-Modell
Ein geeignetes Beispiel f&#252;r die Einf&#252;hrung eines Governance-Modells im &#246;ffentlichen Sektor hat die Regierung
von Singapur ver&#246;ffentlicht.861 Das AI-Governance-Framework-Modell bietet Organisationen, die KI-L&#246;sungen
verantwortungsbewusst und unter ethischen Gesichtspunkten einsetzen wollen, Orientierungshilfe, um m&#246;gliche
Risiken bei der Einf&#252;hrung von KI-Systemen zu minimieren. Die Handlungsempfehlungen, die aus dem
freiwillig nutzbaren Modell abgeleitet werden, konzentrieren sich haupts&#228;chlich auf vier Bereiche: interne Governance-
Strukturen und Ma&#223;nahmen, Entscheidungsmodelle, Management/Betrieb von KI-Anwendungen und
Nutzermanagement. Damit geht das AI-Governance-Framework mit seinen Empfehlungen sogar &#252;ber eine Data-
Governance hinaus.
Das Modell Singapurs bezieht sich nicht auf spezifische KI- oder Datenanalysemethoden. Vielmehr gilt es f&#252;r
die Gestaltung, Anwendung und Verwendung von KI-Systemen im Allgemeinen. Zudem ist das AI-Governance-
Framework nicht ausschlie&#223;lich auf den &#246;ffentlichen Sektor begrenzt, sondern liefert auch f&#252;r andere Branchen
Empfehlungen. Dies verdeutlicht, dass der Staat auch bei KI-Systemen als Vorbild und Treiber dient, um
Entwicklungen zu steuern. Governance-Frameworks k&#246;nnen als Ma&#223;nahme verstanden werden, andere Akteure zu
bestimmten Strukturen und Verantwortlichkeiten zu verpflichten bzw. darauf aufmerksam zu machen.
Vorgehen
KI-Systeme am Wohle des Menschen orientieren
KI-Anwendungen in der &#246;ffentlichen Verwaltung m&#252;ssen im Sinne des Grundgesetzes am Wohl des Menschen
orientiert sein. Der Schutz der Interessen der B&#252;rgerinnen und B&#252;rger sowie der Mitarbeiterinnen und Mitarbeiter
muss bei der Entwicklung und internen Anwendung von KI-Systemen in der Verwaltung im Vordergrund stehen.
Verwaltungseinrichtungen, die KI-Systeme einsetzen, m&#252;ssen sicherstellen, dass der Entscheidungsprozess stets
nachvollziehbar, transparent und auf Basis der Verwaltungsprinzipien abl&#228;uft, um das Vertrauen von
B&#252;rgerinnen und B&#252;rgern, Unternehmen und zivilgesellschaftlichen Organisationen in KI-Systeme zu gew&#228;hrleisten. Die
jeweils notwendigen Transparenzforderungen ergeben sich dabei aus einer Risikoklassenanalyse des Systems.
Besonders gro&#223;es Potenzial f&#252;r den Einsatz von KI-Systemen in der Verwaltung existiert bei einfach
strukturierten Verwaltungsvorg&#228;ngen, die sich stark wiederholen und hohe Fallzahlen aufweisen.862 Somit sollte es ein
erstes Ziel sein, einheitliche Prinzipien zu etablieren, um Anwendungsf&#228;lle und potenzielle Einsatzgebiete f&#252;r
KI-Systeme in deutschen Verwaltungseinrichtungen zu identifizieren.
&#220;berpr&#252;fung der gesetzlichen Grundlagen
&#8226; Die in &#167; 155 Absatz 4 AO genannte Abstraktion sollte bereits in die allgemeine Norm des &#167; 35a VwVfG 
&#252;bertragen werden, um f&#252;r Klarheit zu sorgen und die Schaffung weiterer Erlaubnisnormen zur erleichtern.
&#8226; Ein vollautomatisierter Erlass von Verwaltungsakten ist bislang nur f&#252;r das Besteuerungsverfahren sowie
unter bestimmten Voraussetzungen im Geltungsbereich der Sozialgesetzb&#252;cher m&#246;glich. Es wird eine
Untersuchung empfohlen, um zu pr&#252;fen, welche erschwerenden Rechtsnormen es zudem f&#252;r den Einsatz von
lernenden k&#252;nstlichen Systemen in der Verwaltung gibt und wie diese Rechtsnormen angepasst werden
k&#246;nnten. 
&#8226; Wenn KI-Technologien in der Verwaltung angewendet werden, sollten diese, wie jede andere Technik,
umfassend gepr&#252;ft werden. Zudem sollte dar&#252;ber nachgedacht werden, einheitliche europ&#228;ische Standards zu
etablieren, damit entsprechende Technologien europaweit im &#246;ffentlichen Sektor angewendet werden
k&#246;nnen. 
859 Vgl. Ho (2019): Estonia &#8222;The judge is not human&#8220;.
860 Vgl. Niiler (2019): Can AI be a fair judge in court? Estonia thinks so.
861 Im Januar 2020 wurde die zweite Fassung ver&#246;ffentlicht: Info-communications Media Development Authority; Personal Data
Protection Commission (2020): Artificial Intelligence Governance Framework.
862 Vgl. Opiela et al. (2018): EXEKUTIVE KI 2030.
&#8226; Es gilt verst&#228;rkt, die Verantwortlichkeit bzgl. Sicherheit und Haftung zu er&#246;rtern und diese entsprechend zu
pr&#252;fen. Mit Blick auf Security by Design sollten hohe Sicherheitsanspr&#252;che in der Entwicklung und
Anwendung erf&#252;llt werden. Eine eindeutige Verantwortungszuweisung f&#252;r KI-Systeme sollte stets gegeben
sein. Haftungsregelungen sollten entsprechend gepr&#252;ft und &#252;berarbeitet werden. 
Systematisch vorgehen und &#252;bergeordnete Prinzipien anwenden
&#8226; Um geeignete Anwendungsfelder f&#252;r den Einsatz von KI-Systemen in einer Beh&#246;rde effizient auszuw&#228;hlen, 
bedarf es einer systematischen und standardisierten Vorgehensweise. Standardisierte Vorgehensweisen
erleichtern ein gemeinsames Verst&#228;ndnis und den Erfahrungsaustausch und erm&#246;glichen einheitliche
Qualit&#228;tsstandards. Das britische Digital Cabinet Office863 arbeitet daher z. B. mit sog. Guiding Principles, die
den Regierungs- und Verwaltungsbeh&#246;rden klare Leitlinien vorgeben (z. B. f&#252;r den Aufbau und die Nutzung
von KI im &#246;ffentlichen Sektor), ohne jedes Detail zu regeln.  
&#8226; Erfahrungen und Wissen aus einzelnen KI-Projekten sollten geb&#252;ndelt werden. Der Einkauf und Einsatz
von KI-Systemen sollte mithilfe von organisations&#252;bergreifenden Qualit&#228;tskriterien gesteuert werden. Die
Qualit&#228;tskriterien sollten sich u. a. auf Anforderungen an die Evaluierung der Leistungsf&#228;higkeit,
Nachvollziehbarkeit der Output-Generierung und den Ausschluss von Diskriminierung beziehen. 
&#8226; Anhand der H&#228;ufigkeit (Fallzahl) eines Verwaltungsvorgangs und der Einfachheit der Bearbeitung des
Verwaltungsvorgangs k&#246;nnen geeignete Verwaltungsvorg&#228;nge ermittelt werden. Einfache Vorg&#228;nge mit hoher
Fallzahl sollten m&#246;glichst zuerst durch KI-Systeme optimiert bzw. automatisiert werden, wenn dies
rechtlich zul&#228;ssig ist.
&#8226; Die folgende Grafik stellt m&#246;gliche Einsatzgebiete f&#252;r KI-Systeme in der &#246;ffentlichen Verwaltung dar.
Einsatzbeispiele mit hohem Nutzen f&#252;r B&#252;rgerinnen und B&#252;rger, die bei der Implementierung zu priorisieren
w&#228;ren, sind blau hinterlegt. Die orange hinterlegten Beispiele stellen interne Vorg&#228;nge dar, die vornehmlich 
Vorg&#228;nge innerhalb der Beh&#246;rde betreffen und keine direkte Verbesserung des Services f&#252;r die B&#252;rgerinnen
und B&#252;rger mit sich bringen. 
863 Das britische Digital Cabinet Office ist die f&#252;r Digitalfragen zust&#228;ndige Unterabteilung des Cabinet Office, einer britischen
Regierungsbeh&#246;rde, die den Premierminister und das Kabinett bei der Regierungsarbeit unterst&#252;tzen.
Abbildung 1 
Beispiel f&#252;r eine standardisierte Vorgehensweise f&#252;r die Ermittlung von m&#246;glichen geeigneten
Einsatzgebieten von KI-Systemen in der &#246;ffentlichen Verwaltung
(Autor: Sachverst&#228;ndiges Mitglied Dr. Sebastian Wieczorek)
Standardprozesse f&#252;r den Einsatz von KI-Systemen in der Verwaltung etablieren
Es ist n&#246;tig, einen Standardprozess f&#252;r Entscheidung, Einkauf und Implementierung zu entwickeln und zu
etablieren. Damit l&#228;sst sich die Planung der Analyseaufgaben vereinfachen, der Planungs- und Umsetzungs-prozess
beschleunigen und die M&#246;glichkeiten der Evaluierung verbessern. Es gilt zu pr&#252;fen, inwiefern welche
Standardprozesse als Leitf&#228;den f&#252;r die Implementierung von KI-Systemen im &#246;ffentlichen Sektor geeignet sind. Die
Leitf&#228;den sollten auch Qualit&#228;tskriterien f&#252;r die Evaluierung der KI-Systeme enthalten.
Ein m&#246;gliches Standardprozessverfahren k&#246;nnte das &#8222;CRISP-DM&#8220;-Prozess-Modell (Cross-Industry Standard
Process for Data Mining) sein, das in der Industrie in diversen Anwendungsfeldern eingesetzt wird.864 Das Modell
ist hier auf die Nutzung von lernenden k&#252;nstlichen Systemen ausgelegt, kann somit auch f&#252;r KI-Systeme oder
algorithmische Entscheidungssysteme angepasst werden.865 
Wenn es sich um KI-Systeme mit einer lernenden Komponente handelt, die mittelbar oder unmittelbar &#252;ber
Menschen entscheidet, m&#252;ssen weitere Phasen des Prozesses explizit mitbehandelt werden:866 so beispielsweise
bei der Wahl eines Qualit&#228;ts- und Fairnessma&#223;es, dem genauen Einsatzgebiet des Systems, der Schulung der
Mitarbeiterinnen und Mitarbeiter und dem Feedback zur Verbesserung des Systems.
864 Vgl. Wirth und Hipp (2000): CRISP-DM: Towards a standard process model for data mining, S. 29&#8211;39.
865 Das CRISP-DM beinhaltet die folgenden sechs Phasen:
1. Gesch&#228;ftsverst&#228;ndnis: Definition von Zielen und Anforderungen, Darlegen der Aufgabenstellung und der Vorgehensweise 
2. Datenverst&#228;ndnis: Sammlung von Daten bzw. erste Durchsicht der bestehenden Daten; &#220;berpr&#252;fung der Datenqualit&#228;t auf
m&#246;gliche Komplikationen 
3. Datenvorbereitung: Erstellung des Datensatzes f&#252;r die Modellierung 
4. Modellierung: Umsetzung geeigneter Data-Mining-Verfahren, Optimierung der Parameter; i. d. R. Ermittlung von mehreren
Modellen
5. Evaluierung: Auswahl des Modells, das die Aufgabenstellung bestm&#246;glich umsetzt; Vergleich mit der Aufgabenstellung aus
Phase 1
6. Bereitstellung: Verarbeitung und Pr&#228;sentation der Ergebnisse; Implementierung des Modells in geeignete Entscheidungsprozesse
in der Verwaltung.
866 Vgl. Zweig (2018): Wo Maschinen irren k&#246;nnen; Lischka et al. (2017): Wenn Maschinen Menschen bewerten.
Qualitativ hochwertige Daten und Data-Governance
F&#252;r verl&#228;sslich gute Ergebnisse von KI-Anwendungen werden Daten ben&#246;tigt, deren Integrit&#228;t und Qualit&#228;t f&#252;r
verschiedene Anwendungen jederzeit gew&#228;hrleistet werden kann.867 In diesem Zusammenhang sollte es das Ziel
sein, die Etablierung eines Datenkonzepts im Sinne einer Data-Governance f&#252;r die Verwaltung zu pr&#252;fen.
Aufbauend auf dem verbindlichen Regelwerk einer Data-Governance868 k&#246;nnten Datenkonzepte die Datenbasis der
jeweiligen Beh&#246;rde erfassen, die Datenhandhabung und die Beachtung von Prozessen darlegen und Trainings-
und Verwendungszwecke beschreiben: 869 
&#8226; Im Datenkonzept m&#252;sste festgelegt werden, wer in der Beh&#246;rde daf&#252;r zust&#228;ndig ist, die Datengrundlage auf
Eignung der Datenqualit&#228;t und Balancierung/Verzerrungsfreiheit der Datengrundlage (ungerechtfertigte
Diskriminierung) zu &#252;berpr&#252;fen sowie die Daten in Trainings- und Testdaten zu unterteilen. 
&#8226; Auch die Zust&#228;ndigkeit f&#252;r die Evaluierung des trainierten Modells und die Zust&#228;ndigkeit f&#252;r die
fortlaufende Entscheidungsg&#252;te des trainierten Modells m&#252;ssen im Datenkonzept der entsprechenden Beh&#246;rde
bestimmt werden.870 
&#8226; Zudem m&#252;ssen Regeln definiert werden, wie die Zivilgesellschaft &#8211; insbesondere mit Blick auf den Zugang
zu nicht ohnehin offenliegenden Datens&#228;tzen und Systemen &#8211; beteiligt werden kann. 
&#8226; Durch die Erstellung von Datenkonzepten k&#246;nnte eine h&#246;here Transparenz in Bezug auf die Datenherkunft
erreicht werden. In diesem Zusammenhang gilt es jedoch stets, den Zweck der Anwendung zu beachten, f&#252;r
den Daten benutzt werden.
&#8226; Diskriminierung kann in algorithmischen Systemen durch Defizite bei der Aufbereitung und Verwendung
von zugrundeliegenden Daten entstehen und/oder von Menschen in die konkrete Ausgestaltung eines
algorithmischen Systems eingebracht werden. Durch entsprechende Ma&#223;nahmen bei der Auswahl und
Anpassung der Datenbasis, bei der Ausgestaltung und im Einsatz des algorithmischen Systems muss
Diskriminierungen entgegengewirkt werden.
&#8226; Auch in der &#8222;analogen&#8220; Verwaltung ist Diskriminierung problematisch, denn ausgeschlossen ist sie nie.
Durch die neue Konfrontation mit Diskriminierung in algorithmischen Systemen werden auch &#8222;analoge&#8220;
Diskriminierungen st&#228;rker sichtbar und idealerweise reduziert.
&#8226; Erforderlich sind Anpassungen gesetzlicher Regelungen f&#252;r algorithmische Systeme und gleichzeitig eine
effektivere Umsetzung des bestehenden Rechts. Es sollte gepr&#252;ft werden, inwiefern eine Anpassung auf
europ&#228;ischer Ebene zielf&#252;hrend sein k&#246;nnte. 
Nachvollziehbarkeit beim Einsatz algorithmischer Systeme
&#8226; Es sollte f&#252;r B&#252;rgerinnen und B&#252;rger nachvollziehbar sein, in welchen Bereichen der Verwaltung KI-
Systeme genutzt werden, sofern dies in der Entscheidungsvorbereitung oder Entscheidungsphase erfolgt und
nicht das schlichte Verwaltungshandeln betrifft.871 Es muss stets klar gekennzeichnet sein, wenn ein KI-
System ma&#223;geblich bei einem Verwaltungsvorgang verwendet wurde, der ein Schadenspotenzial f&#252;r
Menschen bzw. die Gesellschaft nach sich ziehen k&#246;nnte.
867 Es wird bislang angenommen, dass es f&#252;r KI in der Verwaltung erforderlich ist, die Qualit&#228;t der Daten sicherzustellen. Gleichzeitig
ist zu beachten, dass statische Qualit&#228;tsstandards nicht zielf&#252;hrend sind. Vielmehr sind die Datenhandhabung und die Beachtung von 
Prozessen entscheidend.
868 Hierunter versteht man ein verbindliches Regelwerk, das eine Steuerungs- und Regelungsfunktion f&#252;r die Modalit&#228;ten der Erhebung,
Aufbereitung, Pflege, Nutzung und ggf. Ver&#246;ffentlichung von Daten innerhalb der &#246;ffentlichen Verwaltung aus&#252;bt. Aufbauend auf
einem Regelwerk zur Data-Governance k&#246;nnen Datenkonzepte die Datenbasis der jeweiligen Beh&#246;rde erfassen, die
Datenhandhabung und die Beachtung von Prozessen darlegen und Trainings- und Verwendungszwecke beschreiben. Datenkonzepte sind die
spezifische Ausgestaltung einer Data-Governance.
869 Vgl. Fragenkatalog zum Einkauf und Einsatz von ADM-/KI-Systemen durch Bundesministerien und nachgeordnete Beh&#246;rden,
Projektgruppendrucksache 19(27)PG 2-25 vom 12. Dezember 2019.
870 Vgl. Fragestellungen zum Einkauf und Einsatz von ADM-/KISystemen durch Bundesministerien und nachgeordnete Beh&#246;rden,
Projektgruppendrucksache 19(27)PG 2-25 vom 12. Dezember 2019.
871 Als schlichtes Verwaltungshandeln (auch tats&#228;chliches oder faktisches Verwaltungshandeln oder Realakt) werden Ma&#223;nahmen der
Verwaltung bezeichnet, die &#8211; anders als ein Verwaltungsakt &#8211; nicht auf die Setzung einer Rechtsfolge gerichtet sind. Ein Beispiel f&#252;r
schlichtes Verwaltungshandeln per Algorithmus ist eine Auskunft, die von einem Chatbot erteilt wird. Ein Beispiel f&#252;r einen
Verwaltungsakt per Algorithmus ist ein Steuerbescheid, der von einer Software erstellt wird.
&#8226; F&#252;r alle vom Staat zu beschaffenden oder zu erstellenden algorithmischen Entscheidungssysteme muss
zuerst festgestellt werden, ob sie lernende Komponenten beinhalten. Wenn ja, muss das
Gesamtschadenspotenzial und danach die Risikoklassifizierung ermittelt werden. Daraus folgen die notwendigen
M&#246;glichkeiten zum Widerspruch und die &#220;berpr&#252;fung des maschinell ermittelten Resultates, die fest verankert werden
sollten.872 Es bestand Dissens dar&#252;ber, ob f&#252;r den Fall einer Einordnung in die h&#246;chste Risikoklasse der
Einsatz des KI-Systems unterbunden werden muss. 
&#8226; Die &#246;ffentliche Verwaltung sollte den Verwaltungsprozess des Algorithmus allen Betroffenen
nachvollziehbar erkl&#228;ren k&#246;nnen. Insbesondere sollten Entscheidungsvorschl&#228;ge des Entscheidungsprozesses
interpretierbar sein.
&#8226; Verwaltungshandeln muss kontrollierbar und nachvollziehbar bleiben. Dazu z&#228;hlt die Reproduzierbarkeit
von Ergebnissen durch KI-Systeme in der Verwaltung. 
&#8226; Algorithmische Systeme agieren nicht unabh&#228;ngig von den Menschen, die sie beauftragen, herstellen oder
einsetzen &#8211; Pflichten und Verantwortung ergeben sich f&#252;r alle am algorithmischen System beteiligten
Menschen. Diese Verantwortlichkeiten m&#252;ssen definiert und zugeordnet sein.
Partizipation
Beim Einsatz von KI-Systemen mit einem nicht-trivialen Schadenspotenzial sollten zivilgesellschaftliche
Akteure &#252;ber das gesamte Verfahren von Entscheidung, Entwicklung und Betrieb beteiligt werden. Dies setzt eine
m&#246;glichst hohe Transparenz der Verwaltung bez&#252;glich der Planung und des Einsatzes von KI-Systemen und den
Austausch mit allen betroffenen Stakeholdern voraus, um die Bed&#252;rfnisse der Gesellschaft ber&#252;cksichtigen zu
k&#246;nnen. Es gilt, m&#246;gliche ungerechtfertigte Diskriminierungen beim Einsatz von algorithmischen
Entscheidungssystemen stets zu minimieren.
Unabh&#228;ngigkeit von Drittanbieter-Plattformen anstreben
Wenn Leistungen mit h&#246;chstpers&#246;nlichem Bezug in Anspruch genommen werden, wie es beispielsweise bei
Antr&#228;gen auf Sozialleistungen der Fall ist, muss sichergestellt werden, dass sensible Informationen vor
unzul&#228;ssigem Zugriff Dritter bewahrt werden. Unternehmen, die Datenschutzgrunds&#228;tze verletzen, sollten von der
Interaktion mit der &#246;ffentlichen Verwaltung ausgeschlossen werden. Der Dialog mit dem Staat (oder dessen KI) muss
Vertraulichkeit erm&#246;glichen. Es muss deshalb sichergestellt werden, dass die Integrit&#228;t der Daten von
B&#252;rgerinnen und B&#252;rgern umfassend gew&#228;hrleistet wird und aufgrund schon bekannter Verletzungen der DSGVO sowie
der Privatsph&#228;re von der Nutzung von Drittanbieter-Plattformen abzusehen ist, soweit diese sich nicht konform
mit den Datenschutzgrunds&#228;tzen verhalten.
Auch im Hinblick auf die Monopolbildung von Drittanbieter-Infrastruktur sollte davon abgesehen werden, diese
bei der Integration von &#246;ffentlichen KI-Systemen noch zu f&#246;rdern. Dabei zeigen sich Probleme der
Daten&#252;bertragung und der Zugangsh&#252;rden.
Aktuell basieren viele KI-L&#246;sungen, die zur Verbesserung der Kommunikation und Interaktion mit der
&#246;ffentlichen Verwaltung beitragen, auf Chatbots. Chatbot-Anwendungen nutzen dabei h&#228;ufig Messenger-Dienste gro&#223;er
Drittanbieter. Da die KI-Anwendungen momentan auf die Nutzung von Drittanbieter-Plattformen angewiesen
sind, haben jene Plattformen ebenfalls Zugriff auf alle Informationen, die w&#228;hrend dieses Prozesses
weitervermittelt werden.
Das zweite Problem tritt au&#223;erdem bei den Zugangsh&#252;rden auf. Wenn staatliche KI-Anwendungen auf die
Dienste von Drittanbietern angewiesen sind, k&#246;nnen sowohl im Rahmen der Entwicklung von Systemen als auch 
bei deren Nutzung Zugangsh&#252;rden entstehen und eine breite Teilhabe hemmen. B&#252;rgerinnen und B&#252;rger, die eine
Dienstleistung der &#246;ffentlichen Verwaltung in Anspruch nehmen wollen, d&#252;rfen nicht dazu gezwungen sein, sich
den Zugangsvoraussetzungen von Drittanbietern zu beugen. Daher m&#252;ssen barrierefreie Mindestanforderungen
an einen Messenger-Dienst beschrieben werden.
872 Ein geeigneter Ansatz w&#228;re die Implementierung der Sozialvertr&#228;glichkeitsregeln, die von Prof. Michael Wagner-Pinter
zusammengestellt wurden.
Um diesen Problemen entgegenzuwirken, sollten Standards in Form von Mindestanforderungen an einen
Messenger-Dienst beschrieben werden, durch die zugangsbeschr&#228;nkende Messenger-Dienste von Drittanbietern f&#252;r
die Nutzung in der &#246;ffentlichen Verwaltung ausgeschlossen werden. Im Optimalfall sollte ein Messenger-Dienst 
angestrebt werden, der als &#246;ffentlich-rechtliche Plattform direkt von der Verwaltung betrieben wird.
KI-Systeme als Digitalisierungsantrieb nutzen
Eine weitere Herausforderung, die sich auch am Beispiel des DoNotPay-Chatbots zeigt, ist nat&#252;rlich die
Tatsache, dass niedrigere Antragsh&#252;rden im ersten Moment zu einer h&#246;heren Arbeitsauslastung der &#246;ffentlichen
Verwaltung f&#252;hren k&#246;nnen. Der Einsatz von KI-Systemen f&#252;hrt auch zu Digitalisierungsdruck in Bereichen, in denen
KI-Systeme gar nicht zum Einsatz kommen. Schon um auf diese Entwicklung gut vorbereitet zu sein, sollten die
Prozesse der &#246;ffentlichen Verwaltung digitalisiert werden, um eine effizientere Bearbeitung zu erm&#246;glichen.
Lernende k&#252;nstliche Systeme keine Ermessens- oder Beurteilungsspielr&#228;ume f&#252;llen lassen
Es macht einen Unterschied, welche KI-Ans&#228;tze in der &#246;ffentlichen Verwaltung eingesetzt werden
(Expertensysteme oder lernende k&#252;nstliche Systeme) und in welchen Bereichen diese angewendet werden. Beim Einsatz
von KI-Systemen mit einer lernenden Komponente ist zu unterscheiden, ob erstens ein Verwaltungsakt (mit
Rechtsfolge) tangiert ist oder ob es sich um schlichtes Verwaltungshandeln (ohne Rechtsfolge) handelt und ob
zweitens eine Entscheidung dadurch vollzogen oder vorbereitet wird.873 Diese unterschiedlichen Logiken und
Wirkungsdimensionen sollten als &#252;bergreifende Orientierung Eingang in die einheitlichen Prinzipien finden.
Planerische und gestalterische Vorg&#228;nge und Entscheidungen mit Ermessensspielraum sollten auch zuk&#252;nftig
weiterhin von Mitarbeiterinnen und Mitarbeitern in den Verwaltungen ausge&#252;bt werden. Es muss sichergestellt sein,
dass Mitarbeiterinnen und Mitarbeiter auch wirklich gegen die Vorschl&#228;ge des Systems entscheiden k&#246;nnen.
Dazu bedarf es weiterer Forschung, insbesondere zu der Frage, wie Menschen in der Interaktion mit KI-Systemen
auf vorbereitete Entscheidungsvorschl&#228;ge reagieren und welche Automatisierungsgrade welche tats&#228;chliche
menschliche Autonomie zur Folge haben. Zudem m&#252;ssen in Arbeitsvertr&#228;gen entsprechende Regelungen
aufgenommen werden. Hiermit wird sich die Projektgruppe &#8222;Arbeit, Bildung, Forschung&#8220; in ihrem Bericht ausf&#252;hrlich
befassen. Zus&#228;tzlich sollten die mit den KI-Systemen arbeitenden Verwaltungsmitarbeiterinnen und -mitarbeiter
zur grunds&#228;tzlichen Funktionsweise und den Grenzen der KI-Systeme geschult werden, Ethik-Kompetenzen im
Umgang mit KI-Systemen erlangen sowie &#252;ber m&#246;gliche Fehlerquellen und Fehlinterpretationen aufgekl&#228;rt
werden.
Kompetenzen der Verwaltungsmitarbeiterinnen und -mitarbeiter aufbauen
&#8226; Durch die Digitalisierung ver&#228;ndern sich die erforderlichen Kompetenzen der &#246;ffentlichen Verwaltung.
Erfolgreicher Wandel und Adoption von Technologie erfolgt von innen: M&#246;glichst alle Mitarbeiterinnen und
Mitarbeiter einer Verwaltungseinrichtung sollten grundlegende Kenntnisse der eingesetzten KI-Systeme
erwerben, um die Technologie in ihrem Arbeitsalltag bestm&#246;glich zu nutzen, nachvollziehen zu k&#246;nnen und
den B&#252;rgerinnen und B&#252;rgern bei R&#252;ckfragen bedarfsgerecht erkl&#228;ren zu k&#246;nnen. 
&#8226; Bereits in der Ausbildung bzw. dem Hochschulstudium sollten angehende Verwaltungsmitarbeiterinnen und
-mitarbeiter ein m&#246;glichst breites Prozesswissen zu Verwaltungsvorg&#228;ngen aufbauen, das mit Wissen zu
KI-Systemen und deren Wirkung verbunden werden sollte.
&#8226; Um dem zuk&#252;nftigen Bedarf von KI-Expertinnen und -Experten zu begegnen, m&#252;ssen die
Karrierem&#246;glichkeiten in der Verwaltung f&#252;r KI-Expertinnen und -Experten attraktiver gestaltet werden.
Handlungsempfehlungen und Operationalisierung
Es gelten die &#252;bergeordneten Handlungsempfehlungen aus dem Kapiteln 1 [Kurzfassung des
Projektgruppenberichts] und dem Kapitel 3 [Handlungsempfehlungen] dieses Projektgruppenberichts. Die Enquete-Kommission
empfiehlt dem Deutschen Bundestag folgende Ma&#223;nahmen:
873 Darstellung Matthias Fl&#252;gge (damals Director des Digital Public Services des Fraunhofer Instituts f&#252;r Offene
Kommunikationssysteme) in der Sitzung der Projektgruppe &#8222;KI und Staat&#8220; am 11. M&#228;rz 2019.
Teilhaberelevante KI-Anwendungen
Es sollte ein Zustand in der &#246;ffentlichen Verwaltung angestrebt werden, bei dem sowohl B&#252;rgerinnen und B&#252;rger
als auch Verwaltungsmitarbeiterinnen und -mitarbeiter von KI-Systemen vielschichtig profitieren. Besonders
wichtig ist hierbei die Schaffung der sprachlichen Barrierefreiheit, Verringerung der Zugangsh&#252;rden, Teilhabe
der breiten Masse an &#246;ffentlichen Angeboten und Leistungen, Beschleunigung von Verwaltungsprozessen sowie
die Entlastung von Verwaltungsmitarbeiterinnen und -mitarbeitern durch eine positive Aufgabenverschiebung.
Um diesen Zustand zu erreichen, sind innovative L&#246;sungen f&#252;r KI-Systeme zu erm&#246;glichen und zu f&#246;rdern. Dabei
m&#252;ssen offene Standards entwickelt werden, die z. B. eine Entwicklung von Chatbots in der
Informationsbereitstellung und im Antragswesen erm&#246;glichen. Die im Januar 2019 bekannt gegebene Neufassung der PSI-
Richtlinie874 der EU ist dabei eine Gelegenheit f&#252;r die Bundesregierung, bei der Umsetzung in nationales Recht &#252;ber
die Vorgaben der Richtlinie hinauszugehen und die ben&#246;tigte Infrastruktur zu schaffen.
Dazu m&#252;ssen auf kommunaler sowie auf Landes- und Bundesebene Anreize und rechtliche Rahmenbedingungen
geschaffen werden, damit m&#246;glichst vollst&#228;ndige und durchgehende Open-Data-Best&#228;nde existieren. Isolierte 
Datenpools verhindern die Skalierung von KI-Anwendungen und f&#252;hren zu kleinteiligen L&#246;sungen und
Doppelstrukturen innerhalb der Verwaltung. Durch eine einheitliche Open Data-Plattform werden personelle Ressourcen
effizienter eingesetzt und au&#223;erdem leistungsf&#228;higere KI-basierte Algorithmen und Analysen erm&#246;glicht.
Rechtsanspruch auf Verwaltungsprozesse ohne Mitwirkung von KI-Systemen bieten
Da auch bei KI-Systemen Fehler auftreten k&#246;nnen, m&#252;ssen B&#252;rgerinnen und B&#252;rger Widerspruch gegen KI-
Empfehlungen in Verwaltungsprozessen einlegen k&#246;nnen. Jene Abl&#228;ufe, auf die KI-Systeme einen relevanten
Einfluss nehmen, m&#252;ssen dementsprechend gekennzeichnet werden. Durch das Widerspruchsverfahren k&#246;nnen
B&#252;rgerinnen und B&#252;rger im Zweifel von einem Rechtsanspruch auf eine Bearbeitung durch Menschen Gebrauch
machen. Dabei ist zu beachten, dass keine Person, die von diesem Recht Gebrauch macht, grundlos im
Bearbeitungsprozess benachteiligt wird, sondern dieselbe Priorit&#228;t f&#252;r den Bearbeitungsvorgang erh&#228;lt wie B&#252;rgerinnen
und B&#252;rger, die am standardm&#228;&#223;igen KI-gest&#252;tzten Verwaltungsprozess teilnehmen. 
Um den unterst&#252;tzenden Charakter von KI-Systemen zu unterstreichen, m&#252;ssen zudem innerhalb der Verwaltung
geeignete und fein ausbalancierte Anreize und Sanktionen erdacht werden. Diese kommen zum Einsatz, wenn
die Entscheidung der Maschine &#252;bergangen wird &#8211; ansonsten kommt es schnell zur De-facto-Automatisierung
der Entscheidung.
2 AG 2: Smart City und Open Data875 
Einf&#252;hrung
Smart City876 steht heute einerseits f&#252;r eine ganze Reihe von Konzepten im Zusammenhang mit Urbanisierung
und Digitalisierung aller Lebensbereiche, andererseits beschreibt der Begriff auch eine konkrete
Auspr&#228;gungsform dieses Zusammenhangs. Bezugsort ist dabei der Lebensraum der Menschen, meist in Form der Stadt (bzw.
kleineren oder gr&#246;&#223;eren Einheiten, wie Kommune, Dorf oder eben auch Metropole und Metropolregion). Im
Kern geht es um umbauten Raum. 
Smart City meint im weiteren Sinne877 demnach die zunehmende Nutzung digitaler Technologien in nahezu allen
Lebensbereichen urbaner Lebensr&#228;ume &#8211; prim&#228;r in St&#228;dten, aber eben auch in Metropolregionen und im
l&#228;ndlichen Raum (vgl. etwa das Konzept digitaler D&#246;rfer, Entwicklungsagentur Rheinland-Pfalz 2017). Dabei ist also
874 Vgl. Richtlinie (EU) 2019/1024 vom 20. Juni 2019 &#252;ber offene Daten und die Weiterverwendung von Informationen des &#246;ffentlichen 
Sektors (Neufassung).
875 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion der AfD vor [Sondervotum zu Kapitel 2 der AG-Berichte der
Projektgruppe 2 &#8222;KI und Staat&#8220; (&#8222;AG 2: Smart City und Open Data&#8220;) des Abgeordneten Dr. Marc Jongen sowie der Abgeordneten Joana 
Cotar und Peter Felser].
876 Der Begriff &#8222;Smart City&#8220; geht im Kern auf das Werk &#8222;City of Bits&#8220; von Mitchell zur&#252;ck. Daraus wurden in der Beschreibung
mannigfaltige Derivate entwickelt. Bol&#237;var fasst z. B. synonyme Begriffe, wie &#8222;Intelligent Cities&#8220;, &#8222;Virtual Cities&#8220;, &#8222;Knowledge-based
Cities&#8221;, &#8222;Digital Cities&#8221; und &#8222;Information Cities&#8221; zusammen.
877 Die Bedeutung der Smart City im engeren Sinne kn&#252;pft an die Digitalisierung in den St&#228;dten insofern an, als dass hier sehr viel 
operativer auf konkrete Planungen und Zielstellungen eingegangen wird. Hier differenziert sich auch meist st&#228;rker die Abgrenzung 
z. B. zum l&#228;ndlichen Raum aus. Stadt (oder auch Metropolregionen mit einem sehr starken Stadtkern, wie z. B. Hamburg oder Berlin)
meint in dem Fall in der Tat den st&#228;dtischen Raum, h&#228;ufig vor allem Wohn-, Industrie-, Handelsgebiete sowie &#246;ffentliche und/oder
kritische Infrastruktur, Stra&#223;en und Stadtsysteme. Viel h&#228;ngt mit der Funktionsf&#228;higkeit des Systems &#8222;Stadt&#8220; zusammen (vgl.
Etezadzadeh (2015): Smart City &#8211; Stadt der Zukunft?).
nicht der Einsatz einzelner spezifischer Technologien mit Smart City gemeint, sondern ein Konglomerat bzw. 
die vernetzte Nutzung diverser Digitaltechnologien, um die Lebenssituation der Menschen in einem
Sozialverbund zu verbessern. Darunter fallen u. a. Konzepte der Elektromobilit&#228;t und der Verkehrswegesteuerung, digitale
Gesundheitsvorsorge, Nutzung von Sensorik im Rahmen des Internet of Things bzw. des Internet of Everything, 
digitale B&#252;rgerservices im Rahmen von E-Government etc. Anders als bei der rein technischen Betrachtung der
Komponente der Digitalisierung ist bei Smart-City-Konzepten zus&#228;tzlich eine soziale Komponente zu
ber&#252;cksichtigen. 
Herausragend im Kontext der Anwendung von KI in Smart Cities sind dabei einerseits sicherlich die
M&#246;glichkeiten der hohen Messbarkeit (bei geeigneter Infrastruktur) rein technischer Systeme (Stichwort IoT-basierte KI-
Systeme878) einschlie&#223;lich der damit verbundenen Steuerung in den Stadtsystemen (Energie, Verkehr, Sicherheit
etc.) sowie die Option der vereinfachten Angebote f&#252;r die Bewohnerinnen und Bewohner sowie die G&#228;ste der
Stadt (z. B. Mobilit&#228;tsplattformen). Im engeren Sinne ist die grunds&#228;tzliche Zielstellung in der Smart City klar
darauf ausgerichtet, vor allem m&#246;glichst vielen Menschen ein besseres Lebensangebot zu unterbreiten, um
gleichzeitig dr&#228;ngende Probleme und Fragestellungen (Umweltverschmutzung, Energiesteuerung, Mobilit&#228;t) je nach
Fall spezifisch zu beantworten. KI kann in diesem Zusammenhang vor allem dann hilfreich sein, wenn
entsprechende Interaktionspotenziale oder autonome Systeme gefordert sind. Dennoch, das zeigen nahezu alle
aktuelleren Studien und Untersuchungen, sind es heute (Stand 2019) noch eher die Auswertungen gro&#223;er Datenbest&#228;nde,
die als zentrale Treiber betrachtet werden.
In fast allen Bereichen finden sich heute schon erste KI-Anwendungen, die von der Bereitstellung von Realdaten
(im Gegensatz zu den in Europa aufgrund der DSGVO und anderer Gesetze h&#228;ufig verwendeten synthetischen
Daten) gerade unter Trainingsaspekten profitieren k&#246;nnen. Sie bedeuten f&#252;r diejenigen, die direkten Zugriff auf
diese Daten haben, gro&#223;e wirtschaftliche Chancen. Dabei stellt sich h&#228;ufig die Frage, wer unter welchen
Bedingungen Zugang hat oder (exklusive) Nutzungsrechte an diesen Daten h&#228;lt. 
Diese Fragen der Bereitstellung und Verf&#252;gbarkeit stellen sich dabei nicht nur f&#252;r privatwirtschaftliche Bereiche,
sondern auch f&#252;r die &#246;ffentliche Hand, denn auch hier werden gro&#223;e Datenpools bzw. Datenbanken aufgebaut.
Gerade in dem Zusammenhang stellt sich dann die Frage, in welcher geeigneten Form diese Daten der
Gesellschaft zur Verf&#252;gung gestellt werden k&#246;nnen. Das zentrale Konzept hierf&#252;r ist Open Data.
Unter Open Data werden Daten verstanden, die von jedem Menschen grunds&#228;tzlich freiverf&#252;gbar ohne
(wesentliche) Einschr&#228;nkungen genutzt werden d&#252;rfen und k&#246;nnen. Es handelt sich um Daten, die im Kern &#8222;frei&#8220; (im
Sinne der Handlungs- und Nutzungsfreiheit) sind, was nicht bedeutet, dass keine Rechte daran bestehen k&#246;nnen.
Frei bedeutet in dem Fall auch, dass grunds&#228;tzlich eine kommerzielle Weiterverarbeitung m&#246;glich ist. Typische 
Beispiele, die in diesem Kontext immer genannt werden, sind Wetter- oder Verkehrsdaten. Dies kann aber auch
in hohem Ma&#223;e f&#252;r Verwaltungsdaten oder auch sonstige Daten, die im &#246;ffentlichen Raum entstehen, gelten.
Vielfach wird Open Data daher auch mit Daten aus &#246;ffentlichen Systemen gleichgesetzt (Open-Government-
Data).
Open Data stellt zwar keine zwingende Voraussetzung f&#252;r die Entwicklung von Smart-City-Systemen an sich
dar, ist aber ein wesentlicher Faktor, um sowohl zu Entwicklungen und Innovationen als auch zu Investitionen 
anzuregen.879 Dabei geht es aber nicht nur um die wirtschaftliche Verwertung von frei verf&#252;gbaren Daten,
sondern ebenso um Transparenz, E-Partizipation, Open-Government-Kollaboration880 und um soziale Innovation, 
die die Lebensqualit&#228;t erh&#246;hen und dem Gemeinwohl dienen, aber nicht notwendigerweise rein kommerziell
entwickelt und bereitgestellt werden.
So profitieren bzw. befruchten sich z. B. technologische L&#246;sungen und Sharing-Konzepte gegenseitig. Auch
werden die M&#246;glichkeiten aktiver Partizipation durch die digitalen M&#246;glichkeiten erh&#246;ht. Es zeigt sich, dass
Smart-City-Ans&#228;tze mehr sind als das Prinzip der digitalen Stadt.881 Dar&#252;ber hinaus verspricht man sich im
Smart-City-Kontext heute vor allem &#246;kologische und Nachhaltigkeitseffekte, eine effiziente
Ressourcen&#246;konomie sowie die M&#246;glichkeiten, die Resilienz innerhalb von umbauten R&#228;umen zu steigern.882 F&#252;r die l&#228;ndlichen 
Regionen (Smart Country) spielen hingegen oft Ans&#228;tze zur Verbesserung der medizinischen Versorgung 
(E-Health), der Versorgung mit G&#252;tern oder des &#246;ffentlichen Personennahverkehrs eine wichtige Rolle. 
878 IoT: Abk&#252;rzung f&#252;r Internet of Things.
879 Vgl. auch Singh (2017): Open data 101.
880 Eine umf&#228;ngliche (&#228;ltere) Bestandsaufnahme aus Deutschland hat das Bundesministerium des Innern 2012 hierzu ver&#246;ffentlicht.
881 Vgl. Boorsma (2017): A new digital deal; Etezadzadeh (2015): Smart City &#8211; Stadt der Zukunft?
882 Vgl. Goldsmith und Crawford (2014): The responsive city und Pelton und Singh (2019): Smart Cities of Today and Tomorrow.
Fragestellungen
Vor dem Hintergrund der hier vorgenommenen Definitionen von Open Data und Smart City stellt sich die
berechtigte Frage, wie dies im Zusammenhang mit der Entwicklung des Einsatzes bzw. der Entwicklung von KI-
Anwendungen im Rahmen von Smart Cities steht.
Man sollte sich dar&#252;ber im Klaren sein, dass Smart-City-Konzepte sehr unterschiedliche Konnotationen
aufweisen k&#246;nnen. Erbst&#246;&#223;er verweist in ihrem Status-quo-Report zur Metropolregion Berlin auf die Felder Green- und
Clean-Technologien, smarte Technologien sowie urbane Technologien.883 Folgt man dieser Taxonomie auf einer
logischen Ebene, definieren sich damit auch die (sozialen) Innovationen des Smart-City-Konzeptes. Erbst&#246;&#223;er
sieht dabei zwei Treiber f&#252;r die Entwicklungen in der Ressourceneffizienz und der Re-Urbanisierung. Hieraus
lassen sich dann die jeweiligen Ziele gut ableiten, wie z. B. Klimaneutralit&#228;t oder auch die Reduktion des
Energiebedarfs. Die jeweiligen Innovationen entstehen dabei vielfach aus dem Wechselspiel der Anforderungen und
heutigen technischen M&#246;glichkeiten. Dabei sind es Energietechnologien, Verkehr, Logistik und
Mobilit&#228;tsl&#246;sungen, digitale und soziale Medien sowie Gesundheitswirtschaft. Als Grundvoraussetzung f&#252;r die Smart City wird 
dabei immer wieder die digitale Infrastruktur genannt. 
Hingegen findet man bisher kaum Hinweise auf KI als zentrale Technologie, allenfalls Verweise auf Open-Data-
Konzepte.
Smart Cities bieten aufgrund der allgemeinen hohen Dichte von Bev&#246;lkerung und Infrastruktur die M&#246;glichkeit,
in g&#252;nstigen Strukturen viele Realdaten zu gewinnen. Damit gehen allerdings Verantwortlichkeiten der
Erhebenden einher, mit denen Fragen zu Qualit&#228;tssicherung, Zugriff, Monitoring, Anonymisierung (ggf.
Pseudonymisierung) und Nutzung verbunden sind.  
Open Data er&#246;ffnen mannigfaltige Optionen f&#252;r soziale, wirtschaftliche und politische Innovationen. Gerade in
einer durch Daten getriebenen &#214;konomie ver&#228;ndert die freie Verf&#252;gbarkeit von Daten die Ausgangslage an und
in derzeit hart umk&#228;mpften M&#228;rkten. Die Barrieren f&#252;r den Markteintritt werden gesenkt und Innovationen, die
auf reale Daten bzw. sogar Echtzeitdaten setzen, erm&#246;glicht.
Open Data verspricht Nutzeneffekte f&#252;r viele Bereiche: Bildung, Mobilit&#228;t, Logistik, Konsumprodukte,
Energieversorgung, das Gesundheits- und das Finanzwesen. Mit Bezug auf das European-Data-Portal, das Open-Data-
Barometer, GovData und die Open-Data-Impact-Map sollten die Bereiche Landwirtschaft, Verwaltung,
Rechtssystem, St&#228;dte und Regionen, Wissenschaft, Polizei und Verbrechensbek&#228;mpfung, Versicherungswesen,
allgemeine Statistik sowie Land und Klimadaten erg&#228;nzt werden.884 
Diese generellen Themen fasst der Bundesverband Smart City mit seinen zentralen Clusterthemen zusammen,885 
wie z. B. Smart Mobility886, Smart Energy887, Smart Home888, Smart Lightning889, Smart Building890, Smart
883 Vgl. Erbst&#246;&#223;er (2014): Smart City Berlin, S. 8 ff.
884 Vgl. Singh (2017): Open data 101.
885 Weitere Informationen dazu unter: https://bundesverband-smart-city.org/projekt-smart-wiki (zuletzt abgerufen am: 23. Juli 2020).
886 Unter Smart Mobility werden vor allem Verkehrssysteme verstanden, die auf Basis von Verkehrsdaten den Verkehrsfluss versuchen
zu optimieren. Dazu kommen neue Mobilit&#228;tsformen und Ger&#228;te, synergetische Konzepte sowie &#246;kologische Aspekte (zum Beispiel:
Sadik-Khan und Solomonow (2017): Streetfight; Schwartz (2015): Street smart; Neckermann (2018): smart cities, smart mobility). 
Zahlreiche Beispiele finden sich im Bericht der Projektgruppe KI und Mobilit&#228;t&#8220; in Kapitel C. VI. [K&#252;nstliche Intelligenz und
Mobilit&#228;t (Projektgruppe 5)], insbesondere in Kapitel 4.1 [Zukunft der Mobilit&#228;t], Kapitel 4.2 [Intermodalit&#228;t und Plattformen] und 
Kapitel 4.3 [Stra&#223;enverkehr].
887 Mit Smart Energy werden Konzepte verbunden, die sowohl im Kontext der Energiegewinnung, -verteilung als auch -steuerung liegen.
888 Mit dem Smart-Home-Ansatz verbunden sind vor allem Technologien, die im privaten Umfeld angesiedelt sind, seien es intelligente 
Wohnungssteuerungen von Licht, W&#228;rme oder Strom oder auch der gesamte Entertainmentbereich. Aus technischer Perspektive 
fallen hierunter zus&#228;tzlich die Fragen der Konnektivit&#228;t und der Nutzung der Daten im h&#228;uslichen Bereich.
889 Smart Lightning bedeutet, dass sich Lichtanlagen intelligent steuern lassen, was heute schon vielfach der Fall ist. Gemeint sind dabei
aber nicht nur einfache Lichtsteuerungsanlagen zur Senkung des Energieverbrauchs, sondern auch die Frage der Gestaltung einer
Smart City. Mumtaz et al. z. B. beziehen sich ganz konkret auf die Fragen der (Geb&#228;ude-)Sicherheit und zeigen, wie hier neuronale
Netzwerke zur Steigerung der Sicherheit beitragen k&#246;nnen. Bekannt ist dar&#252;ber hinaus, dass Beleuchtung in Stra&#223;en zu deutlich
geringeren Einbruchsdelikten f&#252;hrt (vgl. Mumtaz et al. (2018): An Automation System for Controlling Streetlights and Monitoring 
Objects Using Arduino).
890 Smart Building steht f&#252;r einen Zweig der Architektur und des Bauingenieurswesens, welcher sich sowohl mit Fragen technischer
Infrastruktur, &#8222;intelligenten Materialien&#8220; als auch KI-basierten Sensortechnologien in der Steuerungs- und Regelungstechnik befasst.
Waste891, Smart Health892, Smart Country893 oder auch Smart Learning894, die sich als Themenbl&#246;cke im Konzept
der Smart City (dem Wohn-, Arbeits- und Lebensraum der Menschen) in sehr unterschiedlichen Auspr&#228;gungen
spiegeln.
Open Data gilt gerade im Smart-City-Kontext als einer der Erfolgsschl&#252;ssel, um die vielen neuen
Anwendungsfelder sowohl gesellschaftlich als auch wirtschaftlich zu erschlie&#223;en. Dies beinhaltet die Entwicklung und
Anwendung von KI in Smart Cities.
Es ist klar, dass Open Data als Chance f&#252;r den Einsatz von KI zu sehen ist. Diese Daten sind jedoch nur von Wert
und k&#246;nnen Grundlage f&#252;r positive Effekte f&#252;r eine Stadt sein, wenn die Qualit&#228;t der Daten hoch genug ist. 
Dar&#252;ber hinaus muss neben der rechtlichen auch die technische Verf&#252;gbarkeit auf hohem Niveau sichergestellt
werden. Ben&#246;tigt werden dazu entsprechend ausgebildetes Personal sowie geeignete Infrastrukturen, die heute
l&#228;ngst nicht in allen St&#228;dten in Deutschland in ausreichender Form zur Verf&#252;gung stehen. Hier ist die Politik
aufgefordert, durch Investitionen am Arbeitsmarkt durch Aus-, Fort- und Weiterbildung schnell Abhilfe zu
schaffen. 
Oft bleibt allerdings unklar, ob die Bereitstellung von Open Data den gew&#252;nschten Effekt auf Wirtschaft und 
Gesellschaft erzeugt. Das generelle Ziel soll und muss lauten, dass Open Data eine hohe Priorit&#228;t genie&#223;t, damit
KI-Systeme in und aus Deutschland auf Basis von Realdaten trainiert werden k&#246;nnen. Es gilt abzuw&#228;gen, welche
Daten der Staat oder im konkreten Anwendungsfall die Smart Cities offenlegen wollen und sollen. Zielstellung 
ist es, so viele Daten wie m&#246;glich verf&#252;gbar zu machen. Ebenfalls ist zu &#252;berpr&#252;fen, ob und inwiefern die Systeme
zur Resilienz sowie Nachhaltigkeit der Stadt beitragen.
Zuk&#252;nftig stellt sich in dem Zusammenhang die Frage, ob &#8211; wenn Open Data als Trainingsdaten f&#252;r KI-Systeme
genutzt werden &#8211; dann auch die Algorithmen bzw. der Code der KI-Systeme als Open Source zur Verf&#252;gung
stehen sollte, dies w&#228;re konsequent, wenn man dem &#8222;Open&#8220;-Gedanken folgt. Im Zusammenhang damit steht
dann auch die Frage, ob im Umkehrschluss Daten, die mit mit Open-Source-Systemen erhoben wurden, auch
unter die Lizenz fallen sollten und entsprechend als Open Data zur Verf&#252;gung zu stellen sind. 
Thematischer Schwerpunkt
Status quo
Es gibt heute bereits sehr viele Smart-City-Fallbeispiele. Vor allem international wird neben den chinesischen
Megacitys immer wieder auf Wien895, Barcelona896, Singapur897, Moskau898, New York City899 oder San
Francisco900 verwiesen. Allerdings fehlen in diesem Zusammenhang oft spezifische Darstellungen mit Bezug zu KI.
Dieser l&#228;sst sich mittelbar aber h&#228;ufig ableiten, da die meisten Systeme grunds&#228;tzlich eine hohe Kompatibilit&#228;t
mit KI-Systemen aufweisen.
891 Gerade in der M&#252;llentsorgung und Reststoffverwertung haben in den letzten Jahren Smart-Waste-Technologien erheblich an
Bedeutung gewonnen. Dies reicht von intelligenten Sortiersystemen &#252;ber M&#252;llcontainer, die mit Sensortechnologien ausgestattet sind, bis
hin zur Routenoptimierung.
892 Smart Health oder E-Health ist ein gro&#223;er eigener Sektor. Im Rahmen der Gestaltung von Smart Cities spielt der Gesundheitssektor
nat&#252;rlich eine besondere Rolle. Verschiedene Anwendungsbeispiele finden sich im Bericht der Projektgruppe KI und Gesundheit&#8220; in 
Kapitel C. VI [K&#252;nstliche Intelligenz und Gesundheit (Projektgruppe 3)], inbesondere im Kapitel 3 [Anwendungen von KI in
Gesundheit und Pflege].
893 Smart Country hat, &#228;hnlich wie Smart City zwei Bedeutungen.
894 Smart Learning steht hier sinnbildlich f&#252;r die Bildung in der Smart City. Darunter fallen zahlreiche Konzepte der digitalen Bildung.
Beispiele finden sich in den Kapiteln 3.2.2 [Beispiele f&#252;r KI-Anwendungen in Schule und Hochschule] und 5.2 [KI in der Bildung]
des Berichts der Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220;.
895 Vgl. Wien Holding GmbH: Smart City Wien und Bertelsmann Stiftung: Stadtplanung der Zukunft in der Smart City Wien.
896 Vgl. Urban Hub (2018): Smart City 3.0 &#8211; Fragen Sie Barcelona nach der n&#228;chsten Generation von Smart City und Albers (2018):
Wie Barcelona eine offene &#8222;Smart City&#8220; im Dienste des Gemeinwohls plant.
897 Vgl. Friedrich Ebert Stiftung (2018): Smart City Singapur und Gropp (2018): Singapur ist f&#252;hrende &#8222;Smart City&#8220;.
898 Vgl. Novak (2018): Smart City Moskau: Architektur der Vernetzung und Schayani (2018): Moskau: Smart City.
899 Vgl. Smart Cities New York (2018): Smart Cities New York, Tobias (2018): How New York is becoming a smart city und Pandit 
(2019): It&#180;s time for NYC to enhance its smart city status.
900 Vgl. San Francisco (2016): Smart City San Francisco; Highfield (2018): Sensors, Scandal And Sustainability: Inside The San
Francisco Smart City Being Built From Scratch On An Abandoned Naval Yard.
In Deutschland gelten mit Berlin, K&#246;ln, M&#252;nchen und vor allem Hamburg901 die gr&#246;&#223;ten St&#228;dte als
Vorreiterst&#228;dte, wenn es um Smart Cities geht. Dennoch kann man bei keiner dieser St&#228;dte bisher ein Fokus-Thema KI
als Kern der Smart-City-Strategie erkennen.902 Daher ist auch eine Fallstudie einer einzelnen Metropole bzw. der
Metropolregion nicht sinnvoll. In einer Erhebung aus dem Januar 2018903 wurden 200 St&#228;dte mit jeweils &#252;ber
50 000 Einwohnerinnen und Einwohnern in Deutschland untersucht. Insgesamt hatte ein Drittel der untersuchten 
St&#228;dte Smart-City-Strategieans&#228;tze aufzuweisen.904 Fasst man die empirischen Ergebnisse der Studie zusammen, 
kommt man zum Schluss, dass KI heute noch keine oder kaum eine Rolle im Kanon der Smart-City-Strategien
und -Umsetzungen in Deutschland spielt. 
KI-Systeme werden heute eher in Pilotversuchen eingesetzt, so etwa bei der Stadtplanung905 und
Immobilienbewirtschaftung906, bei Kommunikation mittels Chatbots907, bei Mobilit&#228;t, Transport908 und Verkehr909. Die
Dokumentation von Erfahrungswerten und Daten ist rar. Daher ist eine konkrete Messung von Erfolg anhand konkreter
Kriterien im Jahr 2019 noch wenig zielf&#252;hrend, u. a. da es keine (spezifischen) Referenzdaten gibt.910 
Der Markt f&#252;r Smart-City-Anwendungen und -L&#246;sungen w&#228;chst kontinuierlich. Dabei handelt es sich aber eben
nicht um einen traditionellen Markt, dessen Volumen pr&#228;zise in Gelddimensionen ausgedr&#252;ckt werden kann, da
die Zuschreibung einzelner Felder im Gesamtkontext unm&#246;glich erscheint. Die bisherigen Ausf&#252;hrungen greifen
bewusst keine Marktprognosen auf, da hier &#8211; je nach Zurechnung &#8211; sehr gro&#223;e Schwankungen vorliegen.
Ungef&#228;hre Sch&#228;tzungen liegen heute bei einem Weltmarkt von 100 Milliarden US-Dollar f&#252;r Smart-City-
Anwendungen.911 Innerhalb der n&#228;chsten drei Jahre wird mit einer Verdopplung der Ausgaben gerechnet.
Die strikte Aufgabentrennung zwischen Bund, Land und Stadt/Kommune schafft bei der Implementierung von 
Smart-City-L&#246;sungen komplexe Herausforderungen. Integrierte L&#246;sungen erfordern ein koordiniertes Vorgehen.
&#220;bergreifende Konzepte f&#252;r Governance-Strukturen machen deshalb ein wichtiges Bedarfsfeld der Smart Cities
aus. Aufgrund der vertikalen Machtverteilung m&#252;ssen in Deutschland alle beteiligten &#246;ffentlichen Akteure, aber
auch die privaten Investoren eingebunden werden. Ein spezielles Bundesf&#246;rderprogramm im Bereich Smart
Cities und Smart Countries, das gezielt eine solche strategische Herangehensweise und Umsetzung der
Digitalisierung in Kommunen im Sinne der integrierten Stadtentwicklung unterst&#252;tzen w&#252;rde, gibt es nach Auskunft der
Bundesregierung bisher nicht.912 
Die Smart-City-Forschung ist einerseits als weit fortgeschritten zu bezeichnen und andererseits stark heterogen
und interdisziplin&#228;r gepr&#228;gt. Aus technischer Sicht werden dabei in j&#252;ngerer Zeit auch die Verkn&#252;pfungen von
901 Vgl. Hampel (2019): Smart City Index 2019: Wie digital sind Deutschlands St&#228;dte? und B&#252;ttgen (2019): Smart City Index: Hamburg
ist die smarteste Stadt Deutschlands.
902 Theoretisch h&#228;tte man an dieser Stelle auch auf international gut dokumentierte Referenzf&#228;lle (z. B. in Herzberg im Jahr 2017)
verweisen k&#246;nnen. Allerdings zeigt sich, dass auch hier bisher keine F&#228;lle von Smart-City-Strategien mit einem Schwerpunkt KI
dokumentiert wurden. Lediglich Einzelanwendungen werden mehrfach thematisiert.
903 Vgl. Soike und Libbe (2018): Smart Cities in Deutschland &#8211; eine Bestandsaufnahme.
904 Bei St&#228;dten unter 100 000 Einwohnerinnen und Einwohnern treten Smart-City-Strategien eher in Form von Einzelprojekten auf, bei
St&#228;dten &#252;ber 100 000 Einwohnerinnen und Einwohnern steigt die Anzahl der St&#228;dte mit einer umfassenderen Smart-City-Strategie
rapide an. Bei &#252;ber 250 000 Einwohnerinnen und Einwohnern hat nahezu jede Stadt zumindest einige Teilbereiche einer Smart-City-
Strategie aufzuweisen. Mit zunehmender Einwohnerzahl steigt die Wahrscheinlichkeit, dass eine Stadt sich dem Thema intensiv
widmet. Im Mittelpunkt stehen einerseits Multi-Stakeholder-Ans&#228;tze sowie multi-thematische Projekte. Viele gr&#246;&#223;ere Projekte
wurden bzw. sind dabei in der Verwaltung verankert. Ambitioniertere Ans&#228;tze oder auch Ans&#228;tze bei kleineren Kommunen und
Gemeinden werden h&#228;ufig als Pilotprojekte mit kleinerem Ma&#223;stab geplant. Der Umsetzungsstand geht &#252;ber die in den 1990er- und 2000er-
Jahren implementierten reinen IKT-L&#246;sungen (IKT = Informations- und Kommunikationstechnik) hinaus. Schwerpunkte wurden 
deutlich bei der Verwaltung (E-Government) sowie dem Strukturausbau gesetzt. Vorreiter und Pilotprojekt hierf&#252;r war in
Deutschland Friedrichshafen (2007&#8211;2015). Kernziele sind heute einerseits Klima- und andererseits Energieziele, wobei diese Kernziele im
Wesentlichen im Jahr 2030 umgesetzt werden sollen. Als qualitative Ziele werden daneben angegeben: die Verbesserung der
Standort- und Lebensqualit&#228;t, der Erhalt der Innovations- und Wettbewerbsf&#228;higkeit sowie die Erh&#246;hung der Energie- und
Ressourceneffizienz.
905 Vgl. HafenCity Universit&#228;t Hamburg: CityScienceLab, eine Kooperation mit dem MIT Media Lab.
906 Vgl. Hunziker (2019): Wenn deine Stadt wei&#223;, wo du bist.
907 Vgl. smart-city-berlin.de (2019): Berlin ist Vorreiter f&#252;r K&#252;nstliche Intelligenz in Deutschland.
908 Vgl. Wiegand (2019): KI f&#252;r Smart Cities.
909 Vgl. Internationales Verkehrswesen (2019): Smart City: K&#252;nstliche Intelligenz f&#252;r die Mobilit&#228;t von morgen.
910 In einer erweiterten Perspektive allerdings k&#246;nnten Referenzen in den Bereichen Energie- und W&#228;rmeversorgung vorliegen (z. B. bei
Stadtwerken oder auch gr&#246;&#223;eren Anbietern). Dokumentierte F&#228;lle gibt es allerdings bislang nicht.
911 Vgl. Research and Markets (2019): Worldwide Smart City Platforms Market Analysis, 2019-2023 &#8211; Government Initiatives for Smart
Cities Presents Lucrative Opportunities.
912 Antwort der Bundesregierung auf die Kleine Anfrage der Fraktion DIE LINKE. auf Bundestagsdrucksache 19/1221.
Smart Cities und z. B. Anwendungen im Kontext des Internet of Things st&#228;rker behandelt, was in diesem
Zusammenhang sowohl unmittelbar als auch mittelbar Br&#252;cken zur KI-Forschung bietet. &#196;hnliches gilt f&#252;r &#246;konomisch 
gepr&#228;gte Forschung auf dem Gebiet, wobei sehr h&#228;ufig Fragen des Konsums in St&#228;dten in den Mittelpunkt
ger&#252;ckt werden. Die Richtung der Forschung ist also h&#228;ufig mitentscheidend f&#252;r die behandelten Schwerpunkte.
Wenn es z. B. im Rahmen von stadtplanerischen &#220;berlegungen h&#228;ufig technische Infrastruktur und soziologische
&#220;berlegungen sind, f&#228;llt die Forschung aus technischer Sicht deutlich anders aus und geht eher in Richtung von
Machbarkeiten.
Hinsichtlich der Forschung zu KI er&#246;ffnen sich neue Felder und Terminologien. Sinnbildlich hierf&#252;r steht z. B. 
der Begriff &#8222;Cognitive City&#8220;913, der Konzepte der Smart City mit dem Lernen verbindet.
Die politische Bedeutsamkeit von Open Data f&#252;r Smart Cities zeigt sich schon seit vielen Jahren in
entsprechenden Berichten, Studien und Dokumentationen, z. B. der Bundes-914 oder Landesministerien. Auch die explizite
Thematisierung im Ersten Gesetz zur &#196;nderung des E-Government-Gesetzes915 (h&#228;ufig auch als Open-Data-
Gesetz bezeichnet) und die bis zum Jahr 2021 umzusetzende Open-Data-Richtlinie der EU veranschaulichen die
hohe politische Bedeutung des Themas. 
In vielen St&#228;dten und Gemeinden stehen daf&#252;r aber h&#228;ufig weder die finanziellen und infrastrukturellen Mittel
noch das geeignete Personal zur Verf&#252;gung. Anreize, wie z. B. Transparenz gegen&#252;ber den B&#252;rgerinnen und
B&#252;rgern oder auch die Legitimationsfunktion durch die datenm&#228;&#223;ige Offenlegung politischer Entscheidungen,
k&#246;nnen aber durchaus f&#252;r die Entscheidungstr&#228;ger als politisches Kapital und Investition in die Digitalisierung
bewertet werden.
In der politischen Entwicklung treffen unterschiedlichste Ebenen mit unterschiedlichsten Voraussetzungen
aufeinander. Dies gilt sowohl f&#252;r die vorhandene Struktur als auch die Vorstellungen und das Vorwissen der
handelnden Akteure. Der erkl&#228;rte politische Wille ist in vielen Bereichen einerseits recht hoch, andererseits aber
zeigen sich gro&#223;e Defizite, wenn es darum geht, die Vorstellungen und Ma&#223;nahmen zu realisieren. Dabei sind es
neben der fehlenden Breitbandinfrastruktur vielfach auch finanzielle Grenzen, die dazu f&#252;hren, dass bestimmte
Anwendungsfelder zwar denkbar, aber in vielen F&#228;llen bisher nicht umsetzbar sind. 
Die Bundesregierung widmet sich inhaltlich ebenfalls dem Thema Smart City und untermauert es durch konkrete
Formulierungen in ihrem Koalitionsvertrag. Es werde ein Bundesprogramm &#8222;Smarte Modellregionen&#8220; aufgelegt,
welches insbesondere l&#228;ndliche Regionen und mittlere St&#228;dte in den Fokus r&#252;ckt.916 Das BMI f&#246;rdert in diesem
Zusammenhang 13 Smart-City-Modellprojekte seit Herbst 2019.917 Damit einhergehend solle der
Erfahrungsaustausch in Form eines &#8222;Smart-City-Dialogs&#8220; ausgebaut werden. Insgesamt sollen so in vier Umsetzungsstaffeln
insgesamt rund 50 Modellprojekte gef&#246;rdert werden.918 
Das Beispiel Paderborn und andere Beispiele
Nachfolgend werden am Fallbeispiel der Stadt Paderborn exemplarisch Chancen und Herausforderungen der
Nutzung von Open Data im Kontext von KI-basierten Smart-City-Anwendungen aufgezeigt. 
Die Stadt Paderborn m&#246;chte lokale, anonymisierte Daten in einem Open-Data-Portal zusammenf&#252;hren und
kostenlos bereitstellen, um damit sowohl Transparenz in st&#228;dtischen Entscheidungsprozessen zu schaffen und die
B&#252;rgerbeteiligung zu f&#246;rdern als auch Grundlagendaten f&#252;r Wirtschaft und Stadtentwicklung anzubieten. Dazu
wird der Plattform ein Open-Data-Cockpit vorgeschaltet, welches der Anwenderin oder dem Anwender eine
Benutzeroberfl&#228;che bereitstellt, um die Daten auch sinnvoll mit h&#246;chstm&#246;glicher Anwendungsfreundlichkeit zu
visualisieren, zu erheben und zu analysieren. 
Dabei ist eine der gr&#246;&#223;ten Herausforderungen der Digitalisierung, die immer gr&#246;&#223;er werdenden Datenmengen
aktuell zu halten, zu strukturieren und intelligent zu verkn&#252;pfen, damit sie in Echtzeit wertvolle Grundlage f&#252;r
Entscheidungen und neue Gesch&#228;ftsmodelle sein k&#246;nnen. KI ist in der Lage, derart riesige Datenmengen schnell
913 Portmann et al. (2019): Designing Cognitive Cities.
914 Vgl. Bundesministerium des Innern, f&#252;r Bau und Heimat: Open Data.
915 Gesetz zur F&#246;rderung der elektronischen Verwaltung (E-Government-Gesetz &#8211; EGovG). Vgl. auch Bundestagsdrucksache 18/11614 
und 18/12406, vgl. auch Bundesministerium des Innern, f&#252;r Bau und Heimat: E-Government-Gesetz.
916 Vgl. CDU, CSU, SPD (2018): Ein neuer Aufbruch f&#252;r Europa. Eine neue Dynamik f&#252;r Deutschland Ein neuer Zusammenhalt f&#252;r
unser Land, Zeile 2118.
917 Vgl. Bundesministerium des Innern, f&#252;r Bau und Heimat (2019): Auftakt f&#252;r erste Staffel Modellprojekte Smart Cities.
Wissenstransfer soll in die Breite wirken.
918 Vgl. Presse- und Informationsamt der Bundesregierung (2020): Digitale Stadtentwicklung und F&#246;rderung von Smart Cities.
und effizient zu katalogisieren, zu analysieren und zu durchsuchen, sodass einzelne Dokumente und
Informationen mit geringem Aufwand zu finden sind. KI kann somit helfen, die digitale Basis einer Stadt zu verwalten.
Insbesondere im Bereich der Meta-Daten soll der Einsatz von KI in Paderborn getestet werden. Ein aktueller
Anwendungsfall, der in Paderborn hinsichtlich des Einsatzes von KI verfolgt wird, ist das Parkraum-
Management. Hier werden historische Daten und Rahmenparameter von der KI ausgewertet, um auf deren Basis
Trendanalysen und Prognosen abzuleiten.
Die systematische Anwendung von KI in den &#246;ffentlichen Verwaltungen stellt jedoch eine sehr gro&#223;e
Herausforderung dar, denn n&#246;tig sind daf&#252;r neben einer einheitlichen IT-Infrastruktur ein funktionierender
Datenaustausch und einheitliche, fl&#228;chendeckende Datenformate. Dazu reicht es nicht aus, dass alle relevanten Dokumente
einer Verwaltung digitalisiert sind, sondern die betreffenden Arbeitsprozesse m&#252;ssen zun&#228;chst optimiert werden.
Das macht tiefgreifende strukturelle Ver&#228;nderungen in den Verwaltungen notwendig, die historisch bedingt
hierarchisch und in &#196;mtern organisiert und bisher nicht fl&#228;chendeckend projektorientiert arbeiten. IT-Insell&#246;sungen
(und zahlreiche dezentrale Rechenzentren), die &#252;ber Jahrzehnte gewachsen sind, erschweren dar&#252;ber hinaus ein
&#252;bergreifendes Zusammenwirken von Prozessen. 
Zus&#228;tzlich unterliegt auch die Verwaltung immer komplexer werdenden gesetzlichen Datenschutz- und
Datensicherheitsbestimmungen sowie dem Vergaberecht.
Insgesamt l&#228;sst sich sagen, dass die deutschen St&#228;dte im Hinblick auf Open Data unterschiedliche Schwerpunkte
gesetzt haben. W&#228;hrend f&#252;r M&#252;nchen ein Schwerpunkt auf die wirtschaftliche Nutzung von Daten (Smart-Data-
Management) gelegt wurde, haben z. B. Wolfsburg, Stuttgart oder Ingolstadt einen Mobilit&#228;tsschwerpunkt. 
Grunds&#228;tzlich gilt dabei ein technologieaffines Umfeld als beg&#252;nstigender Faktor. 
Vorgehen
Wie beschrieben, sind Open-Data-Strategien von St&#228;dten und Regionen ein wichtiger Faktor, um KI-basierte 
Smart-City-Konzepte umsetzen zu k&#246;nnen.
Als wesentliche Hemmfaktoren f&#252;r mangelnde oder fehlende Open-Data-Strategien werden vor allem B&#252;rokratie
bzw. Verwaltungsroutinen, allgemeine N&#228;herungs&#228;ngste, Zugangsbarrieren und die M&#246;glichkeit, mit den
hochdynamischen Ver&#228;nderungen und Entwicklungen Schritt zu halten, benannt. Als Voraussetzung betonen St&#228;dte
auch den Auf- und Ausbau der IKT-Infrastrukturen (Netze, Daten, Steuerung). Die Steuerung und Leitung wird
meist durch Leitungsgremien f&#252;r die Projektkoordination vorgenommen. Die Einzelprojekte werden hingegen
meist privatwirtschaftlich oder in Public-private-Partnerships vorangetrieben und die Kommunen begleiten
lediglich den Verlauf. 
Politisch gilt es noch pr&#228;ziser als bisher den Zusammenhang von Open Data, KI und Smart Cities hier in seiner
Zielstellung zu benennen. Politisch ist es sicherlich w&#252;nschenswert, dass, wenn &#246;ffentliche Gelder in die
Entwicklung von St&#228;dten im Smart-City-Kontext (z. B. die F&#246;rderausschreibungen des BMI im Jahr 2019) flie&#223;en,
eine entsprechende Vergabevoraussetzung besteht, die die Empf&#228;nger zur Entwicklung und Umsetzung einer
lokalen Open-Data-Strategie verpflichtet.
Mit einer Open-Data-Strategie verbunden sein sollten Verpflichtungen zur Eintragung in die entsprechenden
Datenbanken sowie zur zentralen oder lokalen Bereitstellung der Rohdaten, die maschinenlesbar abgerufen werden
k&#246;nnen. Sollten die Daten lokal verwaltet werden, sollte dabei sichergestellt sein, dass die entsprechende
Kommune, Stadt oder Metropolregion einen &#8222;Chief Data-Scientist&#8220; besch&#228;ftigt, der die Verf&#252;gbarkeit und Qualit&#228;t
sicherstellt, sowie missbr&#228;uchliche Verwendung beobachtet, erkennt und entsprechend handelt. Weitere wichtige
Voraussetzungen sind die Kl&#228;rung der Nutzungsrechte und die zur Verf&#252;gung stehenden Lizenzierungsformate,
verbunden mit der schon erw&#228;hnten Fragestellung der Sekund&#228;rwirkung auf verwendete Software.
Neben rechtlichen ergeben sich zahlreiche technische Fragen. Insbesondere die Formate sind hier von Bedeutung.
Die Standardisierung von Datenformaten ist ebenso von Bedeutung wie die Nutzung der Software zur
Auswertung. Ohne die Forschungsbreite der Data-Sciences an sich ansprechen zu wollen, gelten nat&#252;rlich viele
Fragestellungen, die auch f&#252;r die generelle Forschung zu Daten zutreffen, auch f&#252;r Open Data. Eine spezifische
Forschung zum Zusammenhang zwischen Open Data und KI-Systemen ist hingegen bisher nicht etabliert. Dies
k&#246;nnte aber gerade vor dem skizzierten Hintergrund der bisherigen &#220;berlegungen aus Sicht der Wirtschafts-, 
Sozial-, Verhaltens- und Kulturwissenschaften besonders relevant werden, sieht man den hohen Einfluss, den
KI-Systeme hier im t&#228;glichen Leben entfalten k&#246;nnen. Daher w&#228;ren sowohl Begleit- als auch
Technologiefolgenabsch&#228;tzung wichtig.
M&#246;glich und w&#252;nschenswert w&#228;ren Langfristdaten, die im Rahmen von Zeitreihenanalysen erlauben, Einfluss-
Faktoren &#252;ber die Zeit zu errechnen, also Smart Cities motivieren, &#252;ber Open-Data-Modelle deren Referenzdaten
Dritten zug&#228;nglich zu machen. 
Ein konkreter Fall w&#228;re z. B., wenn die Smart-City-Strategie einer Stadt in der Reduktion der
Umweltverschmutzung liegen w&#252;rde,919 dann sollten bei gezieltem Einsatz entsprechender KI-Systeme &#252;ber die Zeit die
gemessenen Parameter (z. B. Luftwerte, Wasserverschmutzung etc.) signifikant bessere Werte aufweisen. Es m&#252;sste sich
dann auch zeigen, dass die Werte bei einer verbesserten Leistungsf&#228;higkeit der KI-Systeme nochmals signifikant
besser werden. Dieses Modell funktioniert allerdings nur dann, wenn vorher die Vergleichswerte bekannt sind,
auf die es ankommt. Diese lassen sich jedoch insofern nicht verallgemeinern, als es sich gerade bei Smart-City-
L&#246;sungen um sehr (Stadt-)individuelle L&#246;sungen handelt, die entsprechende strategische &#220;berlegungen
voraussetzen.
Der Erfolg von Smart-City-Strategien wird aber nicht nur von der Verf&#252;gbarkeit von Daten abh&#228;ngen. Ebenso
definiert sich dieser Markt durch Datenqualit&#228;t und marktlich verwertbare Leistungen (inklusive real
existierender Nachfrage und Monetarisierbarkeit etc.). Momentan ist oft unklar, welche Anbieter auf welche Arten von
Open Data zugreifen, da kein regelm&#228;&#223;iges Monitoring stattfindet. W&#252;nschenswert w&#228;re ein
Informationsaustausch mit kommerziellen Anbietern zu der Frage, welche Open-(Government-)Data zu kommerziellen Zwecken
genutzt werden. Dies ist insbesondere auch vor dem Hintergrund der Ressourceneffizienz sinnvoll, da durch die
verl&#228;ssliche Bereitstellung von Open Data entsprechende Kosten f&#252;r die Gemeinschaft entstehen, die sich aus
Technologie, Energie und Personalkosten zusammensetzen.
Da Open Data keiner Zugangsbeschr&#228;nkung unterliegt, k&#246;nnen diese weltweit genutzt werden. F&#252;r die
Entwicklung des KI-Standortes Deutschland bzw. Europa wird es dabei wichtig sein, dass unter den Aspekten einer
digitalen Souver&#228;nit&#228;t von Staat und Gesellschaft entsprechende internationale Abkommen getroffen werden,
damit das &#8222;Level Playing-Field&#8220; erhalten bleibt.920 
Handlungsempfehlungen und Operationalisierung
Ausbau der nationalen Open Data-Plattform GovData
Es gelten die &#252;bergeordneten Handlungsempfehlungen in Kapitel 1 [Kurzfassung des Projektgruppenberichts] 
und Kapitel 3 [Handlungsempfehlungen] dieses Projektgruppenberichts. Die Enquete-Kommission empfiehlt
dem Deutschen Bundestag weiterhin f&#252;r den Abschnitt &#8222;Smart City und Open Data&#8220; Folgendes:
Daten der &#246;ffentlichen Hand sollten der &#214;ffentlichkeit im Rahmen der rechtlichen Begrenzungen (vgl.
Informationsfreiheitsgesetz) uneingeschr&#228;nkt zur Verf&#252;gung stehen. Um die Verf&#252;gbarkeit der Daten der &#246;ffentlichen
Hand &#252;ber Ressort- und Beh&#246;rdengrenzen hinweg ebenso wie f&#252;r Wirtschaft und Zivilgesellschaft zu verbessern,
wird die Einrichtung eines Open-Data-Instituts angeregt, das die Verwaltungen bei der Erstellung von Konzepten 
f&#252;r Data-Governance und bei der Offenlegung von Daten unterst&#252;tzt. Um &#246;ffentliche Daten systematisch zum
Training von KI-Systemen zur Verf&#252;gung zu stellen, sollte die nationale Open-Data-Plattform GovData
ausgebaut werden. Die zur Verf&#252;gung gestellten Daten sollten hohe Qualit&#228;tsstandards aufweisen und rechtlich auch
f&#252;r kommerzielle Zwecke nutzbar gemacht werden. F&#252;r KI besonders geeignete Datens&#228;tze sollten dabei
gesondert gekennzeichnet sein. Zur Erh&#246;hung von Nutzbarkeit und Akzeptanz sollten wo m&#246;glich auch
Beispielanwendungen ver&#246;ffentlicht werden, die als Open Source zur Verf&#252;gung stehen. 
Gezielte F&#246;rderung von KI-Projekten, die auf Open Data setzen
Um das gesellschaftliche und wirtschaftliche Potenzial zu heben, das durch die Bereitstellung von Open Data
potenziell entsteht, sollten KI-Projekte, die auf Open Data aufsetzen und daf&#252;r den Code als Open Source bzw.
als frei verf&#252;gbare Anwendung zur Verf&#252;gung stellen, finanziell und ideell gef&#246;rdert werden.
Pr&#228;zisierung und Erweiterung des Rechtsrahmens f&#252;r Open Data
Das Open-Data-Gesetz sollte dahingegen weiterentwickelt werden, dass noch offene Verwertungs- und
Rechtefragen gekl&#228;rt werden, die unter diese Regelungen fallen. Dies gilt insbesondere f&#252;r den Anwendungsfall von
KI-Systemen, bei dem die Daten nicht Bestandteil einer Softwarel&#246;sung werden, sondern lediglich zum Training 
benutzt werden. Neben einem Open-Data-Gesetz, das die Nachnutzung von verf&#252;gbaren Inhalten kl&#228;rt, sollte
919 Die Stadt K&#246;ln verfolgt dies mit ihrer Smart-City-Strategie (vgl. Bolz et al. (2019): Smart City Cologne).
920 Vgl. International Data Corporation, 4. September 2019.
aber auch der Rechtsrahmen f&#252;r den Zugang zu solchen Daten im Besitz und der Obhut von staatlichen
Einrichtungen und Einrichtungen der &#246;ffentlichen Daseinsvorsorge geschaffen werden. Dabei sollen auch ethische
Grunds&#228;tze eine besondere Rolle spielen. 
F&#246;rderung der Erforschung von Best Practices zum Einsatz von KI in Smart Cities
In Deutschland werden noch relativ wenig spezifische KI-Systeme f&#252;r Smart Cities angeboten. Gleichzeitig ist
die Vielfalt deutscher St&#228;dte z. B. in Bezug auf ihre Bev&#246;lkerungsdichte, Fl&#228;che oder Lage aber enorm und meist
nicht vergleichbar mit den Mega-St&#228;dten Asiens, die KI-Systeme schon vermehrt nutzen. Deshalb ist es
notwendig, Forschungs- und Transferf&#246;rderung zur Verf&#252;gung zu stellen, um L&#246;sungen f&#252;r deutsche St&#228;dte zu
entwickeln, die &#252;ber den Rahmen der Entwicklung reiner E-Government-L&#246;sungen hinausgehen. 
Sichere, leistungsstarke und robuste digitale Infrastruktur schaffen
Damit die gew&#252;nschten Effekte zur Verbesserung der Lebensqualit&#228;t der Menschen durch den Einsatz von KI-
Technologien im Smart-City-Kontext sichergestellt werden k&#246;nnen, bedarf es einer sicheren, leistungsstarken
und robusten digitalen Infrastruktur. Ein hochleistungsf&#228;higes Breitbandnetz, Mobilfunksysteme, aber auch eine
gut gesch&#252;tzte Infrastruktur gegen Hacking und Angriffe auf Systeme und Daten sind eine nicht verhandelbare
Voraussetzung. 
Klarerer, harmonisierter Rechtsrahmen zum Einsatz von KI in Smart Cities
Es sollen ein regulativer und organisatorischer Rahmen geschaffen und des Weiteren Normen und
Technologiestandards entwickelt werden, die zumindest verbindlich f&#252;r Europa gelten. Die auf EU-Ebene geltende DSGVO
verhindert in vielen F&#228;llen ein Training von KI-Systemen mit Realdaten. Im Smart-City-Kontext, insbesondere
in Verbindung mit Open Data, besteht dieser Nachteil au&#223;ereurop&#228;ischer Entwicklerinnen und Entwickler von
KI-Systemen nicht. Daher ist es wichtig, hier schnell und zielstrebig die Grundlagen zu schaffen, sodass sich
europ&#228;ische Standards hinsichtlich der Nutzbarkeit der Realdaten zu Trainingszwecken etablieren.
Schaffung spezifischer Bildungsangebote im Bereich KI und Smart Cities
Am Arbeitsmarkt sind Arbeitskr&#228;fte rar, die diese Systeme entwickeln oder gezielt nutzen und verbessern
k&#246;nnen. Dazu braucht es sowohl Informatikerinnen und Informatiker als auch Datenwissenschaftlerinnen und -
wissenschaftler, die sich mit der komplexen Materie der Steuerung sozio-technischer Systeme im Kontext von KI-
Applikationen auskennen.921 
Forschung zu Stadtplanung und Entwicklung zum Einsatz von KI
Die Forschung soll gest&#228;rkt werden, um schneller Referenzdaten und konkrete Erfahrungswerte zu sammeln
sowie geeignete Mess- und Erfolgsparameter zu erheben und zu &#252;berpr&#252;fen. Um hier explizit die Forschung
voranzutreiben, sollten Forschungsinstitutionen mit einem spezifischen Erforschungsauftrag zur Erfassung und
Analyse internationaler, KI-spezifischer Anwendungen beauftragt werden. Dies w&#252;rde nachhaltig zur Transparenz
und Aufkl&#228;rung beitragen und und in Deutschland die schnellere Verbreitung und Akzeptanz von KI-L&#246;sungen 
in Smart Cities f&#246;rdern. Vor allem bedeutet dies auch, dass Stadtplanerinnen und Stadtplaner sehr viel schneller
in entsprechenden Simulationen die Folgewirkungen absch&#228;tzen k&#246;nnen.
Etablierung von Chief Data-Scientists
Mit einer Open-Data-Strategie verbunden sein sollte dar&#252;ber hinaus, dass eine Verpflichtung zur Eintragung in
die entsprechenden Datenbanken besteht. Rohdaten sollten entweder &#252;ber zentrale Datenbanken vorgehalten oder
&#252;ber lokale Rechenzentren zur Verf&#252;gung gestellt, aufbereitet und maschinenlesbar abgerufen werden k&#246;nnen
(Meilensteinmodell). Au&#223;erdem sollten Anspr&#252;che aus dem Informationsfreiheitsgesetz zeitnah erf&#252;llt werden 
k&#246;nnen. Sollten die Daten lokal verwaltet werden, sollte viertens sichergestellt sein, dass die entsprechende
Kommune, Stadt, Metropolregion eine oder einen Chief Data-Scientist besch&#228;ftigt, der die Verf&#252;gbarkeit und die
Qualit&#228;t sicherstellt und gleichzeitig missbr&#228;uchliche Verwendung beobachtet, erkennt und entsprechend handelt.
921 Hierzu bieten sich sowohl prim&#228;re als auch Weiterbildungsstudieng&#228;nge an, z. B. f&#252;r Sozio-Informatikerinnen und -Informatiker,
aber auch f&#252;r Soziologinnen und Soziologen, Stadtentwicklerinnen und -entwickler etc.
3 AG 3: Innere Sicherheit, &#196;u&#223;ere Sicherheit, IT-Sicherheit
In der AG 3 wurden Einsatz und Auswirkungen von KI in den Bereichen Innere Sicherheit, &#196;u&#223;ere Sicherheit
und IT-Sicherheit untersucht.
Innere Sicherheit922 
3.1.1 Einf&#252;hrung
Eine der Hauptaufgaben des Staates ist die Gew&#228;hrleistung der Sicherheit der eigenen B&#252;rgerinnen und B&#252;rger.
Im Hinblick auf den vermehrten Einsatz von KI-Systemen sollten diese auch aus einer sicherheitspolitischen
Sichtweise betrachtet werden. Die Chancen des Einsatzes von KI- und ADM-Systemen in der &#246;ffentlichen
Verwaltung gelten grunds&#228;tzlich auch f&#252;r Beh&#246;rden und Ministerien, die mit Sicherheitsfragen zu tun haben. Das
betrifft z. B. interne Prozesse und Abl&#228;ufe oder einen effektiveren Zugang und eine effektivere Verarbeitung von
Informationen. Beispiele liefern etwa Predictive Policing oder die Erkennung von strafbaren Inhalten im Internet. 
In Indien konnten 3 000 vermisste Kinder durch eine Gesichtserkennungssoftware in wenigen Tagen gefunden
und wieder mit ihren Familien zusammengebracht werden.923 Auch Grenz&#252;bertritte k&#246;nnen durch automatisierte
Gesichtserkennung vereinfacht und beschleunigt werden. In Australien plant man, bis Ende des Jahres 2020
bereits 90 Prozent aller internationalen Einreisen an Flugh&#228;fen durch Gesichtserkennung an Smart Gates
abzuwickeln, an denen es nicht einmal mehr erforderlich ist, den Pass vorzulegen.924 Es bieten sich also M&#246;glichkeiten
f&#252;r die Entstehung innovativer Anwendungen im Sicherheitsbereich.
Auch ethische Fragen hinsichtlich der Anwendung von KI-Systemen m&#252;ssen bedacht werden, insbesondere wenn
Grundrechte ber&#252;hrt werden. Durch die fortschreitende Automatisierung und Digitalisierung wird die Entfernung
von Akteuren zu den Ergebnissen ihres Handelns gr&#246;&#223;er.925 Bei allen Anwendungen von KI-Systemen in Fragen
der Inneren Sicherheit ist eine sorgf&#228;ltige Abw&#228;gung zwischen dem Interesse nach mehr Sicherheit und
m&#246;glichen Einschr&#228;nkungen von Menschen- und B&#252;rgerrechten zu treffen.
Bereits im Prozess der Beschaffung bzw. Erstellung von KI-Systemen im Bereich der Inneren Sicherheit (z. B. 
Predictive Policing oder Social Media Forensis926) m&#252;ssen die gesellschaftlichen und sozialen
Herausforderungen stets betrachtet werden. Es muss klar definiert werden, zu welchem Zweck der Einsatz erfolgen soll und wo
die Grenzen zu ziehen sind. Auf Grundlage der am Zweck orientierten Vorgaben werden KI-Systeme entwickelt,
trainiert und eingesetzt. Dieses gilt ebenso f&#252;r die Einhaltung gesetzter Qualit&#228;tsma&#223;e. Bei der Bewertung des
Einsatzes sollten neben der Relation von Kosten und konkretem Nutzen auch die Wahrung von Menschen-, 
Grund- und Freiheitsrechten, das Verh&#228;ltnis zur polizeilichen Kriminalit&#228;tsstatistik und eine effiziente Nutzung
der polizeilichen Ressourcen beachtet werden.927 
3.1.2 Thematischer Schwerpunkt
Im Folgenden werden aktuelle Anwendungen, weiterf&#252;hrende Entwicklungen und deren Implikationen f&#252;r die
Bereiche Innere Sicherheit sowie Grenzschutz n&#228;her vorgestellt. Aus einer Antwort auf eine Schriftliche Frage
der Abgeordneten Saskia Esken (SPD) geht hervor, dass diverse automatisierte Entscheidungssysteme in
verschiedenen Bundesministerien bereits erprobt werden, darunter fallen auch Anwendungen zum betrachteten
Themenfeld.928 Aus einer Antwort des BMI auf Fragen der Projektgruppe geht hervor, in welchen Bereichen und in
welchem Umfang KI innerhalb der Zust&#228;ndigkeit des BMI eingesetzt wird. In vielen Bereichen befindet sich der
922 Zu diesem Kapitel liegen Sondervoten aus der Fraktion der AfD vor [Sondervotum zu Kapitel 3.1 der AG-Berichte der
Projektgruppe 2 &#8222;KI und Staat&#8220; (&#8222;AG 3: Innere Sicherheit, &#196;u&#223;ere Sicherheit, IT-Sicherheit &#8211; Innere Sicherheit&#8220;) des Abgeordneten Peter
Felser sowie der Abgeordneten Joana Cotar und Dr. Marc Jongen, Sondervotum zu Kapitel 3.1 der AG-Berichte der Projektgruppe 2 
&#8222;KI und Staat&#8220; (&#8222;AG 3: Innere Sicherheit, &#196;u&#223;ere Sicherheit, IT-Sicherheit &#8211; Innere Sicherheit &#8220;) des Abgeordneten Peter Felser
sowie der Abgeordneten Joana Cotar und Dr. Marc Jongen und Sondervotum zu den Kapiteln 3.1 und 3.2 der AG-Berichte der
Projektgruppe 2 &#8222;KI und Staat&#8220; (&#8222;AG 3: Innere Sicherheit, &#196;u&#223;ere Sicherheit, IT-Sicherheit &#8211; Innere Sicherheit &#8220; und &#8222;&#196;u&#223;ere
Sicherheit &#8220;) des Abgeordneten Peter Felser sowie der Abgeordneten Joana Cotar und Dr. Marc Jongen].
923 Vgl. Press Trust of India (2018): Delhi: Facial recognition system helps trace 3,000 missing children in 4 days.
924 Vgl. Hendry (2019): Second Aussie airport gets new contactless arrivals smartgates.
925 Vgl. Dickow (2015): Robotik &#8211; ein Game-Changer f&#252;r Milit&#228;r und Sicherheitspolitik?, S. 6&#8211;7.
926 Predictive Policing (der Vorhersage von Straftaten) und Social Media Forensis (Bildung von Personenprofilen) k&#246;nnen in der
Strafverfolgung und der Gefahrenabwehr angewendet werden.
927 Darstellung Andreas K&#246;nen (Abteilungsleiter &#8222;Cyber- und IT-Sicherheit&#8220; im Bundesministerium des Innern, f&#252;r Bau und Heimat) in
der Sitzung der Projektgruppe &#8222;KI und Staat&#8220; am 6. Mai 2019.
928 Vgl. Antwort der Bundesregierung auf die Schriftlichen Fragen 7, 8, 9 und 10 der Abgeordneten Saskia Esken auf
Bundestagsdrucksache 19/605.
Einsatz von KI in der Planungsphase. Laut BMI ist der Einsatz vor allem dort m&#246;glich, wo gro&#223;e Datenmengen
auszuwerten sind. Hier kann KI durch effiziente Analyse der Daten dabei helfen, Mitarbeiterinnen und
Mitarbeiter zu unterst&#252;tzen. Weitere Einsatzm&#246;glichkeiten k&#246;nnen in der Analyse von Bilddaten, der Anfertigung von
&#220;bersetzungen oder der Mustererkennung liegen.929 
Predictive Policing
Die Potenziale f&#252;r den Einsatz von KI-Systemen im Sicherheitsbereich sind vielf&#228;ltig. KI-Systeme werden u. a.
daf&#252;r eingesetzt, Straftaten vorherzusagen. Das B&#252;ro f&#252;r Technikfolgen-Absch&#228;tzung beim Deutschen Bundestag
beschrieb im Jahr 2017 vier Arten von Predictive Policing:930 
&#8226; Verfahren, mit denen m&#246;gliche &#214;rtlichkeiten und Zeiten mit einem erh&#246;hten Kriminalit&#228;tsrisiko
prognostiziert werden
&#8226; Verfahren, mit denen Individuen identifiziert werden, die zuk&#252;nftig in Straftaten verwickelt sein k&#246;nnten
&#8226; Verfahren, mit denen Profile erstellt werden, bei denen m&#246;gliche zuk&#252;nftige Straftaten von Individuen mit
bereits begangenen Straftaten abgeglichen werden k&#246;nnen
&#8226; Verfahren, mit denen Gruppen oder Individuen identifiziert werden, die zuk&#252;nftig Opfer einer Straftat
werden k&#246;nnten
Predictive Policing wird deutschlandweit seit etwa drei Jahren in sechs Bundesl&#228;ndern eingesetzt. Dazu z&#228;hlen:
Bayern, Baden-W&#252;rttemberg, Hessen, Nordrhein-Westfalen, Niedersachsen und Berlin. Dabei werden
kommerzielle Produkte wie PRECOBS (z. B. in Baden-W&#252;rttemberg und Bayern) oder Eigenentwicklungen wie SKALA
(in Nordrhein-Westfalen) eingesetzt. Keines der Verfahren arbeitet bisher mit personenbezogenen Daten. Sie
beschr&#228;nken sich auf die Prognose m&#246;glicher Tatorte und Tatzeiten, um den Einsatz z. B. von Streifen besser zu
steuern. Damit besitzen diese Anwendungsf&#228;lle von KI bei den Sicherheitsbeh&#246;rden (abweichend von anderen
L&#228;ndern) nur eine geringe Eingriffstiefe. Sie zielen vor allem auf serienm&#228;&#223;ige Wohnungseinbr&#252;che.931
Allerdings kann der Nutzen der Verfahren eingeschr&#228;nkt werden, wenn auch die (smarte organisierte) Kriminalit&#228;t die
Verfahren nutzen k&#246;nnte. KI-Systeme k&#246;nnten vorhersagen, wo die Aufmerksamkeit der Sicherheitsbeh&#246;rden
auf der Grundlage der Systeme verst&#228;rkt und wo im Gegenzug das Auge des Gesetzes in einem Zeitraum nicht
so pr&#228;sent sein wird. Auch fr&#252;her schon wurden gro&#223;e Bankraubvorhaben durch gezielte Ablenkungsma&#223;nahmen
&#8222;gesichert&#8220;. 
Predictive Policing stellt so, wie es in Deutschland genutzt wird, keinen Eingriff in Grundrechte dar.932 Es werden
keine personenbezogenen Daten, sondern nur ortsbezogene Informationen verarbeitet. Auch hier spielt die G&#252;te
und Vollst&#228;ndigkeit der Daten eine wichtige Rolle. Bei der Entwicklung und Einf&#252;hrung von Predictive-Policing-
Systemen sollte auf ein interdisziplin&#228;res Handeln geachtet werden. Neben der kriminalistischen und
kriminologischen Expertise sollte auch interdisziplin&#228;res Wissen beispielsweise aus den Bereichen Datenschutz,
Soziologie und Psychologie vertreten sein.933 
Werden in Zukunft auch personenbezogene Daten einbezogen, bedarf es einer besonders sorgf&#228;ltigen Pr&#252;fung
hinsichtlich der Grundrechtskonformit&#228;t, der Verh&#228;ltnism&#228;&#223;igkeit und auch der Wirksamkeit der Ma&#223;nahme. 
&#8222;Heat Lists&#8220;, d. h. Listen mit den Namen potenzieller Gef&#228;hrderinnen und Gef&#228;hrder, bergen Risiken und k&#246;nnen
auch zur selbsterf&#252;llenden Prophezeiung werden (d. h., jede Aktivit&#228;t einer Gef&#228;hrderin oder eines Gef&#228;hrders
wird als potenziell kriminell &#252;berinterpretiert), denn Grundrechtseingriffe sind nur anlassbezogen erlaubt und
nicht aufgrund von Prognosen. Das Max-Planck-Institut stellte bei der Untersuchung von Predicitve Policing in 
deutschen St&#228;dten zudem fest, dass Kriminalit&#228;tswahrscheinlichkeiten bestenfalls bei hohen Fallzahlen in
st&#228;dtischen Gebieten und auch dort nur eingeschr&#228;nkt vorhersagbar sind (&#8222;kausale Zusammenh&#228;nge k&#246;nnen nicht
abgeleitet werden&#8220;, &#8222;Effekte sehr klein, Ergebnisse wenig robust&#8220;).934 Zu &#228;hnlichen Schl&#252;ssen in Bezug auf den
Einsatz von Predictive Policing kommen auch Wissenschaftlerinnen und Wissenschaftler aus &#214;sterreich.935
929 Vgl. Antwort des BMI auf Fragen der Projektgruppe &#8222;KI und Staat&#8220;, Projektgruppendrucksache 19(27)PG 2-17 vom 17. Juli 2019.
930 Vgl. TAB Richter und Kind (2016): Predictive Policing, S. 7.
931 Vgl. Eschemann und Knobloch (2018): Transkript zum Hintergrundgespr&#228;ch &#8222;Predictive Policing in Deutschland&#8220;.
932 Vgl. Knobloch (2018): Vor die Lage kommen: Predictive Policing in Deutschland, S. 5&#8211;6.
933 Vgl. Eschemann und Knobloch (2018): Transkript zum Hintergrundgespr&#228;ch &#8222;Predictive Policing in Deutschland&#8220;; Thesenpapier
von Lorena Jaume-Palas&#237; (The Ethical Tech Society) f&#252;r die Projektgruppe &#8222;KI und Staat&#8220; vom Juni 2019.
934 Gerstner (2017): Predictive Policing als Instrument zur Pr&#228;vention von Wohnungseinbruchdiebstahl, S. 87 ff.
935 Vgl. Heitm&#252;ller (2019): Missing Link: Predictive Policing &#8211; die Kunst, Verbrechen vorherzusagen.
In anderen L&#228;ndern936 werden Predictive-Policing-Systeme ebenfalls eingesetzt. Dabei werden mitunter auch
personenbezogene Daten verwendet, insbesondere beim Einsatz von KI-Systemen zur Vorhersage k&#252;nftiger
Straff&#228;lligkeit. Derartige Systeme waren urspr&#252;nglich f&#252;r die Bewilligung von Resozialisierungsma&#223;nahmen bei
bereits Verurteilten entwickelt worden. Sie finden nun auch Einsatz vor Gericht und bei Entscheidungen &#252;ber
das Strafma&#223;. Die Schadenswirkung und damit einhergehend die grundrechtliche Eingriffsintensit&#228;t einer
falschen Zuordnung z. B. von Resozialisierungsma&#223;nahmen im Gef&#228;ngnis ist nat&#252;rlich eine andere als die
Schadenswirkung einer falschen Entscheidung zur L&#228;nge von Gef&#228;ngnisstrafen oder dar&#252;ber, ob sie zur Bew&#228;hrung
ausgesetzt werden oder nicht. Die vom Broward County in Florida eingesetzten Algorithmen haben sich in
80 Prozent der Wiederholungsfall-Prognosen zu Gewaltverbrechen Straff&#228;lliger geirrt. Selbst bei allen Straftaten
insgesamt waren nur 60 Prozent der R&#252;ckfall-Prognosen zutreffend. Bei Menschen mit dunkler Hautfarbe
bestand die Falschprognose dabei vor allem in der Annahme wahrscheinlicher Wiederholungstaten, bei T&#228;terinnen
und T&#228;tern mit wei&#223;er Hautfarbe dagegen in der Annahme eines (zu) geringen Risikos, erneut straff&#228;llig zu
werden.937 KI-Systeme m&#252;ssen mit hoher Sensibilit&#228;t entwickelt werden (Kontrolle der Trainingsdaten und
fortlaufende Evaluierung). So k&#246;nnen Diskriminierungen vermieden und die vollen Potenziale genutzt werden. Die hier
dargestellten Beispiele zeigen aber auch, dass es eine gesellschaftliche Debatte dar&#252;ber geben muss, wo die
Grenzen gezogen werden m&#252;ssen und wo die Entscheidungen nicht Maschinen &#252;berlassen werden d&#252;rfen.
Gesichtserkennung und Video&#252;berwachung
Im gemeinsamen Pilotprojekt &#8222;Sicherheitsbahnhof Berlin S&#252;dkreuz&#8220; des BMI, der Bundespolizei und der
Deutschen Bahn AG wurde die Nutzung intelligenter Videoanalysetechnik mithilfe von Gesichtserkennungssystemen 
erprobt. Das Bundeskriminalamt (BKA) war ebenfalls beratend bei diesem Projekt t&#228;tig. Die Deutsche Bahn
stellte im Rahmen des Projekts die technische Infrastruktur zur Verf&#252;gung, somit bestand keine inhaltliche
Beteiligung.938 Das Projekt gliederte sich in zwei Teilprojekte. Teilprojekt 1 unterteilte sich zudem in zwei
Testphasen. F&#252;r die erste Testphase (6 Monate) stellten sich 312 freiwillige Testpersonen zur Verf&#252;gung, um die
Tauglichkeit des Systems zu pr&#252;fen. In der zweiten Testphase (6 Monate) nahmen 201 Probanden freiwillig 
teil.939 Von ihnen wurden hochaufl&#246;sende Aufnahmen angefertigt, welche dann zum Abgleich mit den
Videoaufnahmen genutzt wurden. Die Falsch-positiv-Rate des Gesamtsystems, das durch die verschiedenen getesteten
Einzelsysteme zusammengesetzt wurde, lag nach deren Kombination durchschnittlich bei unter 0,1 Prozent.940 
Das hei&#223;t, dass von 1 000 Personen, deren Videoaufnahme mit den Gesichtern in der Datenbank abgeglichen
wurde, eine Person f&#228;lschlicherweise als Treffer identifiziert wurde. W&#228;hrend in der ersten Testphase das beste
System eine Trefferquote von 68,5 Prozent aufwies und damit eine Falsch-negativ-Rate von 31,5 Prozent,
steigerte sich die Rate in der zweiten Testphase deutlich. Das am besten getestete System wies in der zweiten
Testphase eine durchschnittliche Trefferquote von 82,8 Prozent auf. Damit lag die Falsch-negativ-Rate bei 17,2
Prozent.941 Das BMI hat den Versuch als Erfolg gewertet. Kritik kommt u. a. vom Chaos Computer Club, der von
einer gro&#223;en Zahl unbegr&#252;ndeter Treffer ausgeht.942 Durch die Kombination der besten Systeme ist eine
Reduzierung der Falsch-positiv-Raten m&#246;glich. Neben der Frage nach der Einschr&#228;nkung von Grundrechten sollte
aber auch die angestrebte Entlastung der Sicherheitsbeh&#246;rden durch die Technik mit den teils falsch-positiven
Ausgaben des Systems abgewogen werden. Es muss gepr&#252;ft werden, ob die Technologie das mildeste Mittel zur
Zielerreichung darstellt. Der Bundesbeauftragte f&#252;r den Datenschutz und die Informationsfreiheit hat die
Gesichtserkennung in seinem Bericht zur ersten Testphase als &#8222;eingriffsintensive Ma&#223;nahme&#8220; kritisiert, die viele
betreffe. Es handele sich zudem um einen starken Grundrechtseingriff, f&#252;r den es zurzeit keine gesetzliche
Grundlage gebe.943 Diskutiert wird angesichts der Fehlerquoten auch in der Wissenschaft verst&#228;rkt die Frage, wo
intelligente Videosoftware und Gesichtserkennung an ihre Grenzen sto&#223;en.944 
936 Vgl. Knobloch (2018): Vor die Lage kommen: Predictive Policing in Deutschland.
937 Vgl. Angwin et al. (2016): Machine Bias.
938 Vgl. Bundespolizeipr&#228;sidium (2018): Abschlussbericht des Bundespolizeipr&#228;sidiums zur biometrischen Gesichtserkennung.
939 Vgl. Greis (2018): Fl&#228;chendeckende Gesichtserkennung r&#252;ckt n&#228;her.
940 Vgl. Bundespolizeipr&#228;sidium (2018): Abschlussbericht des Bundespolizeipr&#228;sidiums zur biometrischen Gesichtserkennung.
941 Vgl. Bundespolizeipr&#228;sidium (2018): Abschlussbericht des Bundespolizeipr&#228;sidiums zur biometrischen Gesichtserkennung.
942 Vgl. Krempl (2018): CCC: Bundespolizei hat Bericht zur Gesichtserkennung absichtlich gesch&#246;nt.
943 Siehe T&#228;tigkeitsbericht 2017 und 2018 des Bundesbeauftragten f&#252;r den Datenschutz und die Informationsfreiheit,
Bundestagsdrucksache 19/9800, S. 77.
944 Vgl. Kr&#228;mer (2017): Digitale Augen und Hummel (2017): Die T&#252;cken der Gesichtserkennung.
Das Projekt am Bahnhof Berlin-S&#252;dkreuz wurde weitergef&#252;hrt und der zweite Teil des Projekts startete im Juni
2019. Der Test lief bis zum Ende des Jahres 2019 und arbeitete ohne Gesichtserkennungssoftware. Das Projekt
sollte dem Erkennen von Situationen dienen, die Qualit&#228;t, Sicherheit und Zuverl&#228;ssigkeit des Bahnbetriebs
beeintr&#228;chtigen k&#246;nnen.945 
Die Bundesregierung plant gemeinsam mit der Europ&#228;ischen Union, die Nutzung von
Gesichtserkennungssystemen in polizeilichen Datenbanken weiter auszubauen und zusammenzuf&#252;hren.946 Das BKA hat bis Ende des
Jahres 2019 die aktuell verf&#252;gbaren Gesichtserkennungssysteme auf ihre Einsatzf&#228;higkeit unter besonderen
Bedingungen gepr&#252;ft. Das Projekt &#8222;Ert&#252;chtigung des Gesichtserkennungssystems im BKA (EGES)&#8220; nutzt
Methoden der lernenden k&#252;nstlichen Systeme.947 
Ein anderes Beispiel f&#252;r den Einsatz bildauswertender Video&#252;berwachung findet sich in Mannheim. In
Zusammenarbeit mit dem Fraunhofer-Institut f&#252;r Optronik, Systemtechnik und Bildauswertung IOSB und dem Land
Baden-W&#252;rttemberg ist ein Modellprojekt entstanden. Der Einsatz der Kamera&#252;berwachung soll es erm&#246;glichen,
verlassene Gep&#228;ckst&#252;cke oder begangene K&#246;rperverletzungen an Orten mit erh&#246;hter Gefahrenlage automatisch
zu erkennen. Das System w&#252;rde eine kaskadierte Anonymisierung bieten. Das bedeutet, dass irrelevante
Bereiche, Personen oder Szenen nicht im Klarbild, sondern nur verpixelt oder ganz ausgeblendet sichtbar sein sollen.
Erst wenn das System eine Gefahrensituation erkennt, soll das Bild scharf gestellt und ein Signal an eine
Polizeibeamtin oder einen Polizeitbeamten ausgegeben werden. Die Entscheidungskompetenz l&#228;ge somit beim
Menschen, in dem Fall bei einer Polizeibeamtin und einem Polizeibeamten. Die Software w&#252;rde auf der Erkennung 
von Handlungsmustern basieren. Durch die Videoauswertungen sollen Reaktionszeiten der Ermittlungsbeh&#246;rden
gesenkt werden k&#246;nnen.948 Dies zeigt, dass sachgerechte Ans&#228;tze im Spannungsfeld zwischen Grundrechten und 
Potenzialen von KI-Anwendungen m&#246;glich sind.
Ein &#228;hnlicher Einsatz ist in Nordrhein-Westfalen geplant. Mithilfe von KI-basierter Video&#252;berwachung sollen
Selbstmorde und Zellen-Br&#228;nde in den Haftanstalten verhindert werden. KI kann dabei die vorgeschriebene
&#220;berpr&#252;fung von suizidgef&#228;hrdeten H&#228;ftlingen im 15-Minuten-Takt ersetzen.949 
Bei der Einf&#252;hrung von Video&#252;berwachungs- und Gesichtserkennungssystemen muss sorgf&#228;ltig zwischen ihrem
Nutzen und einer m&#246;glichen Einschr&#228;nkung von Grundrechten der Betroffenen abgewogen werden. Bei der
Entscheidung &#252;ber den Einsatz von &#220;berwachungssystemen sollten quantifizierbare Parameter bzw. tats&#228;chliche 
Erfolgsquoten, also z. B. nennenswert weniger Verbrechen oder nennenswert mehr aufgekl&#228;rte Straftaten,
herangezogen werden. Letztlich h&#228;ngt der Einsatz auch davon ab, ob er die Grundrechte wahrt.950 Bei neuen
&#220;berwachungsma&#223;nahmen ist laut Bundesverfassungsgericht951 vor ihrer Einf&#252;hrung eine Gesamt-
&#220;berwachungsrechnung anzustellen. Ma&#223;nahmen, insbesondere Ma&#223;nahmen der anlasslosen Massen&#252;berwachung, d&#252;rfen nicht
f&#252;r sich allein bewertet werden, sondern m&#252;ssen in ihrer Gesamtwirkung auf die Bev&#246;lkerung und auf ihre
informationelle Selbstbestimmung betrachtet werden. Video&#252;berwachung darf deshalb nicht fl&#228;chendeckend
eingesetzt werden, sondern bedarf einer konkreten Gefahrenlage oder allgemein gesteigerter Risiken von
Rechtsgutsgef&#228;hrdungen oder -verletzungen.
Schaut man auf den internationalen Einsatz von Gesichtserkennungssystemen, so stehen diese zus&#228;tzlich durch
Fehlerquoten in der Kritik. Sie k&#246;nnen zu unzul&#228;ssigen Ungleichbehandlungen auf Basis von Ethnie und
Geschlecht f&#252;hren, also z. B. zu h&#228;ufigerer Einstufung Unschuldiger als Verd&#228;chtige, wenn sie dunkelh&#228;utig sind. 
945 Vgl. Bundespolizei (2019): Test intelligenter Videoanalyse-Technik.
946 Vgl. Bundestagsdrucksache 19/4889. Vgl. auch Mertens (2018): EU und Berlin planen mehr Gesichtserkennung in polizeilich
genutzten Datenbanken; Monroy (2018): &#8222;Gemeinsamer Identit&#228;tsspeicher&#8220;: Biometrische Daten landen in europ&#228;ischem Datentopf
und Fanta (2018): EU-Projekt entwickelt smarten L&#252;gendetektor f&#252;r Grenzkontrollen.
947 Vgl. Bundestagsdrucksache 19/4889.
948 Vgl. Fraunhofer-Institut f&#252;r Optronik, Systemtechnik und Bildauswertung (2018): Privatsph&#228;re und Datenschutz &#8211; dank intelligenter
Video&#252;berwachung; Fraunhofer-Institut f&#252;r Optronik, Systemtechnik und Bildauswertung: Intelligente Video&#252;berwachung f&#252;r mehr
Sicherheit und Datenschutz; Polizeipr&#228;sidium Mannheim (2019): Auskunft auf Antrag nach dem Landesinformationsfreiheitsgesetz 
Baden-W&#252;rttemberg hier: ,,Daten und Ergebnisse zu der seit 3. Dezember 2018 in Betrieb befindlichen verhaltensbasierten
Video&#252;berwachung am Hauptbahnhof und Anke Domscheit-Berg (2019): Schriftliche Frage in der Woche vom 8. Juli 2019.
949 Vgl. Kowalewsky (2018): K&#252;nstliche Intelligenz soll Suizide in NRW-Gef&#228;ngnissen stoppen.
950 Dieses Recht umfasst die Befugnis des Einzelnen, grunds&#228;tzlich selbst zu entscheiden, wann und innerhalb welcher Grenzen
pers&#246;nliche Lebenssachverhalte offenbart werden, und daher grunds&#228;tzlich selbst &#252;ber die Preisgabe und Verwendung pers&#246;nlicher Daten
zu bestimmen. Das Recht auf informationelle Selbstbestimmung ist der Einschr&#228;nkung im &#252;berwiegenden Allgemeininteresse
zug&#228;nglich, bedarf jedoch einer gesetzlichen Grundlage, die dem rechtsstaatlichen Gebot der Normenklarheit entspricht und
verh&#228;ltnism&#228;&#223;ig ist.
951 Vgl. Bieker et al. (2018): Die &#220;berwachungs-Gesamtrechnung, oder: Es kann nicht sein, was nicht sein darf.
So fand das MIT Media Lab im Jahr 2018 heraus, dass KI-Systeme, die Personen das Geschlecht zuweisen
sollten, eine Fehlerquote von 34,7 Prozent hatten und sich vor allem bei der Identifikation von dunkelh&#228;utigen Frauen
irrten.952 Der US-amerikanische Rechnungshof (Government Accountability Office) stellte im Jahr 2017 fest,
dass vom FBI eingesetzte Algorithmen zur Gesichtserkennung sich in ca. 15 Prozent der F&#228;lle irrten und dass
besonders h&#228;ufig Frauen und People of Color falsch identifiziert wurden.953 Aus Sorge vor Rassismus durch das
sog. Racial Profiling und Missbrauchsgefahr hat die Stadt San Francisco den Einsatz von
Gesichtserkennungssoftware durch Beh&#246;rden generell verboten.954 Dieses Beispiel zeigt, wie wichtig Nicht-Diskriminierung bei der
Entwicklung und &#220;berpr&#252;fung von Algorithmen ist. Dabei besteht einerseits eine Chance, vorhandene
Diskriminierungen durch ein KI-Projekt zu identifizieren. Andererseits l&#228;sst sich daraus nicht schlussfolgern, dass man
grunds&#228;tzlich keine KI-Systeme in diesem Bereich einsetzen darf. Diskriminierungsfreiheit muss das Ziel sein &#8211;
mit und ohne KI-Einsatz. Problematisch ist auch der mit der Gesichtserkennung &#252;blicherweise einhergehende
Zuwachs an gespeicherten biometrischen Daten von Personen, die sich keines Vergehens schuldig machten. In 
Gro&#223;britannien wurde zwischen den Jahren 2016 und 2019 ein Zuwachs von 4 Millionen Bildern verzeichnet,
obwohl der Oberste Gerichtshof des Vereinigten K&#246;nigreichs bereits im Jahr 2012 die Speicherung von Fotos
Unschuldiger als nicht rechtm&#228;&#223;ig erkannte.955 Immer wieder werden auch Vorf&#228;lle bekannt, bei denen
biometrische Daten gehackt oder auch geleakt werden. So haben k&#252;rzlich Sicherheitsforscherinnen und -forscher aus
Israel eine riesige Datenbank mit rund 1 Million Fingerabdr&#252;cken und anderen biometrischen Daten aufgesp&#252;rt,
die quasi ungesch&#252;tzt und unverschl&#252;sselt im Web abgerufen werden konnten. Die Daten sollen vom System
Biostar 2 der koreanischen Sicherheitsfirma Suprema stammen, die nach eigenen Angaben Marktf&#252;hrer in Europa
bei biometrischen Zutrittskontrollsystemen ist.956 
Grenzschutz
Im Grenzschutz werden ebenfalls KI-Systeme eingesetzt, so z. B. durch das EU-Projekt &#8222;Roborder&#8220;957. Es wird
mit rund 8 Millionen Euro aus dem EU-Programm &#8222;Horizon 2020&#8220; gef&#246;rdert. Ziel ist ein autonomes
Grenz&#252;berwachungssystem mit vernetzten Drohnen und anderen unbemannten mobilen Robotern auf der Erde oder im
Wasser. Das System soll zuk&#252;nftig die EU-Grenzen &#252;berwachen. Zus&#228;tzlich soll das System auch nach
k&#252;stennaher Wasserverschmutzung suchen. Getestet wird es derzeit u. a. in Griechenland, Portugal und Ungarn.958 
Auch Gesichtserkennungssoftware kann in kontrollierter Umgebung, beispielsweise an Grenz&#252;berg&#228;ngen,
insbesondere an Flugh&#228;fen, bereits heute Einreiseprozesse beschleunigen. Dabei wird ein vorliegendes Foto mit einem
Gesicht verglichen, das gut ausgeleuchtet in eine Kamera schaut. Diese Gesichtserkennung wird in Deutschland
bereits durch EasyPASS an verschiedenen Flugh&#228;fen angeboten. Auf europ&#228;ischer Ebene soll ab dem Jahr 2021
das Entry-Exit-System (EES) zu wirksameren Kontrollen an den Schengen-Au&#223;engrenzen f&#252;hren. Durch die
digitalisierten und automatisierten Grenzkontrollen soll die Sicherheit im Schengen-Raum erh&#246;ht werden.
Dadurch sollen Identit&#228;tsbetrug und rechtswidriger Aufenthalt leichter festgestellt werden. Der manuelle Eintrag
von Visa-Stempeln wird zuk&#252;nftig durch den Einsatz von Gesichts- und Fingerscannern &#252;berfl&#252;ssig.959 
Zu den beschriebenen Potenzialen des KI-Einsatzes an Grenzen geh&#246;rt die Aufdeckung verd&#228;chtiger Muster bei
Grenz&#252;bertritten, z. B. um Personen zu entdecken, die Autos schmuggeln und mehrfach die Grenze mit jeweils
unterschiedlichen Autos &#252;berqueren. F&#252;r derartige Kontrollen m&#252;ssen jedoch die Daten aller Reisenden
gespeichert und verkn&#252;pft werden k&#246;nnen &#8211; auch ohne vorab bestehenden konkreten Anlass. Das k&#246;nnte ein Einschnitt
in das Recht auf informationelle Selbstbestimmung sein. In anderen L&#228;ndern, wie z. B. den USA, befinden sich
solche Systeme bereits im Praxistest.960 
952 Vgl. Boulamwini und Gebru (2018): Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification.
953 Vgl. Big Brother Watch (2019): Big Brother Watch Briefing for the Westminster Hall debate in Facial recognition and the biometrics
strategy on 1st May 2019.
954 &#8222;Die Gefahr, dass der Einsatz solcher Technologien die B&#252;rgerrechte verletzen k&#246;nne, &#252;berwiege die behaupteten Vorteile bei
Weitem, entschied der Stadtrat&#8220; (Zeit.de (2019): San Francisco verbietet Gesichtserkennung durch Beh&#246;rden). Von diesem Verbot sind
allerdings Flugh&#228;fen, H&#228;fen und Einrichtungen der Bundesbeh&#246;rden ausgenommen, private Nutzerinnen und Nutzer sind vom Verbot
ohnehin nicht betroffen (vgl. Zeit.de (2019): San Francisco verbietet Gesichtserkennung durch Beh&#246;rden).
955 Vgl. Big Brother Watch (2019): Big Brother Watch Briefing for the Westminster Hall debate in Facial recognition and the biometrics
strategy on 1st May 2019.
956 Vgl. Zeit.de (2019): Biometrische Daten von Millionen Nutzern offen im Netz.
957 Weitere Informationen dazu unter: https://roborder.eu/ (zuletzt abgerufen am 1. September 2020).
958 Vgl. Krempl (2019): Grenz&#252;berwachung: Roboterforscher warnt vor EU-Drohnenprojekt Roborder.
959 Weitere Informationen dazu unter: https://www.schengenvisainfo.com/entry-exit-system-ees/ (zuletzt abgerufen am 1. September
2020).
960 Ebd.
Bedrohungsszenarien
Durch den Einsatz von KI-Systemen k&#246;nnen auch neue Gefahren f&#252;r die Innere Sicherheit entstehen, z. B. durch
die F&#228;lschung und Manipulation von Informationen. Das zeigt sich in Anwendungen wie Lyrebird, wo die
Abbildung von Personen in Videos mittels Austausch von Fotos (Deep Fakes) manipuliert oder gesprochene Texte
mit der Stimme einer Person generiert werden k&#246;nnen. Hieraus ergeben sich auch erhebliche Herausforderungen
f&#252;r die Forensik im Hinblick auf den m&#246;glichen Beweiswert etwa in Ermittlungsverfahren. Dadurch k&#246;nnen neue
Gefahren f&#252;r die Innere Sicherheit entstehen, gerade im Hinblick auf die schnelle und unreflektierte Verbreitung
in sozialen Medien.961 Zum Missbrauch und zur Verbreitung von Falschmeldungen (Fake News) wird u. a. am
Deutschen Forschungszentrum f&#252;r K&#252;nstliche Intelligenz (DFKI) geforscht. Mit dem System &#8222;NewsVerifier&#8220;
sollen Falschmeldungen anhand von Bildern erkannt werden. Mittels einer Browsererweiterung wird gepr&#252;ft, ob
Bilder nicht bereits in einem anderen Kontext verwendet wurden. Mithilfe eines Algorithmus kann
herausgefunden werden, ob Bilder manipuliert worden sind.962 Ein weiteres Beispiel liefert die Software FaceForensics. Diese 
wurde von verschiedenen Wissenschaftlerinnen und Wissenschaftlern entwickelt (u. a. an der Technischen
Universit&#228;t M&#252;nchen) und zeigt die h&#246;chste Wahrscheinlichkeit beim Erkennen von Fake-Videos.963 
Social Scoring
Durch Social-Scoring-Systeme werden Menschen anhand ihres Verhaltens bewertet. Der chinesische Staat nutzt
f&#252;r den Aufbau seines &#8222;Citizen-Scores&#8220; eine sehr umfassende &#220;berwachung der Bev&#246;lkerung. Das System soll
fr&#252;hestens im Jahr 2020964 fl&#228;chendeckend in China eingef&#252;hrt werden und ist in seiner Gr&#246;&#223;e und seinem
Ausma&#223; weltweit einmalig. Der chinesische Score soll m&#246;glichst viele Parameter erfassen: Sozialverhalten,
Verhalten im &#246;ffentlichen Raum, soziale Beziehungen, Strafregister, Zahlungsmoral, Steuerhinterziehung und
Einkaufsgewohnheiten. In Deutschland ist ein solches Scoring-Modell nicht vorstellbar, da es den rechtsstaatlichen
Grunds&#228;tzen widerspricht.
Vermeidung und Schutz vor Fehlverhalten
Im internen Einsatz von KI-Systemen liegen Potenziale zur Vermeidung unerw&#252;nschten Verhaltens. Sie k&#246;nnen
unerlaubte Diskriminierung wie Racial Profiling oder anderes Fehlverhalten im Dienst aufdecken und dadurch
minimieren. So nutzt die Polizei in Charlotte (North Carolina, USA) KI-Systeme, um besser zu verstehen, wann
und warum Beamtinnen und Beamte unzul&#228;ssige Polizeigewalt anwenden. Basierend auf diesen Erkenntnissen
werden Dienstschichten so eingeteilt, dass sie polizeilichen Gewaltmissbrauch reduzieren. In D&#228;nemark
verwendet die Polizei komplexe algorithmische Systeme, um den missbr&#228;uchlichen Zugriff von Polizistinnen und
Polizisten auf Datenbanksysteme aufzudecken. Der Einsatz von KI-Systemen zur Kontrolle interner Prozesse kann
dabei helfen, die gesellschaftliche Akzeptanz von KI-Systemen zu f&#246;rdern.
Weitere Einsatzm&#246;glichkeiten
Neben dem Einsatz als Assistenzsystem im Rahmen polizeilicher Arbeit in der Strafverfolgung und
Gefahrenabwehr k&#246;nnen KI-Systeme auch zur &#220;berpr&#252;fung der Wahrheit von Aussagen genutzt werden. Beispiele f&#252;r die
Verwendung solcher Systeme sind Programme wie VeriPol und iBorderCtrl.965 Das BKA beobachtet zudem
fortlaufend den technischen Stand im Bereich der inhaltlichen Textanalyse.966 
Durch die Erkennung wiederkehrender Verhaltensmuster k&#246;nnen T&#228;terinnen und T&#228;ter identifiziert und
Gegenma&#223;nahmen zeiteffizient eingeleitet werden. Dies gilt auch f&#252;r den Bereich der zivilen Sicherheit. Der Einsatz
von KI-Systemen kann im Bereich der Auswertung gro&#223;er Datenmengen eine deutliche Effizienzsteigerung
darstellen.
961 Vgl. Heller (2017): Interessante Technik &#8211; gro&#223;e Gefahr.
962 Vgl. Deutsches Forschungszentrum f&#252;r K&#252;nstliche Intelligenz, 20. April 2017.
963 Vgl. Technische Universit&#228;t M&#252;nchen, 19. Juni 2019.
964 Vgl. Erling (2019): So absurd ausgefeilt ist Chinas &#220;berwachungssystem.
965 Vgl. Darstellung Lorena Jaume-Palasi (Gr&#252;nderin von The Ethical Tech Society) in der Sitzung der Projektgruppe &#8222;KI und Staat&#8220;
am 6. Mai 2019.
966 Vgl. Antwort der Bundesregierung auf die Kleine Anfrage der Fraktion DIE LINKE. auf Bundestagsdrucksache 19/4889, S. 6.
Erkenntnisse aus den Einzelbeispielen
Das Ziel sollte es sein, KI-Technologien f&#252;r die Bev&#246;lkerung nutzbar zu machen, ohne dabei Sicherheitsaspekte
von Anwendungen zu vernachl&#228;ssigen. Wie bereits zum &#252;bergeordneten Thema &#8222;Staat und Gesellschaft&#8220;
festgehalten, m&#252;ssen eine ausreichende Kontrolle und Transparenz gew&#228;hrleistet sein. Wie bei jedem Einsatz in der
&#246;ffentlichen Verwaltung m&#252;ssen Anwenderinnen und Anwender verstehen, wie das eingesetzte KI-System
funktioniert, welche Qualit&#228;t die Input-Daten haben und wie zuverl&#228;ssig sein Output ist. 
Eine einmalige &#220;berpr&#252;fung reicht bei lernenden Systemen nicht, da sie sich kontinuierlich ver&#228;ndern. Diese
Forderungen werden auch von den Beauftragten f&#252;r die Informationsfreiheit aus Bund und L&#228;ndern bei allen 
Anwendungen selbstlernender Systeme in der &#246;ffentlichen Verwaltung unterst&#252;tzt.967 Entscheidend f&#252;r den
sinnvollen Einsatz von KI-Systemen f&#252;r Zwecke der Inneren Sicherheit ist deshalb eine kluge Regulierungsstruktur,
zu der bereits der offene Entscheidungsprozess &#252;ber ihren Einsatz oder auch &#252;ber ihre Grenzen geh&#246;ren muss. 
Dazu m&#252;ssen konkrete und quantifizierbare Ziele definiert und es muss durch Tests evaluiert werden, ob sie mit
der beabsichtigten Technologie &#252;berhaupt erreichbar sind. Der Nutzen von &#220;berwachungsma&#223;nahmen und
m&#246;gliche negative Effekte m&#252;ssen klar benannt werden. 
Risiken des Einsatzes von KI-Systemen ergeben sich auch dann, wenn diese Menschen in Gruppen einteilen und
sie anhand dieser Gruppen unterschiedlich behandeln. Das muss nicht vors&#228;tzlich passieren, sondern liegt h&#228;ufig
an den Daten, die f&#252;r das Training der KI-Systeme eingesetzt wurden und die bestehende Benachteiligungen
abbilden oder die verschiedene demografische Gruppen unterschiedlich gut repr&#228;sentieren. B&#252;rgerrechte sind in
Gefahr, wenn Gesichts- und Verhaltenserkennung zur Identifikation von Straft&#228;terinnen oder Straft&#228;tern
eingesetzt wird, obwohl die Falsch-positiv-Raten sehr hoch sind, bei gleichzeitig zu niedrigen Raten korrekter
Erkennung. Bei derartigen Anwendungen ist daher ein Einsatz nur unter hohen Auflagen denkbar. Gibt es keine
Alternativen zu Prozessen, die von einem KI-System gesteuert sind, k&#246;nnen Gesichtserkennung, Iris-Scans oder
Fingerabdruckscans die Teilhabe von Menschen einschr&#228;nken, etwa wenn eine Authentifizierung aufgrund fehlender
Gliedma&#223;en nicht mehr m&#246;glich ist. 
F&#252;r einen eigenen deutschen und europ&#228;ischen Weg zum Einsatz von KI-Systemen f&#252;r die Wahrung der Inneren
Sicherheit sind differenzierte gesellschaftliche Debatten notwendig. Von der deutschen Bev&#246;lkerung werden
b&#252;rgerliche Freiheitsrechte &#8211; historisch begr&#252;ndet &#8211; als hohes Gut betrachtet. Beispiele wie China tragen daher zur
Skepsis der Menschen in Deutschland gegen&#252;ber dem staatlichen Einsatz von KI-Systemen wesentlich bei. Mit
einer breiten gesellschaftlichen Debatte k&#246;nnte sich Deutschland bzw. die EU auf der Basis europ&#228;ischer Werte 
auch global als Alternative zu den USA und China positionieren.  
3.1.3 Handlungsempfehlungen und Perspektiven
Neben den Empfehlungen in den Kapiteln I.1 [Kurzfassung des Projektgruppenberichts] sowie I.3 [
Handlungsempfehlungen] dieses Projektgruppenberichts empfiehlt die Enquete-Kommission dem Deutschen Bundestag
im Hinblick auf den Einsatz von KI-Systemen f&#252;r die Innere Sicherheit Folgendes:
Gesellschaftliche und soziale Wirkung beachten
Um die Akzeptanz der Bev&#246;lkerung f&#252;r staatliches Handeln im sensiblen Bereich der Inneren Sicherheit
sicherzustellen, m&#252;ssen bei der Beschaffung und beim Einsatz von KI-Systemen auch deren gesellschaftliche und
soziale Wirkung betrachtet werden. Bei dieser Betrachtung sollte interdisziplin&#228;r vorgegangen werden, sodass bei
der Umsetzung auf ein breites Wissen aus relevanten Bereichen wie Soziologie und Psychologie zur&#252;ckgegriffen
werden kann.
Wahrung der Verh&#228;ltnism&#228;&#223;igkeit
Wie am Beispiel der Einf&#252;hrung von Gesichtserkennungssystemen im &#246;ffentlichen Raum oder dem
internationalen Datenaustausch zur Einreisekontrolle veranschaulicht, kann ein Sicherheitszugewinn erzielt werden. Bei
der Bewertung des Einsatzes von KI-Systemen im Bereich Innere Sicherheit sollte neben der Relation von Kosten 
und Nutzen auch die Wahrung der Verh&#228;ltnism&#228;&#223;igkeit von Ma&#223;nahmen gepr&#252;ft werden. Hier m&#252;ssen die
Grundrechte der Betroffenen sorgf&#228;ltig abgewogen werden.
967 Vgl. Matthes (2018): K&#252;nstliche Intelligenz in der Verwaltung.
Investition in KI-Technologien zur Erkennung von Manipulation
Die Sicherheitsbeh&#246;rden m&#252;ssen in die Lage versetzt werden, Angriffe auf die freie Meinungsbildung zu
erkennen. Dazu sollte die universit&#228;re Forschung auf diesem Gebiet gef&#246;rdert und eigene Expertise aufbaut werden.
Erkannt werden sollten u. a. die Manipulationen von Bildern, Videos und Tonaufnahmen sowie die massive
Verbreitung von nachweislich falschen oder tendenzi&#246;sen Informationen.
Keine Legitimierung von Social Scoring
Wie beschrieben, widerspricht Social Scoring den rechtsstaatlichen Grunds&#228;tzen und darf deswegen nicht in
Deutschland eingef&#252;hrt werden.
&#196;u&#223;ere Sicherheit968 
3.2.1 Einf&#252;hrung
Zentrale Definitionen
Eine international allgemein anerkannte Definition von &#8222;autonome Waffensysteme&#8220; fehlt bislang, was die
Befassung mit dem Thema erschwert. Das Bundesministerium der Verteidigung gibt folgende Definition:
&#8222;Demnach ist ein System autonom, wenn es ohne jegliche menschliche Einflussnahme und Kontrolle sein Umfeld und
seinen internen Zustand wahrnehmen, eine Beurteilung der Situation vornehmen, entscheiden, rational handeln,
evaluieren und daraus lernen w&#252;rde.&#8220; Eine Abgrenzung wird zu &#8222;automatisierten Systemen&#8220; vorgenommen: &#8222;So 
sind ,autonome&#699; Waffensysteme nicht zu verwechseln mit ,automatisierten&#699;. [&#8230;] Im Unterschied zu autonomen 
k&#246;nnen automatisierte Systeme bestimmte Aktionen nur ausf&#252;hren, wenn der Mensch die Befehle darin
vorprogrammiert. Das hei&#223;t, dem Computer Entscheidungen im Sinne von Wenn-Dann-Operationen vorgibt. Dies
orientiert an festen Regeln.&#8220;969 
3.2.2 Thematischer Schwerpunkt
Einsatz von KI in Waffensystemen &#8211; Eingrenzung des problematischen Bereichs
Mit Blick auf die schwierige Begriffslage und die gesellschaftlich oft emotional aufgeladene Debatte beim Thema
autonome Waffensysteme erscheint hier, um den Gegenstand der Betrachtung n&#228;her zu bestimmen und somit den
problematischen Bereich auch mit Blick auf die Frage der Regulierung970 herausarbeiten zu k&#246;nnen, eine weitere
Eingrenzung notwendig. Im milit&#228;rischen Bereich werden ebenso wie in zivilen Anwendungsfeldern
verschiedene Assistenzsysteme mit KI-basierten Technologien eingesetzt, so z. B. bei den Fragen der technischen
Wartung von Waffensystemen (predictive maintenance), der Logistik oder der Auswertung von Lagebildern. Auch
in Bereichen wie der Spracherkennung, &#220;bersetzung und bei Funktionen zum automatischen Start oder der
Landung wird KI eingesetzt und kann hier gro&#223;e Effizienzgewinne bringen. Die Verkn&#252;pfung von Informationen
unter Heranziehung von KI-Systemen hilft dabei, Informationen viel schneller und pr&#228;ziser zu einem
umfassenden Lagebild zusammenzuf&#252;gen, als dies von Menschen geleistet werden kann. Damit steigt die M&#246;glichkeit,
Kollateralsch&#228;den auf ziviler Seite zu verringern. Autonome Fahrzeuge oder Roboter k&#246;nnen in gef&#228;hrlichen
(z. B. verminten) Gebieten eingesetzt werden, beispielsweise um dort Risikobewertungen vorzunehmen oder
Opfer zu bergen, ohne Menschenleben zu gef&#228;hrden. KI-Systeme k&#246;nnen helfen, krisenhafte Entwicklungen
weltweit in milit&#228;risch relevanten Zusammenh&#228;ngen fr&#252;hzeitig zu erkennen, um den erforderlichen zeitlichen 
Vorlauf f&#252;r Handlungsempfehlungen an die Entscheidungstr&#228;ger zu schaffen.971 Diese Assistenzsysteme sind in
der Fachdiskussion innerhalb des humanit&#228;ren V&#246;lkerrechts allgemein nicht umstritten. Zentral aus
v&#246;lkerrechtlicher Sicht sind das Unterscheidungsgebot im Hinblick auf zivile und milit&#228;rische Ziele, das Gebot der
Vermeidung unn&#246;tiger Leiden sowie der Grundsatz des verh&#228;ltnism&#228;&#223;igen Einsatzes milit&#228;rischer Gewalt. Dies ist der
aus v&#246;lkerrechtlicher Sicht relevante Bereich beim Einsatz von KI, denn hier finden komplexe Abw&#228;gungen statt,
die nur von Menschen vorgenommen werden d&#252;rfen. Mit Blick auf das zentrale Prinzip der Menschenw&#252;rde wird
968 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion der AfD vor [Sondervotum zu den Kapiteln 3.1 und 3.2 der AG-Berichte
der Projektgruppe 2 &#8222;KI und Staat&#8220; (&#8222;AG 3: Innere Sicherheit, &#196;u&#223;ere Sicherheit, IT-Sicherheit &#8211; Innere Sicherheit &#8220; und &#8222;&#196;u&#223;ere
Sicherheit &#8220;) des Abgeordneten Peter Felser sowie der Abgeordneten Joana Cotar und Dr. Marc Jongen].
969 Fleischer (2018): Entscheidung bleibt beim Menschen.
970 Die CDU/CSU-Fraktion bevorzugt die Formulierung &#8222;einer etwaigen Regulierung&#8220;.
971 Vgl. Antwort des Bundesministeriums der Verteidigung auf Fragen der Projektgruppe &#8222;KI und Staat&#8220;, Projektgruppendrucksache 
19(27)PG 2-16 vom 16. Juli 2019.
daraus abgeleitet, dass nur ein Mensch als Rechtssubjekt die Entscheidung &#252;ber den Verlust menschlichen Lebens
treffen darf &#8211; und nicht eine Maschine.972 
In der internationalen Fachdiskussion zeichnet sich mit Blick auf die Regulierung von KI-gest&#252;tzten
Waffensystemen zunehmend statt einer rein technischen die Durchsetzung einer funktionalen Definition von Autonomie
ab, die sich am Vorschlag des Internationalen Komitees der Roten Kreuzes (IKRK) orientiert. Das IKRK stuft
Waffensysteme dann als problematisch ein, wenn alle sechs Stufen des Entscheidungszyklus zur Zielbek&#228;mpfung 
ohne menschliche Kontrolle oder Aufsicht von einem System mithilfe von Sensoren, Trainingsdaten und
Algorithmen selbst&#228;ndig durchlaufen werden. Dieser Entscheidungszyklus (targeting cycle) beinhaltet die folgenden
sechs Stufen: find (Auffinden m&#246;glicher Ziele), fix (Festlegen des Ziels), track (Verfolgen des Ziels), target
(Erfassung des Ziels mit allen hier stattfindenden Abw&#228;gungen zur Verh&#228;ltnism&#228;&#223;igkeit der Mittel und Schutz von 
Zivilistinnen und Zivilisten), engage (Bek&#228;mpfung des Ziels) und assess (Auswertung des Ergebnisses).973 Auch 
im Rahmen der UN, wo die Debatte, &#252;ber autonome Waffensysteme innerhalb des &#220;bereinkommens &#252;ber das
Verbot oder die Beschr&#228;nkung des Einsatzes bestimmter konventioneller Waffen, die &#252;berm&#228;&#223;ige Leiden
verursachen oder unterschiedslos wirken k&#246;nnen (Convention on Certain Conventional Weapons, CCW) gef&#252;hrt wird,
hat sich als m&#246;gliches Kriterium f&#252;r die Regulierung von autonomen Waffensystemen das der bedeutsamen
menschlichen Kontrolle (meaningful human control) im Entscheidungskreislauf durchgesetzt.974 Was die
Regulierungsfragen angeht, m&#252;ssen die t&#246;dlichen autonomen Waffensysteme betrachtet werden, die Lethal
Autonomous Weapon Systems (LAWS), die selbst&#228;ndig den gesamten Prozess ohne menschliche Kontrolle
durchf&#252;hren. 
Stand der Debatte in Gesellschaft, Wissenschaft und Wirtschaft mit Bezug auf nationale und internationale
Regulierungsoptionen 
Umfragen zufolge lehnt in Deutschland eine Mehrheit der Bev&#246;lkerung die Entwicklung zumindest von LAWS
ab. Es gibt aber auch Bef&#252;rworterinnen und Bef&#252;rworter. Als wichtigste Gr&#252;nde werden bei der Ablehnung
genannt, dass t&#246;dliche autonome Waffen eine moralische Linie &#252;berschreiten w&#252;rden. Weiter besteht die Sorge,
dass es bei solchen Waffen zu technischen Fehlern kommen k&#246;nnte.975 Die Argumente, die f&#252;r den Einsatz von
KI bei Waffensystemen angef&#252;hrt werden, sind verbesserte M&#246;glichkeiten zum Schutz der eigenen Soldatinnen
und Soldaten und zur Vermeidung von Kollateralsch&#228;den, der geringere Bedarf an eingesetztem Personal und 
h&#246;here Effizienz. Zus&#228;tzlich k&#246;nnten diese Systeme in Gegenden ohne ausreichende Kommunikationskan&#228;le f&#252;r
eine Fernsteuerung eingesetzt werden. Es wird darauf hingewiesen, dass f&#252;r die Analyse aller verf&#252;gbaren
Informationen angesichts der zunehmenden Vernetzung von komplexen Daten menschliche Kapazit&#228;ten nicht mehr
ausreichen werden. In der Diskussion wird auch angef&#252;hrt, dass mit Blick auf das Risiko, dass autonome
Waffensysteme von feindlichen Akteuren gegen das eigene Land eingesetzt werden k&#246;nnten, die
Verteidigungsf&#228;higkeit Deutschlands auch gegen&#252;ber solchen Angriffen gew&#228;hrleistet sein m&#252;sse. 
Auf wissenschaftlicher Ebene wird das Thema ebenfalls intensiv diskutiert. Ein Beispiel ist der offene Brief
&#8222;Autonomous Weapons: an Open Letter from AI &amp; Robotics Researchers&#8220;, der im Jahr 2015 auf der International
Joint Conference on Artificial Intelligence von zahlreichen KI- und Robotik-Forscherinnen und -Forschern
unterzeichnet wurde.976 In dem Brief wird einerseits klar betont, dass durch den Einsatz von KI auch zahlreiche
Chancen bestehen, die Sicherheit von Menschen in bewaffneten Konflikten zu erh&#246;hen, insbesondere in Bezug
auf den Schutz von Zivilpersonen. Wovor aber gewarnt wird, sind offensive t&#246;dliche autonome Waffensysteme, 
besonders auch mit Blick auf die Gefahr eines internationalen R&#252;stungswettlaufs in diesem Bereich. In
Deutschland forderte die Gesellschaft f&#252;r Informatik (GI) in einer Stellungnahme aus dem Jahr 2019 eine v&#246;lkerrechtliche 
972 Vgl. Darstellung R&#252;diger Bohn (Stellvertretender Beauftragter der Bundesregierung f&#252;r Fragen der Abr&#252;stung und
R&#252;stungskontrolle) in der Sitzung der Projektgruppe &#8222;KI und Staat&#8220; am 6. Mai 2019.
973 Vgl. Sauer (2018): K&#252;nstliche Intelligenz in den Streitkr&#228;ften, S. 1; Ekelhof (2018): Autonomous weapons: Operationalizing
meaningful human control. Hier wird im Sinne einer weiteren Differenzierung darauf verwiesen, dass die &#8222;menschliche Kontrolle&#8220; mit
Blick auf die Herausforderungen der Praxis auch im Kontext einer &#8222;verteilten Kontrolle&#8220; gesehen werden muss.
974 Vgl. Dahlmann und Dickow (2019): Pr&#228;ventive Regulierung autonomer Waffensysteme, S. 18; aus Sicht der CDU/CSU-Fraktion 
sielt das Konzept der bedeutsamen menschlichen Kontrolle (meaningful human control) im Entscheidungskreislauf bei der
milit&#228;rischen Zielauswahl (targeting cycle) als m&#246;gliches Kriterium f&#252;r die Regulierung von autonomen Waffensystemen eine Rolle.
975 Vgl. Deeney (2019): Six in Ten (61%) Respondents Across 26 Countries Oppose the Use of Lethal Autonomous Weapons Systems.
976 Future of Life (2015): Autonomous Weapons: an Open Letter from AI &amp; Robotics Researchers.
&#196;chtung t&#246;dlicher autonomer Waffensysteme und spricht sich daf&#252;r aus, dass die Erforschung solcher
Waffensysteme auf nationaler Ebene streng reguliert wird.977 Waffensysteme, bei denen im kritischen
Entscheidungszyklus der Zielbek&#228;mpfung zwar KI eingesetzt wird, die jedoch nicht in Zweifel gezogen werden, stellen z. B. 
Raketenabwehrsysteme gegen nicht lebende Ziele dar.978 Andere Stimmen in der Wissenschaft verweisen darauf,
dass es unverzichtbar sei, sich in der milit&#228;rischen Forschung mit allen Facetten von KI zu besch&#228;ftigen,
unabh&#228;ngig davon, ob man selbst die entsprechenden F&#228;higkeiten aufbauen wolle. Wenn ein Gegner neue milit&#228;rische 
F&#228;higkeiten schaffe, dann f&#252;hre dies bei den eigenen Streitkr&#228;ften zu F&#228;higkeitsl&#252;cken, die man zumindest
kennen m&#252;sse und f&#252;r die man Konzepte bereithalten solle.979 
Die Dual-Use-Problematik980 stellt sich bei KI-Systemen in besonderem Ma&#223;e: Wie lassen sich diese auf
friedliche, rein zivile und demokratisch-rechtsstaatliche Anwendungen beschr&#228;nken? Daher ist auch ein Austausch
zwischen ziviler und milit&#228;rischer Forschung notwendig. Ferner ist ein Austausch notwendig, da der globale
zivile KI-Forschungsbereich inzwischen vor dem Milit&#228;rischen liegt.981 Im Rahmen der Wissenschaftsfreiheit
muss es aber ebenso weiter m&#246;glich sein, dass sich Forschungseinrichtungen mit einer Selbstverpflichtung zu
einer Zivilklausel verpflichten. Auch in der Wirtschaft forderten zuletzt zahlreiche Forscherinnen und Forscher,
dass ihr Unternehmen nicht mehr f&#252;r R&#252;stungsprojekte entwickelt.982 
In der Wirtschaft wird das Thema autonome Waffensysteme ebenfalls diskutiert. Der Bundesverband der
Deutschen Industrie (BDI) hat sich im Jahr 2019 in einem Positionspapier &#8222;K&#252;nstliche Intelligenz in Sicherheit und
Verteidigung&#8220; f&#252;r eine verbindliche &#196;chtung von t&#246;dlichen autonomen Waffensystemen ausgesprochen und
fordert eine Regulierung sicherheitsrelevanter KI-Anwendungen. Der BDI verweist darauf, dass sich die
Bundesregierung im Jahr 2015 zum Erhalt nationaler Schl&#252;sseltechnologien bekannt hat, die sich aus den
sicherheitspolitischen Interessen Deutschlands und dem Ziel der strategischen Unabh&#228;ngigkeit ableiten. KI ist nach Auffassung
der Industrie eine solche besonders zentrale Schl&#252;sseltechnologie und werde es in Zukunft immer mehr werden.
Es m&#252;sse darum politisch gekl&#228;rt werden, in welcher Form KI in bewaffneten Auseinandersetzungen eingesetzt
werden darf, damit auf dieser Grundlage die weitere technologische Entwicklung in dem gesetzten Rahmen
geplant und umgesetzt werden k&#246;nne.983 
Stand in der Politik: Deutschland, UN, EU und internationale Staatengemeinschaft
Die Bundesregierung setzt sich laut R&#252;diger Bohn auf UN-Ebene seit Jahren intensiv f&#252;r eine weltweite &#196;chtung
t&#246;dlicher autonomer Waffen ein.984 Dies wird nochmals im Koalitionsvertrag zwischen CDU, CSU und SPD
unterstrichen: 
&#8222;Autonome Waffensysteme, die der Verf&#252;gung des Menschen entzogen sind, lehnen wir ab. Wir wollen sie
weltweit &#228;chten.&#8220;985 Deutschland hat seit dem Jahr 2014 bereits zweimal im Rahmen der Vereinten Nationen den
Vorsitz in den Arbeitsgruppen der CCW zu LAWS gef&#252;hrt.986 Da autonome Waffensysteme k&#252;nftig frei
verf&#252;gbar seien, m&#252;ssten sich die Staaten auf globale Standards f&#252;r den Umgang mit dieser Technologie einigen. Die
Notwendigkeit f&#252;r eine solche Regelung werde jedoch insbesondere von Staaten wie den USA, Russland, China
oder Israel, die diese Systeme herstellen, bestritten.987 Gerade die USA intensivieren aktuell, auch als Reaktion
977 Die GI fordert die v&#246;lkerrechtliche &#196;chtung t&#246;dlicher autonomer Waffensysteme, vgl. Gesellschaft f&#252;r Informatik (2019): T&#246;dliche
autonome Waffensysteme (LAWS) m&#252;ssen v&#246;lkerrechtlich ge&#228;chtet werden.
978 Vgl. Darstellung Prof. Dr. Hans-J&#246;rg Kreowski (Forum InformatikerInnen f&#252;r Frieden und gesellschaftliche Verantwortung e. V.) in 
der Sitzung der Projektgruppe &#8222;KI und Staat&#8220; am 6. Mai 2019.
979 Vgl. Fleischer (2018): &#8222;KI&#8220; ist Thema f&#252;r die ganze Bundeswehr.
980 Dual-Use ist die Verwendbarkeit einer Anlage oder eines Produktes sowohl f&#252;r zivile als auch f&#252;r milit&#228;rische Zwecke.
981 Vgl. Darstellung Prof. Dr. Hans-J&#246;rg Kreowski (Forum InformatikerInnen f&#252;r Frieden und gesellschaftliche Verantwortung e. V.) in 
der Sitzung der Projektgruppe &#8222;KI und Staat&#8220; am 6. Mai 2019.
982 Vgl. Welchering (2019): Dual-Use-Problematikin der IT-Technik.
983 Vgl. Bundesverband der Deutschen Industrie e. V. (2019): K&#252;nstliche Intelligenz in Sicherheit und Verteidigung.
984 Vgl. Darstellung R&#252;diger Bohn (Stellvertretender Beauftragter der Bundesregierung f&#252;r Fragen der Abr&#252;stung und
R&#252;stungskontrolle) in der Sitzung der Projektgruppe &#8222;KI und Staat&#8220; am 6. Mai 2019.
985 CDU, CSU, SPD (2018): Ein neuer Aufbruch f&#252;r Europa Eine neue Dynamik f&#252;r Deutschland Ein neuer Zusammenhalt f&#252;r unser
Land, Zeile 7027.
986 Vgl. Ausw&#228;rtiges Amt (2018): T&#246;dliche Roboter-Waffen weltweit &#228;chten.
987 Vgl. Darstellung R&#252;diger Bohn (Stellvertretender Beauftragter der Bundesregierung f&#252;r Fragen der Abr&#252;stung und
R&#252;stungskontrolle) in der Sitzung der Projektgruppe &#8222;KI und Staat&#8220; am 6. Mai 2019.
der verst&#228;rkten Anstrengungen Russlands und Chinas im Bereich der milit&#228;rischen Nutzung von KI, ihre
Aktivit&#228;ten in diesem Feld. Gerade bei Russland und China ist &#252;ber Fortschritte &#246;ffentlich wenig bekannt.988 Dagegen
fordert eine Gruppe von 28 Staaten &#8211; allen voran Schwellen- und Entwicklungsl&#228;nder wie Brasilien und Sierra
Leone aus der Gruppe der Blockfreien Staaten und aus der EU &#214;sterreich &#8211; ein sofortiges Moratorium und einen
Verbotsvertrag. Hierzu weisen sie u. a. auf die v&#246;lkerrechtlichen Probleme, ein m&#246;gliches Wettr&#252;sten und die
automatische Eskalation aufgrund fehlender menschlicher Handlung hin.989 Deutschland vertritt laut R&#252;diger
Bohn gemeinsam mit Frankreich einen vermittelnden Ansatz zwischen den verh&#228;rteten Fronten der beiden
Gruppen und schl&#228;gt eine politische Erkl&#228;rung als ersten Schritt vor.990 In dieser k&#246;nnten &#8222;vollautonome t&#246;dliche
Waffensysteme&#8220; ge&#228;chtet, das Prinzip wirksamer menschlicher Kontrolle festgeschrieben und Ma&#223;nahmen f&#252;r
eine transparentere Waffenentwicklung definiert werden. Dieses Vorgehen wird mit Ausnahme &#214;sterreichs von
allen europ&#228;ischen Staaten sowie einigen L&#228;ndern aus der Gruppe der Blockfreien Staaten unterst&#252;tzt. In einem
weiteren Schritt wolle die Bundesregierung laut R&#252;diger Bohn dann einen milit&#228;rischen Verhaltenskodex zur
Gew&#228;hrleistung menschlicher Kontrolle &#252;ber Waffensysteme ausarbeiten. Damit eine solche Regelung991 nicht
ins Leere laufe, m&#252;sse sie jedoch unbedingt Herstellerstaaten wie die USA, Russland, China und Israel mit
einbeziehen. Die Bundesregierung setze darauf, auf Ebene der UN &#252;ber einen Dialog mit Regierungsvertreterinnen
und -vertretern in einer &#8222;Group of Governmental Experts&#8220; (Gruppe von Regierungssachverst&#228;ndigen) Elemente
f&#252;r eine wirksame Regulierung autonomer Waffensysteme zu erarbeiten.992 Im letzten Jahr sei es gelungen,
Prinzipien993 zu vereinbaren, auf deren Grundlage eine gemeinsame politische Erkl&#228;rung verfasst werden k&#246;nne. 
Die Bundesregierung lehne nicht allgemein den Einsatz von KI im Bereich Verteidigung ab, sondern solche
t&#246;dlichen Waffensysteme, bei denen dem Menschen die Kontrolle entzogen sei. Dies entspreche auch dem
Artikel 36 des Zusatzprotokolls zur UN-Konvention &#252;ber bestimmte konventionelle Waffen, wonach alle Staaten bei
der Einf&#252;hrung neuer Waffen deren V&#246;lkerrechtskonformit&#228;t gew&#228;hrleisten m&#252;ssten. Bei &#8222;vollautonomen
Systemen&#8220; k&#246;nne dies nicht sichergestellt werden.994 
Die Bedeutung von KI im Bereich Verteidigung wird von der Bundesregierung grunds&#228;tzlich anerkannt. In der
KI-Strategie der Bundesregierung vom November 2018 ist dazu festgeschrieben: &#8222;Der k&#252;nftige Einsatz von KI-
basierten Technologien und Systemen wird Auswirkungen auf Streitkr&#228;fte haben und ist damit ein wichtiges
Thema f&#252;r die Zukunftsentwicklung der Bundeswehr. Die Bundesregierung wird hier, analog zu anderen
Anwendungsgebieten, die Vor- und Nachteile einer umfassenden Bewertung unterziehen. [&#8230;] Die Forschung zu
KI-Anwendungsm&#246;glichkeiten, insbesondere zum Schutz der &#196;u&#223;eren Sicherheit und f&#252;r milit&#228;rische Zwecke, 
wird im Rahmen der Ressortzust&#228;ndigkeiten durchgef&#252;hrt.&#8220;995 
Das Europ&#228;ische Parlament hat im September 2018 eine Entschlie&#223;ung verabschiedet, in der es ein Verbot von
Waffensystemen verlangt, die keiner menschlichen Kontrolle unterliegen. Die Mitgliedstaaten und der Rat
werden aufgefordert, auf internationaler Ebene ein rechtverbindliches Instrument zu erwirken, mit dem LAWS
untersagt werden. In der Entschlie&#223;ung wird betont, dass Waffensysteme, die speziell zur Verteidigung der eigenen
Bev&#246;lkerung und Streitkr&#228;fte gegen Raketen und Munition dienen, nicht als t&#246;dliche Waffensysteme gelten.996 
Die von der EU-Kommission im Juni eingesetzte unabh&#228;ngige &#8222;Hochrangige Expertengruppe zu k&#252;nstlicher
Intelligenz&#8220; (High-Level Expert Group on Artificial Intelligence) hat im April 2019 in ihrem Bericht &#8222;Ethik-
Leitlinien f&#252;r eine vertrauensw&#252;rdige KI&#8220; (&#8222;Ethics Guidelines for Trustworthy AI&#8220;) auch zum Thema LAWS auf die
EU-Resolution verwiesen, mit der Absicht, ein Verbot von LAWS anzustreben. Der Einsatz von LAWS bringe
988 Vgl. Pr&#228;sentation von Prof. Dr. Hans-J&#246;rg Kreowski (Forum InformatikerInnen f&#252;r Frieden und gesellschaftliche
Verantwortung e. V.), Projektgruppendrucksache 19(27)PG 2-9 vom 6. Mai 2019.
989 Vgl. Verbot autonomer Waffen ohne Chance?, abrufbar unter: https://www.ndr.de/info/sendungen/streitkraefte_und_strategien/Ver-
bot-autonomer-Waffen-ohne-Chance,streitkraefte508.html.
990 Die CDU/CSU-Fraktion weist darauf hin, dass sich Deutschland im Rahmen der CCW-Arbeitsgruppe LAWS f&#252;r eine politische
Erkl&#228;rung einsetzt, die die Anwendbarkeit des humanit&#228;ren V&#246;lkerrechts und das Prinzip menschlicher Kontrolle f&#252;r alle
Waffensysteme, auch etwaige zuk&#252;nftige mit autonomen Funktionen, festschreiben soll.
991 Die CDU/CSU-Fraktion bevorzugt die Formulierung &#8222;eine etwaige Regelung&#8220;.
992 Vgl. Darstellung R&#252;diger Bohn (Stellvertretender Beauftragter der Bundesregierung f&#252;r Fragen der Abr&#252;stung und
R&#252;stungskontrolle) in der Sitzung der Projektgruppe &#8222;KI und Staat&#8220; am 6. Mai 2019.
993 Vgl. United Nations Office for Disarmament Affairs (2018): Report of the 2018 session of the Group of Governmental Experts on
Emerging Technologies in the Area of Lethal Autonomous Weapons Systems .
994 Vgl. Darstellung R&#252;diger Bohn (Stellvertretender Beauftragter der Bundesregierung f&#252;r Fragen der Abr&#252;stung und
R&#252;stungskontrolle) in der Sitzung der Projektgruppe &#8222;KI und Staat&#8220; am 6. Mai 2019.
995 Bundesregierung (2018): Strategie K&#252;nstliche Intelligenz der Bundesregierung.
996 Vgl. Entschlie&#223;ung des Europ&#228;ischen Parlaments vom 12. September 2018 zu autonomen Waffensystemen (P8_TA(2018)0341),
abrufbar unter: http://www.europarl.europa.eu/doceo/document/TA-8-2018-0341_DE.html?redirect (zuletzt abgerufen am
22. Juli 2020).
fundamentale ethische Fragen mit sich und k&#246;nne zu milit&#228;rischen Kontexten f&#252;hren, bei denen weitgehend auf
menschliche Kontrolle verzichtet werde und Risiken von Fehlfunktionen entstehen k&#246;nnten. Die Hochrangige
Expertengruppe unterst&#252;tzt in ihrem Bericht die Entschlie&#223;ung des EU-Parlaments vom Oktober 2018 zu
autonomen Waffensystemen.997 Auch die Hohe Vertreterin der EU f&#252;r Au&#223;en- und Sicherheitspolitik, Federica
Mogherini, hat sich klar f&#252;r eine internationale Regulierung ausgesprochen. Mit Blick auf den Dual-Use-Aspekt
verwies sie darauf, dass die zivile Forschung nicht durch politische Ma&#223;nahmen eingeschr&#228;nkt werden d&#252;rfe.998 
3.2.3 Handlungsempfehlungen und Operationalisierung
Aktuelle Trends
Eine zentrale Frage, die in der Wissenschaft diskutiert wird, ist, inwiefern milit&#228;rische und zivile KI-Forschung
voneinander abzugrenzen sind. Hier hat sich ein Paradigmenwechsel ergeben in der Hinsicht, dass lange Zeit das
Milit&#228;r technologische Entwicklungen im Bereich KI mit eigenen Mitteln und Einrichtungen angesto&#223;en hat. 
Wegen der Technologief&#252;hrerschaft bei KI im zivilen Bereich ist man bei der Entwicklung autonomer Systeme 
aber dazu &#252;bergegangen, zivile Produkte f&#252;r milit&#228;rische Zwecke umzubauen, weil dies kosteng&#252;nstiger und
schneller ist als die Entwicklung eigener Technologien.999 Hans-J&#246;rg Kreowski sprach sich aus
wissenschaftlicher Sicht gegen ein Verbot der milit&#228;rischen Nutzung ziviler Technologien aus, wies aber auf die Notwendigkeit
einer ethischen und zivilgesellschaftlichen Diskussion &#252;ber die Unterst&#252;tzung milit&#228;rischer Projekte in
Wissenschaft und Unternehmen hin.1000 Manche Forschungseinrichtungen haben sich selbst Zivilklauseln gegeben,
wonach sie die Verwendung ihrer Erkenntnisse f&#252;r milit&#228;rische Zwecke ablehnen.1001 Ber&#252;cksichtigt werden muss
hier, dass aus der milit&#228;rischen Forschung in der Vergangenheit immer wieder technologische Entwicklungen
angesto&#223;en wurden, die heute im zivilen Bereich genutzt werden, so z. B. das Internet, GPS und
Bilderkennungssysteme.
Herausforderungen
Erschwert wird die Frage des Umgangs mit t&#246;dlichen autonomen Waffensystemen durch das Fehlen einer
allgemein anerkannten internationalen Definition. Auch die Ablehnung wichtiger internationaler Player wie USA und
China gegen&#252;ber der Regulierung von LAWS und die Aufteilung der internationalen Gemeinschaft in drei
unterschiedliche Lager sind strukturell schwierige Ausgangsbedingungen f&#252;r Deutschland. Einen Bereich zu
regulieren, bei dem es bislang noch keine international geteilte Verst&#228;ndnisgrundlage gibt, wird einen aufw&#228;ndigen
Prozess notwendig machen. Eine besondere Herausforderung wird sein, eine klare Grenze f&#252;r den eigenen
Einsatz von KI in Waffensystemen zu ziehen und gleichzeitig in der Zukunft den technologischen Anschluss und
die Einwirkungsm&#246;glichkeiten auf die Gestaltung der internationalen Rahmenbedingungen beim Umgang mit
Autonomie in Waffensystemen nicht zu verlieren. Dar&#252;ber hinaus wies die Anh&#246;rperson Hans-J&#246;rg Kreowski
darauf hin, dass bei der Anwendung von KI in halbautonomen Waffensystemen noch viele ethische,
organisatorische und technische Probleme ungel&#246;st seien.
Handlungsempfehlungen
&#8226; Die Bundesregierung muss sich auch in Zukunft auf internationaler Ebene r&#252;stungskontrollpolitisch f&#252;r eine
weltweite &#196;chtung von t&#246;dlichen autonomen Waffensystemen einsetzen. Dabei muss ein Weg verfolgt
werden, mit dem eine m&#246;glichst gro&#223;e Gruppe von Staaten eingebunden werden kann.1002 Die CCW bleibt daf&#252;r
auch in Zukunft das richtige Forum. Es muss mit einem realistischen Ansatz verhindert werden, dass der
Verhandlungsprozess aus der UN in ein anderes Forum &#252;berf&#252;hrt wird, wie es in der Vergangenheit bei
anderen Waffensystemen wie z. B. bei Streumunition oder Antipersonenminen der Fall war. Denn ein
Abkommen au&#223;erhalb der UN h&#228;tte keinen Effekt auf Staaten, die ihm nicht beitreten.
997 Vgl. High-Level Expert Group on Artificial Intelligence (2019): Ethik-Leitlinien f&#252;r eine vertrauensw&#252;rdige KI.
998 Vgl. EU Strategic Communications (2018): Autonomous weapons must remain under human control, Mogherini says at European 
Parliament.
999 Vgl. Darstellung Prof. Dr. Hans-J&#246;rg Kreowski (Forum InformatikerInnen f&#252;r Frieden und gesellschaftliche Verantwortung e. V.) in 
der Sitzung der Projektgruppe &#8222;KI und Staat&#8220; am 6. Mai 2019.
1000 Vgl. Darstellung Prof. Dr. Hans-J&#246;rg Kreowski (Forum InformatikerInnen f&#252;r Frieden und gesellschaftliche Verantwortung e. V.) in 
der Sitzung der Projektgruppe &#8222;KI und Staat&#8220; am 6. Mai 2019.
1001 Eine &#220;bersicht der Hochschulen in Deutschland mit Zivilklauseln findet sich unter: http://zivilklausel.de/node/18 (zuletzt abgerufen
am 23. Juli 2020).
1002 Die CDU/CSU-Fraktion weist darauf hin, dass sonst die intendierte Wirkung verfehlt w&#252;rde.
&#8226; Damit dies gelingen kann, m&#252;ssen alle m&#246;glichen Anstrengungen unternommen werden, um zu einer
international anerkannten Definition von t&#246;dlichen autonomen Waffensystemen zu kommen. Eine solche
Definition erm&#246;glicht eine pr&#228;zisere v&#246;lkerrechtliche und ethische Einordnung.1003 
&#8226; Das Kriterium der bedeutsamen menschlichen Kontrolle im Entscheidungszyklus zur Zielbek&#228;mpfung muss
im V&#246;lkerrecht verankert werden. Begleitend dazu sollte die Forschung zu den technischen M&#246;glichkeiten
der Sicherstellung menschlicher Kontrolle &#252;ber Waffensysteme mit KI-gest&#252;tzten Assistenzsystemen
gef&#246;rdert werden. Dies betrifft den Ausbau der nationalen Forschung sowie der internationalen
Forschungskooperation.
&#8226; Deutschland sollte einen starken Beitrag dazu leisten, den internationalen Dialog zum Einsatz von KI auch
im Gesamtkomplex R&#252;stungskontrolle zu f&#246;rdern. Ziele m&#252;ssen der Aufbau und die Vertiefung des
gemeinsamen Verst&#228;ndnisses der Chancen und Risiken von KI-Technologien im Bereich Verteidigungspolitik sein.
&#8226; Ein international abgestimmtes Vorgehen bei der &#196;chtung t&#246;dlicher autonomer Waffensysteme bleibt
notwendig. Auch mit Blick auf die B&#252;ndnisverpflichtungen Deutschlands in der NATO und die Einbindung in
die milit&#228;rischen Strukturen der EU f&#252;hren nationale Alleing&#228;nge zu keiner tragf&#228;higen L&#246;sung. Eine
ausschlie&#223;lich nationale Regulierung ist auch mit Blick auf zuk&#252;nftige, gegenw&#228;rtig noch nicht absehbare
sicherheitspolitische Bedrohungen nicht zielf&#252;hrend. 
&#8226; Die Bundesregierung muss ein sicherheitspolitisches Leitliniendokument zum milit&#228;rischen Einsatz von KI
erarbeiten, wie es andere Staaten wie beispielsweise die USA bereits haben. Hier sollten die Grunds&#228;tze und
die Grenzen f&#252;r die Mensch-Maschine-Interaktion festgeschrieben werden.
&#8226; Dazu muss auch eine breite gesellschaftliche Debatte zum Einsatz von KI in der Sicherheits- und
Verteidigungspolitik angesto&#223;en und gef&#246;rdert werden.1004 
&#8226; KI-Systeme sollten in lebensentscheidenden Bereichen nur nach strengen Vorgaben eingesetzt werden. 
&#8226; Der Austausch zwischen ziviler und milit&#228;rischer KI-Forschung in Deutschland sollte keinen Restriktionen
unterliegen, um zu vermeiden, dass m&#246;gliche positive Effekte verhindert werden.
&#8226; Die sicherheitsrelevante KI-Forschung sollte auf EU-Ebene im Rahmen der Beschl&#252;sse der EU zu KI und 
Verteidigung unter Weiterverfolgung des Ziels der &#196;chtung vorangetrieben werden, um die europ&#228;ische
Position zu st&#228;rken und die Technologief&#252;hrerschaft bei schnellen Innovationen nicht den USA oder China
zu &#252;berlassen. Mit der &#8222;Joint European Disruptive Initiative&#8220; (JEDI) als Kern einer europ&#228;ischen
Innovationsagentur, die von der Struktur am amerikanischen Institut zur Erforschung zukunftsorientierter Projekte
f&#252;r die Verteidigung (Defence Advanced Research Projects Agency, DARPA) orientiert ist, wurde hier
bereits eine gute Grundlage geschaffen. Diese muss in den n&#228;chsten Jahren besonders im Bereich KI ausgebaut
werden. Mit der B&#252;ndelung von Marktmacht kann die EU gr&#246;&#223;eren Einfluss auf internationale
Standardisierungsprozesse bei sicherheitsrelevanter KI mit Fokus auf Verteidigung und Pr&#228;vention nehmen und damit
ihren Werten und Normen auf globaler Ebene Geltung verschaffen. 
&#8226; Vor dem Hintergrund des Dual-Use-Charakters von KI sollte, analog zu bestimmten kritischen
Softwarel&#246;sungen, wie beim Wassenaar-Abkommen1005 auch f&#252;r den Export von Komponenten f&#252;r autonome t&#246;dliche
Waffensysteme eine Regelung geschaffen werden. Dabei sollten, angelehnt an die Richtlinien bei
R&#252;stungsexporten, die politische Situation im Empf&#228;ngerland und menschenrechtliche Erw&#228;gungen als Kriterien
immer mitber&#252;cksichtigt werden. 
&#8226; Mit Blick auf die zunehmende Bedeutung von KI-Anwendungen im Bereich Verteidigung in Form von
Assistenzsystemen muss in der Zukunft bei der soldatischen Ausbildung ein besonderer Schwerpunkt auf
die Vermittlung von KI-Kenntnissen in Verbindung mit ethischen Leitlinien gelegt werden.
&#8226; Bei den Filtermethoden, die in KI-basierten Assistenzsystemen eingesetzt werden, um die zunehmende 
Menge an Sensordaten auswerten zu k&#246;nnen, muss sichergestellt werden, dass diese immer unter
menschlicher Kontrolle bleiben. Insbesondere beim Einsatz lernender Systeme muss gew&#228;hrleistet werden, dass die 
1003 Es gilt, weiter darauf hinzuwirken, dass die bereits existierenden Vorgaben des V&#246;lkerrechts, insbesondere des humanit&#228;ren
V&#246;lkerrechts, konsequent f&#252;r alle Waffensysteme angewendet werden.
1004 Der CDU/CSU-Fraktion ist es wichtig, dass neben berechtigten ethischen &#220;berlegungen dabei auch die Chancen der Verwendung 
neuer Technologin in Waffensystemen, etwa auch f&#252;r die Einhaltung der Vorgaben des humanit&#228;ren V&#246;lkerrechts, st&#228;rker betont
werden.
1005 Wassenaar-Abkommen f&#252;r Exportkontrollen von konventionellen Waffen und doppelverwendungsf&#228;higen G&#252;tern und Technologien,
weitere Informationen dazu unter: https://www.wassenaar.org/de/about-us/ (zuletzt abgerufen am 22. Juli 2020).
Zuordnung von Verantwortlichkeiten jederzeit klar nachvollzogen werden kann. Hierzu sollen die Systeme
laufend &#252;berpr&#252;ft und angepasst werden.
&#8226; Trainingsdaten f&#252;r die milit&#228;rische Anwendung von KI sind im Vergleich zu Trainingsdaten f&#252;r zivile
Anwendungen in einzelnen Anwendungsbereichen deutlich eingeschr&#228;nkter verf&#252;gbar. Da Verzerrungen in der
realen Anwendung kritische Folgen haben k&#246;nnen, muss streng &#252;berpr&#252;ft werden, dass die Trainingsdaten
auch immer der Anwendungswirklichkeit entsprechen. 
&#8226; Um ausreichend geeignete Trainingsdaten f&#252;r milit&#228;rische Anwendungen von KI und lernenden Systemen 
zu gewinnen, muss die Bundesregierung sich daf&#252;r einsetzen, dass zum einen national die
Rahmenbedingungen f&#252;r die Beschaffung und Nutzung solcher Trainingsdaten geschaffen werden. Zum anderen sollte
sie durch eine verst&#228;rkte europ&#228;ische Zusammenarbeit mit den anderen Mitgliedsstaaten sowie die
B&#252;ndelung von Ressourcen und Erkenntnissen das Ziel verfolgen, einen europ&#228;ischen Trainingsdatenpool f&#252;r
milit&#228;rische Anwendungen von KI und lernenden Systemen aufzubauen, um die europ&#228;ischen Synergien zur
Entwicklung milit&#228;rischer Systeme zu nutzen.
&#8226; Der Einsatz von KI-Systemen im Entscheidungszyklus zur Zielbek&#228;mpfung bedarf grunds&#228;tzlich einer
interdisziplin&#228;ren Gesamtanalyse. Die Erkenntnisse m&#252;ssen regelm&#228;&#223;ig evaluiert und auf Aus- und
Fortbildungsprozesse zur&#252;ckgespiegelt werden. Bei den Entwicklerinnen und Entwicklern von KI-Systemen im
Verteidigungsbereich sollten die bereits etablierten hohen Standards der Ausbildung, u. a. auch in Bezug
auf ethische Aspekte, weiter angewendet werden.
&#8226; Nur wenn Deutschland und Europa den technologischen Anschluss in sicherheitspolitischen
Anwendungsfeldern der KI auf globaler Ebene halten, wird es m&#246;glich sein, die Weiterentwicklung des V&#246;lkerrechts in 
KI-Fragen wesentlich mitzugestalten und die eigene sicherheitspolitische Unabh&#228;ngigkeit sicherzustellen. 
&#8226; Einer Emotionalisierung der Diskussion im Bereich Verteidigung in Richtung &#8222;Mensch oder KI?&#8220; sollte mit
sachlichen Argumenten entgegengewirkt werden. Vielmehr muss es darum gehen, wie eine m&#246;glichst
effektive Kombination von Mensch und KI gelingt. Die Bundeswehr erf&#252;llt ihre Aufgaben unver&#228;ndert im
Rahmen der durch die Politik gegebenen Auftr&#228;ge. Der Einsatz von KI in der Verteidigung darf keine
&#196;nderungen mit Blick auf die demokratische Kontrolle der Bundeswehr durch den Bundestag nach sich ziehen.
IT-Sicherheit
3.3.1 Einf&#252;hrung
Die Integrit&#228;t und Sicherheit digitaler Strukturen, Technologien und Produkte ist zunehmend Grundlage allen 
&#246;ffentlichen und gesellschaftlichen Lebens. Die IT-Sicherheit wird daher in immer mehr Bereichen zur
staatlichen Aufgabe und Verantwortung, f&#252;r deren Wahrnehmung auch auf L&#246;sungen aus dem Bereich &#8222;KI und
lernende k&#252;nstliche Systeme&#8220; zur&#252;ckgegriffen werden kann. Das Bundesverfassungsgericht hat bereits im Jahr 2008
das Grundrecht auf Gew&#228;hrleistung der Vertraulichkeit und Integrit&#228;t informationstechnischer Systeme (IT-
Grundrecht) festgeschrieben. Das IT-Grundrecht verankert IT-Sicherheit als verfassungsrechtliche
Gew&#228;hrleistungspflicht des Staates, aber angesichts der kurzen Innovationszyklen und der Dynamik des Markts im Sektor
der Informationstechnologie (IT) ist es eine gro&#223;e Herausforderung f&#252;r Politik und Gesellschaft, ein hohes Ma&#223;
an IT-Sicherheit zu gew&#228;hrleisten. Es gibt schlicht einen Zielkonflikt zwischen dem Drang, neue, innovative
Produkte so schnell wie m&#246;glich auf den Markt und zur Anwendung zu bringen, und der Ber&#252;cksichtigung
m&#246;glichst hoher Standards f&#252;r IT-Sicherheit, die bei ihrer Umsetzung Zeit und Geld kosten. Deshalb ist es
w&#252;nschenswert, Zertifizierungsprozesse effizient und preiswert zu gestalten. Auch bei lernenden k&#252;nstlichen
Systemen besteht die Herausforderung, Sicherheitsimplikationen der Technologie m&#246;glichst fr&#252;hzeitig festzustellen 
und Ma&#223;nahmen zu ergreifen, die die Sicherheit der lernenden k&#252;nstlichen Systeme erh&#246;hen. Grunds&#228;tzlich wird
das Problem bei lernenden k&#252;nstlichen Systemen noch dadurch vergr&#246;&#223;ert, dass zur Erkennung von
unautorisierten Manipulationen Abweichungen von der manipulationsfreien Funktionsweise des Systems festgestellt werden
m&#252;ssen. Das setzt ein hohes Ma&#223; an Transparenz und Nachvollziehbarkeit des Systems voraus &#8211; ein Kernproblem
bei vielen Ans&#228;tzen der lernenden k&#252;nstlichen Systeme. Angesichts der Verbreitung der Anwendung der
lernenden k&#252;nstlichen Systeme ist es aber umso wichtiger, sich fr&#252;hzeitig mit der Sicherheit der Systeme in Bezug auf
m&#246;gliche Angriffe von au&#223;en zu befassen und Strategien zu entwickeln, um das Schutzniveau der Systeme zu 
erh&#246;hen.
Um sich Fragen nach politischen Handlungsempfehlungen zur Erh&#246;hung der IT-Sicherheit von lernenden
k&#252;nstlichen Systemen ann&#228;hern zu k&#246;nnen, sind Mapping und Kategorisierung der Angriffsoberfl&#228;che erste Schritte. 
Ziel ist es hierbei, eine umfassende Analyse in der Art durchzuf&#252;hren, dass das Resultat auf m&#246;glichst viele
lernende k&#252;nstliche Systeme zutrifft. Angesichts der Diversit&#228;t der Ans&#228;tze innerhalb der lernenden k&#252;nstlichen 
Systeme wird man wahrscheinlich weitere Ausdifferenzierungen nach unterschiedlichen Modell-Klassen und 
technischen Ans&#228;tzen ben&#246;tigen. Eine solche erste &#220;bersicht erm&#246;glicht es, die konkreten Angriffsvektoren f&#252;r
lernende k&#252;nstliche Systeme zu abstrahieren und darauf aufbauend Empfehlungen f&#252;r IT-Sicherheit und
Resilienz zu entwickeln.
3.3.2 Thematischer Schwerpunkt
Angriffsoberfl&#228;che von lernenden k&#252;nstlichen Systemen
Die Angriffsoberfl&#228;che von lernenden k&#252;nstlichen Systemen besteht aus drei Bereichen: der Trainingsumgebung,
der Einsatzumgebung und der Au&#223;enwelt.
Abbildung 2
Angriffsoberfl&#228;che von Maschinellem Lernen1006 
Trainingsumgebung
Die Trainingsumgebung beinhaltet die f&#252;r das Training des Klassifizierungssystems notwendigen Trainingsdaten
sowie das Klassifizierungssystem1007 selbst. Angriffe auf die IT-Systeme, welche die Trainingsumgebung
repr&#228;sentieren, k&#246;nnen u. a. auf die Manipulation der Trainingsdaten (data poisoning) oder der Spezifikationen des
Klassifizierungsystems (z. B. Hyperparameter) abzielen.
Einsatzumgebung
Die Einsatzumgebung beinhaltet die lernenden k&#252;nstlichen Systeme sowie die Eingabeverarbeitung und Teile
der Ausgabe. Als Angriffe auf die IT-Systeme der Einsatzumgebung sind u. a. Manipulationen der
Eingabeverarbeitung (z. B. Sensoren) und der Ausgabe (z. B. Bremssysteme) denkbar. Bei lernenden k&#252;nstlichen Systemen
kann z. B. die Verf&#252;gbarkeit eingeschr&#228;nkt werden (denial of service). 
1006 Herpig (2019): IT-Sicherheit &amp; Maschinelles Lernen.
1007 Das Klassifizierungssystem ist ein Algorithmus, der Eingabedaten in spezifische Kategorien &#252;berf&#252;hrt, siehe unter anderem Asiri
(2018): Machine Learning Classifiers.
Au&#223;enwelt
Die physische und virtuelle Au&#223;enwelt beinhaltet die Trainingsdatensammlung von Drittparteien, die Daten beim
Online-Lernen1008, die Eingabe f&#252;r die lernenden k&#252;nstlichen Systeme sowie Teile der Ausgabe. Analog zu den 
Trainingsdaten k&#246;nnen die Daten bereits schon auf den IT-Systemen der Drittparteien manipuliert werden. Bei
der Eingabe k&#246;nnen die Daten direkt in IT-Systemen oder in der physischen Au&#223;enwelt (Beispiel: Stopp-Schild)
ver&#228;ndert werden. Das Online-Lernen stellt hierbei eine spezifische Subkategorie da, deren Manipulation sogar
nachhaltige Auswirkungen auf zuk&#252;nftige Entscheidungen der lernenden k&#252;nstlichen Systeme haben kann.
Befindet sich die Ausgabe au&#223;erhalb der Einsatzumgebung, kann auch dort ein Angriff stattfinden, der die bis dahin
valide Ausgabe der lernenden k&#252;nstlichen Systeme vor der finalen Verarbeitung ver&#228;ndert. 
Da es sich bei der Angriffsoberfl&#228;che um Datenfl&#252;sse handelt, bietet sich aus IT-Sicherheitsperspektive eine
n&#228;here Analyse mittels der bekannten CIA-Methode1009 an. Auch eine Erweiterung um Transparenz
(transparency) und Qualit&#228;t der Daten (quality of data) ist denkbar (CIATQ). Bei jedem Element der Angriffsoberfl&#228;che
(z. B. Trainingsdaten) kann man somit pr&#252;fen, welche der Schutzziele (CIATQ) verletzt werden k&#246;nnen und
welche Auswirkungen das auf die lernenden k&#252;nstlichen Systeme h&#228;tte.
Herausforderungen bei der IT-Sicherheit von lernenden k&#252;nstlichen Systemen
Bei Betrachtung der IT-Sicherheit von lernenden k&#252;nstlichen Systemen lassen sich gleich mehrere
Herausforderungen identifizieren. Im Vergleich zu Angriffen auf IT-Systeme ohne lernende k&#252;nstliche Systeme kommen 
ganz neue Angriffsvektoren, wie etwa durch feindliche Beispiele (adversarial examples)1010, hinzu, die
mitbedacht werden m&#252;ssen. Zus&#228;tzlich k&#246;nnen lernende k&#252;nstliche Systeme auch indirekt angegriffen werden, indem
Elemente in der physischen und virtuellen Au&#223;enwelt beeinflusst werden. Das bedeutet, auch wenn die
Trainingsumgebung und die Einsatzumgebung ausreichend abgesichert sind, kann es zu erfolgreichen Angriffen
gegen lernende k&#252;nstliche Systeme kommen. Das Erkennen und die Attribution von Angriffen auf lernende
k&#252;nstliche Systeme ist unter Umst&#228;nden komplexer, da die Unterscheidung zwischen validen Ausgaben und
Anomalien schwerer nachvollziehbar und somit nicht trivial ist.1011 W&#228;hrend bei herk&#246;mmlicher Software oft gilt, dass
Open Source eine M&#246;glichkeit sein kann, um die IT-Sicherheit zu erh&#246;hen (IT-Sicherheitsforscher k&#246;nnen den
Quellcode analysieren und Schwachstellen erkennen), gibt Wissen &#252;ber die Funktionsweise der lernenden
k&#252;nstlichen Systeme einem Angreifer bessere Angriffsm&#246;glichkeiten (white box versus black box attacks). Das
Geheimhalten dieser Funktionsweise ist jedoch kein solider Sicherheitsmechanismus.1012 Schlie&#223;lich kommt hinzu,
dass aufgrund der zunehmenden Automatisierung und Verbreitung erfolgreiche Angriffe auf lernende k&#252;nstliche
Systeme zu Kaskadeneffekten f&#252;hren k&#246;nnen, die gro&#223;en Schaden anrichten. Vor allem bei Einsatzszenarien im
Kontext nationaler Sicherheit und kritischer Infrastrukturen ist dies zu beachten.
3.3.3 Handlungsempfehlungen und Perspektiven
Es gelten die &#252;bergeordneten Handlungsempfehlungen aus den Kapiteln I.1 [Kurzfassung des
Projektgruppenberichts] und I.3. [Handlungsempfehlungen] dieses Projektgruppenberichts. Die Enquete-Kommission empfiehlt 
dem Deutschen Bundestag weiterhin f&#252;r den Abschnitt &#8222;IT-Sicherheit&#8220; Folgendes:
Die Analyse der Schwachstellen lernender k&#252;nstlicher Systeme und m&#246;glicher Angriffsvektoren steht noch am
Anfang. Daher ist hier vor allem dringend mehr Forschung in diesem Bereich notwendig. Zus&#228;tzlich sollte das
Bundesamt f&#252;r Sicherheit in der Informationstechnik (BSI) seine Kapazit&#228;ten in diesem Bereich weiter ausbauen
und sich mit den M&#246;glichkeiten der Entwicklung von Mindeststandards f&#252;r lernende KI-Systeme analog zum
1008 Online-Lernen oder auch inkrementelles Lernen bezeichnet ein Modell, das vor dem operativen Einsatz ohne Training auskommen 
kann und von neuen Beispielen nahezu in Echtzeit lernt, siehe unter anderem Pagels (2018): What is Online Machine Learning?
1009 CIA: Abk&#252;rzung f&#252;r Glaubw&#252;rdigkeit (credibility), Integrit&#228;t (integrity) und Verf&#252;gbarkeit von Daten (availability of data).
1010 Vgl. z. B. Goodfellow und Papernot (2017): Is attacking machine learning easier than defending it?: Eine Ma&#223;nahme zur Erh&#246;hung 
der Sicherheit in lernenden k&#252;nstlichen Systemen ist der Einbau von Sicherheitsspannen. Ein wichtiger Aspekt ist hier, Robustheit 
zu schaffen, also zu gew&#228;hrleisten, dass kleine &#196;nderungen in der Eingabe auch nur kleine &#196;nderungen im Ergebnis bewirken. 2017 
machten Beispiele Schlagzeilen, wo tiefe k&#252;nstliche neuronale Netze (KNN) durch eine f&#252;r den Menschen unmerkliche Ver&#228;nderung
weniger Pixel in einem Bild gravierende Fehlklassifikationen lieferten. So wurden f&#252;r den Menschen unmerklich ver&#228;nderte
Stoppschilder vom System nicht mehr als solche erkannt und einige Gewehre als Hubschrauber kategorisiert. Dies ist ein ernsthaftes
Problem mit sicherheitsrelevanten Implikationen. Ein Ansatz, dem entgegenzuwirken, ist das sogenannte Adversarial Training, bei dem
die Modelle absichtlich mit st&#246;rsignalbehafteten Daten trainiert werden, sodass sie im Einsatz robuster funktionieren.
1011 Vgl. Marshall et al. (2018): Securing the Future of Artificial Intelligence and Machine Learning at Microsoft und Brundage et al.
(2018): The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation.
1012 Vgl. Papernot et al. (2017): Practical Black-Box Attacks against Machine Learning und Athalye et al.: Obfuscated Gradients Give a
False Sense of Security: Circumventing Defenses to Adversarial Examples.
        
 
 
 
 
 
 
  
  
 
 
    
        
  
           
           
 
    
  
   
 
 
 
    
 
 
 
 
  
  
    
 
       
   
  
 
    
 
    
  
        
 
        
   
   
    
 
 
1
BSI-C5-Cloud-Standard befassen. Die Enquete-Kommission empfiehlt dem Deutschen Bundestag daher, die
Forschungsf&#246;rderung verst&#228;rkt auf die Frage der IT-Sicherheit von lernenden KI-Systemen auszurichten.
Au&#223;erdem sollte das BSI hierzu ausgebaut werden und es sollte entsprechende Schutzvorgaben und Mindeststandards
festschreiben. 
IV. K&#252;nstliche Intelligenz und Gesundheit (Projektgruppe 3)
Zusammenfassung
Gesundheit ist grundlegend f&#252;r jeden einzelnen Menschen und f&#252;r die Gesellschaft als Ganzes. Sie ist eine
elementare Voraussetzung daf&#252;r, ein unbeschwertes Leben f&#252;hren zu k&#246;nnen, frei von Schmerzen zu sein, seinem
Beruf nachzugehen und angstfrei in die Zukunft zu blicken. Es ist daher Aufgabe auch der Politik, alle
notwendigen und machbaren Ma&#223;nahmen zu ergreifen, die der Gesundheit der oder des Einzelnen und der gesamten
Gesellschaft f&#246;rderlich sind.
Gerade der K&#252;nstlichen Intelligenz (KI) kommt dabei als neuem Instrument im Gesundheitswesen eine
zunehmende Bedeutung zu. Es ist unerl&#228;sslich, dass sich die Politik mit der Entwicklungen in diesem Bereich
auseinandersetzt. In zahlreichen Feldern des Gesundheitswesens gibt es bereits KI-Anwendungen, die sich in der
Entwicklung befinden, als Prototypen existieren oder bereits eingesetzt werden. Die Vorteile einer zun&#228;chst
abstrakten Technologie, wie der KI im Gesundheitswesen, erschlie&#223;en sich vielen Menschen eher, wenn etwa
Verbesserungen in der Diagnose, Therapie oder Versorgung erzielt werden k&#246;nnen.
Ebenso offenkundig ist die Notwendigkeit, mit Gesundheitsdaten, die f&#252;r den Einsatz von KI die Grundlage sind,
besonders sensibel umzugehen sowie die direkten Folgen f&#252;r Leib und Leben, die KI-Anwendungen im Bereich 
Gesundheit und Pflege haben k&#246;nnen, zu ber&#252;cksichtigen. M&#246;gliche negative Szenarien, wie der &#8222;gl&#228;serne
Patient&#8220;, und die Folgen detaillierter Prognosen &#252;ber den eigenen Gesundheitszustand und die Lebenserwartung, ein 
ver&#228;ndertes Verh&#228;ltnis zwischen &#196;rztin oder Arzt sowie Patientin oder Patient oder eine Entmenschlichung der
Gesundheitsberufe werden bereits debattiert. Diese Themen m&#252;ssen angesprochen und die politischen
Regelungsbedarfe ermittelt werden. Dabei ist es wichtig, die Chancen von KI f&#252;r eine Verbesserung des
Gesundheitswesens zu nutzen und das Vertrauen in verantwortungsvolle und am Menschen orientierte Anwendungen
sicherzustellen.
Der Einsatz von KI im Gesundheitswesen ist kein Selbstzweck, sondern soll die Gesundheit der Menschen
verbessern, die Qualit&#228;t im Gesundheitssystem erh&#246;hen, die Gesundheitsberufe entlasten und den dort Besch&#228;ftigten
mehr Zeit f&#252;r die Patientinnen und Patienten geben. KI-Verfahren sollen der Bek&#228;mpfung von Krankheiten, wie
den gro&#223;en Volkskrankheiten oder seltenen Erkrankungen, dienen, Therapien verbessern und sicherer machen, 
indem etwa Behandlungsfehler vermindert bzw. vermieden werden.
Die Projektgruppe &#8222;KI und Gesundheit&#8220; der Enquete-Kommission K&#252;nstliche Intelligenz hat sich diesen
Ma&#223;st&#228;ben folgend mit verschiedenen Anwendungsgebieten von KI in Medizin und Pflege und ihrer Bedeutung f&#252;r
die Zukunft des Gesundheitssystems befasst. Sie ist sich einig, dass der Mensch im Mittelpunkt steht und auch
weiterhin stehen soll. Darauf aufbauend hat sie Handlungsempfehlungen erarbeitet, die als sinnvoll und
notwendig erachtet werden, um KI im Gesundheitsbereich zum Wohl der Gesellschaft zu nutzen und m&#246;glichen Sch&#228;den
vorzubeugen.  
In dieser Zusammenfassung des Projektgruppenberichts wird in Kapitel 1.1 [Potenziale spezifischer
Anwendungen von KI und ihre Risikoabsch&#228;tzung im Gesundheitsbereich] ein &#220;berblick &#252;ber die spezifischen
Anwendungsfelder von KI im Gesundheitsbereich gegeben und in Kapitel 1.2 [St&#228;rken und Schw&#228;chen, Chancen und
Risiken] die Ergebnisse der St&#228;rken-Schw&#228;chen-Analyse (SWOT) dargestellt. SWOT steht f&#252;r S = Strengths
(St&#228;rken), W = Weaknesses (Schw&#228;chen), O = Opportunities (Chancen) und T = Threats (Risiken). Anschlie&#223;end
folgen in Kapitel 1.3 [Handlungsfelder] Handlungsfelder und -empfehlungen, die sich im nachfolgenden Bericht
detailliert wiederfinden. Die Empfehlungen richten sich an verschiedene Akteure in der Gesundheitspolitik und
sollten aus Sicht der Projektgruppe zeitnah aufgegriffen werden. Als Orientierung finden sich in Kapitel 1.4
[Zehn Handlungsempfehlungen f&#252;r die Entwicklung und den Einsatz von KI im Gesundheitsbereich] zehn
Hauptempfehlungen, die die ausf&#252;hrliche Analyse zusammenfassen.
Potenziale spezifischer Anwendungen von KI und ihre Risikoabsch&#228;tzung im
Gesundheitsbereich
Wenn von KI die Rede ist, entsteht in vielen Anwendungsgebieten leicht die Vorstellung, es k&#246;nnten s&#228;mtliche
Probleme mit ihr gel&#246;st werden. Entscheidend ist aber, in welchen Bereichen Experten- oder selbstlernende
Systeme einen konkreten Beitrag f&#252;r die bessere Gesundheitsversorgung und -therapie oder in der Pflege leisten
k&#246;nnen. Die Projektgruppe hat sich daher zun&#228;chst einen &#220;berblick verschafft, welche Anwendungen bereits
existieren und beispielhaft verdeutlichen k&#246;nnen, warum KI im Gesundheitsbereich sinnvollerweise
weiterentwickelt und breit eingesetzt werden sollte. Es kann sich hierbei nicht um eine abschlie&#223;ende Liste handeln, da
die Anwendungsgebiete so vielf&#228;ltig sind wie die medizinischen Disziplinen selbst. Au&#223;erdem entwickeln sich
die L&#246;sungen kontinuierlich weiter bzw. es entstehen neue. Es l&#228;sst sich an ihnen jedoch verdeutlichen, wo die
Potenziale, aber auch die Herausforderungen liegen.
Bild- und Sprachanalyse zur Fr&#252;herkennung insbesondere gro&#223;er Volkskrankheiten
Bildgebende Verfahren z&#228;hlen zu den wichtigsten Untersuchungsmethoden f&#252;r die Diagnose in verschiedenen
Bereichen, insbesondere von Tumoren. Da sich intelligente Systeme vor allem in der Bilderkennung in den
letzten Jahren entscheidend weiterentwickelt haben, bieten sie ein gro&#223;es Potenzial f&#252;r die fr&#252;hzeitige und
verl&#228;ssliche Erkennung von Krebs. Ergebnisse der bildgebenden Verfahren k&#246;nnen durch Algorithmen auf
Auff&#228;lligkeiten gepr&#252;ft und m&#246;gliche Symptome f&#252;r eine Krebserkrankung automatisiert erkannt werden.1013 
F&#252;r die Anwendung stellen sich vor allem Fragen der Robustheit, also dazu, wie zuverl&#228;ssig und fehlerfrei KI-
Systeme arbeiten, Fragen der Haftung und die Frage, wie &#196;rztinnen und &#196;rzte weiterhin in die Diagnose
eingebunden sind. L&#228;sst sich nachweisen, dass der Algorithmus Auff&#228;lligkeiten verl&#228;sslicher erkennt als erfahrene
&#196;rztinnen und &#196;rzte (wie es bereits in einigen Bereichen der Fall ist)1014, spricht dies daf&#252;r, solche Systeme den 
&#196;rztinnen und &#196;rzten als Unterst&#252;tzung f&#252;r die Diagnose zur Seite zu stellen. F&#252;r pers&#246;nliche Gespr&#228;che bei
einer so sensiblen Diagnose h&#228;tte die &#196;rztin bzw. der Arzt dann entsprechend mehr Zeit zur Verf&#252;gung. Auch
eine zu hohe Problemanzeige eines Algorithmus, also viele sogenannte falsch positive Ergebnisse, m&#252;ssen
vermieden werden, da eine falsche Krebsdiagnose gro&#223;en Schaden anrichten kann. Hinsichtlich der Haftung sind
klare Regelungen zu treffen und es ist festzulegen, ob Hersteller, Programmiererinnen und Programmierer oder
die anwendende &#196;rztin oder der anwendende Arzt f&#252;r fehlerhafte Diagnosen zur Verantwortung zu ziehen sind.
Standardisierungen f&#252;r zul&#228;ssige Fehlerquoten &#8211; so wie sie heute bereits f&#252;r einige Operationsmethoden bestehen
&#8211; sind ein wichtiges Mittel f&#252;r Anforderungen an die Bilderkennungssoftware.
Vergleichbar mit den M&#246;glichkeiten der Bilderkennung zur Fr&#252;herkennung von Krebs sind Verfahren der
Spracherkennung zur Diagnose von Alzheimer. Dieses Feld befindet sich noch in der Entwicklung, hat aber
prinzipiell das gleiche Ziel: durch automatisierte Identifikation geringer Auff&#228;lligkeiten in der Sprache, die f&#252;r
Menschen schwer zu erkennen sind, zu einem fr&#252;hen Zeitpunkt und mit wenig Aufwand eine Diagnose stellen
zu k&#246;nnen. Bei solchen Diagnosen in fr&#252;hen Stadien bei nicht therapierbaren Erkrankungen ist allerdings immer
eine besondere Sensibilit&#228;t der &#196;rztinnen und &#196;rzte notwendig. Fragen der Robustheit und Haftung stellen sich
hier in &#228;hnlicher Weise, allerdings mit geringerer Dramatik, da es in der Regel nicht unmittelbar um Leben oder 
Tod, sondern eher um eine m&#246;gliche Beeinflussung oder Verlangsamung des Krankheitsverlaufs geht.
Versorgung und Monitoring
Die &#220;berwachung der gesundheitlichen Entwicklung der Patientinnen und Patienten, sei es station&#228;r oder
ambulant, beruht zu gro&#223;en Teilen auf der regelm&#228;&#223;igen Erhebung und Beobachtung medizinischer Daten. Diese Daten
bieten grunds&#228;tzlich die M&#246;glichkeit, die &#220;berwachung auf Auff&#228;lligkeiten durch intelligente Systeme zu
automatisieren. Erste Anwendungen gibt es bereits f&#252;r Intensivstationen, wo durch die automatisierte &#220;berwachung
der Blutwerte eine Blutvergiftung (Sepsis) fr&#252;her erkannt und behandelt werden kann.
Es befinden sich Algorithmen in der Entwicklung, die eine Projektion von Datenverl&#228;ufen in die Zukunft
erm&#246;glichen sollen und so Probleme anzeigen k&#246;nnen, bevor die Gesundheit der betroffenen Person tats&#228;chlich
eingeschr&#228;nkt ist.1015 So kann sie fr&#252;hzeitiger und damit oft besser therapiert werden. In Bezug auf die breite Anwen-
1013 Vgl. Auer (2019): K&#252;nstliche Intelligenz im Gesundheitswesen, S. 42; Siehe auch Kapitel 3.1 dieses Projektgruppenberichts [KI-
Anwendungen in der Medizin &#8211; Beispiele aus Diagnose und Therapie].
1014 Kapitel 3.1 dieses Projektgruppenberichts [KI-Anwendungen in der Medizin &#8211; Beispiele aus Diagnose und Therapie].
1015 Laufendes Projekt am Robert-Bosch-Krankenhaus in Stuttgart.
dung solcher Methoden stellt sich die Frage, wie viele Daten erhoben werden m&#252;ssen und ob eine solche
Ausweitung der medizinischen Datenerhebung w&#252;nschenswert ist. Denn f&#252;r die Entwicklung dieser Methoden sind
auch Proben von gesunden Menschen als Kontrollgruppe notwendig, die derzeit nicht zwingend vorliegen.
Personalisierte Therapien
Bereits heute werden auf die einzelne Patientin oder den einzelnen Patienten zugeschnittene, individuelle
Therapien durchgef&#252;hrt. Gerade bei aufwendigen und kostspieligen Therapien, wie z. B. bei Krebs, ist es grunds&#228;tzlich
vielversprechend, die individuelle Situation mit m&#246;glichst vielen gleichartigen Krankheitsbildern zu vergleichen,
um die bestm&#246;gliche Therapie zu finden.1016 Eine automatisierte Auswertung durch ein intelligentes System
erleichtert einen solchen Vergleich erheblich. Offenkundige Voraussetzung f&#252;r eine solche individualisierte
Medizin sind entsprechende Datenregister, die vergleichend herangezogen werden k&#246;nnen. Die Fragen, die sich in
diesem Zusammenhang stellen, werden in Kapitel 3.1 dieses Projektgruppenberichts [KI-Anwendungen in der
Medizin &#8211; Beispiele aus Diagnose und Therapie] ausf&#252;hrlich behandelt.
Pflege
Der derzeitige Fokus bei KI-Anwendungen in der Pflege liegt auf der Unterst&#252;tzung von Pflegebed&#252;rftigen,
Angeh&#246;rigen und Pflegepersonal. Es ist zu hoffen, dass mit fortschreitender Entwicklung auf diesem Feld mehr
Freir&#228;ume f&#252;r alle Beteiligten geschaffen werden, Menschen l&#228;nger autonom leben und damit weniger von
anderen Menschen abh&#228;ngig sein werden und sich die Qualit&#228;t der Pflege weiter verbessert. Die Entlastungen des
Pflegepersonals k&#246;nnen und sollen dazu f&#252;hren, dass mehr Zeit f&#252;r pers&#246;nliche Zuwendung entsteht, die nicht
ersetzt werden kann. Soziale Roboter k&#246;nnen aber sehr wohl positive Auswirkungen auf das Wohlbefinden und
die Lebensqualit&#228;t pflegebed&#252;rftiger Menschen haben sowie deren Autonomie st&#228;rken. KI-Anwendungen, wie
die intelligente Matratze, bieten konkrete Verbesserungen, da durch sie eine bessere, zielgenaue, individuelle
Lagerung m&#246;glich ist. Au&#223;erdem k&#246;nnen medizinisch-pflegerische Dienste durch KI-Werkzeuge entlastet
werden. Denn durch den Einsatz von KI k&#246;nnen sie trotz Fachkr&#228;ftemangel und Kostendruck effizienter und auch
effektiver wirken und so f&#252;r Pflegebed&#252;rftige besser verf&#252;gbar sein.
Es handelt sich dabei jedoch nicht um einen Automatismus. Robotik-Anwendungen, wie die Robbe Paro,
entlasten nicht unbedingt das Personal, sondern sind ein zus&#228;tzliches Hilfsmittel, um z. B. die Interaktion mit den
Pflegebed&#252;rftigen zu verbessern.1017 
Weitere Anwendungsgebiete
Neben den genannten Beispielen finden sich in Kapitel 3.2 dieses Projektgruppenberichts [KI-Anwendungen in
der Pflege] auch kurze Einf&#252;hrungen zum Einsatz von KI im Sport und beim Prozessmanagement sowie konkrete
Beispiele f&#252;r KI-Methoden, die gerade in der Entwicklungsphase sind oder bereits vereinzelt eingesetzt werden.
Damit soll dieser Bericht auch einen Eindruck geben, wie vielf&#228;ltig die zuk&#252;nftigen Einsatzszenarien sind, ohne
dass alle Bereiche hier im Detail oder vollst&#228;ndig beleuchtet werden k&#246;nnen.
St&#228;rken und Schw&#228;chen, Chancen und Risiken
Was ist der Ausgangspunkt f&#252;r die Entwicklung und Anwendung von KI in Deutschland? Zur Beantwortung
dieser Frage hat die Projektgruppe eine Analyse der St&#228;rken und Schw&#228;chen sowie der Chancen und Risiken
(&#8222;SWOT-Analyse&#8220;) vorgenommen, deren Ergebnis in Kapitel 3.4 dieses Projektgruppenberichts [SWOT-
Analyse] tabellarisch dargestellt ist.
Zusammenfassend l&#228;sst sich bei den St&#228;rken auf den Forschungsstandort Deutschland verweisen, der &#252;ber
exzellente und global vernetzte medizinische und forschende Institute verf&#252;gt. Das deutsche Gesundheitssystem
genie&#223;t aufgrund seines Solidarprinzips und der hohen Schutzstandards, etwa im Umgang mit pers&#246;nlichen Daten,
ein hohes Vertrauen. Vorbereitungen f&#252;r die Anwendung von KI werden derzeit getroffen; die Prozesse sind
jedoch zum Teil langwierig und die Vernetzung ist gering. Die elektronische Patientenakte (ePA) geh&#246;rt dazu
ebenso wie die Medizininformatik-Initiative; beide werden in den folgenden Kapiteln1018 n&#228;her beleuchtet.
1016 Vgl. Auer (2019): K&#252;nstliche Intelligenz im Gesundheitswesen, S. 48 ff.
1017 Vgl. Kehl (2018): Robotik und assistive Neurotechnologien in der Pflege &#8211; gesellschaftliche Herausforderungen, S. 74.
1018 Siehe insbesondere auch in Kapitel 4.2.2 dieses Projektgruppenberichts [Forschungsdaten &#8211; Verf&#252;gbarkeit, Qualit&#228;t und offene
Standards].
Die Schw&#228;chen offenbaren sich vor allem im Bereich der Digitalisierung und der Datenverf&#252;gbarkeit. Die n&#246;tige
IT-Ausstattung mit Hard- und Softwaresystemen ist vielerorts h&#228;ufig nicht ausreichend und leicht verf&#252;gbare
medizinische Datenbanken existieren entweder gar nicht oder sind nur sehr l&#252;ckenhaft vorhanden. Bestehende
Interoperabilit&#228;tsstandards, die einen Austausch der Daten erleichtern w&#252;rden, werden in Deutschland nicht
genutzt. Auch bei der Marktzulassung und bei Nutzenbewertungsverfahren gibt es L&#252;cken, da das
Gesundheitssystem noch nicht hinreichend auf digitale bzw. auf KI-basierende Systeme eingestellt ist. Nicht zuletzt fehlt es an
KI-Expertise beim Personal, da die Aus- und Weiterbildungssysteme noch nicht in relevantem Ausma&#223;
weiterentwickelt worden sind.
Die Chancen bestehen in den vielen Anwendungsgebieten, die u. a. im vorigen Abschnitt dargestellt worden sind.
Entscheidend ist, dass der Forschungsstandort Deutschland und das deutsche Solidarsystem daf&#252;r die Grundlage
bilden und weiter gest&#228;rkt werden.
Gelingt Deutschland die Mitgestaltung der KI im Gesundheitswesen nicht, besteht das Risiko, dass Fachkr&#228;fte
abwandern, Deutschland seine Souver&#228;nit&#228;t verliert und von anderen Standorten abh&#228;ngig wird oder es keinen
Nutzen f&#252;r Gesundheit und Pflege der Patientinnen und Patienten gibt. Der &#8222;gl&#228;serne Patient&#8220; und hohe Kosten
k&#246;nnten unerw&#252;nschte Folgen sein, wenn sie nicht rechtzeitig in den Blick genommen werden. Kostenintensive
Therapien k&#246;nnten die finanzielle Stabilit&#228;t aller Krankenversicherungen und damit die Erstattungsf&#228;higkeit von
Leistungen gef&#228;hrden.
Handlungsfelder
Ausgehend von den Leitfragen und den Anwendungsgebieten hat die Projektgruppe die folgenden vier
Handlungsfelder ermittelt: 
&#8226; Voraussetzungen f&#252;r den Einsatz von KI, 
&#8226; Forschungs- und Wirtschaftsstandort im Bereich Gesundheit, 
&#8226; Haftung und Zulassung sowie
&#8226; Pflege. 
Hinter den Voraussetzungen stecken dabei die entscheidenden Schritte, die in den n&#228;chsten Jahren unternommen 
werden m&#252;ssen, um den breiten Einsatz von KI &#252;berhaupt zu erm&#246;glichen. Dazu geh&#246;ren die Digitalisierung des
deutschen Gesundheitssystems, Qualit&#228;t und Verf&#252;gbarkeit von Daten und die Aus- und Weiterbildung des
Personals im gesamten Gesundheitswesen. Nur so kann Deutschland die Entwicklungen in den n&#228;chsten Jahren
souver&#228;n mitgestalten.
1.3.1 Voraussetzungen f&#252;r den Einsatz von KI im Gesundheitsbereich: Digitalisierung,
Datenverf&#252;gbarkeit und Aufbau von KI-Expertise in Gesundheitsberufen
Die erfolgreiche Entwicklung und Anwendung von nutzbringenden KI-L&#246;sungen f&#252;r Gesundheit und Pflege
h&#228;ngen ma&#223;geblich von verschiedenen Voraussetzungen und Rahmenbedingungen ab. Die Projektgruppe hat
insbesondere drei kritische Variablen identifiziert, die sie als zwingende Grundlage f&#252;r die Entwicklung und den
breiten Einsatz von KI im Gesundheitsbereich erachtet.
An erster Stelle steht eine sichere und leistungsf&#228;hige digitale Infrastruktur f&#252;r die Speicherung und &#220;bermittlung
von Gesundheitsdaten und die Digitalisierung von Versorgungsprozessen. Im internationalen Vergleich investiert 
Deutschland in seine Krankenh&#228;user deutlich weniger als andere L&#228;nder1019 und der Verband der
Universit&#228;tskliniken Deutschlands e. V. geht insgesamt von einem Investitionsdefizit im Bereich IT von j&#228;hrlich 5 bis 10
Millionen Euro pro Klinik aus, was eine veraltete IT-Struktur in vielen H&#228;usern bedeutet.1020 Um diesem R&#252;ckstand
zu begegnen, empfiehlt die Projektgruppe
&#8226; eine langfristige und nachhaltige L&#246;sung zu finden, wie die Investitionsrate in IT-Infrastruktur im
Gesundheitsbereich dem internationalen Niveau von 4 Prozent angeglichen werden kann,
1019 Vgl. Stephani et al. (2019): Benchmarking der Krankenhaus-IT: Deutschland im internationalen Vergleich, S. 29.
1020 Vgl. Deutsche Hochschulmedizin e. V. (2014): Medizinischer Fortschritt braucht leistungsstarke IT-L&#246;sungen.
&#8226; eine gemeinsame Anstrengung1021 von Bund und L&#228;ndern in relevanter und angemessener H&#246;he zu
unternehmen, um die Finanzierungsl&#252;cke m&#246;glichst schnell zu schlie&#223;en, sodass mit der dringend n&#246;tigen
Umsetzung begonnen werden kann.
Zum Zweiten ist ein innovationsfreundlicher und effizienter Rechtsrahmen f&#252;r den Datenschutz eine
unerl&#228;ssliche Voraussetzung; er sollte gleicherma&#223;en den Anspruch haben, die Gesundheitsdaten f&#252;r die Forschung und 
Entwicklung von KI-L&#246;sungen nutzbar zu machen und die digitale Souver&#228;nit&#228;t und die Datenschutzrechte der
Patientinnen und Patienten zu wahren. Um die Daten wirklich nutzbar zu machen, m&#252;ssen technische und
semantische Standards f&#252;r die Struktur von Daten auf Grundlage international gebr&#228;uchlicher Terminologien
gef&#246;rdert und durchgesetzt werden (Stichwort &#8222;Interoperabilit&#228;t&#8220;). Weitere Herausforderungen betreffen Aspekte
wie die bessere Zug&#228;nglichkeit und Verkn&#252;pfung von Datenregistern f&#252;r die Forschung. Da es sich bei
Gesundheitsdaten um besonders sensible Daten handelt, m&#252;ssen zudem Aspekte der Datensicherheit gekl&#228;rt sein. Die
Projektgruppe empfiehlt daher,
&#8226; die digitale Souver&#228;nit&#228;t der Patientinnen und Patienten zu wahren und ihnen eine Datenfreigabe zu
Forschungszwecken zu erm&#246;glichen, die freiwillig, individuell abstufbar und widerrufbar ist,
&#8226; ein nationales Versorgungsregister bzw. einen Registerverbund aufzubauen, in dem die von Patientinnen
und Patienten f&#252;r die Forschung freigegebenen und zuvor von dezentralen Vertrauensstellen anonymisierten
bzw. pseudonymisierten Daten unter Wahrung hoher Sicherheitsstandards verwaltet und f&#252;r die Forschung
zug&#228;nglich gemacht werden,
&#8226; eine Strategie f&#252;r die Interoperabilit&#228;t aller relevanten Gesundheitsdaten und der beteiligten Systeme auf
Basis internationaler Standards zu entwickeln und daf&#252;r zu sorgen, dass diese zeitnah von allen beteiligten 
Akteuren umgesetzt wird,
&#8226; zeitnah eine Bund-L&#228;nder-Arbeitsgruppe einzusetzen mit dem Ziel, schnellstm&#246;glich die unterschiedlichen
Datenschutzregelungen in Bund und L&#228;ndern auf Basis der Datenschutz-Grundverordnung (DSGVO) zu
vereinheitlichen und zeitgem&#228;&#223;er auszugestalten.
Nicht zuletzt sieht die Projektgruppe den fl&#228;chendeckenden Aufbau von Digitalkompetenz in
Gesundheitsberufen als zwingende Bedingung f&#252;r den erfolgreichen Einsatz intelligenter Systeme in Versorgung, Therapie und
Pflege an. Die Fachkr&#228;fte m&#252;ssen einsch&#228;tzen k&#246;nnen, was ein Algorithmus tats&#228;chlich &#252;bernehmen kann und
wie seine Ergebnisse zu interpretieren sind. Daf&#252;r sieht die Projektgruppe es als erforderlich an,
&#8226; einen gemeinsamen Fahrplan f&#252;r die Weiterentwicklung von Ausbildung und Studium im Gesundheits- und
Pflegebereich zu entwickeln und daran alle relevanten Akteure zu beteiligen; die Leitung k&#246;nnte z. B. bei
der Kulturministerkonferenz liegen,
&#8226; umfassende Weiterbildungskonzepte f&#252;r alle Gesundheitsberufe aufzulegen und gemeinsam mit
Kommunen und L&#228;ndern leicht zug&#228;nglich vor Ort anzubieten und zu f&#246;rdern.
1.3.2 F&#246;rderung des Forschungs- und Wirtschaftsstandorts zur souver&#228;nen Entwicklung 
von KI im Gesundheitsbereich
Sowohl f&#252;r die Forschung als auch f&#252;r die Wirtschaft im Bereich Gesundheit werden die kommenden Jahre
dar&#252;ber entscheiden, ob und wie es gelingen wird, die Entwicklung und Anwendung von KI in Gesundheit und 
Pflege zur St&#228;rke des deutschen Gesundheitsstandorts zu machen.
Der Forschungsstandort geh&#246;rt zu den St&#228;rken des deutschen Gesundheitssystems. Dementsprechend hat auch
KI l&#228;ngst Einzug in die Gesundheitsforschung gehalten. Dabei sind intelligente Systeme sowohl Werkzeug als
auch Gegenstand der Forschung. Mit ihrer Hilfe k&#246;nnen etwa Experimente simuliert, Modelle erstellt oder gro&#223;e
Datenmengen analysiert werden. Gleichzeitig wird in verschiedenen Fachrichtungen der Gesundheitsforschung
an neuen KI-Anwendungen und Einsatzm&#246;glichkeiten geforscht.
Um diese Forschung weiter zu f&#246;rdern und zu st&#228;rken und in nutzbringende KI-Anwendungen zu &#252;berf&#252;hren,
empfiehlt die Projektgruppe,
1021 Daf&#252;r k&#246;nnten die Erfahrungen aus dem Digitalpakt Schule herangezogen werden.
&#8226; bei der Datenverf&#252;gbarkeit hinsichtlich des Zugangs und der Qualit&#228;t der Daten besonders auf die
Verwendbarkeit f&#252;r die Forschung zu achten und diese durch enge Zusammenarbeit zwischen Gesundheits- und
Forschungspolitik und die Ergebnisse der Medizininformatik-Initiative bei der Entwicklung der ePA zu
ber&#252;cksichtigen,
&#8226; &#214;kosysteme zwischen Forschung und Wirtschaft aufzubauen und KI in Gesundheit und Pflege von der
Entwicklung bis zur Anwendung in langfristigen und interdisziplin&#228;ren Projekten zu f&#246;rdern.
Die Gesundheitswirtschaft ist in Deutschland traditionell auch ein starker Wirtschaftszweig mit mehreren
Clustern in verschiedenen Teilen des Landes. Sie ger&#228;t jedoch auch zunehmend international unter Druck. Ihre
F&#228;higkeit, eine neue Technologie wie KI zu entwickeln und zu nutzen, wird entscheidend f&#252;r ihre zuk&#252;nftige globale
Wettbewerbsf&#228;higkeit und die deutsche Gesundheitsversorgung sein.
Dynamische Entwicklungen, wie die Gr&#252;ndung von Start-ups im Gesundheitssektor, sind notwendig, um neue
Methoden schneller zu etablieren und sie f&#252;r Patientinnen und Patienten nutzbar zu machen. Daf&#252;r ben&#246;tigen
Start-ups ein innovationsfreundliches Umfeld, das der Gesundheitsbereich noch nicht durchg&#228;ngig bietet.
Unternehmerinnen und Unternehmer weisen insbesondere darauf hin, dass die Zulassungs- und Erstattungsprozesse
f&#252;r neue Medizinprodukte f&#252;r Neueinsteiger sehr schwer zu durchschauen sind. Auch fehlt es an
F&#246;rderm&#246;glichkeiten, die auf Start-ups zugeschnitten sind. Instrumente zur Innovationsf&#246;rderung im Gesundheitsbereich richten
sich vor allem an etablierte Akteure und weniger an Start-ups. Die Projektgruppe empfiehlt daher,
&#8226; dass das Bundesministerium f&#252;r Gesundheit (BMG) beim Bundesinstitut f&#252;r Arzneimittel und
Medizinprodukte (BfArM) geeignete und f&#252;r einen breiten Kreis verf&#252;gbare Beratungsangebote f&#252;r die Zulassung
neuer, auf KI basierender digitaler Medizinprodukte aufbaut; in gleicher Weise m&#252;ssen auch
Beratungsangebote zur Erstattung beim Gemeinsamen Bundesausschuss st&#228;rker die Eigenheiten digitaler Angebote und
ihrer Anbieter in den Blick nehmen,
&#8226; bestehende und neu einzurichtende F&#246;rdert&#246;pfe des Bundes, der L&#228;nder und der Selbstverwaltung f&#252;r KI in 
Medizin und Pflege besonders f&#252;r Forschung, Start-ups und junge Unternehmen einschlie&#223;lich KMU leicht
zug&#228;nglich zu machen.
1.3.3 Zulassung, Erstattung und Haftung im Zusammenhang mit neuen KI-Methoden
Angesichts der besonderen Relevanz des Gesundheitsbereichs f&#252;r die Bev&#246;lkerung und der vielen Chancen und
Risiken, die durch den Einsatz von KI-basierten Systemen in der Patientenversorgung bestehen, bedarf die Frage
der Marktzulassung, der Kostenerstattung und der Haftung bez&#252;glich intelligenter Systeme zum einen besonderer
Sorgfalt, zum anderen aber auch transparenter, an KI angepasster Verfahren. 
Es muss in erster Linie gew&#228;hrleistet sein, dass nur Systeme zugelassen werden, die f&#252;r den Einsatz an der
Patientin oder dem Patienten sicher sind. Entscheidend wird aber auch sein, die Zulassungsverfahren f&#252;r digitale
Anwendungen im Gesundheitswesen so zu gestalten, dass sie die Eigenschaften selbstlernender KI-Systeme
antizipieren. Insbesondere Start-ups und kleinere Unternehmen sollten Unterst&#252;tzung erhalten, vor allem bei der
Bew&#228;ltigung der Zulassungsverfahren. Insgesamt kann der regulatorische Rahmen der Marktzulassung f&#252;r die
Anwendung von KI im Gesundheitsbereich perspektivisch nur wirksam auf EU-Ebene gesetzt werden, jedoch
m&#252;ssen bereits nationale Voraussetzungen z&#252;gig geschaffen werden. Die Projektgruppe empfiehlt
dementsprechend,
&#8226; dass die Bundesregierung sich auf europ&#228;ischer Ebene f&#252;r eine Weiterentwicklung des Zulassungsrechts
einsetzt, das die Besonderheiten intelligenter Systeme ber&#252;cksichtigt und Wege vorsieht, wie Systeme f&#252;r
die Zulassung in sinnvoller Weise und zum Wohl von Patientinnen und Patienten weiterentwickelt werden
k&#246;nnen.
Neben der Marktzulassung von KI-basierten Medizinprodukten kann auch die unmittelbare Erstattung KI-
basierter Anwendungen durch die gesetzliche Krankenversicherung (GKV) eine H&#252;rde darstellen. Dieses Problem
wurde bei digitalen Gesundheitsanwendungen wie Apps bereits erkannt, f&#252;r die im Digitale-Versorgung-Gesetz
(DVG) eine Erprobungsphase vorgesehen ist. Die Projektgruppe empfiehlt,
&#8226; dass die Bundesregierung sich auf nationaler und europ&#228;ischer Ebene z&#252;gig f&#252;r eine Weiterentwicklung des
Zulassungsrechts und f&#252;r eine Vereinfachung seiner Umsetzung einsetzt; das Zulassungsrecht sollte die
Besonderheiten intelligenter Systeme ber&#252;cksichtigen und Wege vorsehen, wie Systeme f&#252;r die Zulassung in 
sinnvoller Weise und zum Wohl von Patientinnen und Patienten in einem angemessenen Zeitrahmen
weiterentwickelt werden k&#246;nnen.
Mit dem zunehmenden Einsatz von KI bei Diagnose, Therapie und Pflege stellt sich auch die Frage, ob die
bestehenden Haftungsregelungen im Gesundheitsbereich den neuen Anwendungen angemessen sind. Grunds&#228;tzlich
gelten auch im Gesundheitsbereich, also f&#252;r die Hersteller von Medizinprodukten und f&#252;r die sie einsetzenden
&#196;rztinnen und &#196;rzte und Krankenh&#228;user, die allgemeinen zivilrechtlichen Haftungsvorschriften.
Ob ein KI-System einen Fehler (insbesondere einen Konstruktions- bzw. Programmierfehler) im Sinne des
Produkthaftungsrechts aufweist, kann jedoch nicht durch das Recht selbst abschlie&#223;end beantwortet werden.
Vielmehr h&#228;ngt die Antwort auf diese Frage von technischen Festsetzungen insbesondere der Informatik ab, die
au&#223;erhalb des Rechts gefunden werden m&#252;ssen. Denn ein Fehler in diesem Sinn ist ein Versto&#223; gegen den
anerkannten Stand der Technik, der durch Standards oder durch Techniksachverst&#228;ndige festzulegen ist. Allerdings
k&#246;nnte es sinnvoll sein, die &#8222;berechtigte Erwartung&#8220; an die Sicherheit eines IT-Systems i. S. d. &#167; 3 des
Produkthaftungsgesetzes (ProdHaftG) insbesondere im Hinblick auf autonome KI-Systeme gesetzgeberisch konkreter zu
formulieren. Lernen KI-Systeme nicht &#8222;live&#8220; in der Anwendung, sondern werden sie erst im &#8222;ausgelernten&#8220;
Zustand eingesetzt, ergibt sich aus Sicht der Projektgruppe keine grunds&#228;tzlich andere Haftungssituation als bei
anderen Medizinprodukten.
Die Projektgruppe empfiehlt daher, vorhandene Unsicherheiten bei der Haftung zu beseitigen, indem die
Bundesregierung
&#8226; sich auf nationaler wie auf europ&#228;ischer Ebene f&#252;r klare Vorgaben zur Zertifizierung von KI-Software in
der Medizintechnik (vor allem in Zusammenarbeit mit dem Deutschen Institut f&#252;r Normung) einsetzt,
&#8226; pr&#252;ft, inwieweit geeignete Regeln notwendig sind, die eine hinreichende Absicherung von Haftungsrisiken
f&#252;r Hersteller von KI-basierten Systemen und Anwendungen sicherstellen, beispielsweise durch eine
verpflichtende Produkthaftpflicht oder eine entsprechende Deckungsvorsorge.
1.3.4 Intelligente Assistenzsysteme und Robotik in der Pflege
Die Pflege geh&#246;rt zu den besonders sensiblen Bereichen &#8211; mit einem bisher wenig ausgesch&#246;pften Potenzial,
Technologie sinnvoll einzusetzen &#8211;, bei denen die Akzeptanz von KI immer wieder diskutiert wird, es jedoch 
diverse Piloteins&#228;tze gibt. Umfragen und Erhebungen dazu geben ein sehr diverses Bild von sehr hoher bis
verhaltener Akzeptanz ab, das sehr stark von der jeweiligen Fragestellung abh&#228;ngt.1022 Fest steht, dass die Frage des
Einsatzes von KI im Pflegebereich immer eng mit den Betroffenen abgestimmt und validiert werden muss, um
&#196;ngsten und Sorgen angemessen zu begegnen. Erfahrungen zeigen aber auch, dass eine Offenheit gegen&#252;ber
technischen Anwendungen besteht, die einen sp&#252;rbaren Nutzen f&#252;r die individuelle Situation und das
Pflegesystem im Ganzen mit sich bringen.
Aus pflegewissenschaftlicher, medizinscher aber auch technologischer Sicht ist der Einsatz von KI in der Pflege
im konkreten Anwendungsfall danach abzuw&#228;gen, ob und wie er im konkreten Fall geeignet ist, die Qualit&#228;t des
Pflegeprozesses, und hier vor allem die Patientenversorgung, zu verbessern.  
Um den nutzerzentrierten Entwicklungsprozess von KI und die Maximierung der Versorgungsm&#246;glichkeiten f&#252;r
KI in der Pflege sicherzustellen, empfiehlt die Projektgruppe
&#8226; sich in der Erforschung und Entwicklung von KI-Anwendungen f&#252;r die Pflege klar am individuellen und 
gesamtgesellschaftlichen Bedarf zu orientieren,
&#8226; Bedarfsorientierung und co-kreative Prozesse aus verschiedenen Disziplinen, wie z. B. von IT und
Pflegewissenschaft, zu ber&#252;cksichtigen sowie
&#8226; dabei die zuk&#252;nftigen Anwenderinnen und Anwender einzubeziehen.
Die Frage der Kostenentwicklung durch neue KI-Anwendungen in der Pflege ist zudem aus zwei Gr&#252;nden
entscheidend: Zum einen ist es nicht das Ziel, das Pflegepersonal durch KI-Systeme zu ersetzen, sondern es muss 
um gemeinsame Mensch-Maschine-Interaktion zur Erh&#246;hung der Qualit&#228;t der Pflege gehen. Daher darf nicht der
Kostendruck ausschlaggebend sein, sondern die Qualit&#228;t der Patientenversorgung muss das
Entscheidungskriterium daf&#252;r sein, ob und wie die KI-Systeme in der Pflege autonom und/oder zusammen mit einer Fachkraft
Aufgaben &#252;bernehmen.
1022 Vgl. Stubbe et al. (2019): Akzeptanz von Servicerobotern: Tools und Strategien f&#252;r den erfolgreichen betrieblichen Einsatz, S. 8 f.
Zum anderen darf auch niemand wegen zu hoher Kosten von Anwendungen ausgeschlossen werden, die den
Alltag deutlich verbessern k&#246;nnten. Um diesen beiden Herausforderungen zu begegnen, empfiehlt die
Projektgruppe,
&#8226; die Kriterien f&#252;r die Aufnahme in das Verzeichnis der Pflegehilfsmittel so zu fassen, dass sie die
Eigenschaften und den zus&#228;tzlichen Nutzen von digitalen und KI-gest&#252;tzten L&#246;sungen erfassen, beispielsweise
eine Erh&#246;hung der Selbstst&#228;ndigkeit, die Verbesserung der zwischenmenschlichen Kommunikation oder die
Verbesserung der pers&#246;nlichen Zuwendung durch Entlastung der Pflegekr&#228;fte von anderen Aufgaben,
&#8226; die Auswirkungen des Technikeinsatzes z. B. durch einen strukturierten Monitoringprozess zu beobachten
und das Spannungs- sowie Potenzialfeld von Mensch und Maschine bei der k&#252;nftigen Personalentwicklung
und bei Personalvorgaben zu ber&#252;cksichtigen.
Zehn Handlungsempfehlungen f&#252;r die Entwicklung und den Einsatz von KI im
Gesundheitsbereich
Wie aus dem vorigen Abschnitt hervorgeht, hat die Projektgruppe eine Vielzahl von Handlungsempfehlungen
erarbeitet; diese sollen im Folgenden deutlich ausf&#252;hrlicher hergeleitet und dargestellt werden. Alle Akteure in
der Gesundheitspolitik stehen somit vor der umfassenden Aufgabe, die verschiedenen Voraussetzungen und
Rahmenbedingungen f&#252;r die Entwicklung und den Einsatz von KI in Medizin und Pflege zeitnah umzusetzen.
Neben diesem notwendigen umfassenden Blick hat die Projektgruppe zusammenfassend zehn Empfehlungen
identifiziert, die sie als zentral, dringend und repr&#228;sentativ f&#252;r die verschiedenen Handlungsfelder ansieht:
1. Die Bundesregierung sollte gemeinsam mit allen relevanten Akteuren im Gesundheitsbereich innerhalb
des n&#228;chsten Jahres eine umfassende Strategie zum Einsatz von KI im Gesundheitsbereich auflegen, die
die nachfolgenden Punkte integriert und konkrete Schritte und deren Finanzierung innerhalb der
kommenden f&#252;nf Jahre vorsieht.
2. Bund und L&#228;nder m&#252;ssen in gemeinsamer Anstrengung1023 darauf hinwirken, dass die Digitalisierung der
Infrastruktur im Gesundheitsbereich beschleunigt wird, wobei die Bedarfsangaben von Kliniken zu
ber&#252;cksichtigen sind, und dass dauerhaft in die IT-Infrastruktur investiert wird, wobei die Investitionen dem
internationalen Niveau angeglichen werden.1024 
3. Die Verf&#252;gbarkeit von Daten f&#252;r die Forschung ist zu verbessern. Daf&#252;r empfiehlt die Projektgruppe, eine
abgestufte, freiwillige und widerrufbare Datenfreigabe in enger Abstimmung mit den
Datenschutzaufsichtsbeh&#246;rden zu erm&#246;glichen, abgestimmte, interoperable und wo m&#246;glich offene Standards (mit hohen
Datenschutz- und Sicherheitsanforderungen) zu nutzen, ein nationales Versorgungsregister bzw. einen
Registerverbund und die dazugeh&#246;rigen dezentralen Vertrauensstellen aufzubauen und die
Datenschutzgesetzgebung f&#252;r den Gesundheitsbereich auf Grundlage der DSGVO schnell zu vereinheitlichen.
4. Durch eine umfassende Strategie in der Aus- und Weiterbildung muss KI-Expertise umfassend in allen 
Gesundheitsbereichen verankert werden, um eine breite Anwendung und eine hohe Qualit&#228;t in der Praxis
sicherzustellen.
5. Zur St&#228;rkung des Forschungsstandorts Deutschland und zur Sicherstellung des Transfers in die
Anwendung sind interdisziplin&#228;re &#214;kosysteme in der digitalen Gesundheitsforschung aufzubauen und
langfristige Leuchtturmprojekte von der Grundlagenforschung bis zur klinischen Translation gezielt zu f&#246;rdern.
6. Zur Erh&#246;hung der Innovationsf&#228;higkeit und Sicherung des Wirtschaftsstandorts Deutschland sind
F&#246;rderinstrumente f&#252;r Start-ups zu &#246;ffnen oder neu zu schaffen und ist ein attraktives Umfeld f&#252;r die
Gesundheitswirtschaft zu etablieren.
7. Zulassungsverfahren m&#252;ssen an neue Technologien angepasst und eine befristete Kostenerstattung f&#252;r
neue Technologien muss in der Testphase gepr&#252;ft werden.
1023 Dazu k&#246;nnten die Erfahrungen aus dem Digitalpakt Schule herangezogen werden.
1024 Das Bundeskabinett hat am 2. September 2020 ein Investitionsprogramm f&#252;r Krankenh&#228;user beschlossen, das 4 Milliarden Euro f&#252;r
die Modernisierung von Krankenh&#228;usern vorsieht. Damit soll ausdr&#252;cklich auch die digitale Infrastruktur verbessert werden, etwa in 
den Bereichen Aufbau von Patientenportalen, elektronische Dokumentation von Pflege- und Behandlungsleistungen, digitales
Medikationsmanagement, Ma&#223;nahmen zur IT-Sicherheit sowie sektoren&#252;bergreifende telemedizinische Netzwerkstrukturen.
        
 
 
 
 
   
          
  
 
 
  
   
 
   
       
 
   
   
  
  
 
  
  
 
 
   
   
      
 
 
 
  
 
      
  
         
   
 
       
       
  
  
                                               
         
           
         
       
       
        
   
    
           
2
8. M&#246;gliche L&#252;cken und Unsicherheiten bez&#252;glich der Haftung bei der Anwendung von KI im
Gesundheitswesen sind zu ermitteln; wo notwendig sind transparente Regelungen zu schaffen und L&#252;cken bzw.
Unsicherheiten mithilfe von Normierungs- und Standardisierungsverfahren zu beseitigen bzw. zu verringern.
9. KI-Anwendungen in Gesundheit und Pflege sind auf die Bed&#252;rfnisse der Patientinnen und Patienten sowie
der zu Pflegenden und der Pflegekr&#228;fte auszurichten, indem co-kreative Prozesse in der Entwicklung
aufgesetzt werden und nicht nur das technisch M&#246;gliche oder das Effizienteste, sondern der Nutzen auch im
gesamtgesellschaftlichen Zusammenhang im Vordergrund steht.
10. Der Zugang zu KI-Anwendungen im Gesundheitsbereich ist allen Patientinnen und Patienten zu
erm&#246;glichen; dabei ist die Patientensouver&#228;nit&#228;t zu wahren und insbesondere das Recht auf Nichtwissen zu
erm&#246;glichen. Sicherzustellen ist ferner, dass sich Menschen auch gegen die Anwendung von KI entscheiden
k&#246;nnen &#8211; sofern dadurch das Solidarprinzip im Gesundheitssystem nicht durch unverh&#228;ltnism&#228;&#223;ige
Mehrkosten eingeschr&#228;nkt wird und anderen Patientinnen und Patienten jetzt oder zuk&#252;nftig keine Nachteile
entstehen. 
Einf&#252;hrung: KI und Gesundheit
Was macht KI im Gesundheitswesen aus?
Es ist eine der Urfragen der Menschheitsgeschichte, wie unsere Gesundheit erhalten und Krankheiten geheilt
werden k&#246;nnen. Die Hoffnungen sind stets sehr gro&#223;, wenn neue Technologien versprechen, die
Gesundheitsversorgung zu verbessern und neue Therapien zu erm&#246;glichen. Kein Wunder, dass die Medizin eines der ersten
praktischen Anwendungsfelder der KI war1025 und auch heute oft beispielhaft aufzeigt, wie intelligente Systeme
zum Nutzen f&#252;r den Menschen eingesetzt werden k&#246;nnen.
Seit den ersten Expertensystemen in den 1980er Jahren ist die Entwicklung rasant fortgeschritten. Neue selbst
lernende Verfahren erm&#246;glichen Bild- und Spracherkennung, die in vielen medizinischen Disziplinen direkt
angewendet werden k&#246;nnen. Automatisierte Datenauswertungen k&#246;nnen bei kritischen Krankheitsverl&#228;ufen
fr&#252;hzeitig warnen oder Grundlage f&#252;r individualisierte Therapien sein.1026 
Die M&#246;glichkeiten erscheinen beinahe unbegrenzt, und weltweit forschen private und &#246;ffentliche Akteure mit
zum Teil gro&#223;en Investitionen an weiteren Entwicklungen. Viele Fragen, die an den Einsatz von KI im
Gesundheitsbereich gekoppelt sind, stellen sich daher nicht nur national. Digitale Medizinprodukte werden weltweit
entwickelt und werden immer st&#228;rker auch auf den deutschen Markt dr&#228;ngen. Nur wenn Deutschland sich aktiv
an der Entwicklung beteiligt, kann es auch die Herausforderungen, die damit einhergehen, souver&#228;n bew&#228;ltigen
und sicherstellen, dass f&#252;r die Patientinnen und Patienten und deren Versorgung und Pflege ein Nutzen erzielt
wird.
Es stellt sich eine Vielzahl an Herausforderungen, die mit den zunehmenden M&#246;glichkeiten intelligenter Systeme
im Gesundheitsbereich verbunden sind. KI ben&#246;tigt eine gro&#223;e Menge an Daten, um lernen zu k&#246;nnen. Ob und,
wenn ja, welche Gesundheitsdaten zur Verf&#252;gung gestellt werden sollen, hat der deutsche Ethikrat intensiv
analysiert; in seiner Stellungnahme1027 hat er konkrete Vorschl&#228;ge f&#252;r eine sogenannte Datenspende1028 gemacht.
&#196;hnlich hat sich auch die Plattform &#8222;Lernende Systeme&#8220; in ihrem Arbeitsgruppenbericht f&#252;r die freiwillige
Datenfreigabe ausgesprochen. Sie schl&#228;gt dazu vor, die Rolle eines Datentreuh&#228;nders einzunehmen, um die
Datensouver&#228;nit&#228;t zu sichern.1029 
Wie sich das deutsche Gesundheitssystem durch den Einsatz von KI ver&#228;ndern wird, besch&#228;ftigt neben
Expertinnen und Experten1030 auch die B&#252;rgerinnen und B&#252;rger immer mehr. Droht die Gefahr der
&#8222;Entmenschlichung&#8220;, in der die Menschen in eine Spirale der automatisierten &#8222;Perfektionierung&#8220; hineinlaufen? Geh&#246;ren
langwierige Krankheiten oder Behandlungsfehler bald der Vergangenheit an, weil KI direkt die richtige Therapie
1025 Vgl. Krumm und Dwertmann (2019): Perspektiven der KI in der Medizin, S. 161.
1026 Siehe auch Kapitel 3.1 dieses Projektgruppenberichts [KI-Anwendungen in der Medizin &#8211; Beispiele aus Diagnose und Therapie].
1027 Vgl. Deutscher Ethikrat (2017): Big Data und Gesundheit.
1028 Die Projektgruppe hat sich darauf verst&#228;ndigt, statt des Begriffs der Datenspende den Begriff der Datenfreigabe zu verwenden, da 
der Begriff der Spende das Weggeben von etwas bezeichnet, &#252;ber das man selbst nicht mehr verf&#252;gen kann. Dies ist bei der Freigabe
von Daten nicht der Fall. Man kann die Daten weiter selbst nutzen, die Einwilligung zur Nutzung der Daten zur&#252;ckziehen und von 
den Ergebnissen, die mithilfe der Daten erzielt wurden, potenziell auch selbst profitieren.
1029 Vgl. Plattform Lernende Systeme (2019): Lernende Systeme im Gesundheitswesen &#8211; Bericht der Arbeitsgruppe Gesundheit,
Medizintechnik Pflege, S. 29.
1030 Vgl. Haring (2019): Gesundheit digital; Huss (2019): K&#252;nstliche Intelligenz, Robotik und Big Data in der Medizin.
erkennt? Wie bleiben neue Methoden bezahlbar, sodass sie nicht nur einer bestimmten Gruppe zur Verf&#252;gung
stehen? Besteht ggf. sogar Anspruch auf den Einsatz von KI-L&#246;sungen im Gesundheitswesen, sofern sie
verf&#252;gbar sind? Wie ver&#228;ndert es das deutsche Solidarsystem, wenn auch globale Akteure hineindr&#228;ngen und durch
einen ungleich gr&#246;&#223;eren Datenzugang mit vermeintlich attraktiveren Angeboten zur individuellen
Gesundheitsversorgung locken? Wollen die Menschen alles wissen, wenn jedes Gen analysiert werden kann und eine
pers&#246;nliche Vorhersage der Lebenserwartung versprochen wird?
Wie stellen sich die Menschen schlie&#223;lich die Zukunft der Pflege vor? Sind Pflegeroboter mit gro&#223;en Kulleraugen 
ein erstrebenswertes Ziel oder ist durch kluge Mensch-Maschine-Interaktion die bessere Situation f&#252;r
Pflegekr&#228;fte und f&#252;r die zu Pflegenden zu schaffen? Das B&#252;ro f&#252;r Technikfolgenabsch&#228;tzung beim Deutschen
Bundestag (TAB) hat dazu bereits eine umfassende Stellungnahme1031 vorgelegt, in der sehr konkrete Assistenzsysteme, 
wie der intelligente Pflegewagen, herausgestellt werden, w&#228;hrend andere Vorstellungen eher in den Bereich
Science-Fiction eingeordnet werden.  
Es zeigt sich: Ebenso unbegrenzt wie die M&#246;glichkeiten sind die Fragen, die sich mit der Verf&#252;gbarkeit und dem
Einsatz von KI in der Medizin stellen. Die Enquete-Kommission K&#252;nstliche Intelligenz hat aus diesem Grund
eine Projektgruppe zu diesem Anwendungsgebiet eingesetzt, die sich ausf&#252;hrlich mit den Voraussetzungen, den
Chancen und den Risiken auseinandergesetzt hat. Der Projektgruppenbericht mit seinen Handlungsempfehlungen
ist das Ergebnis der Arbeit dieser Projektgruppe.
Er soll eine erste Grundlage darstellen, um den notwendigen politischen und rechtlichen Rahmen f&#252;r den Einsatz
von KI in Medizin und Pflege zu setzen. Gemeinsames Ziel der Projektgruppe war es, notwendige Schritte zu
pr&#252;fen, die sicherstellen, dass das deutsche Gesundheitssystem und die gesamte Gesellschaft von den m&#246;glichen
Verbesserungen in Versorgung, Therapie und Pflege profitieren. Gleichzeitig sind m&#246;gliche Sch&#228;den vom
Einzelnen und der Gesellschaft abzuwenden; auch ist der globale Rahmen, in dem sich Deutschland bewegt, zu
ber&#252;cksichtigen. 
Um dieses Ziel zu erreichen, hat die Projektgruppe zun&#228;chst Themen und Leitfragen ermittelt, die im folgenden
Abschnitt dargestellt sind. Vorab finden sich zudem grunds&#228;tzliche ethische &#220;berlegungen, die f&#252;r alle weiteren
Themen die Grundlage darstellen, auf der die Projektgruppe &#8222;KI und Gesundheit&#8220; aufbaut. In Kapitel 3 dieses
Projektgruppenberichts [Anwendungen von KI in Gesundheit und Pflege] findet sich ein &#220;berblick &#252;ber KI-
Anwendungen, die in der Entwicklung oder bereits im Einsatz sind, verbunden mit einer tabellarischen &#220;bersicht
&#252;ber die SWOT-Analyse der St&#228;rken, Schw&#228;chen, Risiken und Chancen von KI im Gesundheitsbereich. Die
tiefgehende Analyse der einzelnen Handlungsfelder und die entsprechenden Empfehlungen, die f&#252;r den Einsatz
von KI im Gesundheitsbereich relevant sind, finden sich in Kapitel 4 dieses Projektgruppenberichts [
Handlungsfelder], bevor abschlie&#223;end in Kapitel 5 dieses Projektgruppenberichts [Hintergrundinformationen zur
Projektgruppe KI und Gesundheit] die Arbeitsweise der Projektgruppe ausf&#252;hrlich dargestellt wird.
Ziele, Themen und Leitfragen
Gesundheit ist elementar f&#252;r jeden einzelnen Menschen und f&#252;r die Gesellschaft als Ganzes. Sie ist eine wichtige
Voraussetzung daf&#252;r, ein unbeschwertes Leben f&#252;hren zu k&#246;nnen, frei von Schmerzen und &#196;ngsten vor
Erkrankungen zu sein oder eine verk&#252;rzte Lebenserwartung zu haben. Es ist daher Aufgabe auch der Politik, alle
notwendigen und machbaren Ma&#223;nahmen zu ergreifen, die der Gesundheit des Einzelnen und der gesamten
Gesellschaft f&#246;rderlich sind. 
Dieser Aufgabe hat sich die Projektgruppe &#8222;KI und Gesundheit&#8220; gestellt und beabsichtigt mit ihrem Bericht, die
Schritte aufzuzeigen, die notwendig sind, um den Einsatz von KI im Gesundheitsbereich zum Wohl des
Menschen zu erm&#246;glichen und Schaden abzuwenden. Dazu hat sie sich die folgenden sechs Ziele gesetzt, die die
Politik im Zusammenhang mit KI und Gesundheit verfolgen sollte:
Die Projektgruppe will KI in der Gesundheit so entwickeln und einsetzen, dass
&#8226; erreicht wird, dass Menschen gesund bleiben, Diagnose und Therapie auf h&#246;chstm&#246;glichem Niveau
stattfinden und weniger Menschen an den gro&#223;en Volkskrankheiten oder anderen Krankheiten, aber auch z. B. 
an seltenen Erkrankungen sterben,
&#8226; Lebensqualit&#228;t und Eigenst&#228;ndigkeit &#8211; auch bei chronischen Erkrankungen und im Alter &#8211; l&#228;nger erhalten
bleiben,
1031 Vgl. Kehl (2018): Robotik und assistive Neurotechnologien in der Pflege &#8211; gesellschaftliche Herausforderungen.
&#8226; die menschliche Komponente in der Gesundheitsversorgung gest&#228;rkt wird,
&#8226; das Gesundheitssystem und die im Gesundheitswesen Besch&#228;ftigten entlastet werden,
&#8226; ein solidarisches Gesundheitssystem erhalten bleibt, zu dessen Leistungen alle Zugang haben,
&#8226; individuelle Pers&#246;nlichkeits- und Privatheitsrechte gesch&#252;tzt werden.
Welche Ma&#223;nahmen m&#252;ssen Politik und Gesellschaft ergreifen, um diese Ziele zu erreichen? Um diese zu
ermitteln, hat die Projektgruppe folgende Leitfragen bearbeitet:
1. Welche Potenziale bietet KI tats&#228;chlich durch die verschiedenen Szenarien in Pr&#228;vention, Diagnose und
Therapie von Krankheiten?1032 
2. Welche Voraussetzungen m&#252;ssen f&#252;r den Einsatz von KI im Gesundheitswesen erf&#252;llt sein?
3. Wie kann die Verf&#252;gbarkeit geeigneter Daten f&#252;r die Erforschung und den Einsatz von KI sichergestellt
und verbessert werden?
4. Welche Risiken birgt KI im Gesundheitsbereich f&#252;r den Datenschutz von Patientinnen und Patienten und
f&#252;r die informationelle Selbstbestimmung?
5. Was bedeuten die neuen Technologien der KI f&#252;r die Aus- und Weiterbildung in Gesundheitsberufen?1033 
6. Welche Unterst&#252;tzung ben&#246;tigt medizinische Forschung f&#252;r die Entwicklung von KI-Methoden und ihren
Transfer in die Anwendung?
7. Wie stellt Deutschland sicher, dass seine Gesundheitswirtschaft den Weg in die neue Technologie
mitgestaltet?1034 
8. Welche rechtlichen H&#252;rden oder Regelungsl&#252;cken gibt es f&#252;r den Einsatz von KI im
Gesundheitswesen?1035 
9. Besteht die Gefahr einer Entmenschlichung von Gesundheitsversorgung und Pflege durch eine
Automatisierung verschiedener Bereiche?1036 
Ethische Fragen
Die Entwicklung und der Einsatz von KI-Anwendungen im Gesundheitsbereich werfen zahlreiche ethische
Fragen auf. M&#252;ssen Patientinnen und Patienten k&#252;nftig ihre Gesundheitsdaten preisgeben und werden so zum
&#8222;gl&#228;sernen Patienten&#8220;? Was passiert, wenn eine Krankheit mithilfe von KI zwar diagnostiziert, aber nicht geheilt oder
behandelt werden kann? Wie kann das Recht auf Nichtwissen realisiert werden? Welche Entscheidungen sollen
in jedem Fall nur von &#196;rztinnen und &#196;rzten getroffen werden? Wo verlaufen m&#246;gliche absolute Grenzen f&#252;r den
Einsatz von selbstlernenden Algorithmen im Gesundheitsbereich? Wie ver&#228;ndern intelligente Systeme das
Verh&#228;ltnis von &#196;rztin oder Arzt, Pflegepersonal und Patientin oder Patient? Haben die Menschen in Zukunft ein
Recht auf menschliche Pflege, auch wenn ein Pflegeroboter g&#252;nstiger w&#228;re? Wie kann sichergestellt werden,
dass Zeitersparnisse durch KI-Anwendungen auch tats&#228;chlich den Patientinnen und Patienten zugutekommen 
und nicht zur Kostenersparnis und f&#252;r Personalabbau genutzt werden? Wie kann sichergestellt werden, dass KI-
Anwendungen f&#252;r alle Menschen gleich gut funktionieren &#8211; egal ob Frau oder Mann, alt oder jung, hellh&#228;utig 
oder dunkelh&#228;utig? Diese und andere ethische Fragen werden von Politik, Wissenschaft und Gesellschaft k&#252;nftig
diskutiert und beantwortet werden m&#252;ssen.
Ethische Fragestellungen treten im Gesundheitsbereich h&#228;ufig auf. Sowohl in der medizinischen Forschung als
auch in der Therapie von Patientinnen und Patienten stellen sich ethische Fragen, mit denen sich
Ethikkommissionen, wie z. B. der Deutsche Ethikrat, befassen. Teilweise besch&#228;ftigen sich diese Gremien, die traditionell
eher medizinethischen Fragestellungen nachgehen, nun auch mit den Auswirkungen neuer digitaler
Technologien; ein Beispiel daf&#252;r ist der Ethikrat, der ein ausf&#252;hrliches Papier zu Big Data herausgegeben hat.1037 Teilweise
gibt es zus&#228;tzlich Gremien, die bereichs&#252;bergreifend ethische Fragestellungen behandeln, die in der Forschung
1032 Siehe Kapitel 3.1 dieses Projektgruppenberichts [KI-Anwendungen in der Medizin &#8211; Beispiele aus Diagnose und Therapie].
1033 F&#252;r die Fragen 2 bis 5 siehe Kapitel 4.1 [Voraussetzungen f&#252;r KI im Gesundheitsbereich].
1034 F&#252;r die Fragen 6 bis 7 siehe Kapitel 4.2 dieses Projektgruppenberichts [F&#246;rderung des Forschungs- und Wirtschaftsstandorts &#8211; f&#252;r 
eine souver&#228;ne Entwicklung von KI im Gesundheitsbereich].
1035 Siehe Kapitel 4.3 dieses Projektgruppenberichts [Entwicklung, Marktzulassung, Erstattung und Haftung f&#252;r KI-basierte
Anwendungen im Gesundheitsbereich].
1036 Siehe Kapitel 4.4 dieses Projektgruppenberichts [KI in der Pflege sowie f&#252;r Menschen mit Behinderung].
1037 Vgl. Deutscher Ethikrat (2017): Big Data und Gesundheit.
        
 
 
   
 
 
  
    
   
  
 
  
   
       
   
     
  
 
 
           
    
   
 
 
      
 
   
 
   
  
  
       
 
 
  
 
     
 
  
   
            
       
  
          
  
 
                                               
              
 
          
           
3
oder durch die M&#246;glichkeiten neuer Technologien aufkommen, wie z. B. die Datenethikkommission oder auf
EU-Ebene die European Group on Ethics in Science and New Technologies (EGE).
Auch bei Forschungseinrichtungen, Berufsverb&#228;nden und den L&#228;ndern sind mit den Ethikkommissionen solche
Gremien etabliert, die weniger mit Grundsatzfragen als mit der Beurteilung konkreter Forschungsvorhaben und
medizinischer Interventionen befasst sind. F&#252;r diese Beurteilung gibt es konkrete medizinethische Grunds&#228;tze,
wobei die Deklaration von Helsinki des Welt&#228;rztebunds ein entscheidendes Grundsatzdokument ist.1038 
Je mehr sich Gremien mit Fragestellungen besch&#228;ftigen, die sich aus dem Einsatz von KI ergeben, desto st&#228;rker
sollte sichergestellt sein, dass entsprechende technische Expertise einbezogen wird.
Oft werden vier Grundprinzipien der medizinischen Ethik aufgef&#252;hrt: Wohltun bzw. F&#252;rsorge (beneficence),
Nichtschaden (non-maleficence), Autonomie (autonomy) und Gerechtigkeit (justice).1039 Inwieweit der Einsatz
von Methoden der KI in der Medizin geboten oder auszuschlie&#223;en ist, folgt grunds&#228;tzlich der gleichen Abw&#228;gung
zwischen Wohltun und Nichtschaden wie bei anderen Methoden; spezifische Fragestellungen ergeben sich
insbesondere beim Prinzip der Gerechtigkeit (mit Hinblick auf die Potenziale individualisierter Methoden, auf
m&#246;glichen Bias in Datens&#228;tzen und auf den Zugang) und f&#252;r das Prinzip der Autonomie, also auf das
Selbstbestimmungsrecht der Patienten, unter dem nicht nur die Freiheit von &#228;u&#223;erer Bestimmung und Einflussnahme zu
verstehen ist, sondern auch die F&#246;rderung der Entscheidungsf&#228;higkeit als Grundlage einer informierten
Einwilligung. 
Ein Beispiel f&#252;r Gerechtigkeitsfragen, die sich mit dem Einsatz von KI stellen, ist die unterschiedliche Robustheit
von KI-Anwendungen f&#252;r bestimmte Gruppen. So konstatiert der Gemeinsame Bundesausschuss in seiner
Stellungnahme, dass erste Anwendungen zur Erkennung von Hautkrebs erprobungsreif seien; diese erzielten bislang
allerdings nur f&#252;r hellh&#228;utige Menschen eine hohe Qualit&#228;t der Ergebnisse. Hier m&#252;ssen Entwicklungsprozesse
sichergestellt werden, durch die bestimmte Gruppen von Menschen von Anwendungen weder bevorzugt noch
benachteiligt werden.
Ethische Standards allein reichen jedoch nicht aus, sondern m&#252;ssen sich auch in gesetzlichen Regelungen
wiederfinden. Denn so wichtig ethische Standards sind, so bleiben diese unverbindlich, solange keine
entsprechenden Gesetze oder sonstige zwingende Regelungen geschaffen werden, die demokratisch zustande gekommen
sind, deren Einhaltung unabh&#228;ngig kontrolliert und deren Verletzung effektiv sanktioniert wird. Das bestehende
Recht samt verfassungsrechtlicher und europ&#228;ischer Vorgaben sieht bereits sehr umfangreiche Regelungen vor,
die diese Fragen ber&#252;hren und die ggf. entsprechend weiterentwickelt werden m&#252;ssen.
Anwendungen von KI in Gesundheit und Pflege
KI ist zun&#228;chst eine sehr abstrakte Technologie, bei der es sich im Wesentlichen um die automatisierte
Auswertung von Daten handelt. Gerade bei Anwendungen im Gesundheitsbereich l&#228;sst sich aber besonders gut
veranschaulichen, welchen unmittelbaren Nutzen sie konkret f&#252;r Menschen bringen kann und welche weiter
reichenden Ver&#228;nderungen oder auch Risiken damit verbunden sein k&#246;nnen. So nennt auch die High-Level Expert Group 
on Artificial Intelligence der Europ&#228;ischen Union in ihren Ethik-Leitlinien Gesundheit und Wohlergehen als
Beispiel f&#252;r die Chancen einer vertrauensw&#252;rdigen KI, da mit ihrer Hilfe Behandlungen intelligenter und
zielgerichteter gestaltet, Analysen pr&#228;ziser und detaillierter durchgef&#252;hrt und ma&#223;geschneiderte vorbeugende
Ma&#223;nahmen entwickelt werden k&#246;nnen.1040 
Das Ziel dieses Kapitels ist es, einen ersten &#220;berblick &#252;ber die Einsatzm&#246;glichkeiten und den aktuellen Stand
der Entwicklung im Gesundheitsbereich zu geben. Dieser &#220;berblick kann aufgrund der Vielzahl der m&#246;glichen
Einsatzfelder nicht vollst&#228;ndig oder abschlie&#223;end sein. Er kann aber einen Eindruck vermitteln, mit welchen
Fragen sich die Politik aufgrund der Potenziale und der Ver&#228;nderungen durch KI im Gesundheitsbereich
auseinandersetzen muss. Zur besseren &#220;bersicht ist das Kapitel in die Unterkapitel Medizin [KI-Anwendungen in
der Medizin &#8211; Beispiele aus Diagnose und Therapie], Pflege [KI-Anwendungen in der Pflege] sowie weitere
Anwendungsbereiche mit Gesundheitsbezug [Weitere Anwendungsgebiete mit Gesundheitsbezug] unterteilt. Es
endet auf Grundlage des &#220;berblicks und der Analysen der Projektgruppe abschlie&#223;end mit einer SWOT-Analyse,
die insbesondere die Chancen und Risiken behandelt, die handlungsanleitend f&#252;r die kommenden Jahre sein
k&#246;nnten. 
1038 Vgl. World Medical Association (2013): WMA Declaration of Helsinki &#8211; Ethical Principles for Medical Research Involving Human
Subjects.
1039 Vgl. Beauchamp und Childress (2013): Principles of biomedical ethics.
1040 Vgl. High-Level Expert Group on Artificial Intelligence (2019): Ethik-Leitlinien f&#252;r eine vertrauensw&#252;rdige KI, S. 42&#8211;43.
KI-Anwendungen in der Medizin &#8211; Beispiele aus Diagnose und Therapie
Im Folgenden werden unterschiedliche Anwendungsgebiete in der Medizin beispielhaft diskutiert, die entweder
bereits heute von KI-Methoden stark profitieren oder von denen erwartet werden kann, dass sie in Zukunft an
Bedeutung gewinnen werden. Es zeigt sich, dass insbesondere die Fortschritte intelligenter Systeme in der Bild-
und Spracherkennung gro&#223;e Potenziale f&#252;r die Medizin mit sich bringen. Aber auch die automatisierte Analyse
verschiedener medizinischer Patientendaten kann M&#246;glichkeiten bieten, Krankheiten fr&#252;her zu erkennen oder
individualisiert zu therapieren. Durch die Beispiele werden auch die Herausforderungen deutlich. So wird die
Frage aufgeworfen, ob und welche zus&#228;tzlichen Daten f&#252;r solche Anwendungsszenarien erhoben werden sollten,
die bisher von gesunden Patientinnen und Patienten nicht unbedingt vorliegen.
3.1.1 Bilderkennung: KI-Verfahren in der Krebsdiagnose
Bildgebende Verfahren z&#228;hlen zu den wichtigsten Untersuchungsmethoden f&#252;r die Diagnose nicht nur von
Tumoren. Zu den bildgebenden Verfahren geh&#246;ren die R&#246;ntgenuntersuchung, die Computertomografie (CT), die
Magnetresonanztomografie (MRT), die Szintigrafie, die Positronen-Emissions-Tomografie (PET), die
Sonografie, die Endoskopie und die Dermatoskopie.1041 
Intelligente Systeme haben sich vor allem in der Bilderkennung in den letzten Jahren entscheidend
weiterentwickelt. In der Medizin bietet dies neue M&#246;glichkeiten, Ergebnisse der bildgebenden Verfahren durch Algorithmen
auf Auff&#228;lligkeiten zu pr&#252;fen und m&#246;gliche Symptome, z. B. f&#252;r eine Krebserkrankung, automatisiert und
potenziell mit h&#246;herer Verl&#228;sslichkeit zu erkennen.
Der Nutzen der neuronalen Netze zur Bilderkennung ist seit den 1980er Jahren bekannt. Durch eine wesentlich
h&#246;here Rechenleistung, Verbesserungen der Modelle und der Verf&#252;gbarkeit von umfangreichen Datens&#228;tzen
hoher Qualit&#228;t konnte die Treffsicherheit der Bilderkennung in den letzten Jahren erheblich gesteigert werden. 
Tiefe neuronale Netze bieten bei der Analyse von medizinischen Bilddaten eine Leistung, die mit der von
Fach&#228;rztinnen und Fach&#228;rzten vergleichbar oder sogar besser ist. Durch den Einsatz bildverarbeitender KI-Systeme
kann die &#196;rztin oder der Arzt bei der Diagnose unterst&#252;tzt werden; m&#246;glich ist sogar das Ersetzen rein physischer
T&#228;tigkeiten.
Ob KI-Systeme die Anzahl an Fehldiagnosen verringern, wird ma&#223;geblich von der Akzeptanz dieser Systeme
und deren Integration in die klinischen Arbeitsabl&#228;ufe abh&#228;ngen. Dabei darf der Aufwand zur Erstellung und
Pflege der notwendigen Trainingsdaten nicht untersch&#228;tzt werden. 
Bei erfolgreicher Entwicklung und richtigem Einsatz k&#246;nnte intelligente Bilderkennung gerade im Kampf gegen
die gro&#223;e Volkskrankheit Krebs durch eine bessere Erkennungsrate einen unmittelbaren Fortschritt f&#252;r Betroffene
bringen, die dadurch bessere Therapiechancen erhielten. Bei Hautkrebs, Lungenkrebs und Brustkrebs ist diese
Entwicklung deutlich fortgeschritten und kann bereits erste Erfolge vorweisen.1042 Der Hautkrebs ist eine der
h&#228;ufigsten Krebsarten. Die gef&#228;hrlichste Art des Hautkrebses ist das maligne Melanom (schwarzer Hautkrebs).
Sofern der Tumor noch keine Metastasen gebildet hat, liegt die 5-Jahres-&#220;berlebensrate &#252;ber 70 Prozent. Eine
1041 R&#246;ntgenuntersuchung, Szintigrafie und Endoskopie erzeugen zweidimensionale, CT, MRT und PET dreidimensionale Bilder.
R&#246;ntgenuntersuchung, CT, Szintigrafie und PET verursachen eine Strahlenbelastung, bei der die Patientin bzw. der Patient einer &#228;u&#223;eren
(R&#246;ntgenuntersuchung, CT) oder durch Radionuklide verursachten inneren (Szintigrafie, PET) Strahlung ausgesetzt wird. Die
Sonografie ist nicht mit Strahlenbelastung verbunden; sie ist jedoch ungeeignet zur Untersuchung tieferer Gewebeschichten. Sie kann
Hinweise auf Tumore liefern, zur Krebsdiagnose reicht sie in der Regel jedoch nicht aus. Die Endoskopie liefert Kamerabilder von 
inneren Oberfl&#228;chen und wird oft zur Untersuchung des Magen-Darm-Traktes verwendet. Bei der Szintigrafie und der PET wird ein
Radionuklid gespritzt, das sich in unterschiedlichen Geweben auf verschiedene Weise anreichert. Dadurch l&#228;sst sich die Funktion 
eines Gewebes oder Organs beurteilen. Mit einer PET lassen sich auch kleine Tumore entdecken, die mit einem CT oder MRT nur
schlecht erkannt werden. Ein Nachteil von CT, MRT und PET ist &#8211; neben den hohen Kosten &#8211; die lange Untersuchungsdauer, was
dazu f&#252;hrt, dass die bewegten Organe Herz und Lunge nur in verminderter Qualit&#228;t dargestellt werden k&#246;nnen. Die Dermatoskopie
dient der Untersuchung von Hautver&#228;nderungen. Dabei wird ein bestimmtes &#214;l (Immersions&#246;l) auf die Haut aufgetragen und diese 
durch ein Auflichtmikroskop (Dermatoskop) betrachtet. Mithilfe von polarisiertem Licht k&#246;nnen tiefere, mit unpolarsiertem Licht
oberfl&#228;chliche Hautschichten begutachtet werden. Den bildgebenden Verfahren kann sich eine Entnahme von Gewebeproben
(Biopsie) anschlie&#223;en, um die Diagnose durch eine histologische Untersuchung zu sichern. Dabei wird ein Schnitt der Gewebeprobe
angef&#228;rbt und unter dem Lichtmikroskop untersucht.
1042 Vgl. auch Fu&#223;noten 1046 und 1047; vgl. Stanford University (2017): Deep learning algorithm does as well as dermatologists in
identifying skin cancer.
Fr&#252;herkennung ist durch eine Dermatoskopie der Pigmentflecken m&#246;glich. Neuronale Netze k&#246;nnen ein malignes
Melanom mittlerweile genauso treffsicher erkennen wie Dermatologen. 1043 
Mehrere Unternehmen haben bereits KI-Anwendungen zur Diagnose von Hautkrebs entwickelt und auf den
Markt gebracht. Ein Hersteller bietet z. B. Ger&#228;te an, die Hautver&#228;nderungen mithilfe von tiefen neuronalen
Netzen analysieren.1044 Mit einer Smartphone-Anwendung ist diese Diagnostik auch Endanwenderinnen und
Endanwendern zug&#228;nglich, wobei die limitierenden Faktoren die geringe Bildqualit&#228;t der Kamera des Smartphones
und die uneinheitliche Beleuchtung der Haut im Vergleich zu einem Dermatoskop sind. Ein anderer Hersteller
kombiniert etwa Lasertechnologie mit KI, um Hautkrebs fr&#252;hzeitig bei Routineuntersuchungen zu erkennen.1045 
Die prinzipielle M&#246;glichkeit, mit dieser Technologie die Diagnose in die H&#228;nde von Patientinnen und Patienten
selbst zu legen, verdeutlicht die grunds&#228;tzlichen Auswirkungen auf das Gesundheitssystem, auch wenn hier heute
aufgrund der genannten Einschr&#228;nkungen in der Qualit&#228;t noch von einer theoretischen M&#246;glichkeit gesprochen
werden muss. Der Mangel von fachlicher und menschlicher Begleitung bei der Eigendiagnose durch KI k&#246;nnte
problematisch sein.
Lungenkrebs z&#228;hlt zu den h&#228;ufigsten b&#246;sartigen Erkrankungen.1046 An ihm sterben mehr Menschen als an
Brustkrebs und Prostatakrebs. Auch hier sind neuronale Netze in der Lage, die CT-Scans genauso gut oder sogar besser
zu analysieren als Radiologinnen und Radiologen.1047 In den Szenarien, in denen das Modell eine h&#246;here
Sensitivit&#228;t und Spezifit&#228;t als die Beurteilung durch eine Radiologin oder einen Radiologen besitzt, kann der Einsatz
neuronaler Netze die Anzahl &#252;bersehener Krebsf&#228;lle verringern und unn&#246;tige Behandlungen vermeiden. Auch
bei der Diagnose von Brustkrebs kommt KI bereits erfolgreich zum Einsatz.1048 
Notwendig f&#252;r das Training der neuronalen Netze sind annotierte Bilddaten in gro&#223;er Anzahl (etwa 100 000 
Bilder). Damit ein KI-System die Position und Art eines Tumors in einem medizinischen Bild angeben kann,
m&#252;ssen diese Informationen auch in den Trainingsdaten vorhanden sein. Diese Arbeit ist aufwendig und teuer,
weil sie nur von medizinischen Fachleuten ausgef&#252;hrt werden kann. Fehlerhafte Annotationen f&#252;hren zu einer
verminderten Qualit&#228;t des Datensatzes. Idealerweise ist die Diagnose histologisch gesichert. Die Datens&#228;tze
m&#252;ssen gepflegt werden, um neue Informationen &#252;ber den Gesundheitszustand der Patientinnen und Patienten zu
ber&#252;cksichtigen, von denen die Bilddaten gewonnen wurden. Jede Verbesserung der Analytik, etwa durch eine
h&#246;here Aufl&#246;sung der bildgebenden Verfahren, einen h&#246;heren Signal-Rausch-Abstand oder durch neuartige
Ger&#228;te, erfordert neue Trainingsdaten, die mit den verbesserten Methoden gewonnen wurden. 
1043 Zahlreiche Arbeiten haben sich mit der Beurteilung von Melanomen durch Verfahren der Bildverarbeitung besch&#228;ftigt. Esteva et al.
trainierten ein tiefes neuronales Netz f&#252;r die Klassifikation von Hautver&#228;nderungen, vgl. Esteva et al. (2017): Dermatologist-level
classification of skin cancer with deep neural networks. Das vortrainierte Netz wurde mit klinischen Bildern trainiert, die bereits von 
Dermatologinnen und Dermatologen klassifiziert worden waren. Unter den 129 450 Bildern des Trainingsdatensatzes befanden sich
3 374 Bilder, die durch eine Dermatoskopie gewonnen wurden, und 1 942 Bilder, bei denen die Diagnose durch eine Biopsie gesichert
wurde. Letztere Bilder wurden verwendet, um das trainierte Netz zu testen. Die Treffsicherheit sowohl bei der Erkennung des
malignen Melanoms als auch der Diagnose anderer Hautver&#228;nderungen war vergleichbar mit der Leistung von 21 Dermatologinnen und 
Dermatologen. Dieses Ergebnis zeigt, dass neuronale Netze zur Fr&#252;herkennung des Melanoms geeignet sind. Zu beachten ist jedoch, 
dass bei der dermatologischen Untersuchung Pigmentflecke nicht isoliert, sondern unter Ber&#252;cksichtigung des Hauttyps und des
Aussehens anderer Pigmentflecke beurteilt werden. Allgemein&#228;rztinnen und -&#228;rzten, die nicht die Erfahrung von Dermatologinnen 
und Dermatologen besitzen, k&#246;nnen diese neuronalen Netze eine wertvolle Unterst&#252;tzung bieten.
1044 Weitere Informationen dazu unter: https://www.fotofinder.de/ (zuletzt abgerufen am 9. Juli 2020).
1045 Weitere Informationen dazu unter: https://www.magnosco.com/ (zuletzt abgerufen am 9. Juli 2020).
1046 Vgl. Ardila et al. (2019): End-to-end lung cancer screening with three-dimensional deep learning on low-dose chest computed
tomography.
1047 Ardila et al. trainierten ein Modell zur Erkennung und Vorhersage von Lungenkrebs anhand von CT-Scans, vgl. Ardila et al. (2019):
End-to-end lung cancer screening with three-dimensional deep learning on low-dose chest computed tomography. Ein
dreidimensionales tiefes neuronales Netz wurde mit 42 290 CT-Scans von 14 851 Patientinnen und Patienten trainiert, von denen 578 nach einem
Jahr einen durch Biopsie best&#228;tigten Lungenkrebs entwickelten. CT-Scans von Personen, die keinen Lungenkrebs entwickelten,
wurden als negative Trainingsdaten verwendet. Die Daten sind als National Lung Cancer Screening Trial (NLST) Dataset (Daten-Set der
Nationalen Lungenkrebs-Screening-Studie) &#252;ber das National Cancer Institute verf&#252;gbar. Die Treffsicherheit des Modells bei der
Erkennung und der Vorhersage von Lungenkrebs lag in verschiedenen Szenarien &#252;ber oder war gleichauf mit der Leistung von 
Radiologinnen und Radiologen.
1048 Cire&#351;an et al. haben ein tiefes neuronales Netz verwendet, um im Schnittbildern von Proben aus Brustgewebe die Anzahl der Zellen 
zu z&#228;hlen, die sich im Stadium der Teilung (Mitose) befinden: vgl. Cire&#351;an et al. (2013): Mitosis detection in breast cancer histology 
images with deep neural networks. Diese Zahl besitzt einen prognostischen Wert in der Krebstherapie. Diese Arbeit ist schwierig und
aufwendig, wenn sie von einer Histologin oder einem Histologen durchgef&#252;hrt wird. Das Netz erkannte 70 Prozent aller Mitosen und 
besa&#223; eine bessere Leistung als andere Verfahren.
3.1.2 Spracherkennung: Diagnose von Alzheimer durch automatisierte kognitive Tests
Bisherige Forschungsergebnisse zeigen, dass KI-Systeme das Potenzial besitzen, Alzheimer-Erkrankungen
schon in einem fr&#252;hen Stadium zu diagnostizieren.1049 Die kognitive Testung bietet ebenfalls viel Potenzial zur
Verbesserung durch KI-Algorithmen. Ungeachtet der zu untersuchenden Zielgruppe erfordert momentan eine
aussagekr&#228;ftige kognitive Testung qualifizierte Fachleute aus den Gebieten Neurologie, Psychiatrie und
Neuropsychologie und relativ viel Zeit (mehr als eine Stunde pro Untersuchung). In der medizinischen
Prim&#228;rversorgung (Haus&#228;rztin, Hausarzt oder Pflege) sind solche Untersuchungen wegen mangelnder Expertise und aus
&#246;konomischen Gr&#252;nden nicht darstellbar. Erst in fortgeschrittenen Stadien einer kognitiven St&#246;rung (z. B. bei
einer Demenz durch Alzheimer) werden solche Untersuchungen in der Sekund&#228;rversorgung (Fach&#228;rztin oder
Facharzt) oder Terti&#228;rversorgung (Krankenhaus) rentabel. Zu diesem Zeitpunkt ist der Krankheitsverlauf
allerdings oft nicht mehr stark genug beeinflussbar; dies gilt besonders bei degenerativen Erkrankungen wie etwa
Alzheimer, frontotemporaler Lob&#228;rdegeneration und Parkinson. KI kann helfen, zum einen die Testung an sich
zu unterst&#252;tzen, um dadurch weniger auf Expertise angewiesen zu sein, und zum anderen die Testung durch
Sprach- bzw. Videoanalyse per Telemedizin dezentraler anzubieten (&#246;rtlich unabh&#228;ngig von Spezialkliniken und
Krankenh&#228;usern). Die fr&#252;hzeitigere Erkennung von Demenzerkrankungen er&#246;ffnet auch der in sp&#228;teren
Krankheitsphasen stark eingeschr&#228;nkten Pharmaforschung neue M&#246;glichkeiten.
3.1.3 Mustererkennung in medizinischen Daten zur Pr&#228;vention, zur Diagnose und zum 
Monitoring
KI kann nicht nur Muster in Bildern und Sprache erkennen. Intelligente Systeme sind auch besonders geeignet,
Auff&#228;lligkeiten in verschiedenen Arten von medizinischen Daten zu erkennen. Wo fr&#252;her noch die hauseigene
Laborantin oder der hauseigene Laborant gemerkt hat, dass bei einer Patientin oder einem Patienten die
Kombination von Laborergebnissen Behandlungsbedarf anzeigt, werden Analysen in Kliniken mittlerweile h&#228;ufig
ausgelagert. Bei der Identifikation von Auff&#228;lligkeiten k&#246;nnen daher heute intelligente Systeme, die die Entwicklung
medizinischer Daten &#252;berpr&#252;fen, eine zus&#228;tzliche M&#246;glichkeit sein, Behandlungsbedarf zu ermitteln oder die
&#196;rztin oder den Arzt bei der Diagnose zu unterst&#252;tzen.
Die &#220;berwachung der gesundheitlichen Entwicklung der Patientinnen und Patienten, sei es station&#228;r oder
ambulant, beruht zu gro&#223;en Teilen auf der regelm&#228;&#223;igen und dauerhaften Erhebung medizinischer Daten und deren
Beobachtung. Diese Daten bieten grunds&#228;tzlich die M&#246;glichkeit, sie automatisch durch intelligente Systeme im
Hinblick auf Auff&#228;lligkeiten &#252;berwachen zu lassen.
Blutvergiftung
Erste Anwendungen gibt es f&#252;r Intensivstationen, auf denen durch die automatisierte &#220;berwachung der Blutwerte
eine Blutvergiftung (Sepsis) fr&#252;her erkannt und behandelt werden kann.1050 
Neugeborenen&#252;berwachung
F&#252;r Neugeborene wurde eine Fern&#252;berwachungsl&#246;sung entwickelt, um fr&#252;hzeitig m&#246;gliche Sch&#228;den am Gehirn
zu erkennen.1051 Diese L&#246;sung wird erg&#228;nzt durch einen Softwarealgorithmus, der die neurologischen Daten
interpretieren kann. Die Interpretation dieser Daten ist entscheidend, da das Neugeborene nicht kommunizieren 
kann und es zu wenig Fachpersonal gibt, das die neurologischen Daten lesen kann. Das System &#252;bertr&#228;gt
sogenannte Elektroenzephalografie (EEG)-Signale, die mithilfe des Algorithmus analysiert werden. Damit wird die
Interpretation neurologischer Signale in Echtzeit erm&#246;glicht.
Unterst&#252;tzung von Diabetikerinnen und Diabetikern
Bei der Unterst&#252;tzung von Diabetikerinnen und Diabetikern analysiert KI Daten aus verschiedenen Quellen
(Wearables, Medical Devices, Location etc.) und identifiziert individualisierte, auff&#228;llige Datenmuster, die auf
1049 Vgl. PricewaterhouseCoopers (2017): Sherlock in Health; Hodsden (2016): Artificial Intelligence Could Aid Earlier Diagnose of
Alzheimer&#8217;s.
1050 Vgl. scinexx das Wissensmagazin (2018): Bessere Sepsis dank KI?; Ghalati et al. (2019): Critical Transitions in Intensive Care Units:
A Sepsis Case Study.
1051 Weitere Informationen dazu unter: http://www.infantcentre.ie/research/research-studies/babylink (zuletzt abgerufen am
14. Juli 2020).
kritische Krankheitszust&#228;nde hinweisen. Beispielsweise reagieren Diabetes-Patientinnen und -Patienten auf
verschiedene Ereignisse individuell h&#246;chst unterschiedlich; deswegen m&#252;ssen Algorithmen bei jedem Ereignis aufs
Neue lernen, welche Verhaltensweisen wom&#246;glich zu zu niedrigen oder zu hohen Blutzuckerwerten f&#252;hren.1052 
Diagnose von Herzkrankheiten
Das Elektrokardiogramm (EKG) ist eine Untersuchungsmethode, mit der sich die Funktion des Herzens
beurteilen l&#228;sst. Anhand der Form des EKG-Signals lassen sich Herzrhythmusst&#246;rungen, Durchblutungsst&#246;rungen des
Herzmuskels, Herzinfarkte oder eine krankhafte Verdickung der Herzwand erkennen oder Hinweise darauf
erhalten. Seit den 1970er Jahren werden Verfahren zur Mustererkennung genutzt, um EKG-Signale zu analysieren.
Durch die automatische Analyse wird die &#196;rztin oder der Arzt insbesondere bei der Auswertung eines Langzeit-
EKGs entlastet. Die automatische EKG-Auswertung bietet in der Telemedizin die M&#246;glichkeit, Patientinnen und
Patienten mit chronischen Herzkrankheiten regelm&#228;&#223;ig zu &#252;berwachen, um fr&#252;hzeitig auf Verschlechterungen
des Gesundheitszustands zu reagieren.
Auch die Vorstufe intelligenter Systeme, regelbasierte Expertensysteme, k&#246;nnen &#8211; sofern Patientendaten
einheitlich strukturiert in einer elektronischen Patientenakte gef&#252;hrt werden &#8211; dazu genutzt werden, vor
Arzneimittelunvertr&#228;glichkeiten oder vor fehlerhaften Verschreibungen von Medikamenten zu warnen. 
Ein Nutzen von KI-Systemen zur Analyse von allgemeinen Patientendaten ist bisher nur f&#252;r einfache und eng
begrenzte Anwendungsf&#228;lle erkennbar. Dies ist auch auf die bisher wenig strukturierte Datenlage
zur&#252;ckzuf&#252;hren.
Medizinische Expertensysteme
Regelbasierte Systeme f&#252;r die Diagnose von Erkrankungen, bei denen die Regeln von medizinischen Fachleuten
entwickelt wurden, gibt es bereits seit mehr als 40 Jahren. Solche Systeme bezeichnet man als medizinische
Expertensysteme. Ein von der Universit&#228;t Stanford entwickeltes System1053 benutzte etwa eine Wissensbasis von 
etwa 600 von Expertinnen und Experten entwickelten Regeln, um bakterielle Infektionen zu erkennen und eine
Therapie mit Antibiotika zu empfehlen. An der Universit&#228;t Pittsburgh wurde in den 1970er und 1980er Jahren
ein Diagnosesystem entwickelt, welches &#252;ber 1 000 internistische Krankheitsbilder diagnostizieren konnte.1054 
Die Leistung der Systeme ist derjenigen von &#196;rztinnen und &#196;rzten einer Universit&#228;tsklinik &#228;hnlich. Die Systeme
waren langj&#228;hrig im Einsatz, wurden aber inzwischen eingestellt. In den 1980er und 1990er Jahren wurden
zahlreiche medizinische Expertensysteme f&#252;r spezielle sowie f&#252;r allgemeinmedizinische Erkrankungen entwickelt,
die ebenfalls gute Diagnosen lieferten, aber keine breite Verwendung fanden.
Eine wesentliche Ursache f&#252;r das Scheitern der medizinischen Expertensysteme trotz guter Performanz war, dass
diese die Rolle der &#196;rztin oder des Arztes darauf reduzierten, Patientendaten einzugeben und die Entscheidung
des Systems zur Kenntnis zu nehmen.1055 Dieses &#8222;griechische Orakel&#8220; wurde von &#196;rztinnen und &#196;rzten nicht
akzeptiert. Zudem dauerte die Eingabe und Erhebung der Patientendaten l&#228;nger als ein zielgerichtetes Vorgehen
der &#196;rztin oder des Arztes bis zur Entscheidung &#252;ber das weitere Vorgehen. Bei nachfolgenden Systemen wurde
daher versucht, die &#196;rztin oder den Arzt nicht zu ersetzen, sondern sie oder ihn in der Entscheidung unterst&#252;tzen.
Diese Unterst&#252;tzungssysteme f&#252;r klinische Entscheidung (Clinical Decision Support Systems &#8211; CDSS) werden 
mit unterschiedlichem Erfolg in verschiedenen klinischen Bereichen eingesetzt. Hersteller von medizinischen
Analyseger&#228;ten statten ihre Produkte h&#228;ufig mit entsprechender Funktionalit&#228;t aus.
Mit dem Aufkommen der elektronischen Gesundheitsakte in den USA und dem Erfolg des Deep Learning wurde 
erneut der Versuch unternommen, KI-Systeme auf medizinische Daten anzuwenden. Der fr&#252;here Pr&#228;sident einer
verbreiteten Datenplattform gr&#252;ndete im Jahr 2014 ein Unternehmen, das tiefe neuronale Netze f&#252;r die Analyse 
radiologischer Bilder verwendet und eine datengetriebene Diagnostik f&#252;r andere Patientendaten zu entwickeln
versucht.1056 
1052 Weitere Informationen dazu unter: http://www.xbird.io/ (zuletzt abgerufen am 14. Juli 2020).
1053 Vgl. Wikipedia, Die freie Enzyklop&#228;die (2020): Mycin (Expertensystem); Weitere Informationen dazu unter: https://exhibits.stan-
ford.edu/feigenbaum/browse/the-mycin-experiments (zuletzt abgerufen am 9. Juli 2020).
1054 Vgl. Wikipedia, Die freie Enzyklop&#228;die (2016): Internist-I; Wikipedia, Die freie Enzyklop&#228;die (2019): CADUCEUS (expert system); 
Pople (1985): Caduceus: a Computer-Based Diagnostic Consultant.
1055 Vgl. Miller (1994): Medical diagnostic decision support systems-past, present, and future: a threaded bibliography and brief
commentary.
1056 Vgl. Wikipedia, Die freie Enzyklop&#228;die (2020): Jeremy Howard (entrepreneur).
Nachdem ein KI-System in der Frage-und-Antwort-Show Jeopardy im Jahr 2011 erfolgreicher war als Menschen,
wurde versucht, die F&#228;higkeit der Sprachverarbeitung daf&#252;r zu nutzen, auf der Basis von Wissen aus
medizinischen Fachartikeln Patientendaten zu analysieren. Um Erfolge im Gesundheitsmarkt zu erreichen, gab es
Kooperationen mit Kliniken und Gesundheitsorganisationen; Fachwissen wurde durch Zuk&#228;ufe erworben. Viele
Projekte zeigten vielversprechende Ergebnisse, aber nicht alle waren erfolgreich, da u. a. die Verf&#252;gbarkeit und die
Qualit&#228;t der Daten von entscheidender Bedeutung sind. Ferner ist die Interpretation von Bild- und Sprachdaten
erheblich schwieriger als deren Klassifikation. Beispielsweise stimmten die Therapieempfehlungen des KI-
Systems bei Patientinnen und Patienten mit Darmkrebs in S&#252;dkorea aus verschiedenen Gr&#252;nden nur zu 49 Prozent
mit denen von Fach&#228;rztinnen und Fach&#228;rzten &#252;berein.1057 
Inzwischen setzt sich die Erkenntnis durch, dass ein KI-System zwar eine &#196;rztin oder einen Arzt unterst&#252;tzen,
aber nicht autonom zur Krebstherapie oder Diagnose eingesetzt werden kann. Erfolge sind daher oft nur bei eng
begrenzten Indikationen zu finden. Vielversprechend, aber noch nicht gut genug sind Verfahren, die durch
Sprachverarbeitung aus wissenschaftlichen Texten Modelle f&#252;r Expertensysteme gewinnen. Eine weitere
M&#246;glichkeit ist die Kombination von menschlichem Wissen und Modellen, welche maschinell aus Daten spezieller
Dom&#228;nen gewonnen werden (z. B. aus digitalen R&#246;ntgenbildern) in hybriden Expertensystemen.1058 
KI-Anwendungen als Unterst&#252;tzung bei Therapie und Behandlung in der personalisierten Medizin
Die personalisierte Medizin oder Pr&#228;zisionsmedizin versucht mithilfe moderner Diagnostik der genetischen,
molekularen und zellul&#228;ren Besonderheiten eine ma&#223;geschneiderte Therapie f&#252;r Patientinnen und Patienten zu
finden. Besonders in der Behandlung von Krebs kommt diese bereits zum Einsatz.1059 Seit den 1980er Jahren forscht
die Wissenschaft daran, die genetische Zusammensetzung von Tumoren zu erkennen.
Die Auswertung dieser gro&#223;en Datenmengen war ohne die Hilfe von KI lange Zeit nur schwer m&#246;glich.1060 Denn 
die individuelle Situation der Patientin bzw. des Patienten muss mit m&#246;glichst vielen gleichartigen
Krankheitsbildern verglichen werden, um die bestm&#246;gliche Therapie zu finden.1061 Nur eine automatisierte Auswertung 
durch ein intelligentes System macht in vielen F&#228;llen einen solchen Vergleich in der Therapie &#252;berhaupt m&#246;glich. 
Mittlerweile sind schon fast 60 personalisiert einzusetzende Medikamente in Deutschland zugelassen, die
meisten davon onkologische Pr&#228;parate.1062 
Zu beachten ist bei diesem Einsatzfeld, dass es sich oft um sehr kostenintensive Therapien handelt. Hier ist f&#252;r
den zuk&#252;nftigen Einsatz auch entscheidend, ob erleichterter Datenzugang auch die Kosten reduzieren kann, damit
diese Behandlung potenziell allen Betroffenen zur Verf&#252;gung gestellt werden kann, ohne das Solidarsystem zu 
&#252;berfordern.
Erweiterte M&#246;glichkeiten der Simulation durch KI bieten ebenfalls Chancen f&#252;r neue Therapieans&#228;tze. Auf Basis
von Bilddaten k&#246;nnen (z. B. auf Grundlage von MRT-Daten bei Herzklappenfehlern oder
Hauptschlagaderverengungen) die Effekte verschiedener Therapieans&#228;tze mithilfe von KI simuliert werden, sodass die &#196;rztin oder
der Arzt bei der Therapiefindung unterst&#252;tzt wird.1063 
Neue Chancen f&#252;r intelligente Prothesen
Forschung zu smarter Prothetik hat eine bionische Handprothese f&#252;r K&#246;rperversehrte entwickelt, die mittels KI-
Technologie und einer eingebauten Kamera Objekte treffsicher erkennen und greifen kann.1064 Bisher verbreitete
Alternativl&#246;sungen zur aktiven Steuerung einer Prothese, wie z. B. durch Bet&#228;tigung eines unversehrten
Brustmuskels, erm&#246;glichen das Ausf&#252;hren von Bewegungen eines Prothesengelenks in einzelne Richtungen. Im
Gegensatz dazu haben auf KI-Technologie basierende Prothesen das Potenzial, mehrere Freiheitsgrade durch
Steuersignale aus gemessener Hirnaktivit&#228;t zu kontrollieren und diese Funktionen auch gel&#228;hmten Patientinnen und
1057 Vgl. Choi et al. (2019): Concordance Rate between Clinicians and Watson for Oncology among Patients with Advanced Gastric 
Cancer: Early, Real-World Experience in Korea.
1058 Vgl. Wagner (2017): Trends in expert system development: A longitudinal content analysis of over thirty years of expert system case
studies, S. 76, 85&#8211;96.
1059 Vgl. vfa. Die forschenden Pharma-Unternehmen: Personalisierte Medizin &#8211; das beste Medikament f&#252;r den Patienten finden.
1060 Vgl. Pfundner (2019): Digitalisierung in der Medizin: Im disruptiven Wandel wandelbar bleiben.
1061 Vgl. Huss (2019): K&#252;nstliche Intelligenz, Robotik und Big Data in der Medizin, S. 48 ff.
1062 Vgl. vfa. Die forschenden Pharma-Unternehmen: Personalisierte Medizin &#8211; das beste Medikament f&#252;r den Patienten finden.
1063 Vgl. Waschbusch (2019): Digitaler Zwilling: Ein Herzensprojekt.
1064 Vgl. Newcastle University, 3. Mai 2017.
Patienten, wie solchen, die an amyotropher Lateralsklerose (ALS)1065 leiden, zug&#228;nglich zu machen.1066
Menschen mit eingeschr&#228;nkter motorischer Kontrolle leiden oft am Verlust der F&#228;higkeit, sich frei zu bewegen oder
sogar mit anderen zu kommunizieren. Mittels Gehirn-Computer-Schnittstellen (Brain Computer Interfaces &#8211;
BCI) und daran angebundener Technologie ist es m&#246;glich, diesen Patientinnen und Patienten zumindest teilweise
ihre Eigenst&#228;ndigkeit zur&#252;ckzugeben. Die Steuerung von Prothesen oder stabilisierenden Exoskeletten1067 wird
dabei ebenso erforscht wie das Durchdringen eines Locked-in-Zustandes. Durch KI-gest&#252;tzte Methoden wurde
Patientinnen und Patienten mit vollst&#228;ndigem Locked-in-Syndrom erstmals die Kommunikation mit dem
Pflegepersonal und der Familie erm&#246;glicht.1068 Die verh&#228;ltnism&#228;&#223;ig geringe Zahl der Betroffenen steht einem umso
gr&#246;&#223;eren Leidensdruck gegen&#252;ber und macht die Erkundung skalierbarer, kosteng&#252;nstiger L&#246;sungen umso
dringender.
Anwendungsfelder f&#252;r KI im Bereich Gesundheit und Pflege gibt es auch au&#223;erhalb klassischer
Versorgungsszenarien. Die Optimierung der Abl&#228;ufe im Krankenhaus ist eine gro&#223;e Herausforderung, z. B. im Bereich der
Planung, Dokumentation und Evaluation von Therapien und Pflege. Hier k&#246;nnen KI-gest&#252;tzte Kontrollzentren
Abl&#228;ufe optimieren und Ressourcen optimal verteilen. Dies hat in Krankenh&#228;usern in den USA, z. B. im Johns
Hopkins Hospital, nachweislich zu reduzierten Wartezeiten und zu Kosteneinsparungen gef&#252;hrt.1069 
Chatbots in der Telemedizin
KI-basierte Chatbots werden f&#252;r die Befragung von Patientinnen und Patienten eingesetzt. Diese selektieren und
vermitteln Patientinnen und Patienten direkt an eine (telemedizinische) &#196;rztin oder einen (telemedizinischen)
Arzt oder an einen anderen Leistungserbringer. In akuten F&#228;llen empfiehlt der Chatbot, zum n&#228;chsten
Notfallzentrum zu fahren. Per Smartphone-App k&#246;nnen Patientinnen und Patienten ihre Beschwerden mitteilen, der
Chatbot &#252;bernimmt mit einem KI-gesteuerten Fragenkatalog die medizinische Befragung. Nach dem Gespr&#228;ch
werden der Patientin oder dem Patienten die &#228;rztlichen Empfehlungen noch schriftlich &#252;bermittelt.1070 
KI-Anwendungen in der Pflege
Der derzeitige Fokus bei KI-Anwendungen in der Pflege liegt auf der Unterst&#252;tzung von Patientinnen und
Patienten, Angeh&#246;rigen und Pflegepersonal. Es ist zu erwarten, dass mit fortschreitender Entwicklung auf diesem
Feld mehr Freir&#228;ume f&#252;r alle Beteiligten geschaffen werden, Menschen l&#228;nger autonom leben und damit weniger
von anderen Menschen abh&#228;ngig sein werden und die Qualit&#228;t in der Pflege weiter steigt. Die Entlastungen des
Pflegepersonals k&#246;nnen und sollen dazu f&#252;hren, dass mehr Zeit f&#252;r pers&#246;nliche Zuwendung zur Verf&#252;gung steht,
da diese nicht ersetzt werden kann und f&#252;r gute Pflege wichtig ist. Soziale intelligente Assistenzsysteme k&#246;nnen
positive Auswirkungen auf das Wohlbefinden und die Lebensqualit&#228;t pflegebed&#252;rftiger Menschen haben und
deren Autonomie st&#228;rken. Hinzu kommt ein gro&#223;es Potenzial, n&#228;mlich dass die Verf&#252;gbarkeit von
medizinischpflegerischen Diensten durch KI-Werkzeuge steigt, da durch sie trotz Fachkr&#228;ftemangels weniger Menschen an
mehr Orten gezielter und effektiver handeln k&#246;nnen. KI-Anwendungen bieten auch ganz unabh&#228;ngig vom
Personalmangel in der Pflege zahlreiche Chancen, die Qualit&#228;t zu steigern, das Wohlbefinden der Pflegebed&#252;rftigen
zu erh&#246;hen und die Arbeit der Pflegenden zu erleichtern.1071 
Smarte Wohnungen
Zu den Unterst&#252;tzungssystemen in der Wohnung geh&#246;ren z. B. smarte Sensorik-Fu&#223;b&#246;den, die bei Sturz Alarm
schlagen oder bei Aktivit&#228;t automatisch das Licht anschalten, um St&#252;rze zu verhindern. Weiterhin gibt es
Liegematten f&#252;r Betten sowie weitere Sensorik-Elemente in der Wohnung, die Bewegungsdaten sammeln, KI-gest&#252;tzt 
die zu Pflegenden &#8222;kennenlernen&#8220; und so automatisch Aktionen ausf&#252;hren k&#246;nnen, wie z. B. das &#214;ffnen von
1065 Bei ALS handelt es sich um eine schwere Erkrankung des zentralen und peripheren Nervensystems, welche zu
L&#228;hmungserscheinungen f&#252;hrt, weitere Informationen dazu unter: https://www.dgm.org/muskelerkrankungen/amyotrophe-lateralsklerose-als (zuletzt
abgerufen am 9. Juli 2020).
1066 Vgl. Guger et al. (2001): Prosthetic Control by an EEG-based BrainComputer Interface (BCI), S. 2&#8211;7.
1067 Vgl. IOP Publishing (2015): A brain-computer interface for controlling an exoskeleton.
1068 Vgl. gie/dpa/aerzteblatt.de (2017): Brain-Computer-Interface: Vollst&#228;ndig gel&#228;hmte Patienten kommunizieren wieder.
1069 Vgl. Daley (2019): Surgical Robots, new Medicines and Better Care: 32 Examples of AI in Healthcare; Sennaar (2020): How
America&#8217;s 5 Top Hospitals are Using Machine Learning Today.
1070 Vgl. Medinside Das Portal f&#252;r die Gesundheitsbranche (2018): Patienten von Medgate sprechen wohl k&#252;nftig mit einem Chatbot; 
Montero (2018): IBM and Medgate creating chatbot to diagnose your aches and pains.
1071 Vgl. Plattform Lernende Systeme (2019): Lernende Systeme im Gesundheitswesen &#8211; Bericht der Arbeitsgruppe Gesundheit,
Medizintechnik Pflege.
T&#252;ren. KI-L&#246;sungen, die Verhaltensmuster gelernt haben, k&#246;nnen au&#223;erdem auf abweichende (Not-)Situationen
oder auf Risiken hinweisen und ggf. Pflegedienste oder Angeh&#246;rige informieren.
Autonome Assistenzsysteme und soziale intelligente Assistenzsysteme
Intelligenten Assistenzrobotern in der Pflege wird ein gro&#223;es Potenzial zugeschrieben, die Pflegesituation in
Deutschland signifikant zu verbessern.1072 Hier gilt es zu unterscheiden zwischen autonomen Assistenzrobotern,
die physisch unterst&#252;tzen, und sogenannten sozialen Robotern, deren Ziel die sozialemotionale Unterst&#252;tzung ist.
Als Beispiel sei die Robbe Paro genannt, die wie eine Robbe aussieht und mit Menschen einfache Interaktionen
durchf&#252;hren und sie so zur Aktivit&#228;t animieren oder Kommunikation mit dem Pflegepersonal erleichtern kann. 
Ein Beispiel f&#252;r einen autonomen Assistenzroboter zur physischen Unterst&#252;tzung ist ein intelligentes
Assistenzsystem, das f&#252;r Krankenpflegerinnen und Krankenpfleger auf der Station Boteng&#228;nge &#252;bernimmt oder
Krankenhauszimmer nach einer Verlegung bzw. Entlassung einer Patientin oder eines Patienten f&#252;r die Folgebelegung
vorbereitet. Dieses entlastet das Pflegepersonal von konkreten, einfachen Aufgaben und erh&#246;ht die Genauigkeit,
mit der sie erledigt werden.1073 
Ein weiteres Beispiel k&#246;nnte eine Reha-Klinik sein, in der ein Assistenzroboter der Patientin oder dem Patienten
&#220;bungen zeigt &#8211; also z. B. an das Bett f&#228;hrt und patientenindividuell und nach dem Grundsatz &#8222;Unterst&#252;tzung
nach Bedarf&#8220; beispielsweise die Arme hebt und die Patientin oder den Patienten zum Mit- und Nachmachen
animiert. Auch an der Hochschule f&#252;r Technik und Wirtschaft Dresden wurde ein Roboter entwickelt, der speziell
bei der Pflege von Menschen mit Demenz helfen soll oder als Sitzwache beispielsweise nach einem operativen
Eingriff am Bett der Patientin oder des Patienten bleiben kann.1074 Der neue Forschungszweig der Geriatronik1075 
soll es &#228;lteren Menschen erm&#246;glichen, mithilfe von intelligenten Pflegeassistenzsystemen l&#228;nger zu Hause zu
leben. Ein sich derzeit in der Entwicklung befindendes Assistenzsystem &#8222;Garmi&#8220; soll beispielsweise
perspektivisch T&#228;tigkeiten &#252;bernehmen, wie das Ausr&#228;umen der Geschirrsp&#252;lmaschine oder das Erw&#228;rmen von
Mahlzeiten in der Mikrowelle; im Notfall soll es sogar als Avatar der zugeschalteten &#196;rztin oder des zugeschalteten
Arztes helfen.1076 
Es ist sogar denkbar, dass intelligente Pflegeassistenzsysteme k&#252;nftig einfache medizinische Aufgaben
&#252;bernehmen, wie Blutdruckmessen. Indem medizinisches Fachpersonal &#252;ber einen Bildschirm des intelligenten
Assistenzsystems zugeschaltet werden kann, bieten sich neue Anwendungsfelder der Telemedizin. Patientinnen und
Patienten sowie &#196;rztinnen und &#196;rzte k&#246;nnen so entlastet werden, da etwa Termine f&#252;r Routineuntersuchungen
entfallen.1077 Selbst wenn heute das autonome Interaktionspotenzial zumeist gering ist, d. h. noch lange nicht alle 
Roboter in der Pflege eigenst&#228;ndige Dialoge f&#252;hren k&#246;nnen, so k&#246;nnte sich das in Zukunft aber Zug um Zug
weiterentwickeln.1078 Dasselbe gilt f&#252;r soziale Roboter, also Assistenzsysteme, die soziale Kontakte erg&#228;nzen
und Unterst&#252;tzung bieten, wenn menschliches Pflegepersonal oder Angeh&#246;rige nicht zur Verf&#252;gung stehen.
Beispiele sind humanoide oder tier&#228;hnliche Roboter, die mit Menschen interagieren und Verhaltensmuster lernen,
sodass sie daf&#252;r eingesetzt werden k&#246;nnen, die Stimmung von Patientinnen und Patienten zu heben, Patientinnen
und Patienten zu beruhigen oder Einsamkeit zu lindern. Einsatzfelder sind neben der Altenpflege auch z. B. die
Palliativbetreuung oder die Arbeit mit autistischen Kindern. Dabei ist festzuhalten, dass der Einsatz von sozialen
Robotern einer besonderen ethischen Abw&#228;gung bedarf, pers&#246;nliche Zuwendung nicht ersetzen kann, aber
dennoch erg&#228;nzend sinnvoll sein kann, um Isolation oder Stimmungsschwankungen Pflegebed&#252;rftiger zu lindern. 
Mobilit&#228;ts- und Entlastungshilfen 
Gerade der Pflegeberuf ist durch starke, einseitige k&#246;rperliche Belastungen gekennzeichnet, die etwa durch das
Anheben oder regelm&#228;&#223;ige Umbetten von Patientinnen und Patienten entstehen. Es ist nicht zu erwarten, dass
1072 Wenn in der Folge von &#8222;Roboter&#8220; oder &#8222;Robotik&#8220; die Rede ist, so sind damit KI-gesteuerte, autonome oder teil-autonome
Assistenzsysteme gemeint, die in der Pflege eingesetzt werden.
1073 Vgl. Schwab (2019): A hospital introduced a robot to help nurses. They didn&#8217;t expect it to be so popular.
1074 Vgl. Medizin und Technik (2017): August der Smarte hilft in der Altenpflege.
1075 Die TU M&#252;nchen begr&#252;ndet mit der seit April 2018 bestehenden Professur f&#252;r Robotik und K&#252;nstliche Intelligenz den neuen
Forschungszweig der Geriatronik und forscht daran, wie sich Robotik und Geriatrie verbinden lassen. Dabei fungiert Garmisch-
Partenkirchen als Modellkommune: In der dortigen Au&#223;enstelle der TU M&#252;nchen wird u. a. das intelligente Assistenzsystem &#8222;Garmi&#8220;
entwickelt.
1076 Vgl. Reinbold (2018): Assistenz-Roboter f&#252;r Senioren Geriatronik soll Senioren im Alltag unterst&#252;tzen.
1077 Vgl. Springer Medizin (2019): Roboter in der Pflege &#8212; Ein Ausweg aus dem Personalnotstand?, S. 2.
1078 Vgl. Kehl (2018): Robotik und assistive Neurotechnologien in der Pflege &#8211; gesellschaftliche Herausforderungen, S. 79 und S. 197.
solche T&#228;tigkeiten perspektivisch vollst&#228;ndig durch Automatisierung oder Robotik-Systeme ersetzt werden
k&#246;nnen. Eine M&#246;glichkeit, um Pflegekr&#228;fte dennoch zu entlasten, sind intelligente Mensch-Maschine-Systeme wie
Exoskelette. Sie verbinden menschliche Intelligenz mit maschineller Kraft, indem sie Bewegungen der Tr&#228;gerin
oder des Tr&#228;gers unterst&#252;tzen oder verst&#228;rken. So kann das Risiko von Arbeitsunf&#228;llen und
&#252;berlastungsbedingten Erkrankungen deutlich reduziert werden; Krankenst&#228;nde k&#246;nnten sinken, was eine Verbesserung f&#252;r
Unternehmen und staatliche Gesundheitssysteme bedeuten w&#252;rde. Seit dem Jahr 2017 sind erste Exoskelette f&#252;r den
Pflegebereich auf dem Markt erh&#228;ltlich.1079 Exoskelette bieten nicht nur Nutzungsm&#246;glichkeiten f&#252;r die
Unterst&#252;tzung von Pflegekr&#228;ften, sondern auch f&#252;r Menschen mit einer Behinderung, wie Querschnittsl&#228;hmung oder
Muskelatrophie, oder solchen mit Bewegungseinschr&#228;nkung. Durch autonome oder teilautonome Steuerungs-
und Unterst&#252;tzungsfunktionen k&#246;nnen sie Bewegungseinschr&#228;nkungen bei allen betroffenen Personengruppen
ausgleichen (vor allem Greifen und Gehen). Unterschieden werden k&#246;nnen Hilfsmittel, die am K&#246;rper getragen
werden (z. B. Exoskelette) von solchen, bei denen das nicht der Fall ist (z. B. autonome Rollst&#252;hle bzw.
Rollatoren).1080 Zum einen k&#246;nnen dadurch Menschen, die in Pflegeberufen arbeiten, entlastet werden und zum
anderen k&#246;nnen Pflegebed&#252;rftige wieder ein unabh&#228;ngigeres Leben f&#252;hren. 
Monitoring von Patientinnen und Patienten
Wie auch bei den Anwendungen in der Medizin kann automatisierte Datenauswertung sowohl den
Pflegebed&#252;rftigen als auch den Pflegekr&#228;ften helfen.
F&#252;r Patientinnen und Patienten mit kritischen Gesundheitszust&#228;nden, z. B. bei bestehender kardiovaskul&#228;rer
Erkrankung, ist oftmals eine permanente medizinische &#220;berwachung notwendig, die einen dauerhaften
Krankenhausaufenthalt notwendig macht. Das vermindert die Aufnahmekapazit&#228;ten medizinischer Einrichtungen und die
Lebensqualit&#228;t Betroffener. Solche Patientinnen und Patienten k&#246;nnen in ihr vertrautes Umfeld zur&#252;ckkehren
und dennoch von der Sicherheit medizinischer &#220;berwachung profitieren, wenn das Monitoring mittels tragbarer
Sensoren, einer stabilen Daten&#252;bertragung und eines vereinbarten Eskalationsverfahrens in Notf&#228;llen online
stattfinden kann. Zus&#228;tzlich l&#228;sst sich die Erkennung kritischer Zust&#228;nde automatisieren, sodass medizinisches
Personal erheblich mehr Patientinnen und Patienten gleichzeitig und effektiv &#252;berwachen und betreuen kann als
zuvor. 
Weiterhin unterst&#252;tzen KI-gest&#252;tzte &#220;berwachungssysteme die station&#228;re Pflege, indem automatisch die
kritischen F&#228;lle erkannt werden. Pflegekr&#228;fte k&#246;nnen so entlastet werden. Auch in der Altenpflege kann bereits mit
Anwendungen der Gesundheitszustand bzw. Betreuungsbedarf &#252;berwacht und unterst&#252;tzt werden.1081 
Pflegeplanung, -dokumentation und -evaluation
Bereits jetzt gibt es Software, die in der Pflege bei Planung, Dokumentation und Evaluation unterst&#252;tzen. So gibt
es beispielsweise Systeme, die die Pflegeplanung und -dokumentation f&#252;r die station&#228;re, teilstation&#228;re und
ambulante Altenpflege nahezu komplett von der Anamnese bis zur Ma&#223;nahmen-Evaluierung &#252;bernehmen.1082
Hierbei kann es sich um Expertensysteme oder teilintelligente Anwendungen handeln. Dies schafft Raum f&#252;r
pers&#246;nliche Zuwendung, indem Effizienz und Organisationsqualit&#228;t gesteigert und das Pflegepersonal von pflegefernen,
administrativen T&#228;tigkeiten entlastet wird.
Weitere Anwendungsgebiete mit Gesundheitsbezug
Wie bereits deutlich wurde, ist es im Rahmen dieses Teilberichts nicht m&#246;glich, s&#228;mtliche Anwendungen von KI
mit Gesundheitsbezug ausf&#252;hrlich darzustellen. Denkbar sind jedoch viele Ber&#252;hrungspunkte, etwa bei der
Assistenz von Menschen mit Behinderung oder bei der Unterst&#252;tzung im Sport. Diese beiden Felder werden hier
beispielhaft f&#252;r viele weitere denkbare Einsatzszenarien kurz eingef&#252;hrt, auch wenn sie im weiteren Verlauf nicht
ausf&#252;hrlich behandelt werden k&#246;nnen.
1079 Vgl. Wallenfels (2017): Exoskelette f&#252;r einen leichteren Pflegealltag.
1080 Vgl. Kehl (2018): Robotik und assistive Neurotechnologien in der Pflege &#8211; gesellschaftliche Herausforderungen, S. 14.
1081 Darstellung Bernd Falk (Malteser Hilfsdienst) in der Sitzung der Projektgruppe KI und Gesundheit am 13. Mai 2019 (vgl.
Projektgruppendrucksache 19(27)PG 3-12 vom 13. Mai 2019).
1082 Weitere Informationen dazu unter: https://www.connext.de/software/vivendi-pd/pflege.aspx (zuletzt abgerufen am 14. Juli 2020).
Teilhabe f&#252;r Menschen mit Behinderung
KI-Anwendungen erm&#246;glichen es Menschen mit Behinderung, besser selbstbestimmt am Leben teilzuhaben,
sich zu bewegen, zu kommunizieren, zu lernen und zu arbeiten. Dabei steht der einzelne Mensch im
Mittelpunkt. Die KI-Anwendung erm&#246;glicht ihm etwa, durch Muskel- oder Augenbewegungen oder Hirnstr&#246;me
Kommunikationsger&#228;te oder intelligente Prothesen zu steuern, die helfen, die eigene Beeintr&#228;chtigung
(teilweise) zu auszugleichen.
KI-Anwendungen im Sport
Im Sport kann man zwischen Anwendungen und Use Cases im Leistungs- und im Breitensport unterscheiden.
Im Leistungssport gibt es schon seit L&#228;ngerem Werkzeuge, die KI-basiert die Leistung von Sportlerinnen und
Sportlern analysieren und dabei helfen, diese zu verbessern. Dies betrifft alle Sportarten, die starkes
kommerzielles Potenzial aufweisen, wie z. B. Fu&#223;ball1083, Basketball1084 und Baseball1085, wo KI-Systeme auch zur
Talentsuche eingesetzt werden. H&#228;ufig werden Systeme als Coach bzw. Sparringspartner eingesetzt, z. B. im
Schach. Aber auch andere Sportarten, wie z. B. Segeln, profitieren stark von Datenanalysen und Vorhersagen,
etwa hinsichtlich der Wetter- und Str&#246;mungsverh&#228;ltnisse. Hier steht nicht nur die Leistungssteigerung im
Vordergrund, sondern auch die Vermeidung von Verletzungen durch optimierte Trainingspl&#228;ne und -
anweisungen. Im Breitensport gibt es eine Reihe von Ans&#228;tzen, die basierend auf einfachen Apps Verhalten analysieren.
In der Forschung liegt der Fokus insbesondere auf Systemen, die autonom eingreifen, um bestimmte
Bewegungs- und Verhaltens&#228;nderungen zu unterst&#252;tzen, wie z. B. das tragbare Trainingssystem Footstriker1086, das
vollautomatisch den Laufstil der Benutzerin oder des Benutzers durch elektrische Muskelstimulation
korrigiert. Diese Leistungsdiagnostik mithilfe von KI-Techniken, insbesondere der Erkennung von bestimmten
Bewegungsabl&#228;ufen, erm&#246;glicht Freizeitsportlerinnen und Freizeitsportlern in bestimmten Sportarten unter
&#228;hnlichen Bedingungen zu trainieren wie im Profisport.  
SWOT-Analyse
Zur Einsch&#228;tzung, wo Deutschland in der Anwendung von KI steht, wurde eine sogenannte SWOT-Analyse 
durchgef&#252;hrt. Insbesondere aus den Chancen und Risiken ergibt sich der Handlungsbedarf f&#252;r Politik, Forschung, 
Gesundheitswesen und Anbieter von Gesundheitsleistungen.
Die folgende Tabelle gibt einen &#220;berblick &#252;ber St&#228;rken, Schw&#228;chen, Chancen und Risiken. Details zu den
einzelnen Punkten sind in den nachfolgenden Kapiteln zu finden.
St&#228;rken:
&#8226; Starker Forschungsstandort Deutschland
&#8226; Medizininformatik-Initiative des
Bundesministeriums f&#252;r Bildung und Forschung (BMBF)
&#8226; Wettbewerbsf&#228;hige Unternehmen f&#252;r
Medizintechnik und -ger&#228;te
&#8226; Solidarisches Gesundheitssystem
&#8226; Einf&#252;hrung der ePA
&#8226; Digitale Souver&#228;nit&#228;t der B&#252;rgerinnen und 
B&#252;rger, hoher Datenschutz (Vertrauensfaktor)
&#8226; Einzelne L&#246;sungen bereits implementiert, z. B. 
Videosprechstunde, Chatbots, KI im Sport
Schw&#228;chen:
&#8226; Voraussetzungen f&#252;r digitale L&#246;sungen nicht
fl&#228;chendeckend vorhanden, z. B.
Breitbandausbau
&#8226; Insgesamt im internationalen Vergleich noch 
zu optimierender Digitalisierungsstand des
Gesundheitswesens
&#8226; Mangelnde Digitalexpertise beim
Gesundheitspersonal und in der Ausbildung
&#8226; In den Bundesl&#228;ndern relevante
Datenschutzvorgaben im Gesundheitsbereich uneinheitlich 
und unberechenbar geregelt und gehandhabt
&#8226; Datenverf&#252;gbarkeit und -zugang f&#252;r
medizinische Forschung zur Entwicklung von KI-
L&#246;sungen verbesserungsw&#252;rdig
1083 Vgl. JAAI Newsteam (2018): K&#252;nstliche Intelligenz im Fu&#223;ball &#8211; IBM Watson hilft bei Bundesliga Transfers.
1084 Vgl. Bange (2017): Big Data Analytics &#8211; Tagesgesch&#228;ft in der NBA.
1085 Vgl. Reuters (2018): MLB taps Amazon&#8217;s AI to power real-time game stats and graphics.
1086 Vgl. Hassan et al. (2017): FootStriker: An EMS-based Foot Strike Assistant for Running.
Chancen:
&#8226; Zahlreiche Einsatzgebiete f&#252;r KI zur Diagnose,
Therapie, Steigerung des Patientenwohls,
Bek&#228;mpfung von &#8222;Volkskrankheiten&#8220;, Entlastung 
von Personal, Qualit&#228;tssteigerung 
&#8226; Entlastung des Gesundheitspersonals sowie
des gesamten Gesundheitssystems durch KI
&#8226; Aufwertung des Pflegeberufs
&#8226; Verf&#252;gbarkeit der Daten sowie Datenschutz 
und starke Leitlinien z. B. der
Ethikkommission 
&#8226; Einrichtung eines Trustcenters
(Vertrauensstelle) f&#252;r Daten
&#8226; Ausbau der Forschungsstandorte inkl. Transfer
der Ergebnisse in die Praxis
&#8226; Weiterf&#252;hrung des solidarischen
Gesundheitssystems
&#8226; Internationale Standardsetzung mithilfe von 
Investitionen noch m&#246;glich
&#8226; Verringerung von Behandlungsfehlern durch 
Einsatz von KI
&#8226; Vermeiden unn&#246;tiger Behandlungen durch 
Einsatz von KI
&#8226; Uneinheitliche Datenstandards
&#8226; Zulassung von neuen KI-L&#246;sungen sowie
Richtlinien hinsichtlich Haftung teilweise
ungekl&#228;rt; Regularien generell komplex und 
dadurch unverh&#228;ltnism&#228;&#223;ig teuer (im
Vergleich zu anderen Staaten)
&#8226; Erschwerte klinische KI-Forschung, da stets
individuelle und damit teure L&#246;sungen zur
Erprobung neuer KI-Technologien n&#246;tig
&#8226; Transfer von Forschungsergebnissen in die
praktische Umsetzung verbesserungsw&#252;rdig
&#8226; Zusammenarbeit zwischen Forschung und 
Start-ups bzw. Unternehmen, Praxis und 
Recht/Politik ausbauf&#228;hig 
&#8226; Bisher zu wenig F&#246;rderung von Start-ups im
Bereich KI und Gesundheit
Risiken:
&#8226; H&#246;here Kosten durch Einsatz von KI-
L&#246;sungen (jedoch: h&#246;here Qualit&#228;t der Versorgung &#8211;
siehe Chancen)
&#8226; M&#246;glichkeit der reinen Effizienzsteigerung 
durch KI- und Robotikl&#246;sungen unter
Vernachl&#228;ssigung der angestrebten
Qualit&#228;tssteigerung, z. B. &#8222;Entmenschlichung der Pflege&#8220;, 
Reduzierung von ohnehin knapp bemessenem
Pflegepersonal
&#8226; &#8222;Gl&#228;serner Patient&#8220; durch &#252;berm&#228;&#223;iges
Verf&#252;gbarmachen von Daten ohne entsprechende
Datenschutzregelungen bzw. ohne
Datenfreigabe
&#8226; Medizinische Fehlentscheidungen durch
&#8222;blindes Vertrauen&#8220; in KI-L&#246;sungen, wo
menschliche Kontrolle angebracht w&#228;re
&#8226; Fehlende Verf&#252;gbarkeit und
Erstattungsf&#228;higkeit von KI-L&#246;sungen f&#252;r alle Patientinnen 
und Patienten
&#8226; Vorsprung des Auslands (z. B. China) bei KI
im Gesundheitswesen durch z. B. 
&#8226; Abwanderung von Expertinnen und
Experten und Entwicklung in andere L&#228;nder
&#8226; Einschr&#228;nkende Regulierung
&#8226; Komplexe Zulassungsregelungen
4 Handlungsfelder
Voraussetzungen f&#252;r KI im Gesundheitsbereich
Im vorigen Kapitel ist deutlich geworden, wie umfassend die M&#246;glichkeiten sind, KI in Gesundheit und Pflege
einzusetzen. Entscheidend ist aber, dass diese Anwendungen nur unter bestimmten Voraussetzungen &#252;berhaupt
entwickelt und eingesetzt werden k&#246;nnen. Der Schritt von der Entwicklung zur breiten Anwendung von
nutzbringenden KI-L&#246;sungen f&#252;r Gesundheit und Pflege h&#228;ngt ma&#223;geblich von der Realisierung verschiedener
Voraussetzungen und Rahmenbedingungen ab. Diese werden daher in diesem Teilbericht auch als erstes
Handlungsfeld benannt, um die Unabdingbarkeit dieser Schritte f&#252;r den weiteren Einsatz von KI zu unterstreichen. Kritische
Variablen sind insbesondere
&#8226; eine konsistente und regelm&#228;&#223;ig zu aktualisierende politische Strategie f&#252;r die Digitalisierung und den
Einsatz intelligenter Systeme im Gesundheitswesen; so sind viele Aktivt&#228;ten in der Digitalisierung der Medizin
in den vergangenen Jahren angelaufen, aber bis heute entweder im zeitlichen Verzug oder zu wenig
miteinander vernetzt. Beispiele daf&#252;r sind die Telematik-Infrastruktur, die ePA oder die Medizininformatik-
Initiative. Um das notwendige Umfeld f&#252;r den Einsatz von KI zu schaffen, sind daher eine strategische
Abstimmung der laufenden Aktivit&#228;ten und eine systematische Identifizierung weiterer notwendiger Schritte
mit einem Umsetzungszeitplan geboten.
Als Voraussetzungen f&#252;r den weiteren Einsatz von KI sollte die Strategie die folgenden Punkte enthalten, die in
den nachfolgenden drei Abschnitten ausf&#252;hrlicher dargestellt werden:
&#8226; eine sichere und leistungsf&#228;hige digitale Infrastruktur f&#252;r die Speicherung und &#220;bermittlung von
Gesundheitsdaten und die Digitalisierung von Versorgungsprozessen, 
&#8226; ein innovationsfreundlicher Rechtsrahmen f&#252;r den Datenschutz, der gleicherma&#223;en den Anspruch hat, die
Gesundheitsdaten f&#252;r die Forschung und Entwicklung von KI-L&#246;sungen nutzbar zu machen und
Datenschutzrechte und digitale Souver&#228;nit&#228;t der Patientinnen und Patienten zu sch&#252;tzen,
&#8226; die F&#246;rderung und Durchsetzung technischer und semantischer Standards f&#252;r die Struktur von Daten im
deutschen Gesundheitswesen auf Grundlage international gebr&#228;uchlicher Terminologien (Interoperabilit&#228;t),
&#8226; die bessere Zug&#228;nglichkeit und Verkn&#252;pfung von Datenregistern f&#252;r die Forschung bei hoher
Datensicherheit,
&#8226; den Ausbau der digitalen Kompetenzen der Gesundheitsberufe durch eine umfassende Strategie in der Aus-
und Weiterbildung. 
4.1.1 Digitalisierung und digitale Infrastruktur
In Deutschland bestehen in vielfacher Hinsicht Defizite und Herausforderungen bez&#252;glich der
Breitbandversorgung mit Glasfaser sowie der Infrastruktur von Gesundheitsdaten: Zahlreiche medizinische Einrichtungen,
insbesondere in l&#228;ndlichen Regionen1087, sind unzureichend an die Breitbandversorgung angeschlossen. In vielen 
medizinischen Einrichtungen liegen Gesundheitsdaten bislang noch nicht digital vor; sie k&#246;nnen daher nicht mit
den Methoden Maschinellen Lernens analysiert werden. &#220;berdies verlaufen der Ausbau und die Modernisierung 
der IT-Systeme in deutschen Krankenh&#228;usern nur z&#246;gerlich, insbesondere auch weil die IT-Investitionsquoten in 
deutschen Krankenh&#228;usern im internationalen Vergleich nicht bedarfsgerecht sind. Im Durchschnitt geben
deutsche Krankenh&#228;user etwa 1,5 bis 1,7 Prozent ihrer Gesamtausgaben f&#252;r die IT aus. Im Jahr 2017 betrugen die
Gesamtausgaben der deutschen Krankenh&#228;user 105,7 Milliarden Euro.1088 In vergleichbaren L&#228;ndern wie den
Niederlanden, &#214;sterreich oder der Schweiz ist die Investitionsquote in der IT mit rund 4 Prozent mehr als doppelt
so hoch.1089 Der Verband der Universit&#228;tsklinika Deutschlands geht allein f&#252;r die Universit&#228;tskliniken von einem
j&#228;hrlichen Investitionsdefizit in der IT von etwa 5 bis 10 Millionen Euro pro Klinik aus.1090 Dies f&#252;hrt hierzulande
zu veralteten und fragmentierten IT-Systemen, die den heutigen Anforderungen nicht mehr gerecht werden. 
1087 Nur 3,2 Prozent aller deutschen Haushalte verf&#252;gen &#252;ber Glasfaseranschl&#252;sse, im OECD-Durchschnitt sind es 30,3 Prozent (Stand
Dezember 2019), vgl. Brandt (2020): Glasfaserausbau kommt in Deutschland kaum voran.
1088 Vgl. Statistisches Bundesamt (2018): Kosten der Krankenh&#228;user nach Bundesl&#228;ndern.
1089 Vgl. Stephani et al. (2019): Benchmarking der Krankenhaus-IT: Deutschland im internationalen Vergleich, S. 29.
1090 Vgl. Deutsche Hochschulmedizin e. V. (2014): Medizinischer Fortschritt braucht leistungsstarke IT-L&#246;sungen.
Vor dem Hintergrund der skizzierten Herausforderungen ist eine zukunftsfeste digitale Infrastruktur mit
Breitbandinternet insbesondere in l&#228;ndlichen Regionen unerl&#228;sslich. Es bedarf einer kollektiven Anstrengung, die
n&#246;tige Breitbandversorgung mit Glasfasertechnologie in den n&#228;chsten Jahren sicherzustellen. Damit k&#246;nnen
Gesundheitsdaten zuk&#252;nftig zwischen medizinischen Einrichtungen schnell, effizient, sicher und unter Wahrung
hoher Datenschutzstandards &#252;bermittelt werden.
Dar&#252;ber hinaus muss die Digitalisierung &#252;ber verschiedene Akteure und Institutionen (Arztpraxen,
Krankenh&#228;user, Universit&#228;tskliniken, Krankenkassen, Abrechnungsstellen, Apotheken, Pflegeeinrichtungen etc.) hinweg
forciert werden. Es ist geboten, Krankenh&#228;user, Pflegeeinrichtungen und weitere Anbieter im Gesundheitssektor
dabei finanziell zu unterst&#252;tzen, in die Modernisierung ihrer IT-Systeme zu investieren und die Digitalisierung
der Prozesse und administrativen Strukturen voranzutreiben. In einer im Auftrag der Bundesregierung
erarbeiteten Studie wurde zu diesem Zweck ein Investitionsprogramm zum Ausbau der Digitalisierung (&#8222;Digital Boost&#8220;) 
vorgeschlagen: Bund und L&#228;nder sollen danach f&#252;r acht Jahre zusammen etwa 1,08 Milliarden Euro pro Jahr
investieren, um die &#8222;Ausstattung f&#252;r telemedizinische Ma&#223;nahmen, die [&#8230;] Interoperabilit&#228;t bei elektronischem
Datenaustausch oder die digitale Interaktion mit Patienten&#8220; zu verbessern.1091 Um die IT-Ausgaben von derzeit
rund 1,5 auf 4 Prozent der Gesamtausgaben zu erh&#246;hen, w&#228;ren pro Jahr ca. 2,6 Milliarden Euro an zus&#228;tzlichen
Mitteln notwendig.1092 
Die vielfach bestehenden, f&#252;r unterschiedliche Zwecke erstellten, bislang nicht miteinander vernetzten
Gesundheitsdatenbanken und Register ganz unterschiedlicher Akteure sollten besser miteinander vernetzt werden, sodass
auch die Verf&#252;gbarkeit der Daten f&#252;r die Forschung erh&#246;ht wird. Auch angesichts knapper Mittel ist eine
Gie&#223;kannenf&#246;rderung nicht zweckm&#228;&#223;ig. Es sollten daher vorrangig IT-Investitionen in solchen Krankenh&#228;usern
gef&#246;rdert werden, die auch k&#252;nftig f&#252;r eine bedarfsgerechte Versorgung notwendig sind. Gro&#223;e H&#228;user
(Maximalversorger) k&#246;nnten Vorreiter werden und IT-L&#246;sungen und Use Cases entwickeln, von denen kleinere H&#228;user
ebenfalls profitieren k&#246;nnten. Dies w&#252;rde au&#223;erdem zu mehr Kosteneffizienz f&#252;hren.
4.1.2 Datenschutz, Datenverf&#252;gbarkeit und Umgang mit Patientendaten
F&#252;r die Anwendung von KI in der Medizin sind regelm&#228;&#223;ig Daten zu verarbeiten, die Informationen &#252;ber den
Gesundheitszustand einzelner Personen enthalten oder R&#252;ckschl&#252;sse darauf zulassen. Es ist daher von
entscheidender Bedeutung, dass Deutschland &#252;ber einen Rechtsrahmen und eine praktische Umsetzung f&#252;r
Gesundheitsdaten verf&#252;gt, die individuelle Datenrechte und damit das Vertrauen in das System und dessen Akzeptanz sichern,
Daten aber auch f&#252;r die Forschung und die medizinische Praxis verf&#252;gbar machen.
Zentraler rechtlicher Rahmen f&#252;r die Verarbeitung dieser Daten sind die seit Mai 2018 auf europ&#228;ischer Ebene
geltende DSGVO und auf Ebene des nationalen Rechts das Bundesdatenschutzgesetz (BDSG), die
Sozialgesetzb&#252;cher des Bundes (SGB), die Verschwiegenheitsverpflichtungen im Arzt-Patienten-Verh&#228;ltnis sowie, je nach
Zust&#228;ndigkeit, die Datenschutzgesetze der Bundesl&#228;nder. Hinzu kommen bereichsspezifische Regelungen wie
die Landeskrankenhausgesetze.
Gesundheitsdaten erfordern einen besonderen Schutz. Entsprechende, bislang durch die Aufsichtsbeh&#246;rden noch
nicht im Einzelnen ausgelegte und angewandte Vorgaben enth&#228;lt insbesondere die gerade erst in Kraft getretene
DSGVO.
Dennoch erweisen sich einige datenschutzrechtliche Regelungen f&#252;r die Forschung auf der Grundlage von
medizinischen Daten als nicht mehr zeitgem&#228;&#223;. 16 Datenschutzgesetze der Bundesl&#228;nder, 16
Landeskrankenhausgesetze, das Krankenhausgesetz der Bundeswehr sowie das BDSG verursachen eine uneinheitliche rechtliche 
Situation und wirken innovationshemmend. Hinzu kommen weitere bereichsspezifische Regelungen, etwa im
Sozialrecht. Eine bundesweite Harmonisierung der Rechtslage zur Gesundheitsdatennutzung w&#228;re daher
w&#252;nschenswert und zukunftsorientiert. Die Projektgruppe empfiehlt, zeitnah eine Bund-L&#228;nder-Arbeitsgruppe
einzusetzen mit dem Ziel, schnellstm&#246;glich die unterschiedlichen Datenschutzregelungen in Bund und L&#228;ndern auf
Basis der DSGVO zu vereinheitlichen und zeitgem&#228;&#223;er auszugestalten.
Die DSGVO beinhaltet wie bereits das BDSG ein grunds&#228;tzliches Verbot der Verarbeitung personenbezogener
Daten, sofern nicht ein definierter Ausnahmetatbestand greift. Zu diesen Ausnahmetatbest&#228;nden z&#228;hlt &#8211; neben
dem Fall, dass die Verarbeitung erforderlich ist, um rechtliche Verpflichtungen zu erf&#252;llen oder bestimmte andere
h&#246;her stehende Interessen zu wahren &#8211; insbesondere die Einwilligung der betroffenen Person &#8222;f&#252;r einen oder
1091 Vgl. RWI &#8211; Leibniz-Institut f&#252;r Wirtschaftsforschung (2017): Stand und Weiterentwicklung der Investitionsf&#246;rderung im
Krankenhausbereich, S. 115 f.
1092 Vgl. Deutsche Hochschulmedizin e. V. (2014): Medizinischer Fortschritt braucht leistungsstarke IT-L&#246;sungen, S. 77.
mehrere bestimmte Zwecke&#8220; (Artikel 6). Diese Einwilligung muss in Kenntnis der Sachlage und im Rahmen
einer echten und freien Wahl gegeben werden (Erw&#228;gungsgrund 42 DSGVO).
Bei Gesundheitsdaten handelt es sich um eine &#8222;besondere Kategorie personenbezogener Daten&#8220; im Sinne von 
Artikel 9 DSGVO; sie unterliegt strengeren Bestimmungen. Hierzu geh&#246;ren auch die verwandten Kategorien
genetischer und biometrischer Daten zur eindeutigen Identifizierung sowie solcher Daten, aus denen die
&#8222;rassische und ethnische Herkunft&#8220;1093 hervorgeht, und Daten zum Sexualleben oder zur sexuellen Orientierung. Der
Begriff der Gesundheitsdaten soll alle Daten umfassen, &#8222;die sich auf den Gesundheitszustand einer betroffenen
Person beziehen und aus denen Informationen &#252;ber den fr&#252;heren, gegenw&#228;rtigen und k&#252;nftigen k&#246;rperlichen oder
geistigen Gesundheitszustand der betroffenen Person hervorgehen&#8220;, ebenso wie Nummern und Kennzeichen,
&#8222;die einer nat&#252;rlichen Person zugeteilt wurden, um diese nat&#252;rliche Person f&#252;r gesundheitliche Zwecke eindeutig 
zu identifizieren&#8220; (Erw&#228;gungsgrund 35 DSGVO).1094 
Die Verarbeitung zu Archiv-, Forschungs- und statistischen Zwecken im &#246;ffentlichen Interesse hat nach Artikel
89 DSGVO geeigneten Garantien f&#252;r die Rechte und Freiheiten der betroffenen Person zu unterliegen, durch die
insbesondere die Achtung des Grundsatzes der Datenminimierung gew&#228;hrleistet werden soll. Hierzu kann
ausdr&#252;cklich die Pseudonymisierung geh&#246;ren, also die Trennung und gesonderte Sicherung von Daten, die den
Bezug zu konkreten Personen herstellen. Wenn m&#246;glich, soll stattdessen eine Anonymisierung erfolgen, sodass die
Identifizierung betroffener Personen gar nicht mehr m&#246;glich ist. Derart anonymisierte Daten liegen au&#223;erhalb
des Anwendungsbereichs der Verordnung (Erw&#228;gungsgrund 26 DSGVO). Artikel 89 DSGVO erlaubt den EU-
Mitgliedsstaaten weiter, bei Verarbeitungen f&#252;r diese Zwecke Ausnahmen von den Betroffenenrechten
vorzusehen, soweit dies notwendig ist. In diesem Zusammenhang verweist die Plattform &#8222;Lernende Systeme&#8220; in ihrem 
Arbeitsgruppenbericht ebenfalls auf die M&#246;glichkeit, eine &#8222;Gesundheitsdatenbasis&#8220; aufzubauen. Neben der
Pseudonymisierung wird eine dezentrale Architektur favorisiert, die es KI-Systemen erm&#246;glicht, mit Methoden des
verteilten Lernens (&#8222;Federated learning&#8220;) zu arbeiten, &#8222;wobei die Rohdaten nicht &#252;bertragen werden m&#252;ssen und 
dem Lernalgorithmus unver&#228;ndert zur Verf&#252;gung stehen&#8220;1095. Dies korrespondiert mit den dezentralen
Gesundheitsdatenregistern und Vertrauensstellen, die auch die Projektgruppe als eine M&#246;glichkeit vorschl&#228;gt.
Im BDSG werden entsprechende Grundlagen f&#252;r den medizinischen Bereich in &#167; 22 (Verarbeitung besonderer
Kategorien personenbezogener Daten) und f&#252;r den Forschungsbereich in &#167; 27 (Datenverarbeitung zu
wissenschaftlichen oder historischen Forschungszwecken und zu statistischen Zwecken) geschaffen; in beiden F&#228;llen 
sind angemessene und spezifische Ma&#223;nahmen zur Wahrung der Interessen der betroffenen Person vorzusehen,
wobei &#167; 22 Absatz 2 BDSG eine nicht abschlie&#223;ende Liste m&#246;glicher Ma&#223;nahmen enth&#228;lt. In den
Landesdatenschutzgesetzen finden sich &#228;hnliche, aber nicht durchg&#228;ngig identische Regelungen.
Aus diesen rechtlichen Rahmenbedingungen im Datenschutzbereich ergeben sich f&#252;r die Anwendung von KI im
Gesundheitsbereich und insbesondere in der wissenschaftlichen Forschung folgende Herausforderungen:
Die grundlegenden Vorgaben der DSGVO wurden in den verschiedenen Mitgliedsstaaten und in Deutschland in
den Bundesl&#228;ndern verschieden umgesetzt und konkretisiert. F&#252;r grenz&#252;berschreitende Vorhaben und solche mit
Akteuren in verschiedener Zust&#228;ndigkeit (&#246;ffentlich/nicht&#246;ffentlich, Bund/Land) bringt dies Schwierigkeiten und
rechtliche Unklarheiten mit sich.
DSGVO und BDSG unterscheiden nicht zwischen verschiedenen Arten von Gesundheitsdaten, obwohl dieser
Begriff sehr weit gefasst ist und Daten sehr verschiedener Sensitivit&#228;t enth&#228;lt. In Bezug auf die Ma&#223;nahmen, die
zu treffen sind, um die Interessen der betroffenen Person zu wahren, sieht &#167; 22 BDSG vor, u. a. die
unterschiedliche Eintrittswahrscheinlichkeit und Schwere der mit der Verarbeitung verbundenen Risiken zu ber&#252;cksichtigen, 
macht aber keine n&#228;heren Vorgaben. Ma&#223;geblich ist aber das EU-Recht. Gesundheitsdaten sind eine besondere
1093 Nach Erw&#228;gungsgrund 51 DSGVO soll die Verwendung des Begriffs &#8222;rassische Herkunft&#8220; nicht bedeuten, dass Theorien gutgehei&#223;en
werden, mit denen versucht wird, die Existenz verschiedener menschlicher Rassen zu belegen.
1094 Auch f&#252;r diese Daten ist eine ausdr&#252;ckliche Einwilligung grunds&#228;tzlich eine ausreichende Grundlage f&#252;r die Verarbeitung (Artikel 9 
Absatz 2 Buchstabe a DSGVO). Fehlt eine Einwilligung, kann die Verarbeitung u. a. auch dann auf entsprechender Rechtsgrundlage 
erlaubt werden, wenn sie f&#252;r folgende Zwecke erforderlich ist: f&#252;r Zwecke der Gesundheitsvorsorge oder der Arbeitsmedizin, f&#252;r die
Beurteilung der Arbeitsf&#228;higkeit der oder des Besch&#228;ftigten, f&#252;r die medizinische Diagnostik, die Versorgung oder Behandlung im 
Gesundheits- oder Sozialbereich oder f&#252;r die Verwaltung von Systemen und Diensten im Gesundheits- oder Sozialbereich
(Buchstabe h), aus Gr&#252;nden des &#246;ffentlichen Interesses im Bereich der &#246;ffentlichen Gesundheit, wie dem Schutz vor schwerwiegenden 
grenz&#252;berschreitenden Gesundheitsgefahren oder zur Gew&#228;hrleistung hoher Qualit&#228;ts- und Sicherheitsstandards bei der
Gesundheitsversorgung und bei Arzneimitteln und Medizinprodukten (Buchstabe i) oder f&#252;r im &#246;ffentlichen Interesse liegende Archivzwecke,
f&#252;r wissenschaftliche oder historische Forschungszwecke oder f&#252;r statistische Zwecke (Buchstabe j).
1095 Vgl. Plattform Lernende Systeme (2019): Lernende Systeme im Gesundheitswesen &#8211; Bericht der Arbeitsgruppe Gesundheit,
Medizintechnik Pflege, S. 27.
Kategorie personenbezogener Daten nach Artikel 9 Absatz 1 DSGVO. Gem&#228;&#223; Erw&#228;gungsgrund 35 DSGVO 
werden damit alle Daten erfasst, &#8222;die sich auf den Gesundheitszustand einer betroffenen Person beziehen und
aus denen Informationen &#252;ber den fr&#252;heren, gegenw&#228;rtigen und k&#252;nftigen k&#246;rperlichen oder geistigen
Gesundheitszustand der betroffenen Person hervorgehen&#8220;. Eine weite Auslegung ist angezeigt.
Mit der Anwendung von KI zu Zwecken der Mustererkennung ist die Hoffnung verbunden, aus gro&#223;en
Datenmengen Erkenntnisse abzuleiten, ohne bereits &#252;ber vorgefasste Hypothesen zu verf&#252;gen, sodass die Erfassung
m&#246;glichst vieler Daten angestrebt wird. Dies verkompliziert die Anwendung der
pers&#246;nlichkeitsrechtssch&#252;tzenden Grunds&#228;tze der eindeutigen Zweckbindung und der Datenminimierung.
Die M&#246;glichkeit, sich freiwillig zu entscheiden, individuelle Gesundheitsdaten zu Zwecken der Forschung
freizugeben, ist Ausdruck des informationellen Selbstbestimmungsrechts der B&#252;rgerinnen und B&#252;rger. Zu bedenken
ist hierbei, dass die Freigabe insbesondere individueller genetischer Daten nicht nur die eigenen Rechte betrifft, 
sondern auch Auswirkungen auf Verwandte und deren informationelle Selbstbestimmungsrechte haben kann. 
Der &#8222;goldene Weg&#8220; der Anonymisierung ist zwar f&#252;r manche Anwendungen (etwa der Diagnose mittels
bildgebender Verfahren) denkbar, bei der Korrelation vieler verschiedener Gesundheits- und anderer Daten oder bei
der Betrachtung genetischer Daten wird eine Zur&#252;ckf&#252;hrung auf Individuen aber immer noch m&#246;glich sein; auch
bei Verfahren oder Untersuchungen, die nicht nur die Vergangenheit betreffen, sondern auch neue
Beobachtungen einbeziehen, ist h&#246;chstens eine Pseudonymisierung m&#246;glich. Auch aus Sicht der Patientinnen und Patienten
kann eine Pseudonymisierung der Anonymisierung vorzuziehen sein: Die Erkenntnisse der Untersuchungen
k&#246;nnen ihnen nur dann mitgeteilt werden, wenn sie nach der Pseudonymisierung ihrer Daten wieder zur&#252;ckverfolgt
(re-identifiziert) werden k&#246;nnen. Bei einer Anonymisierung kann diese Verkn&#252;pfung in der Regel nicht
wiederhergestellt werden.
Um die Entwicklung und Anwendung von KI zu forcieren, k&#246;nnten Gesundheitsdaten als Ressource verstanden
werden. Es sollte eine Infrastruktur aufgebaut werden, die sie unter h&#246;chsten IT-Sicherheits- und
Datenschutzstandards sammelt, speichert und &#8211; unter sicheren Voraussetzungen &#8211; kontrolliert f&#252;r die Forschung,
insbesondere auch zur Entwicklung von KI-Anwendungen, freigibt. 
Eine signifikante Chance zur Digitalisierung von Gesundheitsdaten bietet sich mit der Einf&#252;hrung der ePA in der 
GKV, zu deren Bereitstellung die Krankenkassen bis 1. Januar 2021 verpflichtet sind. Mit der ePA sollte nicht
nur die digitale Vernetzung von medizinischen Versorgungseinrichtungen untereinander, sondern auch die
Vernetzung zwischen Forschung und Versorgung vorangetrieben werden. Die ePA stellt somit das zentrale Element
der vernetzten Gesundheitsversorgung und Telematik-Infrastruktur in Deutschland dar. In ihr werden
schrittweise Diagnosen, Therapiema&#223;nahmen, Behandlungsberichte und Impfungen gespeichert werden k&#246;nnen. Damit
ist eine fall- und einrichtungs&#252;bergreifende Dokumentation m&#246;glich. Die ePA unterst&#252;tzt au&#223;erdem den
Notfalldatensatz und den elektronischen Medikationsplan sowie elektronische Arztbriefe. Die Spezifikation der ePA
differenziert zwischen drei Bereichen:
1. Daten, die auf Wunsch der Versicherten von den jeweiligen Leistungserbringern eingestellt werden, 
2. Daten, die von den Versicherten selbst in der Akte abgelegt werden, und 
3. Daten, die den Versicherten von ihrer jeweiligen GKV zur Verf&#252;gung gestellt werden.
Zwar haben einzelne private Krankenversicherungen (PKV) bereits Aktivit&#228;ten f&#252;r elektronische Akten gestartet,
jedoch ist die PKV bislang nicht in die ePA nach dem SGB V und die Telematik-Infrastruktur einbezogen, sodass
die Gesundheitsdaten, die bei der gesundheitlichen Versorgung ihrer Versicherten anfallen, weder f&#252;r die
Versorgung selbst noch f&#252;r die Forschung, beispielsweise zum Zweck der Entwicklung von KI-Anwendungen, zur
Verf&#252;gung stehen w&#252;rden.
Die Wahrung und St&#228;rkung der digitalen Souver&#228;nit&#228;t der Patientinnen und Patienten ist wesentlich. Es ist darum
notwendig, dass die Patientinnen und Patienten bei der ePA die volle Verf&#252;gungshoheit &#252;ber ihre
Gesundheitsdaten erhalten und selbst entscheiden k&#246;nnen, ob sie eine ePA verwenden wollen oder nicht bzw. wer Daten in
ihrer Akte einsehen und/oder speichern darf.
Vor dem Hintergrund, dass bei der Verarbeitung im Rahmen der wissenschaftlichen Forschung der Zweck
oftmals nicht vollst&#228;ndig angegeben werden kann, soll es betroffenen Personen nach Erw&#228;gungsgrund 33 DSGVO
erlaubt sein, ihre Einwilligung f&#252;r bestimmte Bereiche wissenschaftlicher Forschung zu geben, wenn dabei die
anerkannten ethischen Standards der wissenschaftlichen Forschung eingehalten werden. Sie sollen dabei die
Gelegenheit erhalten, ihre Einwilligung nur f&#252;r bestimmte Forschungsbereiche oder Teile von Forschungsprojekten
zu erteilen, und zwar in dem Ma&#223;e, wie es der verfolgte Zweck zul&#228;sst.
Die in der DSGVO und im BDSG angelegten spezifischen Rechtsgrundlagen f&#252;r die Datenverarbeitung in der
Wissenschaft und im Gesundheitssystem gehen allerdings nicht davon aus, dass eine Einwilligung vorliegt, und
enthalten weitere Einschr&#228;nkungen der Betroffenenrechte. So gibt es keine Ausgestaltung einer informierten
Einwilligung und der Wahrnehmung von Rechten, die den speziellen Rahmenbedingungen der (medizinischen)
wissenschaftlichen Forschung angepasst sind und damit dem genannten Erw&#228;gungsgrund folgen.
Patientinnen und Patienten sollten daher die M&#246;glichkeit erhalten, ihre Daten freiwillig der Forschung zur
Verf&#252;gung stellen zu k&#246;nnen. Das k&#246;nnte mithilfe einer formalisierten zweckgebundenen &#8222;Datenfreigabe&#8220;
erm&#246;glicht werden. F&#252;r den Fall einer sp&#228;ter fehlenden Einwilligungsf&#228;higkeit sollten Regelungen zur Datenfreigabe
auch f&#252;r eine Vorsorgevollmacht oder eine Patientenverf&#252;gung geschaffen werden. F&#252;r Menschen, die nicht mehr
einwilligungsf&#228;hig sind und keine solche Vorausverf&#252;gung haben, sollte eine Datenfreigabe auch durch nahe
Angeh&#246;rige bzw. Betreuungspersonen erm&#246;glicht werden.
Die Daten m&#252;ssten differenziert und abgestuft freigegeben werden k&#246;nnen (z. B. nach Sektor, Kontext,
national/international, nur f&#252;r Forschungseinrichtungen oder auch f&#252;r die kommerzielle Forschung).1096 Patientinnen
und Patienten sollten zudem entscheiden k&#246;nnen, ob sie ihre Daten nur bestimmten Institutionen zur Verf&#252;gung
stellen. Au&#223;erdem m&#252;ssen sie die Freigabe ihrer Daten jederzeit unkompliziert f&#252;r zuk&#252;nftige Nutzungen
widerrufen k&#246;nnen. F&#252;r den Fall eines konkreten Nutzens f&#252;r die einzelne Patientin oder den einzelnen Patienten, die
bzw. der ihre bzw. seine Daten zur Verf&#252;gung gestellt hat, sollte eine gut begr&#252;ndete Re-Identifizierung
erm&#246;glicht werden, wenn die Patientin oder der Patient diesem Vorgehen vorher zugestimmt hat. 
Gleichzeitig muss darauf geachtet werden, dass die Einrichtung und Pflege ihrer Datenfreigaben f&#252;r die
Patientinnen und Patienten handhabbar bleiben. Denkbar w&#228;re beispielsweise eine Matrix-Struktur mit
Profilvorschl&#228;gen f&#252;r unterschiedliche Pr&#228;ferenzen. Besonderes Augenmerk ist zu legen auf die verst&#228;ndliche Information und
Beratung der Patientinnen und Patienten &#252;ber die m&#246;glichen Varianten einer Einwilligung, deren Reich- und 
Tragweite sowie (etwa bei genetischen Daten) m&#246;gliche Konsequenzen f&#252;r Dritte.
Neben gut ausgebauten Schnittstellen und Computing-Infrastrukturen zwischen Forschung und medizinischer
Versorgung sind vertrauensw&#252;rdige Stellen f&#252;r die sichere Aufbewahrung, Verwaltung und &#220;bermittlung der
sensiblen Gesundheitsdaten notwendig. Hierbei ist analog zu der Struktur, die im Gesetz zur Errichtung des
Implantateregisters Deutschland oder im Gesetz &#252;ber Krebsregister vorgesehen ist, organisatorisch zu trennen
zwischen dezentralen Trustcentern, die von den Patientinnen und Patienten f&#252;r die Forschung freigegebenen
Gesundheitsdaten sicher aufbewahren und sie anonymisieren oder pseudonymisieren, und einem speziellen
Forschungsdatenregister, an das die anonymisierten bzw. pseudonymisierten Daten von den Trustcentern &#252;bermittelt
werden und das seinerseits diese Daten anfragenden Forschungsinstitutionen nach entsprechend vereinbarten 
Vorgaben f&#252;r die Forschung zur Verf&#252;gung stellt. 
Perspektivisch sollten nationale Versorgungsregister bzw. ein Registerverbund unter dem Gesichtspunkt der
Nutzbarkeit der Daten f&#252;r Forschung und Entwicklung eingerichtet werden. Zur Verwaltung der genannten
Stellen k&#246;nnte eine der staatlichen Aufsicht und Kontrolle unterstehende Treuh&#228;nder-Institution geschaffen werden,
die nach klaren Vorgaben den Zugang zu den individuell freigegebenen Daten f&#252;r die Forschung regelt. Aktuell
gibt es beispielsweise zw&#246;lf getrennte Krebsregister. Diese Trennung gilt es zu &#252;berwinden. Auch derzeit
bestehende Datenbest&#228;nde in Krankenh&#228;usern, Apotheken und Krankenkassen sollten f&#252;r die Forschung mit
Einverst&#228;ndnis der Patientinnen und Patienten zug&#228;nglich und nutzbar gemacht werden. Diese Register m&#252;ssen
sukzessive aufgebaut und weiterentwickelt werden. M&#246;glicherweise auftretende Rechtsfragen, die mit einer
Einwilligung allein nicht &#252;berwunden werden k&#246;nnen, sind ggf. durch den Gesetzgeber zu entscheiden. Es sollte nicht
unmittelbar eine Gesamtl&#246;sung angestrebt werden, da dies zu langen Verz&#246;gerungen f&#252;hren w&#252;rde. 
In einem solchen nationalen Versorgungsregister bzw. einem Registerverbund k&#246;nnten auch die Daten aus
l&#228;ngeren Alltagsstudien oder sogenannten Living Labs sicher verwahrt und der weiteren Forschung zug&#228;nglich
gemacht werden. Ebenso sollte bei der Weiterentwicklung der ePA stets auch die Forschungsperspektive
mitgedacht werden, damit die Anliegen der Forschung, insbesondere bei der Interoperabilit&#228;t der Daten,
vorausschauend in die Technologie eingearbeitet werden k&#246;nnen. Nur eine enge Vernetzung zwischen Praxis und Forschung 
wird es erm&#246;glichen, die Gesundheitsdaten gleicherma&#223;en nutzbringend f&#252;r Versorgung und Forschung zu
verwenden. 
1096 Artikel 4 Nummer 11 DSGVO verlangt eine Einwilligung f&#252;r einen bestimmten Fall in informierter Weise. Um Rechtsunsicherheiten
bei der Datenfreigabe zu vermeiden, sind weitere Entscheidungen und Auslegungshinweise der Datenschutzaufsichtsbeh&#246;rden
w&#252;nschenswert, vgl. European Data Protection Board (2019): Stellungnahme 3/2019 zu den Fragen und Antworten zum Zusammenspiel
der Verordnung &#252;ber klinische Pr&#252;fungen und der Datenschutz-Grundverordnung (DSGVO) (Artikel 70 Absatz 1 Buchstabe b).
Derzeit werden Daten von Krankenkassen nur f&#252;r die Abrechnung erhoben (mithilfe der internationalen
statistischen Klassifikation der Krankheiten und verwandter Gesundheitsprobleme (ICD, englisch: International
Statistical Classification of Diseases and Related Health Problems) und Operationen- und Prozedurenschl&#252;ssel (OPS)
f&#252;r diagnosebezogene Fallgruppen (DRG, englisch: Diagnosis Related Groups))1097. Dies f&#252;hrt zu einem Bias in
den Daten, der gerade f&#252;r KI-Anwendungen problematisch sein kann. Der Bias l&#228;sst sich zwar mit Aufwand
herausrechnen. Es ist aber zu empfehlen, durch eine breitere systematische Datenerhebung, wie etwa in der
NAKO Gesundheitsstudie1098, einen solchen Bias zu korrigieren.
Eine wichtige Voraussetzung f&#252;r die Nutzung von Gesundheitsdaten zur Entwicklung von KI-Anwendungen sind
interoperable Systeme und Datenstrukturen auf Grundlage internationaler Standards. Zwischen den beteiligten
Systemen in der Gesundheitsversorgung und in der Forschung ist ein gemeinsames Verst&#228;ndnis der
Informationsobjekte, ihres Inhaltes und ihrer Strukturen unabdingbar (semantische Interoperabilit&#228;t). Anderenfalls
k&#246;nnen Informationen nicht &#252;bermittelt werden oder gehen verloren. &#220;berdies kann die Orientierung an bestehenden
internationalen Standards auch den Aufwand und die Kosten f&#252;r die Anpassung von bestehenden digitalen
L&#246;sungen an das jeweilige nationale Gesundheitswesen reduzieren.1099 
Auf internationaler Ebene existieren deshalb bereits eine Reihe derartiger Standards wie etwa Health Level 7 
(HL7) oder Clinical Document Architecture (CDA), die insbesondere den Aufbau klinischer Dokumente
beschreiben, oder Digital Imaging and Communications in Medicine (DICOM), ein Standard f&#252;r die Speicherung
und den Austausch von Daten bildgebender Systeme. Eine moderne Weiterentwicklung von HL7 ist Fast
Healthcare Interoperability Resources (FHIR). In diesem Format gespeicherte Daten f&#252;hrten beispielsweise einer
aktuellen Studie zufolge zu guten medizinischen Vorhersagen, wenn die ePA mit Hilfe Maschinellen Lernens
analysiert wird.1100 Dar&#252;ber hinaus existieren semantische Standards bzw. Referenzterminologien, die das Ziel
haben, klinische Inhalte unabh&#228;ngig von der verwendeten Ursprungssprache eindeutig und pr&#228;zise darzustellen.
Die detaillierteste Terminologie dieser Art stellt die Systematisierte Nomenklatur der Medizin (SNOMED CT)
dar.
Bei der Anwendung und Verbreitung solcher Standards hinkt das deutsche Gesundheitswesen bislang noch
erheblich hinterher. 1101 Internationale Standards wie HL7, DICOM oder SNOMED CT werden in Deutschland nur
in wenigen Projekten oder nur ganz vereinzelt verwendet.1102 Zudem ist Deutschland bislang kein Mitglied von 
SNOMED International, sodass deutsche Besonderheiten bei der Weiterentwicklung von SNOMED CT eher
nicht ber&#252;cksichtigt werden und eine fl&#228;chendeckende Verbreitung und Akzeptanz in Deutschland erschwert
wird.
Um die Interoperabilit&#228;t und damit Auswertbarkeit der Gesundheitsdaten zu gew&#228;hrleisten sowie nationale und
internationale Forschungsinitiativen im Gesundheitsbereich unterst&#252;tzen oder etablieren zu k&#246;nnen, m&#252;ssen
daher Anstrengungen unternommen werden, Standards insbesondere auf Grundlage g&#228;ngiger internationaler
Terminologien st&#228;rker zu etablieren und zu verbreiten.
4.1.3 Aus-, Weiter- und Fortbildung in Gesundheitsberufen
Die Ausbildung in Gesundheitsberufen erfolgt immer noch weitgehend ohne Ber&#252;cksichtigung der
demografischen und medizinisch-technischen Ver&#228;nderungen. Die Themen Personalisierung, Digitalisierung und
Automatisierung, aber auch KI und Robotik f&#252;r Diagnose- und Therapieanwendungen, die die Gesundheitsversorgung
k&#252;nftig ver&#228;ndern und bestimmen werden, werden nicht hinreichend ber&#252;cksichtigt. In der Konsequenz sind
&#196;rztinnen und &#196;rzte oder Besch&#228;ftigte in anderen Gesundheitsberufen etwa nach Abschluss des Studiums derzeit
vielfach unzureichend auf die (zuk&#252;nftigen) Ver&#228;nderungen vorbereitet, die sich durch den Einzug technischer
Neuerungen f&#252;r die Patientenversorgung oder die Pflege ergeben werden. 
Es ist jedoch unabdingbar, dass &#196;rztinnen und &#196;rzte sowie Fachkr&#228;fte aus weiteren in diesem Zusammenhang
relevanten Gesundheitsberufen Chancen, Risiken und Grenzen von KI-Gesundheitsanwendungen einsch&#228;tzen
k&#246;nnen, wenn sie diese anwenden. Kenntnisse der Datenanalyse und lernender Systeme f&#252;r Therapeutik und
1097 ICD ist der von der WHO definierte internationale Klassifikationsschl&#252;ssel f&#252;r Krankheiten und Gesundheitsprobleme; OPS
beschreiben die konkreten medizinischen Ma&#223;nahmen. DRG sind die diagnosebezogenen Fallpauschalen, die zu Abrechnungszwecken
im deutschen Krankenhauswesen genutzt werden.
1098 Weitere Informationen dazu unter: https://nako.de/ (zuletzt abgerufen am 20. Oktober 2020).
1099 Vgl. PricewaterhouseCoopers (2013): Interoperability: An essential component for scalable mHealth.
1100 Vgl. Rajkomar et al. (2018): Scalable and accurate deep learning with electronic health records.
1101 Vgl. PricewaterhouseCoopers Strategy&amp; (Germany) GmbH (2016): Weiterentwicklung der eHealthStrategie, S. 136.
1102 Vgl. PricewaterhouseCoopers Strategy&amp; (Germany) GmbH (2016): Weiterentwicklung der eHealthStrategie, S. 138.
Diagnostik m&#252;ssen Teil der medizinischen Lehrpl&#228;ne sein und bereits fr&#252;h in Studium, Lehre und Fortbildung
verankert werden. Die Themen KI und Robotik m&#252;ssen grunds&#228;tzlich st&#228;rker in der Ausbildung ber&#252;cksichtigt
werden.
&#196;rztinnen und &#196;rzte werden in Zukunft mit KI-Anwendungen Hand in Hand arbeiten. Daf&#252;r m&#252;ssen sie z. B. in 
der Lage sein, von KI erstellte Diagnosen zu interpretieren und vorgeschlagene Therapien mit Alternativen
abzuw&#228;gen. Unkenntnis der verschiedenen Verfahren k&#246;nnte also je nach Risikostufe der Anwendung zu schweren
Folgen f&#252;r die Gesundheit der Patientinnen und Patienten f&#252;hren. K&#252;nftige Medizinerinnen und Mediziner sollten
sich deshalb bereits im Studium und durch explizite Fortbildung mit dem Thema KI auseinandersetzen. Um
diesen Bereich in der Lehre zu ber&#252;cksichtigen, ben&#246;tigen die medizinischen Fakult&#228;ten die entsprechenden
Freiheiten und Mittel, mitsamt aktiv unterst&#252;tzter Br&#252;cken zu den technischen Fakult&#228;ten und Einrichtungen. Die
Projektgruppe h&#228;lt deshalb den Ausbau beispielsweise der &#8222;Clinical- und Medical-Data-Scientist-Programme&#8220;
f&#252;r erforderlich.
Wichtig ist aber auch die Erh&#246;hung der digitalen Expertise in der Pflege und in anderen Gesundheitsberufen, um
etwa mit intelligenten Assistenzsystemen und Robotern optimal zusammenarbeiten zu k&#246;nnen. Die Ausbildung
der Pflegekr&#228;fte wurde zwar bereits in Teilen neu geregelt, jedoch finden auch hier neue Technologien nur
unzureichend Eingang. Vermehrt wird die Akademisierung der Pflege gefordert. Es fehlen jedoch konkrete
Karriereoptionen und es mangelt an Anerkennung der &#8222;Pflege am Bett&#8220;. Zudem werden die beiden haupts&#228;chlich an
der Versorgung der Patientinnen und Patienten beteiligten Berufsgruppen v&#246;llig getrennt ausgebildet, von
angrenzenden oder neuen Berufsfeldern ganz zu schweigen. Dabei sind in Bezug auf die Pflege gerade auch solche
Berufe wichtig und bei der Vermittlung von Digitalexpertise zu ber&#252;cksichtigen, die nur mittelbar mit ihr in
Ber&#252;hrung kommen, wie beispielsweise Stationsapothekerinnen und -apotheker, Gerontopsychiaterinnen und 
-psychiater oder Pflegehilfskr&#228;fte. Interdisziplin&#228;re Studieng&#228;nge m&#252;ssen gest&#228;rkt werden: Ben&#246;tigt werden
zunehmend mehr medizinische und pflegerische Datenexpertinnen und -experten, Pflege- und
Medizininformatikerinnen und -informatiker; zudem sind in Gesundheitsberufen Datenkompetenz sowie ein nat&#252;rlicher Umgang
mit robotischen Assistenzsystemen erforderlich.
4.1.4 Handlungsempfehlungen
1. Forschungs- und Gesundheitspolitik m&#252;ssen enger zusammenarbeiten: Die Projektgruppe empfiehlt der
Bundesregierung, einen Prozess zur Erarbeitung einer stimmigen Strategie f&#252;r die Digitalisierung im
Gesundheitswesen zu starten, in die alle relevanten Akteure und Ressorts einbezogen sind. Diese Strategie
sollte innerhalb eines Jahres vorgelegt und innerhalb von f&#252;nf Jahren umgesetzt werden. Dabei sollte die
Zielsetzung regelm&#228;&#223;ig aktualisiert und die Perspektive der Nutzerinnen und Nutzer in ausreichendem Ma&#223;e
ber&#252;cksichtigt werden. Orientierung bei der Entwicklung einer solchen Strategie k&#246;nnen internationale
Beispiele wie etwa die &#8222;Danish Digital Health Strategy 2018&#8211;2022&#8220; bieten.
2. Die Investitionen f&#252;r die Digitalisierung von Prozessen sowie f&#252;r Modernisierung und Ausbau von IT-
Systemen in Gesundheitseinrichtungen m&#252;ssen erheblich erh&#246;ht werden. Die Projektgruppe empfiehlt Bund
und L&#228;ndern, durch eine st&#228;rkere finanzielle Unterst&#252;tzung auf die deutliche Erh&#246;hung der IT-
Investitionsquoten in Krankenh&#228;usern in Richtung einer Zielmarke von 4 Prozent1103 ihrer Gesamtausgaben
hinzuwirken. Eine relevante Anschubfinanzierung zur schnelleren Erreichung dieses Ziels k&#246;nnte beispielsweise
durch eine gemeinsame Anstrengung1104 von Bund und L&#228;ndern unterst&#252;tzt werden. Dabei muss eine
Gie&#223;kannenf&#246;rderung vermieden werden. Der bestehende Krankenhausstrukturfonds, der auch f&#252;r die
Finanzierung von Ma&#223;nahmen der IT-Sicherheit genutzt werden kann, sollte auch f&#252;r Unikliniken ge&#246;ffnet werden.
3. Angesichts der gro&#223;en Zersplitterung des Datenschutzrechts &#8211; DSGVO, l&#228;nderspezifische und weitere
spezialgesetzliche Regelungen &#8211; wird eine bundesweite Harmonisierung der Rechtslage zur Nutzung von
Gesundheitsdaten empfohlen. Die Projektgruppe empfiehlt, zeitnah eine Bund-L&#228;nder-Arbeitsgruppe
einzusetzen mit dem Ziel, schnellstm&#246;glich die unterschiedlichen Datenschutzregelungen in Bund und L&#228;ndern
auf Basis der DSGVO zu vereinheitlichen und zeitgem&#228;&#223;er auszugestalten.
4. Notwendig ist eine hohe Qualit&#228;t von Daten, die keinen Bias haben und eine Entwicklung von KI-
Gesundheitsanwendungen f&#252;r alle Teile der Gesellschaft erm&#246;glichen. 
1103 Derzeit eine L&#252;cke von 2,5 Milliaren Euro j&#228;hrlich (siehe auch Kapitel 4.1.1 dieses Projektgruppenberichts [Digitalisierung und 
digitale Infrastruktur]).
1104 Daf&#252;r k&#246;nnten die Erfahrungen aus dem Digitalpakt Schule herangezogen werden.
5. Darum sind einheitliche Standards f&#252;r die Qualit&#228;t, Erhebung, Speicherung etc. von Daten in Forschung und
Versorgung n&#246;tig. &#220;berlegenswert sind Anreize, wie beispielsweise ein Qualit&#228;tssiegel f&#252;r
Gesundheitsdaten und eine Zertifizierung f&#252;r ihre datenschutzkonforme Verarbeitung. Nur so k&#246;nnen die
Forschungserkenntnisse aus qualitativ hochwertigen Daten schnell in die Versorgung einflie&#223;en und Daten aus der
Versorgung f&#252;r die Forschung genutzt werden. Daf&#252;r ist eine enge Abstimmung zwischen Wissenschafts- und 
Gesundheitspolitik Voraussetzung. Das BMG und das BMBF m&#252;ssen hierzu viel enger als bisher
zusammenarbeiten. Die ePA bzw. der Aufbau der Telematik-Infrastruktur und die Medizininformatik-Initiative
m&#252;ssen st&#228;rker koordiniert werden. Die Bundesregierung muss darauf hinwirken, dass auch die PKV in die
Telematik-Infrastruktur f&#252;r den sicheren Austausch von Daten im Gesundheitswesen einbezogen wird und
die PKV-Unternehmen ihren Versicherten die ePA anbieten.
6. F&#252;r die Auswertbarkeit unterschiedlicher Daten im Rahmen der Forschung sowie f&#252;r eine effiziente
Entwicklung von KI-Anwendungen ist sowohl auf Ebene der beteiligten Systeme als auch der beteiligten
Institutionen ein gemeinsames Verst&#228;ndnis der Daten, ihrer Informationsobjekte, Inhalte und Strukturen
unabdingbar. Die Projektgruppe empfiehlt der Bundesregierung, die Anwendung international gebr&#228;uchlicher 
Standards, Schnittstellen und Terminologien und deren Anpassung an den deutschen Kontext durch st&#228;rkere
nationale Koordination und Abstimmung zu unterst&#252;tzen. Hierzu sollte auch m&#246;glichst zeitnah eine
Vollmitgliedschaft Deutschlands bei SNOMED International herbeigef&#252;hrt werden.
7. Die Projektgruppe empfiehlt der Bundesregierung, die rechtlichen und strukturellen Voraussetzungen einer
modular aufgebauten Freigabe der Daten f&#252;r Forschungszwecke zu schaffen, um den Patientinnen und
Patienten selbst bzw. ihren Angeh&#246;rigen oder Betreuungspersonen eine jederzeit widerrufbare Freigabe der
Daten zu erm&#246;glichen. Es muss sichergestellt sein, dass die Patientinnen und Patienten mithilfe
verst&#228;ndlicher Informationen und entsprechender Beratungsangebote informierte Entscheidungen treffen k&#246;nnen. Die
Wahrung der digitalen Souver&#228;nit&#228;t der Patientinnen und Patienten ist f&#252;r die Akzeptanz der Digitalisierung
unabdingbar. F&#252;r die Speicherung der Daten m&#252;ssen h&#246;chste Sicherheitsstandards und klare Regeln gelten,
wer Zugang zu Gesundheitsdaten und wer die M&#246;glichkeit der Weiterverarbeitung und Nutzung hat. Die
Patientinnen und Patienten m&#252;ssen selbst entscheiden k&#246;nnen, ob und wem sie zu Forschungszwecken
Zugang zu ihren sensiblen medizinischen Daten gew&#228;hren wollen.
8. Die Projektgruppe empfiehlt der Bundesregierung und den Bundesl&#228;ndern den Aufbau einer
Dateninfrastruktur, um die Verf&#252;gbarkeit von Gesundheitsdaten f&#252;r die Forschung zu erh&#246;hen. Hierbei sollte analog
zum Krebsregister bzw. zum Implantateregister organisatorisch getrennt werden zwischen Trustcentern und
Registerstellen. Die Trustcenter sind daf&#252;r verantwortlich, die Daten der Patientinnen und Patienten sicher
aufzubewahren und die entsprechenden Datenfreigaben zu verwalten, die Daten zu anonymisieren oder zu
pseudonymisieren und sie an die Registerstellen zu &#252;bermitteln. Die Registerstellen haben die Aufgabe, die
anonymisierten oder pseudonymisierten Daten der Forschung zur Verf&#252;gung zu stellen. Perspektivisch
sollten Bund und L&#228;nder darauf hinwirken, dass die vorhandenen Registerstrukturen, wie etwa bei den
Krebsregistern der L&#228;nder und dem aufzubauenden Implantateregister, zu einem nationalen Versorgungsregister
zusammengef&#252;hrt werden. 
9. Die Projektgruppe empfiehlt Bund und L&#228;ndern eine umfassende Strategie zum Aufbau von Expertise im
Bereich digitale Anwendungen und insbesondere zum Aufbau von KI im Gesundheitsbereich. Themen wie
Personalisierung, Digitalisierung, KI, Robotik und Automatisierung m&#252;ssen fl&#228;chendeckend Teil der Aus-, 
Weiter- und Fortbildung von &#196;rztinnen und &#196;rzten, Pflegekr&#228;ften und weiteren Fachkr&#228;ften in
Gesundheitsberufen werden. Zudem m&#252;ssen insbesondere die L&#228;nder durch entsprechende interdisziplin&#228;re
Studieng&#228;nge darauf hinwirken, dass der steigende Bedarf insbesondere an medizinischen Datenexpertinnen und
-experten sowie Medizininformatikerinnen und -informatikern gedeckt wird. 
F&#246;rderung des Forschungs- und Wirtschaftsstandorts &#8211; f&#252;r eine souver&#228;ne
Entwicklung von KI im Gesundheitsbereich
4.2.1 KI in der medizinischen Forschung
KI hat l&#228;ngst auch Einzug in die Gesundheitsforschung gehalten. Sowohl in der Grundlagenforschung als auch
in der anwendungsorientierten Forschung geh&#246;rt sie f&#252;r viele Forscherinnen und Forscher zum Alltag. Dabei sind
intelligente Systeme sowohl Werkzeug als auch Gegenstand der Forschung. Mit ihrer Hilfe k&#246;nnen etwa
Experimente simuliert, Modelle erstellt oder gro&#223;e Datenmengen analysiert werden. Gleichzeitig wird in den
verschiedensten Fachrichtungen der Gesundheitsforschung an neuen KI-Anwendungen und Einsatzm&#246;glichkeiten
geforscht. Bei der Suche nach dem &#8222;bekannten Unbekannten&#8220; und besonders dem &#8222;Unbekannten&#8220; wird KI eine
wichtige Rolle im Bereich Gesundheitsforschung spielen.
Die Forschung zu KI-Anwendungen im Gesundheitsbereich ist genauso vielf&#228;ltig, wie es die potenziellen
Einsatzm&#246;glichkeiten intelligenter Systeme sind &#8211; ob bei der Informationsanalyse, bei der Entscheidung bez&#252;glich 
optimaler Strategien f&#252;r chirurgische Eingriffe oder bei der Entwicklung intelligenter Assistenzsysteme in der
Pflege. Auch bei der Erforschung von Medikamenten kommt KI zum Einsatz. Bis ein neues Arzneimittel
marktreif ist, vergehen oft viele Jahre. Schon vorher scheitern 90 Prozent der Forschungsprojekte.1105 Diese Zeit fehlt 
Patientinnen und Patienten, die auf ein bestimmtes Medikament warten. Mithilfe von KI-basierten
Computersimulationen kann die Entwicklung von Arzneimitteln beschleunigt werden. Durch die Analyse gro&#223;er
Datenmengen, z. B. aus Hochdurchsatz-Screenings oder Zellexperimenten, gelingt es, das Verhalten von Molek&#252;len und
deren Interaktion mit menschlichen Zellen und Geweben immer exakter vorherzusagen. So k&#246;nnen
beispielsweise fr&#252;hzeitig erfolgversprechende Wirkstoffkandidaten ermittelt werden. Der Einsatz von KI in der
Arzneimittelforschung kann so das Design neuer Substanzen erheblich beschleunigen. 
Mit dem Einsatz von KI in der Gesundheitsforschung und der Entwicklung von KI-Anwendungen werden somit
verschiedene Ziele verfolgt, die die Qualit&#228;t der Gesundheitsversorgung in Deutschland verbessern sollen:
1. die Erforschung von (seltenen) Krankheiten vorantreiben,
2. Mechanismen und Pr&#228;dispositionen identifizieren, die Krankheiten ausl&#246;sen k&#246;nnen, um darauf basierend
Therapieans&#228;tze zu finden,
3. die bisher zeit- und kostenintensive Erforschung und Entwicklung von Medikamenten effizienter gestalten,
4. Diagnoseverfahren verbessern,
5. Assistenzsysteme zur Verbesserung von Arbeitsabl&#228;ufen im Operationssaal sowie bei der Durchf&#252;hrung
von interventionellen und konventionellen Therapien entwickeln,
6. intelligente Assistenzsysteme entwerfen zum Einsatz in der Pflege und der Rehabilitation,
7. Assistenzsysteme zur &#228;rztlichen Entscheidungsunterst&#252;tzung entwickeln.
In Deutschland wird in diesen unterschiedlichen Bereichen bereits intensiv geforscht, h&#228;ufig in Verbundprojekten
in Kooperation mit der Wirtschaft, unterst&#252;tzt durch die Deutsche Forschungsgemeinschaft (DFG), die L&#228;nder
oder das BMBF. In der Grundlagenforschung spielt Deutschland in der KI-Forschung im Gesundheitssektor, wie
in der allgemeinen KI-Forschung auch, im internationalen Vergleich eine durchaus wichtige Rolle. Probleme
gibt es bei der Umsetzung in konkrete innovative Produkte und insbesondere aufgrund fehlender digitaler
Infrastruktur, die einen solchen innovativen Transferprozess in die breite Anwendung erst erm&#246;glicht. 
Die Digitalisierung des Gesundheitswesens ist, wie in den vorherigen Abschnitten beschrieben, Voraussetzung
f&#252;r die medizinische KI-Forschung in Deutschland. Ohne die n&#246;tige digitale Infrastruktur und den Zugang zu
forschungsrelevanten Patientendaten kann KI-getriebene Gesundheitsforschung nicht funktionieren. So k&#246;nnen
die zuk&#252;nftig in der ePA abgelegten Gesundheitsdaten auch der Forschung eine gro&#223;e Chance bieten. Daf&#252;r muss
die ePA aber forschungskompatibel ausgestaltet werden, wie es in der Hightech-Strategie der Bundesregierung
f&#252;r das Jahr 2025 angek&#252;ndigt wurde. Damit das gelingt, sollte die Forschungsperspektive bereits heute auf allen
Entscheidungsebenen und bei allen Entwicklungsstufen der ePA eng eingebunden werden. 
Ohne die Schaffung der bereits dargestellten Voraussetzungen sind die Ziele der KI-getriebenen
Gesundheitsforschung nur schwer oder gar nicht zu realisieren. Das bezieht sich auf die digitale Infrastruktur ebenso wie auf die
Datenfreigabe, bei der Patientinnen und Patienten bestimmte Daten der Forschung zur Verf&#252;gung stellen k&#246;nnen,
um die Datenverf&#252;gbarkeit zu verbessern. Der folgende Abschnitt stellt daher die Datenverf&#252;gbarkeit f&#252;r die
Forschung in den Mittelpunkt.
4.2.2 Forschungsdaten &#8211; Verf&#252;gbarkeit, Qualit&#228;t und offene Standards
F&#252;r die Forschung zu KI und digitalen Anwendungen auf der Grundlage Maschinellen Lernens im
Gesundheitsbereich sind hochwertige und valide medizinische Daten von zentraler Bedeutung. Der von der
Medizininformatik-Initiative des BMBF gef&#246;rderte Aufbau von Datenintegrationszentren an deutschen Universit&#228;tskliniken ist
ein erster Schritt f&#252;r einen besseren Zugang zu Gesundheitsdaten. Es ist aber wichtig, auch weitere heterogene
1105 Vgl. Huss (2019): K&#252;nstliche Intelligenz, Robotik und Big Data in der Medizin, S. 51.
Daten aus Krankenversorgung, klinischer und biomedizinischer Forschung zusammenzuf&#252;hren und
aufzubereiten, um erfolgreiche KI-Forschung im Gesundheitswesen zu betreiben. 
Daten im Gesundheitssektor liegen oft unstrukturiert vor (etwa als Freitext in Arztbriefen), haben
unterschiedliche Formate und werden in oft miteinander nicht kompatiblen IT-Systemen gespeichert. Damit sie f&#252;r die
Forschung genutzt werden k&#246;nnen, m&#252;ssen die Daten jedoch interoperabel und vergleichbar sein. Einheitliche
Standards beim Erfassen und Speichern von Gesundheitsdaten sind deshalb wichtig und sollten f&#252;r die Entwicklung 
der forschungskompatiblen ePA etabliert werden. Mit den FAIR-Prinzipien (findable: auffindbar, accessible:
zug&#228;nglich, interoperable: vollst&#228;ndig kompatibel, reusable: wiederverwendbar) existieren bereits Grunds&#228;tze,
die daf&#252;r sorgen sollen, dass Forschungsdaten auch von anderen Wissenschaftlerinnen und Wissenschaftlern f&#252;r
ihre Forschung genutzt werden k&#246;nnen. Diese m&#252;ssen im Gesundheitsbereich breiter angewendet werden und als
Orientierung f&#252;r die anzustrebende Dateninfrastruktur dienen. Dabei muss konsequent international gedacht
werden; eine Orientierung an bestehenden und zu entwickelnden internationalen Standards ist unerl&#228;sslich.1106 
Die Nationale Forschungsdateninfrastruktur (NFDI), die auf den FAIR-Prinzipien fu&#223;t, spielt hier eine
entscheidende Rolle. Bei der Entstehung der Konsortien (insbesondere derjenigen, die f&#252;r den Gesundheitsbereich
zust&#228;ndig sind) sollte die Anwendung der Daten im Bereich der KI mitgedacht und besonders auf die
Interoperabilit&#228;t geachtet werden. Internationale Standards sind auch f&#252;r die Verzahnung mit der European Open Science
Cloud wichtig und deren Gebrauch sollte, wenn n&#246;tig, gezielt durch Anreize gef&#246;rdert werden.
Neben der Interoperabilit&#228;t und der Verwendung internationaler Standards spielen auch offene Standards f&#252;r die
Datenverf&#252;gbarkeit eine wichtige Rolle. Offene Standards erleichtern die weitere Nutzung von Daten und tragen
zur Nachvollziehbarkeit von KI-Entscheidungen bei. Denn erst durch offene Standards bei Medizinprodukten
werden Daten aus medizinischen Ger&#228;ten einer breiten Analyse zug&#228;nglich.1107 Damit die Nutzung von Daten
aus medizinischen Ger&#228;ten f&#252;r die KI-Forschung nicht vom guten Willen der Hersteller abh&#228;ngt, muss ein
entsprechender regulatorischer Rahmen sicherstellen, dass auch privatwirtschaftliche Akteure offene Standards
verwenden &#8211; bei gleichzeitiger Belohnung des unternehmerischen Risikos durch effektiven Schutz des geistigen
Eigentums und Vermeidung hoher Preise durch wettbewerbssch&#228;dliche Quasi-Monopolstrukturen. Nur so wird
die Anwendung einsetzbar und finanzierbar werden.
Um der KI-Forschung den Zugang zu medizinischen Daten zu erleichtern, sollten Open-Data-Initiativen in
Wissenschaft und Verwaltung gef&#246;rdert und das Prinzip von Open Data &#252;berall dort zum rechtlich verbindlichen 
Standard werden, wo dem keine datenschutzrechtlichen Bedenken entgegenstehen. Dies ist im medizinischen
Kontext bisher nicht gegeben. Die richtige Balance zwischen dem Schutz pers&#246;nlicher Gesundheitsdaten und
dem Forschungsnutzen zu finden, ist im Gesundheitsbereich besonders wichtig, sollte aber kein Argument f&#252;r
die generelle Abkehr vom Open-Data-Prinzip bedeuten. Gerade die Ergebnisse &#246;ffentlich finanzierter Forschung 
sollten auch f&#252;r die &#214;ffentlichkeit einsehbar sein und sie sollten weiterverwendet werden k&#246;nnen. Gro&#223;e
Kohortenstudien wie die UK Biobank machen ihre Daten etwa nach Pr&#252;fung des legitimen Anspruchs pseudonymisiert
zug&#228;nglich und verpflichten Forscherinnen und Forscher dazu, ihre Forschungsergebnisse wiederum als Open
Data zur Verf&#252;gung zu stellen.
Mithilfe synthetischer medizinischer Daten kann die Sicherheit personenbezogener Daten gew&#228;hrleistet und
trotzdem Forschung mit Gesundheitsdaten erm&#246;glicht werden.1108 Synthetische Daten bilden die Muster der
Originaldaten realit&#228;tsnah ab, ohne einzelne Personen identifizierbar zu machen. Denkbar w&#228;re hier zun&#228;chst die
Unterst&#252;tzung von Projekten, die synthetische Daten f&#252;r den Medizinbereich entwickeln. Diese m&#252;ssten in einem
zweiten Schritt der Forschung insgesamt zur Verf&#252;gung gestellt werden.
F&#252;r die aufwendige Aufbereitung der Daten m&#252;ssen zudem finanzielle Mittel sowie Expertinnen und Experten
bereitgestellt werden, um die vorhandenen Daten auf die n&#246;tige Qualit&#228;t zu bringen und sie in den richtigen
Formaten, mit den n&#246;tigen Labeln und Schlagw&#246;rtern der Forschung zur Verf&#252;gung zu stellen. Das erm&#246;glicht
auch die Verwendung der Daten als qualitativ hochwertiger Trainingsdatens&#228;tze mit einem m&#246;glichst geringen
Bias.
Die Erforschung der technologischen, ethischen und rechtlichen Herausforderungen rund um das Thema
Gesundheitsdaten sollte verst&#228;rkt werden. 
1106 Siehe auch Kapitel 4.1 dieses Projektgruppenberichts [Voraussetzungen f&#252;r KI im Gesundheitsbereich].
1107 Vgl. Berens und Ayhan (2019): Proprietary data formats block health research.
1108 Darstellung Prof. Dr. Sylvia Thun (Berlin Institute of Health) in der Sitzung der Projektgruppe KI und Gesundheit am 1. April 2019.
4.2.3 Forschungslandschaft, F&#246;rderstrukturen und Kooperationen 
KI muss als Teil der Gesundheitsforschung verstanden und entsprechend gef&#246;rdert werden. Hier besteht sowohl
bei der interdisziplin&#228;ren Einbettung als auch bei den F&#246;rderstrukturen Handlungsbedarf. Trotz
Forschungsf&#246;rderung im Bereich der KI ist deren klinische Anwendung bis auf die Diagnostik noch sehr gering. Um KI
schneller in den klinischen Alltag zu integrieren, sind neue F&#246;rderinstrumente unabdingbar. Notwendig w&#228;re z. B. die
F&#246;rderung und Umsetzung von Demonstrator-Projekten, die langfristig von KI-Grundlagenforschung &#252;ber die
biomedizinische Validierung bis zur klinischen Translation durchfinanziert sind. Daf&#252;r sind Programme
notwendig, die eine l&#228;ngere Laufzeit aufweisen als bisher.1109 Au&#223;erdem m&#252;ssen Br&#252;cken zwischen den
Gesundheitsberufen und der KI-Forschung geschlagen und fach&#252;bergreifende Forschungsteams aus Medizin und KI st&#228;rker
gef&#246;rdert werden. Um &#196;rztinnen und &#196;rzte in die Lage zu versetzen, tats&#228;chlich selbst zu forschen oder mit
Forscherteams zu kooperieren, sollten sie in der daf&#252;r ben&#246;tigten Zeit von ihren Aufgaben in der Versorgung
freigestellt werden. In den USA sind &#196;rztinnen und &#196;rzte an Unikliniken etwa einen Tag pro Woche von ihren
Versorgungsaufgaben freigestellt, um sich der Forschung zu widmen. Solche M&#246;glichkeiten sollten auch in
Deutschland gepr&#252;ft werden.
Zur F&#246;rderung von Forschungsschwerpunkten an der Schnittstelle von Medizin und Informatik sollten
&#214;kosysteme geschaffen werden, in denen KI-Expertinnen und -Experten mit Medizinerinnen und Medizinern
gemeinsam agieren und direkt mit Unternehmen und Start-ups kooperieren k&#246;nnen. Dazu sollten existierende
Schwerpunkte, z. B. Universit&#228;ten mit forschungsstarken Universit&#228;tskliniken und Informatikfachbereiche bzw. Institute
mit ausgewiesenem KI-Schwerpunkt, ausgebaut und gezielt gef&#246;rdert werden. 
Die Anzahl der Professuren und Studieng&#228;nge im Bereich KI, Robotik, Datenwissenschaft und
Medizininformatik muss erh&#246;ht und die Professuren und Studieng&#228;nge mit besseren Forschungsbedingungen ausgestattet werden. 
Insbesondere m&#252;ssen auch interdisziplin&#228;re Professuren an der Schnittstelle Medizin, Gesundheitsberufe und KI
geschaffen werden, z. B. im Rahmen der 100 Professuren, die in der KI-Strategie der Bundesregierung1110
angek&#252;ndigt wurden, oder dar&#252;ber hinaus.
Die Universit&#228;ten mit Hochschulmedizin m&#252;ssen als wichtige Akteure gest&#228;rkt werden. Dazu ist die Finanzierung
von Br&#252;ckenprofessuren an Standorten der Hochschulmedizin mit starker KI-Forschung notwendig. Dies w&#252;rde
KI-Forschung und medizinische Forschung verkn&#252;pfen und den medizinischen Fakult&#228;ten und
Universit&#228;tskliniken erlauben, bereits verf&#252;gbare klinische Daten zum Wohl der Patientinnen und Patienten einzusetzen. Dazu
ist auch eine ausreichende Finanzierung der entsprechenden IT-Infrastruktur notwendig. Diese enge Verzahnung
von KI-Forschung mit klinischer Forschung und Patientenversorgung w&#252;rde die klinische KI-Anwendung in den
Universit&#228;tskliniken beschleunigen und eine breite KI-Expertise in den Einrichtungen erh&#246;hen. 
Die Forschung zu intelligenten Systemen steht trotz beeindruckender Erfolge bei spezifischen Anwendungen
noch in vielen Bereichen am Anfang. Die Modellierung von diagnostischer Unsicherheit ist noch eine
Herausforderung. Algorithmen k&#246;nnen derzeit oft keinen Hinweis geben, wenn sie keine ad&#228;quate Entscheidungshilfe
abgeben k&#246;nnen. Diese sogenannte &#8222;overconfidence&#8220; des Algorithmus kann bei Diagnosen zu
Herausforderungen f&#252;hren. Auch die Nachvollziehbarkeit von intelligenten Systemen ist noch eine technische Herausforderung,
die f&#252;r den Gesundheitsbereich ebenfalls von Bedeutung ist. Die Forschung zu Zuverl&#228;ssigkeit, Transparenz und
Erkl&#228;rbarkeit sollte daher besonders im Fokus der Forschungsf&#246;rderung im Bereich Gesundheit und KI stehen. 
Auch Forschungsbedarfe und Entwicklung von KI in der Medizin m&#252;ssen sich an ethischen Grunds&#228;tzen und
Gerechtigkeitsfragen orientieren. Wenn etwa Bilderkennungsverfahren Hautkrebs nur bei heller Haut gut
erkennen und bei dunkler Haut schlechtere Diagnosen abliefern, weil zu wenig Daten von Menschen mit dunkler Haut
vorhanden sind, dann muss dies behoben werden. Gleiches gilt f&#252;r KI-gest&#252;tzte Therapien, die unabh&#228;ngig vom
Geschlecht gleichwertig sein m&#252;ssen.
1109 Darstellung Prof. Dr. Philipp Berens (Universit&#228;tsklinikum T&#252;bingen) in der Sitzung der Projektgruppe KI und Gesundheit am 1.
April 2019 (vgl. Projektgruppendrucksache 19(27)PG 3-17 a) vom 1. April 2019).
1110 Vgl. Bundesregierung (2018): Strategie K&#252;nstliche Intelligenz der Bundesregierung.
4.2.4 Wirtschaftsstandort, Transfer und Start-ups
Neben der F&#246;rderung der KI-Forschung im Gesundheitsbereich muss auch der Transfer von
Forschungsergebnissen in die Wirtschaft st&#228;rker gef&#246;rdert werden. In interdisziplin&#228;ren &#214;kosystemen sollten Forscherinnen und
Forscher deshalb direkt mit Unternehmen und Start-ups zusammenarbeiten k&#246;nnen. Staatliche
Unterst&#252;tzungsinstrumente sollten neben Forschung und Entwicklung auch verst&#228;rkt die Kommerzialisierung und &#220;berf&#252;hrung in
die Regelversorgung f&#246;rdern. 
Denn auch die Gesundheitswirtschaft ver&#228;ndert sich mit der Entwicklung von KI-Anwendungen. Neben den
Arzneimittelherstellern und Medizinunternehmen treten vermehrt Start-ups in Erscheinung und auch
internationale Digitalkonzerne dr&#228;ngen verst&#228;rkt auf den Gesundheitsmarkt. Im Jahr 2018 betrug der Anteil der deutschen
Gesundheitswirtschaft am Bruttoinlandsprodukt 12,1 Prozent, die Bruttowertsch&#246;pfung lag bei 369,8 Milliarden
Euro und mit rund 7,6 Millionen Erwerbst&#228;tigen war etwa jeder sechste Arbeitsplatz in Deutschland in der
Gesundheitswirtschaft angesiedelt.1111 Die Gesundheitsausgaben weltweit liegen seit 20 Jahren konstant bei etwa 8 
bis 10 Prozent des Weltbruttoinlandproduktes, das im Jahr 2021 etwa 100 Billionen Dollar betragen wird.1112 Die
f&#252;nf gro&#223;en Tech-Firmen unserer Zeit (Google, Amazon, Facebook, Apple, Microsoft) engagieren sich alle
zunehmend stark in diesem Bereich. Die Kompetenzen der Unternehmen decken dabei ein breites Spektrum ab:
Versand, Endger&#228;te (in vielen F&#228;llen an das Smartphone gekoppelt), Datenanalyse und -suche, Datenverwaltung
und Zugang zu riesigen Benutzergruppen. Die Unternehmen bauen ihre Kompetenz im Gesundheitssektor zudem
durch gezielte Akquisitionen weiter aus. In Deutschland gibt es ebenfalls gro&#223;e Firmen wie Siemens oder Bosch.
Gerade die KI-Start-ups im Gesundheitsbereich k&#246;nnen mit dieser Schlagkraft allerdings oft nicht mithalten.
KI-Start-ups im Gesundheitsbereich haben in Deutschland oftmals mit den gleichen Problemen zu k&#228;mpfen wie
KI-Start-ups in anderen Branchen: der begrenzte Zugang zu hoch qualitativen Daten, der Mangel an Fachkr&#228;ften
im Bereich KI und Robotik und Engp&#228;sse bei Risiko-Finanzierungen im Bereich bis 150 000 Euro und im
Bereich von 1 bis 5 Millionen Euro. Speziell im Gesundheitsbereich gibt es f&#252;r KI-Start-ups jedoch noch weitere
H&#252;rden, um ihre Produkte auf den Markt zu bringen. Die Zulassungsverfahren von Medizinprodukten, die
Nutzenbewertung und die Verhandlungen zur Kosten&#252;bernahme durch die Krankenkassen ziehen sich nicht selten
&#252;ber Jahre hin. Gerade junge und kleine Unternehmen sind deshalb w&#228;hrend dieser Zeit auf Beratung und
finanzielle Unterst&#252;tzung angewiesen. Denn anders als etwa in den USA ist es kaum m&#246;glich, nach der Anschubphase
eine Risikofinanzierung zu erhalten. So darf beispielsweise die Kreditanstalt f&#252;r Wiederaufbau (KfW) erst
investieren, wenn der j&#228;hrliche Umsatz 100 000 Euro &#252;bersteigt, was in der Medizintechnik aber aufgrund der
Erstattungsproblematik in der Praxis oft nicht m&#246;glich ist.
Im ambulanten Bereich ist eine Kosten&#252;bernahme durch die einzelnen Krankenkassen oder eine Aufnahme in 
den Katalog der erstattungsf&#228;higen Leistungen durch den Gemeinsamen Bundesausschuss f&#252;r Start-ups derzeit
h&#228;ufig zu aufwendig. Der im Jahr 2016 eingef&#252;hrte Innovationsfonds des Gemeinsamen Bundesausschusses1113 
soll mit 300 Millionen Euro j&#228;hrlich helfen, eine fr&#252;he Kosten&#252;bernahme w&#228;hrend der Erhebung der
Nutzenbewertung einer Innovation zu gew&#228;hrleisten. Dieser Innovationsfonds ist in seiner aktuellen Konzeption
ungeeignet f&#252;r Start-ups, da die Anforderungen an Kooperationspartner f&#252;r eine erfolgreiche F&#246;rderung zu hoch und die
Wartezeit auf eine Entscheidung zu lang sind und die Kriterien f&#252;r eine F&#246;rderung technischer Innovationen wie
KI und Robotik nur mangelhaft abgedeckt sind.1114 
Damit KI-Anwendungen schneller aus der Forschung und Entwicklung in die medizinische Praxis gelangen,
sollte die Zusammenarbeit von Start-ups mit Leistungserbringern gest&#228;rkt, Start-ups bei klinischen Studien zur
Nutzenbewertung finanziell unterst&#252;tzt und die finanziellen F&#246;rderungen im Bereich Entwicklung und
Kommerzialisierung ausgeweitet werden. F&#252;r KI-Innovationen sollten bestehende F&#246;rderinstrumente ge&#246;ffnet und neue
geschaffen werden, die sich explizit an KI-Start-ups richten und auch finanzielle Unterst&#252;tzung in den Bereichen
Entwicklung, Zulassung und Nutzenbewertung umfassen. Dar&#252;ber hinaus sollten umfangreiche
Beratungsangebote f&#252;r Start-ups zu den Themen Zulassung, Verg&#252;tungssysteme und Zusammenarbeit mit Krankenkassen
geschaffen werden.
1111 Vgl. Bundesministerium f&#252;r Wirtschaft und Energie (2019): Gesundheitswirtschaft &#8211; Fakten &amp; Zahlen. Ergebnisse der
Gesundheitswirtschaftlichen Gesamtrechnung, Ausgabe 2018.
1112 Darstellung Dipl.-Ing. Oliver P. Christ (CEO Prosystem GmbH) und Dr. Sebastian Hallensleben (Verband der Elektrotechnik,
Elektronik, Informationstechnik e. V.) in der Sitzung der Projektgruppe KI und Gesundheit am 13. Mai 2019 (vgl.
Projektgruppendrucksache 19(27)PG 3-10, Folien 3 und 4).
1113 Weitere Informationen dazu unter: https://innovationsfonds.g-ba.de/ (zuletzt abgerufen am 4. August 2020).
1114 Handlungsempfehlungen von Dr. Alexander K&#246;nig (Reactive Robotics GmbH), Projektgruppendrucksache 19(27)PG 3-21 vom
13. Mai 2019.
4.2.5 Handlungsempfehlungen
1. Um die KI-Forschung im Gesundheitsbereich zu st&#228;rken, sollen interdisziplin&#228;re &#214;kosysteme aufgebaut
und Leuchtturmprojekte von der Grundlagenforschung bis zur klinischen Translation mitsamt Legal
Sandboxing gezielt gef&#246;rdert werden. Die enge Zusammenarbeit zwischen Wissenschaft und
Gesundheitsberufen stellt sicher, dass an Anwendungen geforscht wird, die einen tats&#228;chlichen Mehrwert in der
medizinischen und pflegerischen Praxis haben. Durch die l&#228;ngeren und durchg&#228;ngigen F&#246;rderzeitr&#228;ume wird der
Transfer von Erkenntnissen der Grundlagenforschung in konkrete Anwendungen verbessert.
2. Freir&#228;ume f&#252;r &#196;rztinnen und &#196;rzte, sich in der Forschung und an Kooperationen mit wissenschaftlichen
Einrichtungen zu beteiligen, sollten gr&#246;&#223;er werden. Bund und L&#228;nder sollten gemeinsam &#8211; und
gegebenenfalls auf Antrag &#8211; M&#246;glichkeiten schaffen, sich f&#252;r die Forschung von Aufgaben in der Praxis
freistellen zu lassen.
3. Um das volle Potenzial von KI f&#252;r die Gesundheitsforschung nutzen zu k&#246;nnen, muss die Verf&#252;gbarkeit
von qualitativ hochwertigen und interoperablen Gesundheitsdaten verbessert werden. Die FAIR-
Prinzipien m&#252;ssen breitere Anwendung finden, die Verwendung offener Standards sichergestellt, die Potenziale
synthetischer Daten genutzt und die Anwendung des Open-Data-Prinzips im Gesundheitsbereich
ausgeweitet und gef&#246;rdert werden. Die Bundesregierung muss daf&#252;r sorgen, dass bei der Herstellung von
Interoperabilit&#228;t keine nationalen Sonderl&#246;sungen geschaffen, sondern international gebr&#228;uchliche
Terminologien und bestehende Standards gef&#246;rdert werden.
4. Damit KI-Anwendungen schneller aus der Forschung und Entwicklung in die medizinische Praxis
gelangen, sollten existierende F&#246;rderinstrumente f&#252;r medizinische Innovationen f&#252;r KI-Anwendungen und
Start-ups ge&#246;ffnet und neue Unterst&#252;tzungsinstrumente geschaffen werden, die sich explizit auch an KI-
Start-ups richten. Umfassende Beratung und finanzielle Hilfen bei Zulassung, Nutzenbewertung und
Kosten&#252;bernahme durch die Krankenkassen sind n&#246;tig, um ein attraktives Umfeld f&#252;r die
Gesundheitswirtschaft zu schaffen.
5. Die Erforschung der technologischen, ethischen und rechtlichen Herausforderungen rund um das Thema
Gesundheitsdaten sollte verst&#228;rkt werden. 
6. Ethische Fragen und Fragen der Gerechtigkeit, die im Zusammenhang mit KI im Gesundheitsbereich
entstehen, sollen erforscht und Diskriminierungen verhindert werden. KI-Anwendungen im
Gesundheitsbereich m&#252;ssen so robust sein, dass sie f&#252;r alle Menschen optimale Ergebnisse liefern.
Entwicklung, Marktzulassung, Erstattung und Haftung f&#252;r KI-basierte Anwendungen 
im Gesundheitsbereich
KI-basierte Anwendungen k&#246;nnen unser Gesundheitswesen sowie die ganzheitliche gesundheitliche Versorgung
wesentlich unterst&#252;tzen und verbessern. Es ist daher notwendig, in den Bereichen Zulassung und Haftung
entsprechende regulatorische Ver&#228;nderungen vorzunehmen, wo bestehende Regelungen nicht mehr zur
technologischen Entwicklung passen.
4.3.1 Entwicklung, Marktzulassung und Erstattung
Angesichts der besonderen Relevanz des Gesundheitsbereichs f&#252;r die Bev&#246;lkerung und der vielen Chancen und
Risiken, die durch den Einsatz von KI-basierten Systemen in Bezug auf Patientinnen und Patienten und ihre
Versorgung bestehen, bedarf die Frage der Marktzulassung von Systemen f&#252;r den Einsatz bei Patientinnen und
Patienten besonderer Sorgfalt. In erster Linie muss sichergestellt sein, dass nur Systeme zugelassen werden, die
den Patientinnen und Patienten nutzen und ihnen nicht schaden. Entscheidend wird aber auch sein, die
Zulassungsverfahren f&#252;r digitale Anwendungen im Gesundheitswesen so zu gestalten, dass sie die Eigenschaften KI-
basierter Systeme antizipieren. Insbesondere f&#252;r Start-ups, kleinere Unternehmen und universit&#228;re
Forschungsgruppen sollten die Verfahren zum Marktzugang von KI-Systemen keine zu gro&#223;en b&#252;rokratischen H&#252;rden
aufbauen. Die bisherigen Prozesse sind sehr aufwendig, was jedoch nicht der inhaltlichen Komplexit&#228;t der Zulassung
geschuldet ist, sondern dem hohen b&#252;rokratischen Aufwand und damit einer hochkomplexen Zulassung im
Gesundheitsbereich. Gr&#246;&#223;ere Unternehmen haben die M&#246;glichkeit, hierf&#252;r eigene Expertinnen und Experten
einzustellen und firmeninterne Standards zu setzen. F&#252;r Start-ups, junge Unternehmen und Forschungsgruppen ist es
ohne staatliche Unterst&#252;tzung hingegen schwierig bis unm&#246;glich, eine Zulassung zu erwirken. Auch die
Finanzierung gestaltet sich schwierig, da gro&#223;e zeitliche Abst&#228;nde zwischen Investition und Erstattung durch die
Krankenkassen liegen. In punkto Haftung ergeben sich ebenfalls besondere Fragestellungen. Eine der wichtigsten
Fragen ist die Haftungsfrage, wenn die Patientin oder der Patient durch einen Fehler beim Einsatz oder eine
Fehlfunktion teilautonomer Chirurgieroboter, KI-Diagnoseanwendungen oder Pflegeassistenten gesch&#228;digt wird.
Aufgrund der m&#246;glichen gravierenden Auswirkungen fehlerhafter Produkte gibt es spezielle Vorschriften f&#252;r den
Marktzugang von Medizinprodukten, die von den Herstellern beachtet werden m&#252;ssen. Dies war bisher im
Medizinproduktegesetz (MPG) geregelt, wird aber ab dem 26. Mai 2020 auf Basis der EU-Medizinprodukte-
Verordnung 90/385/EEC stattfinden. Vorgesehen sind dort u. a. die Durchf&#252;hrung von klinischen Studien vor der
Marktzulassung und eine &#220;berwachungspflicht f&#252;r den Hersteller, nachdem das Produkt in den Verkehr gebracht
wurde. Zus&#228;tzlich gibt es eine Markt&#252;berwachung durch die zust&#228;ndigen nationalen Stellen; in Deutschland ist
dies das BfArM. Die Nichteinhaltung der Vorschriften f&#252;r die Zulassung solcher Produkte kann je nach Schwere
eines Falles mit Bu&#223;geldern oder auch Freiheitsstrafen geahndet werden (siehe &#167;&#167; 40 bis 43 MPG). Hersteller
k&#246;nnen wegen der hohen Anforderungen geneigt sein, ihr Produkt &#8211; wenn m&#246;glich &#8211; nicht als Medizinprodukt
zuzulassen. Hier muss es europaweit einheitliche Verfahren geben und analog zum Arzneimittelrecht Aufgabe
der Zulassungsbeh&#246;rden sein, zu beurteilen, welche Anwendungen als Medizinprodukt zu bewerten sind und
welche nicht.
F&#252;r Produkte im Bereich der Pflege ergibt sich die besondere Problematik, dass sie zumeist nicht unter das MPG,
sondern nur unter das Produktsicherheitsgesetz (ProdSG) fallen, da sie nicht immer einen direkten diagnostischen
oder therapeutischen Einsatzzweck haben. Als Beispiel sei ein einfacher Serviceroboter genannt. Dennoch kann
es auch durch ihren Einsatz im Pflegealltag zu Gef&#228;hrdungen kommen und so ist es problematisch, dass nach
dem ProdSG die Zulassung haupts&#228;chlich in der Verantwortung der Hersteller liegt und es auch keine
regelm&#228;&#223;igen Sicherheitspr&#252;fungen gibt. Perspektivisch sollten f&#252;r Pflegeassistenzsysteme vergleichbare Anforderungen
wie f&#252;r Medizinprodukte entwickelt werden.1115 
Die Vorschriften f&#252;r den Marktzugang verlangen von einem Medizinprodukt in der Konsequenz einen &#8222;Design 
Freeze&#8220;, also einen Punkt, ab dem es technisch nicht mehr ver&#228;ndert wird. Au&#223;erdem m&#252;ssen das Verhalten und
die Wirkung vollst&#228;ndig vorhersagbar sein.
Es muss also im Rahmen des Zulassungsverfahrens eine klare Vorgabe geben, wie eine CE-Zertifizierung eines
lernenden Systems m&#246;glich sein kann. Grunds&#228;tzlich ist auch bei intelligenten Systemen ein &#8222;Design Freeze&#8220;
m&#246;glich, bei dem das &#8222;ausgelernte&#8220; System zugelassen wird. Einzelne Entwickler handhaben das z. B. bei
Bilderkennungssoftware bereits heute so. Ein System wird in der Regel vor seiner Zulassung trainiert und lernt im
Einsatz an der Patientin oder am Patienten nicht weiter. Nach Aussagen von Sachverst&#228;ndigen ist dies auch im
Gesundheitsbereich nicht sinnvoll, da sich w&#228;hrend des Einsatzes an der Patientin oder am Patienten der
Dateninput nicht hinsichtlich eines m&#246;glichen Bias kontrollieren l&#228;sst. Bei Zulassungs- und auch den nachfolgenden
Haftungsfragen ist also zwischen Systemen zu unterscheiden, die w&#228;hrend des Einsatzes weiterlernen, und
solchen, die nur w&#228;hrend der Entwicklung lernen und hinterher in einem fixierten Zustand eingesetzt werden. Ein
Weiterlernen sollte nur in begr&#252;ndeten Ausnahmef&#228;llen erm&#246;glicht werden.
In jedem Fall sollte bei selbstlernenden Systemen nicht nur das Ergebnis, sondern der Prozess zertifiziert werden.
Eine M&#246;glichkeit der Qualit&#228;tssicherung ist, die Leistung solcher Verfahren automatisiert auf der Grundlage von 
Testdatens&#228;tzen zu &#252;berpr&#252;fen. Diese Datens&#228;tze k&#246;nnten zentral und unabh&#228;ngig gesammelt, annotiert,
dokumentiert und anbieter&#252;bergreifend zur Verf&#252;gung gestellt werden. In Betracht gezogen werden sollten auch
M&#246;glichkeiten einer Vorab-Zertifizierung im Rahmen eines Zulassungsrahmens f&#252;r kontinuierlich lernende
Algorithmen. Der gesamte Lebenszyklus eines KI-Systems sollte dokumentiert werden, auch die Entwicklungs- und
Trainingsphasen. &#196;hnlich wie bei der Black Box eines Flugzeuges k&#246;nnten so die Ursachen sp&#228;terer Fehlfunktionen 
erforscht, kommuniziert und bei allen Anwendungsf&#228;llen behoben werden.
Aufgrund der hohen Anforderungen an Medizinprodukte und die Gesundheitsversorgung sind die Verfahren zum
Marktzugang zumindest bei Medizinprodukten hoher Risikoklassen voraussetzungsvoll (vgl. insbesondere die
Regelungen der Medical Device Directive (MDD), die seit dem Jahr 2017 EU-weit in Kraft sind, und die der
DSGVO, die seit dem Jahr 2018 EU-weit in Kraft sind). Das kann f&#252;r kleinere Unternehmen und besonders
Startups ein gro&#223;es Hindernis im Bereich der Marktzulassung darstellen. Es existieren diverse
Unterst&#252;tzungsangebote, die aber oft als unzureichend erlebt werden. Die zust&#228;ndigen Stellen, z. B. das BfArM, das Bundesamt f&#252;r 
Wirtschaft und Ausfuhrkontrolle (BAFA), das BMBF, der Gemeinsame Bundesausschuss oder auch die GKV,
sind f&#252;r kleinere Unternehmen oft nicht oder nur schwierig erreichbar.1116 
1115 Vgl. Kehl (2018): Robotik und assistive Neurotechnologien in der Pflege &#8211; gesellschaftliche Herausforderungen.
1116 Handlungsempfehlungen von Dr. Alexander K&#246;nig (Reactive Robotics GmbH), Projektgruppendrucksache 19(27)PG 3-21 vom
13. Mai 2019.
Insgesamt kann der regulatorische Rahmen der Marktzulassung f&#252;r die Anwendung von KI im
Gesundheitsbereich nur wirksam auf EU-Ebene angelegt werden.
Neben der Marktzulassung von KI-basierten Medizinprodukten kann auch die unmittelbare Erstattung KI-
basierter Anwendungen durch die GKV eine H&#252;rde darstellen. Im Digitale-Versorgung-Gesetz (DVG) ist eine
spezifische Erstattungsregelung f&#252;r digitale Gesundheitsanwendungen wie Apps enthalten. Diese sieht vor, dass die
Anwendungskosten nach einer ersten Pr&#252;fung der Sicherheit und von Qualit&#228;tskriterien wie Datenschutz,
Transparenz und Nutzerfreundlichkeit f&#252;r die Laufzeit von einem Jahr vorl&#228;ufig von der GKV erstattungsf&#228;hig sind.
In dieser Zeit muss der Hersteller beim BfArM nachweisen, dass das Angebot positive Effekte f&#252;r die Versorgung
hat. &#220;ber die Verg&#252;tung verhandelt der Anbieter mit dem GKV-Spitzenverband. 
Dieses Verfahren w&#252;rde prinzipiell auch f&#252;r digitale Gesundheitsanwendungen gelten, die auf KI basieren. Um
eine hohe Qualit&#228;t des Prozesses zur Bewertung von positiven Versorgungseffekten im Vergleich zu bestehenden
Methoden sicherzustellen, sollte dieses Verfahren nur an bestimmten Zentren mit entsprechender Expertise wie
etwa Krankenh&#228;usern der Maximalversorgung durchgef&#252;hrt werden. 
Im Fall von Systemen, die w&#228;hrend des Einsatzes weiterlernen, ist zu ber&#252;cksichtigen, dass sich die &#220;berpr&#252;fung
von Versorgungseffekten und einer darauf basierenden Erstattungsentscheidung fortw&#228;hrend ver&#228;ndern k&#246;nnen,
was Einfluss auf die Ergebnisse haben kann, die durch solche Anwendungen erzielt werden. Das unterstreicht
den Vorteil von Systemen, die w&#228;hrend des Einsatzes nicht dazulernen, sondern bei denen Verbesserungen &#252;ber
Updates erfolgen, die nur eine verk&#252;rzte Pr&#252;fung zur Folge haben k&#246;nnten.
4.3.2 Haftungsfragen
Mit dem zunehmenden Einsatz von KI bei Diagnose, Therapie und Pflege stellt sich auch die Frage, ob die
bestehenden Haftungsregelungen im Gesundheitsbereich f&#252;r die neuen Anwendungen angemessen sind. Wenn ein
Pflegeroboter aufgrund eines Fehlers eine Patientin oder einen Patienten verletzt oder wenn eine &#196;rztin oder ein
Arzt mithilfe eines fehlerhaft arbeitenden Diagnoseanwendungen eine falsche Diagnose stellt, aufgrund derer die
Patientin oder der Patient gesch&#228;digt wird, muss klar sein, wer haftet.
Grunds&#228;tzlich gelten auch im Gesundheitsbereich, also f&#252;r die Hersteller von Medizinprodukten und f&#252;r die sie
einsetzenden &#196;rztinnen und &#196;rzte sowie Krankenh&#228;user die allgemeinen zivilrechtlichen Haftungsvorschriften.
Nach dem ProdHaftG haften Hersteller von Produkten f&#252;r Sch&#228;den, die ein fehlerhaftes Produkt an Leib und
Leben eines Menschen oder an einer Sache verursacht hat. Dies ist eine verschuldensunabh&#228;ngige Haftung, die
nur dann nicht greift, wenn das Produkt zum Zeitpunkt des Inverkehrbringens noch nicht fehlerhaft war oder
wenn der Fehler nach dem Stand der Wissenschaft und Technik zu dem Zeitpunkt, zu dem der Hersteller das 
Produkt in den Verkehr brachte, nicht erkannt werden konnte oder wenn der Fehler darauf beruht, dass der
Hersteller sich an eine gesetzliche Vorgabe gehalten hat.
Die Produzentenhaftung ist als Unterform der deliktischen Haftung in &#167; 823 des B&#252;rgerlichen Gesetzbuches
(BGB) geregelt. Deliktische Haftungsanspr&#252;che bestehen gegen diejenigen, die auf vorwerfbare Weise ein
gesch&#252;tztes Rechtsgut eines anderen verletzt haben. Anders als bei der Produkthaftung kommt eine
Verantwortlichkeit nach den Grunds&#228;tzen der Produzentenhaftung nur in Betracht, wenn der Hersteller einen Schaden
vors&#228;tzlich oder fahrl&#228;ssig verursacht hat. Auch muss der Schaden einem Hersteller zugerechnet werden, d. h. kausal
auf eine Pflichtverletzung des Herstellers zur&#252;ckgef&#252;hrt werden k&#246;nnen. Andererseits sch&#252;tzt die deliktische
Haftung nach &#167; 823 BGB einen weiten Kreis von Rechtsg&#252;tern und umfasst auch Verletzungen der Pers&#246;nlichkeit
und sonstiger eigentums&#228;hnlicher Rechte.
Eine Produzentenhaftung kommt in Betracht, wenn ein Hersteller eine Verkehrssicherungspflicht verletzt hat.
Als Verkehrssicherungspflichten anerkannt sind:
1. Organisationspflichten (der Hersteller muss seinen Betrieb so organisieren, dass Fehler durch Kontrollen 
entdeckt und fr&#252;hzeitig beseitigt werden k&#246;nnen),
2. Instruktionspflichten (der Hersteller muss die Nutzerin oder den Nutzer &#252;ber Bedienung und m&#246;gliche
Gefahrenquellen des Produkts informieren),
3. Produktbeobachtungspflichten (der Hersteller muss Hinweisen auf Fehler und Gef&#228;hrdungspotenzial seiner
Produkte nachgehen) und
4. Gefahrabwendungspflichten (der Hersteller muss erkannte Gefahren beim Gebrauch seiner Produkte
beseitigen und notfalls das Produkt vom Markt zur&#252;ckrufen).
Der Hersteller bleibt verpflichtet, den Programmierprozess sorgf&#228;ltig zu organisieren, seine Produkte zu
beobachten und erkannte Gefahren abzuwenden. Er bleibt verantwortlich f&#252;r Sch&#228;den, die durch eine Verletzung dieser
Pflichten verursacht werden.
Nach &#167; 823 BGB haftet aber auch diejenigen, die KI-Systeme einsetzen, wenn sie dadurch vors&#228;tzlich oder
fahrl&#228;ssig eine andere Person oder deren Recht widerrechtlich verletzen. Dann sind sie dieser Person zum Ersatz ihres
Schadens verpflichtet. Auch wer gegen ein Schutzgesetz verst&#246;&#223;t, muss der dadurch gesch&#252;tzten Person den
daraus entstehenden Schaden ersetzen, wenn schuldhaft gehandelt wurde. Au&#223;erdem gelten wie in allen
Vertragsbeziehungen vertragliche Haftungsgrundlagen, z. B. im Rahmen eines Behandlungsvertrages. Zus&#228;tzlich ist
die Strafbarkeit der K&#246;rperverletzung im Strafgesetzbuch verankert.
Die allgemeinen sowie die gesundheitsspezifischen Haftungsregeln sind grunds&#228;tzlich auch auf KI-Produkte
anwendbar. Wenn ein KI-System w&#228;hrend des Einsatzes nicht weiter trainiert wird, bestehen keine relevanten
Unterschiede zur Haftung gegen&#252;ber anderen Medizinprodukten.
Nach dem Wortlaut des ProdHaftG ist als Produkt eine &#8222;bewegliche&#8220;, d. h. k&#246;rperliche Sache anzusehen. Ob eine
Haftungsvorschrift f&#252;r bewegliche Sachen auf KI-Systeme, die aus Computer-Algorithmen und damit aus
Software bestehen, angewendet werden kann, ist in der Rechtswissenschaft umstritten. Da der Bundesgerichtshof
(BGH) in anderem rechtlichen Zusammenhang bereits Rechtsvorschriften f&#252;r bewegliche Sachen auf Software
angewendet hat,1117 liegt eine entsprechende Gleichstellung auch im Produkthaftungsrecht nahe. Eine
diesbez&#252;gliche Konkretisierung durch den Gesetzgeber k&#246;nnte Rechtsunsicherheit beseitigen. 
Andererseits wird die Produkthaftung nur angewendet bei Verletzung von K&#246;rper, Gesundheit und Eigentum.
F&#252;r eine Produkthaftung derjenigen, die KI programmieren, m&#252;sste die KI selbst in der Lage sein, direkt und 
unmittelbar auf diese Rechtsg&#252;ter einzuwirken. Eine rein unk&#246;rperliche KI kann letztlich aber nur mittelbar durch
&#8222;Werkzeuge&#8220; eine Verletzung der gesch&#252;tzten Rechtsg&#252;ter in der realen Welt bewirken. Demnach k&#228;me mangels
direkter Einwirkung auf die gesch&#252;tzten Rechtsg&#252;ter eine Haftung derjenigen, die KI-Algorithmen
programmieren, nach dem ProdHaftG nicht in Betracht. Der Anwendung des Gesetzes steht jedoch nichts entgegen, wenn
ein Hersteller eigen- oder fremdprogrammierte KI zur Steuerung oder Kontrolle von beweglichen Sachen nutzt,
die er in den Verkehr bringt.1118 
Ob ein KI-System einen Fehler, insbesondere einen Konstruktions- bzw. Programmierfehler, im Sinne des
Produkthaftungsrechts aufweist, kann nicht durch das Recht selbst abschlie&#223;end beantwortet werden. Vielmehr
richtet sich die Antwort auf diese Frage nach technischen Festsetzungen insbesondere der Informatik, die au&#223;erhalb
des Rechts gefunden werden m&#252;ssen. Denn ein Fehler in diesem Sinn ist ein Versto&#223; gegen den anerkannten
Stand der Technik, der durch Standards oder durch Techniksachverst&#228;ndige festzulegen ist. Allerdings k&#246;nnte es
sinnvoll sein, die &#8222;berechtigte Erwartung&#8220; an die Sicherheit eines IT-Systems i. S. d. &#167; 3 ProdHaftG
gesetzgeberisch insbesondere mit Hinblick auf autonome KI-Systeme etwas konkreter auszuformulieren. Die Person, die
einen Schaden erlitten hat, muss den Nachweis erbringen, dass ein Produktfehler urs&#228;chlich f&#252;r ihren Schaden
war. Dies kann im Einzelfall f&#252;r Betroffene schwer nachzuweisen sein. Es k&#246;nnte mit Blick auf KI-Systeme auch
dann eine Haftungsl&#252;cke auftreten, wenn die Fehlerquote des eingesetzten KI-Systems dem Stand der Technik
entsprochen hat und der Produzent alles f&#252;r die Optimierung des Systems getan hat, was nach dem Stand der
Technik m&#246;glich und fachgerecht war. Dies w&#228;re noch n&#228;her zu untersuchen. Man k&#246;nnte hierf&#252;r das
Haftungsrisiko bei der Person oder Stelle sehen, die die Technik einsetzt, und das Haftungsrisiko mit einer
Pflichtversicherung abdecken. Gegebenenfalls k&#246;nnte diese in die ohnehin verpflichtende Berufshaftpflichtversicherung
integriert werden, wobei die daraus resultierende Entwicklung der Versicherungsbeitr&#228;ge zu ber&#252;cksichtigen ist. 
Alternativ ist daher zu diskutieren, die Hersteller von KI-basierten Medizinprodukten, &#228;hnlich wie es im
Arzneimittelgesetz f&#252;r Arzneimittel vorgesehen ist, zum Abschluss einer Produkthaftpflichtversicherung oder einer
entsprechenden Deckungsvorsorge f&#252;r den Schadensfall zu verpflichten.
Die Produkthaftung greift nur ein, wenn das Produkt den Fehler, der zu dem Schaden f&#252;hrt, bereits beim
Inverkehrbringen, also bei Auslieferung bzw. &#220;bergabe an einen Abnehmer, aufweist. Daraus folgt, dass der Hersteller
eines KI-Systems nach Produkthaftungsrecht nicht verantwortlich ist, wenn die Fehlfunktion durch Umst&#228;nde
beim Einsatz des Systems verursacht wird (z. B. Umprogrammierung durch Nutzerinnen oder Nutzer, Einsatz
au&#223;erhalb des vorgesehenen Anwendungsbereichs, Zuf&#252;hrung ungeeigneter Datenbest&#228;nde durch die Anwende-
1117 Urteil des Bundesgerichtshofs vom 15. November 2006 (Az.: XII ZR 120/04); Urteil des Bundesgerichtshofs vom 4. November 1987 
(Az.: VIII ZR 314/86).
1118 So hat der Bundesgerichtshof eine Produkthaftung des Fahrzeugherstellers f&#252;r Gesundheitssch&#228;den bejaht, die durch einen Fehler in 
der Steuerungssoftware eines Airbags verursacht wurden, vgl. Urteil des Bundesgerichtshofs vom 16. Juni 2009 (Az.: VI ZR 107/08).
rinnen und Anwender). Auch f&#252;r solche F&#228;lle muss ein Versicherungsschutz des medizinischen Personals
bestehen. Generell muss sichergestellt sein, dass ein eventueller Schaden nicht auf die betroffene Patientin oder den
betroffenen Patienten abgew&#228;lzt wird.
4.3.3 Handlungsempfehlungen
Die Projektgruppe empfiehlt der Bundesregierung
1. zu &#252;berpr&#252;fen, ob und inwiefern ein spezifisches Pr&#252;fungsverfahren zur Erstattung von digitalen
Gesundheitsanwendungen, wie es im DVG geplant ist, auch auf andere KI-basierte Anwendungen &#252;bertragbar ist.
Dies k&#246;nnte im Rahmen eines Experimentierraums erprobt werden.
2. sich auf europ&#228;ischer Ebene f&#252;r klare Vorgaben zur Zertifizierung von KI-Software in der Medizintechnik
(z. B. in Zusammenarbeit mit der amerikanischen Food and Drug Administration (FDA)) einzusetzen.1119 
Es muss die Aufgabe der Zulassungsbeh&#246;rden sein, zu beurteilen, welche Anwendung unter das
Medizinproduktrecht f&#228;llt und welche nicht. F&#252;r die Robotik in der Pflege sind aufgrund ihres
Gef&#228;hrdungspotenzials im Versorgungsalltag Anforderungen nach dem Vorbild der Medizinprodukte zu entwickeln, auch wenn
sie formal bisher nicht in diese Kategorie fallen.
3. vor allem f&#252;r Start-ups und KMU Beratungs- und Unterst&#252;tzungsangebote hinsichtlich der Zertifizierung
und Marktzulassung von KI-Anwendungen im Gesundheitssystem, beispielsweise beim BfArM
einzurichten; denkbar w&#228;ren in diesem Kontext &#246;ffentliche Workshops (nicht zwingend kostenlos) und
Informationsmaterialien in verst&#228;ndlicher Sprache. Um weiterhin eine hohe Produktqualit&#228;t zu gew&#228;hrleisten, sollten die
Bestrebungen nicht dahin gehen, die Zulassungskriterien zu verringern oder herabzusetzen, sondern eine
Optimierung der Prozesse und Abl&#228;ufe zu erreichen. Gezielte unternehmensspezifische
Schulungsm&#246;glichkeiten im Bereich der Zulassungsverfahren k&#246;nnen insbesondere f&#252;r Start-ups und KMU, denen oft die
finanziellen Mittel zur Besch&#228;ftigung einer Expertin oder eines Experten fehlen, einen gro&#223;en Mehrwert
bedeuten. Optimierte und dadurch schnellere Zulassungswege stellen die Grundlage f&#252;r die
Wettbewerbsf&#228;higkeit deutscher Unternehmen dar. Ein erster Schritt w&#228;re in diesem Kontext die Schaffung einer
Kontaktstelle im BfArM, die Unterst&#252;tzung im Zulassungsverfahren bietet, sowie die Straffung der
Zulassungsverfahren und der Abbau von B&#252;rokratie. Des Weiteren sollten geeignete Normen f&#252;r die Zertifizierung von
KI-Anwendungen im Gesundheitssystem erarbeitet werden und es sollte gepr&#252;ft werden, ob KI-Systeme bei
einem Einsatz im Gesundheitsbereich grunds&#228;tzlich nur in begr&#252;ndeten Ausnahmef&#228;llen weiterlernen
sollten und Verbesserungen ansonsten &#252;ber Updates erfolgen m&#252;ssen. Dies kann beispielsweise durch die High
Level Expert Group on Artificial Intelligence im Rahmen der Erarbeitung einer Normungs-Roadmap
erfolgen. Au&#223;erdem m&#252;ssen Haftungsfragen bei Systemen gekl&#228;rt werden, deren Funktion prim&#228;r auf Software
basiert und die auch nach der Zertifizierung noch in einem Selbstlernprozess ihr Verhalten &#228;ndern,
4. zu pr&#252;fen, inwieweit geeignete Regeln notwendig sind, die eine hinreichende Absicherung von
Haftungsrisiken f&#252;r Hersteller von KI-basierten Systemen und Anwendungen gegen&#252;ber Patientinnen und Patienten
sicherstellen, beispielsweise durch eine verpflichtende Produkthaftpflicht- oder eine andere Form der
Deckungsvorsorge-Haftpflichtversicherung,
5. einen engen Austausch mit internationalen Partnern, wie beispielsweise den USA, den skandinavischen
L&#228;ndern oder Estland, zu pflegen, um das Inverkehrbringen von Produkten weltweit zu f&#246;rdern.
KI in der Pflege sowie f&#252;r Menschen mit Behinderung
4.4.1 Verortung, Potenziale und Risiken
Wie in alle Bereiche der Gesundheitsversorgung h&#228;lt KI auch Einzug in die Pflege. Dabei bleibt unbestritten, 
dass gerade in der Pflege der Mensch im Mittelpunkt steht und auch weiterhin stehen soll. Das bezieht sich
sowohl auf Patientinnen und Patienten als auch auf junge, alte oder behinderte Menschen mit Pflegebed&#252;rftigkeit
sowie Pflegekr&#228;fte. Mit Pflegenden sind im Folgenden professionelle Pflegekr&#228;fte wie auch pflegende
Angeh&#246;rige gemeint. 
Bei der Einf&#252;hrung von L&#246;sungen, die sich der Funktionalit&#228;ten von KI bedienen, soll vor allem im Mittelpunkt 
stehen, eine qualitativ hochwertige gesundheitliche und pflegerische Versorgung sowohl in der Stadt als auch auf
dem Land sicherzustellen.
1119 Handlungsempfehlungen von Dr. Alexander K&#246;nig (Reactive Robotics GmbH), Projektgruppendrucksache 19(27)PG 3-21 vom
13. Mai 2020.
Auch die Entlastung des Pflegepersonals ist ein Ziel von KI-Assistenzsystemen, das stets im Blick behalten
werden muss. Auch wenn KI den Pflegenotstand nicht beheben wird, so k&#246;nnen digitale wie auch cyberphysische
Werkzeuge und KI dazu beitragen, den Alltag von Pflegekr&#228;ften deutlich zu erleichtern und damit die
Arbeitsbedingungen zu verbessern. Weiterhin kann die Qualit&#228;t der pflegerischen Versorgung durch solche Werkzeuge
und L&#246;sungen verbessert werden, wenn durch ihren Einsatz mehr Zeit f&#252;r die zuwendungsintensiven T&#228;tigkeiten 
bleibt.
Die Potenziale f&#252;r Pflegekr&#228;fte ergeben sich vor allem durch den Einsatz technischer Hilfsmittel bei der
notwendigen Dokumentation (z. B. durch Spracherkennung und automatische Umsetzung in Text), durch intelligente
Assistenzsysteme (z. B. intelligente Pflegebetten, Unterst&#252;tzung bei k&#246;rperlichen T&#228;tigkeiten wie Heben,
Bewegen, Umbetten, Tragen, oder intelligente Prothesen) sowie durch den Einsatz interaktiver Werkzeuge wie
humanoider oder tier&#228;hnlicher Roboter, z. B. f&#252;r Servicet&#228;tigkeiten oder bei der Betreuung von psychisch
beeintr&#228;chtigten Patientinnen oder Patienten (zur Unterhaltung, Beruhigung etc.). Auch das medizinisch-angezeigte
&#220;berwachen von zu Pflegenden kann durch digitale Werkzeuge mit Funktionalit&#228;ten der KI unterst&#252;tzt werden, um
die wirklich kritischen und dringlichen F&#228;lle zu ermitteln.
KI-Anwendungen k&#246;nnen ebenso dabei helfen, dass Menschen bei Krankheit oder im Alter, bei Vorliegen einer
Behinderung oder bei Pflegebed&#252;rftigkeit ihr Leben selbstbestimmter gestalten und an der Gesellschaft teilhaben
k&#246;nnen. Verschiedene digitale Schnittstellen k&#246;nnen pflegebed&#252;rftigen Menschen (alten Menschen oder
Menschen mit Querschnittsl&#228;hmung) z. B. die M&#246;glichkeit geben, eigenst&#228;ndig zu agieren. Smarte Notruf- oder
Assistenzsysteme k&#246;nnen den Verbleib in den eigenen vier W&#228;nden verl&#228;ngern. Der Mensch sollte in diesem
Szenario, in dem die Hilfsmittel mittels KI gesteuert werden, stets der direkte Nutzer und Taktgeber sein.  
Die Gesundheitspolitik muss daf&#252;r sorgen, dass diese Potenziale f&#252;r die zu Pflegenden und die Pflegekr&#228;fte
erschlossen werden. Notwendig ist daf&#252;r eine &#252;bergeordnete Strategie zur Digitalisierung des Gesundheits- und
Pflegesystems, die der Leitidee folgt, KI zum Nutzen der Anwenderinnen und Anwender zu entwickeln und
einzusetzen.
Beachtet werden muss dabei jedoch, dass die in unserer Gesellschaft verankerten Werte, insbesondere die W&#252;rde
des Menschen &#8211; in diesem Fall des zu pflegenden Menschen &#8211;, und damit einhergehende rechtliche Fragen (z. B. 
zum Pers&#246;nlichkeits- und Datenschutz) sowie generelle ethische Fragen ber&#252;cksichtigt und gekl&#228;rt werden
m&#252;ssen. 
So darf es beispielsweise keine Freiheitseinschr&#228;nkungen durch eine technische &#220;berwachung geben. Bei den
eingesetzten Hilfsmitteln muss die Akzeptanz durch das Pflegepersonal, die Patientinnen und Patienten und ggf.
auch deren Angeh&#246;rige sichergestellt werden. Ebenso spielt es eine Rolle, dass Menschen verschieden sind: Ein
technisches oder sogar KI-Hilfsmittel, das eine Person guthei&#223;t, muss noch lange nicht von allen Patientinnen
und Patienten akzeptiert werden. Dabei &#252;ben auch kulturelle Aspekte einen Einfluss aus. Nicht umsonst ist die
Robotik beispielsweise in Japan, wo es eine h&#246;here Aufgeschlossenheit der Gesellschaft daf&#252;r gibt, weiter
fortgeschritten und verbreitet.1120 
Nicht zuletzt m&#252;ssen auch die Bed&#252;rfnisse von Pflegekr&#228;ften betrachtet werden: Eine Erleichterung der Arbeit,
z. B. durch Unterst&#252;tzung bei der Dokumentation, die gleichzeitig eine Steigerung der Effizienz mit sich bringt,
sollte dazu f&#252;hren, dass die eingesparte Zeit f&#252;r zwischenmenschliche Pfleget&#228;tigkeiten bzw. eine
Neuorganisation und -priorisierung der Pfleget&#228;tigkeiten verwendet wird. Ziel darf nicht sein, dadurch Personal einzusparen
&#8211; denn damit w&#252;rden nur finanzielle, aber nicht qualitative Aspekte der Pflege ber&#252;cksichtigt. Letztlich geht es
darum, KI zielgenau so zu entwickeln und einzusetzen, dass sie den Pflegeprozess sowohl f&#252;r die zu pflegende
Person als auch f&#252;r die Pflegenden qualitativ verbessert und erleichtert.
Die Entwicklung und Einf&#252;hrung neuer Hilfsmittel und Anwendungen muss deshalb stets schon vorab durch eine
Debatte bestimmt werden, aus der hervorgehen kann, was insbesondere aus Sicht der Anwenderinnen und
Anwender machbar und gewollt ist und welche Unterst&#252;tzung nicht gewollt und damit in Deutschland auch nicht
umsetzbar ist oder nur unter bestimmten Ma&#223;gaben eingesetzt werden darf.
Es braucht eine Nutzung der digitalen Technik, die auch die Pflegebed&#252;rftigen ernst nimmt und die als Hilfe im
Hinblick auf soziale Beziehungen zu verstehen ist. Dreht man die Bedenken der Menschen um, kann Technik 
erstens auch die Sicherheit geben, dass (Mindest-)Standards niemals unterschritten werden, dass zweitens
effizient arbeitende Pflegekr&#228;fte dadurch Zeit gewinnen f&#252;r Zwischenmenschliches und drittens transparent und
1120 Vgl. Kehl (2018): Robotik und assistive Neurotechnologien in der Pflege &#8211; gesellschaftliche Herausforderungen, S. 135.
nachvollziehbar gekl&#228;rt ist, welche Datenerhebung und welche Ma&#223;nahmen tats&#228;chlich notwendig sind. Dazu
muss der Einsatz digitaler Technik reflektiert und an Zielsetzungen gekoppelt werden.1121
Potenziale der KI und Robotik sind so zu verbinden, dass KI und Robotik die Menschen bei ihrer Aufgabe im
technischen Sinn unterst&#252;tzen und im sozialen Sinne nicht entlassen.1122 Dies betrifft nicht nur den Pflegebereich, 
sondern alle Lebensbereiche, denn die Projektgruppe geht davon aus, dass die Akzeptanz von intelligenten
Assistenzsystemen in der Pflege durch die Akzeptanz in anderen bzw. allen Lebensbereichen gef&#246;rdert wird.
4.4.2 Status quo von KI-Anwendungen in der Pflege
KI kommt in der Pflege bereits auf unterschiedliche Art zum Einsatz &#8211; h&#228;ufig kombiniert mit technisch-
sensorischen Elementen und KI-gesteuerten, autonomen oder teilautonomen Assistenzsystemen bzw. Robotik. Dabei
handelt es sich um einen &#228;u&#223;erst heterogenen Anwendungsbereich, der von einfachsten Assistenzt&#228;tigkeiten im
h&#228;uslichen Umfeld bis zu hoch spezialisierten personenbezogenen Leistungen im station&#228;ren Bereich reicht.
Nicht immer ist eine trennscharfe Abgrenzung zum Service- und Convenience-Bereich (etwa intelligente
Service-Assistenzsysteme f&#252;r Haushaltst&#228;tigkeiten) oder zu anderen medizinischen Einsatzbereichen (etwa OP-
Robotik oder Prothetik) m&#246;glich. 
Unterschieden werden kann dabei zwischen Zielpersonengruppe, Funktion und Komplexit&#228;t der KI-gest&#252;tzten
Anwendung. So kann zwischen Anwendungen unterschieden werden, die hilfsbed&#252;rftige Personen unterst&#252;tzen
(vor allem im h&#228;uslichen Bereich), und solchen, die professionell Pflegende entlasten (vor allem im station&#228;ren
Bereich). Funktional unterscheiden sich einfache Speziall&#246;sungen von multifunktionalen KI-gest&#252;tzten
Assistenzsystemen. Soziale intelligente Assistenzsysteme k&#246;nnen Interaktionspartner oder Interaktionsmedium
sein.1123 
Aufgrund der Entwicklungst&#228;tigkeiten im Bereich Pflegerobotik, die es seit vielen Jahren gibt, und aufgrund der
Intensivierung der Bem&#252;hungen in den letzten Jahren, verst&#228;rkt durch verbesserte M&#246;glichkeiten mithilfe von
KI, werden gro&#223;e Hoffnungen in intelligente Assistenzsysteme in der Pflege gesetzt und es wird ihnen ein gro&#223;es
Marktpotenzial zugeschrieben. Wichtig ist jedoch, festzustellen, dass KI im Pflegebereich noch in den
Kinderschuhen steckt und nur wenige Anwendungen bislang zur Marktreife gelangt sind. Zwar sind erste Anwendungen 
seit wenigen Jahren auf dem Markt; KI-gest&#252;tzte Technologien kommen in einem engen Rahmen bereits im
Pflegealltag zum Einsatz. Meist handelt es sich dabei jedoch um einfache Speziall&#246;sungen; komplexere
Assistenzsysteme befinden sich dagegen noch in der Entwicklung bzw. Testphase. Oft scheitert der Einsatz von KI
noch an der Realit&#228;t und Praktikabilit&#228;t.1124 
Wie in vielen anderen Bereichen ist zu erwarten, dass sich KI &#252;ber die Frage von Lifestyle und Convenience
bzw. Usability durchsetzt.1125 Das hei&#223;t, wenn ein sich selbst ein- und ausschaltender Herd zuverl&#228;ssig
funktioniert und f&#252;r die Nutzerin oder den Nutzer einen konkreten Mehrwert bringt, wird sich diese Technologie
verbreiten. Im Umkehrschluss bedeutet dies, dass sich KI-gest&#252;tzte Technologien nur etablieren k&#246;nnen, wenn sie
sich in der Praxis als sinnvoller erweisen als die konventionelle Methode. Wenn beispielsweise ein Exoskelett
zwar den eigentlichen Umbettungsvorgang einer Pflegepatientin oder eines -patienten erheblich erleichtert, es
aber sehr lange dauert, um dieses in Betrieb zu nehmen bzw. anzulegen, wird es sich nur schwer durchsetzen.
Gerade in besonders sch&#252;tzenswerten Bereichen wie der Pflege, die die Privat- und Intimsph&#228;re von verletzlichen 
Personen betrifft, ist es wichtig, die Bed&#252;rfnisse der Betroffenen zu respektieren und der &#8211; zumindest momentan 
noch &#8211; vorherrschenden Skepsis behutsam zu begegnen. Solange Generationen in den Krankenh&#228;usern und
Pflegeeinrichtungen gepflegt werden, die in ihrem bisherigen Leben kaum Erfahrungen mit der Digitalisierung
gemacht haben, braucht dieser Aspekt besondere Aufmerksamkeit. 1126
1121 Vgl. Bundesinteressenvertretung f&#252;r alte und pflegebetroffene Menschen e. V. (BIVA-Pflegeschutzbund) (2018): Digitalisierung in
der Altenhilfe.
1122 Darstellung Prof. Dr. Arne Manzeschke (Evangelische Hochschule N&#252;rnberg) in der Sitzung der Projektgruppe KI und Gesundheit
am 13. Mai 2019.
1123 Vgl. Kehl (2018): Robotik und assistive Neurotechnologien in der Pflege &#8211; gesellschaftliche Herausforderungen, S. 12 ff.
1124 Vgl. Kehl (2018): Robotik und assistive Neurotechnologien in der Pflege &#8211; gesellschaftliche Herausforderungen, S. 12 ff.
1125 Darstellung Prof. Dr. David Matusiewizc (Institut f&#252;r Gesundheit &amp; Soziales der FOM Hochschule f&#252;r &#214;konomie und Management)
in der Sitzung der Projektgruppe KI und Gesundheit am 13. Mai 2019; Lobo (2016): Leben im Datenstrom.
1126 Die Bertelsmann-Stiftung kommt in einer repr&#228;sentativen Umfrage zu dem Schluss, dass in der deutschen Bev&#246;lkerung generell ein 
&#8222;[&#8230;] weitverbreitetes Unwissen &#252;ber Algorithmen, eine gro&#223;e Unentschlossenheit &#252;ber die Chancen und Risiken und ein erhebliches 
Unbehagen gegen&#252;ber Urteilen und Entscheidungen [herrscht], die von Algorithmen getroffen werden, sowie damit verbunden ein
Erste Begegnungen zwischen Pflegebed&#252;rftigen und intelligenten Pflegeassistenzsystemen lassen jedoch darauf
schlie&#223;en, dass eine gro&#223;e Offenheit und Neugier der technischen Innovation gegen&#252;ber besteht &#8211; je nachdem,
wie n&#252;tzlich diese f&#252;r die pers&#246;nliche Situation empfunden wird.1127 
Pflegekr&#228;fte werden KI-Anwendungen nur dann akzeptieren, wenn sie ihren Nutzen konkret erkennen und eine
Entlastung anstatt Verdichtung ihrer Arbeit wahrnehmen. Daf&#252;r ist es entscheidend, dass sie den Anforderungen
entsprechend geschult sind und bei der Einf&#252;hrung und Anwendung der neuen Produkte technisch unterst&#252;tzt
werden. Durch Studien l&#228;sst sich belegen, dass das medizinische Personal durch den Einsatz digitaler Werkzeuge
&#252;berwiegend eine Erleichterung im Arbeitsprozess wahrnimmt (&#252;ber 90 Prozent der Befragten). Die
Zustimmungswerte hinsichtlich Effizienz- und Qualit&#228;tssteigerung in der Pflege sind geringer, liegen aber ebenfalls bei
75 Prozent oder h&#246;her.1128 
Auch lassen Beobachtungen in den USA darauf schlie&#223;en, dass sich die Einstellung von zun&#228;chst skeptischen
Pflegekr&#228;ften nach einer Zeit des Umgangs mit intelligenten Pflegeassistenzsystemen positiv ver&#228;ndert.1129 
4.4.3 Rahmenbedingungen f&#252;r einen erfolgreichen Einsatz von KI in der Pflege
Ausgehend von der Pr&#228;misse, dass Pflegebed&#252;rftige ein Recht auf menschliche Zuwendung haben, sofern sie
diese w&#252;nschen, muss der Einsatz von KI-Anwendungen in der Pflege darauf abzielen, Pflegekr&#228;ften soweit
m&#246;glich Freir&#228;ume f&#252;r pflegerische Kernt&#228;tigkeiten und menschliche Zuwendung zu schaffen. Vor diesem
Hintergrund sollen KI-Anwendungen in der Pflege insbesondere f&#252;r einfache und routinem&#228;&#223;ige T&#228;tigkeiten
eingesetzt werden, die oft nicht besonders pflegenah sind.
Um unterscheiden zu k&#246;nnen, in welchen Bereichen der Einsatz von KI w&#252;nschenswert und zielf&#252;hrend ist, sind
Kernt&#228;tigkeiten der Pflege zu identifizieren, insbesondere diejenigen, die typisch menschliche F&#228;higkeiten wie
Empathie und sehr gute Kommunikationsf&#228;higkeiten mit der Patientin oder dem Patienten, aber auch besondere
fachliche Expertise erfordern. Dabei sollte unterschieden werden zwischen ambulanter und station&#228;rer (Alten-)Pflege
etc. KI-Unterst&#252;tzungen bei einfachen, routinem&#228;&#223;igen oder &#8222;pflegefernen&#8220; T&#228;tigkeiten sollten akzeptierte
Hilfsmittel werden. Dies gilt beispielsweise f&#252;r Dokumentation und Monitoring, Unterst&#252;tzung bei Servicet&#228;tigkeiten
oder eine Alarmierung in Notsituationen, aber auch bei der Bewertung der Dringlichkeit von Situationen. 
Aus pflegewissenschaftlicher Sicht ist der Einsatz von KI in der Pflege fernab dieser grunds&#228;tzlichen
Einsch&#228;tzungen in dem konkreten Anwendungsfall danach abzuw&#228;gen, ob er geeignet ist, die Qualit&#228;t des Pflegeprozesses
zu verbessern. Auch vermeintliche Routinet&#228;tigkeiten wie Umlagern, Heben oder der n&#228;chtliche Rundgang
k&#246;nnen im Hinblick auf notwendige Begegnungs- und Kontaktm&#246;glichkeiten f&#252;r eine gute Pflege ausschlaggebend
sein und sollten deswegen nicht pauschal automatisiert werden.1130 
Damit eventuelle Effizienzsteigerungen durch den Einsatz von KI in der Pflege nicht zu Einsparungen von
Pflegepersonal zulasten der Betroffenen f&#252;hren, m&#252;ssen die verantwortlichen Institutionen der Selbstverwaltung in
Aushandlungsprozessen beachten, inwiefern sich Produktivit&#228;tsgewinne durch digitale Innovationen und KI in 
der Pflege abzeichnen. Das Spannungsverh&#228;ltnis zwischen Effizienzsteigerung und Zeitgewinn f&#252;r menschliche
Zuwendung m&#252;sste bei Vorgaben zur Personalausstattung ber&#252;cksichtigt werden. Relevant sind in diesem
Zusammenhang beispielsweise &#8211; zumindest in Bezug auf station&#228;re Leistungen &#8211; die Regelungen der
l&#228;nderspezifischen Heimgesetze, welche Vorschriften zum Schutz der Grundrechte betreuungs- und pflegebed&#252;rftiger
Personen sowie zu personellen Mindeststandards enthalten.1131 
Der Einsatz von neuer Technik und KI kann au&#223;erdem den Arbeitsalltag und damit die Anforderungen, die
Abl&#228;ufe, die Kompetenzen und das Selbstverst&#228;ndnis des Berufsbildes der Pflege beeinflussen. Erforderlich sind
weitergehende empirische Untersuchungen zu den Auswirkungen der Digitalisierung und von KI auf den
Pflegeprozess, um Beurteilungsgrundlagen und Ziele f&#252;r die weitere Entwicklung herauszuarbeiten.1132 
starker Wunsch nach mehr Kontrolle.&#8220;, Fischer und Petersen (2018): Was Deutschland &#252;ber Algorithmen wei&#223; und denkt &#8211;
Ergebnisse einer repr&#228;sentativen Bev&#246;lkerungsumfrage, S. 6. Dabei ist die Abneigung gegen&#252;ber Algorithmen umso gr&#246;&#223;er, je
folgenreicher die Entscheidung ist, vgl. Fr&#252;h und Gasser (2018): Erfahrungen aus dem Einsatz von Pflegerobotern f&#252;r Menschen im Alter.
1127 Fr&#252;h und Gasser (2018): Erfahrungen aus dem Einsatz von Pflegerobotern f&#252;r Menschen im Alter.
1128 Vgl. Br&#228;utigam et al. (2017): Digitalisierung im Krankenhaus, z. B. Abbildung 12: Positive Auswirkungen digitaler Technik.
1129 Vgl. Schwab (2019): A hospital introduced a robot to help nurses. They didn&#8217;t expect it to be so popular.
1130 Vgl. Kehl (2018): Robotik und assistive Neurotechnologien in der Pflege &#8211; gesellschaftliche Herausforderungen, S. 82 ff.
1131 Vgl. Kehl (2018): Robotik und assistive Neurotechnologien in der Pflege &#8211; gesellschaftliche Herausforderungen, S. 98.
1132 Vgl. Kehl (2018): Robotik und assistive Neurotechnologien in der Pflege &#8211; gesellschaftliche Herausforderungen, S. 99.
KI-Anwendungen in der Pflege betreffen h&#228;ufig die Grund- und Menschenrechte besonders verletzlicher
Menschen. Ihre Erprobung und Einf&#252;hrung sollte deshalb schon im Entwicklungsprozess durch eine
Ethikkommission begleitet werden, die nach einem Bewertungs-Schema entscheidet, ob und unter welchen Bedingungen
(beispielsweise bestehender Zugang zu menschlicher Zuwendung, Datenschutz etc.) entsprechende Anwendungen
in Deutschland eingef&#252;hrt werden d&#252;rfen. 
Zentrale Bewertungsdimensionen sind aus ethischer Sicht die Kategorien Autonomie und Wohlergehen eines
Menschen, in diesem Fall des pflegebed&#252;rftigen Menschen.1133 Erste Modelle zur systematischen ethischen
Bewertung von neuen Anwendungen liegen bereits vor, wie z. B. das Modell MEESTAR.1134 Sie sollten nicht nur,
wie gefordert, bereits vor oder w&#228;hrend der Entwicklung von neuen Produkten eingesetzt, sondern bei Bedarf
auch weiterentwickelt werden.
F&#252;r die Frage, welche KI-Systeme in Zukunft im Bereich der Pflege entstehen werden, sind auch die
Pflegeforschung und deren F&#246;rderung entscheidend. Im Unterschied zur Forschung in anderen Medizinbereichen zeichnet
sie sich einerseits durch einen starken Praxisbezug, andererseits durch einen sehr interdisziplin&#228;ren Charakter
aus. Daher braucht es in der Pflegeforschung ganz besonders einen co-kreativen Prozess, d. h. die
Zusammenarbeit der Disziplinen zur Entwicklung und praktischen Anwendungserprobung (Pflegewissenschaft, Informatik,
Pflegepraxis, Ethik bzw. Recht) unter Einbeziehung von potenziellen Anwenderinnen und Anwendern wie
Seniorinnen und Senioren, Menschen mit Behinderung und/oder Pflegebed&#252;rftigen und deren Angeh&#246;rigen und
Interessenvertretungen. Nur so kann gew&#228;hrleistet werden, dass bei der Einf&#252;hrung von digitalen und KI-L&#246;sungen
im Gesundheitswesen nicht der Anschluss an die Realit&#228;t im Anwendungs- und Versorgungsalltag verloren geht.
Das w&#252;rde verhindern, dass interessante technische L&#246;sungen an praktischen Umsetzungsproblemen scheitern.
Die Bundesregierung sollte diesen co-kreativen Prozess mit F&#246;rdergeldern unterst&#252;tzen. 
F&#252;r diesen gemeinsamen Entwicklungsprozess ist in einem stark praxisbezogenen Feld wie der Pflege mehr
Raum zur Erprobung notwendig. Es m&#252;ssen daher vermehrt gesch&#252;tzte, interdisziplin&#228;re Experimentierr&#228;ume
geschaffen werden, um etwa an der Schnittstelle zwischen Wissenschaft, Robotik, Pflegefachkr&#228;ften sowie
Anwenderinnen und Anwendern neue technische L&#246;sungen praktisch erproben zu k&#246;nnen. Pilotprojekte wie die
Modellkommune in Garmisch-Partenkirchen (siehe Kapitel 3.2 dieses Projektgruppenberichts [KI-
Anwendungen in der Pflege]) sind hier wegweisend und sollten deutschlandweit an verschiedenen Standorten eingerichtet
werden. Spezielle F&#246;rderprogramme sollten f&#252;r solche Pilot-Projekte geschaffen werden, um den teilnehmenden
Pflegeeinrichtungen zu erm&#246;glichen, in dem unter Druck stehenden Pflegesystem neue Wege ausprobieren zu
k&#246;nnen. Durch ein gut durchdachtes und langj&#228;hrig geplantes Zusammenspiel verschiedener Fachleute in
Zusammenarbeit mit einer Ethikkommission k&#246;nnen so auch in kritischen Forschungsfeldern Forschungszentren
mit entsprechender Expertise aufgebaut werden (z. B. eine Neurointerface-Gruppe f&#252;r Menschen mit
Querschnittsl&#228;hmung oder f&#252;r Menschen mit Prothesen). Durch die gezielte Einbettung von Experimentier- und
Forschungsr&#228;umen in die Gesellschaftsstruktur k&#246;nnen langfristige Forschungs- und Entwicklungsm&#246;glichkeiten 
geschaffen werden, sodass Technologien in ihrer N&#252;tzlichkeit und ihrem Reifegrad so nachhaltig entwickelt
werden, dass der Nutzen maximiert wird.
Auf dem Gebiet der KI-gest&#252;tzten Robotik sollten insbesondere universell einsatzf&#228;hige Ger&#228;te, wie etwa
intelligente Pflegebetten, gef&#246;rdert werden, damit m&#246;glichst viele Pflegebed&#252;rftige von den Ergebnissen profitieren.
Insgesamt scheint eine st&#228;rkere strategische Ausrichtung der F&#246;rderaktivit&#228;ten im Bereich Robotik in der Pflege
auch im Sinne der Bedarfsorientierung angezeigt. Die F&#246;rderung von Projekten sollte dabei so ausgestaltet sein, 
dass sie es erm&#246;glicht, Anwendergruppen und deren R&#252;ckmeldung einzubeziehen, was mehr Zeit in Anspruch
nehmen kann.1135 
Nicht zuletzt sollen digitale und KI-L&#246;sungen allen B&#252;rgerinnen und B&#252;rgern zur Verf&#252;gung stehen und d&#252;rfen
keine Frage des Einkommens sein. Das gilt besonders f&#252;r den Gesundheits- und den Pflegebereich. L&#246;sungen,
die einen erkennbaren Nutzen haben, sollen &#252;ber die GKV bzw. die Pflegekassen verf&#252;gbar sein. Daf&#252;r m&#252;ssen 
u. a. die Kriterien f&#252;r die Aufnahme in das Verzeichnis der Pflegehilfsmittel so gestaltet sein, dass sie auch die
Eigenschaften und den zus&#228;tzlichen Nutzen von digitalen und KI-gest&#252;tzten L&#246;sungen erfassen, beispielsweise 
eine Erh&#246;hung der Selbstst&#228;ndigkeit.1136 
1133 Vgl. Kehl (2018): Robotik und assistive Neurotechnologien in der Pflege &#8211; gesellschaftliche Herausforderungen, S. 89 ff.
1134 MEESTAR ist ein Modell zur ethischen Evaluation sozio-technischer Arrangements; Darstellung Prof. Dr. Arne Manzeschke
(Evangelische Hochschule N&#252;rnberg) in der Sitzung der Projektgruppe KI und Gesundheit am 13. Mai 2019 (vgl.
Projektgruppendrucksache 19(27)PG 3-14 vom 13. Mai 2009).
1135 Vgl. Kehl (2018): Robotik und assistive Neurotechnologien in der Pflege &#8211; gesellschaftliche Herausforderungen, S. 169 und 177.
1136 Vgl. Kehl (2018): Robotik und assistive Neurotechnologien in der Pflege &#8211; gesellschaftliche Herausforderungen, S. 48 f.
4.4.4 Handlungsempfehlungen
Die allgemeinen Handlungsempfehlungen f&#252;r den Bereich KI und Gesundheit, insbesondere zur Zulassung,
Qualit&#228;tssicherung, Haftung, Finanzierung, zu rechtlichen Rahmenbedingungen und zum Datenschutz sowie zur
Qualifizierung und zur Weiterentwicklung von Gesundheitsberufen, sind explizit auch f&#252;r den Pflegebereich
g&#252;ltig. Sie wurden zur besseren Lesbarkeit in diesem Kapitel nicht erneut aufgef&#252;hrt. Nachfolgend finden sich nur
Handlungsempfehlungen, die sich aufbauend auf den in diesem Kapitel dargestellten Rahmenbedingungen
speziell auf den Pflegebereich beziehen.
Allgemeing&#252;ltig ist dabei der Grundsatz, dass der Einsatz von KI in der Pflege danach abzuw&#228;gen ist, ob er die
Qualit&#228;t des Pflegeprozesses f&#252;r die Beteiligten verbessert. Zudem empfiehlt die Projektgruppe folgende Schritte,
um KI-Systeme erfolgreich im Bereich der Pflege zu entwickeln und in der Praxis einzusetzen:
1. Das Ziel, Effizienzsteigerungen durch KI f&#252;r eine bessere Pflege zu nutzen, kann nur dadurch verwirklicht
werden, dass die Auswirkungen des Einsatzes von Technik beobachtet und das Spannungsfeld bei der
k&#252;nftigen Entwicklung von Personalvorgaben ber&#252;cksichtigt wird.
2. Die Auswirkungen von KI auf den Pflegeprozess, auf den Arbeitsalltag, die Abl&#228;ufe, die Anforderungen
und das Selbstverst&#228;ndnis in der professionellen Pflege m&#252;ssen weitergehend empirisch erforscht werden. 
3. Zur Entwicklung von KI-Anwendungen f&#252;r die Pflege ist ein co-kreativer Prozess aus verschiedenen
Disziplinen, wie z. B. der IT und der Pflegewissenschaft, n&#246;tig, der beispielsweise in gesch&#252;tzten,
interdisziplin&#228;ren Experimentierr&#228;umen stattfinden kann und potentielle Anwenderinnen und Anwender von
vornherein mit einbeziehen sollte. Vorgeschlagen wird eine st&#228;rkere strategische Ausrichtung der
F&#246;rderaktivit&#228;ten im Bereich Robotik in der Pflege &#8211; auch im Sinne der Orientierung am Bedarf.
4. Bereits die Entwicklung von KI-Anwendungen in der Pflege bedarf einer eingehenden ethischen
Betrachtung, die insbesondere die G&#252;ter Autonomie und Wohlergehen der pflegebed&#252;rftigen Person abw&#228;gt. Erste
Modelle, wie z. B. MEESTAR, liegen dazu vor und sollten angewendet und bei Bedarf weiterentwickelt
werden.
5. Deutschland braucht einen Arbeitnehmerdatenschutz auf der H&#246;he der Zeit, um auch angesichts der
Digitalisierung und einer potenziellen Anwendung von KI in der Pflege einen effektiven Datenschutz f&#252;r
Arbeitnehmerinnen und Arbeitnehmer gew&#228;hrleisten zu k&#246;nnen.
6. In Bezug auf die Finanzierung von KI in der Pflege m&#252;ssen u. a. die Kriterien f&#252;r die Aufnahme in das
Verzeichnis der Pflegehilfsmittel so gefasst werden, dass sie die Eigenschaften und den zus&#228;tzlichen Nutzen
von digitalen und KI-gest&#252;tzten L&#246;sungen erfassen, beispielsweise eine Erh&#246;hung der Selbstst&#228;ndigkeit.
5 Hintergrundinformationen zur Projektgruppe KI und Gesundheit
Die Projektgruppe KI und Gesundheit ist von der Enquete-Kommission K&#252;nstliche Intelligenz im Februar 2019
eingesetzt worden und hat bis September 2019 gearbeitet. In diesem Abschnitt finden sich n&#228;here Informationen 
zu ihrer Zusammensetzung, ihrer Arbeitsweise und den erfolgten Anh&#246;rungen.
Expertise durch handelnde Akteure
An der Projektgruppe und ihrem Bericht wirkten mit
f&#252;r die Fraktion der CDU/CSU:
&#8226; Susanne Dehmel als sachverst&#228;ndiges Mitglied
&#8226; Prof. Dr. Antonio Kr&#252;ger als sachverst&#228;ndiges Mitglied
&#8226; die Abgeordnete Prof. Dr. Claudia Schmidtke
&#8226; der Abgeordnete Tino Sorge
&#8226; der Abgeordnete Andreas Steier
f&#252;r die Fraktion der SPD:
&#8226; Prof. Dr.-Ing. Sami Haddadin als sachverst&#228;ndiges Mitglied
&#8226; die Abgeordnete Daniela Kolbe
&#8226; der Abgeordnete Ren&#233; R&#246;spel
&#8226; der Abgeordnete Dr. Jens Zimmermann als stellvertretendes Mitglied
f&#252;r die Fraktion der AfD:
&#8226; der Abgeordnete Dr. G&#246;tz Fr&#246;mming
&#8226; Prof. Dr. Boris Hollas als sachverst&#228;ndiges Mitglied
f&#252;r die Fraktion der FDP:
&#8226; Andrea Martin als sachverst&#228;ndiges Mitglied
&#8226; die Abgeordnete Daniela Kluckert als stellvertretendes Mitglied
f&#252;r die Fraktion DIE LINKE.:
&#8226; die Abgeordnete Dr. Petra Sitte
&#8226; der Abgeordnete Dr. Achim Kessler als stellvertretendes Mitglied
f&#252;r die Fraktion B&#220;NDNIS 90/DIE GR&#220;NEN:
&#8226; die Abgeordnete Dr. Anna Christmann als Vorsitzende der Projektgruppe
&#8226; Prof. Dr. Hannah Bast als sachverst&#228;ndiges und stellvertretendes Mitglied
Arbeitsstruktur der Gruppe
Sieben parlamentarische und sechs sachverst&#228;ndige Mitglieder der Enquete-Kommission K&#252;nstliche Intelligenz
organisierten sich themengeleitet in der Projektgruppe KI und Gesundheit und sammelten und werteten unter
dem Vorsitz der Abgeordneten Dr. Anna Christmann (B&#220;NDNIS 90/DIE GR&#220;NEN) in ausf&#252;hrlichen
regelm&#228;&#223;igen Arbeitstreffen Informationen aus. Am Ende ihrer Arbeit verfassten sie einen gemeinsamen Bericht. 
Um die thematische Breite des Untersuchungsbereichs KI und Gesundheit zu strukturieren, ermittelte die
Projektgruppe zun&#228;chst sechs Themenfelder, in denen KI bereits erfolgreich eingesetzt wird oder einen besonderen
Nutzen erwarten l&#228;sst oder in denen sich ein spezifischer rechtlicher Regelungsbedarf abzeichnet.
Diese Themenfelder wurden in inhaltlich vorbereiteten monatlichen Sitzungen im Zeitraum M&#228;rz 2019 bis
einschlie&#223;lich Juni 2019 eingehend diskutiert. Mithilfe weiterer gemeinsam ausgew&#228;hlter hochrangiger externer
Sachverst&#228;ndiger, die in Vortr&#228;gen ihre spezifische Expertise in den Diskussionsprozess einflie&#223;en lie&#223;en, wurde
dieser Arbeitsprozess immer weiter vertieft. Den Vortr&#228;gen lag jeweils ein in der Arbeitsgruppe abgestimmter
Fragenkatalog zugrunde, in dem Potenziale der Themenfelder skizziert und mit m&#246;glichen Zielen verkn&#252;pft
wurden, was den Vortr&#228;gen als Orientierung diente. Zudem wurden die geladenen G&#228;ste gebeten,
Handlungsvorschl&#228;ge zu unterbreiten, die ihnen ganz besonders dringlich erschienen. Diese Handlungsvorschl&#228;ge flossen
unmittelbar in den Urteilsfindungsprozess der Projektgruppe f&#252;r die Handlungsvorschl&#228;ge an das Parlament ein. 
Es haben folgende Sitzungen mit den genannten Sachverst&#228;ndigen stattgefunden:
1. Stand der Aktivit&#228;ten der Bundesregierung 
&#8226; Vertreterinnen und Vertreter der Bundesregierung zur Unterrichtung &#252;ber den Stand der Planungen und
Initiativen, die den Themenbereich KI und Gesundheit (Pflege, Sport) betreffen
2. Medizinische Forschung
&#8226; Prof. Dr. Peter Dabrock, Vorsitzender des Deutschen Ethikrats; Friedrich-Alexander-Universit&#228;t Erlangen-
N&#252;rnberg
&#8226; Prof. Dr. Martin Hrab&#283; de Angelis, Helmholtz Zentrum M&#252;nchen &#8211; Deutsches Forschungszentrum f&#252;r
Gesundheit und Umwelt; Europ&#228;isches Forschungskonsortium INFRAFRONTIER
&#8226; Prof. Dr. Philipp Berens, Universit&#228;tsklinikum T&#252;bingen
&#8226; Prof. Dr. Sylvia Thun, Berliner Institut f&#252;r Gesundheitsforschung / Berlin Institute of Health (BIH)
&#8226; Prof. Dr. Okan Ekinci, Diagnostics Information Solutions F. Hoffmann-La Roche Ltd.; University College
Dublin
3. Datenverf&#252;gbarkeit und Datenschutz von Gesundheitsdaten
&#8226; Prof. Dr. Christiane Woopen, Datenethikkommission der Bundesregierung; Universit&#228;t zu K&#246;ln
&#8226; Dr. Thilo Weichert, &#8222;Netzwerk Datenschutzexpertise&#8220;; Deutsche Vereinigung f&#252;r Datenschutz e. V. (DVD)
        
 
 
    
    
  
   
   
     
   
     
   
     
   
  
       
 
     
   
   
     
 
       
 
  
    
   
  
   
 
     
   
 
 
   
  
    
  
     
  
         
   
  
  
  
1
&#8226; Prof. Dr. Peter Haas, Fachhochschule Dortmund
&#8226; Sebastian Claudius Semler, Technologie- und Methodenplattform f&#252;r die vernetzte medizinische Forschung
e. V. (TMF)
&#8226; Dr. Philipp Storz-Pfennig, GKV-Spitzenverband
4. Zulassung, Haftung und Qualit&#228;tssicherung in der Gesundheitsversorgung
&#8226; Prof. Dr. Dr. Eric Hilgendorf, Julius-Maximilians-Universit&#228;t W&#252;rzburg
&#8226; Dr. Alexander K&#246;nig, Reactive Robotics GmbH
&#8226; Prof. Dr. Siegfried Jedamzik, Bayerische TelemedAllianz
&#8226; Dipl.-Ing. Oliver Christ, NSF International
&#8226; Dr. Sebastian Hallensleben, Verband der Elektrotechnik, Elektronik, Informationstechnik e. V. (VDE)
5. Gesundheits- und Krankenpflege
&#8226; Bernd Falk, Malteser Hilfsdienst
&#8226; Prof. Dr. Arne Manzeschke, Evangelische Hochschule N&#252;rnberg; Fachstelle f&#252;r Ethik und Anthropologie
im Gesundheitswesen
&#8226; Prof. Dr. David Matusiewicz, Fachhochschule f&#252;r &#214;konomie und Management (FOM) Berlin
&#8226; Sebastian Hofstetter, Medizinische Fakult&#228;t der Martin-Luther-Universit&#228;t/Halle
Auftrag gem&#228;&#223; Einsetzungsbeschluss
KI &#8211; zutreffender wird von Maschinellem Lernen gesprochen &#8211; wird als eine der zentralen Zukunftstechnologien
und einer der gr&#246;&#223;ten Treiber der Digitalisierung angesehen. KI-gest&#252;tzte Maschinen k&#246;nnen im Gegensatz zum
Menschen aus gro&#223;en Datenstr&#246;men in Echtzeit lernen und versetzen die Menschen in die Lage, die Flut an Daten
und Informationen produktiv zu nutzen. Dabei entscheiden Menge und Qualit&#228;t der Daten &#252;ber die M&#246;glichkeiten
der Maschinellen Lern- und KI-Verfahren und -Anwendungen.
Vor diesem Hintergrund beschreibt der Einsetzungsbeschluss des Deutschen Bundestages f&#252;r die Enquete-
Kommission &#8222;K&#252;nstliche Intelligenz &#8211; Gesellschaftliche Verantwortung und wirtschaftliche, soziale und &#246;kologische
Potenziale&#8220; den Arbeitsauftrag der Enquete: Sie soll Chancen und Potenziale der KI sowie die damit verbundenen
Herausforderungen untersuchen sowie Antworten auf die Vielzahl an Fragen &#8211; etwa technische, rechtliche,
politische und ethische &#8211; erarbeiten, um am Ende Handlungsempfehlungen zu formulieren. 
Im Einsetzungsbeschluss wird insbesondere der Gesundheitsbereich als Anwendungsschwerpunkt von KI
angesprochen, in dem immer mehr Entscheidungen bereits auf Algorithmen beruhen, welche die Vielzahl der
gesammelten Daten auf g&#228;nzlich neue Weise auszuwerten verm&#246;gen. In der Zukunft wird KI &#196;rztinnen und &#196;rzte bei
Diagnose und Therapie ma&#223;geblich unterst&#252;tzen und einen tiefgreifenden Einfluss auf unsere medizinische
Versorgung und den gesamten Pflegebereich haben k&#246;nnen.
V. K&#252;nstliche Intelligenz und Arbeit (Projektgruppe 4)
Kurzfassung des Projektgruppenberichts
K&#252;nstliche Intelligenz (KI) gibt dem ohnehin stetigen Wandel der Arbeitswelt bzw. dem gesellschaftlichen Bild 
von Arbeit eine neue Qualit&#228;t. War zuletzt die Digitalisierung in vielen Arbeits- und Organisationsbereichen
ma&#223;geblich f&#252;r die Ver&#228;nderungen im Arbeitsalltag vieler Menschen, beschleunigt KI diesen Prozess weiter. Als
Technologie stellt KI ohnehin einen Paradigmenwechsel dar: Sie wird nicht nur die Arbeitswelt, sondern den
Alltag der Menschen insgesamt ver&#228;ndern. Zu Recht haben die Menschen daher Fragen: Wie wirkt sich KI auf
den Arbeitsmarkt insgesamt und insbesondere auf den pers&#246;nlichen Arbeitsplatz aus? Wie ver&#228;ndert die
Technologie das Personalwesen? Welche Ver&#228;nderungen sind in der betrieblichen Mitbestimmung zu erwarten? Sind
meine beruflichen Qualifikationen ausreichend und wie kann ich mich weiterbilden? Welche Rolle spielt KI
&#252;berhaupt in der Bildung? Was bedeutet der technologische Wandel f&#252;r Lehrerinnen und Lehrer, Schulen und
Hochschulen?
Die Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220; hat sich vom Oktober 2019 bis Juni 2020 intensiv mit
diesen und anderen Fragen besch&#228;ftigt. Dabei sind die bisherigen Wirkungen der Digitalisierung bereits 2013
durch die Enquete-Kommission &#8222;Internet und digitale Gesellschaft&#8220; beschrieben worden.1137 Gleichwohl bleiben
praxisbew&#228;hrte Gestaltungskonzepte der Digitalisierung bedeutsam f&#252;r die Suche nach Gestaltungsans&#228;tzen f&#252;r
KI-Systeme. Die Projektgruppe hat konkrete Handlungsempfehlungen erarbeitet, aber auch eine mit Zielen
versehene Vision formuliert (Kapitel 3.3 dieses Projektgruppenberichts [Deutschland 2030: Vision einer
&#8222;freundlichen KI&#8220;]), in der Arbeit, Bildung und Forschung im Jahr 2030 beschrieben werden.
KI in der Arbeitswelt
F&#252;r die Arbeitswelt &#8211; aber auch f&#252;r die Bereiche Bildung und Forschung &#8211; sind spezifische Gestaltungsans&#228;tze
n&#246;tig, schlie&#223;lich verf&#252;gen KI-Systeme auch &#252;ber spezifische Merkmale. Zu den besonderen Herausforderungen
z&#228;hlen dabei die immanente Komplexit&#228;t und die teilweise Intransparenz lernender Maschinen und die
M&#246;glichkeit, dass durch sie menschliche Arbeit ersetzt und entwertet werden k&#246;nnte. Gleichzeitig bergen lernende
Maschinen auch gro&#223;e Potenziale f&#252;r die Arbeit: Sie k&#246;nnen sich selbst optimieren und sehr gro&#223;e Datenmengen
schnell analysieren. Dies kann genutzt werden, um Prozesse zu verbessern, Arbeit zu erleichtern und flexibler zu
gestalten. F&#252;r den Gesetzgeber ist es nicht m&#246;glich und nicht sinnvoll, universell und vorausschauend allen mit
KI zusammenh&#228;ngenden Gestaltungsanforderungen gerecht zu werden. Dazu ist die Dynamik und sind die
unterschiedlichen Verwendungszwecke von KI zu schnell und zu vielf&#228;ltig. Er muss sich auf wesentliche
Rahmenbedingungen und die Bef&#228;higung der Normsetzungsakteure zu Gestaltungsinitiativen konzentrieren.
KI wird in verschiedenen Unternehmen bereits vielf&#228;ltig eingesetzt bzw. es werden Pilotprojekte durchgef&#252;hrt
(siehe Kapitel 3.2 dieses Projektgruppenberichts [Einf&#252;hrende Beispiele bzw. Anwendungsf&#228;lle (Use Cases)]).
Allerdings ist insgesamt die Zahl der Betriebe, die KI-Technologien einsetzen, noch relativ gering. So haben
2020 in Deutschland nur 6 Prozent der Unternehmen KI genutzt oder implementiert. 22 Prozent haben
angegeben, KI-Eins&#228;tze zu testen oder zumindest solche zu planen.1138 Eine empirisch gesicherte Bestandsaufnahme zu
den Auswirkungen von KI auf die Arbeitswelt steht insofern noch aus. 
KI er&#246;ffnet Chancen und erweitert M&#246;glichkeiten f&#252;r Arbeitnehmerinnen und Arbeitnehmer, l&#246;st aber gerade bei
ihnen auch &#196;ngste und Sorgen aus. Bei der Beurteilung der Auswirkungen des Einsatzes von KI-Systemen in 
der Arbeitswelt ist einerseits davon auszugehen, dass gef&#228;hrliche, k&#246;rperlich schwere und immer wiederkehrende
Arbeiten reduziert werden und KI-Systeme bei der L&#246;sung komplexer Aufgaben eine unterst&#252;tzende Funktion
erf&#252;llen k&#246;nnen. &#220;berdies kann das F&#228;higkeitsspektrum von Menschen durch KI-L&#246;sungen erg&#228;nzt werden.
Andererseits wird mit Blick auf den Einsatz digitaler KI-basierter Assistenzsysteme darauf hingewiesen, dass ein
schmaler Grat zwischen der Unterst&#252;tzung menschlicher T&#228;tigkeiten und Formen der Einschr&#228;nkung der
Entscheidungsautonomie besteht, die mit Arbeitsverdichtung, einer rigideren Kontrolle der Arbeitsleistung und einer
Entwertung menschlichen Erfahrungswissens einhergehen kann.1139 
Eine Kernfrage vieler Arbeitnehmerinnen und Arbeitnehmer wird sein, ob das eigene Besch&#228;ftigungsverh&#228;ltnis
durch den Einsatz von KI-Systemen gef&#228;hrdet ist. Evidenzbasierte Forschungsergebnisse zum Einfluss von KI
auf den Arbeitsmarkt gibt es bisher nur wenige.1140 Es lassen sich allerdings einige Schlussfolgerungen aus
bisherigen Automatisierungswellen ziehen. Demnach hat technologischer Wandel in der Vergangenheit nicht zu
gro&#223;en Nettoverlusten bei der Besch&#228;ftigung gef&#252;hrt, da die Anzahl der neu entstandenen Arbeitspl&#228;tze stets die
Anzahl der weggefallenen mehr als ausgleichen konnte.1141 Gleichwohl gab es gr&#246;&#223;ere Umstrukturierungen
zwischen T&#228;tigkeitsbereichen mit ver&#228;nderten Anforderungen.1142 Gegen solche historischen Analogien spricht
jedoch, dass &#8222;erste wissenschaftliche Studien zum Einsatz von KI zeigen, dass im Unterschied zu bisherigen
Automatisierungswellen ganz andere T&#228;tigkeiten tangiert sein k&#246;nnten, sodass Arbeitspl&#228;tze neu gestaltet (Job-
Redesign) werden m&#252;ssen.&#8220;1143 Es stellt sich also die Frage, ob der Besch&#228;ftigungszuwachs die zu erwartenden
1137 Vgl. Achter Zwischenbericht der Enquete-Kommission &#8222;Internet und digitale Gesellschaft&#8220;, Wirtschaft, Arbeit, Green IT,
Bundestagsdrucksache 17/12505.
1138 Vgl. Bitkom e. V. (2020): Unternehmen tun sich noch schwer mit K&#252;nstlicher Intelligenz.
1139 Darstellung des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo in der Sitzung der Projektgruppe KI und Arbeit, Bildung, Forschung
vom 4. November 2019.
1140 Eine aktuelle Literatur&#252;bersicht findet sich bei Goos et al. (2019): The Impact of Technological Innovation on the Future of Work.
1141 Zu Europa vgl. Gregory et al. (2019): Racing With or Against the Machine? Evidence from Europe.
1142 Handlungsempfehlungen von Dr. Terry Gregory (IZA-Institute of Labor Economics), Projektgruppendrucksache 19(27)PG 4-17 vom
25. November 2019.
1143 Brynjolfsson et al. (2018): The Second Machine Age; Handlungsempfehlungen von Dr. Terry Gregory (IZA-Institute of Labor
Economics), Projektgruppendrucksache 19(27)PG 4-17 vom 25. November 2019.
Substitutionseffekte tats&#228;chlich abdecken kann, wenn diese insbesondere Bereiche kognitiver Arbeit betreffen,
die sich in der Vergangenheit als relativ automatisierungsresistent erwiesen haben.1144 M&#246;glicherweise wird im 
Arbeitsmarkt ein sog. Mismatch entstehen &#8211; also die Koexistenz von disruptiven Arbeitsplatzverlusten auf der
einen Seite und Fachkr&#228;ftemangel auf der anderen Seite.1145 
&#220;berdies gibt es Wechselwirkungen zwischen dem Einsatz von KI-Systemen und verschiedenen Aspekten der
Organisation der Arbeit. Der Schutz der Pers&#246;nlichkeitsrechte, die Organisation von Partizipation und
Mitbestimmung, die Schaffung von Transparenz und Nachvollziehbarkeit, die Schaffung von Vertrauenskulturen durch
aufgekl&#228;rte Akzeptanz und Aspekte qualitativer Personalplanung sowie der Handlungsautonomie und der
Belastung werden vom Einsatz lernender Maschinen ber&#252;hrt. Gestaltungsaufgaben f&#252;r den Einsatz der Systeme
ergeben sich aus der Art der Anwendung, beispielsweise in der Personalverwaltung, der Bewerberauswahl, der
Arbeitssteuerung und -kontrolle, der Entscheidungsfindung, der Assistenz und Kommunikation. Die betrieblichen
Einsatzformen von KI sind bislang allerdings zu wenig untersucht, systematisiert, standardisiert und evaluiert,
um verallgemeinerbare Einsatzempfehlungen aus der Praxis abzuleiten.
F&#252;r die Bearbeitung eines solch zentralen und facettenreichen Themas war die Projektgruppenphase zu kurz: Die
Zukunft der sozialen Sicherungssysteme konnte in der Projektgruppe nur andiskutiert werden. Dabei regt die
Projektgruppe an, dass dieses Feld durch ein anderes Gremium bearbeitet werden sollte, nachdem die Enquete-
Kommission ihre Arbeit beendet hat. 
KI in der Bildung
In einer von KI gepr&#228;gten Welt werden Kenntnisse &#252;ber KI immer mehr zu einer notwendigen
Schl&#252;sselkompetenz f&#252;r die Teilhabe in allen gesellschaftlichen Bereichen. Der Umgang mit und die Gestaltung von KI werden 
f&#252;r ein selbstst&#228;ndiges Leben in der Welt von morgen an Bedeutung gewinnen. Das deutsche Bildungssystem
wird in Bezug auf die Anforderungen einer von KI beeinflussten Lebens- und Arbeitswelt vor die
Herausforderung gestellt, die Menschen so gut wie m&#246;glich darauf vorzubereiten, mit transformierten Arbeits-,
Organisations- und Kommunikationsprozessen umzugehen. Das Bildungssystem muss so gestaltet werden, dass es
m&#246;glichst flexibel und dynamisch auf durch KI getriebene Entwicklungen reagieren kann und ein fundiertes
Basiswissen vermittelt, das dazu bef&#228;higt, selbstst&#228;ndig weiterzulernen und sich neue Dinge anzueignen.
Die Aus- und Weiterbildung betrifft alle Bildungsbereiche: Vorschule1146, Schule, Berufs(fach)schulen,
(Ausbildungs-)Berufe, Hochschulen, aber auch die inner- und au&#223;erbetriebliche Weiterbildung sowie die
Erwachsenbildung. Weiterhin sollte die Gesamtbev&#246;lkerung &#8211; unabh&#228;ngig von den jeweiligen Berufen &#8211; in die Lage versetzt
werden, grundlegende Informationen und Kenntnisse &#252;ber KI zu erlangen. Dies kann beispielsweise durch eine
Lernplattform geschehen, in der Grundkenntnisse zu KI, deren Funktionsweise, Informationen &#252;ber
Anwendungsf&#228;lle usw. vermittelt werden, aber auch &#252;ber die Risiken von KI und M&#246;glichkeiten zu deren Vermeidung
aufgekl&#228;rt wird. 
Die Projektgruppe hat zwei Bereiche von KI und Bildung n&#228;her betrachtet:
1. Lernen &#252;ber KI, das sich auf die Aus- und Weiterbildung zu technischen F&#228;higkeiten, aber auch zu
Anwendungen und Soft Skills im Zusammenhang mit KI bezieht
2. Lernen mit KI, das sich auf die Unterst&#252;tzung und die Analyse von Lernen durch KI-L&#246;sungen bezieht
Damit Menschen sich eine fundierte und differenzierte Meinung &#252;ber die Chancen und Risiken von KI bilden
k&#246;nnen, ist ein grundlegendes Verst&#228;ndnis der Funktionsweise von KI-Systemen und der Methoden, mit denen 
sie entwickelt werden, wichtig. Die Behandlung von KI als f&#228;cher&#252;bergreifendes Thema in Vorschule, Schule,
Studium und beruflicher Aus- und Weiterbildung ist deshalb notwendig, um ein generelles Verst&#228;ndnis f&#252;r
Maschinelles Lernen und weitere methodische Grundlagen, wie Planungsalgorithmen oder Sprach- und
Bildverarbeitung, zu vermitteln. Dabei ist wichtig, dass auch Einblicke in m&#246;gliche Herausforderungen des Maschinellen
Lernens und der dazu notwendigen Datengrundlage gegeben werden.
1144 Vgl. Brynjolfsson et al. (2018): The Second Machine Age. 
1145 Handlungsempfehlungen von Prof. Dr. Jens S&#252;dekum (D&#252;sseldorf Institute for Competition Economics), Projektgruppendrucksache
19(27)PG 4-2 vom 21. November 2019.
1146 Es gibt auch Projekte, die den Einsatz von KI im Vorschulalter erproben, wie beispielsweise das Projekt L2TOR, weitere
Informationen dazu unter: http://www.l2tor.eu/ (zuletzt abgerufen am 5. August 2020).
Lernen ist und bleibt ein sozialer Prozess. Das bedeutet, ma&#223;geblich f&#252;r den Lernerfolg sind u. a. die
Kommunikation und der Austausch zwischen Lehrenden und Lernenden. Es gilt zu erforschen, inwieweit und durch
welchen Einsatz KI-Systeme positiven Einfluss auf den Lernerfolg nehmen k&#246;nnen und Diskriminierungen
verhindern. Mechanismen und Ma&#223;nahmen von KI k&#246;nnen au&#223;erdem in der gesamten Bildungskette dabei unterst&#252;tzen,
komplexe Sachverhalte besser zu durchdringen. KI kann beispielsweise gezielt zur individuellen F&#246;rderung und
zur Unterst&#252;tzung lebenslangen Lernens eingesetzt werden und ist deshalb in diesem Kontext f&#252;r die Zukunft
erstrebenswert.
KI in der Forschung
Die KI-Forschung1147 ist ein breites Feld, in dem viele verschiedene Disziplinen aufeinandertreffen. Es erstreckt
sich von Softwareentwicklung, beispielsweise f&#252;r eine KI, die Logistikabl&#228;ufe optimiert, bis hin zur Robotik, die
z. B. vielfach bei der industriellen Produktion zum Einsatz kommt. In der Grundlagenforschung kann an neuen
Fragen geforscht werden oder man arbeitet an speziellen Problemen f&#252;r die Anwendung. Beides steht aber in
einem engen Austausch und die Grenzen zwischen Grundlagen- und Anwendungsforschung sind oft flie&#223;end.
Differenziert man nach Embodied KI und Disembodied KI1148, ist die Forschungslandschaft in Deutschland in
beiden Bereichen gut aufgestellt. In Deutschland hat die Forschung an Embodied KI Tradition und ist seit
Jahrzehnten von Weltrang. Einige der Hauptbereiche sind die Robotik, das autonome Fahren und intelligente
Maschinen im Allgemeinen. F&#252;r die Robotik gelten viele Universit&#228;ten und Forschungsinstitute in Deutschland als
Spitzenreiter in der internationalen Forschungsgemeinschaft.1149 Autonomes Fahren ist in Deutschland ein
weiteres Forschungsgebiet von internationalem Rang, wobei die meisten Forschungsarbeiten in industriellen
Einrichtungen1150 durchgef&#252;hrt werden; aber auch Universit&#228;ten und Forschungsinstitute haben einen gro&#223;en Anteil
an diesem Gebiet.1151 Im Bereich Disembodied KI ist die Forschung in Deutschland sehr vielf&#228;ltig. Themen wie
Sprachanalyse, Empfehlungssysteme, Maschinelles Lernen und Computer-Vision werden an fast jeder gr&#246;&#223;eren
Universit&#228;t1152 erforscht.
Auch au&#223;eruniversit&#228;re Forschungsinstitute1153 investieren stark in die theoretische und angewandte Forschung
in diesen Bereichen. 
Differenziert man zwischen Grundlagen- und angewandter Forschung, so verschwimmt insbesondere in Bezug
auf KI-Technologien die Grenze zwischen den Forschungsbereichen, die sich zumal wechselseitig stark
bedingen, auch weil die technische Entwicklung sehr schnell voranschreitet. Beispielsweise flie&#223;en in der Robotik
Erkenntnisse aus jahrzehntelanger Grundlagenforschung mit M&#246;glichkeiten des Maschinellen Lernens
zusammen und treffen auf ganz eigene Herausforderungen der Manifestation von Robotik in der physischen Welt.
Intelligente Robotik ist daher weder reine Grundlagenforschung noch reine Anwendung, sondern erst in der
Begegnung dieser Anspr&#252;che entsteht die sinnvolle Forschungsaufgabe. Entsprechend verh&#228;lt es sich in anderen
Bereichen, wie z. B. Bilderkennung und -interpretation, Sprach- und Textverstehen und Mensch-Maschine-
Interaktion.
Die anwendungsbezogene Forschung findet insbesondere in Forschungsinstituten1154, die eng mit der Industrie
zusammenarbeiten, statt, vermehrt auch &#252;ber Start-ups, die mit Universit&#228;ten arbeiten, aber auch in gro&#223;en
Technologiefirmen, wie z. B. den Automobilfirmen sowie Google und Amazon. Zum Teil gibt es auch
Forschungskooperationen mit &#8222;Hidden Champions&#8220; im Bereich der kleinen und mittelst&#228;ndischen Unternehmen (KMU).
Nachfolgend sind einige ausgew&#228;hlte, zentrale Handlungsempfehlungen der Projektgruppe aufgef&#252;hrt:
1147 In Kapitel 9 des Mantelberichts [KI und Forschung] werden Aspekte m&#246;glicher Leitlinien und Ziele sowie St&#228;rken, Schw&#228;chen,
Chancen und Risiken der Forschungslandschaft in Deutschland zum Thema KI behandelt.
1148 Siehe auch Kapitel 5.3.1 dieses Projektgruppenberichts [Disembodied und Embodied KI].
1149 Beispiele daf&#252;r sind das Deutsche Zentrum f&#252;r Luft- und Raumfahrt (DLR), die Munich School of Robotics and Machine
Intelligence der Technischen Universit&#228;t M&#252;nchen (MSRM) oder auch das Max-Planck-Institut f&#252;r Intelligente Systeme (MPI-IS).
1150 Beispiele daf&#252;r sind DAIMLER, BMW und das Bosch Center for Artificial Intelligence (BCAI).
1151 Zu denken ist hier z. B. an fortiss, das Karlsruher Institut f&#252;r Technologie, die Technische Universit&#228;t Braunschweig und die
Technische Universit&#228;t M&#252;nchen.
1152 Dies gilt u. a. f&#252;r die Universit&#228;ten in Berlin, Aachen, M&#252;nchen oder Karlsruhe.
1153 Dazu z&#228;hlen z. B. das Deutsche Forschungszentrum f&#252;r K&#252;nstliche Intelligenz (DFKI), das BCAI und das MPI-IS.
1154 Beispiele daf&#252;r sind das DFKI oder die Fraunhofer-Institute.
KI in der Arbeitswelt
Um den Strukturwandel besser vorbereiten und gestalten zu k&#246;nnen, sind evidenzbasierte Forschung und
belastbare Prognosen f&#252;r die Besch&#228;ftigungseffekte des KI-Einsatzes unerl&#228;sslich. Neben den Aktivit&#228;ten des vom
Bundesministerium f&#252;r Arbeit und Soziales (BMAS) eingerichteten KI-Observatoriums1155 sind spezielle
F&#246;rderprogramme zur systematischen Erfassung und Analyse der arbeitsmarktrelevanten Auswirkungen von KI
aufzulegen.1156 
Die Projektgruppe empfiehlt sektorales Branchenmonitoring/-screening in Zusammenarbeit mit Verb&#228;nden,
Gewerkschaften und Forschungsinstituten zur Beobachtung und vorausschauenden Auswertung von Entwicklungen
auf dem Arbeitsmarkt.1157 
Zu empfehlen ist weiterhin die &#8222;langfristige F&#246;rderung anwendungsbezogener Forschung in betrieblichen
Kontexten, auch und gerade sozial- und verhaltenswissenschaftlicher Forschung, zu den Auswirkungen des KI-
Einsatzes auf Arbeitnehmerinnen und Arbeitnehmer, Arbeit, Qualifikationsbedarf und Unternehmen&#8220;1158.
&#8222;Bei der Interaktion mit KI-Systemen kann ein Teil der Handlungstr&#228;gerschaft bzw. Situationskontrolle (Wer 
st&#246;&#223;t Handlungen an? Wer koordiniert eine Situation?) auf der Seite des technischen Systems liegen (hybride
Handlungstr&#228;gerschaft). Das System nimmt eine Rolle als Akteur ein.&#8220;1159 Die definierten Rollen und Aufgaben
m&#252;ssen au&#223;erdem analysiert werden, um daraus abzuleiten, welche Qualifikationen gebraucht werden. F&#252;r den 
Erhalt der Arbeitszufriedenheit ist es entscheidend, wie ein hohes Ma&#223; an Autonomie f&#252;r Besch&#228;ftigte
aufrechterhalten werden kann. Die Optimierung der Zusammenarbeit zwischen Menschen und lernenden Systemen
beruht zu einem Gro&#223;teil auf pers&#246;nlichen Daten. In diesem Zusammenhang muss gekl&#228;rt werden, wozu
pers&#246;nliche Daten genutzt werden, wo die Grenzen f&#252;r die Datennutzung liegen und wie transparent die Datennutzung
ist.1160 
Nach der Einsch&#228;tzung eines Sachverst&#228;ndigen1161 reichen derzeit bestehende gesetzliche Vorschriften des
Arbeitsschutzes f&#252;r die Anwendung von KI aus. Die Gef&#228;hrdungsbeurteilung der Arbeitsprozesse &#8211; die Basis des
deutschen Arbeitsschutzes &#8211; gelte im Umgang mit KI als sinnvoll. Technische Regeln, die z. B. die
Betriebsoder Arbeitsst&#228;ttenverordnung konkretisieren, seien dagegen zu aktualisieren (z. B. Einsatz von modernen KI-
unterst&#252;tzten Assistenzsystemen wie Datenbrillen und Smartwatches).1162 
Um dem Prozesscharakter lernender Maschinen gerecht zu werden und um vorausschauend, wirksam und schnell
zu wirken, muss die betriebliche Mitbestimmung auf das Konzept der Entwicklung, des Einsatzes und der
Fortentwicklung der Systeme ausgerichtet sein. Sie muss sich au&#223;erdem der normativen Wirkung aller wesentlichen
Fragen der Pers&#246;nlichkeitsrechte annehmen k&#246;nnen, wirksamen Einfluss auf die Arbeitsmenge,
Arbeitsorganisation und die Qualifizierung er&#246;ffnen, die sich im Zusammenhang mit dem Einsatz von KI-Systemen ergeben.
Besch&#228;ftigte und ihre Interessenvertretungen sollen u. a.
&#8226; bereits bei der Definition der Zielsetzung und Konfiguration von KI-Systemen ebenso wirksam mitgestalten
k&#246;nnen wie bei der Evaluation, dem Betrieb und der Fortentwicklung der sozio-technischen
Einsatzbedingungen,
&#8226; aufgrund der steigenden Bedeutung der Personalplanung und -entwicklung sowie der Qualifizierung von
Besch&#228;ftigten ein Mitbestimmungs- und Initiativrecht in Fragen der Weiterbildung erhalten,
&#8226; eine wirksame Mitbestimmung nutzen k&#246;nnen, sodass alle in der Verfassung definierten
Pers&#246;nlichkeitsrechte gesch&#252;tzt werden,
1155 Das KI-Observatorium hat die Aufgabe, Effekte von KI in der Arbeitswelt fr&#252;hzeitig zu erkennen und Felder aufzuzeigen, auf denen
Handlungsbedarf besteht. Eines seiner f&#252;nf Handlungsfelder ist, Technologievorausschau und Technikfolgenabsch&#228;tzung zu
gew&#228;hrleisten.
1156 Siehe auch Kapitel 5.1.1.3.1 dieses Projektgruppenberichts [Die Auswirkungen von KI f&#252;r den Arbeitsmarkt weiter erforschen].
1157 Siehe auch Kapitel 5.1.1.3.1 dieses Projektgruppenberichts [Die Auswirkungen von KI f&#252;r den Arbeitsmarkt weiter erforschen].
1158 Handlungsempfehlungen von Dr. Marie-Christin Fregin (Wissenschaftszentrum Berlin und Input-Consulting),
Projektgruppendrucksache 19(27)PG 4-22 vom 9. Dezember 2019; siehe auch Kapitel 5.1.3.5.1 dieses Projektgruppenberichts [Arbeitsorganisation].
1159 Handlungsempfehlungen von Prof. Dr. Lars Adolph (Bundesanstalt f&#252;r Arbeitsschutz und Arbeitsmedizin),
Projektgruppendrucksache 19(27)PG 4-20 vom 9. Dezember 2019.
1160 Siehe auch Kapitel 5.1.2.6.2 dieses Projektgruppenberichts [Mensch-Maschine-Interaktion].
1161 Darstellung Prof. Dr. Sascha Stowasser (Institut f&#252;r angewandte Arbeitswissenschaft) in der Sitzung der Projektgruppe KI und Arbeit,
Bildung, Forschung vom 13. Januar 2020.
1162 Handlungsempfehlungen von Prof. Dr. Sascha Stowasser (Institut f&#252;r angewandte Arbeitswissenschaft), Projektgruppendrucksache
19(27)PG 4-44 vom 10. Januar 2020; siehe auch dieses Projektgruppenberichts [Mensch-Maschine-Interaktion].
&#8226; ihr Handeln auf eine nachvollziehbare Technikfolgenabsch&#228;tzung, G&#252;tekriterien, Zertifizierungen,
Auditierungen und die Arbeit des Observatoriums der Bundesregierung st&#252;tzen k&#246;nnen,
&#8226; auf Arbeitsdichte und Arbeitsmenge Einfluss haben, die sich aus der Maschine-Mensch-Schnittstelle ergibt,
&#8226; einen einfachen Zugang zu Weiterbildungs- und Beratungsangeboten haben, um die eigene KI-Kompetenz 
auszubauen; gerade f&#252;r eine ad&#228;quate Folgenabsch&#228;tzung ist ein einfacher Zugang zu externem
Expertenwissen notwendig, das entweder durch Arbeitgeber oder &#246;ffentlich finanziert ist. Zu pr&#252;fen w&#228;re hier der
Auf- und Ausbau von staatlich gef&#246;rderten Technologieberatungsstellen.1163 
Es w&#228;re f&#252;r die Arbeitnehmervertretung, aber auch die Unternehmensf&#252;hrungen hilfreich, wenn sie sich bei der
Beurteilung von KI-gest&#252;tzten Systemen, die f&#252;r die betriebliche Arbeitsorganisation relevant sind, an Normen,
Auditergebnissen oder Zertifizierungen von neutralen Dritten orientieren k&#246;nnten, welche Aussagen &#252;ber
mitbestimmungsrelevante Funktionsweisen und Gestaltungsans&#228;tze wie &#8222;Privacy by design&#8220; oder &#8222;Gute Arbeit by
design&#8220; treffen. Die Entwicklung solcher Standards sollte daher gef&#246;rdert werden. Vertrauensstiftend f&#252;r den
Einsatz von KI im Betrieb wirkt die enge Zusammenarbeit von Arbeitgeber und Arbeitnehmervertretung, in die die
oder der betriebliche Datenschutzbeauftragte einbezogen ist. Um konstruktiv und auf Augenh&#246;he &#252;ber den
Einsatz von KI-gest&#252;tzten Systemen in der Arbeitsorganisation beraten zu k&#246;nnen, m&#252;ssen Arbeitnehmervertreter
die n&#246;tige Datenschutz- und KI-Beurteilungskompetenz haben oder zumindest heranziehen k&#246;nnen.1164 Es ist
sinnvoll, betriebliche Best-Practice-Beispiele f&#252;r eine solche Zusammenarbeit zu ermitteln und zu verbreiten.
Im Besch&#228;ftigtenkontext ist besonders relevant, dass gesetzliche Vorgaben der europ&#228;ischen Datenschutz-
Grundverordnung (DSGVO), etwa zum Profiling (Artikel 22 DSGVO), praxisnah und ethikkonform zu
Handlungsempfehlungen pr&#228;zisiert werden. In diesem Kontext w&#228;re es auch hilfreich, wenn Standards f&#252;r
Pseudonymisierung und Anonymisierung1165 verabschiedet w&#252;rden, um personenbezogene Daten f&#252;r KI zu nutzen und zugleich
die Rechte der Betroffenen zuverl&#228;ssig zu wahren.1166 
Die Planungen des BMAS, &#8222;einen Index Besch&#228;ftigtendatenschutz zu entwickeln&#8220;, ist f&#252;r die Wahrung der
Pers&#246;nlichkeitsrechte beim Einsatz von KI in der Arbeit von besonderer Bedeutung; sie ist deshalb zu
unterst&#252;tzen.1167 
Beim Einsatz von KI-Anwendungen muss sichergestellt werden, dass Menschen weiterhin in Personalfragen
entscheiden. In der Personalverwaltung d&#252;rfen f&#252;r die Nutzung in automatisierten Programmen oder KI-
L&#246;sungen keine Daten erhoben und verwendet werden, welche der willentlichen Steuerung der Betroffenen
grunds&#228;tzlich entzogen sind. Die Subjektqualit&#228;t und die Selbstbestimmung des Menschen m&#252;ssen immer geachtet
werden.1168 
Anbieter und Nutzerinnen und Nutzer von KI-L&#246;sungen f&#252;r die Personalgewinnung m&#252;ssen sicherstellen, dass
die zugrundeliegenden Daten &#252;ber eine hohe Qualit&#228;t verf&#252;gen und systembedingte Diskriminierungen
ausgeschlossen werden. Vor bzw. beim Einsatz einer KI-L&#246;sung im Personalwesen m&#252;ssen die davon betroffenen
Menschen &#252;ber Einsatz, Zweck und Logik der erhobenen und verwendeten Datenarten informiert werden.1169 
Die Projektgruppe h&#228;lt f&#252;r den Einsatz von KI in der Verwaltung einen Handlungsrahmen f&#252;r sinnvoll, der hilft,
kritische KI-Anwendungen zu erkennen und sie angemessen zu pr&#252;fen. Durch KI freigewordene Kapazit&#228;ten 
sollten daf&#252;r genutzt werden, unterbesetzte Abteilungen zu st&#228;rken und z. B. in die Beratung und Vermittlung zu
reinvestieren. Das Ziel sollte nicht vorrangig das Ersetzen von Personal, sondern in erster Linie die
Qualit&#228;tssteigerung sein.
1163 Siehe auch Kapitel 5.1.2.6.2 dieses Projektgruppenberichts [Mensch-Maschine-Interaktion].
1164 Siehe zum Kompetenzerwerb bzw. zur Orientierung etwa &#252;ber Auditierung und Zertifizierung die Handlungsempfehlungen in Kapitel
5.1.2.5 [Partizipation und Mitbestimmung] und im Kapitel 5.2.7 [KI in Aus- und Weiterbildung] dieses Projektgruppenberichts.
1165 Eine M&#246;glichkeit zur sicheren Daten-Anonymisierung und Daten-Pseudonymisierung ist das Einschalten einer unabh&#228;ngigen und 
vertrauensw&#252;rdigen dritten Instanz (&#8222;Trust Center&#8220;) zwischen der Daten erhebenden Stelle, den betroffenen Personen und jenen
Akteuren, welche die Daten auswerten und verarbeiten m&#246;chten. Eine De-Anonymisierung erhobener Daten muss zu jeder Zeit
ausgeschlossen sein. Vgl. dazu J&#228;schke et al. (2018): F&#252;r immer anonym: Wie kann De-Anonymisierung verhindert werden? Gutachten
zur Verhinderung der De-Anonymisierung, S. 65 f.
1166 Darstellung Eva Gardyan-Eisenlohr (Konzerndatenschutzbeauftragte der Bayer AG) in der Sitzung der gesamten Enquete-
Kommission am 13. Januar 2020.
1167 Siehe auch Kapitel 5.1.3.5.1 dieses Projektgruppenberichts [Arbeitsorganisation].
1168 Siehe auch Kapitel 5.1.3.5.2 dieses Projektgruppenberichts [Einsatz von automatisierten Entscheidungssystemen und KI in der
Personalverwaltung].
1169 Siehe auch Kapitel 5.1.3.5.2 dieses Projektgruppenberichts [Einsatz von automatisierten Entscheidungssystemen und KI in der
Personalverwaltung].
In Anlehnung an den &#8222;Corporate Governance Kodex&#8220; f&#252;r gute Unternehmensf&#252;hrung1170 kann ein System
ethischer Ma&#223;st&#228;be als Instrument der Selbststeuerung der Wirtschaft implementiert werden, das auch f&#252;r die Arbeit
von Arbeitnehmervertretungen Relevanz entfaltet.1171 Ein Modell wie das der Datenethikkommission f&#252;r die
Einstufung algorithmischer Systeme in Kritikalit&#228;tsstufen1172 k&#246;nnte auch f&#252;r die betriebliche Arbeitsgestaltung 
erstellt und zur Orientierung f&#252;r Entscheidungen &#252;ber den Einsatz von bestimmten Systemen im jeweiligen
Kontext genutzt werden. Es sollte jedoch um einen Mechanismus erg&#228;nzt werden, um die Nutzenpotenziale von KI-
Systemen f&#252;r die verschiedenen Stakeholder-Gruppen in den Betrieben zu untersuchen. Damit k&#246;nnten Chancen-
und Risikopotenziale gleichzeitig in die Formulierung von betrieblichen Regulierungsans&#228;tzen einflie&#223;en.
KI in der Bildung:
Um KI in Lernprozessen p&#228;dagogisch sinnvoll einzusetzen, sollte noch mehr erforscht werden, wie KI-Systeme 
auf Lernende und Lehrende wirken und wie sie diese dabei unterst&#252;tzen k&#246;nnen, p&#228;dagogische Ziele (u. a.
Inklusion) zu erreichen. Bei der Einf&#252;hrung von KI-Systemen und der zugeh&#246;rigen Dateninfrastruktur ist eine
medienp&#228;dagogische Prozessbegleitung zur Verf&#252;gung zu stellen.1173 
KI, aber auch die Grundlagen daf&#252;r (z. B. Mathematik, abstraktes Denken, Verst&#228;ndnis f&#252;r gesellschaftliche
Auswirkungen), m&#252;ssen in die Lehrpl&#228;ne aller Schularten Eingang finden bzw. in ausreichender Tiefe erhalten
bleiben. Zudem sollte Informatik als Pflichtfach in den Lehrpl&#228;nen verankert werden. An den Oberstufen in allen
Bundesl&#228;ndern sollten sich die Lehrinhalte im Fach Mathematik an den Anforderungen der Hochschulen
ausrichten.1174 
Kompetenzen zu KI und Algorithmik sollten jahrgangsstufengerecht sowohl im Fach Informatik als auch als
Querschnittsthema im gesamten F&#228;cherkanon aufgenommen werden. Neben technisch orientierten KI-
Kompetenzen sowie der F&#228;higkeit, KI-L&#246;sungen anzuwenden, sollte in allen Schulformen sowie in der beruflichen Aus-
und Weiterbildung ein Augenmerk auf die Soft Skills, wie kritisches Denken und Entscheidungsf&#228;higkeit, sowie
ein Bewusstsein f&#252;r philosophische Fragestellungen und gesellschaftliche Herausforderungen durch KI gelegt
werden.1175 
Digitalkompetenzen m&#252;ssen in der ersten Phase der Lehrkr&#228;fteausbildung verpflichtend sein; in der zweiten und 
dritten Phase sind sie in die Weiterbildungsf&#246;rderprogramme der L&#228;nder aufzunehmen, um die Basis f&#252;r einen
p&#228;dagogisch wertvollen und informierten Einsatz von KI-Systemen zu legen.1176 
Bestehende Ungleichgewichte, die zwischen M&#228;dchen und Jungen bzw. Frauen und M&#228;nnern im Hinblick auf
das Wissen &#252;ber und die Anwendung von KI bestehen, sollen ausgeglichen werden. Dazu k&#246;nnen sowohl Schulen
als auch Hochschulen Angebote entwickeln, die M&#228;dchen und junge Frauen f&#252;r Informatik und KI interessieren 
und ihnen Gestaltungsm&#246;glichkeiten mitgeben.
Im Bereich Aus- und Weiterbildung m&#252;ssen Bildungsangebote geschaffen werden, die die KI-Kompetenz der
Erwerbst&#228;tigen f&#246;rdern. Diese Fortbildungsangebote sollten einheitliche Standards erf&#252;llen. Hierf&#252;r w&#228;re es
sinnvoll, wenn Fortbildungsmodule gemeinsam mit Hochschulen sowie Fachvertreterinnen und -vertretern
entwickelt w&#252;rden. Diese Angebote k&#246;nnen von Betrieben, Volkshochschulen, IHK und privaten Anbietern genutzt
bzw. angeboten werden.1177 
Die St&#228;rkung der betrieblichen Weiterbildung ist zentral, um das durch KI immer wichtiger werdende
lebenslange Lernen zu erm&#246;glichen. Es sind massive Investitionen in den Bildungssektor in all seinen Facetten
erforderlich.1178 
Die Weiterbildungspolitik sollte dabei &#8211; im Sinne von Finanzierung, Beratung und Organisation &#8211; auf Augenh&#246;he
mit der Erstausbildungspolitik liegen und entsprechende Anreize in Bezug auf die er&#246;ffneten Karrierewege und
die Eingruppierung/Entlohnung von T&#228;tigkeiten beinhalten. Ein formaler Qualifikationsrahmen ist und bleibt
1170 Vgl. Regierungskommission Deutscher Corporate Governance Kodex (2019): Deutscher Corporate Governance Kodex.
1171 Siehe auch Kapitel 3.3.3 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220; [Angestrebte Wirtschaftsziele: &#8222;KI made in Germany&#8220;
als internationales G&#252;tesiegel].
1172 Vgl. Datenethikkommission der Bundesregierung (2019): Gutachten der Datenethikkommission der Bundesregierung, S. 177. Die 
Einstufung von KI-Systemen in Kritikalit&#228;tsstufen war in der Enquete-Kommission allgemein und in der Projektgruppe umstritten.
1173 Siehe auch Kapitel 5.2.8 dieses Projektgruppenberichts [Handlungsempfehlungen].
1174 Siehe auch Kapitel 5.2.8.1 dieses Projektgruppenberichts [Lehrkr&#228;ftebildung].
1175 Siehe auch Kapitel 5.2.8.1 dieses Projektgruppenberichts [Lehrkr&#228;ftebildung].
1176 Siehe auch Kapitel 5.2.8.1 dieses Projektgruppenberichts [Lehrkr&#228;ftebildung].
1177 Siehe auch Kapitel 5.2.8.2 dieses Projektgruppenberichts [Aus- und Weiterbildung].
1178 Siehe auch Kapitel 5.2.8.2 dieses Projektgruppenberichts [Aus- und Weiterbildung].
wichtig, n&#252;tzlich und effektiv. Er muss allerdings mit flexiblem Kompetenzerwerb und einer flexiblen
Anerkennung von Qualifikationen verbunden werden.1179 
Aus- und Weiterbildungssysteme m&#252;ssen flexibler als heute reagieren und sich vor allem durch gezielte
Ma&#223;nahmen st&#228;rker auf Geringqualifizierte und &#196;ltere fokussieren.1180 
(Berufliche) Weiterbildung, die sich am konkreten Bedarf der Betriebe orientiert, sollte vom Arbeitgeber
finanziert und gef&#246;rdert werden. Dar&#252;ber hinaus muss es &#246;ffentliche F&#246;rderprogramme f&#252;r Weiterbildung geben, die
unabh&#228;ngig von der aktuellen Besch&#228;ftigung sind.1181 
Um die Bev&#246;lkerung in die Lage zu versetzen, grundlegende Zusammenh&#228;nge im Bereich KI zu verstehen und
ihre Funktionsweise einordnen zu k&#246;nnen, sollte eine Weiterbildungsplattform entwickelt werden.1182 Um einen
hohen Qualit&#228;tsstandard sicherzustellen, sollte hier mit anerkannten Forschungs- und/oder
Bildungseinrichtungen zusammengearbeitet werden.1183 Dabei ist darauf zu achten, dass eine staatliche Weiterbildungsplattform 
verschiedene Angebote nicht nur geb&#252;ndelt darstellt, sondern den Zugang zu den Angeboten niedrigschwellig
m&#246;glich macht. Hierzu geh&#246;ren die Gestaltung von Angeboten f&#252;r verschiedene Altersstufen und Lerntypen,
Sprachen und Barrierefreiheit. Die Suche nach KI-spezifischen Ma&#223;nahmen sowie die Anmeldung zu
Fortbildungen sollten &#252;ber dasselbe Portal laufen.
KI in der Forschung:
Der Erfolg der KI-Forschung in den Anwendungsbereichen Arbeit und Bildung h&#228;ngt ebenso wie in anderen
Bereichen in besonderem Ma&#223;e von einer fruchtbaren Interaktion zwischen Grundlagenforschung,
problemorientierter Grundlagenforschung und unmittelbar anwendungsorientierter Forschung ab. Als lernende Systeme
m&#252;ssen KI-Systeme stets an ihren Anwendungskontext angepasst werden und sie entwickeln sich dort durch das
Verarbeiten von Daten weiter.1184 
Die informatische und ingenieurswissenschaftliche Forschung sollte von arbeitswissenschaftlicher bzw.
p&#228;dagogischer Forschung begleitet sein, welche die Nutzererfahrungen, die Aneignungspraktiken der Akteure sowie die
kurz- und mittelfristigen Folgen des Technologieeinsatzes untersucht. Neben betriebswissenschaftlichen und
ergonomischen bzw. lernpsychologischen Erkenntnissen sollte die Forschung auch die normative Fragestellung
einbeziehen, welche Rolle der Technikeinsatz f&#252;r eine qualitative Aufwertung von Arbeit sowie die inklusive
Gestaltung von individuell optimierten Bildungsangeboten haben kann.1185 
Regul&#228;re staatliche F&#246;rderprogramme im Bereich der KI-Forschung sollten explizit zur Bildung interdisziplin&#228;rer
Konsortien ermuntern und Anreize f&#252;r transdisziplin&#228;re Fragestellungen schaffen.1186 
Erforderlich ist der Ausbau von Transfer- und Kooperationsmechanismen zwischen Wissenschaft, Wirtschaft,
Politik und Zivilgesellschaft im Bereich der KI-Forschung, somit auch eine Zug&#228;nglichkeit von KI-Entwicklung 
im Rahmen von &#8222;Citizen Sciences&#8220;, Reallaboren und &#228;hnlichen inklusiven Ans&#228;tzen der Innovation. Auch die
Lehre muss mehr mit der Anwendung und mit praktischen Arbeiten verkn&#252;pft werden. Dazu bedarf es einer
intensiveren Betreuung durch mehr qualifizierte Lehrkr&#228;fte oder der Freistellung von Personal f&#252;r die Lehre und
einer viel besseren Ausstattung von Laboren, Werkst&#228;tten und Computerr&#228;umen.1187 
Um die Potenziale von KI zur Verbesserung von Arbeit und Bildung zu heben, sollten mittel- bis langfristige
F&#246;rderprogramme eingerichtet bzw. existierende Programme aufgestockt werden, die besonderes Gewicht auf
gesellschaftlich relevante Zielsetzungen legen. Dies betrifft insbesondere die in Kapitel 3.3.3 dieses
Projektgruppenberichts [Wie die Forschung von morgen aussehen k&#246;nnte] aufgef&#252;hrten Beispiele, wie z. B. KI-basierte
Telepr&#228;senzsysteme und Portale f&#252;r das Ersetzen von T&#228;tigkeiten in gef&#228;hrlichen Umgebungen, Formen der
1179 Siehe auch Kapitel 5.2.8.2 dieses Projektgruppenberichts [Aus- und Weiterbildung].
1180 Siehe auch Kapitel 5.2.8.2 dieses Projektgruppenberichts [Aus- und Weiterbildung].
1181 Siehe auch Kapitel 5.2.8.2 dieses Projektgruppenberichts [Aus- und Weiterbildung].
1182 Beispiele f&#252;r solche Plattformen gibt es in den Niederlanden, vgl. https://app.ai-cursus.nl/home, speziell f&#252;r Kinder, vgl. https://fu-
turenl.org/nationale-ai-cursus-junior/), und in Finnland, vgl. https://www.elementsofai.com/ (alle zuletzt abgerufen am 5. August
2020), inzwischen gibt es auch eine deutsche Version dieser Plattform, vgl. https://www.elementsofai.de/ (zuletzt abgerufen am
3. September 2020).
1183 Siehe auch Kapitel 5.2.8.2 dieses Projektgruppenberichts [Aus- und Weiterbildung].
1184 Siehe auch Kapitel 5.3.3 dieses Projektgruppenberichts [Handlungsempfehlungen].
1185 Siehe auch Kapitel 5.3.3 dieses Projektgruppenberichts [Handlungsempfehlungen].
1186 Siehe auch Kapitel 5.3.3 dieses Projektgruppenberichts [Handlungsempfehlungen].
1187 Siehe auch Kapitel 5.3.3 dieses Projektgruppenberichts [Handlungsempfehlungen].
        
 
 
 
  
  
    
   
 
       
 
      
 
  
 
 
       
   
  
   
 
      
  
  
          
    
 
    
 
  
  
    
 
     
    
     
      
   
  
 
    
    
  
   
   
 
      
 
  
                                               
        
   
   
2
Mensch-Maschine-Interaktion zur Anreicherung und Aufwertung von Arbeit sowie KI-Lernsysteme zur
Unterst&#252;tzung von Sch&#252;lerinnen und Sch&#252;lern mit Lernschw&#228;chen.1188 
Vorbemerkungen
Im Einsetzungsbeschluss der Enquete-Kommission &#8222;K&#252;nstliche Intelligenz &#8211; Gesellschaftliche Verantwortung
und wirtschaftliche, soziale und &#246;kologische Potenziale&#8220; (Bundestagsdrucksache 19/2978) nehmen die
Auswirkungen von KI auf die Arbeitswelt sowie auf Bildung und Forschung eine zentrale Rolle ein. Dabei wird davon
ausgegangen, dass die aktuellen Entwicklungen einen tiefgreifenden Einfluss auf viele Lebens- und
Arbeitsbereiche haben werden. So sollen die Chancen und Herausforderungen von KI f&#252;r die Wirtschaft und die
Arbeitswelt sowie f&#252;r Bildung und Forschung erarbeitet werden. Insbesondere sollen die Ver&#228;nderungen der Arbeitswelt
und der Wertsch&#246;pfungsketten, die Kooperation und Kollaboration von KI-Systemen mit Menschen im
beruflichen Umfeld sowie die Folgen des technologischen Wandels auf die soziale Marktwirtschaft, Tarifbindung und
Mitbestimmung analysiert werden. F&#252;r den Bereich Bildung sieht der Einsetzungsbeschluss insbesondere vor,
sich mit den Auswirkungen von KI als m&#246;glicherweise f&#252;r die gesamte Bildungskette disruptiver Technologie
und mit der Gestaltung der Bildungs-, Hochschul- und Forschungslandschaft zur Ausbildung k&#252;nftiger KI-
Expertinnen und -Experten auseinanderzusetzen. Zum Thema Forschung sollen u. a. die M&#246;glichkeiten zur
St&#228;rkung und Weiterentwicklung der Grundlagen- und Anwendungsforschung im Zusammenhang mit dem KI-
Einsatz und der internationale Vergleich &#246;ffentlicher und privater Forschungsaktivit&#228;ten untersucht werden.
Vor dem Hintergrund dieser drei sehr umfangreichen Themenfelder sowie des engen Zeitrahmens hat sich die 
Projektgruppe &#8211; auch aufgrund der besonderen Bedeutung in der &#246;ffentlichen Diskussion &#8211; daf&#252;r entschieden,
den Schwerpunkt auf den Bereich KI und Arbeit zu legen, wobei beachtet wurde, dass die Themen Bildung und
Arbeit insofern miteinander verkn&#252;pft sind, dass die Bildungsbiografie unmittelbar auf den beruflichen
Lebenslauf vorbereitet und diesen so mitpr&#228;gt. Beim Themenkomplex Bildung hat sich die Projektgruppe
schwerpunktm&#228;&#223;ig auf den Bereich KI in der Schule und Hochschule konzentriert. Bei der Bearbeitung des Themas berufliche
Bildung wurde darauf geachtet, keine Parallelen zur Arbeit der zeitgleich beratenden Enquete-Kommission
&#8222;Berufliche Bildung in der digitalen Arbeitswelt&#8220; zu schaffen. Die Bearbeitung von Forschungsfragen wurde
gr&#246;&#223;tenteils im Mantelbericht behandelt und in der Projektgruppe schwerpunktm&#228;&#223;ig KI als Instrument der Forschung
thematisiert.
Um sich den breiten Themenfeldern zu n&#228;hern, hat die Projektgruppe, neben der Nutzung wissenschaftlicher
Studien und der umfangreichen Kenntnisse der sachverst&#228;ndigen Mitglieder, zahlreiche externe Expertinnen und
Experten in den Projektgruppensitzungen angeh&#246;rt. Diese wurden ebenfalls gebeten, aus ihrer Perspektive
schriftliche Handlungsempfehlungen zu formulieren.1189 
Die ersten beiden Sitzungen am 14. Oktober und 4. November 2019 dienten der internen Diskussion &#252;ber die
Schwerpunktsetzung sowie der Einf&#252;hrung in die Thematik durch die sachverst&#228;ndigen Mitglieder. In der Sitzung
am 25. November 2019 verschafften sich die Projektgruppenmitglieder einen &#220;berblick &#252;ber die
Einsatzm&#246;glichkeiten von KI in der Arbeitswelt und deren Auswirkungen und besch&#228;ftigten sich mit der
Arbeitsmarktforschung zu KI. In der Sitzung am 9. Dezember 2019 r&#252;ckten wiederum die Fragen in den Vordergrund, wie sich
Berufsfelder und Arbeitsinhalte durch KI und die Mensch-Maschine-Interaktion ver&#228;ndern und welche
Auswirkungen KI auf Arbeitsbedingungen, Arbeitsschutz und Arbeitszeit hat. Am 16. Dezember 2019 ging es im ersten 
Teil der Sitzung um den Einfluss von KI auf die Arbeitsorganisation und -verwaltung und um Fragen der
Mitbestimmung sowie den Einsatz von KI f&#252;r die Personalgewinnung und bei der Beratung und Vermittlung. Im
zweiten Teil der Sitzung setzte sich die Projektgruppe intensiv mit KI und Lernen sowie den Auswirkungen von KI
in Schule und Hochschule auseinander. In der Sitzung am 13. Januar 2020 stand erneut der Themenkomplex 
Arbeit im Mittelpunkt. Es fand ein Gespr&#228;ch mit Vertreterinnen und Vertretern von Gewerkschaften und
Arbeitgeberverb&#228;nden sowie ausgew&#228;hlten Branchen und Betrieben statt, bei dem St&#228;rken und Schw&#228;chen sowie
Chancen und Risiken von KI in der Arbeitswelt diskutiert wurden. In den Sitzungen am 2. und 9. M&#228;rz 2020 wurden
zudem Vortr&#228;ge zum Thema KI und Forschung geh&#246;rt.
Die Sitzung am 10. Februar 2020, der Gro&#223;teil der Sitzungen am 2. und 9. M&#228;rz 2020 sowie die aufgrund der
Corona-Pandemie &#252;ber Videokonferenz abgehaltenen Sitzungen im Mai und Juni 2020 waren der intensiven
Textarbeit und Diskussion der Handlungsempfehlungen gewidmet. Die Handlungsempfehlungen wurden auf
1188 Siehe auch Kapitel 5.3.3 dieses Projektgruppenberichts [Handlungsempfehlungen].
1189 Eine Auflistung der zu den jeweiligen Sitzungen geladenen Anh&#246;rpersonen befindet sich in Kapitel 6.1. dieses
Projektgruppenberichts [Auflistung der in den Sitzungen angeh&#246;rten Expertinnen und Experten].
        
 
 
  
 
   
 
 
  
    
     
  
  
 
     
  
 
   
 
  
   
   
 
 
  
    
      
 
 
    
  
 
 
   
     
 
 
 
 
   
  
           
                                               
    
   
      
      
  
    
         
  
     
  
   
3
Grundlage der Formulierung von Zielen und der umfassenden Analyse des Status quo erarbeitet. Zudem
sammelte die Projektgruppe zahlreiche Beispiele und Anwendungsf&#228;lle (Use Cases), um den Einsatz von KI in den
drei Themenfeldern nachvollziehbar und konkreter darzustellen. Ziel war es, unter den
Projektgruppenmitgliedern weitgehend Konsens herzustellen. Zu Inhalten, die kontrovers diskutiert wurden und zu denen keine
gemeinsamen Formulierungen gefunden werden konnten, werden die unterschiedlichen Positionen dargestellt.1190 
Einf&#252;hrung
Grundlagen und Sachstandskl&#228;rung
Arbeit und das gesellschaftliche Bild von Arbeit unterliegen seit jeher einem stetigen Wandel. Ein Einflussfaktor
f&#252;r den Wandel ist seit Jahrzehnten die Digitalisierung von Arbeitsprozessen und Gesch&#228;ftsmodellen. KI-
Systeme sind ein Entwicklungsschritt der Digitalisierung.
Computergest&#252;tzte Arbeitssysteme haben schon im letzten Jahrhundert zun&#228;chst als Automaten in das
Arbeitsleben Einzug gehalten. Die Digitalisierung brachte weitere Entwicklungsschritte hervor, die die Arbeit pr&#228;gten. 
PCs wurden zum vielseitigen Werkzeug, Laptops zum Medium der Arbeit. Internetplattformen wurden zum
Instrument der Vermittlung von G&#252;tern, Dienstleistungen und Arbeit. Mobile Endger&#228;te entwickelten sich zum
st&#228;ndigen Begleiter und zu Assistenzsystemen. Fortschrittliche Datenanalysesysteme, die wachsende technische 
Leistungsf&#228;higkeit und die universelle Verf&#252;gbarkeit gro&#223;er Datenmengen brachten neue Analyse- und
Prognosesysteme hervor.1191 Die F&#228;higkeiten von Robotern werden laufend weiterentwickelt. Die F&#228;higkeiten von
Maschinen, kognitives Handeln zu imitieren, nehmen zu; in kontrollierter Form werden Maschinen schon heute
Teilentscheidungen &#252;berlassen &#8211; auch ohne den Einsatz von KI-Systemen.
Die bisherige pr&#228;gende Wirkung herk&#246;mmlicher Datenverarbeitungssysteme und die Wirkungen der
Digitalisierung auf die Arbeitswelt bleiben bestehen, auch ohne den Einsatz von KI-Systemen. Eine Untersuchung der
pr&#228;genden Wirkungen von KI-Systemen sollte ber&#252;cksichtigen, dass die Weiterentwicklungen aufeinander
aufbauen.
KI l&#228;sst sich zwar in eine auf Entwicklungsstufen abgestellte Betrachtungsweise einordnen, wobei die Frage &#8222;Ist
es noch Digitalisierung oder schon KI?&#8220; in der &#246;ffentlichen Diskussion nicht trennscharf beantwortet wird. KI ist
nur eine Teilmenge von Digitalisierung. In Debatten &#252;ber Systeme des Maschinellen Lernens werden, ungeachtet
der in der Enquete-Kommission verwendeten Bedeutung1192, h&#228;ufig technische Entwicklungen im Bereich der
Sensorik, der automatisierten Entscheidungen und der Maschinenkommunikation mit einbezogen. Wie Optionen
genutzt werden, um menschliche Arbeit zu pr&#228;gen, zu ersetzen oder zu schaffen, aufzuwerten oder zu entwerten,
zu steuern oder zu erleichtern, zu unterst&#252;tzen oder zu kontrollieren, zu belasten oder zu entlasten, dies wird
h&#228;ufig im Zusammenhang mit diesen Elementen der Digitalisierung beurteilt.
Dabei sind die Einflussfaktoren auf die Ver&#228;nderung der Arbeit noch weitaus vielf&#228;ltiger. So haben
beispielsweise Globalisierung, demografischer Wandel, Migration, Wertewandel, Bildungsver&#228;nderungen1193 und neue
Konzepte der Arbeitsorganisation ebenfalls eine pr&#228;gende Wirkung und h&#228;ufig sind monokausale
Erkl&#228;rungsmuster unzureichend. Weiterhin stehen ver&#228;nderte Nachhaltigkeitskonzepte, Besch&#228;ftigungsformen,
Diversifikationsanspr&#252;che und der Fachkr&#228;ftebedarf in Wechselwirkung mit der Transformation von Arbeit. All diese
Einflussfaktoren korrespondieren mit den Ver&#228;nderungen, die KI im Arbeitsleben ausl&#246;st. 
Die bisherigen Wirkungen der Digitalisierung beschrieb bereits im Jahr 2013 die Enquete-Kommission &#8222;Internet 
und digitale Gesellschaft&#8220;.1194 Die Entbetrieblichung der Arbeit1195, die Steigerung ihrer Verlagerungsf&#228;higkeit, 
der Bedeutungszuwachs f&#252;r Pers&#246;nlichkeitsrechte und die Erosion der Pr&#228;gung durch tarifliche und
betriebsr&#228;tliche Normung haben Fragen aufgeworfen, auf die bis heute keine ersch&#246;pfende Antwort gefunden wurde.
1190 Eine Auflistung der Mitglieder der Projektgruppe befindet sich Kapitel 6.2 dieses Projektgruppenberichts [Auflistung der Mitglieder
der Projektgruppe].
1191 Vgl. Schr&#246;der (2016): Die digitale Treppe.
1192 Siehe auch Kapitel 1 des Mantelberichts [Begriffskl&#228;rung K&#252;nstliche Intelligenz].
1193 Vgl. Bundesministerium f&#252;r Arbeit und Soziales, Abteilung Grundsatzfragen des Sozialstaats, der Arbeitswelt und der sozialen 
Marktwirtschaft (2016): Weissbuch Arbeiten 4.0.
1194 Vgl. Achter Zwischenbericht der Enquete-Kommission &#8222;Internet und digitale Gesellschaft&#8220;, Wirtschaft, Arbeit, Green IT, 
Bundetsagsdrucksache 17/12505.
1195 Der Begriff &#8222;Entbetrieblichung&#8220; beschreibt die Verlagerung von Wertsch&#246;pfung &#252;ber das Netz auf Personen und Leistungsprozesse,
die au&#223;erhalb des herk&#246;mmlichen, r&#228;umlich fixierten Betriebes ans&#228;ssig sind, bzw. Telearbeiterinnen und Telearbeiter,
Freiberuflerinnen und Freiberufler, Crowdsourcees und Arbeitsvermittlungsplattformen.
Gleichwohl bleiben praxisbew&#228;hrte Gestaltungskonzepte der Digitalisierung bedeutsam f&#252;r die Suche nach
Gestaltungsans&#228;tzen f&#252;r KI-Systeme.
Spezifische Merkmale von KI-Systemen verlangen nach spezifischen Gestaltungsans&#228;tzen in der Arbeitswelt. Zu
den besonderen Herausforderungen bei KI z&#228;hlt die immanente Komplexit&#228;t und teilweise Intransparenz
lernender Maschinen und die M&#246;glichkeit, dass durch sie menschliche Arbeit ersetzt und entwertet werden k&#246;nnte.
Gleichzeitig bergen lernende Maschinen auch gro&#223;e Potenziale f&#252;r die Arbeit: Sie k&#246;nnen sich selbst optimieren
und sehr gro&#223;e Datenmengen schnell analysieren. Dies kann genutzt werden, um Prozesse zu verbessern, Arbeit
zu erleichtern und sie flexibler zu gestalten. Von Menschen getroffene Entscheidungen basieren oft auf Faktoren 
wie beispielsweise Erfahrung, Intuition oder Mitgef&#252;hl. KI-Systeme k&#246;nnen &#8211; in manchen F&#228;llen &#8211; zwar darauf
trainiert werden, auf Emotionen von Menschen zu reagieren, ihre Entscheidungslogik ist aber anders. Sie folgt
entweder von Menschen festgelegten Regeln oder die KI analysiert gro&#223;e Datenmengen und identifiziert Muster, 
auf Basis derer sie dann eine Handlungsoption ausw&#228;hlt. 
Ethische Fragen stellen sich in der Arbeit mit KI in besonderer Weise, weil beim Schutz der Pers&#246;nlichkeitsrechte
ber&#252;cksichtigt werden muss, dass Besch&#228;ftigte in einem Abh&#228;ngigkeitsverh&#228;ltnis stehen, das sie schutzbed&#252;rftig
macht. Mehrere Einsatzm&#246;glichkeiten von KI-Systemen betreffen die Pers&#246;nlichkeitsrechte der Besch&#228;ftigten
und bed&#252;rfen daher ihrer Mitbestimmung. Dies trifft beispielsweise auf Systeme zu, welche die Leistungen der
Besch&#228;ftigten kontrollieren. Aber auch dar&#252;ber hinaus gibt es KI-Anwendungen, die Pers&#246;nlichkeits- und
Kontaktprofile erstellen und Gesundheitswerte, Einstellungen und Merkmale berufst&#228;tiger Menschen erheben,
verarbeiten oder nutzen.1196 Das verlangt nach ad&#228;quaten Schutzregeln und innovativen Gestaltungsprozessen. 
Auch wegen der Dynamik und der unterschiedlichen Verwendungszwecke von KI wird es f&#252;r den Gesetzgeber
nicht sinnvoll und m&#246;glich sein, universell und vorausschauend allen mit KI zusammenh&#228;ngenden
Gestaltungsanforderungen gerecht zu werden. Er muss sich auf wesentliche Rahmenbedingungen und die Bef&#228;higung der
Normsetzungsakteure zu Gestaltungsinitiativen konzentrieren. Deshalb kommen auf die Akteure der
betrieblichen und wirtschaftlichen Mitbestimmung, des Arbeitsschutzes, der Industrienormung, der Gewerbeaufsicht, der
Berufsgenossenschaften, der Handwerks- und Handelskammern, der Forschung, der Bildung und des
Tarifvertragswesen neue Aufgaben zu.1197 Die Folgeabsch&#228;tzung und das Monitoring von Praxiserfahrung mit KI im
Arbeitsleben sind dabei unabdingbar, um gute Gestaltungsbeispiele zu identifizieren und Vergleichsma&#223;st&#228;be zu
entwickeln. Sachkunde sowie wirksame und ausreichende Mitbestimmungsrechte sind erfolgsrelevant.
Ein nationaler und ein internationaler Dialog zum menschenzentrierten Einsatz von KI in der Arbeitswelt1198 
muss erkennbar auf die verantwortungsvolle und gemeinwohlorientierte Verbreitung der Technik ausgerichtet
werden und am Ziel, gute Arbeit hier und auf globaler Ebene zu schaffen. Eine klare Zielvorstellung ist auch
aufgrund der zugleich skeptischen und offenen Haltung vieler Erwerbst&#228;tiger zum KI-Einsatz erforderlich.
Diese resultiert auch aus unterschiedlichen und nicht immer positiven Erfahrungen mit der bisherigen
Digitalisierung von Betrieben und Prozessen. Eine beachtliche Zahl von Besch&#228;ftigten nimmt eine gestiegene psychische 
Belastung durch eine Steigerung von Arbeitsdichte, Arbeitsmenge, Geschwindigkeit, Erreichbarkeit und
Multitasking wahr. Steigt die Autonomie in der Disposition von Arbeitsort und -zeit, sinkt die durchschnittlich
wahrgenommene Belastung.1199 Auch die Einstellungen zu den verschiedenen KI-Anwendungen differieren.
Autonome Entscheidungen von Computern bei der &#220;berpr&#252;fung der Rechtschreibung w&#252;rden Erwerbst&#228;tige zu
53 Prozent akzeptieren, aber bei der Vorauswahl von Stellenbewerberinnen und Stellenbewerbern nur zu 6
Prozent.1200 
1196 Vgl. Bundesministerium f&#252;r Arbeit und Soziales, Abteilung Grundsatzfragen des Sozialstaats, der Arbeitswelt und der sozialen 
Marktwirtschaft (2016): Weissbuch Arbeiten 4.0, S. 142.
1197 Siehe auch Kapitel 5.4 dieses Projektgruppenberichts [Gestaltungsinstrumente und Gestaltungsakteure].
1198 Vgl. Bundesregierung (2018): Strategie K&#252;nstliche Intelligenz der Bundesregierung.
1199 Vgl. Institut DGB-Index Gute Arbeit (2016): DGB-Index Gute Arbeit Der Report 2016; Roth (2017): Digitalisierung und
Arbeitsqualit&#228;t Eine Sonderauswertung auf Basis des DGB-Index Gute Arbeit 2016 f&#252;r den Dienstleistungssektor: Demnach gibt fast die
H&#228;lfte der in (sehr) hohem Ma&#223; digital Arbeitenden im Dienstleistungssektor an, die Arbeitsbelastung sei f&#252;r sie durch die
Digitalisierung insgesamt gr&#246;&#223;er geworden. Die Mehrbelastung h&#228;ngt insbesondere mit einer Steigerung der Arbeitsmenge (56 Prozent) und 
mit erh&#246;htem Multitasking (57 Prozent) zusammen. 59 Prozent der Befragten geben an, sehr h&#228;ufig oder oft unter Zeitdruck zu stehen.
47 Prozent berichten von einem Anstieg der &#220;berwachung und Kontrolle der Arbeit. Generell deuten die Ergebnisse darauf hin, dass 
die psychischen Belastungen im Zuge der Digitalisierung steigen, die k&#246;rperlichen Belastungen hingegen geringer werden. Dagegen
haben sich die Entscheidungsspielr&#228;ume der Besch&#228;ftigten im Durchschnitt nur leicht erweitert (von einer Vergr&#246;&#223;erung berichten 
25 Prozent). Wo die Arbeitsbedingungen insgesamt schlecht sind, verengen sich die Spielr&#228;ume; f&#252;r F&#252;hrungskr&#228;fte und Besch&#228;ftigte
mit (hoch-)komplexen T&#228;tigkeiten vergr&#246;&#223;ern sie sich &#252;berdurchschnittlich.
1200 Vgl. Grzymek und Puntschuh (2019): Was Europa &#252;ber Algorithmen wei&#223; und denkt &#8211; Ergebnisse einer repr&#228;sentativen
Bev&#246;lkerungsumfrage, Abbildung 8 Akzeptanz von Algorithmen.
Einf&#252;hrende Beispiele bzw. Anwendungsf&#228;lle (Use Cases)
Ziel dieses Unterkapitels ist es, einen ersten &#220;berblick &#252;ber bereits bestehende KI-Anwendungen im
Zusammenhang mit Arbeit und Bildung zu geben und die Bandbreite der Anwendungsm&#246;glichkeiten darzustellen, ohne sie
abschlie&#223;end zu bewerten. Die angef&#252;hrten Beispiele befinden sich zum Teil noch in der Entwicklung und sind
nicht notwendigerweise technisch ausgereift. Um dem rasanten technischen Fortschritt gerecht zu werden, greift
das Unterkapitel auch Pilotprojekte auf, bei denen sich in Zukunft erweisen muss, ob und inwieweit sie auch im
Regelbetrieb Bestand haben. Mitunter ist die Umsetzung der Anwendungen technisch, wissenschaftlich,
&#246;konomisch oder gesellschaftlich umstritten. Eine Auseinandersetzung mit der politischen Bewertung und den
Gestaltungsoptionen von KI-Anwendungen, z. B. eine Auseinandersetzung mit Fragen der Arbeits- und Lernqualit&#228;t
sowie des Datenschutzes und -missbrauchs, findet an anderen Stellen im Bericht der Enquete-Kommission statt,
so z. B. in Kapitel 5 dieses Projektgruppenberichts [Status quo und Handlungsempfehlungen: KI und Arbeit,
Bildung, Forschung]. 
3.2.1 Beispiele f&#252;r KI-Anwendungen im betrieblichen Einsatz oder in der Erprobung
KI birgt das Potenzial, nicht nur die Arbeitsprozesse einzelner Arbeitnehmerinnen und Arbeitnehmer, sondern
auch gesamte betriebsinterne Prozesse und Gesch&#228;ftsmodelle von Unternehmen umzugestalten. KI-basierte
Technologien ver&#228;ndern sowohl die Suche nach neuen Arbeitskr&#228;ften als auch die Arbeitsrealit&#228;t von
Besch&#228;ftigten. So &#252;bernimmt KI-basierte Software in einigen Betrieben bereits heute den Erstkontakt mit Bewerberinnen
und Bewerbern sowie Kundinnen und Kunden oder bearbeitet Standardf&#228;lle im Mitarbeiter- und Kundendialog.
KI-Anwendungen k&#246;nnen einen Beitrag zur Optimierung und Erleichterung von Arbeitsabl&#228;ufen leisten und
Mitarbeiterinnen und Mitarbeiter dabei unterst&#252;tzen, angesichts gro&#223;er Informationsmengen den &#220;berblick &#252;ber
Informationsfl&#252;sse und Arbeitsschritte zu behalten. Zudem kann KI-Einsatz den Anteil immer wiederkehrender
Aufgaben an der Arbeitszeit von Mitarbeiterinnen und Mitarbeitern senken und Aufgaben, die z. B. in
besonderem Ma&#223;e Kreativit&#228;t oder Empathie erfordern, ins Zentrum des Arbeitsalltags r&#252;cken. Mit diesem Potenzial, den
Arbeitsalltag zu optimieren, kann jedoch gleichzeitig das Risiko einer Arbeitsverdichtung, Vereinzelung oder
Arbeitsentfremdung zulasten der Arbeitnehmerschaft einhergehen. In bestimmten Einsatzszenarien kann die
Anwendung von KI gar die Zunahme immer wiederkehrender und monotoner Aufgaben nach sich ziehen. 
Im Folgenden werden Technologien vorgestellt, die bereits in einer Vielzahl von Arbeitsst&#228;tten verschiedenster
Wirtschaftssektoren Arbeitsprozesse erg&#228;nzen oder die sich in Pilotprojekten als vielversprechend erwiesen
haben.
3.2.1.1 Assistenz- und Serviceroboter
Assistenz- und Serviceroboter haben das Potenzial, die Arbeit von Mitarbeiterinnen und Mitarbeitern zu erg&#228;nzen
und ihnen einzelne Aufgaben abzunehmen. Aus dem bisherigen Einsatzkontext heraus erscheint dies vor allem
(aber nicht nur) f&#252;r Routine- oder k&#246;rperlich intensive Aufgaben relevant.
Basierend auf einer Warenbeschilderung, die f&#252;r Roboter identifizierbare elektromagnetische Wellen entsendet,
k&#246;nnen KI-basierte Inventurhelfer im Einzelhandel Fehlbest&#228;nde erfassen und entsprechende Waren automatisch
nachbestellen.1201 Mithilfe derselben Technologie orientieren sich Serviceroboter im Verkaufsbereich und
erg&#228;nzen die Servicearbeit des Verkaufspersonals.1202 Erfolge in der Grundlagenforschung zur Bilderkennung erh&#246;hen
ihr Einsatzpotenzial.1203 Auch in der Logistik k&#246;nnen Roboter den Arbeitsalltag erg&#228;nzen. Laut Daten der
Bundesanstalt f&#252;r Arbeitsschutz und Arbeitsmedizin (BAuA) sind Besch&#228;ftigte in Logistikberufen besonders
gef&#228;hrdet, Muskel-Skelett-Erkrankungen zu erleiden, denn jede und jeder zweite Besch&#228;ftigte im Bereich Logistik hat
h&#228;ufig schwere Lasten zu bewegen.1204 Der Einsatz von Logistikrobotern im Lagerbetrieb kann Mitarbeiterinnen
und Mitarbeiter bei der Einlagerung und dem Kommissionieren sowie beim Verstauen und Heraussuchen von
Waren unterst&#252;tzen. Mittels feiner Sensorik erkennen Logistikroboter, wenn Mitarbeiterinnen oder Mitarbeiter
1201 So z. B. der Roboter Tory der Firma MetraLabs, im Einsatz bei der Modekette Adler, vgl. Henkel (2019): Adler Modem&#228;rkte: 40 neue 
Service-Roboter erfolgreich im Einsatz.
1202 Ein Beispiel daf&#252;r ist der Roboter Paul von Unity Robotics, eingesetzt bei der MediaMarktSaturn Retail Group, vgl. Weidemann 
(2017): Roboter als Verk&#228;ufer: Media Markt und Saturn gehen neue Wege.
1203 Vgl. ifm electronic gmbh (2019): Erwischt: O3X in Walmart.
1204 Vgl. Bundesanstalt f&#252;r Arbeitsschutz und Arbeitsmedizin (2018): Liefern, lagern und bef&#246;rdern &#8211; Arbeitsbedingungen in Verkehrs-
und Logistikberufen.
ihren Weg kreuzen, passen ihre Laufwege entsprechend an und wahren so die Betriebssicherheit im h&#228;ufig
hektischen Lagerbetrieb.1205 Ein anderer Forschungsansatz verfolgt die Unterst&#252;tzung beim Heben schwerer Lasten 
oder beim Arbeiten in unergonomischen Positionen, etwa &#252;ber Kopf, durch den Einsatz von Exoskeletten, das
hei&#223;t &#228;u&#223;eren St&#252;tzstrukturen zur physischen Ergonomieunterst&#252;tzung.1206 
Bestehende Pilotprojekte demonstrieren das Potenzial, das Servicerobotik insbesondere f&#252;r die Unterst&#252;tzung
von Mitarbeiterinnen und Mitarbeitern in der station&#228;ren Pflege mit sich bringt.1207 Laut einer umfangreichen
Bedarfsanalyse des vom BMBF gef&#246;rderten Projekts zur F&#246;rderung des Wissenstransfers f&#252;r eine aktive
Mitgestaltung des Pflegesektors durch Mikrosystemtechnik (WiMi-Care) w&#252;nscht sich das Pflegepersonal vor allem
in den Bereichen Logistik und Hauswirtschaft sowie bei Hebevorg&#228;ngen oder Dokumentationst&#228;tigkeiten
Unterst&#252;tzung durch Serviceroboter-Technologien.1208 Wichtiger Bestandteil der Arbeit von Altenpflegekr&#228;ften ist
z. B., daf&#252;r zu sorgen, dass die Bewohnerinnen und Bewohner einer Pflegestation genug trinken. Pilotprojekte
zeigen, wie moderne Serviceroboter in einem Trinkprotokoll die Fl&#252;ssigkeitsaufnahme von Bewohnerinnen und
Bewohnern dokumentieren und gezielt diejenigen ansprechen k&#246;nnen, die noch nicht ausreichend getrunken
haben.1209 Pflegekr&#228;fte sind in besonderem Ma&#223;e k&#246;rperlichen Belastungen wie schwerem Heben und Tragen
ausgesetzt.1210 Der Piloteinsatz von Transportrobotern zeigt, dass sie Pflegekr&#228;fte in k&#246;rperlich anstrengenden
T&#228;tigkeiten wie dem Transport von Wasserkisten oder Schmutzw&#228;sche unterst&#252;tzen k&#246;nnen. Gleichzeitig sind sie
in der Lage, mittels intelligenter Sensorik nachts ungew&#246;hnliche Bewegungen auf dem Flur von
Pflegeeinrichtungen zu registrieren und das Pflegepersonal so auf potenzielle Gefahrensituationen aufmerksam zu machen.1211 
Aufgrund des hohen Potenzials von Assistenz&#8208; und Servicerobotik gerade in der Pflege wurde dazu bereits ein
neuer F&#246;rderschwerpunkt gebildet.1212 
Auch die Arbeit von Rettungskr&#228;ften kann durch intelligente Robotik erleichtert werden. In ihrem t&#228;glichen
Einsatz f&#252;r die Lebensrettung sind Rettungskr&#228;fte oftmals lebensfeindlichen Bedingungen ausgesetzt, z. B. bei
Br&#228;nden in Industrieanlagen, &#220;berschwemmungen oder Lawinenabg&#228;ngen. Aktuelle Projekte trainieren intelligente
Roboter zur Unterst&#252;tzung von Rettungskr&#228;ften, indem sie Lage- und Gef&#228;hrdungsinformationen liefern oder den
Zustand von Opfern und den sich im Einsatz befindenden Rettungskr&#228;ften &#252;berwachen.1213 
3.2.1.2 Wissens- und Assistenzsysteme
In den modernen Fertigungsst&#228;tten der Industrie 4.0 k&#246;nnen zuk&#252;nftig &#252;ber Sensorik rund um die Uhr
Sensordaten erhoben werden. KI-basierte Software macht diese Daten nutzbar. So gewonnene Erkenntnisse k&#246;nnen daf&#252;r
eingesetzt werden, die Arbeitsschritte von Mitarbeiterinnen und Mitarbeitern besser zu planen und effizienter
auszugestalten. Die Auswirkungen auf die Arbeitsrealit&#228;t sind dabei je nach Arbeitsfeld sehr unterschiedlich.
Einerseits kann KI-Einsatz die Autonomie der Besch&#228;ftigten erh&#246;hen. Andererseits kann KI auch technologische
M&#246;glichkeiten er&#246;ffnen, diese Autonomie zu begrenzen. Erforscht wird dies derzeit u. a. in
Anwendungsszenarien der Projekte von &#8222;Zukunft der Arbeit&#8220; des BMBF.1214 
Pilotprojekte zeigen, wie KI-basierte Assistenzsysteme per Mixed-Reality-Interface, das hei&#223;t der
Zusammenf&#252;hrung von digitaler und analoger Welt auf dem Tablet oder per Datenbrille, ihren Weg in die Fertigungsstelle
1205 Dies gilt z. B. f&#252;r den Logistikroboter TORU, im Piloteinsatz im Zalando-Logistikzentrum Erfurt, vgl. Zalando SE (2018): Zalando
testet Logistikroboter TORU in Erfurt.
1206 Vgl. Deutsches Forschungszentrum f&#252;r K&#252;nstliche Intelligenz GmbH (DFKI) Robotics Innovation Center (2020): Exoskeleton active
(Capio).
1207 Zum Einsatz von intelligenten Assistenzrobotern in der Pflege siehe auch das Kapitel 3.2 des Berichts der Projektgruppen &#8222;KI und 
Gesundheit&#8220; [KI-Anwendungen in der Pflege].
1208 Zum Projekt WiMi-Care des Fraunhofer IPA vgl. Fraunhofer-Institut f&#252;r Produktionstechnik und Automatisierung IPA: WiMi-Care:
F&#246;rderung des Wissenstransfers f&#252;r eine aktive Mitgestaltung des Pflegesektors durch Mikrosystemtechnik.
1209 Vgl. Fraunhofer-Institut f&#252;r Produktionstechnik und Automatisierung IPA: Produktblatt &#8222;Care-O-bot&#174; 3&#8220;.
1210 Vgl. Bundesanstalt f&#252;r Arbeitsschutz und Arbeitsmedizin (2014): Arbeit in der Pflege &#8211; Arbeit am Limit? Arbeitsbedingungen in der
Pflegebranche; Kehl (2018): Robotik und assistive Neurotechnologien in der Pflege &#8211; gesellschaftliche Herausforderungen.
1211 Ein Beispiel daf&#252;r ist der vom Ludwigsburger Unternehmen MLR System entwickelte Roboter Casero.
1212 Zum F&#246;rderschwerpunkt &#8222;Robotische Systeme f&#252;r die Pflege&#8220; vgl. Bundesministerium f&#252;r Bildung und Forschung (2018):
Bekanntmachung. Richtlinie zur F&#246;rderung von Forschung und Entwicklung auf dem Gebiet &#8222;Robotische Systeme f&#252;r die Pflege&#8220;.
1213 Ein Training robotischer Systeme f&#252;r die Verwendung bei Rettungseins&#228;tzen findet derzeit am DFKI statt, vgl. Plattform Lernende
Systeme Arbeitsgruppe 7 &#8211; Lebensfeindliche Umgebungen: KI-Anwendungsszenario &#8211; Schnelle Hilfe beim Rettungseinsatz.
1214 Vgl. z. B. das Future Work Lab in Stuttgart (Fraunhofer&#8208;IAO), weitere Informationen dazu unter: https://futureworklab.de/ (zuletzt
abgerufen am 9. September 2020), oder das Projekt &#8222;SmartAIWork &#8208; Zukunft der Betriebsabl&#228;ufe: Sachbearbeitung zukunftsorientiert
gestalten mit Automatisierung durch K&#252;nstliche Intelligenz&#8220;, weitere Informationen dazu unter: https://www.smart-ai-work.de/ 
(zuletzt abgerufen am 9. September 2020).
finden und Mitarbeiterinnen und Mitarbeiter in der Produktion z. B. bei der Interaktion mit Maschinen
unterst&#252;tzen k&#246;nnen.1215 Auf der Basis von Sensordaten der Maschinen liefert die Software den Mitarbeiterinnen und
Mitarbeitern unterst&#252;tzende Informationen zu der Maschine, an der sie gerade arbeiten. Nach Zusammenf&#252;hrung 
von Maschinendaten mit anderen Datens&#228;tzen wie Betriebsanleitungen, Schadensdokumentationen oder
St&#252;cklisten kann KI-basierte Software Zusammenh&#228;nge erkennen. So l&#228;sst sich beispielsweise die fehlerhafte
Ausf&#252;hrung von Montageschritten aufdecken und durch die Einblendung detaillierter Informationen zu ihrer Korrektur
per Assistenzsystem durch die Mitarbeiterin oder den Mitarbeiter zeitnah ausbessern. Allerdings sollte gerade
bei Systemen, die der F&#228;higkeitserweiterung dienen und/oder die den Charakter eines Tutoriums haben, darauf
geachtet werden, dass sie weder zu einer Mehrbelastung f&#252;hren noch dass eine Unterforderung stattfindet. Dazu
ist es hilfreich, dass eine gute Balance zwischen Unterst&#252;tzung und Handlungsspielraum der jeweiligen Nutzerin
oder des jeweiligen Nutzers gefunden wird. Viele Betriebe stehen vor der Herausforderung, dass sie in den
kommenden Jahren Teile ihrer Belegschaft altersbedingt verlieren werden. KI-basierte Wissenssysteme k&#246;nnen in 
Zukunft dazu beitragen, einem drohenden Wissensverlust entgegenzuwirken, w&#228;hrend Assistenzsysteme einen
Beitrag dazu leisten k&#246;nnen, die mangelnde Praxiskenntnis neuer Mitarbeiterinnen und Mitarbeiter
auszugleichen. 
In Pilotprojekten kommen KI-basierte Assistenzsysteme z. B. &#252;ber Datenbrillen auch in der Logistik zum
Einsatz. Diese Technik unterst&#252;tzt das nat&#252;rliche Sehen von Mitarbeiterinnen und Mitarbeitern. Dies birgt das
Potenzial, ihr Navigationsverm&#246;gen sowie die schnelle Informationserfassung beim Zusammenstellen von
Sendungen unter Zeitdruck zu verbessern. Beispielsweise kann eine Staplerfahrerin oder ein Staplerfahrer durch digital
eingeblendete Pfeile auf effizientestem Wege zum n&#228;chsten Artikel geleitet werden, mithilfe eines
Assistenzsystems die korrekte Produktnummer schneller erkennen und vor physischen Gefahren im Lagerraum gewarnt
werden.1216 Gerade aus dem Logistikbereich wird aber vonseiten der Arbeitnehmerschaft von negativen Erfahrungen 
berichtet, z. B. zunehmender Arbeitsverdichtung durch strenge Taktung der Arbeitsschritte, Monotonie,
Leistungskontrolle und fehlender Autonomie durch den Einsatz effizienzorientierter KI-Systeme. 1217 So nutzt z. B. 
der Amazon-Konzern schon l&#228;nger KI, um Bestellabl&#228;ufe und Lieferzeiten in seinen Logistikzentren
hocheffizient zu organisieren. Die Software optimiert jedoch nicht nur die Laufwege der Mitarbeiterinnen und
Mitarbeiter, sie misst auch, wie produktiv die Angestellten arbeiten.1218 Besch&#228;ftigte an den Amazon-Logistik-Standorten 
in Deutschland m&#252;ssen innerhalb einer vorgegebenen Taktzeit eine festgelegte Abfolge von Arbeitsschritten
ausf&#252;hren (&#8222;Standard Work&#8220;). Jeder Arbeitsschritt wird von dem System vorgegeben und digital &#252;berwacht.
Unterschiede unter den Menschen, wie Alter, Gr&#246;&#223;e oder Gesundheitszustand, werden nicht ber&#252;cksichtigt.
Besch&#228;ftigte berichten, sich als Teil einer Maschine zu f&#252;hlen.1219 Laut der Vereinten Dienstleistungsgewerkschaft
(ver.di) hat diese Arbeitsweise negative Auswirkungen auf die psychische und physische Gesundheit der
Besch&#228;ftigten.1220 
3.2.1.3 Prozessoptimierung durch Predictive Analysis1221 
Durch KI-basierte Software werden Maschinen- und Sensordaten nutzbar. Die von der Software in einer
Datenmenge erkannten Muster k&#246;nnen als Grundlage f&#252;r die Optimierung betriebsinterner Prozesse dienen.
1215 Ein solches Pilotprojekt ist beispielsweise das Verbundprojekt APPsist, das vom BMWi gef&#246;rdert wird, vgl. Fraunhofer IAO,
Forschungsbereich Cognitive Engineering and Production: &#8222;APPsist&#8220;: Wissens- und Assistenzsysteme in der smarten Produktion.
1216 Vgl. z. B. die SAP-Pilotanwendung im Lager der Bechtle AG, vgl. Steck (2017): Augmented Reality in der Logistik: Wegweiser in
der Brille.
1217 Darstellung Anka Grosch (Betriebsrat Amazon Logistikzentrum Leipzig) in der Sitzung der Projektgruppe KI und Arbeit, Bildung,
Forschung am 13. Januar 2020.
1218 Vgl. Kr&#228;hling (2014): Behandeln Sie die Amazon-Mitarbeiter/innen fair!; Lecher (2019): How Amazon automatically tracks and
fires warehouse workers for &#8216;productivity&#8217;; Bort (2019): Bericht: Amazon nutzt ein System, das automatisch K&#252;ndigungen f&#252;r
unproduktive Mitarbeiter schreibt.
1219 Vgl. Kr&#228;hling (2014): Behandeln Sie die Amazon-Mitarbeiter/innen fair!.
1220 Laut ver.di liegt die Krankenquote an manchen Tagen teilweise bei etwa 20 Prozent, an manchen Tagen bei mehr als 20 Prozent.
Muskel- und Skeletterkrankungen und psychische Erkrankungen sind dabei vorherrschend. Vgl. Kr&#228;hling (2014): Behandeln Sie die 
Amazon-Mitarbeiter/innen fair!.
1221 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 3.2.1.3 des Berichts der
Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220; (&#8222;Prozessoptimierung durch Predictive Analysis &#8220;) der Abgeordneten Dr. Petra Sitte
und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo].
Im Rahmen der Predictive Analysis, das hei&#223;t der vorausschauenden Analyse, wird durch KI eine
vorausschauende Wartung in vielen Industriefeldern m&#246;glich.1222 Mittels KI-basierter Echtzeitanalyse von Zeitreihen-,
Nutzungs- und Sensordaten kann der Zeitpunkt, an dem Wartungsarbeiten an einer Maschine notwendig werden,
besser eingesch&#228;tzt werden. So k&#246;nnten Mitarbeiterinnen und Mitarbeiter auf Basis dieser Informationen
Wartungstermine fr&#252;hzeitig einplanen. Kostspielige Ausfallzeiten k&#246;nnten reduziert1223 und Dienstpl&#228;ne sowie
Touren der Reparaturteams verl&#228;sslicher gestaltet werden, indem KI-Systeme durch ihre Analyse Monteurinnen und
Monteure bei der Suche nach den zu reparierenden oder zu ersetzenden Teilen unterst&#252;tzen. Andere Beispiele
effizienzsteigernder KI-Eins&#228;tze im Dienstleistungssektor k&#246;nnten Hinweise auf auff&#228;llige Schadensmeldungen
bei Versicherungen sein, die der genaueren Untersuchung bed&#252;rfen,1224 oder der Einsatz sogenannter Legal-Tech-
Programme1225, die die anwaltliche Arbeit erg&#228;nzen, um in k&#252;rzester Zeit gro&#223;e Mengen an Vertr&#228;gen zu
analysieren sowie die potenziellen Erfolgsaussichten von Klagen abzusch&#228;tzen.1226 Auch in der Landwirtschaft k&#246;nnte
der Einsatz von KI-Systemen zu einer Optimierung von Prozessen beitragen und damit das Berufsbild des
Landwirts bzw. der Landwirtin dahingehend ver&#228;ndern, dass weitere Anforderungen an das Technikverst&#228;ndnis und
die Analysef&#228;higkeit gestellt werden. In allen F&#228;llen hat die Technologie das Potenzial, die Arbeitsrealit&#228;t der
Besch&#228;ftigten grundlegend zu ver&#228;ndern.1227 
Auch im Einzelhandel macht KI Sensordaten f&#252;r Prozessoptimierung und innovative Kommunikation nutzbar. 
Im Umfeld des Einzelhandels entstehen permanent Informationen, die eine sofortige Reaktion der
Mitarbeiterinnen und Mitarbeiter erfordern. Indem KI-basierte Software Sensor-, Kalender- und Service-Daten einbezieht, ist 
sie in der Lage, die Laufwege von Mitarbeiterinnen und Mitarbeitern zu optimieren. &#220;ber
Kommunikationsplattformen k&#246;nnen entsprechende Anweisungen direkt auf mobile Endger&#228;te &#252;bermittelt werden, die die
Mitarbeiterinnen und Mitarbeitern tragen, wie z. B. Smartwatches. Mithilfe der Software k&#246;nnen Arbeitsschritte priorisiert
werden.1228 Derartigen Optimierungsm&#246;glichkeiten steht stets die Herausforderung gegen&#252;ber, im Rahmen der
Leistungsf&#228;higkeit der Mitarbeiterinnen und Mitarbeiter zu bleiben und ihre Autonomie nicht &#252;ber Geb&#252;hr
einzuschr&#228;nken. 
3.2.1.4 KI-basierte Chatbots
Im Folgenden werden zwei Einsatzarten von Sprachtechnologie betrachtet, die sich darin ma&#223;geblich
unterscheiden, dass Chatbots zu inhaltlichen Dialogen eingesetzt werden, w&#228;hrend Sprachanalyse sich in der Regel mit 
oberfl&#228;chlichen Eigenschaften der Sprache wie der akustischen Qualit&#228;t oder der Satzstruktur befasst. Erstere
geh&#246;ren im Kern zum Gebiet Natural Language Processing, das hei&#223;t der Erfassung nat&#252;rlicher Sprache und ihrer
computerbasierten Verarbeitung durch Algorithmen. Letztere ist eine psychologisch motivierte Art der
Sprachsignalverarbeitung. In der Praxis k&#246;nnen beispielsweise in Bewerbungsverfahren beide Technologien zum
Einsatz kommen. In Chatbots werden an verschiedenen Stellen verschiedene KI-Technologien verwendet. W&#228;hrend
die meisten Chatbots im Kern einem mehr oder weniger starren Skript folgen und damit lediglich auf m&#246;gliche
Nutzereingaben (h&#228;ufig nur Signalw&#246;rter), die im Vorfeld definiert wurden, vordefinierte Antwortm&#246;glichkeiten 
haben, spielen Techniken des Maschinellen Lernens auch in diesem Bereich eine immer gr&#246;&#223;ere Rolle.
KI-basierte Chatbots sind in Betriebsprozessen vielseitig einsetzbar; aufgrund ihrer F&#228;higkeit, Erstkontakte und
standardisierte Anfragen zu &#252;bernehmen, werden sie verst&#228;rkt in Personalabteilungen genutzt. Bestehende
Anwendungsf&#228;lle zeigen, dass in die Unternehmens-Webseite integrierte KI-basierte Chatbots potenziellen
Bewerberinnen und Bewerbern Fragen beantworten und ihnen auch die auf ihr individuelles Profil passenden
Stellenangebote aus der entsprechenden Datenbank herausfiltern k&#246;nnen.1229 Gleichzeitig k&#246;nnen sie die Anfragen be-
1222 In Verbundforschungsprojekten von &#8222;Mikroelektronik f&#252;r Industrie 4.0&#8220; des BMBF werden neue Systeme entwickelt, die den Einsatz
von KI-Systemen in der industriellen Produktion steigern k&#246;nnen; vgl. Bundesministerium f&#252;r Bildung und Forschung (2019):
Bekanntmachung. Richtlinie zur F&#246;rderung von Forschungsinitiativen auf dem Gebiet der &#8222;Mikroelektronik f&#252;r Industrie 4.0 (Elektronik I4.0)&#8220;.
1223 So geschieht es beispielsweise bei Lufthansa, vgl. Schmal und Werner (2018): From Prototype to Operative Software with Rapid
Miner.
1224 Vgl. adesso SE: Betrugserkennung f&#252;r Versicherer.
1225 Vgl. Kind et al. (2019): Legal Tech &#8211; Potenziale und Wirkungen.
1226 Vgl. Brien (2018): KI schl&#228;gt 20 Anw&#228;lte bei der Analyse von Vertr&#228;gen klar.
1227 Vgl. Spacenus GmbH: Spacenus.
1228 Dies ist z. B. mithilfe der Plattform von ReAct m&#246;glich, weitere Informationen dazu unter: https://react-now.com/call-to-action/ 
(zuletzt abgerufen am 2. September 2020).
1229 Dies kann der Chatbot Allie der Allianz Deutschland AG, vgl. Allianz SE (2017): The Future of Work &#8211; Harry und Allie.
reits angestellter Mitarbeiterinnen und Mitarbeiter teils direkt beantworten, teils an die zust&#228;ndigen
Mitarbeiterinnen und Mitarbeiter der Personalabteilung weiterleiten.1230 Somit k&#246;nnte die Personalabteilung zu weiten
Teilen von der Beantwortung immer wieder auftretender Standardfragen befreit werden und die M&#246;glichkeit
erhalten, mehr Zeit in die individuelle Mitarbeiterbetreuung oder das Vorantreiben einer nachhaltigen Personalpolitik 
zu investieren. Die Verwendung KI-basierter Chatbots kann aber auch zu Stellenabbau f&#252;hren.
Auch der Kundenkontakt kann durch den Einsatz intelligenter Chatbots optimiert werden. Mit Kundenanfragen
konfrontiert, merkt sich die Software wiederholt vorkommende Schlagworte oder S&#228;tze sowie das thematische
Umfeld, in dem die jeweiligen Begriffe verwendet werden. Auf dieser Basis werden die passenden Antworten
auf Anfragen herausgesucht und eigenst&#228;ndig versendet.1231 Die f&#252;r den Chatbot nicht zu beantwortenden
Anfragen werden vorsortiert und an Sachbearbeiterinnen und Sachbearbeiter weitergeleitet.
3.2.1.5 Intelligente Sprachanalyse
Obgleich der Nutzen und die ethische Vertretbarkeit des Einsatzes h&#246;chst strittig ist, wird derzeit vermehrt an
Softwarel&#246;sungen gearbeitet, die die sprachliche Analyse von W&#246;rtern und S&#228;tzen mit Maschinellem Lernen 
verbinden und zum Ziel haben, z. B. die Tonalit&#228;t einer Nachricht zu erkennen.1232 Auch Schl&#252;sselw&#246;rter, die auf
Emotionen wie Ver&#228;rgerung hindeuten, k&#246;nnten von der Software erkannt und f&#252;r Service-Mitarbeiterinnen und
-Mitarbeiter vorsortiert werden. So entsteht f&#252;r Service-Personal die M&#246;glichkeit, schwierige Kundengespr&#228;che
entsprechend vorbereitet zu f&#252;hren. Dem Vorteil f&#252;r die Service-Mitarbeiterin oder den Service-Mitarbeiter kann
eine falsche Beurteilung des Anrufers gegen&#252;berstehen. Gleichzeitig kann aber auch die Emotionalit&#228;t der
Kundendienstmitarbeiterinnen und -mitarbeiter analysiert und dem maschinellen Schlussfolgern zug&#228;nglich gemacht
werden. Bei beiden Zielgruppen maschineller Analyse werden auch nicht willentlich erzeugte Informationen 
genutzt, was derartige KI-Systeme ethisch umstritten und rechtlich sensibel macht.
Intelligente Sprachanalyse kommt auch in Bewerbungsverfahren vermehrt zum Einsatz. Bislang sind
Assessment-Center eine bei Arbeitgebern beliebte Methode, um die Eignung von Bewerberinnen und Bewerbern f&#252;r
ein bestimmtes Stellenprofil festzustellen. Besonders f&#252;r Bewerberinnen und Bewerber, die sich in bestehenden
Besch&#228;ftigungsverh&#228;ltnissen befinden, ist es h&#228;ufig schwierig, Zeit f&#252;r solche mehrst&#252;ndigen
Bewerbungsverfahren zu finden. Der Einsatz KI-basierter Sprachanalysesoftware kann Bewerbungsverfahren automatisieren
und es Bewerberinnen und Bewerbern erm&#246;glichen, das Verfahren zu einem Zeitpunkt sowie an einem Ort ihrer
Wahl zu durchlaufen. Nach einem automatisierten Bewerbungsgespr&#228;ch oder einer Reihe spielerischer Tests
kann die Software die Struktur der von der Bewerberin oder dem Bewerber gegebenen Antworten auswerten und
kann zulassen, R&#252;ckschl&#252;sse auf vom Arbeitgeber definierte Anforderungskategorien zu ziehen, wie logisches
Denken oder die F&#228;higkeit, kreativ Probleme zu l&#246;sen. Durch die zeitliche Straffung verzeichnen Arbeitgeber,
die derartige KI-basierte, automatisierte Bewerbungsverfahren nutzen, mehr Bewerberinnen und Bewerbern, die
sich zum Zeitpunkt ihrer Bewerbung in einem festen Besch&#228;ftigungsverh&#228;ltnis befinden.1233 Es gibt
Erfahrungsberichte von einzelnen Unternehmen, dass KI-unterst&#252;tzte Bewerberbewertungsverfahren, in denen das zentrale
Augenmerk auf der Bewertung von Fertigkeiten liegt, die ethnische, altersm&#228;&#223;ige und sozio&#246;konomische Vielfalt
erfolgreicher Bewerberinnen und Bewerber erh&#246;hen k&#246;nnen.1234 Durch KI-basierte Automatisierung k&#246;nnen
Unternehmen z. B. auch nicht erfolgreichen Bewerberinnen und Bewerbern Feedback zu ihrer Bewerbung geben
und Bewertungsprozesse so transparenter gestalten.1235 Gleichzeitig zeigen bestehende Anwendungsf&#228;lle
zentrale Herausforderungen des Einsatzes von KI in diesem Bereich auf. So kann eine unausgewogene
Datengrundlage automatisierte Entscheidungen hervorbringen, die bestimmte Bewerbergruppen benachteiligen.1236 Zudem
ist die Aussagekraft der KI-gest&#252;tzten Analyse von Sprache und Mimik wissenschaftlich umstritten, z. B. da die
Konnotation von Gesichtsausdr&#252;cken zwischen verschiedenen Kulturen variieren kann.1237 Ethisch und rechtlich 
umstritten ist auch, welche generelle Aussagekraft Pers&#246;nlichkeitstests f&#252;r zuk&#252;nftige Leistungen am
Arbeitsplatz haben; dies muss diskutiert werden.1238 
1230 Vgl. assono GmbH: Chatbot f&#252;r Recruiting, Personalmanagement und HR.
1231 So Chatbot Sophie des Energiediscounters eprimo und Chatbot Tinka der &#246;sterreichischen Telekom-Tochter Magenta.
1232 Dies kann z. B. die Software Parlamind.
1233 Dies ist zu sehen am Beispiel der Talanx AG, vgl. Backovic (2018): Robo-Recruiting &#8211; 5 wichtige Fragen verst&#228;ndlich beantwortet.
1234 Ein Bespiel daf&#252;r ist Unilever, vgl. Rudzio (2018): Wenn der Roboter die Fragen stellt.
1235 Vgl. Birkner: Unilever rekrutiert mit menschlicherem Gesicht &#8211; durch k&#252;nstliche Intelligenz.
1236 Siehe zum Einsatz von automatisierten Entscheidungssystemen und KI in der Personalverwaltung auch Kapitel 5.1.3.5.2 dieses
Projektgruppenberichts [Einsatz von automatisierten Entscheidungssystemen und KI in der Personalverwaltung]. 
1237 Vgl. Chen et al. (2018): Distinct facial expressions represent pain and pleasure across cultures.
1238 Vgl. Morgeson et al. (2007): Reconsidering the Use of Personality Tests in Personnel Selection Contexts.
3.2.2 Beispiele f&#252;r KI-Anwendungen in Schule und Hochschule1239 
Durch den in Deutschland bislang noch weitestgehend in der Pilotphase befindlichen Einsatz von KI im
Bildungsbereich &#8211; das hei&#223;t in Schule und Hochschule, aber grunds&#228;tzlich auch in der inner- und au&#223;erbetrieblichen 
Weiterbildung &#8211; er&#246;ffnen sich M&#246;glichkeiten, Lernangebote in Zukunft individueller zu gestalten und auf
konkrete Bed&#252;rfnisse der Lernenden und Lehrenden einzugehen. KI-Systeme im Unterricht k&#246;nnen Lehrkr&#228;ften
Aufschluss &#252;ber die Anwendung von Lehrmitteln oder auch den Lernstand einzelner Sch&#252;lerinnen und Sch&#252;ler
geben, sodass mit gezielten Aufgaben auf St&#228;rken und Schw&#228;chen eingegangen werden kann. Dabei sind
intelligente Bildungsangebote keineswegs Ersatz f&#252;r den pers&#246;nlichen Kontakt mit den Lehrkr&#228;ften, sondern
Unterst&#252;tzung des Lernprozesses, der von Lernendem zu Lernendem unterschiedlich ist und h&#228;ufig nicht linear
verl&#228;uft.
Das sogenannte KI-unterst&#252;tzte adaptive Lernen, das sich individuellen Lernbed&#252;rfnissen anpasst, kann auch 
au&#223;erhalb des Unterrichtskontexts von Nutzen sein. Auch Lernmanagementsysteme zur eigenst&#228;ndigen
Weiterbildung nutzen intelligente Software. Adaptives Lernen wird erm&#246;glicht, indem sich KI-Systeme dem
Wissensstand und der akuten Situation der oder des Lernenden anpassen, beispielsweise indem die KI-Systeme
feststellen, wann der oder die Lernende m&#252;de wird oder auf welchem Gebiet Wissensl&#252;cken bestehen. Um diese
R&#252;ckschl&#252;sse zuzulassen, k&#246;nnen an verschiedenen Stellen der Lerninteraktion Daten gesammelt werden. Bildung und
insbesondere personalisierte Hilfestellung im Lernprozess k&#246;nnen durch KI-gest&#252;tztes adaptives Lernen auch f&#252;r
gro&#223;e Lerngruppen und unter Umst&#228;nden auch ortsungebunden zug&#228;nglich werden. Es ist allerdings zu beachten,
dass der Lernprozess, der auf Basis der erhobenen Daten geschieht, sehr linear verl&#228;uft. Das Lernen durch die
Konfrontation mit Unbekanntem und durch die &#220;berwindung unerwarteter H&#252;rden kommt hier mitunter deutlich 
zu kurz.
Des Weiteren kann mithilfe von KI auch die Ausbildung von Lehrerinnen und Lehrern unterst&#252;tzt werden, indem
relevante Inhalte durch KI vorsortiert und an pers&#246;nliche Pr&#228;ferenzen angepasst werden, wie z. B. im Projekt
Assist des Forschungsinstituts f&#252;r Bildung Digital an der Universit&#228;t des Saarlandes vorgeschlagen.1240 Die
Datengrundlage und Zuverl&#228;ssigkeit der KI-gest&#252;tzten Analyse ist derweil weiterer Forschung zu unterziehen.
Bisher ist das Thema KI-Anwendungen in der Schule noch nicht in einem ausreichenden Ma&#223;e in der Aus- und
Weiterbildung von Lehrerinnen und Lehrern verankert. Dabei ist Wissen und Reflexion &#252;ber die Wirkweise der
Lernmittel entscheidend, um ihr Potenzial auszusch&#246;pfen und negative Auswirkungen, wie etwa
Diskriminierungen, zu vermeiden. Wissen &#252;ber die Technologien ist auch wichtig, um reflektierte Entscheidungen &#252;ber die
konkrete Anwendung und die verwendete Software treffen zu k&#246;nnen und nicht auf die &#8222;Rundum-sorglos-
Pakete&#8220; gro&#223;er kommerzieller Anbieter angewiesen zu sein.
3.2.2.1 Lehrmittel mit intelligenter Sensorik und Data Analytics
Indem intelligente Sensoren Faktoren wie Bewegung, Temperatur und Position im Raum analysieren, k&#246;nnen sie
ein neues Lernerlebnis schaffen. Die KI-gesteuerten Lehrmittel interagieren mit den Lernenden, indem sie z. B. 
ihr Schreib- oder Leseverhalten verarbeiten und dementsprechend Hilfestellung leisten. So k&#246;nnen Stifte mit KI-
basierter Signalverarbeitung und Sensorik Rechtschreibung und Schriftbild verbessern.1241 Wenn eine App den
Lernenden einen Text diktiert, k&#246;nnen in R&#252;ckkopplung mit dem Stift unmittelbar Fehler im Schriftbild
identifiziert werden; somit kann au&#223;erhalb des Unterrichtskontexts direkt eine Korrektur vorgenommen werden. Auch
Eye-Tracking kann in Lernprozesse eingebunden werden. Mithilfe dieser Technologie lassen intelligente
Schulb&#252;cher Schl&#252;sse darauf zu, wie Lernende den Inhalten folgen k&#246;nnen.1242 In einem zweiten Schritt k&#246;nnen Inhalte
entsprechend angepasst werden. Viele der angebotenen Produkte sind jedoch hinsichtlich ihrer Erkl&#228;rbarkeit und
ihrer Wirkweise durchaus kritisch zu betrachten. Dabei ist zu beachten, dass eine abschlie&#223;ende ethische und
rechtliche Bewertung der Technologie noch aussteht. Der Einsatz darf nicht zu einer Verletzung von
Pers&#246;nlichkeitsrechten f&#252;hren.
1239 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion der AfD vor [Sondervotum zu Kapitel 3.2.2, 5.2.4, 5.2.6 und 5.2.8.1 des
Berichts der Projektgruppe 4 &#8222;KI und Arbeit, Bildung, Forschung&#8220; (&#8222;Beispiele f&#252;r KI-Anwendungen in Schule und Hochschule&#8220;,
&#8222;Anforderungen an den Schulunterricht&#8220;, &#8222;KI und Hochschule&#8220;  und &#8222;Lehrkr&#228;ftebildung&#8220;) des sachverst&#228;ndigen Mitglieds Prof.
Dr. Boris Hollas sowie der Abgeordneten Joana Cotar, Peter Felser und Dr. Marc Jongen].
1240 Vgl. FoBiD Forschungsinstitut Bildung Digital: Forschungsprojekt Assist.
1241 Vgl. Mohr (2019): BMBF-F&#246;rderung: &#8222;Intelligenter&#8220; Stift soll Erlernen der Rechtschreibung unterst&#252;tzen.
1242 Vgl. iQL &#8211; Immersive Quantified Learning Lab: InCoRAP.
3.2.2.2 Learning Analytics und Data Analytics im Lernmanagement
Durch Learning Analytics k&#246;nnen die Lerndaten von Sch&#252;lerinnen und Sch&#252;lern aufgezeichnet und ausgewertet
werden.1243 Dadurch k&#246;nnen virtuelle Tutoren auf ihre Sch&#252;lerinnen und Sch&#252;ler eingehen und das
Bildungsangebot sowie ihre Unterst&#252;tzung an den individuellen Wissensstand anpassen. So muss sich der oder die Lernende
nicht selbst um organisatorische Aspekte des Lernprozesses k&#252;mmern, sondern kann sich auf die inhaltliche
Weiterbildung fokussieren. KI-basierte Software ist beispielsweise in der Lage, die Tagesform der Lernenden
sowie weitere Faktoren, die sich auf ihren akuten Lernzustand auswirken, zu erkennen und an Lehrende
weiterzugeben. So besteht das Potenzial, das Lernpensum tages- und personenabh&#228;ngig anzupassen und entsprechende
Hilfestellung einzuplanen.1244 
KI-basierte Chatbots und Apps k&#246;nnen zur Festigung von Wissen beitragen, z. B. indem sie selbstst&#228;ndig Fragen 
zu hochgeladenen Texten erstellen und gezielt Wissen abfragen.1245 Chatbots k&#246;nnen Online-Tutorien begleiten,
indem sie unmittelbar auf falsche Antworten reagieren und je nach Wissensstand Zusatzinformationen zur
Aufgabenl&#246;sung bereitstellen. Durch den Dialog mit dem KI-basierten Chatbot kann Wissen interaktiv abgerufen
und gefestigt werden.1246 Die KI-gest&#252;tzte Anpassung von Lerninhalten an das Niveau und die pers&#246;nlichen
Pr&#228;ferenzen der Lernenden findet bereits heute breite Anwendung in g&#228;ngigen Sprachlern-Apps, die mittels
gesonderter Lizenzen auch im Schulunterricht eingesetzt werden k&#246;nnen.1247 Aggregierte, d. h. zusammengef&#252;hrte
Metadaten &#252;ber die Lernentwicklung aller Nutzerinnen und Nutzer k&#246;nnen zu wegweisenden p&#228;dagogischen
Erkenntnissen &#252;ber kollektives Lernverhalten, wie z. B. &#252;ber die h&#228;ufigsten Fehlerquellen beim Lernen einer
Zweitsprache, f&#252;hren.
3.2.2.3 Lernunterst&#252;tzender Einsatz von KI-Systemen
Es gibt durchaus auch Beispiele f&#252;r den Einsatz von KI-Systemen als Werkzeug f&#252;r die Lernenden, das den
Lernerfolg erh&#246;ht, ohne die Lernenden selbst zu vermessen: So verwenden einige deutsche Hochschulen wie das
Karlsruher Institut f&#252;r Technologie (KIT) bereits &#220;bersetzungs- bzw. Transkriptionssoftware in Vorlesungen.1248 
Mithilfe automatischer Spracherkennung werden Vorlesungen in Echtzeit untertitelt. Studierende k&#246;nnen
Vorlesungen somit &#252;ber das Internet an einem Computerbildschirm mitlesen. Da Untertitel live in mehreren Sprachen
mit Gegen&#252;berstellung zum deutschsprachigen Text bereitgestellt werden, hilft das System, Sprachbarrieren zu
&#252;berwinden. Gleichzeitig wirkt sich die Transkriptionssoftware positiv auf die Barrierefreiheit in H&#246;rs&#228;len aus
und kann die Nachbereitung von Lehrveranstaltungen erleichtern. Diese Beispiele zeigen das Potenzial von
lernunterst&#252;tzendem Einsatz von KI-Systemen in Schulen und Hochschulen. Besonders deutlich zeigt die aktuelle
Corona-Krise, wie schnell der Einsatz von KI-unterst&#252;tztem Lernen wichtig werden kann. Dies gilt jedoch nicht
nur in Pandemie-Zeiten, sondern kann auch hilfreich sein, wenn einzelne Studentinnen und Studenten aus
beruflichen oder pers&#246;nlichen Gr&#252;nden (z. B. Krankheit) nicht an Pr&#228;senzveranstaltungen teilnehmen k&#246;nnen. 
Eine weitere unterst&#252;tzende Wirkung kann mit Robotern an sogenannten dritten Lernorten geschaffen werden.
Die Bibliothek in Berlin-Reinickendorf setzt bereits auf Roboter, die beim Lernen vom Programmieren
unterst&#252;tzen.1249 In diesem Umfeld steht das Lernen im Vordergrund, ein Analysieren und Bewerten der Lernenden
findet nicht statt.
Au&#223;erdem k&#246;nnen KI-gesteuerte Augmented-Reality(AR)1250- oder Virtual-Reality(VR)1251-Anwendungen
genutzt werden, um naturwissenschaftliche Experimente zu veranschaulichen und greifbarer zu machen. Hierbei
wird das nat&#252;rliche Sehen z. B. per Datenbrille oder Anwendung auf mobilem Endger&#228;t um zus&#228;tzliche
Informationen erg&#228;nzt oder es wird g&#228;nzlich in eine virtuelle Welt eingetaucht. Dies erm&#246;glicht es Lernenden, Versuche
durchzuf&#252;hren, die in der analogen Welt z. B. aus Kostengr&#252;nden unm&#246;glich umzusetzen w&#228;ren. Besonders in
den Naturwissenschaften, aber auch im Bereich der Statik sind derartige Anwendungen reizvolle Erg&#228;nzungen
1243 Siehe auch Kapitel 5.2 dieses Projektgruppenberichts [KI in der Bildung]. 
1244 Vgl. Fraunhofer-Institut f&#252;r Optronik, Systemtechnik und Bildauswertung IOSB: Intelligent Tutoring Interface for Technology
Enhanced Learning.
1245 Z. B. die QuizCo GmbH, weitere Informationen dazu unter: https://quizco.de/#content (zuletzt abgerufen am 6. August 2020).
1246 Z. B. El Lingo, E-Tutor der Leibniz Universit&#228;t Hannover, weitere Informationen dazu unter: https://e-tutorium.net/de/ (zuletzt
abgerufen am 6. August 2020).
1247 Vgl. Mobile-Tech: Duolingo f&#252;r Schulen.
1248 Vgl. Gr&#228;vemeyer (2019): Simultan&#252;bersetzer und Dialogsysteme aus deutschen KI-Schmieden.
1249 Vgl. Voss (2018): Roboter und Netflix-Konkurrenz aus der Bibliothek.
1250 Deutsch: erweiterte Realit&#228;t.
1251 Deutsch: virtuelle Realit&#228;t.
zur analogen Lehre.1252 &#196;hnliche VR- und AR-Anwendungen werden auch in einzelnen unternehmensinternen
Trainingszentren eingesetzt.1253 
3.2.2.4 KI-Grundlagen und Robotik an Schulen
Ausgezeichnete digitale Vorreiterschulen vermitteln nicht nur das Wissen, wie KI funktioniert und entwickelt 
wird, sondern bringen die Sch&#252;lerschaft auch in direkten Kontakt mit Robotern und intelligenten Lerntools.1254 
Beispielsweise geben Robotik-AGs Sch&#252;lerinnen und Sch&#252;lern sowie Lehrkr&#228;ften die M&#246;glichkeit, mit KI in 
Kontakt zu kommen und sie f&#252;r n&#252;tzliche Zwecke zu programmieren. An einigen Schulen wurden hierf&#252;r sogar
humanoide Roboter angeschafft.1255 In speziellen Projekten bieten zudem Studierende und Doktorandinnen und
Doktoranden aus dem MINT-Bereich Workshops zum Thema KI an Schulen an, die nicht nur f&#252;r die
Auseinandersetzung mit den technischen Aspekten von KI konzipiert sind, sondern auch soziale und ethische Aspekte des
KI-Einsatzes thematisieren.1256 
Vor allem in den Unterricht von IT-Auszubildenden haben Inhalte, die mit dem Verst&#228;ndnis und der Entwicklung
von KI-Systemen im Zusammenhang stehen, bereits Einzug gehalten. An Vorzeigeschulen werden IT-
Auszubildende in den Bereichen Spracherkennung und Sprachausgabe f&#252;r die Mensch-Maschine-Interaktion,
Bildverarbeitung (Bilderkennung, Bildverfolgung) und alternative Ein- und Ausgabetechniken (Sensorik,
Gestensteuerung) unterrichtet.1257 
3.2.3 Beispiele f&#252;r KI-Anwendungen in der Forschung
L&#228;ngst ist KI auch zum Werkzeug im Forschungslabor geworden und ver&#228;ndert so den Alltag von Forscherinnen
und Forschern. Durch die stetig besser werdende Datenverf&#252;gbarkeit sowie verbesserte Analysem&#246;glichkeiten
durch Algorithmen und Maschinelles Lernen birgt KI Potenzial, um zu neuen Erkenntnissen in einer Vielzahl
von Forschungsbereichen zu gelangen.
3.2.3.1 Prognose bzw. Simulation
Die F&#228;higkeit, gro&#223;e Mengen an Daten zu analysieren und hierin Muster zu erkennen, macht KI zu einem
Instrument zur Prognose von Forschungsergebnissen. KI-basierte Simulations- und Prognoseprozesse k&#246;nnen dazu
beitragen, die Erfolgschancen von Forschungsexperimenten zu erh&#246;hen und gleichzeitig den f&#252;r die Experimente
notwendigen Ressourcenaufwand zu optimieren.
Z. B. kann die pr&#228;diktive Modellierung biologischer Prozesse &#8211; die Vorhersage biologischer Prozesse auf
Grundlage vorhandener Daten &#8211; die Erfolgschancen von Forschung im pharmazeutischen Bereich steigern. So werden
in der Pharmazie KI-Modelle eingesetzt, um die Effekte unterschiedlicher Dosierungen von Medikamenten auf
Patientinnen und Patienten zu simulieren.1258 Auch im fr&#252;hen Stadium der Wirkstoffforschung wird KI als
potenzielles Werkzeug gehandelt. Durch die F&#228;higkeit, riesige Datenmengen erfolgreich auf Muster zu
durchforsten, wird KI-basierter Software beispielsweise beim anf&#228;nglichen Screening von Arzneimittelverbindungen
zugetraut, den Erfolg der Interaktion verschiedener Stoffe prognostizieren zu k&#246;nnen.1259 
Ein Beispiel f&#252;r KI-Anwendung als Forschungsinstrument liegt in der statistischen Physik. Die statistische
Physik setzt sich mit der Berechnung von Material- und Molek&#252;leigenschaften auf Grundlage der Interaktion ihrer
atomaren Bestandteile auseinander. Um entsprechende Eigenschaften vorhersagen zu k&#246;nnen, muss eine Vielzahl
m&#246;glicher Molek&#252;lbewegungen simuliert werden. Der Rechenaufwand hierf&#252;r ist mit herk&#246;mmlichen
Computersimulationen nicht m&#246;glich, da die ben&#246;tigte Rechenzeit die Kapazit&#228;ten von Supercomputern &#252;bersteigt
(sogenanntes Sampling-Problem). KI-basierte Lernverfahren k&#246;nnen derartige Berechnungen enorm beschleunigen
und somit zu zuvor f&#252;r unm&#246;glich gehaltenen Erkenntnissen f&#252;hren, indem sie in k&#252;rzester Zeit eine Vielzahl
m&#246;glicher Interaktionen von Atomen und Molek&#252;len auswerten.1260 Auch ein Anwendungsbeispiel aus der Quan-
1252 Vgl. Bundesministerium f&#252;r Bildung und Forschung: Be-greifen.
1253 Vgl. imsimity GmbH: imsimity.
1254 Vgl. Smart School by bitkom: Smart Schools in Deutschland.
1255 Dies ist der Fall am Erich-Gutenberg-Berufskolleg in K&#246;ln, vgl. EGB Erich-Gutenberg-Berufskolleg K&#246;ln: Robotik.
1256 Vgl. KI macht Schule, ein Projekt von IT4Kids e. V.: KI macht Schule.
1257 Ein Beispiel daf&#252;r ist ebenfalls das Erich-Gutenberg-Berufskolleg in K&#246;ln.
1258 Vgl. Faggella (2020): 7 Applications of Machine Learning in Pharma and Medicine.
1259 Vgl. Odell (2016): Machine learning in the pharmaceutical industry.
1260 Vgl. Freie Universit&#228;t Berlin (2019): K&#252;nstliche Intelligenz f&#252;r die Physik.
tenphysik zeigt, wie KI zu neuen Erkenntnissen verhelfen kann. Mittels KI-basierter Software ist es z. B.
m&#246;glich, anhand experimenteller Daten vorherzusagen, an welchen Punkten sich Stoffeigenschaften ver&#228;ndern
(sogenannte Quantenphasen&#252;berg&#228;nge).1261 Mit etablierten Methoden nimmt die Vermessung von
Quantenphasen&#252;berg&#228;ngen viel Zeit in Anspruch. Der Einsatz von KI tr&#228;gt in diesem Fall also zu enormer Zeitersparnis bei. 
3.2.3.2 Auswertung von Forschungsergebnissen bzw. Forschungsanalyse
Maschinelles Lernen hat das Potenzial, gro&#223;e Mengen an Forschungspapieren automatisch auswerten zu k&#246;nnen,
um anschlie&#223;end Zusammenh&#228;nge aufzuzeigen. Durch Natural Language Processing k&#246;nnen aus umfangreichen
Datens&#228;tzen relevante Forschungspapiere, ihre Schl&#252;sselaussagen oder die f&#252;r vordefinierte Zwecke n&#252;tzlichsten
Forschungsergebnisse herausgefiltert werden.1262 Dies kann an verschiedenen Stufen des Forschungsprozesses
von Nutzen sein. Z. B. kann durch KI-basierte Software die bereits bestehende Forschungslandschaft zu einem
Thema erfasst werden. Bei der Formulierung von Forschungshypothesen kann es KI-basierte Software
vereinfachen, die bereits bestehende Forschungslandschaft einzubeziehen. Die daraus resultierende Zeitersparnis kann 
Forschungsprozesse beschleunigen.
Deutschland 2030: Vision einer &#8222;freundlichen KI&#8220;
3.3.1 Wie die Arbeitswelt von morgen aussehen k&#246;nnte
3.3.1.1 Leitvorstellungen
Der Einsatz von KI wird voraussichtlich zu einer neuen Stufe der Digitalisierung der Arbeit f&#252;hren, mit
deutlichen Unterschieden zur bisherigen Automatisierung und Digitalisierung. Wie bei anderen Technologiespr&#252;ngen
werden sich Arbeitsgestaltung, Arbeitsorganisation, Arbeitsbeziehungen, Produktivit&#228;t,
Qualifikationsanforderungen, betriebliche Besch&#228;ftigungspotenziale, Gesch&#228;ftsmodelle und Transformationsgeschwindigkeit
ver&#228;ndern. Neu ist, dass erstmals nicht ausschlie&#223;lich ausf&#252;hrende Arbeit, sondern auch dispositive Arbeit betroffen
sein wird. Den Menschen und seine Lebensbedingungen in den Mittelpunkt einer KI-Strategie zu stellen, die 
auch auf die Ver&#228;nderung der Arbeit Einfluss nimmt, erfordert f&#252;r die Arbeitswelt eine menschenzentrierte
Entwicklung und Nutzung von KI-Anwendungen, bei der eine gute Balance zwischen den Bed&#252;rfnissen und
Interessen von Besch&#228;ftigten und Arbeitgebern gefunden wird.1263 
Um Potenziale f&#252;r Emanzipation, Nachhaltigkeit und gute Arbeit zu f&#246;rdern und Risiken f&#252;r Besch&#228;ftigte durch
Entwertung ihrer F&#228;higkeiten, ihrer Pers&#246;nlichkeitsrechte und ihrer beruflichen Anschlussf&#228;higkeit zu
minimieren sowie ungerechtfertigte Kontrolle, Entm&#252;ndigung, Arbeitsverdichtung und Arbeitsplatzverluste zu
vermeiden, braucht die Arbeitsgestaltung besondere Leitvorstellungen. Es ist sinnvoll, die Einflussnahme des
Gesetzgebers und der weiteren Normsetzungsakteure unter anderen auf folgende Ziele auszurichten:
&#8226; das Potenzial von KI zur Produktivit&#228;tssteigerung und zur Steigerung des Wohlergehens der Erwerbst&#228;tigen
nutzen1264 
&#8226; neue Gesch&#228;ftsmodelle entwickeln und f&#246;rdern, die dazu beitragen, Besch&#228;ftigung zu sichern und
auszubauen
&#8226; &#8222;Gute Arbeit by design&#8220;1265 entwickeln und vorrangig eint&#246;nige oder gef&#228;hrliche Aufgaben an Maschinen
&#252;bertragen
&#8226; sozialer Sicherheit und Gesundheit dienen
&#8226; den arbeitenden Menschen unterst&#252;tzen und entlasten
1261 Vgl. Universit&#228;t Hamburg (2019): K&#252;nstliche Intelligenz (KI) erkennt Quantenphasen&#252;berg&#228;nge.
1262 Weitere Informationen dazu unter: https://iris.ai/ (zuletzt abgerufen am 6. August 2020).
1263 Vgl. Bundesregierung (2018): Strategie K&#252;nstliche Intelligenz der Bundesregierung.
1264 Vgl. Bundesregierung (2018): Strategie K&#252;nstliche Intelligenz der Bundesregierung.
1265 &#8222;Gute Arbeit by design&#8220; ist ein Konzept des DGB und bezeichnet einen vorausschauenden Ansatz zur Arbeitsgestaltung im Kontext
von autonomen Softwaresystemen. Besch&#228;ftigte und deren Interessenvertretungen sollen bereits bei der Konzeption neuer Systeme
in die Planungen miteinbezogen werden und Mitbestimmungsrechte bei der Definition von Zielen erhalten. Der DGB empfiehlt, KI
als Assistenzsysteme zu nutzen, um Arbeitsbelastungen zu reduzieren und gute Arbeit zu f&#246;rdern. Vgl. dazu auch Deutscher
Gewerkschaftsbund (2020): K&#252;nstliche Intelligenz (KI) f&#252;r Gute Arbeit.
&#8226; daf&#252;r sorgen, dass der Mensch als soziales Wesen an seinem Arbeitsplatz die M&#246;glichkeit hat, sozial mit
anderen Menschen zu interagieren, menschliches Feedback zu erhalten und sich als Teil einer Belegschaft
zu begreifen
&#8226; Kompetenzen der Besch&#228;ftigten entwickeln
&#8226; menschlichen F&#228;higkeiten wie Empathie und Kreativit&#228;t Raum geben 
&#8226; ethische Gestaltungsprinzipien auch in die Arbeitswelt tragen
&#8226; den Besch&#228;ftigten und deren Interessenvertretungen ausreichende Mitbestimmungsrechte er&#246;ffnen
&#8226; barrierefreie Zug&#228;nge schaffen
&#8226; KI-Anwendungen im Betrieb transparent, nachvollziehbar und erkl&#228;rbar machen1266 
&#8226; gute betriebliche Regulierungsbeispiele sowie Ergebnisse der Arbeitsforschung verbreiten und
Gestaltungskompetenz vermitteln1267 
&#8226; eine Vision f&#252;r eine menschenzentrierte KI in der Arbeitswelt im Dialog mit betrieblichen
Normsetzungsakteuren entwickeln
3.3.1.2 Vision 2030 &#8211; mit KI arbeiten
Eine positive KI-Vision f&#252;r eine Arbeitswelt im Deutschland des Jahres 2030 k&#246;nnte wie folgt aussehen:
Die Selbstbestimmung der arbeitenden Menschen wahren, ihre Pers&#246;nlichkeit zu f&#246;rdern und sie zu unterst&#252;tzen,
statt sie zu ersetzen, dies sind zentrale Leitgedanken f&#252;r die Zwecke und Prinzipien f&#252;r lernende Maschinen
geworden, die an den Arbeitspl&#228;tzen in Deutschland immer beliebter geworden sind. Umsicht,
Sozialverpflichtung und Vorausschau sind die Basis f&#252;r die Stimulation neuer Gesch&#228;fte, Gemeinwohlanwendungen, f&#252;r
Forschung und Arbeitsgestaltung geworden. Trusted AI (vertrauensw&#252;rdige KI) ist zum europ&#228;ischen
Markenzeichen geworden, das seine Wurzeln in Deutschland hat.1268 
Kontrolle mittels Social Scoring und r&#252;cksichtsloser Datenhandel gelten 2030 weltweit nicht mehr als erlaubte
und akzeptierte Umgangsformen, genauso wenig wie sich an den Arbeitspl&#228;tzen eine Steuerung des Menschen
durch Maschinen durchgesetzt hat. Hierzulande sch&#228;tzt man 2030 mehr &#8222;intelligente Assistenzsysteme&#8220;, die
unliebsame Arbeiten &#252;bernehmen, hohen Datenschutzstandards gen&#252;gen und dem Menschen eine bessere
Grundlage f&#252;r selbstbestimmte Entscheidungen bieten.1269 Die Systeme &#252;berschreiten die sensorischen und
kombinatorischen F&#228;higkeiten der Menschen bei Weitem.1270 Sie k&#246;nnen viel schneller un&#252;bersehbare Datenmengen
auswerten, als dies mit der sinnlichen Wahrnehmung und den geistigen F&#228;higkeiten der Menschen m&#246;glich ist. Das
hat sie zum verbreiteten Werkzeug werden lassen.
Nat&#252;rlich hat das die Arbeit ver&#228;ndert. T&#228;tigkeiten haben sich in erheblichem Umfang ver&#228;ndert oder sie sind
komplett weggefallen, daf&#252;r sind jedoch neue Arbeitspl&#228;tze und Anforderungen entstanden. Die
Besch&#228;ftigungsbilanz ist unter dem Strich positiv, die Arbeitsbedingungen haben sich verbessert und die Arbeitsbelastung hat
sich verringert. Die Mitbestimmung wurde weiterentwickelt, die Tarifbindung ausgeweitet und die
Crowdsourcees1271 haben die M&#246;glichkeit, ihre Interessen kollektiv zu vertreten. Betriebliche Interessenvertretungen
haben 2030 wirksame Mitbestimmungsrechte beim Einsatz von KI-Systemen, bei der Arbeitsmenge der
Besch&#228;ftigten und beim Schutz der Pers&#246;nlichkeitsrechte im Betrieb. Das hatte Einfluss auf das Wesen der Ver&#228;nderung.
Weiterbildung und Qualifizierung hat eine ganz neue, eine zentrale Bedeutung bekommen. Mittlerweile werden 
die passgenauen Angebote unabh&#228;ngig von der Vorbildung und dem sozialen Milieu gleicherma&#223;en gut
angenommen. Daf&#252;r war eine gro&#223;e gesellschaftliche Kraftanstrengung n&#246;tig, die sich aber gelohnt hat. Eine erh&#246;hte
Flexibilit&#228;t wurde mit sozialer Sicherheit f&#252;r alle Besch&#228;ftigungsformen verkn&#252;pft, Orts- und Zeitautonomie der
1266 Thesen und Handlungsempfehlungen des Bundesbeauftragten f&#252;r den Datenschutz und die Informationsfreiheit (BfDI),
Kommissionsdrucksache 19(27)95 vom 13. Januar 2020.
1267 Vgl. High-Level Expert Group on Artificial Intelligence (2019): Ethik-Leitlinien f&#252;r eine vertrauensw&#252;rdige KI, S. 3.
1268 Vgl. Plattform Lernende Systeme (2019): Neue Gesch&#228;ftsmodelle mit K&#252;nstlicher Intelligenz, Bericht der Arbeitsgruppe
Gesch&#228;ftsmodellinnovationen, Kapitel 2 &#8222;Zukunftsbild KI in Deutschland 2030&#8220;.
1269 Vgl. Schr&#246;der (2019): Menschenbilder, Visionen, Normen. Orientierungen f&#252;r &#8222;Gute Arbeit mit KI&#8220;.
1270 Dies ist bereits heute vielfach der Fall.
1271 Personen, die f&#252;r ein Unternehmen ausgelagerte Teilaufgaben &#252;bernehmen. Diese Auslagerung und Auftragsvergabe an einzelne
Personen erfolgt meist &#252;ber digitale Plattformen.
Erwerbst&#228;tigen ist gewachsen.1272 Dadurch ist es f&#252;r Erwerbspersonen auch m&#246;glich, Familien- und Pflegezeiten
partnerschaftlich zu teilen und ehrenamtlich aktiv zu sein.
Die Einsatzgebiete der KI sind vielf&#228;ltig. Beliebt ist ein Administrationssystem, das den Aufwand f&#252;r
zeitintensive Reisekostenabrechnungen minimiert hat. Oben auf der &#8222;N&#252;tzlichkeitsliste&#8220; stehen auch Systeme zur
Simultan&#252;bersetzung, die in der Telefonie eingesetzt werden und den weltweiten Nachrichtenaustausch erleichtert
haben.
Die Bundesagentur f&#252;r Arbeit (BA) nutzt auch KI, um Berufseinsteigerinnen und -einsteigern sowie
Arbeitssuchenden Rat in Bezug auf die m&#246;glichen Arbeitsmarktchancen der Zukunft und die Entwicklung von Jobprofilen
zu geben. Der Rat ist gesch&#228;tzt, weil trotz der Unsicherheit von Vorhersagen die KI eben nicht herk&#246;mmliche 
Rollenzuweisungen und tradierte geschlechterspezifische Vorpr&#228;gungen &#252;bersetzt. Neben dem Urlaub hat ein
Gro&#223;teil der tarifgebundenen Besch&#228;ftigten mehrere freie Tage im Jahr, die als &#8222;KI-Dividende&#8220; bezeichnet
werden. In Deutschland ist es 2030 politisch weitgehend unumstritten, dass Effektivit&#228;tsgewinne, die mit KI erzielt
werden, auch zugunsten einer Verk&#252;rzung der Arbeitszeit und eines Gewinns an M&#246;glichkeiten zur unmittelbaren
zwischenmenschlichen Kommunikation und zur F&#246;rderung empathischer, sorgender und kreativer T&#228;tigkeiten
genutzt werden k&#246;nnen. Nicht nur die Besch&#228;ftigten im Dienstleistungssektor sch&#228;tzen die Entwicklung. Denn
sie haben jetzt mehr Zeit f&#252;r B&#252;rgerinnen und B&#252;rger, Kundinnen und Kunden, Mandantinnen und Mandaten
sowie Sch&#252;lerinnen und Sch&#252;ler. 
Schule und Ausbildung qualifiziert f&#252;r die Zusammenarbeit mit KI-Systemen und vermittelt Anwendungswissen,
Beurteilungsverm&#246;gen und Gestaltungsans&#228;tze f&#252;r derartige Systeme. Die Produktivit&#228;tsgewinne durch KI haben
auch zu einem Ausbau der Systeme sozialer Sicherheit gef&#252;hrt. Die Sozialversicherungen speisen sich nicht mehr
allein aus dem Lohn f&#252;r Erwerbsarbeit, sondern werden teilweise durch KI-Produktivit&#228;tsgewinne erg&#228;nzt. Eine
Wertsch&#246;pfungsabgabe war in der Projektgruppe umstritten. 
3.3.2 Wie die Bildung von morgen aussehen k&#246;nnte
KI-Technologien sollen 2030 in vielen Lebensbereichen gewinnbringend und verantwortungsbewusst eingesetzt
werden. Voraussetzung daf&#252;r ist eine digitale Grundbildung, die dem Menschen ein Verst&#228;ndnis f&#252;r die Funktion 
und Mechanismen von KI vermittelt und das Fundament f&#252;r einen vertieften und kompetenten Umgang mit ihr
erm&#246;glicht. Entlang der gesamten Bildungskette, von der fr&#252;hkindlichen Bildung bis ins Alter, wird KI zur
F&#246;rderung der individuellen Bildungsziele eingesetzt. Hierbei wird insbesondere ihre unterst&#252;tzende Funktion
genutzt, die die pers&#246;nliche Entwicklung und Selbstbestimmung der Lernenden nicht einschr&#228;nkt, sondern ihnen
neue Freir&#228;ume im Lernprozess schafft.
Dabei wird insbesondere ber&#252;cksichtigt, dass Lernende nicht in ihrem Verhalten durchleuchtet werden, sondern
p&#228;dagogisch und didaktisch geeignete Methoden als erg&#228;nzendes Werkzeug genutzt werden, um den Lernprozess
zu f&#246;rdern und unterschiedliche Begabungen bestm&#246;glich zu f&#246;rdern. KI-Ma&#223;nahmen werden nur selektiv
eingesetzt, das Lernen als sozialer Prozess steht im Vordergrund. 
Die deutschen Schulen sind durch die erfolgreiche Kooperation von Bund und L&#228;ndern auf allen Ebenen zu Smart
Schools ausgebaut worden. Notwendige, vertrauensw&#252;rdige und sichere Infrastrukturen, gepr&#252;fte, transparente
und nachvollziehbare KI-Anwendungen, p&#228;dagogische und didaktische Konzepte sowie umfangreiche
Lehrkr&#228;ftefortbildungen machen den konstruktiven Einsatz von KI jahrgangsstufengerecht im Unterricht m&#246;glich. Dank
einschl&#228;giger Forschung wei&#223; man, in welchen Lernszenarien der Einsatz intelligenter Tools eine Bereicherung
f&#252;r Lernende und Lehrkr&#228;fte darstellt und an welchen Stellen traditionelle didaktische Ans&#228;tze vorzuziehen sind.
Dazu beigetragen haben auch ein breiter gesellschaftlicher Diskurs und Aus-, Weiter- sowie
Fortbildungsangebote, die Lehrkr&#228;fte und Eltern dazu bef&#228;higen, sich kompetent in dieser neuen Lernwelt zu bewegen. F&#228;higkeiten 
wie kritisches Denken, Kreativit&#228;t, Zusammenarbeit und Kommunikation spielen gleichzeitig eine zentrale Rolle.
Der kombinierte Einsatz dieser Kompetenzen und von KI unterst&#252;tzt Sch&#252;lerinnen und Sch&#252;ler bestm&#246;glich beim
Erreichen ihrer Lernziele. Die eingesetzten Tools sind den rechtlichen Vorgaben gem&#228;&#223; so konzipiert und werden
so verwaltet, dass die von ihnen erhobenen Daten &#252;ber Lernende und Lehrende nur zweck- und
datenschutzgerecht verwendet werden. Die Lehrkr&#228;fte wurden f&#252;r einen kompetenten und verantwortungsvollen Umgang mit
KI geschult und haben die M&#246;glichkeit, sich durch ein umfangreiches Weiterbildungsangebot fortlaufend mit
neuesten Technologien auseinanderzusetzen. Die gesetzten Rahmenbedingungen haben dazu gef&#252;hrt, dass es
eine gro&#223;e Vielfalt kompetenter Anbieter von KI-Systemen f&#252;r Schulen gibt. Digitalisierung und Grundlagen
1272 Vgl. Plattform Lernende Systeme (2019): Neue Gesch&#228;ftsmodelle mit K&#252;nstlicher Intelligenz, Bericht der Arbeitsgruppe
Gesch&#228;ftsmodellinnovationen, Kapitel 2 &#8222;Zukunftsbild KI in Deutschland 2030&#8220;.
von KI werden gleicherma&#223;en an Sch&#252;lerinnen und Sch&#252;ler vermittelt. Stereotype zu Computern und Maschinen
als &#8222;Jungssache&#8220; geh&#246;ren der Vergangenheit an. M&#228;dchen und Jungen lernen bereits in der Schule, gemeinsam
an technischen Problemstellungen zu arbeiten und im Team L&#246;sungen zu entwickeln.
Nicht nur in der Schulbildung werden die Potenziale intelligenter Technologien an den passenden Stellen genutzt
und der verantwortungsvolle Umgang damit gelehrt. Ihr Einsatz ist auch in der Aus- und Hochschulbildung keine
Ausnahme mehr. Sowohl im betrieblichen als auch im universit&#228;ren Kontext ist die Lehre durch KI-gest&#252;tzte
Lerntools vielf&#228;ltiger und vor allem praxisnaher sowie interaktiver geworden. Berufsschulen und Hochschulen
vermitteln so in allen Fachbereichen grundlegende Anwendungskompetenzen f&#252;r KI in der Arbeitswelt 4.0.
Durch die Vermittlung von KI-spezifischem Fachwissen in einem interdisziplin&#228;ren Ansatz mit IT-Sicherheit,
Soziologie, Psychologie und Rechtswissenschaften in IT-Ausbildungs- und Studieng&#228;ngen bildet Deutschland
international angesehene KI-Expertinnen und -Experten aus und gilt als eine der f&#252;hrenden Nationen auf dem
Gebiet der interdisziplin&#228;ren KI.
Weiterbildungen zu KI und Big Data sind mittlerweile selbstverst&#228;ndlich und f&#252;r alle zug&#228;nglich. Von dem digital
transformierten Bildungssystem k&#246;nnen alle profitieren: jede und jeder Einzelne durch bessere
Besch&#228;ftigungsf&#228;higkeit und Entwicklungschancen sowie Unternehmen durch eine verbesserte Standortqualit&#228;t und eine hohe
Innovationsf&#228;higkeit. Nicht zuletzt hat der Einsatz KI-gest&#252;tzter Technologien, z. B. simultaner
&#220;bersetzungstools, auch die Inklusion erleichtert und so die Chancengerechtigkeit gest&#228;rkt.
Auf dem Weg zu einem digitalen Bildungssystem, das KI an den richtigen Stellen als unterst&#252;tzende,
menschenzentrierte und gewinnbringende Technologie integriert, haben sich folgende anerkannte Leitziele
herauskristallisiert:
&#8226; KI muss zum Unterst&#252;tzer des Lernprozesses f&#252;r alle werden und sollte einzelne Lernende nur am
Bildungszweck orientiert analysieren, ohne die Selbstbestimmung des Lernenden einzuschr&#228;nken. Au&#223;erdem sollte
sie p&#228;dagogisch sinnvoll eingebunden werden und nicht die traditionellen didaktischen Methoden
verdr&#228;ngen.
&#8226; Alle Menschen m&#252;ssen die Chance haben, sich zum Thema KI weiterzubilden und einen kompetenten
Umgang mit intelligenten Tools zu erlernen.
&#8226; F&#228;higkeiten wie kritisches Denken, Kreativit&#228;t, Zusammenarbeit und Kommunikation m&#252;ssen im
Bildungskontext eine zentrale Rolle spielen.
&#8226; Damit alle Beteiligten in der gesamten Bildungskette m&#252;ndig mit KI umgehen k&#246;nnen, m&#252;ssen
jahrgangsstufen- und lernortgerecht &#8211; neben grundlegenden Kenntnissen in Mathematik und Informatik &#8211; weitere
F&#228;higkeiten im Bereich IT-Sicherheit und soziale Kompetenzen vermittelt werden.
&#8226; Weiterbildungsangebote m&#252;ssen flexibel an Innovationen im KI-Bereich angepasst werden k&#246;nnen.
&#8226; Bildungsinstitutionen1273 m&#252;ssen langfristig finanziell gef&#246;rdert werden, um eine Infrastruktur auszubauen,
die den Einsatz von KI beg&#252;nstigt.
3.3.3 Wie die Forschung von morgen aussehen k&#246;nnte
Die Forschung ist Motor einer Vision einer &#8222;freundlichen KI&#8221;, sie entwickelt und verbessert KI und ihre
Anwendungen laufend, um &#8222;mit KI arbeiten&#8221; zu k&#246;nnen (siehe Kapitel 3.3.1.2 dieses Projektgruppenberichts [Vision
2030 &#8211; mit KI arbeiten]) und KI &#8222;zum Unterst&#252;tzer des Lernprozesses f&#252;r alle&#8221; zu machen (siehe Kapitel 3.3.2
dieses Projektgruppenberichts [Wie die Bildung von morgen aussehen k&#246;nnte]). Ihre Aufgabe ist gleichzeitig
immer auch die Entwicklung neuer, verbesserter Anwendungen und Technologien, die neue Visionen
erm&#246;glichen.1274 
Deutschland ist Heimat zahlreicher wissenschaftlicher und technologischer Durchbr&#252;che im Bereich der KI z. B. 
auf dem Gebiet der intelligenten Robotik, dazu geh&#246;ren autonome Fahrzeuge und kollaborative Roboter, welche
durch die Koevolution von rechnergest&#252;tzten F&#228;higkeiten und intelligenten cyber-physischen Systemen erreicht
wurden. Auch auf dem Forschungsgebiet der kognitiven Assistenzsysteme, in dem maschinelle Lernverfahren 
mit anderen KI-Verfahren, wie z. B. der Wissensrepr&#228;sentation in cyber-physischen Systemen, untersucht wer-
1273 Innerhalb der Projektgruppe wurde dar&#252;ber diskutiert, ob nicht nur &#246;ffentliche Bildungsinstitutionen finanziell gef&#246;rdert werden 
sollten.
1274 F&#252;r konkrete Ma&#223;nahmen und Ziele f&#252;r die KI-Forschung siehe Kapitel 9 des Mantelberichts [KI und Forschung].
        
 
 
           
    
   
    
              
       
  
 
  
 
      
 
  
  
  
  
 
 
  
   
 
  
   
  
 
        
 
      
   
   
 
    
 
     
   
   
      
  
   
   
     
 
                                               
   
  
   
   
  
4
den, ist Deutschland federf&#252;hrend. Im Bereich solch cyber-physischer Systeme hat Deutschland einen
Technologievorsprung gegen&#252;ber den beiden wichtigsten globalen Konkurrenten &#8211; China und den USA. Das Potenzial
dieser bedeutenden wachsenden KI-Felder &#8211; gerade f&#252;r die Bundesrepublik &#8211; wurde von der Forschung
identifiziert und deren Sprung in die &#8222;reale&#8220; Welt vorangetrieben, insbesondere in Anwendungen in der Arbeitswelt und
in der Bildung. Basierend auf europ&#228;ischen Werten steht dabei eine vertrauensw&#252;rdige1275 KI im Vordergrund.
So ist Europa mit f&#252;hrend in der Forschung zur Mensch-Roboter-Kollaboration, die F&#228;higkeiten der
menschlichen und k&#252;nstlichen Intelligenz in den Mittelpunkt stellt und f&#252;r viele Anwendungsgebiete gro&#223;es Potenzial
besitzt. Deutschland hat seine St&#228;rken in Forschung und Wirtschaft synergistisch genutzt, spielt eine zentrale
Rolle in technologiebasierten Wertsch&#246;pfungsketten und konnte gro&#223;e Teile der Produktion zur&#252;ck ins Inland
verlegen.
Im Rahmen gro&#223; angelegter Missionen und strategischer Forschungsinitiativen, die erfolgreich auf Exzellenz und
Vernetzung setzen, wurde eine vertrauensw&#252;rdige KI entwickelt, die im Arbeits- und Bildungsalltag der
Menschen angekommen ist. Statt durch Schutzz&#228;une getrennt arbeiten die Menschen direkt mit feinf&#252;hligen und
intelligenten Maschinen, Robotern und Softwaresystemen zusammen oder steuern diese bequem &#252;ber neue
M&#246;glichkeiten der Telepr&#228;senz und leicht bedienbare Portale aus der Ferne. Menschen m&#252;ssen sich nicht mehr in
gef&#228;hrliche Umgebungen begeben und viele lange, zeitraubende wie umweltsch&#228;dliche Arbeitswege k&#246;nnen
vermieden werden. KI hat in Form von intelligenten Maschinen und Robotern besonders die manuelle Arbeit
grundlegend optimiert, international wettbewerbsf&#228;hig gestaltet und die Flexibilit&#228;t der Arbeitnehmerinnen und -
nehmer erh&#246;ht. Intelligente Roboter &#252;bernehmen anstrengende, eint&#246;nige, aber auch potenziell gef&#228;hrliche Arbeiten
und entlasten die Besch&#228;ftigten. Im Bereich der Pflege beispielsweise werden k&#246;rperlich anstrengende und
monotone T&#228;tigkeiten an Technologien abgegeben, damit das Pflegepersonal sich auf anspruchsvollere T&#228;tigkeiten
und die so wichtige pers&#246;nliche Patientenbetreuung konzentrieren kann. Aber auch Handwerk und Produktion
profitieren von flexiblen Systemen, die auf einfache und verst&#228;ndliche Art und Weise f&#252;r oder mit Menschen
agieren, lernen und kommunizieren. In Schulen und Hochschulen verbessern interaktive Lernsysteme den
Lernerfolg und erm&#246;glichen eine Ausrichtung von Lerninhalten und -methoden am individuellen Bedarf.
Diese Erfolge sind nicht zuletzt auf die interdisziplin&#228;ren Anstrengungen der KI-Forschung im Schulterschluss
mit der Soziologie, Philosophie und Ethik wie auch Expertise aus Gestaltung und Design zur&#252;ckzuf&#252;hren, welche
wichtige Erkenntnisse und Konzepte dieser Disziplinen tief in die KI-Systeme integriert haben. Grundlegend f&#252;r
eine erfolgreiche Technologieeinf&#252;hrung waren zudem partizipative Entwicklungsprozesse, bei denen die
Nutzererfahrung der Stakeholder, wie z. B. der Shopfloor1276-Mitarbeiterinnen und Mitarbeiter oder der Lehrkr&#228;fte.
Die n&#228;chste Generation vertrauensw&#252;rdiger KI ist gesellschaftlich gew&#252;nscht und interagiert mit der physischen 
Welt. Dies resultiert auch aus einem Bildungssystem, in dem KI nicht nur als Mittel der Lehre und der Forschung
(Kapitel 3.3.2 dieses Projektgruppenberichts [Wie die Bildung von morgen aussehen k&#246;nnte]) angewendet wird, 
sondern auch fester Bestandteil der Lehrpl&#228;ne von KI-qualifiziertem Lehrpersonal ist. Aber auch die nachhaltigen
Investitionen in eine fl&#228;chendeckende Infrastruktur haben sich ausgezahlt. Diese gew&#228;hrleisten nun, dass Daten
gesch&#252;tzt und anonymisiert f&#252;r Forschende, medizinisches Personal und politische Entscheiderinnen und
Entscheider aufbereitet werden k&#246;nnen und so eine sichere Entscheidungsgrundlage darstellen.1277 
Technologieakzeptanz als Erfolgskriterium f&#252;r den KI-Einsatz (Treiber und Bremser)
Um dezidierte Handlungsempfehlungen f&#252;r die Verbreitung und Regulierung von KI-Anwendungen in der
Arbeitswelt zu begr&#252;nden, ist zun&#228;chst die Betrachtung von Treibern und Bremsern der Entwicklung von KI
sinnvoll.
KI ist heute schon und wird in Zukunft zunehmend in der Lage sein, Aufgaben auszuf&#252;hren und Entscheidungen
vorzubereiten oder sogar zu &#252;bernehmen. Eine repr&#228;sentative Befragung der Bitkom aus dem Jahr 2017 zeigt, 
dass Vertrauen in KI-Systeme f&#252;r einige Felder durchaus vorhanden ist. Z. B. finden 93 Prozent der Befragten
die Anwendung von KI sinnvoll, wenn durch den Einsatz von Algorithmen fr&#252;her vor Unwetter oder
Katastrophen gewarnt werden kann. Auch bei der Reduktion von Verkehrsstaus oder der effizienteren Bearbeitung von
1275 Vertrauensw&#252;rdige KI zeichnet sich im Sinne der High-Level Expert Group on Artificial Intelligence (vgl. High-Level Expert Group 
on Artificial Intelligence (2019): Ethik-Leitlinien f&#252;r eine vertrauensw&#252;rdige KI) durch drei zentrale Komponenten aus:
Rechtm&#228;&#223;igkeit, Ethik und Robustheit.
1276 Deutsch: Fertigung/Werkstatt.
1277 Abweichend zu den vorhergehenden Kapiteln sind hier keine konkreten Ziele formuliert. Siehe auch Kapitel 9 des Mantelberichts
[KI und Forschung].
Verwaltungsvorg&#228;ngen erkennen Menschen Vorteile.1278 Wenn allerdings Entscheidungen, die bislang durch
Menschen getroffen wurden, partiell oder sogar komplett einer Maschine &#252;berlassen werden, sind Menschen eher
skeptisch. Hier besteht z. B. die Sorge, dass KI die Vorurteile der Programmiererinnen und Programmierer
abbildet (67 Prozent der Befragten der Bitkom-Studie) und faktenbasierte Entscheidungen nur vorgegaukelt werden
(64 Prozent). Rund jede und jeder Zweite hat Angst, dass sich intelligente Maschinen irgendwann gegen den
Menschen richten (54 Prozent).1279 Laut &#8222;Statusreport K&#252;nstliche Intelligenz&#8220; des Vereins Deutscher Ingenieure
(VDI) erkl&#228;ren mehr als ein Drittel der Unternehmen, dass Widerst&#228;nde gegen den KI-Einsatz im Unternehmen
bestehen.1280 
Derart differenzierte Vorpr&#228;gungen haben Ursachen. Nach den Erfahrungen einiger Mitglieder der Arbeitsgruppe
&#8222;KI und Arbeit, Bildung, Forschung&#8220;, den Ausf&#252;hrungen angeh&#246;rter Expertinnen und Experten und der
Auswertung zahlreicher Literaturquellen wird von folgenden wesentlichen Faktoren ausgegangen, die die
Implementierung und Nutzung von KI beeinflussen.
Treiber der Entwicklung
Notwendige Voraussetzung f&#252;r den Einsatz von KI-Systemen in der Arbeitswelt ist ein attraktives Angebot, das
hei&#223;t Produkte, die den Kundenunternehmen Mehrwert verschaffen oder Kosten senken. Vertrauen geh&#246;rt zu den
wichtigsten Treibern der Implementierung. Hierzu geh&#246;rt, dass Menschen Bescheid wissen, wie Systeme
funktionieren und mit welchen Zielen sie eingesetzt werden.1281 Wichtig ist auch, dass Systeme vorhersehbar und 
erkl&#228;rbar sind und beeinflusst werden k&#246;nnen. Daf&#252;r werden Stellschrauben ben&#246;tigt, &#252;ber welche die Systeme
an ihren entsprechenden Kontext angepasst werden k&#246;nnen.1282 F&#252;r den verbreiteten und akzeptierten Einsatz 
von KI-Systemen in der Arbeitswelt sind Regeln und eine vorausschauende Gestaltung der Schnittstellen
zwischen Menschen und Maschinen vertrauensf&#246;rdernd. Dazu z&#228;hlen eine vorausschauende Arbeitsgestaltung und
Qualifizierungsstrategie ebenso wie die Folgenabsch&#228;tzung f&#252;r die Pers&#246;nlichkeitsrechte. &#8222;Privacy by design&#8220;1283 
und &#8222;Gute Arbeit by design&#8220; sind wichtige Treiber der Entwicklung. Von der Konzeptentwicklung bis zur
Implementierung Transparenz, Nachvollziehbarkeit und Gestaltungsoptionen mitzudenken und zu
implementieren1284 f&#246;rdert Akzeptanz. Voraussetzung f&#252;r einen akzeptierten KI-Einsatz in der Arbeitswelt sind zudem
partizipative, dialogische Einf&#252;hrungs-, Nutzungs- und Evaluationsprozesse, die bei der Festsetzung der Ziele
beginnen, eine Absch&#228;tzung der Folgen f&#252;r Arbeitnehmerinnen und Arbeitnehmer anschlie&#223;en und bei der
&#220;berpr&#252;fung regelgerechter Anwendung enden. Dies umfasst wirksame Einflussm&#246;glichkeiten mit Kommunikations-
und Beteiligungsprozessen und einer verbindlichen Prozessgestaltung im Rahmen von
mitbestimmungspflichtigen Angelegenheiten. Ein wichtiges Merkmal von KI ist, dass sie sich weiterentwickelt. Deswegen muss
Mitbestimmung in den Betrieben &#252;ber den ersten Einsatz der Anwendungen hinaus in einem &#8222;prozeduralen
Mitbestimmungsrecht&#8220; mit Interventions- und Korrekturm&#246;glichkeiten sichergestellt werden.1285 Hierzu geh&#246;rt auch eine
transparente Definition von Grenzen und Revisionsm&#246;glichkeiten sowie die Einhaltung von
Arbeitsschutznormen, die Durchf&#252;hrung von Belastungsanalysen und das Ziel, die Besch&#228;ftigten vor &#220;berforderung zu sch&#252;tzen.
Eine Einbindung des Handelns in dokumentierte und verpflichtende Ethikprinzipien ist ebenso erfolgskritisch 
f&#252;r die Verbreitung von lernenden Maschinen wie die Wahrung der Handlungs- und Entscheidungstr&#228;gerschaft
des Menschen. Was aus Arbeitnehmersicht als Treiber gewertet wird, kann aus Arbeitgebersicht als Bremser
gesehen werden. Die eigene, praktische Erfahrung der N&#252;tzlichkeit des Technikeinsatzes tr&#228;gt zudem auch
entscheidend zur Akzeptanz und Verbreitung bei.1286 F&#252;r Kunden und Besch&#228;ftigte erw&#228;chst Vertrauen auch aus der
Klarheit &#252;ber die Verantwortung und der Kl&#228;rung von Haftungsfragen bei Sch&#228;den durch den KI-Einsatz. Ob
sich diese Elemente als Treiber oder Bremser der Entwicklung erweisen, h&#228;ngt von ihrer Ausgestaltung ab.
1278 Vgl. Holtel et al. (2017): K&#252;nstliche Intelligenz verstehen als Automation des Entscheidens.
1279 Vgl. Bitkom e. V. (2017): Bundesb&#252;rger geben K&#252;nstlicher Intelligenz gro&#223;e Chancen.
1280 Vgl. Deutscher Gewerkschaftsbund (2019): K&#252;nstliche Intelligenz und die Arbeit von morgen, S. 3.
1281 Vgl. Muir (1994): Trust in automation: Part I. Theoretical issues in the study of trust and human intervention in automated systems.
1282 Vgl. Lee und See (2004): Trust in automation: designing for appropriate reliance.
1283 &#8222;Privacy by design&#8220; bedeutet Datenschutz durch Technikgestaltung. Schon bei der Konzeption und Entwicklung von Produkten zur
Verarbeitung personenbezogener Daten muss der Datenschutz mitgedacht und entsprechend implementiert werden. Durch die
Datenschutz-Grundverordnung (DSGVO) ist das Prinzip ab 25. Mai 2018 f&#252;r Unternehmen verpflichtend. Vgl. dazu auch Fraunhofer-
Institut f&#252;r Optronik, Systemtechnik und Bildauswertung IOSB: Privacy by Design.
1284 Vgl. Deutscher Gewerkschaftsbund (2019): K&#252;nstliche Intelligenz und die Arbeit von morgen, S. 4.
1285 Vgl. Deutscher Gewerkschaftsbund (2018): Stellungnahme des DGB zu den Eckpunkten der Bundesregierung f&#252;r eine Strategie
K&#252;nstliche Intelligenz vom 18. Juli 2018.
1286 Vgl. Venkatesh et al. (2003): User Acceptance of Information Technology: Toward a Unified View.
Bremser der Entwicklung
Ein Mangel an bzw. ein Fehlen der oben genannten Treiber kann die Entwicklung hemmen. Relevant sind hier
u. a. die Sorge um dem Verlust an Entscheidungshoheit und der Pers&#246;nlichkeitsrechte des Menschen sowie
unklare Verantwortlichkeiten, insbesondere in Zusammenhang mit Intransparenz von Mechanismen und
Zielsetzungen oder uneindeutigen Absichten. Ein Bremser w&#228;re auch Rechtsunsicherheit aufgrund fehlender, unklarer,
inakzeptabler oder unstimmiger Regulierung. Bleiben Sorgen vor der Entwertung von Qualifikationen und dem
Verlust des Wertstatus und des Arbeitsplatzes der Menschen unbearbeitet, steigt das Potenzial f&#252;r die Verbreitung
ablehnender Haltungen. Auch ein fehlendes Verst&#228;ndnis bzw. mangelnde Aufkl&#228;rung &#252;ber die
Anwendungsoptionen und Funktionsweisen von KI-Systemen k&#246;nnen als Bremser wirken.1287 Hierzu geh&#246;ren auch Angst sowie
eine teils emotionalisierte &#220;berh&#246;hung der Risiken.1288 Auf der anderen Seite existieren in der Bev&#246;lkerung ernst
zu nehmende Sorgen &#252;ber den Einsatz von KI, die durch sinnvolle Regulierung ausger&#228;umt werden k&#246;nnen. Ein
weiteres Hindernis ist der akute KI-Fachkr&#228;ftemangel. So beklagen 80 Prozent deutscher Unternehmen einen
Mangel an KI-Expertinnen und -Experten. Die H&#228;lfte der Unternehmen sieht den Fachkr&#228;ftemangel als
Haupthemmnis f&#252;r den Fortschritt von KI-Projekten.1289 
Von entscheidender Bedeutung ist, dass N&#252;tzlichkeitserfahrungen1290 verbreitet werden und die &#220;berzeugung
getragen wird, wonach Selbstwirksamkeit1291 und Handlungstr&#228;gerschaft durch ein KI-System nicht untergraben 
werden. Derartige Erfahrungen und Einstellungen tragen eher zu Akzeptanz und Verbreitung von KI-Systemen
bei als dogmatische Bef&#252;rwortung. Auch f&#252;r den Abbau von Misstrauen gilt: Es braucht eine gesellschaftliche
Vision eines positiven Einsatzes der Technik sowie Handlungs- und Entscheidungsmodelle, die diesen positiven
Einsatz auch &#252;ber die Zeit gew&#228;hrleisten. Lernende Systeme k&#246;nnen und sollten dabei nicht durchweg so gestaltet
werden wie herk&#246;mmliche IT-Systeme. Ben&#246;tigt wird eine Verabredung zu betrieblichen Einsatzbedingungen,
die mehr auf Prozesse abstellt, von den verschiedenen Stakeholder-Gruppen getragen wird und Antworten auf
die spezifischen Fragen gibt, die KI-Systeme aufwerfen.
5 Status quo und Handlungsempfehlungen: KI und Arbeit, Bildung, Forschung
KI in der Arbeitswelt
5.1.1 Entwicklung des Arbeitsmarktes (Prognosen, Arbeitsmarktforschung)
5.1.1.1 Folgen der Automatisierung f&#252;r den Arbeitsmarkt
Es gibt zahlreiche Studien, die die Auswirkungen der Digitalisierung auf das Volumen der Besch&#228;ftigung
prognostizieren. Nahezu alle g&#228;ngigen Studien zu Besch&#228;ftigungseffekten beziehen sich auf Digitalisierung und
Automatisierung im Allgemeinen bzw. fokussieren sich auf bestimmte Technologien wie Robotik. Die
Kernaussagen dieser Studien lassen sich wie folgt zusammenfassen:
F&#252;r gro&#223;es Aufsehen und unbegr&#252;ndete Angst sorgte die Frey/Osborne-Studie (2013).1292 Diese prognostiziert,
dass 47 Prozent der Besch&#228;ftigten in den USA in Berufen arbeiten, die in den n&#228;chsten 20 Jahren mit hoher
Wahrscheinlichkeit (70 Prozent) automatisiert werden k&#246;nnen. Die darauf aufbauende Prognose f&#252;r Deutschland
sieht 59 Prozent der Berufe in Deutschland in Gefahr.1293 Die Studie von Frey/Osborne (2013) ber&#252;cksichtigt
jedoch nicht, dass in erster Linie einzelne T&#228;tigkeiten und nicht ganze Berufe automatisiert werden. Laut der
&#220;bertragung der Frey/Osborne-Studie auf Deutschland (2015)1294 weisen deshalb lediglich 12 Prozent der
Arbeitspl&#228;tze T&#228;tigkeitsprofile mit einer relativ hohen Automatisierungswahrscheinlichkeit auf. Dem Institut f&#252;r
Arbeitsmarkt- und Berufsforschung (IAB) zufolge arbeiteten im Jahr 2013 15 Prozent, 2016 bereits 25
Prozent1295 der sozialversicherungspflichtig Besch&#228;ftigten in Deutschland in einem Beruf mit sehr hohem
Substituierbarkeitspotenzial (das hei&#223;t, mehr als 70 Prozent der T&#228;tigkeiten innerhalb eines Berufes k&#246;nnten schon heute
durch Computer &#252;bernommen werden).
1287 Vgl. Mayer et al. (1995): An Integrative Model of Organizational Trust.
1288 Vgl. Venkatesh et al. (2003): User Acceptance of Information Technology: Toward a Unified View.
1289 Vgl. Hensel und Litzel (2018): IDC-Studie identifiziert Nachholbedarf &#8211; Mangel an Fachkr&#228;ften bremst KI-Projekte aus.
1290 Vgl. Davis (1989): Perceived Usefulness, Perceived Ease of Use, and User Acceptance of Information Technology.
1291 Vgl. Bandura (1977): Self-efficacy: Toward a unifying theory of behavioral change.
1292 Vgl. Frey und Osborne (2013): The future of employment: How susceptible are jobs to computerisation? 
1293 Vgl. Brzeski und Burk (2015): Die Roboter kommen. 
1294 Vgl. Bonin et al. (2015): &#220;bertragung der Studie von Frey/Osborne (2013) auf Deutschland. 
1295 Vgl. Dengler und Matthes (2018): Substituierbarkeitspotenziale von Berufen &#8211; Wenige Berufsbilder halten mit der Digitalisierung
Schritt.
Die Berechnungen solch technikzentrierter Arbeitsmarktprognosen greifen h&#228;ufig zu kurz. Manche schlie&#223;en von
technischen Potenzialen unmittelbar auf eine Substitution von T&#228;tigkeiten oder Berufen, untersch&#228;tzen die
Variabilit&#228;t von Arbeitssituationen und &#252;bersch&#228;tzen die Leistungsf&#228;higkeit von Technologien in variablen
Kontexten. Au&#223;erdem bleiben betriebswirtschaftliche Fragen nach dem Kosten-Nutzen-Verh&#228;ltnis von Investitionen
meist ebenso unber&#252;cksichtigt wie m&#246;gliche Reibungsverluste bei deren Implementierung und die damit
verbundenen Folgekosten. Des Weiteren geht die Betrachtung von Substitutionspotenzialen meist von einem statischen
Verst&#228;ndnis von Berufen aus; die Ver&#228;nderungen von T&#228;tigkeiten sowie neue Formen von Interaktionen
zwischen Technik und Menschen werden vernachl&#228;ssigt. Zudem findet oftmals keine Betrachtung des Zuwachses
von Besch&#228;ftigung statt.1296 Insofern sind hohe Substituierbarkeitspotenziale der Berufe nicht gleichzusetzen mit
dem Verlust von Arbeitspl&#228;tzen. Denn die Potenziale beschreiben zun&#228;chst eine technische Machbarkeit. Sofern
die menschliche Arbeit wirtschaftlicher, flexibler oder von besserer Qualit&#228;t ist oder rechtliche oder ethische 
H&#252;rden einem Einsatz entgegenstehen, werden auch ersetzbare T&#228;tigkeiten eher nicht ersetzt werden.1297 
Ein realistischeres Bild zeichnen solche Studien, die &#246;konometrische Rechenmodelle und Szenario-Analysen
aufstellen. Bei den Modellen werden neben der allgemeinen technischen Machbarkeit auch &#246;konomische
Faktoren mit einbezogen, die bei der Substitution von T&#228;tigkeiten und der Entstehung neuer Arbeitsfelder eine
bedeutende Rolle spielen. 
Die Economix-Studie (2016) prognostiziert beim Szenario einer beschleunigten Digitalisierung bis 20301298
einen Besch&#228;ftigungsgewinn von einer Million Erwerbst&#228;tigen in 13 Branchen1299 und einen Besch&#228;ftigungsverlust
von 750 000 Erwerbst&#228;tigen in 27 Wirtschaftszweigen.1300 Das IAB prognostizierte 2018 einen nahezu
ausgeglichenen Gesamtbesch&#228;ftigungseffekt mit Blick auf das Jahr 2035.1301 Bei dieser Modellierung wurden zahlreiche
Aspekte ber&#252;cksichtigt, wie etwa Investitionen, Substitution und Preismechanismus.
5.1.1.2 Bislang wenig Forschung zu den Besch&#228;ftigungseffekten von KI1302 
Derzeit gibt es wenig evidenzbasierte Forschungsergebnisse zu den Auswirkungen von KI auf den
Arbeitsmarkt.1303 Dies liegt zum einen daran, dass KI-Anwendungen bislang noch wenig in der Breite angewendet
werden, zum anderen an der unzureichenden Datenlage zu den Aspekten von Digitalisierung.1304 Existierende
Studien nutzen indirekte Ma&#223;e f&#252;r Automatisierung oder untersuchen speziellere Technologien wie den Einsatz von
Informations- und Kommunikationstechniken (IKT) oder Industrie-Robotern. Damit werden technischer Wandel
und insbesondere KI-Aspekte nur indirekt erfasst. Zudem sind die ben&#246;tigten Informationen &#252;berwiegend nur
auf aggregierter Ebene bzw. auf Industrieebene verf&#252;gbar. Damit lassen sich die wichtigen Anpassungsprozesse
auf Ebene der Betriebe und Besch&#228;ftigten, wie Anpassungen der Belegschaftsstruktur, der Arbeitsorganisation,
der Aus- und Weiterbildung sowie der individuellen Erwerbsbiografien, nur eingeschr&#228;nkt bewerten.1305 
Zwar k&#246;nnen die genauen Wirkungen von KI daher noch nicht hinreichend bestimmt werden, allerdings lassen
sich einige Schlussfolgerungen aus bisherigen Automatisierungswellen ziehen. Demnach hat technologischer
Wandel in der Vergangenheit nicht zu gro&#223;en Nettoverlusten bei der Besch&#228;ftigung gef&#252;hrt, da die Anzahl der
neu entstandenen Arbeitspl&#228;tze stets die Anzahl der weggefallenen ausgleichen konnte.1306 Gleichwohl gab es
1296 Darstellung des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo in der Sitzung der Projektgruppe KI und Arbeit, Bildung, Forschung
am 4. November 2019.
1297 Vgl. auch die Arbeit der Enquete-Kommission &#8222;Berufliche Bildung in der digitalen Arbeitswelt&#8220;. 
1298 Vgl. Vogler-Ludwig et al. (2016): Arbeitsmarkt 2030 &#8211; Wirtschaft und Arbeitsmarkt im digitalen Zeitalter.
1299 Es geht vor allem um Herstellerbranchen f&#252;r digitale Technik und Dienste. Dazu geh&#246;ren die klassischen Industriebranchen, d. h.
Maschinenbau, Fahrzeugbau und Elektronikindustrie, ebenso wie IT-Dienste, Unternehmensdienste sowie Forschung und Entwicklung. 
1300 Hierbei geht es um Anwenderbranchen von digitaler Technik. Dies gilt vor allem f&#252;r den Einzelhandel, das Papier- und Druckgewerbe
sowie die &#246;ffentliche Verwaltung. 
1301 Vgl. Zika et al. (2018): Arbeitsmarkteffekte der Digitalisierung bis 2035 &#8211; Regionale Branchenstruktur spielt eine wichtige Rolle.
1302 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 5.1.1.2 des Berichts der
Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220; (&#8222;Bislang wenig Forschung zu den Besch&#228;ftigungseffekten von KI &#8220;) der
Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo].
1303 Eine aktuelle Literatur&#252;bersicht findet sich bei Goos et al. (2019): The Impact of Technological Innovation on the Future of Work.
1304 Vgl. Frank et al. (2019): Toward understanding the impact of artificial intelligence on labor; Furman und Seamans (2019): AI and
the Economy; Mitchell und Brynjolfsson (2017): Track how technology is transforming work und Raj und Seamans (2019): Artificial
Intelligence, Labor, Productivity, and the Need for Firm-Level Data.
1305 Handlungsempfehlungen von Dr. Terry Gregory (IZA-Institute of Labor Economics),Projektgruppendrucksache 19(27)PG 4-17 vom
25. November 2019. 
1306 Zu Europa vgl. Gregory et al. (2019): Racing With or Against the Machine? Evidence from Europe.
gr&#246;&#223;ere Umstrukturierungen zwischen T&#228;tigkeitsbereichen mit ver&#228;nderten Anforderungen.1307 Gegen solche
historische Analogien spricht jedoch, dass &#8222;erste wissenschaftliche Studien zum Einsatz von KI zeigen, dass im
Unterschied zu bisherigen Automatisierungswellen ganz andere T&#228;tigkeiten tangiert sein k&#246;nnten, sodass
Arbeitspl&#228;tze neu gestaltet (Job-Redesign) werden m&#252;ssen&#8220;1308. Es stellt sich also die Frage, ob der
Besch&#228;ftigungszuwachs die zu erwartenden Substitutionseffekte tats&#228;chlich abdecken kann, wenn diese insbesondere Bereiche 
kognitiver Arbeit betreffen, die sich in der Vergangenheit als relativ automatisierungsresistent erwiesen
haben.1309 
M&#246;glicherweise wird im Arbeitsmarkt ein Mismatch entstehen &#8211; also die Koexistenz von disruptiven
Jobverlusten an der einen Stelle und Fachkr&#228;ftemangel an der anderen Stelle.1310 H&#228;ufig genannte Beispiele f&#252;r das
Potenzial disruptiver Ver&#228;nderungen durch KI sind Sachbearbeitert&#228;tigkeiten bei der Beurteilung der Bonit&#228;t bzw. der
Anspruchsberechtigung von Kundinnen und Kunden bei Banken und Versicherungen, LKW-Fahrerinnen und
-Fahrer im Zuge des autonomen Fahrens sowie Call-Center.1311 Neben den Substitutionseffekten durch KI wirken 
sich nat&#252;rlich auch andere Faktoren auf die Besch&#228;ftigung aus, die mittelbar im Zusammenhang mit KI im
engeren oder Digitalisierung und Automatisierung im weiteren Sinn stehen, z. B. Ver&#228;nderungen in der
Innovationskraft und Wettbewerbsf&#228;higkeit von Unternehmen, Modifikationen der Geografie der Wertsch&#246;pfung (Off- oder
Reshoring1312) oder strukturelle Ver&#228;nderungen ganzer Sektoren durch neue Gesch&#228;ftsmodelle. Wie am aktuellen
Beispiel der Automobilindustrie ersichtlich ist, in der sich der digitale Wandel mit dem technologischen Bruch
der Antriebssysteme &#252;berschneidet, k&#246;nnen solche Ver&#228;nderungen erhebliche Folgen f&#252;r den Arbeitsmarkt
haben. Welche Rolle der Einsatz von KI in diesen vielschichtigen Transformationen spielt, ist freilich schwer
herauszufinden.
Die technologisch bedingte Transformation der Besch&#228;ftigungsverh&#228;ltnisse ist also ein wesentliches
Gestaltungsfeld der Arbeitswelt im 21. Jahrhundert. Die Frage, ob die Substitution von Hunderttausenden von Arbeitspl&#228;tzen
und die Neubesetzung eines &#228;hnlich gro&#223;en Volumens in neuen T&#228;tigkeitsbereichen gelingen kann, ist ein
wesentliches Kriterium daf&#252;r, ob die digitale Transformation der Gesellschaft sozialvertr&#228;glich gestaltet werden
kann oder nicht. Angesichts des demografischen Wandels gibt es gute Voraussetzungen daf&#252;r, dass KI-basierte
Automatisierung nicht zu jenen sozialen Verwerfungen f&#252;hrt, die pessimistische Prognosen bef&#252;rchten lassen.
Die Sozialpartner und die Politik m&#252;ssen ihren Gestaltungsauftrag aber vorausschauend wahrnehmen, um den
Wandel der Arbeitsm&#228;rkte im Sinne des Allgemeinwohls zu begleiten. Eine der Herausforderungen besteht dabei
darin, Besch&#228;ftigten mithilfe der Aus- und Weiterbildung die M&#246;glichkeit zu geben, sich schnell, flexibel und
kontinuierlich auf die ver&#228;nderten Anforderungen und T&#228;tigkeiten dieser neuen Arbeitspl&#228;tze vorzubereiten.
5.1.1.3 Handlungsempfehlungen
5.1.1.3.1 Die Auswirkungen von KI f&#252;r den Arbeitsmarkt weiter erforschen
Um den Strukturwandel besser vorbereiten und gestalten zu k&#246;nnen, sind evidenzbasierte Forschung und
belastbare Prognosen f&#252;r die Besch&#228;ftigungseffekte des KI-Einsatzes unerl&#228;sslich. Neben den Aktivit&#228;ten des vom
BMAS eingerichteten KI-Observatoriums sind spezielle F&#246;rderprogramme zur systematischen Erfassung und
Analyse der arbeitsmarktrelevanten Auswirkungen von KI aufzulegen. Dabei sollten sowohl die
Voraussetzungen f&#252;r quantitativ angelegte Studien verbessert (etwa durch die Bereitstellung von Mikrodaten und die
thematische Anreicherung bestehender Datens&#228;tze durch Digitalisierungsdaten/KI-relevante Daten) als auch qualitative
Studien gef&#246;rdert werden, die genauere Erkenntnisse &#252;ber die Wirkungszusammenh&#228;nge auf betrieblicher Ebene
zutage f&#246;rdern k&#246;nnen. Wichtig ist, dass Daten bei denselben Untersuchungseinheiten im Zeitverlauf wiederholt
erfasst werden (Panelstruktur).
Die Projektgruppe empfiehlt sektorales Branchenmonitoring/-screening in Zusammenarbeit mit Verb&#228;nden,
Gewerkschaften und Forschungsinstituten zur Beobachtung und vorausschauenden Auswertung von Entwicklungen
1307 Handlungsempfehlungen von Dr. Terry Gregory (IZA-Institute of Labor Economics), Projektgruppendrucksache 19(27)PG 4-17 vom
25. November 2019.
1308 Handlungsempfehlungen von Dr. Terry Gregory (IZA-Institute of Labor Economics),Projektgruppendrucksache 19(27)PG 4-17 vom
25. November 2019; Brynjolfsson et al. (2018): The Second Machine Age. 
1309 Vgl. Brynjolfsson et al. (2018): The Second Machine Age. 
1310 Handlungsempfehlungen von Prof. Dr. Jens S&#252;dekum (D&#252;sseldorf Institute for Competition Economics), Projektgruppendrucksache
19(27)PG 4-2 vom 21. November 2019.
1311 Darstellung des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo in der Sitzung der Projektgruppe KI und Arbeit, Bildung, Forschung
am 4. November 2019. 
1312 Deutsch: Verlagerung ins Ausland bzw. R&#252;ckverlagerung.
auf dem Arbeitsmarkt. Somit wird wichtiges Wissen f&#252;r die Ausgestaltung politischer oder branchenspezifischer
Initiativen z. B. im Bereich der Weiterbildung verf&#252;gbar.
5.1.1.3.2 Strukturwandel flankieren &#8211; politische Ma&#223;nahmen evaluieren und anpassen
Zur Behebung des Mismatch-Problems ist die z&#252;gige Umsetzung und Ausweitung des
Fachkr&#228;fteeinwanderungsgesetzes erforderlich. Dies ergibt sich allein aufgrund der demografischen Perspektive
Deutschlands, die sich von den globalen Trends diametral unterscheidet.1313 Weiterhin wird von Expertinnen und
Experten empfohlen, schon bei der Implementierung k&#252;nftiger Ma&#223;nahmen zur F&#246;rderung von KI und
Weiterbildung eine wirkungsvollere wissenschaftliche Begleitung sicherzustellen, damit geeignete
Forschungsdesigns implementiert werden k&#246;nnen. Bislang sei es g&#228;ngige Praxis, Wissenschaftlerinnen und
Wissenschaftler erst nach Einf&#252;hrung einer Ma&#223;nahme mit der Evaluation zu beauftragen. Dadurch seien Ursache-
Wirkungs-Bestimmungen im Vorfeld nicht m&#246;glich. 
Der von der Projektgruppe angeh&#246;rte Sachverst&#228;ndige Dr. Terry Gregory 1314 empfiehlt die hierzulande
wenig eingesetzten &#8222;randomisierten Feldexperimente&#8220;1315. Die wissenschaftlichen Erkenntnisse sollten dann 
auch genutzt werden, um Politikma&#223;nahmen gegebenenfalls anzupassen. Denkbar ist dabei auch, dass
F&#246;rderprogramme in unterschiedlicher Form f&#252;r einzelne Gruppen aufgesetzt und hinsichtlich der Wirksamkeit
verglichen werden. Anschlie&#223;end kann die wirkungsvollste Ma&#223;nahme fl&#228;chendeckend umgesetzt
werden.1316 
5.1.2 (Qualitative) Auswirkungen von KI auf die Arbeitswelt 
KI wird in verschiedenen Unternehmen bereits vielf&#228;ltig eingesetzt (siehe Kapitel 3.2 dieses
Projektgruppenberichts [Einf&#252;hrende Beispiele bzw. Anwendungsf&#228;lle (Use Cases)])Allerdings ist insgesamt die Zahl der Betriebe,
die KI-Technologien einsetzen, noch relativ gering. So haben 2020 in Deutschland nur sechs Prozent der
Unternehmen KI genutzt oder implementiert. 22 Prozent haben angegeben, KI-Eins&#228;tze zu testen oder zumindest
solche zu planen.1317 Eine empirisch gesicherte Bestandsaufnahme zu den Auswirkungen von KI auf die Arbeitswelt
steht insofern noch aus. 
Bei der Beurteilung der Auswirkungen des Einsatzes von KI-Systemen in der Arbeitswelt ist einerseits davon
auszugehen, dass gef&#228;hrliche, k&#246;rperlich schwere und immer wiederkehrende Arbeiten reduziert werden und KI-
Systeme bei der L&#246;sung komplexer Aufgaben eine unterst&#252;tzende Funktion erf&#252;llen k&#246;nnen. &#220;berdies kann das
F&#228;higkeitsspektrum von Menschen durch KI-L&#246;sungen erg&#228;nzt werden. 
Andererseits wird mit Blick auf den Einsatz digitaler KI-basierter Assistenzsysteme darauf hingewiesen, dass ein
schmaler Grat zwischen der Unterst&#252;tzung menschlicher T&#228;tigkeiten und Formen der Einschr&#228;nkung der
Entscheidungsautonomie besteht, die mit Arbeitsverdichtung, einer rigideren Kontrolle der Arbeitsleistung und einer
Entwertung menschlichen Erfahrungswissens einhergehen kann.1318 Beispielsweise sto&#223;en auch in Deutschland 
die rigide Steuerung des Arbeitseinsatzes &#252;ber Assistenzsysteme bei einzelnen Unternehmen in der
Handelslogistik sowie neue Formen algorithmischer Kontrolle von Arbeitsinhalten und -leistung im Bereich der
Angestelltenarbeit auf Kritik.1319 Das Gelingen des Einsatzes von KI h&#228;ngt auch davon ab, wie man es schafft, die Systeme
in bestehende Arbeitsprozesse einzupassen, und ob Besch&#228;ftigte die Ergebnisse von KI-Systemen verstehen,
interpretieren und kontextualisieren k&#246;nnen. Diese Themen sprechen einerseits die Funktionalit&#228;t des KI-Einsatzes
im Sinne der Prozessinnovation und neuer Gesch&#228;ftsmodelle an, ber&#252;hren aber zentral auch Fragen der Gerech-
1313 Handlungsempfehlungen von Prof. Dr. Jens S&#252;dekum (D&#252;sseldorf Institute for Competition Economics), Projektgruppendrucksache
19(27)PG 4-2 vom 21. November 2019.
1314 Dr. Terry Gregory (IZA-Institute of Labor Economics).
1315 Angrist und Pischke (2009): Mostly harmless econometrics. Bei dieser Methodik wird die Ma&#223;nahme nicht gleich fl&#228;chendeckend
angewendet, sondern nur in einer zuf&#228;llig zusammengesetzten Gruppe, sodass &#8211; &#228;hnlich wie in der Medizinforschung &#8211; &#8222;behandelte&#8220;
und &#8222;nicht-behandelte&#8220; Gruppen verglichen werden k&#246;nnen.
1316 Handlungsempfehlungen von Dr. Terry Gregory (IZA-Institute of Labor Economics), Projektgruppendrucksache 19(27)PG 4-17 vom
25. November 2019.
1317 Vgl. Bitkom e. V. (2020): Unternehmen tun sich noch schwer mit K&#252;nstlicher Intelligenz.
1318 Darstellung des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo in der Sitzung der Projektgruppe KI und Arbeit, Bildung, Forschung
am 4. November 2019.
1319 Darstellung Eva-Maria Nyckel (Humboldt-Universit&#228;t zu Berlin) in der Sitzung der Projektgruppe KI und Arbeit, Bildung, Forschung 
am 16. Dezember 2019.
tigkeit. Der Einsatz von KI-Systemen sollte u. a. daran gemessen werden, inwieweit die Akzeptanz der
Besch&#228;ftigten im Umgang mit der Technik erh&#246;ht wird und inwieweit diese Systeme dazu beitragen, die Arbeitsbelastung
zu verringern, indem menschliches Handeln unterst&#252;tzt wird. Schlie&#223;lich sollte auch thematisiert werden, welche
positiven Auswirkungen der KI-Einsatz auf das betriebliche Sozialgef&#252;ge hat, das hei&#223;t, wie Kompetenzen
m&#246;glichst breit gestreut und aufgebaut werden k&#246;nnen, wie sich die Arbeitsbelastung der Mitarbeiterinnen und
Mitarbeiter ver&#228;ndert und wie sich dies auf die Arbeitsbedingungen auswirkt.
Insofern sind die Politik und die Sozialpartner gefordert, die Ver&#228;nderungen der Arbeitswelt so zu gestalten, dass
Chancen f&#252;r eine Aufwertung von Arbeit genutzt und Risiken in Bezug auf Qualifikationsanforderungen und
Arbeitsbedingungen ausgeschlossen werden k&#246;nnen; dabei sind die empirischen Forschungsergebnisse zu
ber&#252;cksichtigen. 
Bei der Gestaltung der Auswirkungen von KI auf die Arbeitswelt sollte die qualitative Transformation der Arbeit
(das hei&#223;t die &#196;nderung der T&#228;tigkeiten und der Arbeitsqualit&#228;t) ebenso Beachtung finden wie die quantitative
Transformation (das hei&#223;t das Entstehen und Wegfallen von Arbeitspl&#228;tzen).
5.1.2.1 Strukturelle &#196;nderungen der Arbeitswelt: Plattformarbeit
KI wirkt sich nicht nur auf Arbeitsorganisation und -inhalte bestehender Besch&#228;ftigungsverh&#228;ltnisse im
betrieblichen Kontext aus, sondern betrifft in besonderem Ma&#223;e auch &#252;ber digitale Plattformen entstandene neue
Erwerbsformen.1320 Dabei handelt es sich um bezahlte Dienstleistungsarbeit, die &#252;ber internetbasierte Plattformen
vermittelt werden. Diese kann sowohl ortsunabh&#228;ngig geleistete Arbeit (&#8222;Cloudwork&#8220;/&#8220;Crowdwork&#8220;/&#8220;
Clickwork&#8220;) als auch ortsgebundene Arbeit (&#8222;Gigwork&#8220;) sein. Auch die Art der vermittelten Dienstleistungen und die
dazu notwendigen Qualifikationen sowie ihre Verg&#252;tung variieren stark. Sie k&#246;nnen aus einfachen, kurzen,
immer wiederkehrenden T&#228;tigkeiten bestehen (sogenannten Microtasks), die keine besondere Qualifikation
voraussetzen und entsprechend geringf&#252;gig verg&#252;tet werden (z. B. die Klassifizierung von Bildern f&#252;r KI-
Trainingsdatens&#228;tze). Sie k&#246;nnen aber auch komplexe, anspruchsvolle T&#228;tigkeiten umfassen, die eine hohe Qualifikation
vom Leistungserbringer erfordern und entsprechend h&#246;her dotiert sind (z. B. Auftr&#228;ge f&#252;r Programmiererinnen
und Programmierer oder Designerinnen und Designer). In manchen Bereichen besteht eine Wechselwirkung
zwischen dem Einsatz von KI und der Plattformarbeit. Denn Crowdworking kann f&#252;r die Erledigung einiger KI-
relevanter Aufgaben eingesetzt werden (z. B. zur Aufbereitung von Trainingsdaten) und das Zusammenbringen
von Plattformarbeiterinnen und -arbeitern und Kundenauftr&#228;gen (Matching) kann durch KI effizienter organisiert
werden.1321 
Ein Vorteil der Plattformarbeit ist, dass durch niedrige Markteintrittsbarrieren und flexible Arbeitsgestaltung ein
gr&#246;&#223;erer Personenkreis als bisher Dienste anbieten kann, darunter z. B. Privatpersonen, die sich einen
gelegentlichen Zuverdienst verschaffen wollen, oder auch Personen, die bislang nicht in einem regul&#228;ren
Besch&#228;ftigungsverh&#228;ltnis stehen. Zudem gibt es f&#252;r gut ausgebildete Menschen in Entwicklungs- und Schwellenl&#228;ndern die
M&#246;glichkeit, eine T&#228;tigkeit aufzunehmen, die, verglichen mit lokalen Verdienstm&#246;glichkeiten, eine bessere
Bezahlung erm&#246;glichen kann.1322 
Als Nachteil gilt, dass Crowdworkerinnen und Crowdworker in der Regel als Solo-Selbstst&#228;ndige zum Teil in
einem bundesweiten und sogar weltweiten Wettbewerb stehen, in dem die Entgelte stark unterschiedlich
ausfallen k&#246;nnen. F&#252;r sie gelten die gesetzlichen Schutzregelungen f&#252;r Arbeitnehmerinnen und Arbeitnehmer zumeist
nicht. Das liegt auch daran, dass die unterschiedlichen Rechtsrahmen und der Arbeitnehmerbegriff so komplex 
sind, dass selbst f&#252;r sie g&#252;ltige Schutzstandards h&#228;ufig nicht durchgesetzt werden. Zudem bietet Plattformarbeit
wenige M&#246;glichkeiten f&#252;r eine Karriere- oder berufliche Kompetenzentwicklung.1323 
Es sollte auf Grundlage empirischer Forschungsergebnisse gepr&#252;ft werden, ob und inwieweit f&#252;r die
sozialversicherungsrechtliche Einstufung schutzbed&#252;rftiger Plattformarbeiterinnen und -arbeiter passende Kriterien und
Regelungen geschaffen werden k&#246;nnen.
1320 Vgl. Greef und Schroeder (2017): Plattform&#246;konomie und Crowdworking: Eine Analyse der Strategien und Positionen zentraler
Akteure.
1321 Darstellung Prof. Dr. Florian Schmidt (Hochschule f&#252;r Technik und Wirtschaft Dresden) in der Sitzung der Projektgruppe KI und
Arbeit, Bildung. Forschung am 13. Januar 2020.
1322 Darstellung Prof. Dr. Florian Schmidt (Hochschule f&#252;r Technik und Wirtschaft Dresden) in der Sitzung der Projektgruppe KI und
Arbeit, Bildung, Forschung am 13. Januar 2020.
1323 Vgl. Eurofound (2019): Platform work: Maximising the potential while safeguarding standards?
5.1.2.2 Mensch-Maschine-Interaktion
KI erm&#246;glicht neue Formen der Zusammenarbeit zwischen Menschen und Maschinen. Dies bewirkt nicht nur
einen neuen Zuschnitt einzelner T&#228;tigkeiten, sondern wirkt sich auch auf Prozesse, Strukturen und das gesamte
Sozialgef&#252;ge des Betriebs aus, das hei&#223;t auf die Arbeitsteilung und die Gestaltung der Arbeitsabl&#228;ufe. Insofern
sind mit Blick auf die Mensch-Maschine-Interaktion zwei zentrale Aspekte zu ber&#252;cksichtigen: &#8222;Zum einen geht
es um die Ver&#228;nderung und Verdr&#228;ngung bestimmter T&#228;tigkeitsprofile sowie die Formen der Arbeitsteilung
zwischen Mensch und Technik. [&#8230;] Zum anderen steht auch die Entwicklung von Gestaltungskriterien f&#252;r die
Mensch-Maschine-Interaktion &#8211; insbesondere vor dem Hintergrund verschiedener Anwendungsfelder,
unterschiedlicher Formen der Arbeitsteilung zwischen Mensch und Technik sowie (m&#246;glicher) neuer T&#228;tigkeitsprofile
&#8211; im Mittelpunkt.&#8220;1324 
Hierbei ist zu beachten, dass die Art und Weise, wie KI das betriebliche Sozialgef&#252;ge ver&#228;ndert, davon abh&#228;ngt,
wie dieses von den betrieblichen Akteuren gestaltet wird. In der Diskussion um Arbeit 4.0 wird unterschieden
zwischen einem Werkzeugszenario, in dem der Mensch entlastet wird und die Handlungshoheit beh&#228;lt, und einem
Automatisierungsszenario, in dem Arbeit gegen&#252;ber den technischen Systemen auf eine Restfunktion reduziert
wird und die Selbstbestimmung der Besch&#228;ftigten eingeschr&#228;nkt wird. Diese m&#246;glichen Entwicklungspfade
bewegen sich entsprechend im Spektrum einer betrieblichen Schwarmorganisation mit nahezu gleichwertigen,
breiten Aufgabenzuschnitten und dem Szenario einer polarisierten Organisation.1325 
Hinsichtlich der Ver&#228;nderung der T&#228;tigkeiten ist es wichtig, schon bei der Entwicklung und Einf&#252;hrung von KI-
Technologien verschiedene Aufgaben, Rollenprofile und Arbeitszusammenh&#228;nge zu ber&#252;cksichtigen,
Arbeitsumgebungen gesundheits-, pers&#246;nlichkeits- und lernf&#246;rderlich zu gestalten und Besch&#228;ftigte durch KI-
Technologien zu entlasten und zu unterst&#252;tzen. Dadurch kann das Engagement der Mitarbeiterinnen und Mitarbeiter,
ihre Identifikation mit dem Betrieb und ihre Motivation sowie die Akzeptanz von KI-Systemen gef&#246;rdert
werden.1326 Gelingt die Technologieeinf&#252;hrung in diesem Sinne, kann KI bei gef&#228;hrlichen oder k&#246;rperlich schweren 
T&#228;tigkeiten entlasten, Routinet&#228;tigkeiten &#252;bernehmen und Handicaps ausgleichen. Au&#223;erdem kann KI bei
komplexen Prozessen und gro&#223;en Datenmengen Analysen vornehmen und so beispielsweise die &#196;rztin oder den Arzt
bei der Erstellung von Diagnosen unterst&#252;tzen.
Bei der Entwicklung von Kriterien f&#252;r die Gestaltung der Mensch-Maschine-Interaktion sind folgende
Gesichtspunkte von Relevanz: Prinzipien der Transparenz, Nachvollziehbarkeit, Datenschutz und Erkl&#228;rungsf&#228;higkeit
sowie die Beachtung von Grundrechten. Au&#223;erdem stellen sich auch Fragen der Sicherheit, der
Benutzerfreundlichkeit, der Verantwortlichkeit und der Autonomie. Diese Kriterien k&#246;nnen auch als Grundlage f&#252;r die nationale
und internationale Normung und Standardisierung sowie die Weiterentwicklung des Arbeitsschutzes dienen.1327 
Aufgrund der besonderen Eigenschaft von KI als lernendem System wird die Gestaltung der Technik au&#223;erdem
zu einer permanenten Aufgabe. Dadurch entstehen Chancen f&#252;r eine umfassendere Gestaltung sozio-technischer
Systeme durch die Sozialpartner, aber auch die Herausforderung f&#252;r Betriebsr&#228;te und das Management, die
Folgen komplexer technischer Systeme einsch&#228;tzen und identifizieren zu k&#246;nnen. 
Gegen&#252;ber der gegenw&#228;rtig vorherrschenden Form der sozialpartnerschaftlichen Aushandlung des
Technologieeinsatzes, bei der dieser Einsatz als einmalige Implementation behandelt wird, m&#252;ssen hier neue Vereinbarungen
getroffen werden, die eine kontinuierliche Begleitung des Einsatzes von KI-Systemen erm&#246;glichen1328 (siehe
Kapitel 5.1.2.5 dieses Projektgruppenberichts [Partizipation und Mitbestimmung]).
5.1.2.3 Neue Qualifikationsanforderungen
Die Frage der Qualifikationsanforderungen und des Kompetenzaufbaus hat eine besondere Bedeutung f&#252;r die
Gestaltung der Arbeitswelt der Zukunft. 1329 
Ein wichtiger Forschungsgegenstand ist derzeit die Frage, welche Kompetenzen mit dem Einsatz von KI-
Systemen besonders gefragt sein werden. Nach Ansicht einiger Expertinnen und Experten werden &#8222;grunds&#228;tzlich [&#8230;]
1324 Plattform Lernende Systeme (2019): Arbeit, Qualifizierung und Mensch-Maschine Interaktion.
1325 Vgl. Hirsch-Kreinsen et al. (2018): Digitalisierung industrieller Arbeit; Handlungsempfehlungen von Dr. Britta Matthes (Institut f&#252;r
Arbeitsmarkt- und Berufsforschung), Projektgruppendrucksache 19(27)PG 4-21 vom 9. Dezember 2019.
1326 Vgl. Plattform Lernende Systeme (2019): Arbeit, Qualifizierung und Mensch-Maschine Interaktion.
1327 Vgl. Plattform Lernende Systeme (2019): Arbeit, Qualifizierung und Mensch-Maschine Interaktion.
1328 Vortrag von Dr. Constanze Kurz (Gesamtbetriebsrat Robert Bosch AG), Projektgruppendrucksache 19(27)PG 4-28 vom 16.
Dezember 2019.
1329 Vgl. auch die Arbeit der Enquete-Kommission &#8222;Berufliche Bildung in der digitalen Arbeitswelt&#8220;.
Kompetenzen und F&#228;higkeiten an Bedeutung gewinnen, bei denen Menschen einen komparativen Vorteil
gegen&#252;ber Maschinen besitzen&#8220;1330. Hierzu z&#228;hlten zum einen komplexe F&#228;higkeiten wie etwa kreatives Arbeiten,
Probleml&#246;sungskompetenz oder Verhandlungsgeschick in komplexen Umgebungen sowie bestimmte
Kompetenzen aus den Bereichen des abstrakten Denkens und der Feinmotorik. Auch die Kombination aus analytischen 
und sozialen Kompetenzen k&#246;nne an Bedeutung gewinnen. 
Bei der Einsch&#228;tzung dieser Frage sollte jedoch auch bedacht werden, dass der &#8222;komparative Vorteil&#8220; des
Menschen auch bei T&#228;tigkeiten zur Geltung kommt, die gro&#223;e Varianz in der Arbeitsumgebung oder den Umgang
mit vielf&#228;ltigen oder f&#252;r Robotik schwer zu beherrschenden Materialien beinhalten1331 bzw. wo Vollautomatik 
zu teuer ist. Hierbei handelt es sich keineswegs nur um hochqualifizierte T&#228;tigkeiten, sondern um ein breites
Spektrum an personenbezogenen Dienstleistungen oder Montaget&#228;tigkeiten in der verarbeitenden Industrie. 
Entsprechend der in der wissenschaftlichen Literatur verbreiteten Einsch&#228;tzung, dass die Einsatzfelder von KI
stark variieren und zudem verschiedenartige Szenarien in Bezug auf die Qualifikationsanforderungen m&#246;glich
sind, ist es unwahrscheinlich, dass der Einsatz von KI pauschal zu einer Auf- oder Abwertung von Arbeit f&#252;hrt.
In Bezug auf den Einsatz von KI in der Arbeitswelt k&#246;nnen jedoch bestimmte Anforderungen identifiziert
werden, die f&#252;r den sowohl in funktionaler als auch in normativer Hinsicht gelungenen Umgang mit KI-Systemen
wichtig sind. Diese umfassen u. a.: 
&#8226; Kompetenzen zum Verst&#228;ndnis, zur Interpretation und zur Kontextualisierung automatisierter
Entscheidungen &#8211; da die Besch&#228;ftigten die F&#228;higkeit besitzen m&#252;ssen, Entscheidungshilfen zu beurteilen und
gewinnbringend zu nutzen
&#8226; die F&#228;higkeit zum bereichs&#252;bergreifenden Denken und Handeln &#8211; da sich der Zuschnitt vieler
T&#228;tigkeitsfelder ver&#228;ndern wird und insbesondere &#8222;&#220;bersetzungsleistungen&#8220; zwischen technischen Systemen und
dom&#228;nenspezifischem Erfahrungswissen wichtiger werden
&#8226; konzeptionelles und kreatives Denken, Kommunikationsf&#228;higkeit sowie Prozessverst&#228;ndnis und
Abstraktionsf&#228;higkeit &#8211; um den Einsatz von KI-Systemen an jenen R&#228;ndern zu erg&#228;nzen, an denen die Technik bisher
an Grenzen st&#246;&#223;t1332 
Die F&#246;rderung dieser F&#228;higkeiten beinhaltet Potenziale zur Aufwertung von Arbeit, die sich dann durch
interaktivere, interdisziplin&#228;rere und vielf&#228;ltigere Inhalte auszeichnen. Die Aufgabe der Sozialpartner und der Politik ist
es, solche Chancen m&#246;glichst breit zu streuen und eine Polarisierung der T&#228;tigkeitsstruktur zu vermeiden, bei der 
diese Aspekte h&#246;herwertiger T&#228;tigkeiten auf wenige Spezialistinnen und Spezialisten beschr&#228;nkt bleiben. Von
besonderer Bedeutung ist es daher, die oben genannten F&#228;higkeiten im Bildungssystem und in der beruflichen
Weiterbildung zu vermitteln, damit die neuen M&#246;glichkeiten der Digitalisierung effektiv genutzt werden
k&#246;nnen.1333 
Digitale F&#252;hrungskompetenz
In der digitalen Arbeitswelt wird von F&#252;hrungskr&#228;ften erwartet, dass sie die digitale Transformation im
Unternehmen vorantreiben, selbst digitale F&#228;higkeiten an den Tag legen und ihre Mitarbeiterinnen und Mitarbeiter in
den Transformationsprozess einbinden und sie dabei unterst&#252;tzen, den Wandel zu meistern (sogenanntes Digital
Leadership).1334 Dies gilt verst&#228;rkt f&#252;r die Einf&#252;hrung von KI-Technologien.
F&#252;hrungskr&#228;fte m&#252;ssen sich dar&#252;ber im Klaren sein, welche (KI-)Technologien in ihrem Unternehmen bzw.
ihrem Bereich sinnvoll eingesetzt werden sollen und wie sich diese auf die Arbeit in ihrem Bereich auswirken.
Diesbez&#252;glich m&#252;ssen sich F&#252;hrungskr&#228;fte auch mit ethischen Fragestellungen auseinandersetzen. Sie m&#252;ssen
&#252;berdies den Mitarbeiterinnen und Mitarbeitern erkl&#228;ren k&#246;nnen, wie sich die einzuf&#252;hrenden neuen
Technologien konkret auf ihren Arbeitsplatz und ihr Berufsprofil auswirken und welche Qualifizierungsma&#223;nahmen
notwendig werden. Wenn KI-Tools zunehmend Routinet&#228;tigkeiten &#252;bernehmen k&#246;nnen, k&#246;nnten die frei werdenden
Kapazit&#228;ten der Vorgesetzten f&#252;r die zwischenmenschliche Kommunikation und origin&#228;re F&#252;hrungsaufgaben
wie Motivieren und Coaching verwendet werden. Allerdings werden F&#252;hrungskr&#228;fte m&#246;glicherweise auch mehr
1330 Handlungsempfehlungen von Dr. Terry Gregory (IZA-Institute of Labor Economics), Projektgruppendrucksache 19(27)PG 4-17 vom
25. November 2019.
1331 Vgl. Marcus und Davis (2019): Rebooting AI.
1332 Handlungsempfehlungen von Prof. Dr. Enzo Weber (Institut f&#252;r Arbeitsmarkt und Berufsforschung), Projektgruppendrucksache 
19(27)PG 4-3 vom 22. November 2019.
1333 Handlungsempfehlungen von Prof. Dr. Enzo Weber (Institut f&#252;r Arbeitsmarkt und Berufsforschung), Projektgruppendrucksache 
19(27)PG 4-3 vom 22. November 2019.
1334 Vgl. Hofmann und Wienken (2018): Digital Leadership.
Zeit daf&#252;r ben&#246;tigen, aufgrund der h&#246;heren Entwicklungsgeschwindigkeit auf ver&#228;nderte Bedingungen zu
reagieren. F&#252;r das Gelingen der digitalen Transformation sind allerdings auch die Mitarbeiterinnen und Mitarbeiter
gefordert, an Weiterbildungen teilzunehmen und offen f&#252;r Experimente mit neuen Technologien zu sein.
5.1.2.4 Arbeitsbedingungen
Wie aus den Anwendungsbeispielen in Kapitel 3.2 dieses Projektgruppenberichts [Einf&#252;hrende Beispiele bzw.
Anwendungsf&#228;lle (Use Cases)] hervorgeht, bieten KI-Systeme vielf&#228;ltige Potenziale zur Automatisierung von
T&#228;tigkeiten, zur Verringerung von Komplexit&#228;t und zur Unterst&#252;tzung bzw. Entlastung der Besch&#228;ftigten in
kognitiver und ergonomischer Hinsicht. Wie es auch schon bei herk&#246;mmlichen Automatisierungsschritten bzw. der
Einf&#252;hrung der Informations- und Kommunikationstechnik der Fall war, entfalten sich derartige
Entlastungspotenziale nicht allein durch die Technik. KI wirkt nicht isoliert, sondern in Verbindung mit je spezifischen
Organisationskonzepten und arbeitspolitischen Strategien. Somit kann der Einsatz von KI auch jene Trends zu
wachsenden Leistungsanforderungen, Transparenz und Kontrolle der Leistungserbringung, Standardisierung von
T&#228;tigkeiten und zunehmender Flexibilit&#228;t verst&#228;rken, die die Arbeitswelt in den vergangenen Jahren gepr&#228;gt
haben.1335 
Unterst&#252;tzung oder weitere Intensivierung der Arbeit?
Eine zentrale Dimension f&#252;r den besch&#228;ftigtenfreundlichen Einsatz von KI ist deren Einfluss auf die
Arbeitsintensit&#228;t. Zeit- und Leistungsdruck in der Arbeit und hohe Arbeitsintensit&#228;t geh&#246;ren Besch&#228;ftigtenumfragen
zufolge zu den am h&#228;ufigsten genannten Belastungen.1336 Aus Sicht der Besch&#228;ftigten hat der Einsatz digitaler
Technologien diesbez&#252;glich keine Verbesserungen mit sich gebracht. Im vom Deutschen Gewerkschaftsbund
(DGB) erstellten Index &#8222;Gute Arbeit 2016&#8220; antworteten 55 Prozent der Befragten, dass sie eine Erh&#246;hung der
Arbeitsmenge im Zuge der Digitalisierung erlebten.1337 KI-spezifische Erhebungen stehen in dieser Hinsicht noch
aus. Die Befragungsergebnisse unterstreichen jedoch den Eindruck, dass der Einsatz potenziell
arbeitserleichternder digitaler Technologien nicht zwangsl&#228;ufig mit einer Verringerung der Arbeitsintensit&#228;t einhergeht und
sich die tats&#228;chliche oder wahrgenommene Belastung sogar noch steigern kann. 
In Bezug auf die Spezifika von KI-Systemen sind diesbez&#252;glich folgende Faktoren als m&#246;gliche Treiber erh&#246;hter
Arbeitsintensit&#228;t hervorzuheben:
&#8226; erh&#246;hte Komplexit&#228;t von Prozessen und h&#246;here Anforderungen an deren Geschwindigkeit und Flexibilit&#228;t.
Diese sind zwar nicht KI-getrieben und ergeben sich aus den allgemeinen Umweltbedingungen der
Unternehmen. KI-basierte Technologien bieten jedoch neue M&#246;glichkeiten, diesen Erfordernissen
nachzukommen (Stichworte: &#8222;Losgr&#246;&#223;e 1&#8220;, &#8222;On-demand-Economy&#8220;), die somit auch die Arbeitswelt zunehmend
pr&#228;gen;
&#8226; Arbeitsverdichtung infolge einer allgemeinen Beschleunigung und Rationalisierung von Prozessen;
&#8226; Substitution von Routinet&#228;tigkeiten und eine Verschiebung des T&#228;tigkeitsspektrums hin zu geistig
anspruchsvolleren T&#228;tigkeiten (auch: Multitasking, bereichs&#252;bergreifende Zusammenarbeit). Sollte hier kein
Ausgleich entstehen, steigt die Arbeitsbelastung. Eine Auspr&#228;gung dieses Ph&#228;nomens ist die Verbreitung
projektf&#246;rmiger Arbeit, deren Auspr&#228;gung zwischen &#8222;digitalem Flie&#223;band&#8220; und selbstbestimmter agiler
Arbeit variiert;1338 
&#8226; eine rigidere Kontrolle der Arbeitsleistung durch Techniken des algorithmischen Managements: Beispiele
hierf&#252;r betreffen die bereits erw&#228;hnte algorithmische Steuerung des Arbeitseinsatzes in manchen
Unternehmen der Handelslogistik sowie KI-basierte Anwendungen des Customer-Relations-Managements1339 zur 
Optimierung und Standardisierung von Verkaufsprozessen.1340 
Diese Hinweise auf m&#246;gliche Problemfelder sollten nicht so gedeutet werden, dass die zu beobachtende
Intensivierung von Arbeit einseitig auf Wirkungen der Digitalisierung bzw. KI zur&#252;ckzuf&#252;hren seien und dass sich KI-
1335 Darstellung Dr. Martin Kuhlmann (Soziologisches Forschungsinstitut G&#246;ttingen), Projektgruppendrucksache 19(27)PG 4-62 vom
2. M&#228;rz 2020.
1336 Vgl. Ahlers (2015): Leistungsdruck, Arbeitsverdichtung und die (ungenutzte) Rolle von Gef&#228;hrdungsbeurteilungen.
1337 Vgl. Holler (2017): Verbreitung, Folgen und Gestaltungsaspekte der Digitalisierung in der Arbeitswelt, S. 50.
1338 Vgl. Boes et al. (2018): Lean und agil im B&#252;ro &#8211; Neue Organisationskonzepte in der digitalen Transformation und ihre Folgen f&#252;r
die Angestellten.
1339 Deutsch: Management der Kundenbeziehungen.
1340 Vortrag von Eva-Maria Nyckel (Humboldt-Universit&#228;t zu Berlin), Projektgruppendrucksache 19(27)PG 4-30 vom 16.
Dezember 2019.
Technologien eindeutig in Richtung einer Arbeitsintensivierung und nicht etwa der Entlastung auswirkten. In
einer Befragung von Betriebsr&#228;tinnen und -r&#228;ten des gewerkschaftsnahen Wirtschafts- und
Sozialwissenschaftlichen Instituts (WSI) wurde der Digitalisierung f&#252;r die Arbeitsintensivierung eine sekund&#228;re Rolle
zugesprochen, w&#228;hrend hohe Arbeitsintensit&#228;t in erster Linie unzureichender Personalbemessung, F&#252;hrungsm&#228;ngeln, der
Auftragszunahme und schlechter Arbeits- und Prozessorganisation zugeschrieben wurde.1341 
Dies verdeutlicht, dass die Wirkungen von KI auf Arbeitsvolumen und -belastung im Kontext des
demografischen Wandels (Personalmangels) sowie zunehmender allgemein steigender Anforderungen an Unternehmen
hinsichtlich der Flexibilit&#228;t und der Komplexit&#228;t von Prozessen analysiert werden m&#252;ssen. Digitale
Assistenzsysteme, datenbasierte Entscheidungsunterst&#252;tzung und flexible Robotik k&#246;nnen entscheidende technische
Komponenten daf&#252;r sein, damit die Besch&#228;ftigten die gestiegenen Anforderungen &#252;berhaupt bew&#228;ltigen k&#246;nnen. Die
Wirkung der Technologie auf die Arbeitsbelastung muss jedoch im Rahmen der Einf&#252;hrungsprozesse
thematisiert werden und sozialpartnerschaftlicher Aushandlung unterliegen. KI-Systeme, die einseitig auf die
&#220;berwachung und Verdichtung von Arbeitsleistung abzielen, widersprechen diesem sozialpartnerschaftlichen Gedanken
(siehe Kapitel 5.1.2.6 dieses Projektgruppenberichts [Handlungsempfehlungen]).
Arbeits- und Gesundheitsschutz
Eine Meta-Studie zur bisherigen Literatur &#252;ber den Zusammenhang zwischen Digitalisierung/Industrie 4.0 und
der Gesundheit der Besch&#228;ftigten kommt zu dem Ergebnis, dass &#8222;deutlichen Entlastungspotenzialen [&#8230;]
Belastungsverschiebungen und das Auftreten neuer Belastungen gegen&#252;ber[stehen]&#8220;1342; die Studie weist jedoch
darauf hin, dass diesbez&#252;glich noch deutlicher Forschungsbedarf besteht. Erwartet wird vor allem die Verringerung
physischer Belastungen durch weitere Automatisierungsschritte, w&#228;hrend andererseits auf Risiken neuer
psychischer Belastungen vor allem durch die M&#246;glichkeit digitaler Leistungs&#252;berwachung, Fehlertracking und die
Verringerung von Einflussm&#246;glichkeiten auf Takt und Geschwindigkeit der Arbeitsakte hingewiesen wird.1343 
Eine weitere Meta-Auswertung von 85 existierenden Studien thematisiert, wie sich eine potenzielle
&#220;berwachung der Arbeitsleistung mit der Einf&#252;hrung digitaler Assistenzsysteme auf Besch&#228;ftigte auswirkt, und
identifiziert &#252;berwiegend kleine nachteilige Effekte auf Stresserleben, Beanspruchung, wahrgenommene Kontrolle,
Zufriedenheit, Commitment1344 und Affekt. Es wird jedoch geschlussfolgert, dass diese &#8222;durch eine bewusste
Gestaltung und Implementierung der Systeme abgefedert werden k&#246;nnen, z. B. durch die Vermeidung von
Einzel&#252;berwachung (&#220;berwachungsebene), eine partizipative Einf&#252;hrung unter Beteiligung der Besch&#228;ftigten, eine
sinnvolle Begr&#252;ndung und ein positives Feedback&#8220;1345.
Die Befunde weisen jeweils auf den weiteren Forschungsbedarf sowie auf die Gestaltungsoffenheit von KI-
Systemen hin. Neben einer Zunahme von Belastungen bieten sich auch Chancen, Arbeitsbedingungen individueller
zu gestalten, Belastungen zu reduzieren und Besch&#228;ftigungsf&#228;higkeit auch f&#252;r beeintr&#228;chtigte Menschen zu
f&#246;rdern.1346 Beim Einsatz von KI-Systemen ist daher darauf zu achten, dass die Mensch-Maschine-Schnittstelle
menschenfreundlich und ganzheitlich gestaltet wird.1347 
Auch k&#246;nnen KI-Systeme selbst als Instrumente f&#252;r den Arbeitsschutz eingesetzt werden. Beispielsweise kann
eine Schutzkleidung f&#252;r die Feuerwehr durch Sensoren Vitalparameter der Feuerwehrleute und Umgebungsdaten
erfassen und ein Algorithmus erm&#246;glicht die Aggregation von Daten zum Zweck der Gef&#228;hrdungsbeurteilung.
Die Schutzkleidung kann somit ihrer Tr&#228;gerin oder ihrem Tr&#228;ger und der Einsatzleitung Warnsignale &#252;bermitteln,
wobei wichtige Fragen hinsichtlich der Datennutzung und der Entscheidungskompetenzen zwischen KI-System 
und den Nutzenden noch gekl&#228;rt werden m&#252;ssen, um diese Systeme nutzbar zu machen.1348 
1341 Vgl. Ahlers (2020): Arbeitsintensivierung in den Betrieben. Problemdeutungen und Handlungsfelder von Betriebsr&#228;ten.
1342 Bretschneider et al. (2018): Digitalisierung, Industrie 4.0 und Gesundheit &#8211; ein Literaturreview zur empirischen Befundlage.
1343 Vgl. Bretschneider et al. (2018): Digitalisierung, Industrie 4.0 und Gesundheit &#8211; ein Literaturreview zur empirischen Befundlage.
1344 Deutsch: Engagement bzw. Einsatz.
1345 Backhaus (2019): Kontextsensitive Assistenzsysteme und &#220;berwachung am Arbeitsplatz: Ein meta-analytisches Review zur
Auswirkung elektronischer &#220;berwachung auf Besch&#228;ftigte, S. 10.
1346 Handlungsempfehlungen von Prof. Dr. Lars Adolph (Bundesanstalt f&#252;r Arbeitsschutz und Arbeitsmedizin),
Projektgruppendrucksache 19(27)PG 4-20 vom 9. Dezember 2019.
1347 Handlungsempfehlungen von Prof. Dr. Lars Adolph (Bundesanstalt f&#252;r Arbeitsschutz und Arbeitsmedizin),
Projektgruppendrucksache 19(27)PG 4-20 vom 9. Dezember 2019.
1348 Darstellung Prof. Dr. Lars Adolph (Bundesanstalt f&#252;r Arbeitsschutz und Arbeitsmedizin), in der Sitzung der Projektgruppe KI und
Arbeit, Bildung, Forschung am 9. Dezember 2019.
Arbeitszufriedenheit
&#220;ber die Auswirkungen der Nutzung von KI-Systemen auf die Arbeitszufriedenheit sind bisher kaum
Forschungsergebnisse vorhanden. Bestehende Studien zum Einsatz digitaler (nicht notwendigerweise KI-basierter)
Assistenzsysteme deuten darauf hin, dass diese von den Besch&#228;ftigten oft als eine Entlastung erlebt werden, da
sie dabei helfen k&#246;nnen, die Komplexit&#228;t von Aufgaben zu verringern und Fehler zu vermeiden.1349 Dies ist 
insbesondere dann der Fall, wenn Fragen der Arbeitsqualit&#228;t und -belastung im Technologieentwicklungsprozess
bewusst adressiert und bearbeitet wurden, so wie im Fall der Pilotprojekte APPsist und des KI-basierten HR-
Chatbots &#8222;CARL&#8220;, bei dem &#252;ber eine gestiegene Arbeitsqualit&#228;t berichtet wurde.1350 Allerdings ist davon
auszugehen, dass die subjektive Erfahrung in der Arbeit mit KI-Systemen je nach Einsatzgebiet und
Technologiegestaltung variiert. So nehmen einzelne Besch&#228;ftigtengruppen die Vorgaben der Software durchaus auch als
Einschr&#228;nkung ihrer Autonomie wahr.1351 Zudem k&#246;nnen in der Zusammenarbeit mit Assistenzsystemen neue
Belastungen entstehen, vor allem ist dabei an eine Beeintr&#228;chtigung der Konzentrationsf&#228;higkeit zu denken.1352 
Zuk&#252;nftig wird es Aufgabe sein, die Forschung zu intensivieren, um ein umfassendes Bild zu erhalten.
Lohnentwicklung
Eine h&#228;ufig gestellte Frage im digitalen Zeitalter ist, inwieweit Erwerbst&#228;tige an Produktivit&#228;tsfortschritten
teilhaben k&#246;nnen. Damit ist ein Thema angesprochen, das durch ein breites Spektrum betrieblicher, tariflicher,
steuerrechtlicher und sozialstaatlicher Ma&#223;nahmen bearbeitet werden sollte.
So sind zuk&#252;nftig die Implikationen des Strukturwandels auf die Lohnentwicklung zu beobachten, der mit dem
Einsatz von KI-Systemen verbunden ist. Grunds&#228;tzlich ist diesbez&#252;glich davon auszugehen, dass die
Ver&#228;nderung der Erwerbsstruktur und der Steigerung der Produktivit&#228;t sich auch in einer ver&#228;nderten Gehaltsstruktur
niederschl&#228;gt. Sollte jedoch der Technologieeinsatz eher mit einer polarisierten Besch&#228;ftigungsstruktur
einhergehen, so ist es wahrscheinlich, dass sich dies auch in verst&#228;rkter Lohnungleichheit niederschl&#228;gt.1353 Umgekehrt
sollte sich eine qualifikatorische Aufwertung der Arbeit auch allgemein in h&#246;heren Einkommen niederschlagen,
soweit sich dies angemessen in den Entlohnungstabellen niederschl&#228;gt. Wie bereits in Kapitel 5.1.2.1 dieses
Projektgruppenberichts [Strukturelle &#196;nderungen der Arbeitswelt: Plattformarbeit] angedeutet, kann sich die
ver&#228;nderte Lohnstruktur auch im Kontext von digitalen Arbeitsplattformen auswirken, indem die in der Regel
soloselbstst&#228;ndigen Plattformarbeiterinnen und -arbeiter im Bereich niedrigqualifizierter T&#228;tigkeiten nur ein
niedriges Einkommen erzielen und sie f&#252;r ihre soziale Absicherung nicht hinreichend vorsorgen (k&#246;nnen).
Eine grunds&#228;tzliche &#220;berlegung betrifft die Frage, inwieweit durch KI erzielte Produktivit&#228;tsfortschritte sich
&#252;berhaupt positiv auf die Entwicklung von L&#246;hnen und Geh&#228;ltern auswirken und in welchem Zeitraum dies
geschieht. Einhellige kausale R&#252;ckschl&#252;sse k&#246;nnen aus Erfahrungen der Vergangenheit dabei nur bedingt gezogen
werden. So gibt es Untersuchungen, die aufgrund des Produktivit&#228;tsfortschritts, der durch den Einsatz von
Industrie-Robotern bedingt ist, eher negative Lohnentwicklungen ableiten, aber es gibt auch Einsch&#228;tzungen, die
das Gegenteil belegen. Die Debatte &#252;ber die Auswirkungen auf die Lohnentwicklung in Deutschland und Europa
sowie bestehende Wertsch&#246;pfungsketten &#8211; und damit auch auf Schwellen- und Entwicklungsl&#228;nder &#8211; ist ebenso
wie in der Wissenschaft auch in der Projektgruppe kontrovers diskutiert worden. Eine genaue Prognose ist unter
den derzeitigen Bedingungen nur schwer m&#246;glich, dazu ist eine weitere wissenschaftliche Begleitung
notwendig.1354 
1349 Vgl. Kuhlmann et al. (2018): Montagearbeit 4.0 ? Eine Fallstudie zu Arbeitswirkungen und Gestaltungsperspektiven digitaler
Werkerf&#252;hrung; Butollo et al. (2018): Von Lean Production zur Industrie 4.0. Mehr Autonomie f&#252;r die Besch&#228;ftigten?
1350 Darstellung Dr. Marie-Christin Fregin (Wissenschaftszentrum Berlin und Input-Consulting), in der Sitzung der Projektgruppe KI und
Arbeit, Bildung, Forschung am 9. Dezember 2019.
1351 Vgl. Walker (2017): Subjektive Aneignungspraktiken digitaler Technologien und die zugrunde liegenden Gerechtigkeitsanspr&#252;che
der Besch&#228;ftigten; Staab und Geschke (2019): Ratings als arbeitspolitisches Konfliktfeld.
1352 Vgl. Butollo et al. (2017): Amazonisierung der Industriearbeit?
1353 Vgl. Hirsch-Kreinsen et al. (2018): Digitalisierung industrieller Arbeit.
1354 Prof. Dr. Jens S&#252;dekum (D&#252;sseldorf Institute for Competition Economics) berichtete in seinem Vortrag in der Sitzung der
Projektgruppe KI und Arbeit, Bildung, Forschung am 25. November 2019, dass die verf&#252;gbaren Daten &#252;ber den Einsatz von Industrie-
Robotern in den Jahren 1994 bis 2014 zeigen, dass dies nicht der Fall war. Im Durchschnitt sei die Lohnquote in diesen Jahren
gefallen, obwohl die Vorreiterunternehmen durch den Einsatz der Robotik ihre Wettbewerbsf&#228;higkeit steigern konnten. Der Gro&#223;teil
der Besch&#228;ftigten habe in der Rolle als Arbeitnehmerin oder Arbeitnehmer nicht vom Robotereinsatz profitiert. W&#228;hrend die
prognostizierte &#8222;KI-Dividende&#8220; aufgrund von Produktivit&#228;tssteigerungen durchaus Spielr&#228;ume f&#252;r eine gerechte Verteilung der Ertr&#228;ge
mit sich bringe, ist es sehr wohl m&#246;glich, dass auch der Einsatz von KI die Einkommensungleichheit f&#246;rdert, da der
Technologieeinsatz nun auch den quantitativ noch bedeutsamen Dienstleistungssektor betrifft.
Flexibilisierung der Arbeitszeit
Digitale Technologien erm&#246;glichen in einigen Berufen das zeit- und ortsunabh&#228;ngige Arbeiten. Die Verbreitung
flexibler Arbeitsmodelle ist zwar nicht vorwiegend auf den Einsatz von KI zur&#252;ckzuf&#252;hren, ist aber Teil der
Digitalisierungsdebatte. Im Rahmen dieser Debatte gibt es zum Teil sehr abweichende Positionen, wie mit der
M&#246;glichkeit des orts- und zeitflexiblen Arbeitens umgegangen werden soll. 
Unter Hinweis auf jene Branchen und Berufe, in denen Homeoffice, mobiles und zeitlich flexibles Arbeiten
bereits umfassend praktiziert werden oder praktiziert werden k&#246;nnten, fordern Branchen- und Arbeitgebervertreter
seit einigen Jahren M&#246;glichkeiten, &#252;ber die derzeit bestehenden Arbeitsregelungen hinaus zu gehen und die
t&#228;gliche H&#246;chstarbeitszeit auf eine reine Wochenarbeitszeit f&#252;r alle Branchen umzustellen. Es wird zudem u. a.
vorgeschlagen, die bestehende &#214;ffnungsklausel des Arbeitszeitgesetzes (ArbZG) zu erweitern1355, den
Anwendungsbereich des ArbZG weiter einzuschr&#228;nken1356, die t&#228;gliche Ruhezeit zu verk&#252;rzen oder sie geringf&#252;gig
unterbrechen zu d&#252;rfen.
Innerhalb der Projektgruppe wurde das Thema kontrovers diskutiert. Die Bef&#252;rworterinnen und Bef&#252;rworter
einer &#196;nderung der gesetzlichen Arbeitszeitregelungen verweisen auf die Vorteile f&#252;r Unternehmen und
Besch&#228;ftigte. Durch eine Flexibilisierung des Arbeitszeitgesetzes k&#246;nnen Betriebe besser auf Marktgegebenheiten
eingehen und Betriebsabl&#228;ufe im Sinne von Arbeitgeber und Besch&#228;ftigten besser gestalten. Des Weiteren
argumentieren die Bef&#252;rworterinnen und Bef&#252;rworter, dass die derzeitigen gesetzlichen Ruhezeiten und der 8-Stunden-
Arbeitstag einer zeitsouver&#228;nen Arbeitsgestaltung einiger Besch&#228;ftigten und der damit verbundenen besseren
Vereinbarkeit von Familie, Beruf und Privatleben im Wege stehen w&#252;rden. 
Die Gegnerinnen und Gegner einer arbeitgeberseitigen Flexibilisierung verweisen darauf, dass bereits bestehende
gesetzliche Regelungen den Betrieben schon jetzt umfassende Flexibilisierungsm&#246;glichkeiten bieten. Eine
weitere Flexibilisierung der Arbeitszeiten im Sinne der Unternehmen erschwere die Vereinbarkeit von Familie, Beruf
und Privatleben. Zudem wird auf arbeitsmedizinische Untersuchungen verwiesen, nach denen Mehrarbeit und
die damit einhergehende Reduzierung von Ruhezeiten die Gesundheit und damit auch die
Besch&#228;ftigungsf&#228;higkeit der Besch&#228;ftigten gef&#228;hrden k&#246;nnen.1357 
Der Wunsch vieler Besch&#228;ftigter, ihren Arbeitstag im Rahmen der gesetzlichen Regelungen selbstbestimmter
planen und gestalten zu k&#246;nnen1358, wurde von den Mitgliedern der Projektgruppe als nicht kontrovers angesehen;
sie wollten daraus allerdings auch keine Handlungsempfehlung ableiten. In diesem Zusammenhang wird auch
auf arbeitswissenschaftliche Untersuchungsergebnisse verwiesen, wonach eine h&#246;here Zeitsouver&#228;nit&#228;t und mehr
eigener Handlungsspielraum der Besch&#228;ftigten mit besserer Gesundheit und Zufriedenheit mit der Work-Life-
Balance einhergehen.1359 
Flexible Arbeitsformen und KI-Fachkr&#228;fte
Um weiterhin als attraktiver Arbeitgeber wahrgenommen zu werden, m&#252;ssen Unternehmen in der
Digitalwirtschaft auf die W&#252;nsche der IT- und KI-Expertinnen und -Experten reagieren und flexible Arbeitsformen (z. B. 
Vertrauensarbeitszeit und -ort) anbieten. IT- und KI-Expertinnen und -Experten wie Entwicklerinnen und
Entwickler, Data Scientists, Business-Analystinnen und -Analysten oder Trainerinnen und Trainer stellen hohe
Anforderungen an flexible Arbeitsformen vor allem aus zwei Gr&#252;nden: Zum einen sind diese f&#252;r die agile
Arbeitsweise von IT- und KI-Fachkr&#228;ften notwendig.1360 Zum anderen besteht ein internationaler Wettbewerb der
Unternehmen um die Gewinnung der entsprechenden Fachkr&#228;fte und kl&#252;gsten K&#246;pfe. Insbesondere die
Generationen, die digital aufgewachsen sind (Digital Natives), formulieren gegen&#252;ber dem Arbeitgeber ihren Wunsch nach
Flexibilit&#228;t.1361 
1355 Derzeit erm&#246;glicht das Arbeitszeitgesetz eine flexiblere Arbeitszeitgestaltung nur unter Verwendung der Tarif&#246;ffnungsklausel des
&#167; 7 des Arbeitszeitgesetzes (ArbZG). Das hei&#223;t, Ausnahmeregelungen setzen f&#252;r Abweichungen &#252;berwiegend einen Tarifvertrag oder
eine Betriebs- oder Dienstvereinbarung aufgrund eines Tarifvertrages voraus. Dies schlie&#223;t Unternehmen in Branchen ohne eine
entsprechende Tarifvereinbarung aus.
1356 Derzeit sind nur leitende Angestellte im Sinne des &#167; 5 Absatz 3 des Betriebsverfassungsgesetzes (BetrVG) aus dem
Anwendungsbereich des ArbZG ausgeschlossen.
1357 Vgl. Beermann et al. (2019): Arbeitswissenschaftliche Erkenntnisse zu Arbeitszeit und gesundheitlichen Auswirkungen;
Bundesanstalt f&#252;r Arbeitsschutz und Arbeitsmedizin (2018): 100 Jahre Achtstundentag.
1358 Vgl. IG Metall (2017): Arbeitszeit &#8211; sicher, gerecht und selbstbestimmt.
1359 Vgl. W&#246;hrmann et al. (2016): Arbeitszeitreport Deutschland 2016.
1360 Vgl. Dettmers et al. (2020): Agile Unternehmen; Haak (2020): Dieses KI-Startup arbeitet auch nur mit Google und Slack.
1361 Vgl. Welz (2018): Das Buhlen um den digitalen Nachwuchs.
Agilit&#228;t bezeichnet die F&#228;higkeit von Unternehmen, schnell, effektiv und gewinnbringend auf sich &#228;ndernde
Gegebenheiten reagieren zu k&#246;nnen. Die Anwendung agiler Methoden der Zusammenarbeit (z. B. &#8222;Scrum&#8220;,
&#8222;Kanban&#8220;, &#8222;Design Thinking&#8220;) kann beispielsweise den Kundenbezug erh&#246;hen sowie Produktivit&#228;tssteigerungen
realisieren. Agile Teams erarbeiten sich in einem kreativen und innovativen Prozess ihre Aufgabenstellung selbst &#8211;
und parallel sofort die L&#246;sung. Zu den Kriterien der agilen Arbeitsweise z&#228;hlen Transparenz, Selbstorganisation,
durchl&#228;ssige Hierarchien sowie flexible Systeme und Verfahren. Die Entwicklung erfolgt h&#228;ufig in virtuellen
Teams1362, dessen Mitglieder &#252;ber Landesgrenzen und Zeitzonen hinweg zusammenarbeiten. Die Arbeit ist ziel-
und ergebnisorientiert, die am Arbeitsplatz verbrachten Stunden spielen eine weniger bedeutsame Rolle. Die
agile Arbeitsweise erfordert die M&#246;glichkeit einer flexiblen Arbeitszeitgestaltung.
Deutschland ben&#246;tigt dringend IT- und KI-Expertinnen und -Experten, um die digitale Transformation zu
gestalten. Seit Jahren k&#228;mpft Deutschland mit einem IT-Fachkr&#228;ftemangel. Derzeit sind circa 124 000 Stellen f&#252;r IT-
Spezialistinnen und -Spezialisten unbesetzt.1363 Was speziell KI-Fachkr&#228;fte angeht, beklagen 80 Prozent
deutscher Unternehmen einen Mangel an KI-Expertinnen und -Experten. Die H&#228;lfte der Unternehmen sieht den
Fachkr&#228;ftemangel als Haupthemmnis f&#252;r den Fortschritt von KI-Projekten.1364 Laut einer Studie des Leibniz-Zentrums
f&#252;r Europ&#228;ische Wirtschaftsforschung (ZEW) waren 2019 in Deutschland 22 500 KI-Stellen unbesetzt; nur jede
zweite offene Stelle im Bereich KI konnte besetzt werden.1365 
5.1.2.5 Partizipation und Mitbestimmung
&#8222;Ein zentrales Element f&#252;r die erfolgreiche Gestaltung und Einf&#252;hrung von KI-Technologien in den Betrieben
ist die fr&#252;hzeitige Einbindung der Besch&#228;ftigten und ihrer Interessenvertretungen in die
Transformationsprozesse: Dabei geht es auf Grundlage einer attraktiven Arbeitsgestaltung um die Gewinnung von Vertrauen und die
Erm&#246;glichung von Akzeptanz f&#252;r die neuen KI-Systeme.&#8220;1366 
&#8222;Betriebliche Mitbestimmung und eine fr&#252;hzeitige Einbindung der Betriebsr&#228;te st&#228;rken das Vertrauen und die
Akzeptanz der Besch&#228;ftigten bei der Einf&#252;hrung und Anwendung von KI!&#8220;1367 Die Hochrangige Expertengruppe
f&#252;r k&#252;nstliche Intelligenz der Europ&#228;ischen Kommission (High-Level Expert Group on Artificial Intelligence &#8211;
HLEG AI) h&#228;lt die &#8222;Beteiligung der Interessentr&#228;ger w&#228;hrend des gesamten Lebenszyklus des KI-Systems&#8220; f&#252;r
erforderlich. &#8222;Schulungs- und Ausbildungsf&#246;rderung&#8220; sollen dem Ziel dienen &#8222;allen Interessenstr&#228;gern
Kompetenzen auf dem Gebiet der vertrauensw&#252;rdigen KI zu vermitteln&#8220;. Die Expertengruppe stellt fest: &#8222;Es ist von
Vorteil, auch nach der Einf&#252;hrung eines Systems regelm&#228;&#223;ige R&#252;ckmeldungen einzuholen und l&#228;ngerfristige
Vorkehrungen zur Beteiligung der Interessentr&#228;ger zu schaffen.&#8220;1368 Bei der Ausgestaltung der
Mitbestimmungsrechte der Interessenvertretungen &#252;ber die Verarbeitung personenbezogener Daten im Betrieb muss der
bestehenden Wissensasymmetrie zwischen Arbeitgeber- und Arbeitnehmerseite &#252;ber die Wirkungsweise und Details
der Verarbeitungsvorg&#228;nge angemessen Rechnung getragen werden.1369 &#8222;Angesichts der st&#228;ndigen
Fortentwicklung datenverarbeitender Systeme im Betrieb sollte eine Fortentwicklung von punktueller Mitbestimmung zur
dauerhaften Begleitung von Prozessen durch die Interessenvertretungen erfolgen.&#8220;1370 Auch die
Herausforderungen f&#252;r die Sicherheit im gesamten Lebenszyklus eines KI-basierten Systems machen deutlich, dass eine
einmalige Pr&#252;fung vor dem Inverkehrbringen nicht ausreicht.1371 
KI-Systeme erlauben neue Interaktionsbeziehungen zwischen technischen Systemen und dem Menschen mit
Wirkungen auf Verhalten und Erleben des Individuums. Dies macht den partizipativen Einbezug von
Nutzerinnen und Nutzern, Entwicklerinnen und Entwicklern und betroffenen Besch&#228;ftigten bei Design, Umsetzung und
Nutzung der Systeme besonders wichtig. Lernende Systeme ver&#228;ndern sich in ihrer Laufzeit. Sie werden
entweder iterativ mit Trainingsdaten versorgt oder lernen kontinuierlich. So wird es auch auf der technischen Ebene
1362 Vgl. Wisskirchen et al. (2017): Artificial Intelligence and Robotics and Their Impact on the Workplace.
1363 Vgl. Bitkom e. V. (2019): Erstmals mehr als 100 000 unbesetzte Stellen f&#252;r IT-Experten.
1364 Vgl. Hensel und Litzel (2018): IDC-Studie identifiziert Nachholbedarf &#8211; Mangel an Fachkr&#228;ften bremst KI-Projekte aus.
1365 Vgl. Bundesministerium f&#252;r Wirtschaft und Energie (2020): Einsatz von K&#252;nstlicher Intelligenz in der Deutschen Wirtschaft.
1366 Plattform Lernende Systeme (2019): Arbeit, Qualifizi erung und Mensch-Maschine Interaktion, S. 13.
1367 Bundesregierung (2018): Strategie K&#252;nstliche Intelligenz der Bundesregierung, S. 28.
1368 High-Level Expert Group on Artificial Intelligence (2019): Ethik-Leitlinien f&#252;r eine vertrauensw&#252;rdige KI, S. 23.
1369 Vgl. Datenethikkommission der Bundesregierung (2019): Gutachten der Datenethikkommission der Bundesregierung, S. 113.
1370 Datenethikkommission der Bundesregierung (2019): Gutachten der Datenethikkommission der Bundesregierung, S. 113.
1371 Vgl. Verband der T&#220;V e. V.: Vertrauen in KI-basierte Systeme schaffen, Nr. 5.
erforderlich sein, das Systemverhalten zu beobachten und Erfahrungen an den Hersteller zur&#252;ckflie&#223;en zu
lassen.1372 
Laut einer ver.di-Befragung berichtete 2019 nur ein Teil der Interessenvertretungen, voll oder zumindest
teilweise einbezogen zu werden bei der Planung (9 bzw. 23 Prozent), der Einf&#252;hrung (23 bzw. 33 Prozent) und der
Nutzung (15 bzw. 29 Prozent) von KI im Unternehmen. 88 Prozent der Befragten reklamierten, dass sie als
Betriebs-/Personalrat mehr und st&#228;rkere Mitbestimmungsrechte bei der Planung f&#252;r den KI-Einsatz im Betrieb
bez&#252;glich der Arbeitsgestaltung brauchen.1373 
Die Mitbestimmung gilt als besonderes Merkmal der Sozialordnung Deutschlands und als Erfolgsfaktor der
deutschen Wirtschaft. Doch die gesetzlichen Grundlagen orientieren sich nach wie vor an einer herk&#246;mmlichen
industriegesellschaftlich gepr&#228;gten und analogen Arbeitswelt. Mitbestimmung wurde urspr&#252;nglich u. a. auf den
Vorgang der Einf&#252;hrung technischer Einrichtungen ausgerichtet, die im Betrieb nach der Einf&#252;hrung &#252;ber l&#228;ngere
Zeitr&#228;ume unver&#228;ndert geblieben sind. Eine derartige Mitbestimmungskultur wird dem Prozesscharakter
lernender Maschinen nicht gerecht.   
Nach &#167; 75 des Betriebsverfassungsgesetzes (BetrVG) haben Arbeitgeber und Betriebsr&#228;te die freie Entfaltung
der Pers&#246;nlichkeit der im Betrieb besch&#228;ftigten Arbeitnehmerinnen und Arbeitnehmer zu sch&#252;tzen und zu
f&#246;rdern. Sie haben dar&#252;ber zu wachen, dass die im Betrieb t&#228;tigen Personen nach den Grunds&#228;tzen von Recht und
Billigkeit behandelt werden und dass insbesondere jede Diskriminierung unterbleibt. Diesem Anspruch stehen
aber keine wirksamen Initiativrechte gegen&#252;ber, obwohl die Bedeutung dieser Aufgaben durch den KI-Einsatz
steigt.
Die urspr&#252;nglichen Adressaten des Schutzanspruches, die Arbeitnehmerinnen und Arbeitnehmer im Betrieb,
werden heute zunehmend durch Leistungserbringer erg&#228;nzt, die au&#223;erhalb herk&#246;mmlicher Betriebsgrenzen
verortet sind, z. B. Soloselbstst&#228;ndige auf digitalen Arbeitsplattformen.
Die Anh&#246;rung einer deutschen Betriebsr&#228;tin von Amazon1374 offenbarte das Machtungleichgewicht in der
Gestaltung von KI-Anwendungen zwischen einem amerikanischen Weltkonzern und einem regional verorteten
Mitbestimmungstr&#228;ger. Selbst europ&#228;ische Betriebsr&#228;te haben nur Anh&#246;rungs-, keine Normsetzungsrechte,
w&#228;hrenddessen KI-Systeme nationale Grenzen nicht kennen. Dies verlangt nach einer Aktualisierung transnationaler
Mitbestimmungsregeln. 
Der Anspruch, den Einsatz von KI an ethischen Prinzipien auszurichten, braucht die Aufmerksamkeit auch der
Aufsichtsr&#228;te als Funktionstr&#228;ger wirtschaftlicher Mitbestimmung. In 50 Prozent der Betriebe beklagen
Betriebsr&#228;te im Organisationsbereich der IG-Metall, dass es heute keine systematische Personalplanung gibt. Das f&#252;hrt
zu Problemen im Hinblick auf die Anschlussf&#228;higkeit der Besch&#228;ftigten und zu wirtschaftlichen Nachteilen f&#252;r
Unternehmen. Qualitative Personalplanung sollte auch die Akteure wirtschaftlicher Mitbestimmung
interessieren, gerade weil Vertreterinnen und Vertreter der Wirtschaft heute einen Fachkr&#228;ftemangel als Wachstumsbremse
definieren und einen Mangel an KI-Anwendungs- und Entwicklungswissen beklagen.
Beim Einsatz von automatisierten Entscheidungssystemen (ADM) und KI-Systemen in Organisationen muss die
Zielsetzung f&#252;r die Nutzung gekl&#228;rt werden und alle relevanten Interessengruppen mit eingebunden werden. Der
Einsatz muss zudem der Mitbestimmung des Betriebsrats unterliegen, soweit ein solcher vorhanden ist.1375 Von 
der in den Systemen festgelegten Zielbestimmung h&#228;ngt auch die konkrete Gestaltung von Arbeitsbedingungen
ab, etwa im Hinblick auf Belastungsver&#228;nderungen oder Qualifikationserfordernisse. Gerade wenn &#8222;Gute Arbeit 
by design&#8220; erfolgreich in die Systeme implementiert wird, sind positive Entwicklungen einer pr&#228;ventiven
betrieblichen Arbeitsgestaltung zu erwarten. F&#252;r Unternehmen und andere Organisationen ohne Betriebs- oder
Personalr&#228;te k&#246;nnen, neben den Vorgaben des Gesetzgebers, auch Grundbedingungen &#252;ber die M&#246;glichkeiten der
Industrienormung und der Daten- und Arbeitsschutzinstanzen verbreitet werden. Es muss klare
Verantwortlichkeiten f&#252;r Risiken und Sch&#228;den des Einsatzes von KI-Systemen geben. Diese d&#252;rfen nicht auf das KI-System 
selbst, die Anwenderinnen und Anwender oder andere betroffene Personen abgew&#228;lzt werden.
1372 Handlungsempfehlungen von Prof. Dr. Lars Adolph (Bundesanstalt f&#252;r Arbeitsschutz und Arbeitsmedizin),
Projektgruppendrucksache 19(27)PG 4-20 vom 9. Dezember 2019.
1373 Vgl. Zanker et al. (2019): ver.di &#8211; Innovationsbarometer 2019 K&#252;nstliche Intelligenz, S. 32.
1374 Darstellung Anka Grosch (Betriebsrat Amazon Logistikzentrum Leipzig) in der Sitzung der Projektgruppe KI und Arbeit, Bildung,
Forschung vom 13. Januar 2020.
1375 Bereits nach aktueller Rechtslage stehen dem Betriebsrat verschiedene Mitbestimmungsrechte im Fall der Implementierung neuer
IT-Systeme durch den Arbeitgeber zur Verf&#252;gung. So regelt &#167; 87 Absatz 1 Nummer 6 des Betriebsverfassungsgesetzes (BetrVG) ein
Mitbestimmungsrecht bei der Einf&#252;hrung und Anwendung von technischen Einrichtungen, die dazu bestimmt sind, das Verhalten
oder die Leistung der Besch&#228;ftigten zu &#252;berwachen.
5.1.2.6 Handlungsempfehlungen
5.1.2.6.1 Im Allgemeinen
KI so gestalten, dass Arbeit menschengerechter wird
Die Gestaltung der KI ist das Ergebnis von Aushandlungsprozessen. KI kann in unterschiedlichster Weise
gestaltet werden, was von den gesteckten Zielen und deren Priorisierung abh&#228;ngt und von einer kompletten
Maximierung der Automation bis zur individuellen Anpassung f&#252;r bestimmte Probleme reicht. Das Ergebnis der
Optimierung durch die KI h&#228;ngt also von den gesteckten Zielen und deren Priorisierung ab. Dazu ist die Beteiligung
aller relevanten gesellschaftlichen Interessengruppen erforderlich.1376 
Auch eine Selbstverpflichtung von Unternehmen1377 kann dazu beitragen, dass die Auswirkungen der
Automatisierung in einer Organisation genau beschrieben und die Betroffenen fr&#252;hzeitig eingebunden werden
(sogenannter &#8222;Human-Friendly-Automation&#8220;-Ansatz).
Die Akzeptanz unter den Besch&#228;ftigten und die erfolgreiche Implementierung von KI h&#228;ngt ma&#223;geblich von 
fr&#252;hzeitiger Information und Beteiligung ab. Die Betriebsratsgremien bilden hier ein wichtiges Scharnier.1378 
Kompetenzbedarf erforschen &#8211; Kompetenzerwerb entlang der gesamten Bildungskette f&#246;rdern
Zur Erforschung der notwendigen Kompetenzen in der digitalen Arbeitswelt entwickelt das BMAS gemeinsam
mit dem Institut f&#252;r Arbeitsmarkt- und Berufsforschung (IAB) einen sogenannten Kompetenzkompass, in dem
Ver&#228;nderungen der Kompetenzanforderungen nach Branchen &#8222;geclustert&#8220; werden. Dieser bezieht sich auf die
allgemeine digitale Transformation, bei der KI einen Aspekt darstellt.1379 Zur weiteren und praxisnahen
Erforschung der notwendigen Kompetenzen speziell f&#252;r die Entwicklung und den Einsatz von KI, sollten &#252;ber den
&#8222;Kompetenzkompass&#8220; hinaus spezifische F&#246;rderprogramme eingerichtet werden.
Um die Menschen auf den Umgang mit KI optimal vorzubereiten, m&#252;ssen die notwendigen F&#228;higkeiten entlang 
der gesamten Bildungskette vermittelt und gef&#246;rdert werden. Die Ausbildungsinhalte sollten die zuk&#252;nftige
Einsatzf&#228;higkeit der Besch&#228;ftigten sichern, indem &#252;bergreifende Schl&#252;sselqualifikationen und
bereichs&#252;bergreifendes Denken gef&#246;rdert werden.1380 
&#8222;Der Umgang mit KI bedarf eines neuen und speziellen Sets an digitalen und sozialen F&#228;higkeiten. Zu den
digitalen F&#228;higkeiten geh&#246;ren u. a. grundlegende Programmierkenntnisse sowie zentrale analytische F&#228;higkeiten &#8211;
wie z. B. der Umgang mit Daten und Methoden des Maschinellen Lernens. Daneben werden soziale F&#228;higkeiten 
wie kritisches Denken, Kreativit&#228;t, Stressresistenz, Kommunikationsf&#228;higkeit und emotionale Intelligenz immer
wichtiger. Gerade diese F&#228;higkeiten machen die &#220;berlegenheit des Menschen gegen&#252;ber Maschinen aus und
werden k&#252;nftig noch bedeutsamere Faktoren auf dem Arbeitsmarkt sein.&#8220;1381 
&#8222;Gleicherma&#223;en gilt es, das duale Bildungssystem f&#252;r die Zukunft fit zu machen. [&#8230;] Die Rahmenlehrpl&#228;ne f&#252;r
die duale Berufsausbildung sollten an die Anforderungen einer digitalen, durch den Einsatz von KI gepr&#228;gten
Arbeitswelt angepasst werden. Um mit dem technologischen Wandel schritthalten zu k&#246;nnen, bedarf es zudem
der Schaffung von Mechanismen zur regelm&#228;&#223;igen Evaluierung der Bildungsinhalte. Zudem sollte die
Etablierung neuer Ausbildungsberufe, die durch die zunehmende Verbreitung von KI entstehen werden, sowie deren
Anerkennung durch das Bundeswirtschaftsministerium schnell und unb&#252;rokratisch erfolgen.&#8220;1382 
1376 Handlungsempfehlungen von Dr. Britta Matthes (Institut f&#252;r Arbeitsmarkt- und Berufsforschung), Projektgruppendrucksache
19(27)PG 4-21 vom 9. Dezember 2019.
1377 Vgl. Schatilow (2019): Human Friendly Automation Charta.
1378 Siehe auch Kapitel 5.1.2.5 dieses Projektgruppenberichts [Partizipation und Mitbestimmung].
1379 Darstellung Dr. Julia Borggr&#228;fe (Abteilungsleiterin &#8222;Digitalisierung und Arbeitswelt&#8220; im Bundesministerium f&#252;r Arbeit und
Soziales), in der Sitzung der Projektgruppe KI und Arbeit, Bildung, Forschung am 25. November 2019.
1380 Siehe zum Thema schulische Bildung und Hochschule auch Kapitel 5.2 dieses Projektgruppenberichts [KI in der Bildung]; vgl. auch
die Arbeit der Enquete-Kommission &#8222;Berufliche Bildung in der digitalen Arbeitswelt&#8220;.
1381 Handlungsempfehlungen von Thomas Langkabel (Microsoft Deutschland), Projektgruppendrucksache 19(27)PG 4-6 vom 6.
Dezember 2019.
1382 Handlungsempfehlungen von Thomas Langkabel (Microsoft Deutschland), Projektgruppendrucksache 19(27)PG 4-6 vom 6.
Dezember 2019; vgl. hierzu auch die Arbeit der Enquete-Kommission &#8222;Berufliche Bildung in der digitalen Arbeitswelt&#8220;.
5.1.2.6.2 Mensch-Maschine-Interaktion
Klarheit von Handlungstr&#228;gerschaft, F&#252;hrung und Situationskontrolle bei der Arbeit mit KI-Systemen
gew&#228;hrleisten
&#8222;Bei der Interaktion mit KI-Systemen kann ein Teil der Handlungstr&#228;gerschaft beziehungsweise
Situationskontrolle (Wer st&#246;&#223;t Handlungen an? Wer koordiniert eine Situation?) auf der Seite des technischen Systems liegen
(hybride Handlungstr&#228;gerschaft). Das System nimmt eine Rolle als Akteur ein. Diese Rollenverteilung ist
bewusst zu gestalten. Verantwortlichkeiten m&#252;ssen zu Zeitpunkten und f&#252;r Prozesse definierbar sein. Auch m&#252;ssen
Rollenwechsel zwischen Person und KI-System definierbar sein, nur so kann auch Verantwortung gekl&#228;rt
werden.&#8220;1383 
Die definierten Rollen und Aufgaben m&#252;ssen au&#223;erdem analysiert werden, um daraus abzuleiten, welche
Qualifikationen gebraucht werden. F&#252;r den Erhalt der Arbeitszufriedenheit ist es entscheidend, wie ein hohes Ma&#223; an
Autonomie f&#252;r Besch&#228;ftigte aufrechterhalten werden kann. Die Optimierung der Zusammenarbeit zwischen
Menschen und lernenden Systemen beruht zu einem Gro&#223;teil auf pers&#246;nlichen Daten. In diesem Zusammenhang muss
gekl&#228;rt werden, wozu pers&#246;nliche Daten genutzt werden, wo die Grenzen f&#252;r die Datennutzung liegen und wie
transparent die Datennutzung ist. So sollten beispielsweise pers&#246;nliche Daten f&#252;r die Gesundheitsf&#246;rderung
genutzt werden k&#246;nnen, ohne dass dieser Vorgang zur Kontrolle und &#220;berwachung der Besch&#228;ftigten f&#252;hrt.1384 
Menschengerechte und gute Arbeitsgestaltung bei KI-Systemen f&#246;rdern
&#8222;Grunds&#228;tzlich ist der regulative Rahmen, z. B. mit der Betriebssicherheitsverordnung, die ein systemisches
Verst&#228;ndnis von Ergonomie beinhaltet, auch f&#252;r Systeme mit KI geeignet. Es erscheint f&#252;r eine bessere Umsetzung
jedoch sinnvoll, im untergesetzlichen Bereich (technische Regeln, Normung, Leitf&#228;den) Konkretisierungen f&#252;r
die Spezifika von KI zu schaffen.&#8220;1385 
Nach der Einsch&#228;tzung eines Sachverst&#228;ndigen1386 reichen derzeit bestehende gesetzliche Vorschriften des
Arbeitsschutzes f&#252;r die Anwendung von KI aus. Die Gef&#228;hrdungsbeurteilung der Arbeitsprozesse &#8211; die Basis des
deutschen Arbeitsschutzes &#8211; gelte im Umgang mit KI als sinnvoll. Technische Regeln, die z. B. die
Betriebsoder Arbeitsst&#228;ttenverordnung konkretisierten, seien dagegen zu aktualisieren (z. B. Einsatz von modernen KI-
unterst&#252;tzten Assistenzsystemen wie Datenbrillen und Smartwatches).1387 
5.1.2.6.3 Mitbestimmung modernisieren
Die Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220; schlie&#223;t sich den Empfehlungen der Projektgruppe &#8222;KI
und Wirtschaft&#8220; an, die zu Recht feststellt: &#8222;Zur Wahrung von Einflussm&#246;glichkeiten von Arbeitnehmerinnen
und Arbeitnehmern beim Schutz ihrer Pers&#246;nlichkeitsrechte, der Vermeidung von &#220;berlastung, der Bew&#228;ltigung
von betrieblicher Transformation und der Gestaltung von Besch&#228;ftigungsbedingungen, ist ein Update der
Mitbestimmung erforderlich, das der technischen Entwicklung Rechnung tr&#228;gt und die bisherige Balance zwischen
Arbeitnehmerrechten und Eigentumsrechten fortentwickelt&#8220;.1388 Um dem Prozesscharakter lernender Maschinen
gerecht zu werden und um vorausschauend, wirksam und schnell zu wirken, muss die betriebliche
Mitbestimmung auf das Konzept der Entwicklung, des Einsatzes und der Fortentwicklung der Systeme ausgerichtet sein. 
Sie muss sich au&#223;erdem der normativen Wirkung aller wesentlichen Fragen der Pers&#246;nlichkeitsrechte annehmen
k&#246;nnen und einen wirksamen Einfluss auf die Arbeitsmenge, Arbeitsorganisation und die Qualifizierung
er&#246;ffnen, die sich im Zusammenhang mit dem Einsatz von KI-Systemen ergeben. Dieser Intention folgend sind
folgende Elemente der Modernisierung der Mitbestimmung zu pr&#228;zisieren:
1383 Handlungsempfehlungen von Prof. Dr. Lars Adolph (Bundesanstalt f&#252;r Arbeitsschutz und Arbeitsmedizin),
Projektgruppendrucksache 19(27)PG 4-20 vom 9. Dezember 2019.
1384 Darstellung Oliver Suchy (Deutscher Gewerkschaftsbund) in der Sitzung der Projektgruppe KI und Arbeit, Bildung, Forschung am
25. November 2019.
1385 Handlungsempfehlungen von Prof. Dr. Lars Adolph (Bundesanstalt f&#252;r Arbeitsschutz und Arbeitsmedizin),
Projektgruppendrucksache 19(27)PG 4-20 vom 9. Dezember 2019; siehe hierzu auch Kapitel 5.4 dieses Projektgruppenberichts [Gestaltungsinstrumente 
und Gestaltungsakteure].
1386 Prof. Dr. Sascha Stowasser (Institut f&#252;r angewandte Arbeitswissenschaft).
1387 Handlungsempfehlungen von Prof. Dr. Sascha Stowasser (Institut f&#252;r angewandte Arbeitswissenschaft), Projektgruppendrucksache
19(27)PG 4-44 vom 10. Januar 2020.
1388 Vgl. Kapitel 5.6. des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220; [Rechtsentwicklung und Politik].
Besch&#228;ftigte und ihre Interessenvertretungen sollen u. a.
&#8226; bereits bei der Definition der Zielsetzung und Konfiguration von KI-Systemen ebenso wirksam mitgestalten
k&#246;nnen wie bei der Evaluation, dem Betrieb und der Fortentwicklung der soziotechnischen
Einsatzbedingungen; ob dies generell bei der Verwendung von Daten oder nur bei der Verwendung personenbezogener
Daten gelten soll, war in der Projektgruppe umstritten,
&#8226; der steigenden Bedeutung der Personalplanung und -entwicklung sowie der Qualifizierung von
Besch&#228;ftigten Rechnung tragen k&#246;nnen, indem sie ein Mitbestimmungs- und Initiativrecht in Fragen der Weiterbildung
erhalten,
&#8226; eine wirksame Mitbestimmung nutzen k&#246;nnen, wobei alle in der Verfassung definierten
Pers&#246;nlichkeitsrechte gesch&#252;tzt werden,
&#8226; ihr Handeln auf eine nachvollziehbare Technikfolgenabsch&#228;tzung, G&#252;tekriterien, Zertifizierungen,
Auditierungen und die Arbeit des Observatoriums der Bundesregierung st&#252;tzen k&#246;nnen,
&#8226; auf Mitbestimmungsrechte zugreifen k&#246;nnen, die dem Prozesscharakter der Transformation gerecht werden.
Zeit- und ortsflexibles Arbeiten muss auch in der Betriebsratsarbeit zur Realit&#228;t werden k&#246;nnen.
Betriebsratssitzungen sollten auch per Videokonferenz stattfinden k&#246;nnen und eine elektronische Stimmabgabe bei
der rechtsverbindlichen Beschlussfassung sollte gesetzlich erm&#246;glicht werden. Der Betriebsrat muss
au&#223;erdem die Besch&#228;ftigten elektronisch erreichen k&#246;nnen,
&#8226; einen besseren Einfluss bei der Verortung von Produktion und Dienstleistung erhalten, weil sie im
Gegensatz zu KI-Systemen r&#228;umlich gebunden sind,
&#8226; auf Arbeitsdichte und Arbeitsmenge Einfluss haben, die sich aus der Maschine-Mensch-Schnittstelle ergibt,
&#8226; einen einfachen Zugang zu Weiterbildungs- und Beratungsangeboten haben, um die eigene KI-Kompetenz 
auszubauen, gerade f&#252;r eine ad&#228;quate Folgenabsch&#228;tzung ist ein einfacher Zugang zu externem
Expertenwissen notwendig, das entweder durch Arbeitgeber oder &#246;ffentlich finanziert ist. Zu pr&#252;fen w&#228;re hier der
Auf- und Ausbau von staatlich gef&#246;rderten Technologieberatungsstellen.
Bei der Modernisierung der Mitbestimmung ist au&#223;erdem zu ber&#252;cksichtigen, dass neben den Arbeitnehmerinnen
und Arbeitnehmern im Betrieb heute zunehmend externe Leistungserbringer an der Wertsch&#246;pfung teilnehmen. 
Zudem m&#252;ssen Mitbestimmungsl&#252;cken bei transnational verantworteten KI-Systemen sowie transnationalen
Konzernen geschlossen werden.
Zugleich sollten die Prinzipien und Inhalte von herk&#246;mmlichen Betriebsvereinbarungen auf Basis des &#167; 87
Absatz 1 Nr. 6 BetrVG weiter bzw. neu gedacht werden. Es geht darum, die Prozessorientierung zu st&#228;rken und
agiler zu gestalten sowie die Analyse von Auswirkungen und die Evaluierung auf Standards und
wissenschaftlichen Erkenntnissen aufzubauen.
Um die Mitbestimmung praktikabel zu gestalten, sollten Prozesse zwischen Arbeitgeber und Betriebsrat
vereinbart werden, die den Einsatz von KI in den Unternehmen unterst&#252;tzen bzw. beschleunigen und gleichzeitig die
Rechte und Interessen der Besch&#228;ftigten wahren.
Um den Zustimmungsprozess zu beschleunigen, w&#228;re es beispielsweise m&#246;glich, dass Arbeitgeber und
Betriebsrat eine prinzipienbasierte Rahmenvereinbarung und anwendungsspezifische Einzelvereinbarungen abschlie&#223;en.
Ein Vorteil dieser L&#246;sung w&#228;re es, den Aufwand beim Abschluss der zahlreichen Einzelvereinbarungen zu
reduzieren. In der Rahmenvereinbarung sollten Punkte geregelt werden, die bei der Einf&#252;hrung aller Anwendungen
als Fragen aufkommen. Beispielsweise k&#246;nnten Fragen des Datenschutzes, der Ethik oder der Transparenz
gekl&#228;rt werden, z. B. welche Personen im Unternehmen und im Betriebsrat auf die Input- bzw. Ergebnis-Daten
Zugriff erhalten oder wer den Algorithmus kennt und wie dessen technische Robustheit, Transparenz,
Erkl&#228;rbarkeit und Diskriminierungsfreiheit gew&#228;hrleistet werden. Hierbei m&#252;sste die Rahmenvereinbarung Prinzipien
definieren, und wenn diese erf&#252;llt sind, w&#252;rden sie in anwendungsspezifischen Vereinbarungen nicht mehr
gesondert behandelt. F&#252;r die Ersteinf&#252;hrung bieten sich Tests, Pilotverabredungen und gemeinsame Lernlabore an.
Aufsichtsr&#228;te f&#252;r die Auswirkungen von KI sensibilisieren
Daneben sind Mechanismen zu schaffen, um die Aufmerksamkeit von Aufsichtsr&#228;ten auf die Implikationen von 
KI-Systemen zu richten. Es geht darum, einer qualitativen Personalplanung Gewicht zu geben, Transparenz f&#252;r
den innerbetrieblichen Einsatz von KI-Systemen zu organisieren, neue Gesch&#228;ftsmodelle mit KI anzuregen und
Ethikma&#223;st&#228;be relevant f&#252;r die Unternehmenssteuerung werden zu lassen.
Ma&#223;st&#228;be entwickeln
Wer KI-L&#246;sungen in der Arbeitsorganisation anbietet oder nutzt, muss darauf achten, dass diese empirisch
evaluiert sind und &#252;ber eine wissenschaftliche Grundlage verf&#252;gen. Hierf&#252;r k&#246;nnte etwa eine Fach- oder
Zertifizierungsstelle eingerichtet werden, die auf wissenschaftlicher Basis Empfehlungen oder Zertifikate erstellt. Auch
eine &#246;ffentlich verf&#252;gbare Sammlung von Experten-Bewertungen und Betriebsvereinbarungen zu gepr&#252;ften
Softwares ist sinnvoll. Gleichzeitig m&#252;ssen Organisationen die zugrunde liegende Technologie der eingesetzten KI
und deren Entscheidungslogik sowie die Auswirkungen auf die Arbeitsprozesse verstehen und erkl&#228;ren k&#246;nnen.
5.1.3 Arbeitsorganisation und Arbeitsverwaltung 
5.1.3.1 Arbeitsorganisation
Es gibt Wechselwirkungen zwischen dem Einsatz von KI-Systemen und verschiedenen Aspekten der
Organisation der Arbeit. Der Schutz der Pers&#246;nlichkeitsrechte, die Organisation von Partizipation und Mitbestimmung,
die Schaffung von Transparenz und Nachvollziehbarkeit, die Schaffung von Vertrauenskulturen durch
aufgekl&#228;rte Akzeptanz und Aspekte qualitativer Personalplanung sowie der Handlungsautonomie und der Belastung
werden vom Einsatz lernender Maschinen ber&#252;hrt. Gestaltungsaufgaben f&#252;r den Einsatz der Systeme ergeben
sich aus der Art der Anwendung, beispielsweise in der Personalverwaltung, der Bewerberauswahl, der
Arbeitssteuerung und -kontrolle, der Entscheidungsfindung, der Assistenz und Kommunikation. 
Die betrieblichen Einsatzformen von KI sind bislang allerdings zu wenig untersucht, systematisiert, standardisiert
und evaluiert, um verallgemeinerbare Einsatzempfehlungen aus der Praxis abzuleiten. &#8222;Aufgrund (noch)
fehlender Daten und des jungen Forschungsstandes ist die Diskussion jedoch arm an empirischer Evidenz und reich an
kontroversen Einsch&#228;tzungen.&#8220;1389 
Bei der Befragung1390 von knapp 1 000 Betriebsr&#228;ten, Personalr&#228;ten sowie Arbeitnehmervertreterinnen und 
-vertretern in Aufsichtsr&#228;ten in Dienstleistungsunternehmen gaben rund 20 Prozent an, dass KI-Anwendungen
in ihrem Unternehmen f&#252;r interne Prozesse im Bereich &#8222;Verwaltungen/Personal/Finanzen&#8220; bereits genutzt
werden; weitere 37 Prozent berichteten, dass ein entsprechender Einsatz in ihrem Unternehmen geplant sei. Dass
noch keine verallgemeinerbaren Erfahrungen f&#252;r den Einsatz dieser Techniken verf&#252;gbar sind, wird von
Besch&#228;ftigten und Interessenvertretungen durchaus als Manko empfunden und d&#252;rfte mit dazu beitragen, dass 60 Prozent
der in der Studie Befragten angeben, durch den Einsatz von KI n&#228;hmen die Entscheidungs- und
Handlungsspielr&#228;ume von Besch&#228;ftigten ab.1391 
Pers&#246;nlichkeitsrechte
Die verfassungsrechtlich normierten Pers&#246;nlichkeitsrechte der Menschen gelten auch im Betrieb. Deswegen sind
beim Einsatz von KI-Systemen neben dem Schutz der informationellen Selbstbestimmung u. a. auch die W&#252;rde
des Menschen, die freie Entfaltung seiner Pers&#246;nlichkeit, der Schutz seiner Gesundheit und der Schutz vor
Diskriminierung relevant f&#252;r die Auspr&#228;gung der sozio-technischen Einsatzbedingungen. 
Ein wichtiger Pfeiler f&#252;r den Schutz der Pers&#246;nlichkeitsrechte ist das Datenschutzrecht. Da KI-Anwendungen im
Bereich der Arbeitsorganisation oft personenbezogene Daten verarbeiten, sind hier zumeist die allgemeinen
Datenschutzvorgaben aus der Datenschutz-Grundverordnung (DSGVO) zu beachten. Damit gelten auch bei der
Verarbeitung von Arbeitnehmerdaten die DSGVO-Prinzipien, wie Rechtm&#228;&#223;igkeit, Verarbeitung nach Treu und
Glauben, Transparenz, Zweckbindung, Datenminimierung, Richtigkeit, Integrit&#228;t und Vertraulichkeit sowie die
Rechenschaftspflicht der verarbeitenden Stelle.1392 Ferner gelten die Erlaubnistatbest&#228;nde aus Artikel 6 DSGVO
einschlie&#223;lich der Einwilligung, welche freiwillig und informiert sein muss (was im Arbeitsverh&#228;ltnis nur sehr
begrenzt angenommen wird) sowie die Informations- und Auskunftspflichten gegen&#252;ber den Betroffenen, das
Recht auf L&#246;schung und die Regelungen zur automatisierten Einzelentscheidung inklusive der Profilerstellung, 
dem sogenannten Profiling. 
F&#252;r Besch&#228;ftigungsverh&#228;ltnisse erg&#228;nzt und konkretisiert werden diese Vorgaben durch &#167; 26 des
Bundesdatenschutzgesetzes (BDSG), welcher die zul&#228;ssigen Zwecke beschreibt, f&#252;r die im Besch&#228;ftigungsverh&#228;ltnis Daten
verarbeitet werden d&#252;rfen. In &#167; 26 Absatz 4 BDSG wird die Verbindung zum Mitbestimmungsrecht hergestellt. 
1389 Menzel und Winkler (2018): Zur Diskussion der Effekte K&#252;nstlicher Intelligenz in der wirtschaftswissenschaftlichen Literatur, S. 2.
1390 Vgl. Zanker et al. (2019): ver.di &#8211; Innovationsbarometer 2019 K&#252;nstliche Intelligenz, S. 23. 
1391 Zanker et al. (2019): ver.di &#8211; Innovationsbarometer 2019 K&#252;nstliche Intelligenz, S. 28.
1392 Artikel 5 DSGVO.
Danach d&#252;rfen f&#252;r die Zwecke des Besch&#228;ftigungsverh&#228;ltnisses Daten auch dann verarbeitet werden, wenn dies
in einer Kollektivvereinbarung festgelegt ist und sich innerhalb des von der DSGVO vorgegebenen Rahmens
bewegt.1393 
Auch das Mitbestimmungsrecht adressiert die Pers&#246;nlichkeitsrechte der Arbeitnehmerinnen und Arbeitnehmer
direkt in &#167; 75 Absatz 2 Satz 1 BetrVG, der besagt: &#8222;Arbeitgeber und Betriebsrat haben die freie Entfaltung der
Pers&#246;nlichkeit der im Betrieb besch&#228;ftigten Arbeitnehmer zu sch&#252;tzen und zu f&#246;rdern.&#8220; Der Betriebsrat hat auch
dar&#252;ber zu wachen, dass sowohl die zugunsten der Arbeitnehmerinnen und Arbeitnehmer geltenden Gesetze als
auch Betriebsvereinbarungen gewahrt werden.1394 Bei der Einf&#252;hrung und Anwendung von technischen
Einrichtungen, die dazu bestimmt sind, das Verhalten oder die Leistung der Arbeitnehmerinnen und Arbeitnehmer zu
&#252;berwachen, hat er mitzubestimmen.1395 
Bei technischen Einrichtungen, die zur Leistungs- oder Verhaltenskontrolle bestimmt sind, ergibt sich also eine
Schnittmenge zwischen dem Mitbestimmungsrecht und dem Datenschutz. Beide Rechtsbereiche sind ber&#252;hrt,
wenngleich mit sehr unterschiedlichen Ans&#228;tzen: Das BetrVG bestimmt &#8222;nur&#8220;, dass der Betriebsrat
mitbestimmen darf. Das Datenschutzrecht dagegen regelt umfassend und unabh&#228;ngig vom Mitbestimmungsrecht, in
welchem Umfang eine Verarbeitung von Leistungs- oder Verhaltensdaten durch den Arbeitgeber aus
datenschutzrechtlicher Sicht zul&#228;ssig ist. Nur in diesem zul&#228;ssigen Umfang k&#246;nnen dann &#252;berhaupt Regelungen zwischen
Arbeitgeber und Betriebsrat verhandelt werden.
Schutz vor Diskriminierung im Besch&#228;ftigungsverh&#228;ltnis bietet auch das Allgemeine Gleichbehandlungsgesetz
(AGG), welches Benachteiligungen aus Gr&#252;nden der Rasse oder wegen der ethnischen Herkunft, des
Geschlechts, der Religion oder Weltanschauung, einer Behinderung, des Alters oder der sexuellen Identit&#228;t zu
verhindern oder zu beseitigen sucht. Diese Vorgaben sind beim Einsatz von KI-Systemen in der Arbeitsorganisation
ebenfalls zu beachten.
Gesetzliche Vorgaben, an denen sich der KI-Einsatz in der betrieblichen Arbeitsorganisation ausrichten muss,
sind also gegeben. Dennoch sind die Anwendung der Vorgaben und ihre Durchsetzung in der betrieblichen Praxis
keine Selbstl&#228;ufer. Zum einen sind die Auslegung und Anwendung der Bestimmungen im konkreten Fall oft
schwierig &#8211; zwar gibt es im Besch&#228;ftigtendatenschutz einiges an Rechtsprechung, aber nicht jeder neue
Sachverhalt wurde schon entschieden. Im Zusammenhang mit dem Einsatz von KI-Systemen k&#246;nnen z. B.
Schwierigkeiten bei der Herstellung der erforderlichen Transparenz in Bezug auf die Funktionsweisen entstehen. Auch
welcher Systemeinsatz und welche Datenauswertung f&#252;r die Zwecke des Besch&#228;ftigungsverh&#228;ltnisses
erforderlich sind, kann durchaus unterschiedlich beurteilt werden. Die Gemengelage von Datenschutzrecht, auf dessen
Einhaltung der betriebliche Datenschutzbeauftragte hinwirkt und f&#252;r den die Unternehmensleitung
verantwortlich ist, und die betrieblichen Mitbestimmungsaufgaben/-rechte, f&#252;r die der Betriebsrat zust&#228;ndig ist, bed&#252;rfen
daher eines konstruktiven Zusammenwirkens aller Beteiligten.
F&#252;r den Datenschutz haben die Datenschutzbeauftragten des Bundes und der L&#228;nder mit ihrer Hambacher
Erkl&#228;rung zur K&#252;nstlichen Intelligenz1396 Empfehlungen erarbeitet, deren Prinzipien f&#252;r den Einsatz von KI-Systemen
mit personenbezogenen Daten hilfreich sind.
Die Gestaltungsprinzipien der Zweckbindung der Daten, das Transparenzgebot f&#252;r Erhebung, Verarbeitung und
Nutzung, die Auswahl datenschutzfreundlicher Grundeinstellungen (&#8222;Privacy by default&#8220;) und
datenschutzfreundlicher Technologien (&#8222;Privacy by design&#8220;), die Rechenschaftspflichten, die Einrichtung einer
verantwortlichen Stelle und eine stringente Reglementierung automatisiert generierter Einzelentscheidungen, die in die
Pers&#246;nlichkeitsrechte der Betroffenen eingreifen, haben f&#252;r jeglichen KI-Einsatz im Arbeitsleben Relevanz.
1393 &#167; 26 Absatz 4 BDSG f&#252;hrt dazu aus: &#8222;Die Verarbeitung personenbezogener Daten, einschlie&#223;lich besonderer Kategorien
personenbezogener Daten von Besch&#228;ftigten f&#252;r Zwecke des Besch&#228;ftigungsverh&#228;ltnisses, ist auf der Grundlage von Kollektivvereinbarungen 
zul&#228;ssig. Dabei haben die Verhandlungspartner Artikel 88 Absatz 2 der Verordnung (EU) 2016/679 zu beachten.&#8220; Artikel 88 Absatz 2 
DSGVO regelt: &#8222;Diese Vorschriften umfassen geeignete und besondere Ma&#223;nahmen zur Wahrung der menschlichen W&#252;rde, der
berechtigten Interessen und der Grundrechte der betroffenen Person, insbesondere im Hinblick auf die Transparenz der Verarbeitung,
die &#220;bermittlung personenbezogener Daten innerhalb einer Unternehmensgruppe oder einer Gruppe von Unternehmen, die eine
gemeinsame Wirtschaftst&#228;tigkeit aus&#252;ben, und die &#220;berwachungssysteme am Arbeitsplatz.&#8220;.
1394 &#167; 80 Absatz 1 Nummer 1 BetrVG.
1395 &#167; 87 Absatz 1 Nummer 6 BetrVG.
1396 Vgl. Datenaufsichtsbeh&#246;rden des Bundes und der L&#228;nder (2019): Hambacher Erkl&#228;rung zur K&#252;nstlichen Intelligenz. Sieben
datenschutzrechtliche Anforderungen.
Dar&#252;ber hinaus k&#246;nnten unerf&#252;llte Forderungen der Datenschutzbeauftragten des Bundes und der L&#228;nder sowie
der Gewerkschaften durch den Einsatz von KI-Systemen eine neue Bedeutung erhalten. Sie fordern seit 1984
bereichsspezifische und pr&#228;zise gesetzliche Bestimmungen zum Besch&#228;ftigtendatenschutz.1397 
5.1.3.2 Einsatz von automatisierten Entscheidungssystemen und KI in der
Personalverwaltung
Die Bandbreite, in der bereits heute algorithmische Systeme im Personalwesen eingesetzt werden, ist gro&#223;.
Unternehmen erhoffen sich, mithilfe von KI Prozesse in der Personalverwaltung zu optimieren und zu
rationalisieren. Von einem vollautomatischen &#8222;Robot Recruiting&#8220; ist Deutschland allerdings noch weit entfernt. W&#228;hrend
teil- und vollautomatisierte Computerprogramme in der Personalauswahl in den USA schon relativ h&#228;ufig zum
Einsatz kommen, sind diese in Deutschland noch eher die Ausnahme. Bislang setzen nur knapp 4 Prozent der
Unternehmen in Deutschland digitale Werkzeuge zur Mitarbeitersuche und im Einstellungsprozess ein.1398 
KI kann Unternehmen darin unterst&#252;tzen, passend qualifizierte Fachkr&#228;fte f&#252;r offene Stellen im Unternehmen zu
finden; sei es durch Analysen des Arbeitsmarktes und einzelner Branchen, sei es durch aktive Personalsuche.1399 
Wer sich bei einem Unternehmen bewirbt, kann auch hierzulande zunehmend damit rechnen, es nicht
ausschlie&#223;lich mit Menschen zu tun zu haben. Programme extrahieren, sortieren und bewerten Daten, die Bewerberinnen
und Bewerber in Online-Formulare eingeben oder schriftlich einsenden. Unternehmen durchforsten automatisiert
soziale Netzwerke wie Facebook, Instagram, LinkedIn und Xing, um potenzielle Mitarbeiterinnen und
Mitarbeiter zu finden oder um mehr &#252;ber die Bewerberinnen und Bewerber zu erfahren.
F&#252;r Unternehmen bietet der Einsatz von KI den Vorteil, schneller und effizienter potenzielle Mitarbeiterinnen 
und Mitarbeiter zu finden. Eine automatisierte Anwendung kann die Mitarbeiterinnen und Mitarbeiter der
Personalabteilung zudem von Routinet&#228;tigkeiten entlasten, z. B. indem schriftliche Bewerbungen vorsortiert und
vorgefiltert werden. Einige Fachleute versprechen sich durch den Einsatz von KI auch eine diskriminierungsfreiere 
Personalauswahl: Schlie&#223;lich ist bekannt, dass die Personalauswahl durch Menschen oft von subjektiven
Vorurteilen und Erfahrungen gepr&#228;gt ist, was h&#228;ufig nicht zur Auswahl der geeigneten Bewerberin oder des geeigneten
Bewerbers f&#252;hrt. Gut belegt ist beispielsweise die Benachteiligung von Personen mit ausl&#228;ndisch klingenden
Namen oder von Frauen in Bewerbungsprozessen.1400 Eine KI-gest&#252;tzte Aus- und Bewertung k&#246;nnte, so die
Hoffnung, helfen, dies zu verhindern und so f&#252;r mehr Chancengerechtigkeit sorgen.
Dazu ist es laut Expertinnen und Experten allerdings notwendig, dass KI-Programme zuvor mit den &#8222;richtigen&#8220;
Daten trainiert wurden.1401 Werden diese mit alten, vorurteilsbeladenen Entscheidungen trainiert, werden
Maschinen diese Vorurteile bei ihren Entscheidungen systematisch &#252;bernehmen.
Der Einsatz von KI-Systemen im Personalwesen birgt jedoch auch Risiken. So gibt es KI-Systeme, die tief in die
Privatsph&#228;re von Bewerberinnen und Bewerber vordringen.1402 Ihre auf KI-Technologien basierende Software
verspricht, mithilfe eines kurzen automatisierten Telefoninterviews eine Pers&#246;nlichkeitsanalyse der
Bewerberinnen und Bewerber zu erstellen, wobei nicht nur die gegebenen Antworten analysiert, sondern zudem Merkmale
der Stimme ausgewertet werden. Der Ethikbeirat HR-Tech spricht sich in seinen Richtlinien f&#252;r den
verantwortungsvollen Einsatz von KI ausdr&#252;cklich gegen den Einsatz solcher Systeme in der Personalarbeit aus. Indem
von der KI Daten erhoben werden, die ein Mensch weder bewusst zur Verf&#252;gung stellt noch beeinflussen kann,
w&#252;rde er vom wahrnehmenden und handelnden Subjekt zum analysierten Objekt. Laut dem Ethikbeirat HR-Tech
m&#252;ssen KI-L&#246;sungen immer die Subjektqualit&#228;t als einen Pfeiler der Menschenw&#252;rde und Selbstbestimmung 
1397 Vgl. Datenschutzbeauftragten des Bundes und der L&#228;nder (1992): Entschlie&#223;ung der 43. Konferenz der Datenschutzbeauftragten des 
Bundes und der L&#228;nder.
1398 Vgl. Leibniz-Institut f&#252;r Wirtschaftsforschung an der Universit&#228;t M&#252;nchen e. V. und Randstad Gruppe Deutschland (2019):
Randstad-ifo Personalleiterbefragung.
1399 Vgl. mit vielen Beispielen und Belegen Hustedt und Knobloch (2019): Der maschinelle Weg zum passenden Personal; Dr&#228;ger und 
M&#252;ller-Eiselt (2019): Wir und die intelligenten Maschinen.
1400 Stellvertretend f&#252;r viele seien hier genannt: Kaas und Manger (2010): Ethnic Discrimination in Germany&#8217;s Labour Market: A Field
Experiment; Schneider et al. (2014): Diskriminierung am Ausbildungsmarkt: Ausma&#223;, Ursachen und Handlungsperspektiven; Beicht
(2017): Ausbildungschancen von Ausbildungsstellenbewerbern und -bewerberinnen mit Migrationshintergrund; Orwat (2020):
Diskriminierungsrisiken durch Verwendung von Algorithmen, S. 34&#8211;41.
1401 Vgl. Dr&#228;ger und M&#252;ller-Eiselt (2019): Wir und die intelligenten Maschinen, S. 50 f., 143&#8211;147.
1402 Kritisch diskutiert wurden in der Projektgruppe beispielhaft &#8222;HireVue&#8220;, mehr Informationen dazu unter: http://www.hirevue.com/
und &#8222;PRECIRE&#8220;, mehr Informationen dazu unter: http://precire.com (beides zuletzt abgerufen am 7. August 2020).
achten,1403 zumal der Einsatz von Systemen, die vorgeben, anhand von Stimm- oder Mimikanalysen auf
Pers&#246;nlichkeitsmerkmale schlie&#223;en zu k&#246;nnen, wissenschaftlich h&#246;chst umstritten ist. Nach derzeitigem
Forschungsstand sind Algorithmen nicht verl&#228;sslich in der Lage, Emotionen von Menschen anhand von Gesichtsausdr&#252;cken
zu erkennen.1404 Aufgrund der oben aufgef&#252;hrten Risiken treten f&#252;r viele Menschen die potenziellen gro&#223;en
Vorteile in den Hintergrund, die mit dem Einsatz von teil- und vollautomatisierten Computerprogrammen verbunden
sind. In einer Umfrage gaben nur 2 Prozent der Befragten an, dass sie den Einsatz von KI zur
Pers&#246;nlichkeitsanalyse im Bewerbungsprozess akzeptabel finden.1405 Selbst in den USA wird der Einsatz in diesem Bereich
mehrheitlich abgelehnt.1406 Nicht nur in der Personalauswahl, sondern auch in der allgemeinen
Personalverwaltung werden zunehmend automatisierte Systeme sowie Big-Data-Analysen eingesetzt. Bei sogenannten &#8222;People
Analytics&#8220;-Systemen werden Personal- und Arbeitsdaten von Besch&#228;ftigten gesammelt. Auf individueller Ebene
k&#246;nnen dann detailliert Leistungsverl&#228;ufe ausgewertet und grafisch dargestellt werden. Die Hoffnung von
Unternehmen ist, notwendige Personalkapazit&#228;ten im Betrieb flexibler und effizienter planen zu k&#246;nnen.1407 
Hier liegt das Risiko in der l&#252;ckenlosen &#220;berwachung, Kontrolle und Bewertung von Besch&#228;ftigten durch den
Arbeitgeber. Ein Praxisbeispiel f&#252;r People Analytics ist &#8222;Zonar&#8220;, das der Online-H&#228;ndler Zalando in Berlin
einsetzt:1408 Die Besch&#228;ftigten m&#252;ssen sich dabei zun&#228;chst gegenseitig bewerten. Diese Ratings werden zusammen
mit weiteren Leistungsdaten automatisiert in einen individuellen Wert (Score) umgerechnet. Damit k&#246;nnen die
Besch&#228;ftigten in eine Rangfolge gebracht werden, die mit der Aussicht auf Lohnerh&#246;hungen verkn&#252;pft werden
sollen.1409 
5.1.3.3 KI in der Arbeits- und Sozialverwaltung
In der Arbeits- und Sozialverwaltung reichen die m&#246;glichen KI-Anwendungen von vergleichsweise
unbedenklicher Automatisierung von Verwaltungsverfahren bis hin zu der kontrovers diskutierten Erstellung von
Risikoprofilen durch Big-Data-Analyse.1410 Vielfach wird KI bereits eingesetzt: in der Digitalisierung und (Teil-)
Automatisierung von Arbeitsabl&#228;ufen und bei der Auswertung gro&#223;er Datens&#228;tze. Die Anwendungen k&#246;nnen dazu
genutzt werden, Qualit&#228;t und Effizienz administrativer und operativer Prozesse durch Automatisierung zu steigern
und Beratungs- und Vermittlungsangebote zu verbessern.1411 Fallbeispiele aus Deutschland, benachbarten EU-
Staaten und Nordamerika zeigen aber auch, dass der erhoffte Effizienzgewinn durch KI-Anwendungen nicht
immer eintritt oder sogar diskriminierende Strukturen verst&#228;rkt werden k&#246;nnen.
Aufgrund der Vielzahl an standardisierten Verfahren in der Verwaltung kann die Automatisierung durch KI hier
zu Effizienzsteigerungen f&#252;hren. Ein Beispiel f&#252;r Effizienzsteigerung durch den Einsatz von KI in der
Sozialverwaltung ist ein bisher als Prototyp eingesetztes System, welches Studienbescheinigungen f&#252;r den
Kindergeldantrag erkennen soll.1412 Die antragstellende Person wird dadurch entlastet, dass sie weniger manuelle Eingaben
machen muss. Gleich nach dem Hochladen erh&#228;lt sie eine Mitteilung mit dem Ergebnis der KI-basierten
Auswertung &#8211; im alten Verfahren wurden Kundinnen und Kunden per Brief benachrichtigt, wenn der Nachweis
1403 Vgl. Ethikbeirat HR-Tech (2020): Richtlinien f&#252;r den verantwortungsvollen Einsatz von K&#252;nstlicher Intelligenz und weiteren
digitalen Technologien in der Personalarbeit.
1404 Chen und Hao (2020): Emotion AI researchers say overblown claims give their work a bad name; Korte (2020): Facial-Recognition
Technology Cannot Read Emotions, Scientists Say.
1405 Vgl. Petry (2019): Robot Recruiting: Roboter sucht Kollegen; Selbst in den USA wird der Einsatz in diesem Bereich mehrheitlich
abgelehnt, vgl. Smith (2018): Public Attitudes Toward Computer Algorithms. In Deutschland setzen derzeit nur 2 Prozent der Unternehmen 
KI f&#252;r Zwecke der Personalauswahl ein, vgl. Berg (2020): K&#252;nstliche Intelligenz Einsatz und Forschung in Deutschland, S. 6.
1406 Vgl. Smith (2018): Public Attitudes Toward Computer Algorithms.
1407 Vgl. Gr&#228;fe (2019): Stellen uns bald Roboter ein?, S. 9; M&#252;ller (2019): Plaudernd zum Job.
1408 Von der Gewerkschaft ver.di wurde der Einsatz der Software wegen Belastung f&#252;r das Betriebsklima und datenschutzrechtlicher
Bedenken kritisiert, vgl. ver.di (2019): ver.di kritisiert System permanenter digitaler Leistungskontrollen und Ratings bei Zalando. 
Das Pr&#252;fungsverfahren der Berliner Datenschutzbeh&#246;rde l&#228;uft noch, erste Kriterien seien bereits entwickelt worden, vgl. Bath (2020):
Beh&#246;rde nennt Zalando Kriterien f&#252;r Feedback-App.
1409 Weitere Informationen zu Zonar unter: https://corporate.zalando.com/de/newsroom/de/news-storys/ueber-zonar (zuletzt abgerufen 
am 9. September 2020) sowie Staab und Geschke (2019): Ratings als arbeitspolitisches Konfliktfeld, insb. S. 31 f.
1410 Zu detaillierten Informationen zur Verwendung von KI siehe auch den Bericht der Projektgruppe &#8222;KI und Staat&#8220; in Kapitel C. III.
[K&#252;nstliche Intelligenz und Staat (Projektgruppe 2)].
1411 Darstellung Martina Hofmann (IT-Systemhaus der Bundesagentur f&#252;r Arbeit) in der Sitzung der Projektgruppe KI und Arbeit,
Bildung, Forschung am 16. Dezember 2019.
1412 Darstellung Martina Hofmann (IT-Systemhaus der Bundesagentur f&#252;r Arbeit) in der Sitzung der Projektgruppe KI und Arbeit,
Bildung, Forschung am 16. Dezember 2019.
unvollst&#228;ndig oder falsch war. Die Trefferquote der KI liegt laut Bundesagentur f&#252;r Arbeit bei 99,7 Prozent.1413 
Am Ende pr&#252;ft eine Mitarbeiterin oder ein Mitarbeiter die Angaben und erl&#228;sst den Festsetzungsbescheid, denn
die Software versteht nicht den Inhalt des Textes, sondern erkennt und klassifiziert bestimmte Textbausteine.
Beispielsweise pr&#252;ft die KI, ob die Studienbescheinigung auf das betreffende Kind ausgestellt ist und gibt eine
Einsch&#228;tzung ab, ob es sich um die aktuelle Studienbescheinigung handelt. 
Ziel ist, immer eine tats&#228;chliche Qualit&#228;tssteigerung des Verfahrens anzustreben. Automatisierung um ihrer selbst
willen kann einen negativen Effekt haben. Das zeigt sich in einem vergleichbaren Beispiel aus den USA: Es
wurden Sachbearbeiterinnen und Sachbearbeiter ganz durch ein Dokumentenerkennungssystem ersetzt und
anstatt besserer Beratung oder Versorgung bekamen Empf&#228;ngerinnen und Empf&#228;nger von Sozialhilfeleistungen
und Krankenversicherte keine Auskunft &#252;ber fehlende Dokumente und hatten keine M&#246;glichkeit, gegen das
Ergebnis des IT-Systems vorzugehen, obwohl es falsche Ergebnisse lieferte. Dies f&#252;hrte vielfach dazu, dass
medizinische Behandlungen und Medikamente nicht von den Versicherungen bezahlt wurden.1414 Dies ist in
Deutschland wegen des Widerspruchsrechts nicht m&#246;glich. In Deutschland wurde ein IT-Fachverfahren im Bereich
Jugendhilfe von einer Enquete-Kommission der B&#252;rgerschaft Hamburg negativ bewertet, weil es schlecht
funktionierte.1415 Anstatt den Sozialarbeiterinnen und Sozialarbeitern die Arbeit zu erleichtern, nahm es ihnen
Beratungszeit, die sie an anderer Stelle gebraucht h&#228;tten.1416 
Grunds&#228;tzlich sind rechtlich klar definierte Verwaltungsvorg&#228;nge ohne unbestimmte Rechtsbegriffe oder
Ermessensspielr&#228;ume gut f&#252;r Automatisierung und KI geeignet. Das Ermessen, also die Beurteilung eines Einzelfalls
unter Beachtung der Verh&#228;ltnism&#228;&#223;igkeit, sollte nach Auffassung der Projektgruppe weiterhin bei einem
Menschen verbleiben. So funktioniert etwa eine Anwendung der Bundesagentur f&#252;r Arbeit f&#252;r das Aufdecken von
Betrug und falsch gezahlten Leistungen. Ein automatisiertes Verfahren wird eingesetzt, bei dem jedes Quartal
die Renten- und die Arbeitslosengeld-II-Bez&#252;ge verglichen werden, um festzustellen, ob eine Person doppelte
Leistungen erh&#228;lt. Das Ergebnis wird anschlie&#223;end aber von einer Sachbearbeiterin oder einem Sachbearbeiter
gepr&#252;ft und erst daraufhin wird eine Untersuchung angesto&#223;en.1417 
Deutlich riskanter f&#252;r Grundrechte und Diskriminierungsfreiheit ist der Einsatz von KI nach derzeitigem Stand
dort, wo Risikoprofile erstellt werden. So verh&#228;lt es sich bei einem Beispiel aus den Niederlanden, wo die
Verwaltung einen Algorithmus einsetzte, welcher f&#252;r die Zivilgesellschaft nicht einsehbar war. Er wurde in
Wohnvierteln mit niedrigen Einkommen verwendet, wo er auf Basis von vormals getrennten Datenbest&#228;nden,
beispielsweise zu Besch&#228;ftigungsverh&#228;ltnis, Verschuldung, bezogenen Sozialhilfeleistungen, Bildungsgrad und
ehemaligen Wohnsitzen, einen Risikowert f&#252;r die Wahrscheinlichkeit von Sozialbetrug berechnete. Das beh&#246;rdlich
eingesetzte Programm wurde von einem Gericht wegen Eingriffs in die Privatsph&#228;re verboten.1418 Dieses Beispiel
zeigt, wie wichtig Nicht-Diskriminierung bei der Entwicklung und &#220;berpr&#252;fung von Algorithmen ist. Dabei
besteht einerseits eine Chance, bestehende Diskriminierungen durch ein KI-Projekt festzustellen. Andererseits l&#228;sst
sich daraus nicht schlussfolgern, dass man grunds&#228;tzlich keine KI-Systeme in diesem Bereich einsetzen darf.
Denn Diskriminierungsfreiheit muss das Ziel sein &#8211; mit und ohne KI-Einsatz.
Ein Scoring-System am polnischen Arbeitsmarkt wurde gerichtlich als nicht verfassungskonform eingestuft und
von der Regierung wieder ausgesetzt. Problematisch war das System in Bezug auf Diskriminierung und
Datenschutz, weil pers&#246;nliche Daten der Betroffenen und gegebene Antworten in Jobcenter-Interviews intransparent
von einem Algorithmus analysiert und zu einem Score zusammengefasst wurden, der dann gro&#223;en Einfluss auf
die weiteren Chancen im Arbeitsmarkt hatte.1419 Nicht nur auf die Auswahl der Daten, sondern auch auf die
Datenqualit&#228;t ist zu achten, um eine m&#246;gliche Diskriminierung zu verhindern, beispielsweise bei Stellenanzeigen.
1413 Darstellung Martina Hofmann (IT-Systemhaus der Bundesagentur f&#252;r Arbeit) in der Sitzung der Projektgruppe KI und Arbeit,
Bildung, Forschung am 16. Dezember 2019.
1414 Vgl. Eubanks (2018): Automating inequality.
1415 Zwar handelt sich hierbei nicht um ein KI-System, aber das Beispiel verdeutlicht funktionierende Kontrollmechanismen in Deutschland.
1416 B&#252;rgerschaft der Freien und Hansestadt Hamburg (2018): Bericht der Enquete-Kommission Kinderschutz und Kinderrechte weiter
st&#228;rken: &#220;berpr&#252;fung, Weiterentwicklung, Umsetzung und Einhaltung gesetzlicher Grundlagen, fachlicher Standards und Regeln in
der Kinder- und Jugendhilfe &#8211; Verbesserung der Interaktion der verschiedenen Systeme und Akteurinnen und Akteure&#8220;.
1417 Den rechtlichen Rahmen f&#252;r die Anwendung von KI-Systemen in der Verwaltung bilden &#167; 155 Absatz 4 der Abgabenordnung (AO),
&#167; 35a des Verwaltungsverfahrensgesetzes (VwVfG), &#167; 31a des Zehnten Buches Sozialgesetzbuch (SGB X) und Artikel 22 DSGVO.
Voraussetzung ist, dass kein Ermessensspielraum vorliegt, keine Opt-out-Regelung besteht, das Recht auf Neubewertung gewahrt
wird und die Entscheidung einer transparenten Logik folgt. Siehe auch Kapitel 1.2 des Berichts der Projektgruppe &#8222;KI und Staat&#8220;
[Thematischer Scherpunkt]&#8220;.
1418 Vgl. Henley und Booth (2020): Welfare surveillance system violates human rights, Dutch court rules.
1419 Vgl. Niklas (2019): Polen: Regierung schafft umstrittenes Scoring-System f&#252;r Arbeitslose ab.
Das sieht man an einem Beispiel aus &#214;sterreich, wo Frauen bei gleicher Qualifikation andere Chancen als
M&#228;nnern zugesprochen wurden. In der Berufsvermittlung des Arbeitsmarktservice wurden Berufssuchende &#8211;
entsprechend ihren algorithmisch berechneten Chancen f&#252;r den Wiedereinstieg in den Arbeitsmarkt &#8211; in drei Kategorien
eingeordnet und bekamen aufgrund der Zuordnung unterschiedliche Angebote und Betreuung. Der eingesetzte
Algorithmus basierte auf der statistischen Analyse historischer Daten. Der Algorithmus ermittelte, dass Frauen
in der Vergangenheit tendenziell eine schlechtere Chance f&#252;r den Wiedereinstieg in die Arbeitswelt hatten und
ordnete sie dementsprechend in eine andere Kategorie ein als M&#228;nner mit gleicher Qualifikation. Von den
Betreibern des Systems wurde jedoch argumentiert, dass diese Unterscheidung wichtig sei, um Frauen eine
entsprechend h&#246;here F&#246;rderung zukommen zu lassen. Hier zeigt sich, dass sehr genau hingeschaut werden muss, ob und
warum eine Diskriminierung nach einem bestimmten Merkmal besteht und ob sie mit geltendem Anti-
Diskriminierungsrecht vereinbar ist.1420 
Derzeit erprobt die Bundesagentur f&#252;r Arbeit, die Vielzahl von Stellenangeboten mittels KI auszuwerten und die
Beratungsangebote darauf zu st&#252;tzen (sogenanntes Matching).1421 Die Stellenangebote werden analysiert und 
Cluster zu nachgefragten Kompetenzen in Berufen erstellt. Diese werden f&#252;r die Vermittlung von
Dienstleistungen genutzt und flie&#223;en in die thematische Ausrichtung von Qualifizierungsma&#223;nahmen ein. Konkret werden bei
der Analyse Stellenangebote klassifiziert, beispielsweise anhand des Arbeitszeitmodells, der Befristung und der
Mitarbeiterverantwortung. Mithilfe von Textmining und Natural Language Processing k&#246;nnen Branchen,
Arbeitgeber und gesuchte Kompetenzen ausgelesen werden. Arbeitgeber k&#246;nnten die Ergebnisse nutzen, um
Arbeitsplatzprofile zu erstellen, diese mit den Profilen der Kompetenzen, F&#228;higkeiten und Fertigkeiten ihrer Belegschaft
abzugleichen sowie den Bedarf an Qualifikation und betrieblichen Weiterbildungsprogrammen ermitteln.
Arbeitnehmerinnen und Arbeitnehmer k&#246;nnten die Analysen nutzen, um eigene Karriere- und Weiterbildungswege zu
planen. 
5.1.3.4 Weiterentwicklung der sozialen Sicherungssysteme1422 
Der schnelle und tiefgreifende Wandel in der Arbeitswelt vor allem durch Digitalisierung und im weiteren Schritt 
durch KI kann erhebliche Konsequenzen f&#252;r individuelles Arbeiten wie auch f&#252;r die Sozialversicherungssysteme
insgesamt nach sich ziehen: Neue Erwerbsformen und Einkommensquellen k&#246;nnen entstehen; selbstst&#228;ndige
oder unselbstst&#228;ndige Erwerbsarbeit und abh&#228;ngige Besch&#228;ftigung k&#246;nnen verschwimmen und so schwieriger
voneinander abgrenzbar sein; ortsflexible und mobile Arbeit au&#223;erhalb eines typischen Betriebsortes kann ebenso
zunehmen wie unstete Verl&#228;ufe in individuellen Erwerbsbiografien. Selbstst&#228;ndige und abh&#228;ngige Erwerbsarbeit
k&#246;nnen auch parallel verlaufen und sich innerhalb eines Erwerbslebens mehrfach abwechseln.
Die zunehmende Verbreitung von KI-Systemen in Wirtschaft und Gesellschaft gibt einer bereits laufenden
Debatte um die Weiterentwicklung der sozialen Sicherungssysteme zus&#228;tzliche Bedeutung. Die bisherige
facettenreiche Diskussion dreht sich im Kern um die generelle Frage, wie einerseits der wachsende, durch
Automatisierung erzielte Wertsch&#246;pfungsbetrag auch f&#252;r Gemeinwohlaufgaben und soziale Sicherheit erschlossen werden
kann, und andererseits darum, ob und wie das Individuum im Sozialversicherungssystem abgesichert werden
kann und soll. 
In den Fokus der aktuellen Debatte geraten zu erwartende Produktivit&#228;tsgewinne durch KI-Anwendungen. Die
in der Projektgruppe und von verschiedenen anderen Akteuren dazu diskutierten Konzepte sind ebenso vielf&#228;ltig 
wie strittig. Sie erhalten aber durch unterschiedliche Annahmen zur &#246;konomischen Wirkung von KI auf die
Verteilungsgerechtigkeit neue Relevanz.
Er&#246;rtert werden u. a. so unterschiedliche Ans&#228;tze wie ein steuerfinanziertes, bedingungsloses Grundeinkommen,
ein solidarisches Grundeinkommen, eine F&#246;rderung des Aktienbesitzes, eine Lenkung von
&#8222;Automatisierungsdividenden&#8220; in gesellschaftliche Bedarfsfelder, die Nutzung von Produktivit&#228;tsgewinnen zum Ausbau sozialer
Sicherheit, eine Einbeziehung aller Erwerbst&#228;tigen in die gesetzliche Sozialversicherung, die Schaffung von
1420 F&#252;r Details zu den Fragen Diskriminierung, Bias und Nutzung von KI im Bereich Staat siehe auch Kapitel 3 des Mantelberichts [KI 
und Umgang mit Bias/Diskriminierung] und den Bericht der Projektgruppe &#8222;KI und Staat&#8220; in Kapitel C. III. [K&#252;nstliche Intelligenz 
und Staat (Projektgruppe 2)]; Dieses Beispiel greift auch das B&#252;ro f&#252;r Technikfolgenabsch&#228;tzung beim Deutschen Bundestag (TAB)
in seinem Bericht zur Diskriminierung von Algorithmen auf , vgl. Kolleck und Orwat (erscheint voraussichtlich Ende 2020):
M&#246;gliche Diskriminierung durch algorithmische Entscheidungssysteme und maschinelles Lernen &#8211; ein &#220;berblick.
1421 Darstellung Martina Hofmann (IT-Systemhaus der Bundesagentur f&#252;r Arbeit) in der Sitzung der Projektgruppe KI und Arbeit,
Bildung, Forschung am 16. Dezember 2019.
1422 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion der FDP vor [Sondervotum zu Kapitel 5.1.3.4 des Berichts der
Projektgruppe 4 &#8222;KI und Arbeit, Bildung, Forschung&#8220; (&#8222; Weiterentwicklung der sozialen Sicherungssysteme &#8220;) des Abgeordneten Carl-
Julius Cronenberg].
Steuergerechtigkeit f&#252;r weltweit wirkende Hyperscaler und/oder die Entrichtung von
Sozialversicherungsabgaben durch Plattformen (z. B. nach dem Prinzip der digitalen sozialen Sicherung). 
Wegen des grunds&#228;tzlichen Charakters und der auch KI-unspezifischen Wirkungszusammenh&#228;nge hat die
Projektgruppe keine Empfehlung zu den unterschiedlichen konzeptionellen Ans&#228;tzen erarbeitet.
5.1.3.5 Handlungsempfehlungen
5.1.3.5.1 Arbeitsorganisation
Die Auswirkungen von KI im betrieblichen Kontext anwendungsbezogen erforschen
Um die Auswirkungen besser verstehen, empirisch belegen und gestalterisch begleiten zu k&#246;nnen, m&#252;ssen 
&#8222;die Entwicklung und Umsetzung von KI-Systemen in der Arbeitswelt systematisch, quantitativ und qualitativ
beobachtet werden&#8220;1423. Zu empfehlen ist weiterhin die &#8222;langfristige F&#246;rderung anwendungsbezogener
Forschung in betrieblichen Kontexten, auch und gerade sozial- und verhaltenswissenschaftlicher Forschung, zu den
Auswirkungen des KI-Einsatzes auf Arbeitnehmerinnen und Arbeitnehmer, Arbeit, Qualifikationsbedarfe und
Unternehmen&#8220;1424.
Inwiefern der Einsatz von KI Arbeit ver&#228;ndert und welche Konsequenzen intelligente Automatisierung f&#252;r
Arbeitnehmerinnen und Arbeitnehmer auch heute schon hat, ist jedoch nicht hinreichend erforscht. Die Bew&#228;ltigung
der aktuellen Herausforderungen bedarf daher empirischer Evidenz, die weit &#252;ber das hinausgeht, was mit kleinen 
Forschungsprojekten geleistet werden kann. Vielmehr braucht es eine breit angelegte, datenbasierte und
anwendungsbezogene Betrachtung von KI-Anwendungen in Bereichen mit hohem Transferpotenzial. In besonderem
Ma&#223;e k&#246;nnen die wissenschaftliche Begleitung und formative Evaluierung betrieblicher Ver&#228;nderungen durch
KI-Einsatz n&#252;tzlich sein.1425 Da sich die Transformationen in Auspr&#228;gung und Geschwindigkeit h&#246;chst
unterschiedlich gestalten, ist ein branchenspezifisches Monitoring und entsprechende Begleitforschung vonn&#246;ten.
&#8222;Wissenschaftliche Forschung kann dazu beitragen, Debatten zu versachlichen und zudem soziale Innovationen 
generieren, die einer wirkungs- und sinnvollen Gestaltung des Wandels zutr&#228;glich sind. Deshalb sollte
Wissenschaft in handlungsrelevanten Bereichen agieren und mit allen Stakeholdern des Ver&#228;nderungsprozesses
kooperieren, n&#228;mlich: Politik, Gewerkschaften, Unternehmen sowie Betriebs- und Personalr&#228;ten. Durch &#8218;Co-Creation-
Prozesse&#8216; kann wissenschaftliche Evidenz in praktische Relevanz &#252;berf&#252;hrt werden.&#8220;1426 
Zum Schutz der Pers&#246;nlichkeitsrechte Best Practice-Beispiele ermitteln und verbreiten und die
Entwicklung von Standards f&#246;rdern
F&#252;r den Datenschutz haben die Datenschutzbeauftragten des Bundes und der L&#228;nder mit ihrer Hambacher
Erkl&#228;rung zur K&#252;nstlichen Intelligenz1427 Empfehlungen erarbeitet. Die Verfasser der Hambacher Erkl&#228;rung halten es
f&#252;r eine wichtige Aufgabe von Wirtschaft und Wissenschaft, Best-Practice-Beispiele zum Einsatz von KI zu
entwickeln und die Erkenntnisse zu mehren. Dies ist auch f&#252;r die Arbeitsorganisation sinnvoll. Insbesondere
sollten gute Beispiele f&#252;r die Umsetzung der Informationspflichten gegen&#252;ber den Besch&#228;ftigten sowie f&#252;r
&#8222;Privacy by design&#8220;-Ans&#228;tze als Vorbild dienen.
Es w&#228;re f&#252;r die Arbeitnehmervertretung, aber auch die Unternehmensf&#252;hrungen hilfreich, wenn sie sich bei der
Beurteilung von KI-gest&#252;tzten Systemen, die f&#252;r die betriebliche Arbeitsorganisation relevant sind, an Normen,
Auditergebnissen oder Zertifizierungen von neutralen Dritten orientieren k&#246;nnten, welche Aussagen &#252;ber
mitbestimmungsrelevante Funktionsweisen und Gestaltungsans&#228;tze wie &#8222;Privacy by design&#8220; oder &#8222;Gute Arbeit by
design&#8220; treffen. Die Entwicklung solcher Standards sollte daher gef&#246;rdert werden.
1423 Handlungsempfehlungen von Prof. Dr. Lars Adolph (Bundesanstalt f&#252;r Arbeitsschutz und Arbeitsmedizin),
Projektgruppendrucksache 19(27)PG 4-20 vom 9. Dezember 2019.
1424 Handlungsempfehlungen von Dr. Marie-Christin Fregin (Wissenschaftszentrum Berlin und Input-Consulting),
Projektgruppendrucksache 19(27)PG 4-22 vom 9. Dezember 2019.
1425 Handlungsempfehlungen von Dr. Marie-Christin Fregin (Wissenschaftszentrum Berlin und Input-Consulting),
Projektgruppendrucksache 19(27)PG 4-22 vom 9. Dezember 2019.
1426 Handlungsempfehlungen von Dr. Marie-Christin Fregin (Wissenschaftszentrum Berlin und Input-Consulting),
Projektgruppendrucksache 19(27)PG 4-22 vom 9. Dezember 2019.
1427 Vgl. Datenaufsichtsbeh&#246;rden des Bundes und der L&#228;nder (2019): Hambacher Erkl&#228;rung zur K&#252;nstlichen Intelligenz. Sieben
datenschutzrechtliche Anforderungen.
Vertrauensstiftend f&#252;r den Einsatz von KI im Betrieb wirkt die enge Zusammenarbeit von Arbeitgeber- und
Arbeitnehmervertretung, in die auch die oder der betriebliche Datenschutzbeauftragte einbezogen wird. Um
konstruktiv und auf Augenh&#246;he &#252;ber den Einsatz von KI-gest&#252;tzten Unternehmen in der Arbeitsorganisation beraten
zu k&#246;nnen, m&#252;ssen Arbeitnehmervertreterinnen und -vertreter die n&#246;tige Datenschutz- und KI-
Beurteilungskompetenz haben oder zumindest heranziehen k&#246;nnen.1428 Es ist sinnvoll, betriebliche Best-Practice-Beispiele f&#252;r
eine solche Zusammenarbeit zu identifizieren und zu verbreiten.
Im Besch&#228;ftigtenkontext ist besonders relevant, dass gesetzliche Vorgaben der europ&#228;ischen DSGVO etwa zum
Profiling (Artikel 22 DSGVO) praxisnah und ethikkonform zu Handlungsempfehlungen pr&#228;zisiert werden. In 
diesem Kontext w&#228;re es auch hilfreich, wenn Standards f&#252;r Pseudonymisierung und Anonymisierung1429
verabschiedet w&#252;rden, um personenbezogene Daten f&#252;r KI zu nutzen und zugleich die Rechte der Betroffenen
zuverl&#228;ssig zu wahren.1430 
Die Planungen des BMAS, einen Index Besch&#228;ftigtendatenschutz zu entwickeln, sind f&#252;r die Wahrung der
Pers&#246;nlichkeitsrechte beim Einsatz von KI in der Arbeit von besonderer Bedeutung; sie sind zu unterst&#252;tzen. Das
Ministerium verfolgt dabei das Ziel, &#8222;wissenschaftlich fundierte anwendungsbezogene Qualit&#228;tsma&#223;st&#228;be f&#252;r den
Besch&#228;ftigtendatenschutz in den Betrieben vergleichbar und handhabbar zu machen&#8220;1431. 
Betriebliche Gestaltungsinitiativen f&#246;rdern
Die Unterst&#252;tzung betrieblicher Gestaltungsinitiativen ist gerade wegen der Komplexit&#228;t der KI-Systeme und
deren vielf&#228;ltiger Einsatzformen zweckm&#228;&#223;ig. Um daf&#252;r zu sorgen, dass die genannten Prinzipien in der Arbeit
angewendet werden, m&#252;ssen daf&#252;r relevante Funktionsweisen von KI-Systemen gekennzeichnet werden.
Entsprechende Normen und Benchmarks sowie entsprechende Auditierung und Zertifizierung w&#252;rden Ansatzpunkte
liefern, mit denen sich betriebliche Akteure der Arbeitsgestaltung ein Urteil dar&#252;ber bilden k&#246;nnen, ob eine KI-
Anwendung Anforderungen gen&#252;gen und beispielsweise die Gestaltungsans&#228;tze &#8222;Privacy by design&#8220; oder &#8222;Gute
Arbeit by design&#8220; umsetzen kann. 
In Anlehnung an den &#8222;Corporate Governance Kodex&#8220; f&#252;r gute Unternehmensf&#252;hrung kann ein System ethischer 
Ma&#223;st&#228;be als Instrument der Selbststeuerung der Wirtschaft implementiert werden, das auch f&#252;r die Arbeit von
Arbeitnehmervertretungen Relevanz entfaltet.1432 Ein Modell wie das der Datenethikkommission f&#252;r die
Einstufung algorithmischer Systeme in Kritikalit&#228;tsstufen k&#246;nnte auch f&#252;r die betriebliche Arbeitsgestaltung erstellt
werden und zur Orientierung f&#252;r Entscheidungen &#252;ber den Einsatz von bestimmten Systemen im jeweiligen
Kontext genutzt werden.1433 Es sollte jedoch um einen Mechanismus erg&#228;nzt werden, der die Untersuchung der
Nutzenpotenziale von KI-Systemen f&#252;r die verschiedenen Stakeholder-Gruppen in den Betrieben zu erm&#246;glichen.
Damit k&#246;nnen Chancen- und Risikopotenziale gleichzeitig in die Formulierung von betrieblichen
Regulierungsans&#228;tzen einflie&#223;en.
Die F&#246;rderung von Sozialpartnerprojekten mit partizipativem Charakter, bei denen Wissenschaftlerinnen und
Wissenschaftler und Unternehmen gemeinsam mit Personal- und Betriebsr&#228;ten Gestaltungsinitiativen
entwickeln, kann hilfreich sein f&#252;r die Entwicklung von Ma&#223;st&#228;ben f&#252;r das betriebliche Handeln.
1428 Siehe zum Kompetenzerwerb bzw. zur Orientierung etwa &#252;ber Auditierung und Zertifizierung auch die Handlungsempfehlungen in 
Kapitel 5.1.2.5 [Partizipation und Mitbestimmung] und Kapitel 5.2.7 [KI in Aus- und Weiterbildung] dieses Projektgruppenberichts.
1429 Eine M&#246;glichkeit zur sicheren Daten-Anonymisierung und Daten-Pseudonymisierung ist das Einschalten einer unabh&#228;ngigen und 
vertrauensw&#252;rdigen dritten Instanz (&#8222;Trust Center&#8220;) zwischen der Daten erhebenden Stelle, den betroffenen Personen und jenen
Akteuren, welche die Daten auswerten und verarbeiten m&#246;chten. Eine De-Anonymisierung erhobener Daten muss zu jeder Zeit
ausgeschlossen sein. Vgl. J&#228;schke et al. (2018): F&#252;r immer anonym: Wie kann De-Anonymisierung verhindert werden? Gutachten zur
Verhinderung der De-Anonymisierung, S. 65 f.
1430 Darstellung Eva Gardyan-Eisenlohr (Konzerndatenschutzbeauftragte der Bayer AG) in der Sitzung der gesamten Enquete-
Kommission am 13. Januar 2020.
1431 Bundesministerium f&#252;r Arbeit und Soziales, Abteilung Grundsatzfragen des Sozialstaats, der Arbeitswelt und der sozialen
Marktwirtschaft (2016): Weissbuch Arbeiten 4.0, S. 150.
1432 Siehe auch Kapitel 3.3.3 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220; [Angestrebte Wirtschaftsziele: &#8222;KI made in Germany&#8220;
als internationales G&#252;tesiegel].
1433 Vgl. Datenethikkommission der Bundesregierung (2019): Gutachten der Datenethikkommission der Bundesregierung, S. 177.
Menschenzentrierung und Barrierefreiheit f&#246;rdern
&#8222;KI-Systeme haben das Potenzial, die menschliche Informationsverarbeitung zu &#252;berfordern und auch zu
unterfordern. Sie k&#246;nnen einerseits psychische und physische Fehlbelastungen erzeugen und andererseits bieten sich
neue Chancen, Arbeitsbedingungen individueller zu gestalten, Belastungen zu optimieren und
Besch&#228;ftigungsf&#228;higkeit auch f&#252;r beeintr&#228;chtigte Menschen zu f&#246;rdern.&#8220;1434 Diese Ambivalenz beim Einsatz von KI-Systemen
ist zugunsten der arbeitenden Menschen zu beeinflussen. Um die Aufgaben der betrieblichen Gestaltungsarbeit
in dieser Hinsicht zu leisten, braucht es auch entsprechend angepasste Regeln, Normen und Leitf&#228;den der
Arbeitsschutzinstanzen und Institute der Industrienormung. &#8222;Die Systeme sollten benutzerorientiert und so gestaltet
sein, dass m&#246;glichst viele Menschen, f&#252;r die sie gedacht sind, sie unabh&#228;ngig von ihrem Alter, Geschlecht, ihren
F&#228;higkeiten oder Merkmalen nutzen k&#246;nnen. Die barrierefreie Zug&#228;nglichkeit dieser Technologie f&#252;r Menschen
mit Behinderung, die in allen gesellschaftlichen Gruppen pr&#228;sent sind, ist von besonderer Bedeutung.&#8220;1435 
KI-Systeme sollten dazu dienen, die kognitiven, sozialen und kulturellen F&#228;higkeiten des Menschen zu st&#228;rken, 
zu erg&#228;nzen und zu f&#246;rdern. Die Zusammenarbeit zwischen Menschen und KI-Systemen sollte nach
menschenzentrierten Entwicklungsgrunds&#228;tzen erfolgen und sinnvolle Spielr&#228;ume f&#252;r menschliche Entscheidung lassen.
Das bedeutet, dass die menschliche Aufsicht und Kontrolle &#252;ber Arbeitsprozesse in KI-Systemen sichergestellt
ist.1436 
5.1.3.5.2 Einsatz von automatisierten Entscheidungssystemen und KI in der
Personalverwaltung
Beim Einsatz von KI-Anwendungen muss gew&#228;hrleistet sein, dass Menschen weiterhin in Personalfragen
entscheiden.
In der Personalverwaltung d&#252;rfen f&#252;r die Nutzung in automatisierten Programmen oder KI-L&#246;sungen keine Daten
erhoben und verwendet werden, welche der willentlichen Steuerung der Betroffenen grunds&#228;tzlich entzogen sind.
Die Subjektqualit&#228;t und Selbstbestimmung des Menschen m&#252;ssen immer geachtet werden. &#220;berwachung und
Auswertung von k&#246;rperlichen Ph&#228;nomenen sowie von Emotionen der Besch&#228;ftigten und eine umstrittene1437 
&#8222;Vermessung&#8220; der Pers&#246;nlichkeit von Bewerberinnen und Bewerbern sind grunds&#228;tzlich durch Verbot und auch
unter Androhung strafrechtlicher Konsequenzen auszuschlie&#223;en, wenn sie nicht zum Nutzen der Arbeitnehmerin 
oder des Arbeitnehmers sind.
Anbieter sowie Nutzerinnen und Nutzer von KI-L&#246;sungen f&#252;r die Personalgewinnung m&#252;ssen sicherstellen, dass
die zugrundeliegenden Daten &#252;ber eine hohe Qualit&#228;t verf&#252;gen und systembedingte Diskriminierungen
ausgeschlossen werden.
Vor bzw. beim Einsatz einer KI-L&#246;sung im Personalwesen m&#252;ssen die davon betroffenen Menschen &#252;ber Einsatz,
Zweck und Logik der erhobenen und verwendeten Datenarten informiert werden. Es ist gesetzlich klarzustellen,
dass &#8222;People Analytics&#8220;-Verfahren nur eingesetzt werden d&#252;rfen, wenn eine Betriebsvereinbarung vorliegt oder
die Besch&#228;ftigten individuell eingewilligt haben.1438 
Werden Datengenerierung und darauf erfolgende Verarbeitungen zur Arbeitsverteilung f&#252;r Leistungs- und
Potenzialbeurteilungen oder andere Scoring-Zwecke genutzt, m&#252;ssen f&#252;r die ADM- und KI-Systeme
Gef&#228;hrdungsbeurteilungen durchgef&#252;hrt werden &#8211; sowohl vor deren Einsatz als auch regelm&#228;&#223;ig im laufenden Betrieb. ADM-
Systeme m&#252;ssen dabei zweckgebunden passgenau auditiert und zertifiziert werden. F&#252;r die Kriterien solcher 
Gef&#228;hrdungsbeurteilungen existieren bereits erste Modelle im Verbraucherschutz1439 sowie bei der
Datenethikkommission. Diese k&#246;nnten auch in Unternehmen als Grundlage dienen, m&#252;ssen aber entsprechend dem
besonderen Verh&#228;ltnis Arbeitgeber / Arbeitnehmerin oder Arbeitnehmer angepasst werden. Ber&#252;cksichtigt werden
1434 Handlungsempfehlungen Prof. Dr. Lars Adolph (Bundesanstalt f&#252;r Arbeitsschutz und Arbeitsmedizin), Projektdrucksache 19(27)PG 4-
20 vom 9. Dezember 2019.
1435 High-Level Expert Group on Artificial Intelligence (2019): Ethik-Leitlinien f&#252;r eine vertrauensw&#252;rdige KI, S. 23.
1436 Vgl. High-Level Expert Group on Artificial Intelligence (2019): Ethik-Leitlinien f&#252;r eine vertrauensw&#252;rdige KI, S. 15.
1437 Umstritten ist sowohl, ob die Pers&#246;nlichkeitsmodelle eine Aussagekraft &#252;ber k&#252;nftige Leistungen am Arbeitsplatz haben, als auch,
ob die Softwares das messen, was sie angeben zu messen (&#8222;Validit&#228;t&#8220;). Vgl. etwa Lischka et al. (2017): Wenn Maschinen Menschen
bewerten, S. 23; Kanning (2018): Fachbuch im Fokus.
1438 Vgl. Wedde (2020): Automatisierung im Personalmanagement &#8211; arbeitsrechtliche Aspekte und Besch&#228;ftigtendatenschutz und AW
AlgorithmWatch gGmbH (2020): Positionen zum Einsatz von KI im Personalmanagement. Rechte und Autonomie von Besch&#228;ftigten
st&#228;rken &#8211; Warum Gesetzgeber, Unternehmen und Betriebsr&#228;te handeln m&#252;ssen.
1439 Vgl. Krafft und Zweig (2019): Transparenz und Nachvollziehbarkeit algorithmenbasierter Entscheidungssysteme; &#196;hnlich zuletzt
Datenethikkommission der Bundesregierung (2019): Gutachten der Datenethikkommission der Bundesregierung, S. 177 ff.
muss, dass in Arbeitsverh&#228;ltnissen eine starke Machtasymmetrie vorliegt und bereits dadurch ein hohes
Schadenspotenzial f&#252;r die Besch&#228;ftigten besteht. Es darf aufgrund des Abh&#228;ngigkeitsverh&#228;ltnisses auch nicht davon 
ausgegangen werden, dass eine Einwilligung der Mitarbeiterinnen oder der Mitarbeiter in die Verarbeitung
personenbezogener Daten durch diese Systeme in Unternehmen zul&#228;ssig ist. Die DSGVO sieht hier strenge
Anforderungen f&#252;r die Wirksamkeit von Einwilligungen vor, welche auch durch die Aufsichtsbeh&#246;rden &#252;berpr&#252;ft
werden k&#246;nnen und sollten.
Vor der Einf&#252;hrung von ADM-Systemen und KI-gest&#252;tzten Systemen sind betriebliche Folgenabsch&#228;tzungen
hinsichtlich des Schadenspotenzials, der Pers&#246;nlichkeitsrechte und der Auswirkungen auf die
Arbeitsbedingungen unerl&#228;sslich. Ein Teil der Projektgruppe empfiehlt, dass &#8211; abh&#228;ngig von der dort festgestellten
&#8222;Regulierungsklasse&#8220; 1440 des eingef&#252;hrten Systems &#8211; in Abstimmung mit dem Betriebsrat vorab und im laufenden Einsatz
geeignete Schutzma&#223;nahmen getroffen werden. Diese generelle und ex ante Einteilung von ADM-Systemen und
KI-gest&#252;tzten Systemen in Risikoklassen war in der Enquete-Kommission und in der Projektgruppe
umstritten.1441 Wird eine KI-L&#246;sung in einer Organisation eingesetzt, muss regelm&#228;&#223;ig &#252;berpr&#252;ft werden, ob die
Nutzung in Einklang mit den oben genannten Richtlinien ist und den festgelegten Zielsetzungen entspricht. Bei
Abweichungen sind Anpassungen vorzunehmen. Das Instrument der Gef&#228;hrdungsbeurteilung wird zum
Belastungsmonitor und betrieblichen Fr&#252;hwarnsystem ausgebaut. Vorab ist eine entsprechende Verordnung des BMAS zu
psychischen Gef&#228;hrdungen notwendig, die klare Sanktionen f&#252;r unterlassene Gef&#228;hrdungsbeurteilungen sowie
enge Kontrollen vorsieht. Entsprechende Kontrollbeh&#246;rden m&#252;ssen personell aufgestockt werden. F&#252;r
Unternehmen und andere Organisationen ohne Betriebs- oder Personalr&#228;te sollte die Bundesregierung gesetzliche
Mindeststandards definieren und einf&#252;hren.
5.1.3.5.3 KI in der Arbeits- und Sozialverwaltung
Die Projektgruppe h&#228;lt f&#252;r den Einsatz von KI in der Verwaltung einen Handlungsrahmen f&#252;r sinnvoll, der hilft,
kritische KI-Anwendungen zu erkennen und sie angemessen zu pr&#252;fen.1442 So kann auch der fl&#228;chendeckende
Einsatz von unbedenklicher KI unterst&#252;tzt werden. Vorgaben zur Nutzung von KI sollten iterativ anhand
konkreter Anwendungsf&#228;lle erarbeitet werden. Dabei m&#252;ssen bestehende Gesetze zu Datenschutz und Datennutzung
sowie datenethische Grunds&#228;tze wie Transparenz, Nachvollziehbarkeit und Nicht-Diskriminierung eingehalten
werden.1443 
Durch KI freigewordene Kapazit&#228;ten sollten daf&#252;r genutzt werden, unterbesetzte Abteilungen zu st&#228;rken und
z. B. in die Beratung und Vermittlung zu reinvestieren. Das Ziel sollte nicht vorrangig das Ersetzen von Personal,
sondern in erster Linie die Qualit&#228;tssteigerung sein. Sollten sich durch den Einsatz von KI die Arbeitsprofile der
Mitarbeiterinnen und Mitarbeiter ver&#228;ndern, sollten sie mit Aus- und Weiterbildungen unterst&#252;tzt werden. Ein
KI-System soll dann eingesetzt werden, wenn es ein bestehendes Problem l&#246;st. Kosten und Nutzen m&#252;ssen vor
Einf&#252;hrung einer neuen Anwendung gepr&#252;ft werden; beim Einkauf von externen Herstellern sollte sichergestellt
werden, dass die Anwendung auch im neuen Kontext gut funktioniert. Dazu geh&#246;rt in der Regel, dass
Anregungen und Hinweise der betroffenen Besch&#228;ftigten einbezogen werden.
F&#252;r einen positiven Einsatz von KI in der Arbeits- und Sozialverwaltung sollte es einen Wissenstransfer zwischen
den einsetzenden Organisationen geben, sodass aus positiven und negativen Erfahrungen mit den neuen
Systemen gelernt werden und gemeinsam neue L&#246;sungsans&#228;tze entwickelt werden k&#246;nnen. Ein positives Beispiel
hierf&#252;r ist die NExT-Netzwerk-Initiative, eine l&#228;nder&#252;bergreifende Plattform im &#246;ffentlichen Dienst, wo sich
&#246;ffentliche Verwaltungen vernetzen k&#246;nnen, um ihre Erfahrungen im Bereich Digitalisierung auszutauschen.1444 
1440 Diese Klassen k&#246;nnten z. B. von &#8222;0 &#8211; keine Regulierungsanforderungen&#8220; bis &#8222;4 &#8211; Verbot&#8220; reichen, vgl. z. B. Krafft und Zweig (2019):
Transparenz und Nachvollziehbarkeit algorithmenbasierter Entscheidungssysteme; &#196;hnlich zuletzt Datenethikkommission der
Bundesregierung (2019): Gutachten der Datenethikkommission der Bundesregierung, S. 177 ff.
1441 Vgl. Kapitel 4 des Mantelberichts [KI und Umgang mit Risiko].
1442 Die von der Datenethikkommission vorgeschlagene Kritikalit&#228;tspyramide beschreibt eine M&#246;glichkeit f&#252;r einen solchen
Handlungsrahmen, &#252;ber die aber in der Projektgruppe nicht abschlie&#223;end diskutiert wurde. Siehe f&#252;r Weiteres zum Einsatz von KI in der
Verwaltung auch den Bericht der Projektgruppe &#8222;KI und Staat&#8220; in Kapitel C. III. [K&#252;nstliche Intelligenz und Staat (Projektgruppe 2)].
1443 Siehe auch Kapitel 3 des Mantelberichts [KI und Umgang mit Bias/Diskriminierung].
1444 Im Bericht der Projektgruppe &#8222;KI und Staat&#8220; in Kapitel C. III. [K&#252;nstliche Intelligenz und Staat (Projektgruppe 2)] finden sich weitere
Handlungsempfehlungen f&#252;r den Einsatz von KI in der Verwaltung.
5.1.3.5.4 Weiterentwicklung der sozialen Sicherungssysteme
Die Projektgruppe h&#228;lt eine gesellschaftliche und politische Diskussion &#252;ber die Zukunft der sozialen
Sicherungssysteme f&#252;r angezeigt, auch vor dem Hintergrund der Erfahrung vieler abh&#228;ngig Erwerbst&#228;tiger,
Selbstst&#228;ndiger und freiberuflich t&#228;tiger Menschen.
Die Projektgruppe konnte aus zeitlichen Gr&#252;nden dieses Thema nicht vertiefen, hat aber wegen des
grunds&#228;tzlichen Charakters und der &#252;berwiegend KI-unspezifischen Wirkungszusammenh&#228;nge keine inhaltliche
Empfehlung zu den unterschiedlichen konzeptionellen Ans&#228;tzen erarbeitet. Sie h&#228;lt aber f&#252;r sinnvoll, f&#252;r die n&#228;chste
Legislaturperiode des Bundestages eine Expertenkommission zu dieser Fragestellung einzurichten und dabei
z. B. die Sozialpartner, Vertreterinnen und Vertreter freiberuflich t&#228;tiger Menschen, der Wohlfahrtsverb&#228;nde, der
Zivilgesellschaft, der Wissenschaft und der Politik einzubeziehen. Eine weitere Herausforderung f&#252;r die sozialen
Sicherungssysteme bleibt der demografische Wandel.
KI in der Bildung1445 
In einer von KI gepr&#228;gten Welt werden Kenntnisse &#252;ber KI immer mehr zu einer notwendigen
Schl&#252;sselkompetenz f&#252;r die Teilhabe in allen gesellschaftlichen Bereichen. Der Umgang mit und die Gestaltung von KI werden 
f&#252;r ein selbstst&#228;ndiges Leben in der Welt von morgen an Bedeutung gewinnen. Schon Kinder und Jugendliche
sind in ihrem Alltag von KI-Anwendungen umgeben. So nutzen sie t&#228;glich auf ihren Smartphones, freuen sich
&#252;ber die M&#246;glichkeiten, die sich mit digitalen Sprachassistenten ergeben, stehen aber auch Risiken gegen&#252;ber,
wie dem Mobbing in sozialen Medien mittels &#8222;Deepfakes&#8220;.1446 Die Vermittlung der Funktionsweisen und
Auswirkungen sowie die erfolgreiche Einf&#252;hrung bzw. Nutzung von KI in der Bildung ist daher von gro&#223;er
Bedeutung f&#252;r die Zukunftsf&#228;higkeit des deutschen Bildungs- und Ausbildungssystems, f&#252;r die Wettbewerbsf&#228;higkeit
des Wirtschaftsstandortes Deutschland und somit letztendlich der deutschen Gesellschaft.
Aufgabe des Bildungssystems ist es, Kinder bei der Auspr&#228;gung ihrer Pers&#246;nlichkeit zu unterst&#252;tzen und ihnen
die Grundlagen f&#252;r eine selbstst&#228;ndige Gestaltung ihres Lebensweges mitzugeben. Daf&#252;r sind Grundkenntnisse
&#252;ber die digitale Welt einschlie&#223;lich KI-Verfahren heute ein wichtiger Aspekt. Das Bildungssystem soll so gut
wie m&#246;glich darauf vorbereiten, in einer von KI gepr&#228;gten Welt mit transformierten Arbeits-, Organisations- und
Kommunikationsprozessen umzugehen. Dies stellt das deutsche Bildungssystem vor gro&#223;e Herausforderungen &#8211;
insbesondere, wenn man von der Pr&#228;misse &#8222;In der Schule lernen wir f&#252;r das Leben&#8220; aber auch vom Schlagwort
des lebenslangen Lernens ausgeht. Viele KI-Technologien haben noch gar keine Marktreife erlangt, aber die
Entwicklung zuk&#252;nftiger Anwendungsgebiete von KI geht rasant voran. Von vielen Berufsfeldern,
T&#228;tigkeitsprofilen und Ver&#228;nderungen, die sich durch die KI ergeben, wei&#223; man vielleicht heute noch nicht. Trotzdem muss
das deutsche Bildungssystem so gestaltet werden, dass es m&#246;glichst flexibel und dynamisch auf durch KI
getriebene Entwicklungen reagieren kann und ein fundiertes Basiswissen vermittelt, das dazu bef&#228;higt, selbstst&#228;ndig
weiterzulernen und sich neue Dinge anzueignen.
Hinsichtlich des Einsatzes von KI in der Bildung wird &#252;ber zwei unterschiedliche, aber gleicherma&#223;en wichtige
Bereiche gesprochen:
1. Lernen &#252;ber KI, das sich auf die Aus- und Weiterbildung zu technischen F&#228;higkeiten, aber auch zu
Anwendungen und Soft Skills im Zusammenhang mit KI bezieht
2. Lernen mit KI, das sich auf die Unterst&#252;tzung und die Analyse von Lernen durch KI-L&#246;sungen bezieht
Die Aus- und Weiterbildung betrifft alle Bildungsbereiche: Vorschule1447, Schule, (Ausbildungs-)Berufe,
Hochschulen, aber auch die inner- und au&#223;erbetriebliche Weiterbildung sowie die Erwachsenenbildung. Weiterhin
sollte die Gesamtbev&#246;lkerung &#8211; unabh&#228;ngig von den jeweiligen Berufen &#8211; in die Lage versetzt werden,
grundlegende Informationen und Kenntnisse &#252;ber KI zu erlangen. Dies kann beispielsweise durch eine Lernplattform
geschehen, in der Grundkenntnisse zu KI, deren Funktionsweise, Informationen &#252;ber Anwendungsf&#228;lle usw.
vermittelt werden, aber auch &#252;ber die Risiken von KI und M&#246;glichkeiten zu deren Vermeidung aufgekl&#228;rt wird.
1445 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 5.2 des Berichts der
Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220; (&#8222;KI in der Bildung &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des
sachverst&#228;ndigen Mitglieds Dr. Florian Butollo].
1446 Vgl. Bovenschulte (2019): Deepfakes. Manipulation von Filmsequenzen.
1447 Es gibt auch Projekte, die den Einsatz von KI im Vorschulalter erproben, wie beispielsweise das Projekt L2TOR, weitere
Informationen dazu unter: http://www.l2tor.eu/ (zuletzt abgerufen am 5. August 2020).
Wichtige Grundlage f&#252;r die KI-Kompetenz von Sch&#252;lerinnen und Sch&#252;lern und Auszubildenden ist die
Ausstattung der Schulen mit der notwendigen Soft- und Hardware. Hier gibt es &#8211; im f&#246;deralen System abh&#228;ngig von
Bundesland oder Kommune &#8211; gro&#223;e Unterschiede. Allgemein l&#228;sst sich aber festhalten: Die Bildungsst&#228;tten
haben Nachholbedarf. IT-Infrastruktur ist oft unzureichend vorhanden und es mangelt an IT-Kompetenzen bei 
Lehrkr&#228;ften, Schulleitungen und Eltern (z. B. in Bezug auf Datenschutz und -sicherheit oder Auswahl geeigneter
Hard- und Software) sowie an Fortbildungsangeboten. Zudem m&#252;ssen oftmals die Lehrkr&#228;fte die IT betreuen
statt eines IT-Dienstleisters, was wichtige Ressourcen bindet. Es gibt sehr gute Projekte und Initiativen, die
jedoch Einzelprojekte bleiben und nicht die notwendige Reichweite erzielen, da sie vom Engagement einzelner
Lehrerinnen und Lehrer oder Schulen abh&#228;ngig sind. Mit dem DigitalPakt Schule haben Bund und L&#228;nder im
Jahr 2019 die digitale Transformation der Schule angesto&#223;en. Ziel des DigitalPaktes ist es, Schulen besser mit
digitaler Technik auszustatten. Pilotinitiativen und der DigitalPakt Schule sind notwendige Voraussetzungen f&#252;r
den Ausbau der Bildung im Bereich KI, reichen aber bei Weitem nicht aus. Es bedarf eines dauerhaften Konzepts
der hierf&#252;r zust&#228;ndigen L&#228;nder, um das Thema KI langfristig in der Bildung zu verankern. Die Corona-Krise hat 
verdeutlicht, welche Vorteile der Einsatz digitaler Technik in der Bildung mit sich bringen kann. Es hat sich aber
auch gezeigt, dass einheitliche Konzepte und Plattformen erforderlich sind. Digitale Bildung (als Grundlage f&#252;r
das Lernen mit und &#252;ber KI bzw. als Teil davon) kann immer nur in der Verbindung von Ausstattung, Konzept
und Qualifizierung gelingen. Das ist auch der Grund, warum der Bund (&#252;ber das BMBF) nicht nur Technik
f&#246;rdert, sondern bereits im DigitalPakt Schule festgeschrieben hat, auch die digitale Lehrerfortbildung und die
Curricula in den L&#228;ndern verst&#228;rkt in den Blick zu nehmen. Die Verantwortung f&#252;r die inhaltliche und
organisatorische Aus&#8208;, Fort&#8208; und Weiterbildung von Lehrerinnen und Lehrern liegt in der Zust&#228;ndigkeit der L&#228;nder.
5.2.1 Lernen &#252;ber KI
Damit Menschen sich eine fundierte und differenzierte Meinung &#252;ber die Chancen und Risiken von KI bilden
k&#246;nnen, ist ein grundlegendes Verst&#228;ndnis &#252;ber die Funktionsweise von KI-Systemen und die Methoden, mit
denen sie entwickelt werden, erforderlich. Die Behandlung von KI als f&#228;cher&#252;bergreifendes Thema in Vorschule,
Schule, Studium und beruflicher Aus- und Weiterbildung ist deshalb notwendig, um ein generelles Verst&#228;ndnis
f&#252;r Maschinelles Lernen und weitere methodische Grundlagen, wie Planungsalgorithmen oder Sprach- und
Bildverarbeitung, zu vermitteln. Dabei ist es wichtig, dass auch Einblicke in m&#246;gliche Herausforderungen des
Maschinellen Lernens und der dazu notwendigen Datengrundlage gegeben werden. KI-Systeme lernen induktiv von 
Daten, wodurch ein Generalisierungsfehler (Sampling Bias) bzw. eine Verzerrung in Ergebnissen, die von KI
erzeugt wurden, entstehen kann, wenn die Trainingsdaten nicht hohen qualitativen Anforderungen entsprechen.
Menschen m&#252;ssen im Umgang mit KI daher in der Lage sein, die Chancen von KI zu erkennen; sie m&#252;ssen aber
auch die von KI erzeugten Ergebnisse einordnen und Verzerrungen erkennen k&#246;nnen, um eventuelle
Fehlinterpretationen zu vermeiden. Digitale Lernmaterialien m&#252;ssen hohe Qualit&#228;tsstandards erf&#252;llen und wie klassische
Schulb&#252;cher von geeigneten Stellen (z. B. dem Kultusministerium) gepr&#252;ft werden. Wissen &#252;ber KI muss dabei
Sch&#252;lerinnen und Sch&#252;lern gleicherma&#223;en vermittelt werden.
5.2.2 Lernen mit KI
Lernen ist und bleibt ein sozialer Prozess. Das bedeutet, ma&#223;geblich f&#252;r den Lernerfolg sind u. a. die
Kommunikation und der Austausch zwischen Lehrenden und Lernenden. Es gilt zu erforschen, inwieweit und durch
welchen Einsatz KI-Systeme positiven Einfluss auf den Lernerfolg nehmen k&#246;nnen und Diskriminierungen
verhindern. Auch Lehrkr&#228;fte machen Fehler bei der Differenzierung und Bewertung &#8211; sicherzustellen ist sowohl bei 
menschlichen Lehrkr&#228;ften als auch bei maschinellen Unterst&#252;tzungssystemen, dass Fehleinsch&#228;tzungen
korrigierbare Einzelf&#228;lle bleiben, dass sie nicht systematisiert und institutionalisiert werden. Bisherige Pilotprojekte
von KI-Systemen als Werkzeug beim Lernen zeigen Chancen und Risiken auf.
Mechanismen und Ma&#223;nahmen von KI k&#246;nnen Menschen in der gesamten Bildungskette dabei unterst&#252;tzen,
komplexe Sachverhalte besser zu durchdringen. KI kann beispielsweise gezielt zur individuellen F&#246;rderung und
zur Unterst&#252;tzung lebenslangen Lernens eingesetzt werden und ist deshalb in diesem Kontext f&#252;r die Zukunft
erstrebenswert. M&#246;glich sind beispielsweise tagesaktuelle Stundenpl&#228;ne, je nach Leistungsstand. Dieser wird
erfasst und es werden entsprechende Wiederholungen bekannter Inhalte oder neue Aufgaben bereitgestellt.
Lernschw&#228;chere Sch&#252;lerinnen und Sch&#252;ler k&#246;nnen dabei ebenso individuell unterst&#252;tzt werden wie st&#228;rkere. So kann
auch die Inklusion in Schulen unterst&#252;tzt werden. Dar&#252;ber hinaus ist eine pers&#246;nliche KI-Lernstandserhebung
m&#246;glich, einhergehend mit dem Erstellen eines individuellen Schulbuchs und dem flexiblen Hinzuf&#252;gen
individueller Lernmedien. Ein intelligentes Schulbuch kann dabei unterst&#252;tzen, konstant den Lernstand und das
Lernverst&#228;ndnis der Sch&#252;lerin oder des Sch&#252;lers zu messen und dadurch ihre bzw. seine St&#228;rken und Schw&#228;chen
festzustellen. Auf dieser Grundlage kann es Inhalte und Aufgaben individuell anpassen. Technisch kann z. B. 
mittels Sensoren (Eye-Trackern1448) ausgewertet werden, welche Textpassagen oder Grafiken wiederholt oder
l&#228;nger angesehen werden.1449 Die KI-Algorithmen k&#246;nnen dann R&#252;ckschl&#252;sse auf etwaige
Verst&#228;ndnisschwierigkeiten oder verst&#228;rkte Interessen einer Sch&#252;lerin oder eines Sch&#252;lers ziehen. Das Schulbuch kann anschlie&#223;end
individuell und adaptiv darauf reagieren und beispielsweise weitere Informationen zu einem Begriff oder Thema
liefern. Die Integration von KI in Lernplattformen kann dabei helfen, die f&#252;r den individuellen Lernprozess
notwendigen Medien zu ermitteln und bereitzustellen. Das Immersive Quantified Learning Lab (iQ-L) des
Deutschen Forschungszentrums f&#252;r K&#252;nstliche Intelligenz (DFKI) stellt eine cyber-physische Lernumgebung mit
p&#228;dagogisch-didaktisch fundierten, technologieunterst&#252;tzten, adressatenspezifischen, interaktiven und
partizipativen Lehr- und Lernkonzepten dar. Diese Form des &#8222;Quantified Learnings&#8220; erm&#246;glicht eine personalisierte, auf
die Sch&#252;lerinnen und Sch&#252;ler zugeschnittene Form des Lernens, in der nicht nur der jeweilige Wissensstand,
sondern auch die konkrete Lernsituation und die individuelle Aufnahmef&#228;higkeit ber&#252;cksichtigt werden. 
Gleichzeitig geht mit der Nutzung solcher KI-Systeme im Bildungsprozess ein Risiko einher, wenn sich die
Systeme auf Lernende beziehen. In China werden bereits Systeme zur Gesichtserkennung, zum Beobachten von
Augenbewegung1450 und EEG-Messungen1451 eingesetzt, um das Verhalten beim Lernen und auf dem
Schulgel&#228;nde auszuwerten und zu bewerten. F&#252;r uns in Deutschland hingegen muss eindeutig sein, dass solche
Lernsysteme nur eingesetzt werden sollen, um den Lernerfolg und das Lernerlebnis der Sch&#252;lerinnen und Sch&#252;ler zu
verbessern &#8211; dort, wo es p&#228;dagogisch sinnvoll ist, nicht jedoch zur Verhaltensbewertung und Disziplinierung.
Am DFKI wird derzeit mit F&#246;rderung durch das BMBF an einem Schulbuch geforscht, das beispielsweise mit
einer Infrarotkamera die Nasentemperatur misst, um so R&#252;ckschl&#252;sse auf Anstrengung beim Lernen zu
ziehen.1452 Fehlinterpretationen sowie direkte und indirekte Folgen dieser Systeme auf das Lernverhalten, den
Lernprozess, Lehrende sowie Lernende sind noch nicht vollst&#228;ndig erforscht, au&#223;erdem m&#252;ssen alle n&#246;tigen
Anforderungen an den Einsatz von KI-Systemen mit personenbezogenen Daten im Schulbetrieb und in Schulbeh&#246;rden
erf&#252;llt werden. Daten, die der willentlichen Steuerung der Betroffenen entzogen sind und mit hoher
Wahrscheinlichkeit der Fehlinterpretation unterliegen, wie es beispielsweise bei Sprach-, Stimm- und Mimikanalysen
m&#246;glich ist, sollten nicht erhoben, verarbeitet oder gespeichert werden.
Der Einsatz von KI-Systemen, die Lehr- und Lernmittel sowie Lehr- und Lernmethoden analysieren, kann die
Vorteile der Technologie im Bildungssystem nutzen, ohne die beschriebenen Risiken zu f&#246;rdern.1453 M&#246;glich
w&#228;re es, bei Kollaborationsprojekten, z. B. Gruppenarbeit, Heatmaps1454 anzuzeigen, Aktivit&#228;tsniveaus zu
messen, Fortschritte im Projekt auszuwerten oder auch Zusammenh&#228;nge und Verl&#228;ufe sichtbar zu machen. Der
Austausch von Lehr- und Lernmitteln als Open Educational Resources (OER)1455 k&#246;nnte hierf&#252;r eine wichtige
Voraussetzung sein. Diese Ans&#228;tze und ihre Chancen sollten weiter untersucht und erforscht werden.
Lernen ist ein sozialer Prozess und Lernende sind als Menschen wahrnehmende und handelnde Subjekte, das
hei&#223;t, die Bewertung des Lernverhaltens Einzelner erfordert eine ganzheitliche Analyse und Bewertung der
Lernenden, die nicht nur dieses Lernverhalten, sondern z. B. auch sozio&#246;konomische Hintergr&#252;nde einbezieht, die
f&#252;r den Lernerfolg mit ausschlaggebend sind.1456 Im schulischen Kontext kann nur eine Lehrkraft die
Gesamtsituation von Heranwachsenden erkennen und in die Beurteilung einflie&#223;en lassen. Der Lehrkraft kommt daher
beim Einsatz von KI-Systemen eine entscheidende Rolle zu, sie entscheidet &#252;ber den Einsatzort und
gegebenenfalls das verwendete Tool. Die Lehrkr&#228;fte m&#252;ssen deshalb eine hohe Kompetenz durch Aus- und Weiterbildung
erlangen, um reflektiert die richtigen Anwendungsfelder zu finden und gegebenenfalls auch zu erkennen, wenn
durch die angewendeten Tools etwa Ungleichheiten eher verst&#228;rkt als abgebaut werden.
1448 Deutsch: Systeme, die Augenbewegungen erkennen und aufzeichnen.
1449 Je nach Einsatzszenario wird diese Anwendung von der Projektgruppe als Chance oder als Risiko betrachtet.
1450 Vgl. Dorloff (2019): China &#8211; K&#252;nstliche Intelligenz als Staatsziel.
1451 Vgl. Nickel (2019): Chinesische Lehrer &#252;berwachen Gehirnwellen ihrer Sch&#252;ler.
1452 Vgl. Petermann (2019): K&#252;nstliche Intelligenz im Klassenzimmer &#8211; Wenn das Schulbuch mitdenkt.
1453 Z. B. k&#246;nnen die Teilnahme und der Lerneffekt an Projekten zum Thema KI gemessen und analysiert werden, hieraus kann KI das
Projektdesign optimieren und weiterentwickeln, etwa bei Projekten zum Verst&#228;ndnis von Algorithmen wie an der Universit&#228;t Kiel,
vgl. Christian-Albrechts-Universit&#228;t zu Kiel Philosophische Fakult&#228;t: Sch&#246;nheit im &#8222;Auge&#8220; der Algorithmen; ein Beispiel aus dem
Hochschulbereich zeigt M&#246;glichkeiten f&#252;r Gruppenarbeiten, die auf den Schulkontext heruntergebrochen werden k&#246;nnten, vgl.
Christian-Albrechts-Universit&#228;t zu Kiel Philosophische Fakult&#228;t Institut f&#252;r P&#228;dagogik: Student Crowd Research (SCoRe).
1454 Heatmap bezeichnet ein Diagramm zur Visualisierung von Daten. Diese Visualisierung dient dazu, &#252;ber eine gro&#223;e Datenmenge 
intuitiv und schnell einen &#220;berblick zu geben und besonders markante Werte leicht erkennbar zu machen.
1455 Weitere Informationen dazu unter: https://open-educational-resources.de/was-ist-oer-3-2/ (zuletzt abgerufen am 6. August 2020).
1456 Vgl. Gewerkschaft Erziehung und Wissenschaft (GEW) im DGB in Kooperation mit dem Verband f&#252;r Schulen f&#252;r gemeinsames
Lernen (GGG) und der Arbeitskammer des Saarlandes: Die Hattie-Studie.
Es spielen weitere, nicht messbare Faktoren eine Rolle, die f&#252;r ein KI-System nicht oder nur schwer
operationalisierbar, das hei&#223;t, nicht in Daten umwandelbar sind, sodass ein KI-System sie verarbeiten kann. Dazu geh&#246;ren
auch die im Kontext der digitalen M&#252;ndigkeit geforderten, sogenannten 4-K-Kompetenzen (Kollaboration,
kritisches Denken, Kommunikation, Kreativit&#228;t). 
Hingegen k&#246;nnen KI-Systeme, die Lernenden dabei helfen, gro&#223;e Textmengen zu analysieren, ohne dabei die
Lernenden zu beobachten, eine gro&#223;e Unterst&#252;tzung im Lernprozess darstellen. 
KI-Systeme k&#246;nnen dar&#252;ber hinaus den Lehrerinnen und Lehrern unterst&#252;tzend zur Seite stehen und sie damit
entlasten, damit sie u. a. mehr Zeit f&#252;r Individualbetreuung haben. Intelligente Tutorsysteme wie humanoide
Roboter kommunizieren &#252;ber Sprache, sie k&#246;nnen Wissensl&#252;cken und immer wieder auftretende Fehler erkennen
und so gezielt und konkret auf den Lernenden eingehen. Sie k&#246;nnen zudem bei der Sprachf&#246;rderung unterst&#252;tzen.
Dies macht individualisiertes Lernen sowie fortlaufende Weiterbildung in Schule, Studium, Ausbildung und
Beruf m&#246;glich und kann damit zum Lernerfolg beitragen.
Ebenso ist es denkbar, Lehrkr&#228;fte darin zu unterst&#252;tzen, Lehr- und Lernmittel sowie Lehr- und Lernmethoden 
mithilfe von KI auszuwerten. Die hierbei anfallenden Nutzungsdaten der Lernenden k&#246;nnen anonymisiert oder
pseudonymisiert erfasst, lokal gespeichert und nur aggregiert in die Analyse einflie&#223;en. Die Voraussetzung
hierf&#252;r ist, dass Nutzungsdaten anonymisiert erhoben, verarbeitet und gespeichert werden und nur aggregiert durch
das KI-System eingesetzt werden.
5.2.3 Umgang mit KI bzw. Learning Analytics
Beim Einsatz von KI im Lernprozess entstehen Daten &#252;ber Lernende. Diese Daten &#252;ber Lernende bzw.
Lernumgebungen k&#246;nnen gesammelt, algorithmisch ausgewertet und genutzt werden, um Lernen zu verbessern, indem
beispielsweise Lernende fr&#252;hzeitig auf Fehler oder Wissensl&#252;cken hingewiesen werden (Learning Analytics).
Learning-Analytics-Programme sammeln Daten, werten sie algorithmisch aus und schlagen Verbesserungen f&#252;r
den Lernprozess vor.1457 W&#228;hrend Learning-Analytics-Programme simple Datenanalysen durchf&#252;hren, erweitern
sich mit KI die M&#246;glichkeiten zur Analyse von Lernverhalten auf psychischer, sozialer und biometrischer Ebene:
KI-Systeme bieten die M&#246;glichkeiten, Gesichtsausdr&#252;cke zu lesen, Emotionen aus der Stimme abzuleiten und
daraus R&#252;ckschl&#252;sse auf Unsicherheiten zu ziehen, K&#246;rperhaltungen und die Art und Weise zu schreiben, zu
analysieren und sogar Herzfrequenzen zu interpretieren.
Grunds&#228;tzlich sind dabei drei Systemarten zu unterscheiden: Lernsysteme (Zielgruppe: Sch&#252;lerinnen und
Sch&#252;ler), Beurteilungssysteme (Zielgruppe: Lehrkr&#228;fte) und Aufsichtssysteme (Zielgruppe: Beh&#246;rden).1458 
Einerseits kann dies Chancen f&#252;r den Lernprozess einer Einzelnen oder eines Einzelnen und auch f&#252;r die weitere 
Optimierung von KI-basierten Lernmaterialien bieten, andererseits k&#246;nnen die Systeme eine Verhaltens&#228;nderung
bei Sch&#252;lerinnen und Sch&#252;lern bedeuten oder zu Fehlinterpretationen durch Lehrkr&#228;fte f&#252;hren. Eine besondere
Bedeutung muss in diesem Zusammenhang aber gleichzeitig immer auch der Schutz der pers&#246;nlichen Daten der
Lernenden und die Frage finden, wie personenbezogenen Daten zu Lernstandserhebung, Vorwissen oder Lerntyp 
gespeichert werden.
Die Arbeit mit KI-Systemen im Unterricht erfordert ein hohes Ma&#223; an Datenschutz, klare Regelungen f&#252;r den
Umgang mit den Lernmaterialien und entsprechende Schulungen f&#252;r das Lehrpersonal. Daf&#252;r wichtig sind der
Aufbau geeigneter Infrastrukturen (beispielsweise landeseigene Schul-Clouds), um Daten sicher zu speichern,
oder Regelungen zur Datensouver&#228;nit&#228;t. Das BMBF hat hierzu beispielsweise das Projekt Vermittlungsinstitut
digitale Schule (VIDIS) gestartet, welches aus Mitteln des DigitalPakts Schule finanziert wird und darauf abzielt,
dass Sch&#252;lerinnen und Sch&#252;ler sowie Lehrerinnen und Lehrer Angebote aus anderen Bundesl&#228;ndern nutzen
k&#246;nnen, ohne dabei sensitive Daten preiszugeben. Dabei stehen die Herstellung von Rechtssicherheit, die
Pseudonymisierung von Daten aus verschiedenen Schul-Cloud-Systemen und die Schaffung interoperabler
Identit&#228;tsmanagement-Systeme im Vordergrund.
Insgesamt sollten die Infrastrukturen der Schulen und Kompetenzen der Verantwortlichen so weit optimiert
werden, dass die richtige Erhebung, Aufbereitung, Analyse und Interpretation sowie die Abw&#228;gung sozialer
Auswirkungen und die Durchf&#252;hrung der n&#246;tigen Sicherheitsma&#223;nahmen (Grundrechte, Datenschutz, IT-Sicherheit)
1457 Darstellung Prof. Dr. Heidrun Allert (Professorin f&#252;r Medienp&#228;dagogik/Bildungsinformatik, Christian-Albrechts-Universit&#228;t zu Kiel)
in der Sitzung der Projektgruppe KI und Arbeit, Bildung, Forschung am 16. Dezember 2019.
1458 Vgl. Baker und Smith (2019): Educ-AI-tion Rebooted?
zum Wohle, Nutzen und Schutz aller Beteiligten erfolgen k&#246;nnen.1459 Angesichts der wachsenden Aufgaben von 
Lehrkr&#228;ften und Schulleitungen und dem fortschreitenden Lehrkr&#228;ftemangel sind weitere Belastungen der
Verantwortlichen zu vermeiden.1460 Da Schulen und Lehrkr&#228;fte mit dem Einsatz von KI-Systemen, die sich auf
Lernende beziehen, zus&#228;tzliche umfangreiche Anforderungen erf&#252;llen m&#252;ssen (Aufbau von Infrastrukturen,
Einsetzung von Datenschutzbeauftragten, Kompetenzaufbau zur Funktionsweise und Bewertung von KI-Systemen und
deren Beschaffung, Verkn&#252;pfung von Vor- und Nachmittagsunterricht bzw. Nachmittagsbetreuung,
Datenanonymisierung und maschinelle Lesbarkeit von Daten, Kl&#228;rung von Verantwortung und Haftungsfragen,
Sicherstellen der Nachvollziehbarkeit f&#252;r Eltern etc.) sollten vorrangig KI-Systeme weiter erforscht und entwickelt 
werden, die sich auf Lehr- und Lernmittel sowie Lehr- und Lernmethoden beziehen.
5.2.4 Anforderungen an den Schulunterricht1461 
Um Sch&#252;lerinnen und Sch&#252;ler auf die Welt von morgen vorzubereiten, ist die Vermittlung eines grundlegenden
Verst&#228;ndnisses f&#252;r KI (Lernen &#252;ber KI) in allen Schularten von gro&#223;er Bedeutung. Erg&#228;nzend kann KI zur
individuellen F&#246;rderung von Sch&#252;lerinnen und Sch&#252;lern im Unterricht eingesetzt werden (Lernen mit KI). Diese
birgt ein besonderes Potenzial f&#252;r Inklusion und individuelle F&#246;rderung in der heterogenen Sch&#252;lerschaft. Wenn
eine KI f&#252;r die Zukunft gestaltet werden soll, bei welcher der Mensch im Mittelpunkt steht und die den ethischen
Ma&#223;st&#228;ben entspricht, dann werden Menschen gebraucht, die KI-Systeme nicht nur verantwortungsvoll nutzen, 
sondern auch bauen k&#246;nnen. Ferner wird eine klare Richtschnur ben&#246;tigt, wie KI in der Gesellschaft eingesetzt
werden soll. Beides muss seinen Ausgangspunkt in den Schulen bei der digitalen Bildung haben.
F&#252;r ein technisches Verst&#228;ndnis und die Gestaltung von KI spielt die Mathematik eine wichtige Rolle. F&#252;r eine
sp&#228;tere Ausbildung im Bereich KI sind die schulische Bildung zu den Themen der linearen Algebra, der Analysis, 
der Wahrscheinlichkeitstheorie, der Logik und die F&#228;higkeit zum abstrakten Denken eine unerl&#228;ssliche
Voraussetzung. Au&#223;erdem spielt KI in vielen Gesellschaftsbereichen eine wichtige Rolle und Sch&#252;lerinnen und Sch&#252;ler
sollten im Unterricht f&#252;r ethische Fragen rund um KI sensibilisiert werden. 
Die Mathematikkenntnisse deutscher Sch&#252;lerinnen und Sch&#252;ler liegen im internationalen Vergleich lediglich im
Mittelfeld und unter denen der Nationen, die im Bereich KI f&#252;hrend sind. Die Studie TIMSS 2015 zeigte, dass
die Testleistungen in Deutschland signifikant unter denen in S&#252;dkorea, Japan und den USA lagen. Insbesondere
die so wichtige Spitzengruppe ist in Deutschland wesentlich schw&#228;cher als in den asiatischen L&#228;ndern.1462 Auch 
in der Studie PISA 2019 lag Deutschland deutlich hinter Japan und S&#252;dkorea.
In einigen Studien zur Studierf&#228;higkeit deutscher Abiturientinnen und Abiturienten1463 wird festgestellt, dass
Sch&#252;lerinnen und Sch&#252;ler h&#228;ufig nicht ausreichend auf die Anforderungen des Ingenieurs- oder
Informatikstudiums vorbereitet sind, insbesondere was die hohe Abstraktionsf&#228;higkeit und die mathematischen Anforderungen
der Studienf&#228;cher angeht.1464 
F&#252;r die Vermittlung eines generellen Verst&#228;ndnisses f&#252;r KI ist es erforderlich, dass das Thema KI in den
Lehrpl&#228;nen verankert wird. In der Schule kann KI als Teilgebiet der Informatik im Informatikunterricht in allen
Schularten behandelt werden, allerdings auch als Querschnittsthema in weiteren F&#228;chern. Zentral ist, das Thema
jahrgangsstufengerecht sowie f&#252;r Kinder und Jugendliche jedweden Geschlechts und aller sozio-&#246;konomischen
Hintergr&#252;nde zug&#228;nglich zu machen und p&#228;dagogisch sinnvoll einzubinden. Nur wer mitentwickelt, kann auch
effektiv mitbestimmen, wie eine Technologie eingesetzt wird. Hier gibt es schon erste Ans&#228;tze, das Thema KI in
den Unterricht zu integrieren: Lehrplankommissionen arbeiten an Konzepten zur Integration in den
Informatikunterricht und erste didaktische Materialien werden entwickelt. Damit alle Sch&#252;lerinnen und Sch&#252;ler von diesen
Neuerungen profitieren, sollte Informatik Pflichtfach in allen Bundesl&#228;ndern werden.
1459 Vgl. Hartong und F&#246;rschler (2019): Opening the black box of data-based school monitoring: Data infrastructures, flows and practices
in state education agencies.
1460 Darstellung Jan Renz (Hasso-Plattner-Institut) in der Sitzung der Projektgruppe KI und Arbeit, Bildung, Forschung am 16. Dezember
2019.
1461 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion der AfD vor [Sondervotum zu Kapitel 3.2.2, 5.2.4, 5.2.6 und 5.2.8.1 des
Berichts der Projektgruppe 4 &#8222;KI und Arbeit, Bildung, Forschung&#8220; (&#8222;Beispiele f&#252;r KI-Anwendungen in Schule und Hochschule&#8220;,
&#8222;Anforderungen an den Schulunterricht&#8220;, &#8222;KI und Hochschule&#8220;  und &#8222;Lehrkr&#228;ftebildung&#8220;) des sachverst&#228;ndigen Mitglieds Prof.
Dr. Boris Hollas sowie der Abgeordneten Joana Cotar, Peter Felser und Dr. Marc Jongen].
1462 In der Studie TIMSS 2015 stellten sich die Punktzahlen wie folgt dar: Singapur: 618, S&#252;dkorea 608, Japan 593, USA 539, OECD
528, Deutschland 522.
1463 Vgl. Hoffmann und Henry-Huthmacher (2016): Ausbildungsreife &amp; Studierf&#228;higkeit.
1464 Vgl. Kampa (2015): Mathematische Kompetenzen in Profiloberstufen in Schleswig-Holstein.
Lehrkr&#228;fte spielen nicht nur bei der Vermittlung des Themas KI, sondern auch beim Einsatz von KI-Technologien
in der Schule eine zentrale Rolle, da der Einsatz auch davon abh&#228;ngt, wie gerne und kompetent Lehrerinnen und
Lehrer mit diesen Technologien arbeiten. Voraussetzung hierf&#252;r ist, dass Schulen fl&#228;chendeckend &#252;ber eine gut
funktionierende und leistungsstarke digitale Infrastruktur verf&#252;gen, inklusive WLAN.1465 Mit dem DigitalPakt 
Schule unterst&#252;tzt der Bund die L&#228;nder und Kommunen bei Investitionen in die digitale Bildungsinfrastruktur
mit 5 Milliarden Euro. Ziel ist die Ausstattung der Schulen mit einer zeitgem&#228;&#223;en digitalen Technik. Damit
Schultr&#228;ger Mittel erhalten k&#246;nnen, ist die Ausarbeitung p&#228;dagogischer Konzepte f&#252;r die digitale Bildung
erforderlich. Diese Konzepte sollten ein besonderes Augenmerk darauf legen, Unterricht so zu gestalten, dass der
Einsatz von KI erm&#246;glicht wird.
Lehrenden kann das Lernen beziehungsweise Lehren mit KI Freir&#228;ume schaffen, um individuell auf die
Lernprozesse einzelner Sch&#252;lerinnen und Sch&#252;ler einzugehen. Beim Unterricht mit KI-gest&#252;tzten Medien k&#246;nnen
Lehrerinnen und Lehrer mehr auf die unterschiedlichen St&#228;rken und Lernst&#228;nde der Lernenden eingehen. Durch
Freir&#228;ume haben sie zudem mehr Zeit f&#252;r die Vermittlung sozialer Kompetenzen und zwischenmenschlicher
Verhaltensregeln, die Bildungsforscherinnen und Bildungsforscher als emotionale Bildung bezeichnen.
Lehrerinnen und Lehrer k&#246;nnen durch den Einsatz von KI-Systemen st&#228;rker zu Regisseuren und Lernbegleitern
werden. KI erweitert ihnen den Raum f&#252;r Kreativit&#228;t und neue Unterrichtsmethoden (als Erg&#228;nzung zum klassischen
Frontalunterricht). Wird KI im Unterricht richtig angewandt, kann die Motivation von Lernenden gesteigert
werden und es lassen sich schnellere, aber auch nachhaltigere Lernerfolge erzielen. Hilfreich sind beispielsweise KI-
basierte Schulb&#252;cher. Intelligente Tutorsysteme k&#246;nnen der Lehrkraft helfen, sich einen &#220;berblick zu
verschaffen, welche Aufmerksamkeit bestimmte Lernende ben&#246;tigen. So kann die Lehrkraft sich besser auf diese
Bed&#252;rfnisse einstellen. Es geht dabei nicht darum, Lehrkr&#228;fte zu ersetzen, sondern sie wieder von reagierenden zu
agierenden Playern zu entwickeln. Denn Lehre ist mehr als nur kognitives Training. Sie erfordert immer auch soziale
Kompetenzen wie Empathie. Somit m&#252;ssen Lehrkr&#228;fte und KI-basierte Tutoren immer in Kombination gedacht
werden. 
Weitere Forschung muss sich der Fragestellung widmen, wie Lehrkr&#228;fte mit systembasierten Vorschl&#228;gen
umgehen, um verifizierte Vorteile von KI-Systemen in der Bildung nutzen zu k&#246;nnen. Es muss sichergestellt werden, 
dass sich der Ermessensspielraum der Lehrkr&#228;fte nicht reduziert &#8211; denn wie auch andere in Arbeitsverh&#228;ltnissen
abh&#228;ngige Nutzerinnen und Nutzer von KI-Systemen kann es auch f&#252;r Lehrkr&#228;fte enorm schwierig sein, sich 
gegen einen systembasierten Vorschlag zu stellen. Daten-Dashboards, die Daten zusammenfassen und
visualisieren (z. B. durch Ampelsysteme) wirken also m&#246;glicherweise nur auf den ersten Blick entlastend. Systeme,
Daten und Modelle sind nie neutral,1466 sondern bilden immer Intentionen ab, schaffen Wirklichkeiten und
steuern damit Verhalten, ohne dass die Verfahrensweisen dieser Systeme f&#252;r Lehrkr&#228;fte transparent w&#228;ren.1467
Lehrkr&#228;ften sollen durch den Einsatz von KI-Systemen zeitliche Freir&#228;ume bei der Leistungsbewertung entstehen,
gleichzeitig sollen ihre Freir&#228;ume bei der qualitativen und ganzheitlichen p&#228;dagogischen Bewertung der
Lernleistung erhalten bleiben. 
Sch&#252;lerinnen und Sch&#252;ler k&#246;nnen beim Lernen mit KI ihre Interessen anders ausleben und dabei n&#246;tige
Erfahrungen sammeln. Sie k&#246;nnen mehr eigenen Anteil am Lernen nehmen, auch weil sich die Beziehung zwischen
Lernenden und Lehrenden durch KI-unterst&#252;tztes Lernen &#228;ndern wird. Dies betrifft insbesondere auch die soziale
Inklusion f&#252;r z. B. sehbehinderte oder motorisch eingeschr&#228;nkte Sch&#252;lerinnen und Sch&#252;ler oder Migrantinnen
und Migranten.1468 
Lerndaten werden jedoch nicht nur in der Schule erhoben und verarbeitet, sondern k&#246;nnen auch auf kommunaler
Ebene in Schulbeh&#246;rden zusammengef&#252;hrt und analysiert werden. F&#252;r diesen Fall m&#252;ssen auch hier die
Anforderungen gelten, die f&#252;r den Einsatz von KI-Systemen an anderen Beh&#246;rden angelegt sind.1469 
1465 Aktuell verf&#252;gen nur 36 Prozent der Schulen &#252;ber schnelles Internet und eine zufriedenstellende WLAN-Infrastruktur, vgl. Statista
(2019): Ist an Ihrer Schule in allen Klassen- und Fachr&#228;umen ein Zugang zu schnellem Internet und WLAN verf&#252;gbar?
1466 Handlungsempfehlungen von Dr. Sigrid Hartong (Helmut-Schmidt-Universit&#228;t Hamburg), Projektgruppendrucksache 19(27)PG 4-
48 vom 12. Januar 2020; Hartong (2019): Learning Analytics und Big Data in der Bildung.
1467 Handlungsempfehlungen von Dr. Sigrid Hartong (Helmut-Schmidt-Universit&#228;t Hamburg), Projektgruppendrucksache 19(27)PG 4-
48 vom 12. Januar 2020; Hartong (2019): Learning Analytics und Big Data in der Bildung.
1468 Beispiele, die die soziale Inklusion unterst&#252;tzen, sind u. a. Vorlesesysteme oder die automatische Umsetzung des gesprochenen
Wortes in Geb&#228;rdensprache, Virtual Reality, Robotiksysteme und die maschinelle &#220;bersetzung in Fremdsprachen.
1469 Siehe auch den Bericht der Projektgruppe &#8222;KI und Staat&#8220; in Kapitel C. III. [K&#252;nstliche Intelligenz und Staat (Projektgruppe 2)].
5.2.5 Lehrkr&#228;ftebildung
Lehrerinnen und Lehrer m&#252;ssen in der Lage sein, ein generelles Verst&#228;ndnis f&#252;r KI bzw. Wissen &#252;ber KI und 
deren (Weiter-)Entwicklung zu vermitteln. Dies erfordert, dass Lehrende hierf&#252;r entsprechend aus- und
weitergebildet werden. Besonders Informatiklehrkr&#228;fte verf&#252;gen bereits &#252;ber einen methodischen Hintergrund, der f&#252;r
die Aus- und Fortbildung im Bereich KI sehr n&#252;tzlich sein kann. An dieser Stelle muss zwischen Lehrkr&#228;ften der
MINT-F&#228;cher und allen anderen Lehrkr&#228;ften unterschieden werden. Lehrkr&#228;fte der MINT-F&#228;cher sollten
mindestens &#252;ber Basiskenntnisse im Programmieren verf&#252;gen. Allgemeine KI-Kompetenzen, wie ein Verst&#228;ndnis
der kreativen Formen des algorithmischen Denkens und der Anwendung von KI als Hilfsmittel in allen
Schulf&#228;chern1470, sollten Teil der Digitalkompetenz aller Lehrkr&#228;fte sein. Letztlich kommt es auf die Interdisziplinarit&#228;t
zwischen allen Schulf&#228;chern und der Zusammenarbeit aller Lehrkr&#228;fte an. Das Angebot muss zeitlich und
r&#228;umlich gut zug&#228;nglich sein und es muss relevante Inhalte zu Risiken der Systeme oder auch IT-Sicherheit
ausreichend behandeln.
In der Lehrkr&#228;fteaus- und -fortbildung kommt es darauf an, die F&#228;higkeit zur Gestaltung von Lernprozessen zu
vermitteln sowie die Sch&#252;lerinnen und Sch&#252;ler sowie Auszubildenden dazu zu bef&#228;higen, selbstbestimmt an
einem zunehmend durch neue Medien vermittelten Lebens- und Entwicklungsprozess teilzuhaben. F&#252;r Lehrende
ist entsprechend im Bereich KI eine zweistufige Kompetenz notwendig: Zun&#228;chst ist die eigene KI-Kompetenz
ein grundlegender Baustein. Hierzu geh&#246;rt zum einen das theoretische Wissen &#252;ber die Funktionsweise von KI
als auch das Know-how, mit digitalen Technologien sicher, reflektiert und selbstbewusst umzugehen. Weiterhin 
elementar ist die entsprechende p&#228;dagogische Vermittlungskompetenz. Zudem sollte KI nicht nur technisch
behandelt werden, sondern auch ihre ethischen und gesellschaftlichen Fragestellungen sollten im Unterricht
besprochen werden. Lehrkr&#228;fte brauchen sowohl in der Ausbildung als auch berufsbegleitend regelm&#228;&#223;ig
Schulungen, um selbstst&#228;ndig mit den Bedingungen umgehen zu k&#246;nnen, die durch KI entstanden sind und sich weiterhin
regelm&#228;&#223;ig ver&#228;ndern.
5.2.6 KI und Hochschule1471 
KI in der Hochschulbildung ist zwar ein bisher noch relativ wenig erforschtes Gebiet, weckt gleichzeitig aber
gro&#223;e Erwartungen an eine verbesserte Qualit&#228;t von Lernen und Lehre.1472 Entsprechend gibt es bez&#252;glich KI an
der Hochschule zwei Herausforderungen: den Einsatz von KI in der Lehre und die Gewinnung bzw. Ausbildung
herausragender KI-Wissenschaftlerinnen und -Wissenschaftler f&#252;r den Standort Deutschland. Um nicht
abgeh&#228;ngt zu werden, braucht Deutschland Expertinnen und Experten in Wissenschaft und Forschung. Um Fachkr&#228;fte
zu gewinnen, hat Deutschland zwei M&#246;glichkeiten: selbst auszubilden oder Fachkr&#228;fte aus anderen L&#228;ndern
anzuwerben. Um erfolgreich zu sein, m&#252;ssen beide Wege gegangen werden und es muss die Attraktivit&#228;t
Deutschlands als Forschungs- und Arbeitsstandort f&#252;r ausgewiesene KI-Expertinnen und -Experten erh&#246;ht werden. Es
braucht Regelungen zur Fachkr&#228;ftezuwanderung, die den Schwerpunkt Forschung und Wissenschaft
ber&#252;cksichtigen. Gleichzeitig sollte die Attraktivit&#228;t des Forschungsstandorts Deutschland weiter erh&#246;ht werden, etwa durch
innovative Forschungsprojekte, gute Arbeitsbedingungen und eine offene Gesellschaft.
KI ist nicht einfach Informatik oder Maschinenbau, sondern bedarf auch der Gebiete
Gesellschaftswissenschaften, Jura und Philosophie. Deutschland braucht hinreichend viele herausragende Wissenschaftlerinnen und
Wissenschaftler an den Hochschulen, die in speziellen KI-Studieng&#228;ngen lehren und forschen. Es ist wichtig, im
Bereich KI interdisziplin&#228;r zusammenzuarbeiten und die gesellschaftlichen Implikationen von KI bereits von
Anfang an in den Entwicklungsprozess einzubeziehen. Um diesen Kern herum wird ein Umfeld f&#252;r
Nachwuchsforscherinnen und Nachwuchsforscher geschaffen. Deutschland braucht mehr KI-Professuren und -Studieng&#228;nge
an den Hochschulen. Darum ist es gut, dass die Bundesregierung im Rahmen ihrer KI-Strategie mit mindestens
1470 Z. B. kann KI als Hilfsmittel angewendet werden, um Wetter-Simulationen in der Geografie voranzutreiben, virtuelle Realit&#228;ten f&#252;r
den Geschichtsunterricht zu schaffen, Korpusrecherchen in Deutsch und Fremdsprachen durchzuf&#252;hren etc.
1471 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion der AfD vor [Sondervotum zu Kapitel 3.2.2, 5.2.4, 5.2.6 und 5.2.8.1 des
Berichts der Projektgruppe 4 &#8222;KI und Arbeit, Bildung, Forschung&#8220; (&#8222;Beispiele f&#252;r KI-Anwendungen in Schule und Hochschule&#8220;,
&#8222;Anforderungen an den Schulunterricht&#8220;, &#8222;KI und Hochschule&#8220;  und &#8222;Lehrkr&#228;ftebildung&#8220;) des sachverst&#228;ndigen Mitglieds Prof.
Dr. Boris Hollas sowie der Abgeordneten Joana Cotar, Peter Felser und Dr. Marc Jongen].
1472 Im Rahmen der Digitalen Hochschulbildung f&#246;rdert das BMBF derzeit bereits Forschungsvorhaben, die die Potenziale untersuchen 
und die Hochschullandschaft mit belastbarem Handlungswissen versorgen sollen, weitere Informationen dazu unter https://hoch-
schulforumdigitalisierung.de (zuletzt abgerufen am 7. Oktober 2020). Im Jahr 2020 wurde zudem eine neue F&#246;rderrichtlinie auf den 
Weg gebracht &#8222;Innovationen in der Hochschulbildung durch K&#252;nstliche Intelligenz und Big Data&#8220;, die noch einmal ganz explizit
Projektideen in diesem Bereich f&#246;rdern soll, vgl. Bundesministerium f&#252;r Bildung und Forschung (2020): Bekanntmachung. Richtlinie
zur F&#246;rderung von Zuwendungen f&#252;r die Forschung zur digitalen Hochschulbildung - Innovationen in der Hochschulbildung durch
K&#252;nstliche Intelligenz und Big Data.
100 zus&#228;tzlichen neuen Professuren eine breite Verankerung der KI an Hochschulen absichern will.1473 Dabei
werden zum einen &#252;ber die Alexander von Humboldt-Stiftung Expertinnen und Experten aus dem Ausland
angeworben und zum anderen Lehrst&#252;hle f&#252;r Expertinnen und Experten aus dem Inland geschaffen. 
Denkbar sind auch KI-Anwendungen zu Literatur-Recherche und Analyse von Mustererkennung in gro&#223;en
Forschungsdatens&#228;tzen. Bedenklich sind hingegen fr&#252;he, rein automatisierte Prognose-Anwendungen zur
Vorhersage von Studienabbrecherinnen und Studienabbrechern, wie sie am KIT eingesetzt werden.1474 Hierbei wird
bereits nach einem Semester eine Wahrscheinlichkeit ermittelt, ob das Studium abgebrochen wird. Es muss
sichergestellt sein, dass nicht zu fr&#252;h und allein aufgrund von Datenanalysen in die Lebensplanung von jungen
Menschen eingegriffen wird. Ist ein Studienabbruch wahrscheinlich, muss in enger individueller Betreuung
Hilfestellung gegeben werden, um Demotivation und Diskriminierung zu verhindern, aber auch um sinnvolle,
gegebenenfalls alternative Wege f&#252;r das weitere Studium beziehungsweise die weitere Ausbildung gemeinsam zu
erarbeiten. Studienleistungen sind jedoch wie Lernleistungen an Schulen auch zur&#252;ckzuf&#252;hren auf soziale und
psychische Ursachen, die nicht ohne Weiteres diskriminierungsfrei zu operationalisieren sind und die durch eine
zu fr&#252;he Einsch&#228;tzung negativ beeintr&#228;chtigt werden k&#246;nnen, zumal wenn das KI-System diese Einsch&#228;tzungen
nicht transparent und nachvollziehbar trifft. Eine begleitende und motivierende Einsch&#228;tzung von menschlichen
Entscheiderinnen und Entscheidern muss stets gew&#228;hrleistet sein. Au&#223;erdem k&#246;nnen solche Systeme eher
anpassende Verhaltensweisen anstelle von Entfaltung und Autonomie im Humboldt&#8127;schen Sinne bef&#246;rdern. In jedem
Fall setzt die DSGVO Hochschulen hierf&#252;r enge Grenzen.1475 
Wird KI als Werkzeug zur Forschung eingesetzt, kann dies das Forschen erleichtern, jedoch kann auch das Risiko
entstehen, dass Forschungsergebnisse nicht mehr nachvollziehbar und reproduzierbar sind.1476 Dem kann durch
rechtzeitige Entwicklung von Richtlinien zur Nachvollziehbarkeit von KI-Systemen in der Forschung begegnet
werden, um die &#8222;Standards guter Forschung&#8220;1477 zur Dokumentation einzuhalten.
5.2.7 KI in Aus- und Weiterbildung 
Im Bereich Aus- und Weiterbildung1478 steht die Entwicklung von und die Arbeit mit KI-L&#246;sungen im
Vordergrund. Maschinelles Lernen spielt dabei eine zentrale Rolle. Dies zeigt sich beispielsweise auch darin, dass die
F&#246;rderung von Qualifizierungsma&#223;nahmen im Bereich Maschinelles Lernen des BMBF sehr gut nachgefragt
wird. Bei der Anwendung des Maschinellen Lernens ist ein Verst&#228;ndnis f&#252;r Daten und deren Qualit&#228;t elementar.
Ein vermehrt digitalisierter und mit KI ausgestatteter Arbeitsplatz verlangt, dass die Besch&#228;ftigten gr&#246;&#223;ere
Kompetenzen im Bereich der Soft Skills ausbilden: kritisches Denken und das Erhalten von Entscheidungskompetenz
in Zeiten, in denen immer mehr Empfehlungen von &#8222;Maschinen&#8220; ausgesprochen werden,
Probleml&#246;sungskompetenz, Kreativit&#228;t, selbstorganisiertes Arbeiten, Neugier, Umgang mit digitalen Medien, soziale Verantwortung 
usw. &#8211; diese F&#228;higkeiten m&#252;ssen zielgerichtet und strukturiert entwickelt und gef&#246;rdert werden (in der Schule,
in Ausbildung/Studium und in Weiterbildungen; Stichwort: lebenslanges Lernen).
KI und Ausbildung
Kenntnisse &#252;ber und praktische F&#228;higkeiten bei der Anwendung von KI-Verfahren k&#246;nnen auch in
Ausbildungsberufen vermittelt werden. Beruflich ausgebildete Datenanalystinnen und -analysten k&#246;nnen akademische
Datenwissenschaftlerinnen und -wissenschaftler bei vorbereitenden Aufgaben unterst&#252;tzen, die in der KI reichlich 
anfallen und deren Erledigung nicht hochkomplex, aber gleichsam wichtig und zeitintensiv ist. Dadurch k&#246;nnen
die Hochschulen entlastet, Ausbildungszeiten verk&#252;rzt und das Angebot an KI-Fachleuten erh&#246;ht werden. Auch
hier sind unzureichende Mathematikkenntnisse der Auszubildenden ein Hindernis f&#252;r den Ausbildungserfolg.1479 
Wesentlich sind jedoch auch Ma&#223;nahmen zur Ausbildung im Bereich der Anwendung von KI-L&#246;sungen.
Mitarbeiterinnen und Mitarbeiter m&#252;ssen geschult werden, wie die L&#246;sungen zu handhaben sind, wie die
Empfehlungen einer KI-L&#246;sung &#8211; die nicht deterministisch, also richtig oder falsch sind, sondern auf Wahrscheinlichkeiten
1473 Vgl. Kapitel 9 des Mantelberichts [KI und Forschung].
1474 Vgl. Weiss (2018): Wie ein Algorithmus Studienabbrecher fr&#252;hzeitig erkennt.
1475 Vgl. Martini et al. (2020): Automatisch erlaubt?
1476 Vgl. Schwan (2019): Wirbel um Reproduzierbarkeitskrise durch KI.
1477 Deutsche Forschungsgemeinschaft (2019): Leitlinien zur Sicherung guter wissenschaftlicher Praxis.
1478 Vgl. auch die Arbeit der Enquete-Kommission &#8222;Berufliche Bildung in der digitalen Arbeitswelt&#8220;.
1479 Vgl. Borstel und Wisdorff (2014): Mangelnde Reife bei Azubis; Knau&#223; (2019): Mittelstandspr&#228;sident Ohoven &#8222;Viele Bewerber
beherrschen nicht einmal die Grundrechenarten&#8220;.
beruhen &#8211; einzuordnen sind und wie sie in die bestehenden Gesch&#228;ftsprozesse und betrieblichen Abl&#228;ufe zu
integrieren sind.
KI und Weiterbildung
Im Weiterbildungssektor sollte nicht nur das Thema &#8222;Lernen &#252;ber KI&#8220; vermittelt werden, KI selbst kann in der
Weiterbildung einen gro&#223;en Mehrwert bringen. Durch den Einsatz von KI k&#246;nnen passgenaue
Weiterbildungsangebote erstellt werden, die auf das Berufsprofil einer oder eines Lernenden eingestellt sind. Insbesondere bei
der Vermittlung von KI-Kenntnissen sollten Weiterbildungsangebote auf einen &#8222;Blended Learning&#8220;-Ansatz, eine
Kombination von Online- und Pr&#228;senzformaten, abzielen, da der Umgang mit intelligenter Technologie am
besten &#8222;on the job&#8220;, also durch Lernen &#252;ber Erfahrungen, zu vermitteln ist.
Auch bei der Organisation und der Auswahl von Weiterbildungsprogrammen kann KI eingesetzt werden.
Einerseits kann mithilfe von KI ein individueller Vorschlag f&#252;r eine Mitarbeiterin oder einen Mitarbeiter gemacht
werden, der ihren bzw. seinen aktuellen Kompetenzen und Aufgaben im Beruf entspricht; es findet eine
individuelle Ansprache statt. Andererseits ist es aber auch m&#246;glich, die Weiterbildungsprogramme mithilfe von KI 
zentral vorzusortieren. Besch&#228;ftigte bekommen also nicht ein breites Angebot, sondern nur eine bestimmte
Auswahl, die auf das firmenspezifische Interesse ausgerichtet ist. Eine solche enge Spezialisierung kann allerdings
auch das Abh&#228;ngigkeitsverh&#228;ltnis der Mitarbeiterin oder des Mitarbeiters gegen&#252;ber dem Unternehmen
verst&#228;rken und die Besch&#228;ftigungsf&#228;higkeit vermindern. Daf&#252;r steigt aber auch ihre Bedeutung f&#252;r den Arbeitgeber. 
Ein weiterer Aspekt sind Informationsangebote f&#252;r die Gesamtbev&#246;lkerung. Um die Chancen und Risiken der
Anwendung von KI-L&#246;sungen einsch&#228;tzen zu k&#246;nnen, sollte die Bev&#246;lkerung die M&#246;glichkeit erhalten,
grundlegende Kenntnisse zu KI und deren Anwendung zu erlangen. Dies ist essenziell, um einen zielf&#252;hrenden und
&#8222;informierten&#8220; &#246;ffentlichen Diskurs zu f&#252;hren.
5.2.8 Handlungsempfehlungen
Lernen ist als sozialer Prozess zu verstehen, der auf der Interaktion von Lehrenden und Lernenden beruht und
nicht nur das Ziel hat, Normen zu erf&#252;llen, sondern auch selbstst&#228;ndig Probleml&#246;sungen zu entdecken und
dar&#252;ber die eigene Pers&#246;nlichkeit zu entwickeln. Um KI in Lernprozessen p&#228;dagogisch sinnvoll einzusetzen, sollte
noch mehr erforscht werden, wie KI-Systeme auf Lernende und Lehrende wirken und wie sie diese dabei
unterst&#252;tzen k&#246;nnen, p&#228;dagogische Ziele (u. a. Inklusion) zu erreichen. Bei der Einf&#252;hrung von KI-Systemen und der
zugeh&#246;rigen Dateninfrastrukturen ist eine medienp&#228;dagogische Prozessbegleitung zur Verf&#252;gung zu stellen.
Grunds&#228;tzlich ist festzuhalten &#8211; das best&#228;tigt der im Juni 2020 ver&#246;ffentlichte nationalen Bildungsbericht
&#8222;Bildung in Deutschland 2020&#8220; &#8211;, dass digitale Kompetenzen bei Sch&#252;lerinnen und Sch&#252;lern &#8222;ausbauf&#228;hig&#8220; sind und 
es bei dem Einsatz digitaler Medien (wie auch von KI) im Unterricht auf einen didaktisch sinnvollen und kritisch
reflektierten Umgang ankommt. Entscheidend ist nicht die eingesetzte Technik, sondern wie Lehrende digitale
Medien in das allt&#228;gliche Lehr&#8208;Lern&#8208;Geschehen integrieren.1480 
5.2.8.1 Lehrkr&#228;ftebildung1481 
KI, aber auch die Grundlagen daf&#252;r, wie z. B. Mathematik, abstraktes Denken, Verst&#228;ndnis f&#252;r gesellschaftliche
Auswirkungen, m&#252;ssen in die Lehrpl&#228;ne aller Schularten Eingang finden bzw. in ausreichendem Umfang erhalten
bleiben. Zudem sollte Informatik als Pflichtfach in den Lehrpl&#228;nen verankert werden. An den Oberstufen in allen
Bundesl&#228;ndern sollten sich die Lehrinhalte im Fach Mathematik an den Anforderungen der Hochschulen
ausrichten. Abiturientinnen und Abiturienten m&#252;ssen die f&#252;r das Studium der Informatik notwendigen
mathematischen Grundlagen beherrschen. Durch die Lehrpl&#228;ne der Sekundarstufe 1 muss gew&#228;hrleistet sein, dass
erforderliche mathematische Kenntnisse f&#252;r bestehende duale Ausbildungsberufe wie &#8222;Fachinformatikerinnen und
Fachinformatiker&#8220; und &#8222;Mathematisch-technische-Softwareentwicklerinnen und -entwickler&#8220; oder f&#252;r die
Themen Datenanalyse und maschinelle Lernverfahren vermittelt werden, die in bestehende Ausbildungsberufe
integriert oder durch die Schaffung neuer Ausbildungsberufe ber&#252;cksichtigt werden sollten. Die
Kultusministerkonferenz sollte daf&#252;r sorgen, dass durch &#252;berpr&#252;fbare und l&#228;nder&#252;bergreifende Standards die Qualit&#228;t der Lehre im
1480 Zu den Ergebnissen des nationalen Bildungsberichts, vgl. Autorengruppe Bildungsberichterstattung (2020): Bildung in Deutschland 2020.
1481 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion der AfD vor [Sondervotum zu Kapitel 3.2.2, 5.2.4, 5.2.6 und 5.2.8.1 des
Berichts der Projektgruppe 4 &#8222;KI und Arbeit, Bildung, Forschung&#8220; (&#8222;Beispiele f&#252;r KI-Anwendungen in Schule und Hochschule&#8220;,
&#8222;Anforderungen an den Schulunterricht&#8220;, &#8222;KI und Hochschule&#8220;  und &#8222;Lehrkr&#228;ftebildung&#8220;) des sachverst&#228;ndigen Mitglieds Prof.
Dr. Boris Hollas sowie der Abgeordneten Joana Cotar, Peter Felser und Dr. Marc Jongen].
Bereich KI sichergestellt wird. Leuchtturm- und Pilotprojekte f&#252;r den Einsatz von KI in der Schule sollten in die
Breite getragen werden, um Synergieeffekte zu nutzen.
Kompetenzen in den Bereichen KI und Algorithmik sollten jahrgangsstufengerecht sowohl im Fach Informatik
als auch als Querschnittsthema im gesamten F&#228;cherkanon aufgenommen werden. Neben technisch orientierten
KI-Kompetenzen sowie der F&#228;higkeit, KI-L&#246;sungen anzuwenden, sollte in allen Schulformen sowie in der
beruflichen Aus- und Weiterbildung ein Augenmerk auf die Soft Skills, wie kritisches Denken und
Entscheidungsf&#228;higkeit, sowie ein Bewusstsein f&#252;r philosophische Fragestellungen und gesellschaftliche Herausforderungen
durch KI gelegt werden. Dies sind &#8211; insbesondere aufgrund der immer weitreichenderen Durchdringung aller
Lebensbereiche durch digitale und KI-Hilfsmittel &#8211; unabdingbare Kompetenzen. Sch&#252;lerinnen und Sch&#252;ler
sollten so im Rahmen eines ganzheitlichen Ansatzes in die Lage versetzt werden, auch ihr eigenes Nutzungsverhalten
zu reflektieren. Um dies zu erm&#246;glichen und umzusetzen, sollte ein gemeinsamer, l&#228;nder&#252;bergreifender Standard
durch die Kultusministerkonferenz erarbeitet werden.  
Jede Institution und damit auch jede Schule ben&#246;tigt Ressourcen, um einen passenden Umgang mit
datenbasierten Technologien, wie KI, zu entwickeln. Am besten gelingt das in einem demokratisch verfassten Rahmen.
Durch ein solches selbstbestimmtes Verfahren k&#246;nnen Vertrauen und Selbstbewusstsein wachsen. Optimal ist
eine medienp&#228;dagogische Begleitung eines solchen Prozesses. Entsprechende Kompetenzen zu
Medienp&#228;dagogik und demokratischen Ans&#228;tzen sollten in den Studieng&#228;ngen vermittelt werden und es sollten Strukturen
aufgebaut werden, die den Schulen zur Verf&#252;gung stehen, wie dies in der Vergangenheit beispielsweise
Landesfilmdienste getan haben.
Bestehende Ungleichgewichte, die zwischen M&#228;dchen und Jungen beziehungsweise Frauen und M&#228;nnern im
Hinblick auf das Wissen &#252;ber und die Anwendung von KI bestehen, sollen ausgeglichen werden. Dazu k&#246;nnen
sowohl Schulen als auch Hochschulen Angebote entwickeln, die M&#228;dchen und junge Frauen f&#252;r Informatik und 
KI interessieren und ihnen Gestaltungsm&#246;glichkeiten mitgeben. Lehrkr&#228;fte sollen daf&#252;r in ihrer Ausbildung
sensibilisiert werden. Hochschulen sollen die M&#246;glichkeiten von spezifischen Angeboten f&#252;r M&#228;dchen und Jungen
innerhalb von Informatikstudieng&#228;ngen pr&#252;fen.
Lehrkr&#228;fteaus-, -fort- und -weiterbildung in allen drei Phasen der Lehrkr&#228;ftebildung muss verpflichtend digitale
Kompetenzen mit KI-Inhalten verkn&#252;pfen und stets p&#228;dagogisch eingebettet werden. Digitalkompetenzen
m&#252;ssen in der ersten Phase der Lehrkr&#228;fte-Ausbildung verpflichtend sein und in der zweiten und dritten Phase in die
Weiterbildungsf&#246;rderprogramme der L&#228;nder aufgenommen werden, um die Basis f&#252;r einen p&#228;dagogisch
wertvollen und informierten Einsatz von KI-Systemen zu legen. In der Lehrkr&#228;ftebildung sollten Bildungswerkzeuge
vermittelt werden, mithilfe derer die H&#252;rden f&#252;r M&#228;dchen und junge Frauen in technischen F&#228;chern abgebaut
werden k&#246;nnen. Damit ein hoher Qualit&#228;tsstandard sichergestellt ist, muss gew&#228;hrleistet sein, dass die Kriterien 
und Ma&#223;nahmen in der Lehrkr&#228;fteaus- und -weiterbildung bundesweit einheitlichen, &#252;berpr&#252;fbaren Standards
folgen. Die Verantwortung f&#252;r die inhaltliche und organisatorische Aus&#8208;, Fort&#8208; und Weiterbildung von
Lehrerinnen und Lehrern liegt in der Zust&#228;ndigkeit der L&#228;nder.1482 
Bund und L&#228;nder sollten gemeinsam eine nachhaltige und anbieterunabh&#228;ngige Beschaffungspraxis f&#252;r KI-
Systeme zur Analyse von Lehr- und Lernmitteln sowie Lehr- und Lernmethoden etablieren, um den Standards
offener Bildung, wie Open Educational Resources (OER) und Open Educational Data (OED)1483, gerecht zu werden,
sofern sie keine personenbezogenen Daten sind oder enthalten. Aufgrund der schnellen digitalen Entwicklung
sollten KI-basierte Lehr- und Lernmittelangebote nicht allein von gro&#223;en Verlagen zur Verf&#252;gung gestellt werden
k&#246;nnen, sondern beispielsweise auch von sogenannten EdTech-Start-ups. In diesem Zusammenhang m&#252;ssen
auch die hohen Zugangsh&#252;rden bei &#246;ffentlichen Ausschreibungen kritisch in den Blick genommen werden, die
in der Praxis gerade von Start-ups kaum &#252;berwunden werden k&#246;nnen.
5.2.8.2 Aus- und Weiterbildung
Im Bereich Aus- und Weiterbildung m&#252;ssen Bildungsangebote geschaffen werden, die die KI-Kompetenz der
Erwerbst&#228;tigen f&#246;rdern. Diese Fortbildungsangebote sollten einheitliche Standards erf&#252;llen. Hierf&#252;r w&#228;re es
sinnvoll, wenn Fortbildungsmodule gemeinsam mit Hochschulen und Fachvertreterinnen und -vertretern entwickelt
w&#252;rden. Diese Angebote k&#246;nnen von Betrieben, Volkshochschulen, IHK und privaten Anbietern genutzt bzw.
1482 Der Bund unterst&#252;tzt die L&#228;nder mit der &#8222;Qualit&#228;tsoffensive Lehrerbildung&#8220;, f&#252;r die der Bund bis Ende 2023 bis zu 500 Millionen 
Euro zur Verf&#252;gung stellt. Bis Ende 2023 werden 91 Einzel&#8208; und Verbundvorhaben unter Einbeziehung von 72 lehramtsausbildenden 
Hochschulen in ganz Deutschland gef&#246;rdert, weitere Informationen dazu unter: https://www.bmbf.de/de/qualitaetsoffensive-lehrer-
bildung-525.html (zuletzt abgerufen am 9. September 2020).
1483 Vgl. European Data Portal (2019): Open education data on the European Data Portal.
angeboten werden. Durch die schnelle Entwicklung von Innovationen im KI-Bereich m&#252;ssen
Weiterbildungsangebote so gestaltet werden, dass sie flexibel, schnell und b&#252;rokratiearm und modular angepasst werden k&#246;nnen.
Die St&#228;rkung der betrieblichen Weiterbildung ist zentral, um das durch KI immer wichtiger werdende
lebenslange Lernen zu erm&#246;glichen. Dem Mismatch-Problem, das hei&#223;t dem gleichzeitigen Vorhandensein von
Jobverlusten und Fachkr&#228;ftemangel auf dem Arbeitsmarkt, ist nur durch einen sp&#252;rbaren Ausbau einer
funktionierenden Wissensinfrastruktur zu begegnen. Es sind massive Investitionen in den Bildungssektor in all seinen
Facetten erforderlich. Ein besonderes Gewicht muss dabei auf dem Bereich der beruflichen Weiterbildung
liegen.1484 In Bezug auf den Wandel am Arbeitsmarkt wirken sich vor allem F&#228;higkeiten jenseits der Erstausbildung 
und F&#252;hrungsqualit&#228;ten positiv aus.1485 Die Weiterbildungspolitik sollte dabei &#8211; im Sinne von Finanzierung,
Beratung und Organisation &#8211; auf Augenh&#246;he mit der Erstausbildungspolitik liegen und entsprechende Anreize in
Bezug auf die er&#246;ffneten Karrierewege und die Eingruppierung/Entlohnung von T&#228;tigkeiten beinhalten. Ein
formaler Qualifikationsrahmen ist und bleibt wichtig, n&#252;tzlich und effektiv. Er muss allerdings mit flexiblem
Kompetenzerwerb und einer flexiblen Anerkennung von Qualifikationen verbunden werden.
Aus- und Weiterbildungssysteme m&#252;ssen flexibler als heute reagieren und sich vor allem st&#228;rker auf
Geringqualifizierte und &#196;ltere fokussieren. Aber auch Personen aus bestehenden Branchen, die beispielsweise eine
technische Ausbildung oder einen Ingenieurshintergrund haben, m&#252;ssen passgenaue Angebote erhalten, um sich stetig
weiterzubilden und weiterentwickeln zu k&#246;nnen. Weiterbildung ist als bildungspolitische Aufgabe zu verstehen,
nicht als Krisenmanagement. Sie muss st&#228;ndig und grunds&#228;tzlich passieren, nicht allein in krisengeplagten
Branchen oder Bereichen.
Die Personalr&#228;te sollen bei der Auswahl der Weiterbildungsangebote ein Mitbestimmungsrecht erhalten.
Besch&#228;ftigte und ihre Interessenvertretungen sollen der steigenden Bedeutung der Personalplanung und -
entwicklung sowie der Qualifizierung von Besch&#228;ftigten Rechnung tragen k&#246;nnen, indem sie ein Mitbestimmungs- und 
Initiativrecht in Fragen der Weiterbildung erhalten. Die Mitbestimmung ist wichtig, damit die Programme die
Besch&#228;ftigungsf&#228;higkeit der Mitarbeiterinnen und Mitarbeiter vergr&#246;&#223;ern und nicht zu einer firmenspezifischen 
Abh&#228;ngigkeit f&#252;hren. Dar&#252;ber hinaus sollten sie einen einfachen Zugang zu Weiterbildungs- und
Beratungsangeboten haben, um die eigene KI-Kompetenz auszubauen; gerade f&#252;r eine ad&#228;quate Folgenabsch&#228;tzung ist ein
einfacher Zugang zu externem Expertenwissen notwendig. Zu pr&#252;fen w&#228;re hier der Auf- und Ausbau von
staatlich gef&#246;rderten Technologieberatungsstellen.
Berufliche Weiterbildung ist eine bildungspolitische Aufgabe und sie muss allen Menschen zug&#228;nglich sein. Die 
Politik sollte die Weiterbildungsaktivit&#228;ten unterst&#252;tzen, vor allem durch eine unabh&#228;ngige, hochwertige
Qualifizierungsberatung f&#252;r Betriebe, Besch&#228;ftigte und Erwerbslose.
Im Hinblick auf die Kosten der Weiterbildung h&#228;lt die Projektgruppe die Empfehlung f&#252;r wichtig, dass
Weiterbildung so zu organisieren ist, &#8222;dass nicht die Besch&#228;ftigten alleine die Kosten und das Risiko zu tragen haben.
Es werden erhebliche Kosten entstehen, da die am schwersten getroffenen Problemgruppen am Arbeitsmarkt oft
nur eine geringe Weiterbildungsbereitschaft mitbringen.&#8220;1486 Die Projektgruppe h&#228;lt eine solche Zielsetzung f&#252;r
sinnvoll.
(Berufliche) Weiterbildung, die sich am konkreten Bedarf der Betriebe orientiert, sollte vom Arbeitgeber
finanziert und gef&#246;rdert werden. Dar&#252;ber hinaus muss es &#246;ffentliche F&#246;rderprogramme f&#252;r Weiterbildung geben, die
unabh&#228;ngig von der aktuellen Besch&#228;ftigung sind. Kontrovers wurde in der Projektgruppe diskutiert, ob ein
allgemeines Recht auf Weiterbildung eingef&#252;hrt werden und ob dieses auch eine ausreichende soziale Absicherung
w&#228;hrend der Bildungsphase umfassen sollte.1487 
1484 Handlungsempfehlungen von Prof. Dr. Jens S&#252;dekum (D&#252;sseldorf Institute for Competition Economics), Projektgruppendrucksache
19(27)PG 4-2 vom 21. November 2019.
1485 Darstellung Prof. Dr. Enzo Weber (Institut f&#252;r Arbeitsmarkt und Berufsforschung), in der Sitzung der Projektgruppe KI und Arbeit,
Bildung, Forschung am 25. November 2019.
1486 Handlungsempfehlungen von Prof. Jens S&#252;dekum (D&#252;sseldorf Institute for Competition Economics), Projektgruppendrucksache
19(27)PG 4-2 vom 21. November 2019.
1487 Handlungsempfehlungen von Prof. Dr. Enzo Weber (Institut f&#252;r Arbeitsmarkt und Berufsforschung), Projektgruppendrucksache 
19(27)PG 4-3 vom 22. November 2019.
Insgesamt sollte Weiterbildung ex-ante, breit, pr&#228;ventiv und innovativ gedacht werden. Dennoch sollten die
Inhalte von Weiterqualifizierungen nicht zu sehr zentral vordefiniert sein. Wichtig ist dabei zum einen, das richtige
Ma&#223; an zentraler Hilfestellung, Unterst&#252;tzung und Organisation zu finden. Zum anderen ist es essenziell,
Informationen aus den Betrieben zu den Qualifikationsanforderungen am Markt systematisch einzubeziehen.1488
Anreize f&#252;r die betriebliche Weiterbildung k&#246;nnten auch dadurch gesetzt werden, dass der zus&#228;tzliche Aufwand sich
in der Entlohnung widerspiegelt und systematisch in die Karriereplanung integriert wird.
Der Druck, Kompetenzen und F&#228;higkeiten kontinuierlich weiterzuentwickeln, steigt zwar grunds&#228;tzlich f&#252;r alle
Besch&#228;ftigten, besonders jedoch f&#252;r geringqualifizierte und &#228;ltere Besch&#228;ftigte.1489 Wie aus Studien zum
Automatisierungsrisiko von KI hervorgeht, besteht ein erh&#246;htes Risiko f&#252;r diese Besch&#228;ftigtengruppen.1490 Eine
zus&#228;tzliche Herausforderung f&#252;r die Politik ergibt sich daraus, dass Geringqualifizierte seltener an
Weiterbildungsma&#223;nahmen teilnehmen, obwohl diese eine positive Wirkung auf die Besch&#228;ftigungsf&#228;higkeit haben.1491 Hier 
sind gezielte Ma&#223;nahmen zur Sensibilisierung und F&#246;rderung von Weiterbildung notwendig.1492 
Die F&#246;rderung ad&#228;quater Ausbildungs- und Weiterbildungsangebote ist mit Fragen der Neubewertung
beruflicher T&#228;tigkeitsprofile verbunden, die sich unmittelbar auf die Entlohnung auswirken. Die Aus- und
Weiterbildung sollte durch finanzielle Anreize f&#252;r die Besch&#228;ftigten gef&#246;rdert werden und auf Freiwilligkeit beruhen. Von
gro&#223;er Bedeutung in diesem Zusammenhang sind neue Wege der Zertifizierung des praxisorientierten,
lebenslangen Lernens, die den kumulativen Kompetenzzuwachs abbilden. Des Weiteren sollten betriebsinterne
Weiterbildungsma&#223;nahmen gef&#246;rdert werden, die die Besch&#228;ftigungsf&#228;higkeit der Mitarbeiterinnen und Mitarbeiter
verbessern. Der Ansatz des Qualifizierungschancengesetzes k&#246;nnte mit Blick auf KI-Qualifizierung zu kurz
greifen, es sollten ausreichend M&#246;glichkeiten er&#246;ffnet werden, auf externe und interne Weiterbildungsangebote
zur&#252;ckzugreifen.1493 
Auch die Unternehmen m&#252;ssen vorausschauend vorgehen: Eine Weiterbildungsstrategie rund um die digitalen 
Kompetenzen von Mitarbeiterinnen und Mitarbeitern und die Bereitstellung entsprechender Mittel sind
Grundlage f&#252;r die Aussch&#246;pfung digitaler Chancen. Dazu z&#228;hlt auch die Sensibilisierung von F&#252;hrungskr&#228;ften f&#252;r die
Vorteile kontinuierlicher Weiterbildung als notwendiger Grundlage f&#252;r den zuk&#252;nftigen Erfolg des
Unternehmens. 
Um digitale und KI-Kompetenzen der Erwerbst&#228;tigen zu st&#228;rken, braucht es zeitgem&#228;&#223;e Weiterbildungsangebote
und -formate1494, die m&#246;glichst flexibel und individuell auf verschiedene Lerntypen1495 zugeschnitten sind.
Moderne Weiterbildung setzt u. a. auf Blended Learning, eine Kombination von Online- und Pr&#228;senzformaten, sowie
auf den Erwerb von Erfahrungswissen, klassische Lerneinheiten und selbstst&#228;ndiges Lernen &#252;ber digitale
Bildungsangebote. Dies gilt umso mehr, als es sich bei KI selbst um einen digitalen Lerninhalt handelt und die
hierf&#252;r zu erwerbenden Kompetenzen auch digital und &#8222;on the job&#8220; zu vermitteln sind. In der digitalisierten
Arbeitswelt werden nichtformalisierte (Weiter-)Bildungsangebote sowie von Unternehmen passgenau
zugeschnittene digitale Weiterbildungsangebote eine immer wichtigere Rolle spielen. Durch solche Mikrozertifikate 
oder Nanodegrees k&#246;nnen Erwerbst&#228;tige in &#252;berschaubaren Zeitabschnitten aktuelles Wissen und am
Arbeitsmarkt nachgefragte Kompetenzen erwerben. Durch diese Weiterbildungen sollte die Erwerbsf&#228;higkeit der
Besch&#228;ftigten erh&#246;ht werden. Auch Hochschulen sollten ihre Lehrangebote f&#252;r Berufst&#228;tige &#246;ffnen und ihnen den
Erwerb von Mikrozertifikaten erm&#246;glichen. Hochschulen sind durchaus schon Akteure der Weiterbildung.1496 
1488 Darstellung Prof. Dr. Enzo Weber (Institut f&#252;r Arbeitsmarkt und Berufsforschung), in der Sitzung der Projektgruppe KI und Arbeit,
Bildung, Forschung am 25. November 2019.
1489 Handlungsempfehlungen von Dr. Terry Gregory (IZA-Institute of Labor Economics), Projektgruppendrucksache 19(27)PG 4-17 
vom 25. November 2019.
1490 Vgl. Arntz et al. (2016): The Risk of Automation for Jobs in OECD Countries: A Comparative Analysis; Nedelkoska und Quintini
(2018): Automation, skills use and training.
1491 Vgl. Albert et al. (2010): On-the-job training in Europe: Determinants and wage returns; Sanders und Grip (2004): Training, task 
flexibility and the employability of low&#8208;skilled workers.
1492 Handlungsempfehlungen von Dr. Terry Gregory (IZA-Institute of Labor Economics), Projektgruppendrucksache 19(27)PG 4-17 vom
25. November 2019.
1493 Vgl. Bundesministerium f&#252;r Arbeit und Soziales (2019): Qualifizierungsoffensive am Arbeitsmarkt; ESF Europ&#228;ischer Sozialfonds
f&#252;r Deutschland (2019): Das Qualifizierungschancengesetz.
1494 Vgl. Schwarzenbach (2019): &#171;Blended Learning&#187;, &#171;Game-Based-Learning&#187; und andere Unbekannte: Je digitaler der Unterricht,
desto besser die Weiterbildung?; Eilers et al. (2020): Lebenslanges Lernen.
1495 Vgl. Technische Universit&#228;t Kaiserslautern: Lerntypen.
1496 Allein an der gr&#246;&#223;ten deutschen Universit&#228;t, der FernUniversit&#228;t in Hagen, gibt es 2.300 Weiterbildungsstudierende.
Sie m&#252;ssen noch besser in ihren Aktivit&#228;ten unterst&#252;tzt werden, Weiterbildung z. B. in Form von
Mikrozertifikaten oder berufsbegleitenden Bachelor-Studieng&#228;ngen anzubieten. Kostendeckende Angebote und Sichtbarkeit
in Weiterbildungsnetzwerken sind daf&#252;r zwei wesentliche Bausteine.
Um die Bev&#246;lkerung in die Lage zu versetzen, grundlegende Zusammenh&#228;nge im Bereich KI zu verstehen und
die Funktionsweise einordnen zu k&#246;nnen, sollte eine Weiterbildungsplattform entwickelt werden.1497 Damit ein
hoher Qualit&#228;tsstandard sichergestellt ist, sollte hier mit anerkannten Forschungs- und/oder
Bildungseinrichtungen zusammengearbeitet werden. Beispielhafte Module sind: Grundkenntnisse zu KI / Maschinellem Lernen,
Anwendungsf&#228;lle aus verschiedenen Branchen und Risiken im Zusammenhang mit KI, Vermeidungsstrategien 
f&#252;r diese Risiken. Dabei ist darauf zu achten, dass eine staatliche Weiterbildungsplattform verschiedene
Angebote nicht nur geb&#252;ndelt darstellt, sondern dass der Zugang niedrigschwellig ist. Hierzu geh&#246;ren die Gestaltung
von Angeboten f&#252;r verschiedene Altersstufen und Lerntypen sowie in verschiedenen Sprachen sowie
Barrierefreiheit. Die Suche nach KI-spezifischen Ma&#223;nahmen sowie die Anmeldung zu Fortbildungen sollten &#252;ber
dasselbe Portal laufen.
KI in der Forschung 
Das Kapitel &#8222;KI und Forschung&#8220;1498 widmet sich ausf&#252;hrlich dem Stand der KI-Forschung in Deutschland und 
leitet daraus Handlungsempfehlungen ab. Die folgenden Ausf&#252;hrungen gehen &#8211; darauf aufbauend &#8211; auf spezielle
Anforderungen an die KI-Forschung im Bereich Arbeit und Bildung ein. Die KI-Forschung ist ein breites Feld, 
in dem viele verschiedene Disziplinen aufeinandertreffen. Es erstreckt sich von Softwareentwicklung,
beispielsweise f&#252;r eine KI, die Logistikabl&#228;ufe optimiert, bis hin zur Robotik, die z. B. vielfach bei der industriellen
Produktion zum Einsatz kommt. In der Grundlagenforschung kann an neuen Fragen geforscht werden oder man
arbeitet an speziellen Problemen f&#252;r die Anwendung. Beides steht aber in einem engen Austausch und die
Grenzen zwischen Grundlagen- und Anwendungsforschung sind oft flie&#223;end.
5.3.1 Disembodied und Embodied KI
Im Zentrum eines jeden KI-Systems steht ein Agent. Der Agent interagiert mit seiner Umgebung, um eine
bestimmte Aufgabe zu erf&#252;llen. Zur Interaktion f&#252;hrt der Agent Handlungen aus, um eine vordefinierte Aufgabe zu
erreichen. Die Umgebung reagiert auf jede dieser Aktionen, indem sich der Gesamtzustand des Systems
ver&#228;ndert. Basierend auf der Art des Agenten, aber auch auf Art und Umfang der von ihm ausgef&#252;hrten Aktionen kann
grunds&#228;tzlich zwischen verk&#246;rperter und entk&#246;rperter KI (Embodied und Disembodied KI) unterschieden
werden.
5.3.1.1 Disembodied KI 
Bei der Disembodied KI (entk&#246;rperter KI) sind sowohl der Agent als auch seine Umgebung ein St&#252;ck Software,
z. B. Videospiele oder Empfehlungssysteme, die oftmals durch Sensoren mit der &#8222;realen&#8220; Welt verbunden sind.
Agenten haben in diesem Fall keinen K&#246;rper und ihre Aktionen sind normalerweise virtuell und nicht
mechanisch. Au&#223;erdem sind Agenten dieser Art nicht in der Lage, die physikalischen Eigenschaften der Welt direkt 
durch Manipulation zu ver&#228;ndern. Indirekt ist dies aber durchaus m&#246;glich, das hei&#223;t, ein KI-Optimierungssystem,
welches einen optimalen Produktionsablauf plant, hat nat&#252;rlich einen indirekten Einfluss auf die Ver&#228;nderung
von physischen Betriebsabl&#228;ufen und kann auch mit einer verk&#246;rperten KI verbunden sein. Eine Besonderheit
bilden dabei auch KI-Systeme, die Menschen unterst&#252;tzen, die ihrerseits physikalische Eigenschaften der
Umgebung beeinflussen.
In Deutschland ist die Forschung in diesem Bereich sehr vielf&#228;ltig. Themen wie Sprachanalyse,
Empfehlungssysteme, Maschinelles Lernen und Computer-Vision werden an fast jeder gr&#246;&#223;eren Universit&#228;t1499 erforscht.
Auch au&#223;eruniversit&#228;re Forschungsinstitute1500 investieren stark in die theoretische und angewandte Forschung
in diesen Bereichen.
1497 Beispiele f&#252;r solche Plattformen gibt es in den Niederlanden, vgl. https://app.ai-cursus.nl/home, speziell f&#252;r Kinder, vgl. https://fu-
turenl.org/nationale-ai-cursus-junior/), und in Finnland, vgl. https://www.elementsofai.com/ (alle zuletzt abgerufen am 5. August
2020), inzwischen gibt es auch eine deutsche Version dieser Plattform, vgl. https://www.elementsofai.de/ (zuletzt abgerufen am
3. September 2020).
1498 Siehe Kapitel 9 des Mantelberichts [KI und Forschung].
1499 Dies gilt u. a. f&#252;r die Universit&#228;ten in Berlin, Aachen, M&#252;nchen oder Karlsruhe.
1500 Dazu z&#228;hlen z. B. das DFKI, BCAI und das MPI-IS.
5.3.1.2 Embodied KI
Bei der Embodied KI (verk&#246;rperte KI) haben die Agenten einen sensomotorischen K&#246;rper; dies gilt z. B. f&#252;r
Fahrzeuge, Roboter, unbemannte Luftfahrzeuge (UAVs), Fertigungs- und andere intelligente Maschinen. Ihre
Handlungen f&#252;hren dazu, dass sich ihre K&#246;rper in der Welt bewegen, sogar physisch, mit ihr interagieren und
dadurch ihre Umgebungen wechselseitig beeinflussen.
In Deutschland hat die Forschung an Embodied KI Tradition und ist seit Jahrzehnten von Weltrang. Einige der
Hauptbereiche sind die Robotik, das autonome Fahren und intelligente Maschinen im Allgemeinen. F&#252;r die
Robotik gelten viele Universit&#228;ten und Forschungsinstitute in Deutschland als Spitzenreiter in der internationalen 
Forschungsgemeinschaft.1501 Autonomes Fahren ist in Deutschland ein weiteres Forschungsgebiet von
internationalem Rang, wobei die meisten Forschungsarbeiten in industriellen Einrichtungen1502 durchgef&#252;hrt werden;
aber auch Universit&#228;ten und Forschungsinstitute haben einen gro&#223;en Anteil an diesem Gebiet.1503 
5.3.2 Formen der KI-Forschung
Eine weitere Differenzierung l&#228;sst sich nach der Zielsetzung der jeweiligen KI-Forschung vornehmen. H&#228;ufig
wird hier besonders im politischen Diskurs unterschieden zwischen angewandter Forschung und
Grundlagenforschung, allerdings besteht keine allgemein akzeptierte Abgrenzung zwischen ihnen.1504 Insbesondere in Bezug
auf KI-Technologien verschwimmt die Grenze und die beiden dualistischen Bereiche beeinflussen einander stark,
auch weil die technische Entwicklung sehr schnell voranschreitet.
Grundlagenforschung zum allgemeinen Erkenntnisgewinn
Grundlagenforschung ist nach der OECD (1982) eine &#8222;[...] experimentelle oder theoretische Arbeit, die in erster
Linie auf die Gewinnung neuer Erkenntnisse &#252;ber den zugrunde liegenden Ursprung von Ph&#228;nomenen und
beobachtbaren Tatsachen gerichtet ist, ohne auf eine besondere Anwendung oder Verwendung abzuzielen&#8220;1505.
Zur Grundlagenforschung in diesem Sinne z&#228;hlen grundlegende theoretische Konzepte und Methoden, wie z. B. 
Maschinelles Lernen (siehe lernende KI-Systeme in der Begriffskl&#228;rung zur KI), intelligente Regelungstechnik
und Optimierungssteuerung methodischer Systemdesigns sowie Bereiche der sogenannten klassischen KI wie
z. B. die Wissensrepr&#228;sentation.
Problemorientierte Grundlagenforschung
Die problemorientierte Grundlagenforschung ist Grundlagenforschung, &#8222;[...] die in der Erwartung durchgef&#252;hrt
wird, dass sie einen breiten Fundus an Kenntnissen schafft, der den Kern f&#252;r die L&#246;sung von Problemen bzw. die
Realisierung von M&#246;glichkeiten bildet, die sich in der Gegenwart oder Zukunft bilden&#8220;1506.
Wie bereits beschrieben, verschwimmen die hier gezogenen Grenzen in der KI, und insbesondere im Bereich des
Maschinellen Lernens werden sehr grundlegende Konzepte in der Forschung angepasst, um konkrete Probleme
zu l&#246;sen, und dadurch auch grundlegend weiterentwickelt.
Beispielsweise flie&#223;en in der Robotik Erkenntnisse aus jahrzehntelanger Grundlagenforschung mit
M&#246;glichkeiten des Maschinellen Lernens zusammen und treffen auf ganz eigene Herausforderungen der Manifestation von 
Robotik in der physischen Welt. Intelligente Robotik ist daher weder reine Grundlagenforschung noch reine
Anwendung, sondern erst in der Begegnung dieser Anspr&#252;che entsteht die sinnvolle Forschungsaufgabe.
Entsprechend verh&#228;lt es sich in anderen Bereichen, wie z. B. Bilderkennung und -interpretation, Sprach- und
Textverstehen und Mensch-Maschine-Interaktion.
1501 Beispiele daf&#252;r sind das DLR, die MSRM oder auch das MPI-IS.
1502 Beispiele daf&#252;r sind DAIMLER, BMW und das BCAI.
1503 Zu denken ist hier z. B. an fortiss, das Karlsruher Institut f&#252;r Technologie, die Technische Universit&#228;t Braunschweig und die
Technische Universit&#228;t M&#252;nchen.
1504 Vgl. Pielke (2012): Basic Research as a Political Symbol.
1505 OECD Publishing (2015): Glossar, S. 440.
1506 OECD Publishing (2015): Glossar, S. 434.
F&#252;r den Transfer von der Forschung in die Anwendung ist eine Verzahnung tiefer Methodenforschung mit
Anwendungen in Gebieten wie Gesundheit, Klima, Arbeit, Energie und Mobilit&#228;t n&#246;tig. Besonders im Bereich des
Maschinellen Lernens gibt es viele Anwendungen, die in Deutschland erforscht werden.1507 
Anwendungsorientierte Forschung
Bei der angewandten Forschung (Applied Science) handelt es sich &#8222;[...] um origin&#228;re Arbeiten, die zur
Aneignung neuen Wissens durchgef&#252;hrt werden, aber prim&#228;r auf ein spezifisches Ziel oder Ergebnis ausgerichtet
sind&#8220;1508.
Wie zuvor sind die Grenzen zur Anwendungsforschung flie&#223;end. Basierend auf Erkenntnissen der
Grundlagenforschung werden hier konkrete Aufgaben gel&#246;st und auf entsprechende Anwendungsf&#228;lle1509 angewendet und
weiterentwickelt. Bekannte Beispiele der Anwendungsforschung, die in Deutschland stattfindet, sind autonomes
Fahren, medizinische Anwendungen (wie z. B. intelligente medizinische Diagnose-Assistenten),
Empfehlungssysteme, Chatbots, aber auch transdisziplin&#228;re Forschung und gesellschaftliche Auswirkungen der Technologien.
Diese Forschung findet insbesondere in Forschungsinstituten1510, die eng mit der Industrie zusammenarbeiten, 
statt, vermehrt auch &#252;ber Start-ups, die mit Universit&#228;ten arbeiten, aber auch in gro&#223;en Technologiefirmen, wie
z. B. den Automobilfirmen sowie Google und Amazon. Zum Teil gibt es auch Forschungskooperationen mit 
&#8222;Hidden Champions&#8220; im Bereich der kleinen und mittelst&#228;ndischen Unternehmen (KMU).
5.3.3 Handlungsempfehlungen
Der Erfolg der KI-Forschung in den Anwendungsbereichen Arbeit und Bildung h&#228;ngt &#8211; ebenso wie in anderen 
Bereichen &#8211; in besonderem Ma&#223;e von einer fruchtbaren Interaktion zwischen Grundlagenforschung,
problemorientierter Grundlagenforschung und unmittelbar anwendungsorientierter Forschung ab. Als lernende Systeme
m&#252;ssen KI-Systeme stets an ihren Anwendungskontext eingepasst werden und sie entwickeln sich dort durch das
Prozessieren von Daten weiter. Dem dom&#228;nenspezifischen Wissen der Akteure in den jeweiligen
Anwendungsfeldern und der Verf&#252;gbarkeit sowie der Aufbereitung geeigneter Daten kommt daher eine herausragende Rolle
zu.
Dies bedeutet, dass die KI-Forschung in den Anwendungsbereichen Arbeit und Bildung in hohem Ma&#223;e von der
Interdisziplinarit&#228;t und den Erfahrungen der Nutzerinnen und Nutzer profitiert. Hier sollte die informatische und
ingenieurswissenschaftliche Forschung daher von arbeitswissenschaftlicher bzw. p&#228;dagogischer Forschung
begleitet sein, welche die Nutzererfahrungen, die Aneignungspraktiken der Akteure sowie die kurz- und
mittelfristigen Folgen des Technologieeinsatzes untersucht. Neben betriebswissenschaftlichen und ergonomischen bzw.
lernpsychologischen Erkenntnissen sollte die Forschung auch die normative Fragestellung einbeziehen, welche
Rolle der Technikeinsatz f&#252;r eine qualitative Aufwertung von Arbeit sowie die inklusive Gestaltung von
individuell optimierten Bildungsangeboten haben kann.
Der interdisziplin&#228;re Dialog zwischen technisch und gesellschaftswissenschaftlich orientierten Disziplinen, die
transdisziplin&#228;re Gestaltung von Forschungsprojekten sowie fakult&#228;ts&#252;bergreifende Forschungseinrichtungen
und Graduiertenkollegs spielen eine wichtige Rolle dabei, die Entwicklung von KI-Systemen und deren
Kontextualisierung aufeinander abzustimmen.
Die Interdisziplinarit&#228;t in der Forschung sollte von einer inklusiven, dialogischen Orientierung in der
Technologieentwicklung und -einf&#252;hrung begleitet werden. Interaktionen zwischen verschiedenen Stakeholdern
gew&#228;hrleisten nicht nur jene Ber&#252;cksichtigung der Praxiserfahrungen, die f&#252;r die passgenaue Entwicklung von KI-
Systemen bedeutend sind, sondern k&#246;nnen auch die Technologieakzeptanz bei Nutzerinnen und Nutzern f&#246;rdern.
Missionsorientierte Forschungsprojekte zu gesellschaftlichen Zielsetzungen1511 in Bezug auf die Arbeitswelt und 
1507 Dies ist z. B. der Fall im Gesundheitswesen (Berliner Institut f&#252;r Gesundheitsforschung, The Center for Biomedical Artificial
Intelligence at the University Medical Center Hamburg-Eppendorf (bAIome), Fraunhofer Institut f&#252;r digitale Medizin (MEVIS),
Deutsches Zentrum f&#252;r Neurodegenerative Erkrankungen (DZNE), Regensburg Medical Image Computing (ReMIC), im
Versicherungswesen auf der Forschungs- und Entwicklungsplattform &#8222;Intelligent Digital Insurance&#8220; (IDI) und in der Informationssicherheit beim
Helmholtz-Zentrum f&#252;r Informationssicherheit (CISPA).
1508 OECD Publishing (2015): Glossar, S. 434.
1509 Siehe auch Kapitel 3.2 dieses Projektgruppenberichts [Einf&#252;hrende Beispiele bzw. Anwendungsf&#228;lle (Use Cases)].
1510 Beispiele daf&#252;r sind das DFKI oder die Fraunhofer-Institute.
1511 Siehe auch Kapitel 9 des Mantelberichts [KI und Forschung].
das Bildungssystem k&#246;nnen ihrerseits einen wichtigen Beitrag dazu leisten, Ressourcen f&#252;r wegweisende
Innovationen zu mobilisieren und fruchtbare R&#252;ckkopplungseffekte zwischen den verschiedenen Ebenen der
Forschung und den jeweiligen Anwendungsfeldern in Gang zu setzen.
Im Folgenden werden detaillierte Handlungsempfehlungen in Anlehnung an die im Kapitel 9 des Mantelberichts
[KI und Forschung] ausgef&#252;hrten Themen1512 formuliert:
Inter- und transdisziplin&#228;re KI-Forschung und -Ausbildung f&#246;rdern
Regul&#228;re staatliche F&#246;rderprogramme im Bereich der KI-Forschung sollten explizit zur Bildung interdisziplin&#228;rer
Konsortien ermuntern und Anreize f&#252;r transdisziplin&#228;re Fragestellungen geben. Diese Ma&#223;nahmen sollten durch
die F&#246;rderung von mittel- bis langfristig angelegten Forschungseinrichtungen, Graduiertenprogrammen und
fakult&#228;ts&#252;bergreifenden &#8222;Schools&#8220; nach amerikanischem Vorbild unterst&#252;tzt werden, in denen
Forschungsaktivit&#228;ten verst&#228;rkt interdisziplin&#228;r angelegt sind und alle f&#252;r eine Umsetzung notwendigen Kompetenzen geb&#252;ndelt
werden. Durch die Fokussierung auf einzelne interdisziplin&#228;re Themen haben auch kleinere Hochschulen die
Chance, schlagkr&#228;ftige Forschung zu betreiben. Mit oder ohne &#8222;Schools&#8220; &#8211; die Kooperation muss sowohl in der
Forschung als auch in der Lehre gest&#228;rkt und Synergien m&#252;ssen gef&#246;rdert werden.
Austauschformate zwischen Wissenschaft und Praxis f&#246;rdern
Hochschulen und Forschungseinrichtungen sollten sich Anforderungen der Gesellschaft &#246;ffnen und Br&#252;cken
zwischen Wissenschaft und Anwendung schaffen, die dr&#228;ngende gesellschaftliche Probleme bearbeiten. Dies
erfordert auch den Ausbau von Transfer- und Kooperationsmechanismen zwischen Wissenschaft, Wirtschaft, Politik
und Zivilgesellschaft im Bereich der KI-Forschung, mithin auch eine Zug&#228;nglichkeit von KI-Entwicklung im 
Rahmen von &#8222;Citizen Sciences&#8220;, Reallaboren und &#228;hnlichen inklusiven Ans&#228;tzen der Innovation. Auch die Lehre
muss mehr mit der Anwendung und praktischen Arbeiten verkn&#252;pft werden. Dazu bedarf es einer intensiveren
Betreuung durch mehr qualifizierte Lehrkr&#228;fte oder Freistellung von Personal f&#252;r die Lehre und einer viel
besseren Ausstattung von Laboren, Werkst&#228;tten und Computerr&#228;umen. Spitzenuniversit&#228;ten wie Stanford oder die
Eidgen&#246;ssische Technische Hochschule (ETH) Z&#252;rich k&#246;nnen hier als Vorbild dienen. 
Missionsorientierte KI-Forschung zu Arbeit und Bildung f&#246;rdern
Um die Potenziale von KI zur Verbesserung von Arbeit und Bildung zu heben, sollten mittel- bis langfristige
F&#246;rderprogramme eingerichtet bzw. existierende Programme aufgestockt werden, die besonderes Gewicht auf
gesellschaftlich relevante Zielsetzungen legen. Dies betrifft insbesondere die in Kapitel 3.3.3 dieses
Projektgruppenberichts [Wie die Forschung von morgen aussehen k&#246;nnte] aufgef&#252;hrten Beispiele, wie KI-basierte
Telepr&#228;senzsysteme und Portale zur Substitution von T&#228;tigkeiten in gef&#228;hrlichen Umgebungen, Formen der Mensch-
Maschine-Interaktion zur Anreicherung und Aufwertung von Arbeit sowie KI-Lernsysteme zur Unterst&#252;tzung
von Sch&#252;lerinnen und Sch&#252;lern mit Lernschw&#228;chen.
Gestaltungsinstrumente und Gestaltungsakteure
Weil KI das Potenzial hat, sich zur Basistechnologie zu entwickeln1513, kann perspektivisch von einer
universellen Durchdringung der Arbeitswelt mit KI-Systemen ausgegangen werden. &#8222;KI-Systeme k&#246;nnen [&#8230;] die
Arbeitswelt fundamental ver&#228;ndern.&#8220;1514 Vielf&#228;ltige Anwendungsszenarien und Gesch&#228;ftsmodelle treffen in der
Arbeit jedoch auf vielf&#228;ltige Systeme der Arbeitsorganisation, auf unterschiedliche Betriebskulturen und
M&#246;glichkeiten, auf differenzierte Erfordernisse sowie auf eine Vielzahl von Beteiligten.
F&#252;r die Regulation der Arbeit hat die deutsche Gesellschaft auch eine Vielfalt von Normsetzungsakteuren und
Gestaltungsinstrumenten hervorgebracht, die ebenso legitimiert wie erfolgreich die bisherigen Arbeitssysteme
regulieren. Neben Entwicklerinnen und Entwicklern, Betreiberinnen und Betreibern sowie Nutzerinnen und
Nutzern von KI-Systemen1515 pr&#228;gen verschiedene Regulierungsinstanzen die Normen f&#252;r Arbeit. Ihnen kommen &#8211;
&#252;ber die Aufgaben des Gesetzgebers hinaus &#8211; bedeutsame Funktionen zur Gestaltung der sozio-technischen
Systeme zu, &#252;ber die KI in der Arbeit wirkt.
1512 Siehe f&#252;r allgemeine Handlungsempfehlungen f&#252;r den Staat auch Kapitel 9 des Mantelberichts [KI und Forschung].
1513 Siehe auch Kapitel 3 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220; [Einf&#252;hrung: Anwendungsfelder und Potenziale von KI in
der Wirtschaft].
1514 High-Level Expert Group on Artificial Intelligence (2019): Ethik-Leitlinien f&#252;r eine vertrauensw&#252;rdige KI, S. 15.
1515 Vgl. High-Level Expert Group on Artificial Intelligence (2019): Ethik-Leitlinien f&#252;r eine vertrauensw&#252;rdige KI, S. 17.
Ob es um die Umsetzung der Empfehlungen dieser Enquete-Kommission, der Datenethikkommission1516 oder
der Hochrangigen Expertengruppe f&#252;r k&#252;nstliche Intelligenz der Europ&#228;ischen Kommission1517 geht oder um die
Umsetzung der in Gestaltungsdialogen entwickelten Anforderungen, die heute noch gar nicht formuliert sind:
Die Selbststeuerung und die Regulation von KI in der Arbeit m&#252;ssen der Dynamik der Entwicklung gerecht
werden k&#246;nnen und brauchen neben gesetzlichen Grundnormen und ethischen Prinzipien den Einfluss
unterschiedlicher Akteure und differenzierte Antworten.
Eine &#220;bersicht der Aufgaben, die den Normsetzungsinstanzen zukommen, ist in Kapitel 6.3 dieses
Projektgruppenberichts [Aufgaben der Normsetzungsinstanzen in der Arbeitswelt] zu finden. Hier ist darauf zu achten, dass
eine Balance zwischen den gesetzlichen Grundnormen und den untergeordneten Normierungsstrukturen und
Normierungsinstanzen gefunden wird.1518 
Geht man davon aus, dass sich KI zur Basistechnologie entwickeln wird und KI-Systeme die Arbeitswelt
durchdringen und damit fundamental ver&#228;ndern werden, ist es erforderlich, dass KI auch in der Bildung entsprechend
Eingang findet. Bildungseinrichtungen m&#252;ssen (zuk&#252;nftige) Arbeitnehmerinnen und Arbeitnehmer darauf
vorbereiten, in einer von KI gepr&#228;gten Arbeitswelt mit transformierten Arbeits-, Organisations- und
Kommunikationsprozessen umzugehen. Dabei muss das Bildungssystem so gestaltet werden, dass es m&#246;glichst flexibel und
dynamisch auf durch KI getriebene Entwicklungen reagieren kann und ein fundiertes Basiswissen vermittelt, das
dazu bef&#228;higt, motiviert und selbstst&#228;ndig zu lernen bzw. weiterzulernen und sich neue Dinge anzueignen.
Die erfolgreiche Nutzung von KI in der Bildung ist vom Einfluss unterschiedlicher Akteure abh&#228;ngig. Eine
&#220;bersicht der Aufgaben der Akteure ist in Kapitel 6.4 dieses Projektgruppenberichts [Aufgaben der
Normsetzungsinstanzen in der Bildung] zu finden.
SWOT-Analyse1519 
Um den derzeitigen Stand von KI in Arbeit, Bildung und Forschung in Deutschland einzuordnen, wurde eine
sogenannte SWOT-Analyse durchgef&#252;hrt. SWOT steht f&#252;r S = Strengths (St&#228;rken), W = Weaknesses
(Schw&#228;chen), O = Opportunities (Chancen) und T = Threats (Risiken). Insbesondere aus den Chancen und Risiken ergibt
sich der Handlungsbedarf f&#252;r Politik, Bildungswesen, Forschung, Sozialpartner und Unternehmen. 
Die folgende Abbildung gibt einen &#220;berblick &#252;ber St&#228;rken, Schw&#228;chen, Chancen und Risiken. Details zu den
einzelnen Punkten sind in den einzelnen Kapiteln des Projektgruppenberichts zu finden. Zu beachten ist, dass es
insbesondere im Kontext von KI und Arbeit mehrere Aspekte gibt, die je nach Ausgestaltung sowohl eine St&#228;rke
als auch eine Schw&#228;che bzw. sowohl eine Chance als auch ein Risiko darstellen k&#246;nnen. Dies spiegelt einerseits
wider, dass die Frage nach Chance und Risiko ma&#223;geblich davon abh&#228;ngt, wie bzw. in welchem Umfeld KI-
L&#246;sungen eingesetzt werden, andererseits, dass in vielen Feldern noch Forschungsbedarf besteht.
St&#228;rken:
&#8226; KI-L&#246;sungen sind in vielen Branchen und
Anwendungsfeldern bereits im Einsatz (z. B.
Chatbots).
&#8226; Es gibt eine Vision f&#252;r &#8222;gute Arbeit&#8220;, die als
Leitbild f&#252;r den Einsatz von KI dienen kann. 
&#8226; Eine starke Tradition der Sozialpartnerschaft
sowie relevantes Praxiswissen der Akteure, das
einbezogen werden kann, sind vorhanden.
&#8226; Der Nutzen von KI f&#252;r den Menschen und die
Gemeinschaft stehen in der politischen Debatte 
Schw&#228;chen:
&#8226; Der Einsatz von KI-L&#246;sungen erfolgt oft
z&#246;gerlich und ist ausbauf&#228;hig; h&#228;ufig fehlt das
Wissen &#252;ber m&#246;gliche Anwendungsfelder.
&#8226; Chancen und Risiken des KI-Einsatzes werden
teilweise im &#246;ffentlichen Diskurs emotional 
und inhaltlich &#252;berh&#246;ht. Beides wird dadurch 
unsachgem&#228;&#223; verst&#228;rkt.
&#8226; Voraussetzungen f&#252;r digitale L&#246;sungen (und 
damit auch KI) sind nicht fl&#228;chendeckend
vorhanden (dokumentierte Unternehmensprozesse, 
1516 Vgl. Datenethikkommission der Bundesregierung (2019): Gutachten der Datenethikkommission der Bundesregierung, Kapitel 3.2.
1517 Vgl. High-Level Expert Group on Artificial Intelligence (2019): Ethik-Leitlinien f&#252;r eine vertrauensw&#252;rdige KI.
1518 Dies wird auch im Rahmen der Steuerungsgruppe Normungs-Roadmap KI, angesiedelt beim Bundesministerium f&#252;r Wirtschaft und 
Energie und beim Deutschen Institut f&#252;r Normung e. V., bearbeitet. Dort ist auch ein Vertreterin bzw. ein Vertreter des BMAS
Mitglied.
1519 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel 5.5 des Berichts der
Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220; (&#8222;SWOT-Analyse &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des
sachverst&#228;ndigen Mitglieds Dr. Florian Butollo].
ebenso im Mittelpunkt wie wirtschaftliche In- Zugang zum Internet etc.) &#8211; dies betrifft den
teressen. Einsatz von KI im Arbeitsumfeld, aber auch in 
&#8226; Deutschland hat starke ethische Grunds&#228;tze, der Bildung.
die auch f&#252;r den Einsatz von KI gelten. &#8226; Es gibt bisher wenige konkrete Forschungser-
&#8226; Es gibt etablierte Verfahren im Deutschen
Bundestag zur kontinuierlichen
Technikfolgenabsch&#228;tzung, damit auch f&#252;r KI.
gebnisse zu den Folgen des KI-Einsatzes auf
Arbeit, Bildung und Forschung (dies gilt nicht
nur in Deutschland, sondern weltweit).
&#8226; Deutschland und Europa k&#246;nnen Vorbild f&#252;r
&#8222;Trusted AI&#8220; sein, was sich zum De-facto-
Markenzeichen weiterentwickeln kann.
&#8226; Unsicherheiten in Bezug auf Haftungsfragen 
beim Einsatz von KI in Arbeit, Bildung und
Forschung m&#252;ssen beseitigt werden (in 
Deutschland und auf europ&#228;ischer Ebene). 
&#8226; Die geltenden Arbeitsschutz- und
Datenschutzgesetze bieten eine gute Grundlage f&#252;r den 
Einsatz von KI.
&#8226; Es herrscht KI-Fachkr&#228;ftemangel in Forschung 
und Wirtschaft, zudem sind zu wenige Frauen 
in diesem Bereich besch&#228;ftigt.
&#8226; Starke Mitbestimmung kann dabei
unterst&#252;tzen, Vertrauen in der Belegschaft zu
eingesetzten KI-L&#246;sungen zu schaffen sowie gesetzlich
geregelte Vorgaben einzuhalten (sie kann aber
auch hemmend wirken &#8211; siehe Schw&#228;chen).
&#8226; Der Transformationsbedarf im Schulwesen ist
sehr hoch &#8211; sowohl was die Digitalisierung als
Voraussetzung f&#252;r den Einsatz von KI-
L&#246;sungen als auch was die Lehrkr&#228;fteaus- und -
fortbildung als auch was den Ausbau der notwen-
&#8226; Es gibt gute Weiterbildungsm&#246;glichkeiten digen Grundkenntnisse f&#252;r KI angeht.
(diese sind jedoch ausbauf&#228;hig &#8211; siehe
Schw&#228;chen). &#8226; Die berufsbegleitende Weiterbildung zu KI ist
ausbauf&#228;hig, weil sie noch zu wenige Besch&#228;f-
&#8226; Deutschland geh&#246;rt in der Grundlagenfor- tigte, insbesondere Geringqualifizierte,
erschung zur Weltspitze &#8211; mit seinen au&#223;eruni- reicht.
versit&#228;ren Forschungseinrichtungen und der
Forschung an Hochschulen. &#8226; Hochschulen und Forschungszentren sind
wenig flexibel und im Vergleich zum Ausland 
weniger attraktiv.1520 Dies f&#252;hrt u. a. dazu, dass
Durchbr&#252;che in der KI-Forschung vor allem
au&#223;erhalb Deutschlands erreicht werden,
oftmals jedoch von Forschenden, die in
Deutschland ausgebildet wurden. 
&#8226; KI-Einsatz in Unternehmen ist oft
intransparent &#8211; &#246;ffentlich diskutiert wird vor allem
Missbrauch zur Leistungskontrolle.
Chancen: Risiken:
&#8226; In allen Branchen kann Arbeit durch den Ein- &#8226; Der Einsatz von KI-L&#246;sungen kann zur
Arsatz von KI aufgewertet, sicherer gemacht und beitsverdichtung, zur Reduzierung der
Autonoerleichtert werden, z. B.: mie am Arbeitsplatz und damit zu erh&#246;htem
o Wegfall von Routine-Arbeiten, Schaffung Stress f&#252;hren (siehe aber auch Chancen).
von interessanterer Arbeit &#8226; Der vollst&#228;ndige Verzicht auf Weiterbildung
o besserer Arbeits- und Gesundheitsschutz oder zu wenig Weiterbildung in Bezug auf KI
m&#246;glich und ihren Einsatz kann zu einem
Wettbewerbso Unterst&#252;tzung von k&#246;rperlich intensiver
nachteil f&#252;r Deutschland f&#252;hren.
bzw. unergonomischer Arbeit durch &#8226; Mithilfe von KI vorsortierte
Weiterbildungsz. B. Robotik empfehlungen k&#246;nnen gegebenenfalls zu einer
&#8226; Dies kann zu h&#246;herer Arbeitsplatzqualit&#228;t,
verringerten Besch&#228;ftigungsf&#228;higkeit f&#252;hren 
mehr Autonomie bei der Arbeit und somit zu 
1520 Probleme f&#252;r die Hochschulen und Forschungszentren sind dabei auch die wenig flexiblen Rahmenbedingungen und Strukturen,
bedingt beispielsweise durch Haushaltsrecht, Besoldungsrecht, Besetzungsverfahren, Unterfinanzierung der Hochschulen in der
Zust&#228;ndigkeit der L&#228;nder und starre Lehrverpflichtungen.
einem Zuwachs an Wohlergehen f&#252;hren (siehe
aber auch Risiken).
&#8226; KI-L&#246;sungen k&#246;nnen zu einer h&#246;heren
Prozesseffizienz beziehungsweise zu einer
h&#246;heren Qualit&#228;t der Arbeitsergebnisse f&#252;hren.
M&#246;gliche Produktivit&#228;tsfortschritte k&#246;nnen 
wiederum zu Zuw&#228;chsen an Wohlstand f&#252;hren.
&#8226; Durch KI-gest&#252;tzte vorausschauende Wartung
k&#246;nnen Ausfallzeiten bei Maschinen verk&#252;rzt
bzw. sogar verhindert werden.
&#8226; KI kann das F&#228;higkeitsspektrum von
Menschen erg&#228;nzen und aufwerten.
&#8226; KI kann zu einer dringend notwendigen
Professionalisierung und besserer Zug&#228;nglichkeit
des deutschen Weiterbildungssystems f&#252;hren.
&#8226; KI-basierte Unterst&#252;tzung bei der Auswahl von 
Bewerberinnen und Bewerbern bei den
Besch&#228;ftigten f&#252;hren (siehe aber auch Risiken).
&#8226; Volkswirtschaftlich gesehen kann es zu einem
Besch&#228;ftigungszuwachs durch KI kommen (es
gibt jedoch noch keine ausreichende Forschung 
zu diesem Thema &#8211; siehe Schw&#228;chen).
&#8226; Das Lernen in Schule, Hochschule und in der
Weiterbildung kann durch den Einsatz von KI
individualisiert werden; dadurch k&#246;nnen
Lehrkr&#228;fte entlastet und Inklusion gef&#246;rdert werden 
und das Lernen kann eine h&#246;here Reichweite 
bekommen. 
&#8226; Die Erfolgschancen in der Forschung k&#246;nnen 
durch KI erh&#246;ht werden; Ergebnisse k&#246;nnen 
schneller erzielt werden.
&#8226; Neue Anreizstrukturen f&#252;r KI-
Spitzenforschung und interdisziplin&#228;re Forschung
k&#246;nnten zu einer Aufwertung des deutschen
Forschungsstandortes f&#252;hren.
&#8226; Lernen &#252;ber und (anonymisiert) mit KI kann 
der gesamten Bev&#246;lkerung M&#252;ndigkeit und 
Bef&#228;higung f&#252;r den Umgang mit KI vermitteln.
und die Abh&#228;ngigkeit der Besch&#228;ftigten
gegen&#252;ber ihren Unternehmen erh&#246;hen (gute
Empfehlungen und gute Weiterbildungsangebote
k&#246;nnen aber auch ein Vorteil sein).
&#8226; Frauen k&#246;nnen noch st&#228;rker aus wichtigen
Entscheidungsfunktionen ausgeschlossen sein, 
wenn es nicht gelingt, sie st&#228;rker f&#252;r Aufgaben 
im Bereich KI zu gewinnen
&#8226; Sofern KI-L&#246;sungen nicht transparent,
nachvollziehbar, erkl&#228;rbar und mit Kontroll- und 
Einspruchsm&#246;glichkeiten gestaltet werden, 
kann das f&#252;r einen Einsatz notwendige
Vertrauen fehlen.
&#8226; Die in Deutschland etablierte Mitbestimmung
kann durch das Mitspracherecht bei der
Einf&#252;hrung von KI-L&#246;sungen zu Verz&#246;gerungen 
bei Fortschritt und Innovation in Unternehmen 
f&#252;hren (sie kann aber auch konstruktiv sein &#8211;
siehe St&#228;rken).
&#8226; KI kann zu einem &#8222;Social Scoring&#8220; sowie zur 
Kontrolle von sowohl Arbeitenden als auch 
Lernenden missbraucht werden.1521 
&#8226; Unbeantwortete Sorgen sowie ein
unzureichendes Verst&#228;ndnis von KI in Bev&#246;lkerung und 
Unternehmen k&#246;nnen zu einem Hemmnis f&#252;r
den Einsatz von KI-L&#246;sungen werden.
&#8226; KI-basierte Unterst&#252;tzung bei der Auswahl von 
Bewerberinnen und Bewerbern kann bei
unausgewogener Datenbasis, falschen
Grundannahmen oder ungeeigneter Modellierung zu 
gruppenbezogenen Diskriminierungen f&#252;hren 
(siehe aber auch Chancen).
&#8226; Rechtsunsicherheit aufgrund fehlender,
unklarer oder unstimmiger Regulierung kann den 
Einsatz von KI bremsen bzw. sogar
verhindern.
&#8226; Unangemessen angewandte Arbeitsschutz- und 
datenschutzrechtliche Vorgaben k&#246;nnen den 
Einsatz von KI in bestimmten Bereichen
hemmen.
&#8226; Bei einer individuellen Arbeitsplatzbetrachtung 
kann es zum Wegfall von Arbeitspl&#228;tzen
kommen, insbesondere wenn generell &#8211; nicht nur
im KI-Kontext &#8211; die Dynamik von
Arbeitsfeldern ignoriert und deshalb Weiterbildung un-
1521 Der Begriff des Social Scorings wird in Kapitel 3.1. des Berichts der Projektgruppe &#8222;KI und Staat&#8220; [Innere Sicherheit] unter den
&#220;berschriften &#8222;Social Scoring&#8220; und &#8222;Keine Legitimierung von Social Scoring&#8220; erl&#228;utert. Dabei wird festgehalten, dass Social Scoring
den rechtsstaatlichen Grunds&#228;tzen in Deutschland widerspricht und deshalb in Deutschland nicht eingef&#252;hrt werden darf. Siehe hierzu
aber auch Kapitel 5.1.3.2 dieses Projektgruppenberichts [Einsatz von automatisierten Entscheidungssystemen und KI in der
Personalverwaltung].
        
 
 
  
 
 
 
  
 
 
  
  
   
    
     
 
    
 
    
  
    
     
    
     
    
    
  
    
   
   
   
    
  
  
    
    
  
    
   
  
  
     
      
6
terlassen wird (es gibt jedoch noch keine
ausreichende Forschung zu diesem Thema &#8211; siehe 
Schw&#228;chen).
&#8226; Eine durch KI beschleunigte Digitalisierung 
kann zu einer verst&#228;rkten Polarisierung von 
Einkommen und Verm&#246;gen beitragen.
&#8226; Der Forschungsstandort Deutschland kann bei
fehlenden ad&#228;quaten Anreizstrukturen an
Wettbewerbsf&#228;higkeit verlieren.
Appendix
Auflistung der in den Sitzungen angeh&#246;rten Expertinnen und Experten 
In der Sitzung am 25. November 2019 wurden zu den Themenkomplexen &#8222;Einsatzm&#246;glichkeiten von KI in der
Arbeitswelt und deren Auswirkungen sowie Arbeitsmarktforschung zu KI&#8220; folgende Personen angeh&#246;rt:
&#8226; Dr. Julia Borggr&#228;fe, Abteilungsleiterin &#8222;Digitalisierung und Arbeitswelt&#8220; im Bundesministerium f&#252;r Arbeit 
und Soziales (BMAS)
&#8226; Dr. Terry Gregory, Institute of Labor Economics (IZA); Leibniz-Zentrum f&#252;r Europ&#228;ische
Wirtschaftsforschung (ZEW)
&#8226; Prof. Dr. Lisa Herzog, Reichsuniversit&#228;t Groningen
&#8226; Oliver Suchy, Deutscher Gewerkschaftsbund (DGB)
&#8226; Prof. Dr. Jens S&#252;dekum, D&#252;sseldorf Institute for Competition Economics (DICE)
&#8226; Prof. Dr. Enzo Weber, Institut f&#252;r Arbeitsmarkt und Berufsforschung (IAB)
In der Sitzung am 9. Dezember 2019 wurden zum Themenkomplex &#8222;Ver&#228;nderung von Berufsfeldern und
Arbeitsinhalten durch KI und die Mensch-Maschine-Interaktion sowie Auswirkungen von KI auf
Arbeitsbedingungen, Arbeitsschutz und Arbeitszeit&#8220; folgende Personen angeh&#246;rt:
&#8226; Prof. Dr. Lars Adolph, Bundesanstalt f&#252;r Arbeitsschutz und Arbeitsmedizin (BAuA)
&#8226; Dr. Marie-Christine Fregin, Wissenschaftszentrum Berlin (WZB) und Input-Consulting
&#8226; Thomas Langkabel, Microsoft Deutschland
&#8226; Dr. Britta Matthes, Institut f&#252;r Arbeitsmarkt- und Berufsforschung (IAB)
&#8226; Dr. Gerlind Wisskirchen, Kanzlei CMS
&#8226; Dar&#252;ber hinaus wurde zu diesem Themenkomplex folgende Person angeh&#246;rt, jedoch erst in der Sitzung am
2. M&#228;rz 2020:
&#8226; Dr. Martin Kuhlmann, Soziologisches Forschungsinstitut G&#246;ttingen (SOFI)
Im ersten Teil der Sitzung am 16. Dezember 2019 wurden zum Themenkomplex &#8222;Einfluss von KI auf die
Arbeitsorganisation und -verwaltung und auf Fragen der Mitbestimmung sowie zum Einsatz von KI im Recruiting
und bei der Beratung und Vermittlung&#8220; folgende Personen angeh&#246;rt:
&#8226; Thomas Belker, Precire Technologies GmbH und Bundesverband der Personalmanager
&#8226; Martina Hofmann, IT-Systemhaus der Bundesagentur f&#252;r Arbeit
&#8226; Prof. Dr. Wolfgang J&#228;ger, Hochschule RheinMain 
&#8226; Dr. Constanze Kurz, Gesamtbetriebsrat Robert Bosch AG
&#8226; Eva-Maria Nyckel, Humboldt-Universit&#228;t zu Berlin
&#8226; Matthias Spielkamp, algorithmwatch
Im zweiten Teil der Sitzung am 16. Dezember 2019 wurden zum Themakomplex &#8222;KI und Lernen sowie
Auswirkungen von KI in der Schule und Hochschule&#8220; folgende Personen angeh&#246;rt:
&#8226; Prof. Dr. Heidrun Allert, Professorin f&#252;r Medienp&#228;dagogik/Bildungsinformatik, Christian-Albrechts-
Universit&#228;t zu Kiel
&#8226; Susan Beudt, Educational Technology Lab am Deutschen Forschungszentrum f&#252;r K&#252;nstliche Intelligenz
&#8226; Prof. Dr. J&#252;rgen Handke, Philipps-Universit&#228;t Marburg
&#8226; Florian Rampelt, Stifterverband (KI-Campus)
&#8226; Jan Renz, Hasso-Plattner-Institut
&#8226; Prof. Dr. Ute Schmid, Professorin f&#252;r Angewandte Informatik, Universit&#228;t Bamberg
&#8226; Detlef Steppuhn, Lehrer am Erich-Gutenberg-Berufskolleg K&#246;ln
Dar&#252;ber hinaus wurde zu diesem Themenkomplex die folgende Person um die Erstellung schriftlicher
Handlungsempfehlungen gebeten:
&#8226; PD Dr. Sigrid Hartong, Helmut-Schmidt-Universit&#228;t Hamburg
Am 13. Januar 2020 nahmen an einem Gespr&#228;ch mit Vertreterinnen und Vertretern von Gewerkschaften und
Arbeitgeberverb&#228;nden sowie ausgew&#228;hlter Branchen und Betriebe folgende Personen teil:
&#8226; Dr. Katie Baldschun, Sozialgericht Dortmund, zum Zeitpunkt des Gespr&#228;chs an der Universit&#228;t Kassel
&#8226; David Beitz, Arbeitgeberverband Gesamtmetall e. V.
&#8226; Marco Grenz, IG Metall
&#8226; Anka Grosch, Betriebsrat Amazon Logistikzentrum Leipzig
&#8226; Ralf Lemster, Bundesverbands der Dolmetscher und &#220;bersetzer
&#8226; Prof. Dr. Florian Schmidt, Hochschule f&#252;r Technik und Wirtschaft Dresden
&#8226; Prof. Dr.-Ing. habil. Sascha Stowasser, Institut f&#252;r angewandte Arbeitswissenschaft
In den Sitzungen am 2. und 9. M&#228;rz 2020 wurden zum Thema &#8222;KI und Forschung&#8220; folgende Personen geh&#246;rt:
&#8226; Prof. Dr. Philipp Hennig, Professor f&#252;r die Methoden des Maschinellen Lernens an der Universit&#228;t T&#252;bingen;
Max-Planck-Institut f&#252;r Intelligente Systeme
&#8226; Prof. Dr. Ulman Lindenberger, Max-Planck-Institut f&#252;r Bildungsforschung
&#8226; Prof. Dr. Dr. Fabian Theis, Helmholtz Zentrum M&#252;nchen
Auflistung der Mitglieder der Projektgruppe
An der Projektgruppe und ihrem Bericht wirkten mit:
f&#252;r die Fraktion der CDU/CSU:
&#8226; der Abgeordnete Marc Biadacz 
&#8226; Susanne Dehmel als sachverst&#228;ndiges Mitglied
&#8226; Prof. Dr. Antonio Kr&#252;ger als sachverst&#228;ndiges Mitglied 
&#8226; die Abgeordnete Jana Schimke 
&#8226; der Abgeordnete Andreas Steier
&#8226; die Abgeordnete Prof. Dr. Claudia Schmidtke als stellvertretendes Mitglied
f&#252;r die Fraktion der SPD:
&#8226; Prof. Dr.-Ing. Sami Haddadin als sachverst&#228;ndiges Mitglied 
&#8226; der Abgeordnete Ren&#233; R&#246;spel als Vorsitzender der Projektgruppe
&#8226; Lothar Schr&#246;der als sachverst&#228;ndiges Mitglied
&#8226; die Abgeordnete Daniela Kolbe als stellvertretendes Mitglied
f&#252;r die Fraktion der AfD:
&#8226; Prof. Dr. Boris Hollas als sachverst&#228;ndiges Mitglied
&#8226; der Abgeordnete J&#246;rg Schneider 
f&#252;r die Fraktion der FDP: 
&#8226; Andrea Martin als sachverst&#228;ndiges Mitglied 
&#8226; der Abgeordnete Carl-Julius Cronenberg als stellvertretendes Mitglied 
f&#252;r die Fraktion DIE LINKE.: 
&#8226; die Abgeordnete Jessica Tatti 
&#8226; Dr. Florian Butollo als sachverst&#228;ndiges und stellvertretendes Mitglied 
und f&#252;r die Fraktion B&#220;NDNIS 90/DIE GR&#220;NEN: 
&#8226; die Abgeordnete Dr. Anna Christmann 
&#8226; der Abgeordnete Dr. Danyal Bayaz als stellvertretendes Mitglied 
Aufgaben der Normsetzungsinstanzen in der Arbeitswelt
Instanz Gestaltungsfeld
Management in den Betrieben und 
Verwaltungen
Schaffung von Transparenz, insbesondere &#252;ber Zielsetzungen, 
Datennutzung, Verantwortlichkeiten und Revisionsinstrumente
Definition von Grenzen, Revisionsm&#246;glichkeiten und 
verantwortlichen Stellen f&#252;r maschinelle Schlussfolgerungen
Entwicklung ethischer Normen
Einordung betrieblicher KI-Systeme in Kritikalit&#228;tsstufen, Bildung
von N&#252;tzlichkeitsprofilen
Durchf&#252;hrung von Tests, Folgeabsch&#228;tzungen und 
Gef&#228;hrdungsanalysen
Schaffung mitbestimmter Normen
Ausrichtung des Beschaffungs-, Qualit&#228;ts- und Personalmanagements
auf betriebliche Normen
Qualitative Personalplanung und -entwicklung 
Mitwirkung an &#252;berbetrieblichem Monitoring und Benchmarking
Hersteller und Dienstleister Schaffung von Transparenz &#252;ber Verwendung und 
Nachvollziehbarkeit im Einsatz von KI
Kundinnen und Kunden Orientierung des Kaufverhaltens an vertrauensw&#252;rdiger KI1522, 
Fairness, Transparenz und guter Arbeit
Investoren Orientierung des Investitionsverhaltens an vertrauensw&#252;rdiger KI, 
Fairness, Transparenz und guter Arbeit
Besch&#228;ftigte Umsetzung einer Berufsethik von vertrauensw&#252;rdiger KI1523 als
Entwicklerin und Entwickler, Betreiberin und Betreiber sowie
Nutzerin und Nutzer
Entwicklung und Ausbau der Beurteilungs- und Anwenderkompetenz
Beteiligung an Gestaltungsdialogen und Tests
1522 Vgl. High-Level Expert Group on Artificial Intelligence (2019): Ethik-Leitlinien f&#252;r eine vertrauensw&#252;rdige KI, S. 6: Die drei
Komponenten vertrauensw&#252;rdiger KI sind Rechtm&#228;&#223;igkeit, ethische Auspr&#228;gung und Robustheit.
1523 Vgl. High-Level Expert Group on Artificial Intelligence (2019): Ethik-Leitlinien f&#252;r eine vertrauensw&#252;rdige KI, S.17:
Umsetzungsrelevante Ziele sind der Vorrang menschlichen Handelns und Aufsicht, technische Robustheit, Schutz der Privatsph&#228;re,
Transparenz, Vielfalt, Nichtdiskriminierung und Fairness.
Instanz Gestaltungsfeld
Whistleblowing bei Rechtsverletzungen
Betriebs- und Personalr&#228;te,
betriebliche
Mitbestimmungsakteure
Hinwirkung auf einen betrieblichen Ordnungsrahmen und ein 
Einf&#252;hrungsmodell zu KI
Schutz der Pers&#246;nlichkeitsrechte und der Diskriminierungsfreiheit
Beteiligung an Tests, Folgeabsch&#228;tzungen und Gef&#228;hrdungsanalysen
Einbringen von Innovationsideen f&#252;r den Einsatz von KI
Aufsichtsr&#228;te Einfordern ethischer Normen
Beaufsichtigung der Rechtskonformit&#228;t im Handeln
Mitwirkung bei qualitativer Personalplanung
Tarifvertragsparteien Verabredung von Normen, die gesetzliche Vorgaben differenzieren
Unterst&#252;tzung der Betriebsparteien bei der Entwicklung von 
Regulationsmechanismen
Verabredung von tariflichen Festlegungen, die Sicherheit in der
Transformation schaffen und Perspektiven f&#252;r die Besch&#228;ftigten 
erschlie&#223;en
Datenschutzbeauftragte Beaufsichtigung und Pr&#252;fung des Datenschutzes
Beratung bei der Sicherstellung der Rechtskonformit&#228;t
Normungsinstitute der Industrie Beschreibung von Technik- und Prozessnormen, u. a. zu Robustheit
und Cybersicherheit
Industrie- und Handelskammern, 
Handwerkskammern
Best-Practice-Transfer
Vermittlung von Gestaltungskompetenz
Arbeitsschutzinstitutionen Schaffung von Arbeitsschutznormen, u. a. zu Belastungsanalysen, 
Handlungstr&#228;gerschaft und Situationskontrolle1524 
Aufsichtsbeh&#246;rden &#220;berpr&#252;fung der Rechtskonformit&#228;t im Handeln
Aufgaben der Normsetzungsinstanzen in der Bildung
Akteur Gestaltungsfeld
Sch&#252;lerinnen und Sch&#252;ler an
Schulen
Lernen &#252;ber1525 und mit1526 KI
1524 Darstellung Prof. Dr. Lars Adolph (Bundesanstalt f&#252;r Arbeitsschutz und Arbeitsmedizin) in der Sitzung der Projektgruppe &#8222;KI und 
Arbeit, Bildung, Forschung&#8220; am 9. Dezember 2019.
1525 Lernen &#252;ber KI bezieht sich auf die Aus- und Weiterbildung zu erforderlichen mathematisch-analytischen Grundlagen, zu KI-
Technologien, zur Nutzung von KI-L&#246;sungen und vor allem auch zu Soft Skills, wie Entscheidungs- und Probleml&#246;sungskompetenz,
kritische Denkf&#228;higkeit, Kreativit&#228;t oder soziale Verantwortung.
1526 Lernen mit KI bezieht sich auf die Unterst&#252;tzung der Aus- und Weiterbildung durch KI-L&#246;sungen.
        
 
 
  
   
 
 
   
   
 
 
 
 
   
   
  
 
 
  
  
  
  
 
    
  
  
    
   
  
      
  
    
   
 
   
   
   
   
   
  
   
                                               
 
        
      
1
Akteur Gestaltungsfeld
Lehrerinnen und Lehrer an Schulen Lehren &#252;ber und mit KI
Erwerb von KI-Kompetenzen (Verst&#228;ndnis &#252;ber KI und Umgang mit
KI-L&#246;sungen sowie p&#228;dagogische Vermittlungskompetenz) in der
Lehrerinnen- und Lehreraus- und -fortbildung
Auszubildende Erwerb von KI-Kompetenzen (grundlegendes Verst&#228;ndnis &#252;ber KI
sowie Nutzung von KI-L&#246;sungen)
Ausbildungsbetriebe und 
Berufsschulen
Vermittlung von KI-Kompetenzen
Kontinuierliche Weiterbildung 
Studentinnen und Studenten Lernen &#252;ber und mit KI
Hochschulen und Forschung Lehren &#252;ber und mit KI
Spitzenforschung im KI-Bereich
Arbeitsforschung zu KI
Arbeitnehmerinnen und 
Arbeitnehmer
Erwerb von Anwendungs- und Gestaltungskompetenz f&#252;r die
Vorbereitung auf eine Arbeitswelt mit KI-Systemen
Arbeitgeber Schaffung von Weiterbildungsangeboten im Bereich KI
Modularisierung der Angebote, sodass der Zeitaufwand f&#252;r
Arbeitnehmerinnen und Arbeitnehmer tragbar ist
VI. K&#252;nstliche Intelligenz und Mobilit&#228;t (Projektgruppe 5)1527 
Kurzfassung des Projektgruppenberichts
Kurzfassung
Die Projektgruppe &#8222;KI und Mobilit&#228;t&#8220; hat sich mit dem Einsatz und zuk&#252;nftigen Anwendungsm&#246;glichkeiten der
K&#252;nstlichen Intelligenz (KI) im Bereich der Mobilit&#228;t befasst.
Um die thematische Breite und Vielf&#228;ltigkeit des Untersuchungsbereiches KI und Mobilit&#228;t zu strukturieren, hat
die Projektgruppe sowohl Querschnittsthemen (Visionen f&#252;r eine Zukunft der Mobilit&#228;t, Intermodalit&#228;t und
Plattformen, &#246;konomische und wettbewerbsrechtliche Fragen sowie Fragen der Stadtentwicklung) als auch
Anwendungsfelder (Stra&#223;enverkehr, Schienenverkehr, Luftfahrt und Schiffsverkehr) identifiziert, in denen KI bereits
erfolgreich zum Einsatz kommt, einen besonderen Nutzwert erwarten l&#228;sst und in denen sich ein rechtlicher
Regelungsbedarf abzeichnet. Entsprechend wurden die einzelnen Sitzungen den folgenden Themen zugeordnet:
&#8226; Zukunft der Mobilit&#228;t
&#8226; Intermodalit&#228;t und Plattformen
&#8226; Stra&#223;enverkehr
&#8226; Schienenverkehr
&#8226; Luftverkehr
&#8226; Schiffsverkehr 
&#8226; &#220;bergreifende Themen (&#214;konomie und Wettbewerb sowie Stadtentwicklung)
1527 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion DIE LINKE. vor [Sondervotum zu Kapitel C. VI. &#8222;K&#252;nstliche Intelligenz 
und Mobilit&#228;t (Projektgruppe 5)&#8220; der Abgeordneten Dr. Petra Sitte und Jessica Tatti].
Neben fach- und themenspezifischen Fragen wurden in den Debatten auch grunds&#228;tzliche Aspekte und
Herausforderungen diskutiert. So befasste sich die Projektgruppe mit bereits bestehenden und zuk&#252;nftigen
Entwicklungen sowie mit notwendigen n&#228;chsten Schritten, um einerseits Megatrends wie Digitalisierung und Urbanisierung
positiv zu gestalten und um andererseits gro&#223;en Herausforderungen wie dem Klimawandel und dem Umgang mit
dem l&#228;ndlichen Raum entgegenzutreten. Ethische und rechtliche Fragen sowie Fragen zum Umgang mit Daten
waren ein wesentlicher Bestandteil der Debatten.
In den Beratungen der Projektgruppe zeigte sich, dass es viele Problemstellungen, Regelungsbedarfe und
Anforderungen an Gesetzgeber, Regierung und Verwaltung sowie an gesellschaftliche und wirtschaftliche Akteure
gibt; die Beratungen m&#252;ndeten daher in gemeinsame Handlungsempfehlungen. 
Die Empfehlungen der Projektgruppe &#8222;KI und Mobilit&#228;t&#8220; sollen einen vorw&#228;rtsgewandten, holistischen und
effizienten Rahmen f&#252;r die Weiterentwicklung und den zielgerichteten Einsatz von KI in der Mobilit&#228;t in
Deutschland und Europa schaffen. Dazu sollen die Empfehlungen dort Strukturen st&#228;rken, wo es bereits
zukunftsweisende und zukunftsf&#228;hige Ans&#228;tze gibt.
1.1.1 Themen&#252;bergreifende Handlungsempfehlungen der Projektgruppe
Mobilit&#228;t ganzheitlich betrachten
Die Mobilit&#228;t der Zukunft und damit auch KI-Anwendungen in der Mobilit&#228;t m&#252;ssen ganzheitlich betrachtet
werden. In allen signifikanten Bereichen der Forschung und Entwicklung sowie der F&#246;rderung und der
Behandlung von Daten ist oftmals noch zu beobachten, dass Verkehrstr&#228;ger oder -systeme einzeln und ohne Einbindung
in das Gesamtkonzept der Mobilit&#228;t betrachtet werden.
Es gilt, die innovativen und zielf&#252;hrenden Anstrengungen in einem holistischen Ansatz zu b&#252;ndeln und somit die
KI f&#252;r den gesamten Mobilit&#228;tssektor voranzubringen. Dazu bedarf es einer st&#228;rkeren Vernetzung in der
Verkehrsplanung, in Forschung und Entwicklung sowie auch in der rechtlichen Rahmensetzung sowohl in
Deutschland als auch in Europa.
Mobilit&#228;t an den Bed&#252;rfnissen des Menschen ausrichten
Der Mensch steht im Mittelpunkt &#8211; dies bezieht sich einerseits ganz konkret auf die Mobilit&#228;tsanforderungen,
z. B. im st&#228;dtischen und l&#228;ndlichen Bereich, oder auf das Bed&#252;rfnis nach Sicherheit sowie die Notwendigkeit der
Barrierefreiheit. Dass der Mensch im Mittelpunkt steht, bezieht sich aber andererseits auch auf die Akzeptanz
und das Vertrauen, welches die Gesellschaft zur KI aufbauen bzw. welches sie ausbauen k&#246;nnen muss.
Entscheidend hierf&#252;r sind der Zugang zu Systemen, Transparenz und das Bewusstsein der Selbstbestimmung und
Sicherheit.
Die digitale Infrastruktur ausbauen 
Eine durchg&#228;ngige Forderung, welche sich durch alle Bereiche &#8211; auch &#252;ber die Mobilit&#228;t hinaus &#8211; zieht, sind 
Investitionen in bereits verbreitete Technologien wie das LTE-Netz und in neue Kommunikationsinfrastrukturen 
wie z. B. das 5G-Netz.
Ohne eine fl&#228;chendeckende und reibungslos funktionierende digitale Infrastruktur werden viele technisch
m&#246;gliche Entwicklungen ungenutzt bleiben. Der Ausbau dieser digitalen Infrastruktur in Deutschland muss deswegen
Priorit&#228;t haben.
Datennutzung regeln / Open-Data-Strategien f&#246;rdern
Das Teilen von Daten ist ein, wenn nicht das beherrschende Thema, welches sich wie ein roter Faden durch die
Befassung mit KI zieht. In der Projektgruppe &#8222;KI und Mobilit&#228;t&#8220; wurde das &#8222;Data-Sharing&#8220; intensiv diskutiert
und hat entsprechend Eingang in die Handlungsempfehlungen gefunden. Datenerhebung und -analyse werden
als zentrale Wettbewerbs- und Weiterentwicklungsfaktoren definiert. M&#246;gliche Interessenkonflikte zwischen
rechtlichen Einschr&#228;nkungen des Datenzugriffs und dem Zugangsbegehren von anderen (Wettbewerbern,
Drittanbietern) m&#252;ssen regulativ gel&#246;st werden. 
Forschung ausbauen und Testfelder einrichten
Themen&#252;bergreifend wurde nicht nur ein erh&#246;hter, sondern dar&#252;ber hinaus ein zielgerichteter und vernetzter
Forschungsbedarf identifiziert, der verst&#228;rkt in die Errichtung und Bereitstellung von Test- und Reallaboren m&#252;nden
soll. Forschung und Testbetriebe, die idealerweise auch europ&#228;isch vernetzt sein sollten, tragen zur Steigerung
der Sicherheit, Effizienz und nicht zuletzt zur Akzeptanz neuer Entwicklungen in der Bev&#246;lkerung bei. So k&#246;nnen
Neuentwicklungen und Innovationen schneller zur Anwendung im Regelbetrieb gebracht werden.
Rechtliche Rahmenbedingungen erarbeiten
Von der vorwettbewerblichen Zusammenarbeit zwischen Forschungseinrichtungen, Beh&#246;rden und Herstellern
bis hin zur konkreten Umsetzung in Angebot, Nutzung und Haftung ist der Gesetzgeber aufgefordert, ein
Regelwerk zu entwickeln, das innovationsfreundlich ist und zugleich eindeutige Rahmenbedingungen setzt. Die
Notwendigkeit von Ex-post-Einzelentscheidungen durch Gerichte sollte auf ein Minimum reduziert werden. Bei den
bedeutenden und komplexen Fragen der Haftung, insbesondere im Bereich des autonomen Fahrens, sollte darauf
geachtet werden, welche juristischen Regularien bereits vorhanden sind und genutzt werden k&#246;nnen und in
welchen Bereichen &#252;berhaupt gesetzlich nachjustiert werden muss. 
Fairen Wettbewerb gew&#228;hrleisten und Monopolbildung entgegenwirken
Funktionierender Wettbewerb ist f&#252;r Innovationen unabdingbar. Das Wettbewerbsrecht muss hier erstens einen
fairen Datenaustausch gew&#228;hrleisten. Um einer Verfestigung von Monopolbildungen z. B. im Bereich der
Mobilit&#228;tsplattformen entgegenwirken zu k&#246;nnen, werden zweitens Verhaltensregeln auf europ&#228;ischer Ebene
angeregt. Langfristig ist ein einheitlicher europ&#228;ischer Rechtsrahmen unabdingbar. Weiterer Kl&#228;rungsbedarf wurde
au&#223;erdem bei den Vorgaben f&#252;r Dateninteroperabilit&#228;t und -portabilit&#228;t gesehen. Durch gezielte F&#246;rderung
dezentraler L&#246;sungen von neuen Ideen auf europ&#228;ischer Ebene sollten Unternehmen mit einer gewissen
Monopolstellung zu verst&#228;rktem Engagement herausgefordert werden. 
Einen europ&#228;ischen Weg gehen
F&#252;r alle behandelten Bereiche, von Standards in der Forschung bis zu Standards in Wettbewerbsrecht und
Datennutzung, ist der angestrebte Weg ein europ&#228;ischer. Deutschland sollte hier eine treibende Kraft f&#252;r diesen
europ&#228;ischen Weg sein, um die Wettbewerbsf&#228;higkeit Europas mit qualitativ hohen Standards zu gew&#228;hrleisten.
Ein positives Beispiel stellt das Projekt GAIA-X dar, welches &#8211; von Deutschland initiiert und mit Frankreich
vorangetrieben &#8211; einen europ&#228;ischen Weg der vernetzten Dateninfrastruktur geht.
1.1.2 Themenschwerpunkte
Die thematische Schwerpunktsetzung, wie sie eingangs beschrieben wurde, spiegelt sich in ihrer Komplexit&#228;t
auch in den Empfehlungen an das Parlament wider. Die Bearbeitung und Debatten jedes Teilbereiches f&#252;hrten
zu der Entwicklung themenspezifischer Handlungsempfehlungen. 
Zukunft der Mobilit&#228;t
Die Themensitzung &#8222;Zukunft der Mobilit&#228;t&#8220; bereitete die darauffolgenden Debatten zu den einzelnen
Themenfeldern der Projektgruppe (Intermodalit&#228;t und Plattformen, Stra&#223;enverkehr, Schienenverkehr, Luftverkehr und
Schiffsverkehr) vor. Leitfrage der Sitzung war insbesondere, welche Rolle bzw. welchen Einfluss KI-
Anwendungen einnehmen k&#246;nnen, um die Vision einer klima- und umweltfreundlichen, komfortablen, sozial gerechten,
barrierefreien und f&#252;r alle Nutzergruppen bezahlbaren Mobilit&#228;t zu unterst&#252;tzen und voranzubringen. 
Der Mobilit&#228;tssektor ist bez&#252;glich des Einsatzes von KI-Anwendungen ganzheitlich f&#252;r die vielf&#228;ltigen
Lebensr&#228;ume- und -situationen zu betrachten: vom urbanen Raum &#252;ber die &#220;bergangsr&#228;ume zwischen Stadt und Land 
bis hin zu d&#252;nn besiedelten Regionen; dabei ist die demografische Entwicklung einzubeziehen. Sowohl die
Kooperation zwischen Kommunen, Bund und L&#228;ndern als auch die Zusammenarbeit &#246;ffentlicher und privater
Mobilit&#228;tsanbieter ist anzustreben und voranzutreiben. M&#246;glichen Rebound-Effekten durch eine erh&#246;hte Nutzung
und einen h&#246;heren datengetriebenen Energieverbrauch sollte entgegengewirkt werden. Dabei sollen die
Wechselwirkungen durch den Einsatz neuer Technologien bewertet und entsprechend darauf reagiert werden.
Intermodalit&#228;t und Plattformen
Diskussionsschwerpunkte waren hier die unterschiedlichen Verf&#252;gbarkeiten von Mobilit&#228;tsangeboten in
st&#228;dtischen und l&#228;ndlichen R&#228;umen, die Frage des Datenzugangs und die Verbesserungsm&#246;glichkeiten der
plattformgetriebenen und -&#252;bergreifenden Entwicklung des Mobilit&#228;tsangebotes.
Die Chancen, durch KI-Anwendungen eine deutliche Verbesserung der Intermodalit&#228;t bei Plattformen zu
erreichen, sind aus Sicht der Projektgruppe zwingend zu ergreifen.
Ein zentrales Anliegen, um Intermodalit&#228;t zu verbessern und Marktteilnahme f&#252;r neue Unternehmen zu
vereinfachen, sind die freie Verf&#252;gbarkeit und der standardisierte Austausch von Daten.1528 Dar&#252;ber hinaus liegt in 
diesem Themenfeld ein besonderes Augenmerk auf dem l&#228;ndlichen Raum, in dem es gilt, sowohl Carsharing und
Ridepooling zu f&#246;rdern als auch die Ausweitung des Einsatzes &#246;ffentlicher, autonom fahrender Verkehrsmittel
voranzubringen. Der Ausbau von intermodalen Plattformen &#246;ffentlicher und privater Anbieter kann dabei enorme
Vorteile bringen.
F&#252;r das private Carsharing werden neben verbesserten rechtlichen Regelungen z. B. bez&#252;glich Haftungsfragen
auch steuerliche Anreize angeregt, um dieses Modell attraktiver zu machen. Die &#220;berf&#252;hrung von Pilotprojekten
des &#246;ffentlichen Personennahverkehrs (&#214;PNV) im l&#228;ndlichen Raum in den Regelbetrieb, z. B. auf festgelegten
Strecken zwischen Verkehrszentren, sollte festes Ziel weiterer Planungen sein.
Stra&#223;enverkehr
Der Fokus der Debatte lag auf der potenziellen Nutzung des autonomen und vernetzten Fahrens, der Anwendung
von Sensorik sowie der h&#246;heren Effizienz im Logistikbereich durch KI. Dem vorgelagert wurden eine Analyse
und eine Begriffsbestimmung des Verkehrssystems Stra&#223;e und der Voraussetzungen, die es zukunftsgerichtet
mitzugestalten gilt. Die Debatte der Projektgruppe beinhaltete verschiedene Bereiche des Themenfeldes
Stra&#223;enverkehr: von Nutzerinnen und Nutzern &#252;ber das autonome Fahrzeug und die Verkehrssicherheit bis zu
Optimierungsm&#246;glichkeiten in der Logistik.
Handlungsbedarf wird in den Bereichen Forschung und F&#246;rderung gesehen: Eine Intensivierung der
Zusammenarbeit von Industrie, Forschungseinrichtungen und Beh&#246;rden ist ebenso anzustreben wie eine
(ressort&#252;bergreifende) st&#228;rkere Schwerpunktsetzung und Abstimmung der F&#246;rderlandschaften. Im Zuge dessen sollen auch die
F&#246;rderrichtlinien f&#252;r Hochschulen f&#252;r die einfachere Beteiligung sowohl von KMU als auch von Beh&#246;rden
modifiziert werden.
Schienenverkehr
Die Projektgruppe h&#228;lt fest, dass die weiterf&#252;hrende Digitalisierung und Implementierung von KI in der Mobilit&#228;t
auch und vor allem im Bereich der Schiene zu erheblichen Fortschritten in der Sicherheit, Effizienz, Planbarkeit
und Zuverl&#228;ssigkeit sowie nicht zuletzt in der &#214;kologie f&#252;hren kann. Es wurde deutlich, dass es sowohl im
Personen- als auch im G&#252;terverkehr erhebliche Herausforderungen zu bew&#228;ltigen gilt. Diese resultieren
insbesondere auch aus der &#220;berlastung des Schienennetzes in Deutschland. Diesen Herausforderungen, die sich unter dem
Stichwort &#8222;Sicherheit des Zugangs zur Mobilit&#228;t auf der Schiene&#8220; zusammenfassen lassen, gilt es sich zu stellen.
Neben den auch f&#252;r andere Themenbereiche identifizierten Schwerpunkten, wie z. B. Forschungsausbau,
Datenzugang und Abbau b&#252;rokratischer Hindernisse, wird eine Empfehlung in Bezug auf Unternehmen ausgesprochen,
die durch den Staat ma&#223;geblich gef&#246;rdert werden. Insbesondere als Hauptanteilseigner der Deutschen Bahn AG
sollen die deutsche Regierung und der Gesetzgeber ihren Einfluss geltend machen, das Unternehmen
aufzufordern und zu verpflichten, die bereits vorhandenen M&#246;glichkeiten der KI schnellstm&#246;glich umzusetzen und
Meilensteine f&#252;r den zuk&#252;nftigen Einsatz zu erarbeiten.
Luftverkehr
Im Themenschwerpunkt Luftverkehr diskutierte die Projektgruppe die M&#246;glichkeiten, durch KI-Anwendungen
die Bewegungen im Luftraum zu optimieren, die Vorteile f&#252;r Instandsetzung und Logistik zu eruieren, ebenso
die Potenziale f&#252;r die Verbesserung der &#246;kologischen Aspekte des Fliegens, M&#246;glichkeiten wie den Einsatz von
Flugtaxis und anderes mehr. Ein wichtiges Thema, das diskutiert wurde und das aufgrund seiner Komplexit&#228;t
bisher nur z&#246;gerlich Akzeptanz erf&#228;hrt, war das autonome Fliegen. 
Viele Synergie- und Effizienzgewinne durch KI im Luftverkehr lassen sich erst durch eine Vereinheitlichung des
europ&#228;ischen Luftraums (Single European Sky &#8211; SES) umsetzen. Die Umsetzung des Single European Sky sollte
deswegen vorangetrieben werden. &#220;ber den europ&#228;ischen Rahmen hinaus ist eine Interoperabilit&#228;t durch Normen
1528 Siehe auch Kapitel 1.1.1 dieses Projektgruppenberichts [Themen&#252;bergreifende Handlungsempfehlungen der Projektgruppe], Absatz 
Datennutzung/Open-Data-Strategy.
und Standards gefordert, die auf Ebene der International Civil Aviation Organization (ICAO) vereinbart und
weltweit verbindlich sind.
F&#252;r das autonome Fliegen sind eine breite Diskussion und die Festsetzung von hohen ethischen Standards
unabdingbar f&#252;r die Akzeptanz dieser Technologie.
Schiffsverkehr
In der Diskussion &#252;ber KI im Schiffsverkehr wurde deutlich, dass in dieser Branche das Thema noch
verh&#228;ltnism&#228;&#223;ig am Anfang steht, allerdings ist eine hohe Dynamik in der Entwicklung von L&#246;sungen und dem Einsatz
von KI in einzelnen Prozessbereichen zu beobachten. Digitale Optimierungsl&#246;sungen, wie sie zum Beispiel in
See- und Binnenh&#228;fen f&#252;r Logistikketten und Arbeitsabl&#228;ufe eingesetzt werden, sollten weiterentwickelt werden 
und k&#246;nnen mithilfe von KI dazu beitragen, dass Logistik und Wartung im Schiffsverkehr effizienter gestaltet
werden. 
F&#252;r die Implementierung von KI im Schiffsverkehr sind Forschungsaktivit&#228;ten, so zum Beispiel f&#252;r die
umweltfreundliche Optimierung von Lieferketten, zu verst&#228;rken und bestehende Entwicklungen zeitnah einzusetzen.
Insbesondere bei der Etablierung von intermodalen Logistikketten bietet KI ein gro&#223;es Potenzial.
&#220;bergreifende Themen (&#214;konomie und Wettbewerb sowie Stadtentwicklung)
Die Projektgruppe diskutierte, auch bezugnehmend auf die in vorherigen Sitzungen bearbeiteten Teilbereiche,
inwiefern und auf welchen Grundlagen Wirtschaftlichkeit, Wettbewerb, IT-Sicherheit und Stadtentwicklung die
Einsatzm&#246;glichkeiten von KI f&#246;rdern und optimal ausgestalten k&#246;nnen. Die Arbeit der &#8222;Wettbewerbskommission 
4.0&#8220; fand hier ebenso Eingang wie Ans&#228;tze wie &#8222;Smart City&#8220; oder das GAIA-X-Projekt. Wettbewerb als
Innovationstreiber muss die n&#246;tigen Voraussetzungen vorfinden, um die Weiterentwicklung neuer und zuk&#252;nftiger
Technologien voranbringen zu k&#246;nnen. 
Um eine Weiterentwicklung von KI-Systemen nicht unn&#246;tig zu verlangsamen, sollte deren Zertifizierung vorerst
mit den bereits existierenden Standards f&#252;r Nicht-KI-Systeme beginnen. So wird der L&#246;sungsraum erweitert. 
Dies kann bei Bedarf zu weiteren Zertifizierungsstandards f&#252;hren.
F&#252;r die Verifizierung und die Validierung von KI-Systemen wird empfohlen, ein Forschungsprogramm
aufzulegen, das mit einem Grundlagenforschungsprogramm der Deutschen Forschungsgemeinschaft (DFG) gekoppelt
ist; denn dieses Themenfeld ist noch nahezu unbearbeitet. 
Anmerkung zur Corona-Pandemie 2020
Es wird darauf hingewiesen, dass der Kontext des Berichtes aufgrund der vergangenen Entwicklungen im Zuge
der Corona-Pandemie 2020 richtig zugeordnet werden muss. Die Prognosen, auf die in den einzelnen Kapiteln
Bezug genommen wird, haben teilweise aufgrund der durch das Corona-Virus hervorgerufenen Disruptionen
insbesondere in der Luftfahrt- und Autoindustrie, aber auch im Schienenverkehr und im &#214;PNV in Teilen keine
aktuelle G&#252;ltigkeit mehr. Auf der einen Seite kann davon ausgegangen werden, dass die in diesem Teilbericht
gezeigten Trends weitergehen bzw. wiederkehren werden, auf der anderen Seite wiederum ist es aber auch
m&#246;glich, dass sich das Mobilit&#228;tsverhalten in Deutschland, Europa und der Welt ver&#228;ndern wird. Fundierte Studien 
und Prognosen lagen zum Zeitpunkt der Erarbeitung des Teilberichts &#8222;Mobilit&#228;t&#8220; nicht vor. Zu erkennen ist aber
bereits, dass es insbesondere im Luftfahrtsektor und im Automobilsektor zu erheblichen Auswirkungen und
dementsprechend auch Krisen kam.
Die Kernaussagen und Handlungsempfehlungen in diesem Bericht sind in ihrer Gesamtheit nicht davon
betroffen, jedoch die Dringlichkeit, mit der die im Bericht genannten Herausforderungen unter Zuhilfenahme von KI
angegangen werden sollen. Die Handlungsempfehlungen sollten folglich gem&#228;&#223; den Erkenntnissen zuk&#252;nftiger
Studien entsprechend priorisiert betrachtet werden.
Vorbemerkungen
Die von der Enquete-Kommission K&#252;nstliche Intelligenz eingesetzte Projektgruppe &#8222;KI und Mobilit&#228;t&#8220; hat sich
im Oktober 2019 konstituiert und bis zum 26. Juni 2020 gearbeitet. Im Folgenden finden sich n&#228;here
Informationen &#252;ber die Zusammensetzung und Arbeitsweise der Projektgruppe.
2
Expertise durch handelnde Akteure:
Mitglieder der Projektgruppe und Mitwirkende am vorliegenden Bericht:
f&#252;r die Fraktion der CDU/CSU:
&#8226; Prof. Dr. Wolfgang Ecker als sachverst&#228;ndiges Mitglied
&#8226; Dr. Sebastian Wieczorek als sachverst&#228;ndiges Mitglied
&#8226; der Abgeordnete Christoph Bernstiel (bis Januar 2020)
&#8226; der Abgeordnete Felix Schreiner (ab Januar 2020)
&#8226; der Abgeordnete Jan Metzler
&#8226; der Abgeordnete Stefan Sauer
&#8226; der Abgeordnete Ulrich Lange als stellvertretendes Mitglied (bis Januar 2020)
&#8226; der Abgeordnete Dr. Hans-Peter Friedrich als stellvertretendes Mitglied (ab Januar 2020)
f&#252;r die Fraktion der SPD:
&#8226; Lothar Schr&#246;der als sachverst&#228;ndiges Mitglied (bis Januar 2020)
&#8226; der Abgeordnete Arno Klare
&#8226; der Abgeordnete Klaus Mindrup (ab Januar 2020)
&#8226; der Abgeordnete Falko Mohrs
f&#252;r die Fraktion der AfD:
&#8226; Prof. Dr. Knut L&#246;schke als sachverst&#228;ndiges Mitglied
&#8226; der Abgeordnete Peter Felser
f&#252;r die Fraktion der FDP:
&#8226; die Abgeordnete Daniela Kluckert als Vorsitzende der Projektgruppe
&#8226; der Abgeordnete Manuel H&#246;ferlin als stellvertretendes Mitglied
f&#252;r die Fraktion DIE LINKE.:
&#8226; die Abgeordnete Anke Domscheit-Berg
&#8226; der Abgeordnete Andreas Wagner als stellvertretendes Mitglied
f&#252;r die Fraktion B&#220;NDNIS 90/DIE GR&#220;NEN:
&#8226; Prof. Dr. Hannah Bast als stellvertretendes sachverst&#228;ndiges Mitglied
&#8226; der Abgeordnete Dieter Janecek
Vorgehensweise und Arbeitsstruktur
Unter dem Vorsitz der Abgeordneten Daniela Kluckert (FDP) trafen sich die oben genannten Abgeordneten und
Sachverst&#228;ndigen zu regelm&#228;&#223;igen Projektgruppensitzungen sowie einer Klausurtagung, um sich vorab
definierten Schwerpunktthemen zur Rolle der KI im Bereich der Mobilit&#228;t zu widmen. Auf den in diesen Treffen
gewonnenen Erkenntnissen fu&#223;t der hier vorliegende Berichtsteil.
Die Mannigfaltigkeit der Einsatzfelder, Einsatzm&#246;glichkeiten und (Noch-)Nischenbereiche erforderte &#8211; aufgrund
der zeitlichen M&#246;glichkeiten der Projektgruppe und ihrer Kapazit&#228;ten &#8211; die Konzentration auf
Schwerpunktthemen. In ihrer konstituierenden Sitzung im Oktober 2019 einigten die Mitglieder sich auf die folgenden: Zukunft
der Mobilit&#228;t, Schiene, Luft, Schiffsverkehr, Stra&#223;e, Intermodalit&#228;t/Plattformen sowie &#252;bergreifende Themen.
Um die thematische Breite des Untersuchungsbereichs &#8222;KI und Mobilit&#228;t&#8220; zu strukturieren, arbeitete die
Projektgruppe zun&#228;chst die obigen Themenfelder heraus, in denen KI bereits erfolgreich zum Einsatz kommt bzw. einen
besonderen Nutzwert erwarten l&#228;sst bzw. wo sich ein spezifischer rechtlicher Regelungsbedarf abzeichnet.
Diese Themenfelder wurden in inhaltlich vorbereiteten monatlichen Sitzungen in der Zeit vom November 2019
bis einschlie&#223;lich M&#228;rz 2020 eingehend diskutiert. Mithilfe gemeinsam ausgew&#228;hlter weiterer hochrangiger
Anh&#246;rpersonen, die in Vortr&#228;gen ihre spezifische Expertise in den Diskussionsprozess einflie&#223;en lie&#223;en, wurde
dieser Arbeitsprozess nach und nach vertieft.
Den Vortr&#228;gen lag jeweils ein in der Arbeitsgruppe abgestimmter Fragenkatalog zugrunde, in dem Potenziale der
Themenfelder skizziert und mit m&#246;glichen Zielen verkn&#252;pft wurden; dieser Fragenkatalog diente den
Vortragenden als Orientierung. Zudem wurden die Anh&#246;rpersonen gebeten, Handlungsvorschl&#228;ge an die Politik zu
formulieren, die ihnen ganz besonders dringlich erscheinen. Diese Handlungsvorschl&#228;ge flossen unmittelbar in den
Urteilsfindungsprozess der Projektgruppe f&#252;r die parlamentarischen Handlungsvorschl&#228;ge ein.
Es fanden folgende Sitzungen mit folgenden externen Expertinnen und Experten statt:
4. November 2019 &#8211; Zukunft der Mobilit&#228;t:
&#8226; Alexander Mankowsky, Daimler AG
&#8226; Prof. Dr. Stephan Rammler, Institut f&#252;r Zukunftsstudien und Technologiebewertung (IZT)
11. November 2019 &#8211; Schiene:
&#8226; Yves Sterbak, Protostellar GmbH; Thales Deutschland GmbH
&#8226; Dr.-Ing. Thomas Thiele, Think Tank Digitalisierung &amp; Technik (TA) &amp; Data Intelligence Center (TDXD) &#8211;
House of AI Deutsche Bahn AG
9. Dezember 2019 &#8211; Luft und Schiffsverkehr:
&#8226; Dr. Christian Seidel, Airbus Helicopters Deutschland GmbH
&#8226; Prof. Dr.-Ing. Thomas Schlipk&#246;ther, Duisburger Hafen AG
16. Dezember 2019 &#8211; Stra&#223;e:
&#8226; Julia Miosga, DieDigitalLandschaftsG&#228;rtnerin
&#8226; Andreas Karanas, Carrypicker GmbH
&#8226; Prof. Dr.-Ing. Thomas Form, Volkswagen AG
&#8226; Demetrio Aiello, Continental AG
&#8226; Dr. Manuel G&#246;tz, Zahnradfabrik Friedrichshafen
13. Januar 2020 &#8211; Intermodalit&#228;t / Plattformen:
&#8226; Dr. Sabine Seelenmeyer, SAP SE
&#8226; Dr. Tim Wiegels, Free Now AG
&#8226; Christoph Weigler, Uber Germany GmbH
10. Februar 2020 &#8211; &#220;bergreifende Themen
&#8226; Prof. Dr. Daniel Zimmer, Universit&#228;t Bonn
&#8226; Prof. Dr. Klaus Beckmann, Deutsche Akademie der Technikwissenschaften/acatech
&#8226; Dr. Dietmar C. Schl&#246;&#223;er, T&#220;V NORD AG (schriftliche Stellungnahme)
Einf&#252;hrung
Nach allgemeinem Verst&#228;ndnis umfasst der Begriff der Mobilit&#228;t das (Sich-)Bewegen von Individuen und
Gruppen. Flexibilisierung und Beschleunigung des Transports von Personen, G&#252;tern und Daten machen Mobilit&#228;t
heute weltweit zu einem Charakteristikum moderner Gesellschaften. Viele Aspekte unseres t&#228;glichen Lebens,
der demografischen und wirtschaftlichen Entwicklung sowie des Konsumverhaltens der Menschen haben zu
einer Steigerung der Mobilit&#228;t in unserem Land gef&#252;hrt. 
3
Verkehr und Mobilit&#228;t als Ganzes werden sich weiter strukturell und technisch ver&#228;ndern. Mobilit&#228;t steht derzeit
weltweit durch Entwicklungen wie Urbanisierung und Landflucht, Klimawandel und Digitalisierung vor
weitreichenden Herausforderungen. Die Verkehrsentwicklung unterscheidet sich je nach Verkehrsmittel und Region
deutlich. Hieraus ergibt sich ein deutlicher Handlungsbedarf in der Verkehrsplanung sowie in der
Weiterentwicklung von Mobilit&#228;tskonzepten und -technologien.
Die Weiterentwicklung der Mobilit&#228;t und die Verkehrswende in Deutschland sind elementare Herausforderungen 
auf dem Weg zu den internationalen und nationalen Klimazielen. So entfallen zum Beispiel 18 Prozent der
globalen CO2-Emissionen auf den Stra&#223;enverkehr.1529 KI hat das Potenzial, den Personen- wie auch den
G&#252;terverkehr zukunftsweisend zu ver&#228;ndern. So kann KI eine sicherere, barrierefreiere, flexiblere, kosteng&#252;nstigere und
umweltvertr&#228;glichere Fortbewegung auf der Stra&#223;e, der Schiene sowie im Luft- und Schiffsverkehr erm&#246;glichen. 
Die Nutzung von Plattformen kann durch Lernende Systeme unterst&#252;tzt werden, neue individuelle oder kollektive
M&#246;glichkeiten k&#246;nnen erschlossen werden. Der G&#252;terverkehr kann durch vernetzte, inter- und multimodale
Mobilit&#228;t effizienter und somit auch umweltschonender gestaltet werden. Diese Effekte sind bereits heute erkennbar.
KI hat in der Logistik nicht nur bei der eigentlichen Verkehrssteuerung ein gro&#223;es Potenzial, sondern
insbesondere auch bei Begleitfaktoren wie zum Beispiel bei b&#252;rokratischen Anforderungen und Dokumentationspflichten, 
Warenverarbeitung und Abfertigungen. Im Koalitionsvertrag aus dem Jahr 2018 sind verschiedene
Mobilit&#228;tsziele der Bundesregierung verankert, auf die im weiteren Verlauf des Teilberichts Mobilit&#228;t detailliert
eingegangen wird.
Daten bzw. der Zugang zu geeigneten Daten ist auch im Bereich der Mobilit&#228;t von entscheidender Bedeutung,
insbesondere Echtzeitdaten sind hier von gro&#223;er Relevanz. M&#246;gliche Datenquellen sind dabei sehr vielf&#228;ltig, von 
Sensoren, die in Fahrzeugen und Infrastrukturen verbaut sind, &#252;ber Positions- und Bewegungsdaten aus
Fahrzeugen, Z&#252;gen, Containern oder mobilen Endger&#228;ten bis hin zu Wetterdaten. Dabei handelt sich sowohl um
nichtpersonenbezogene als auch &#8211; insbesondere bei Positions- und Bewegungsdaten aus PKW oder digitalen
Endger&#228;ten &#8211; um personenbezogene Daten. Entsprechend wichtig sind im Bereich der Mobilit&#228;t Fragen der
Datensouver&#228;nit&#228;t und der informationellen Selbstbestimmung (siehe hierzu auch das Kapitel 2 des Mantelberichts [KI 
und Daten]).
Auf Fragen des Schutzes und der Sicherheit von Daten muss ein europ&#228;ischer Ansatz zur Entwicklung und
Implementierung von KI in der Mobilit&#228;t Antworten geben. Gleiches gilt f&#252;r Fragen des Wettbewerbs und des
Kartellrechts.
Der vorliegende Bericht untersucht die Potenziale der KI, die politischen Rahmenbedingungen sowie
ausgesuchte Bereiche der Mobilit&#228;t. Die Vielfalt der Einsatzfelder und Einsatzm&#246;glichkeiten bis hin zu
Nischenbereichen f&#252;hrte zu einer Konzentration der Projektgruppenarbeit auf die Themenfelder Zukunft der Mobilit&#228;t,
Intermodalit&#228;t und Plattformen, Stra&#223;e, Schiene, Luft- und Schiffsverkehr sowie &#252;bergreifenden Themen wie
Stadt&#246;konomie und Wettbewerbsrecht.
4 Thematischer Schwerpunkt und Handlungsempfehlungen
Zukunft der Mobilit&#228;t
4.1.1 Vision KI und Mobilit&#228;t &#8211; Status quo
Gesellschaft
Deutschland wird immer mobiler. Eine Erhebung zur Mobilit&#228;t in Deutschland (MiD) aus dem Jahre 2017 hat
ergeben, dass t&#228;glich rund 3,2 Milliarden Kilometer zur&#252;ckgelegt werden. Das ist eine Steigerung von 4 Prozent
(113 Millionen Kilometer) im Vergleich zu 2008.1530 Ursachen hierf&#252;r sind neben der Zunahme der Bev&#246;lkerung 
auch der Anstieg der Wirtschaftsleistung in den letzten Jahren sowie die Zunahme des Lieferverkehrs durch ein
ver&#228;ndertes Konsumverhalten (z. B. durch Online-Shopping). So stieg exemplarisch die beruflich bedingte
Wegstrecke um 13 Prozent an. Handwerksbetriebe, Pflegedienste, Kurier- und Paketdienste sind immer zahlreicher
auf den Stra&#223;en Deutschlands unterwegs.1531 Auf der anderen Seite l&#228;sst u. a. der (individuelle) Freizeitverkehr
leicht nach.
1529 Vgl. Statista (2020): Anteil der Verkehrstr&#228;ger an den weltweiten CO2-Emissionen aus der Verbrennung fossiler Brennstoffe im Jahr 2016.
1530 Vgl. Bundesministerium f&#252;r Verkehr und digitale Infrastruktur (2020): Mobilit&#228;t in Deutschland.
1531 Vgl. Nobis et al. (2019): Mobilit&#228;t in Deutschland, S. 60.
Die Verkehrsentwicklung unterscheidet sich je nach Verkehrsmittel und Region deutlich und f&#252;hrt zu vielseitigen 
Herausforderungen: Einem mangelnden Angebot des &#246;ffentlichen Nahverkehrs im l&#228;ndlichen Raum steht die
&#220;berlastung des Verkehrs in Metropolregionen gegen&#252;ber. Weitere Herausforderungen sind die Stauvermeidung
bei viel befahrenen Pendlerstrecken sowie die Reduktion der Logistikbelastung durch eine Effizienzsteigerung
im G&#252;terverkehr &#252;ber die Stra&#223;e hinaus, sei es u. a. in der Verarbeitung von Paketzustellungen oder den
&#220;bergangsphasen zum Beispiel zwischen Schiene und Stra&#223;e.1532 
Insbesondere in St&#228;dten nimmt der Radverkehr seit Jahren stetig zu. Daher ist vor allem die kommunale
Verkehrspolitik gefordert, die Verkehrsinfrastruktur entsprechend weiterzuentwickeln. Global betrachtet ist die
Verkehrssituation in Deutschland im Vergleich zu Megast&#228;dten in anderen Teilen der Welt wie z. B. Los Angeles,
Mexico City oder Peking gut.1533 Dennoch steht die Mobilit&#228;t in unserem Land vor gro&#223;en Ver&#228;nderungen, bei
deren Bew&#228;ltigung KI eine wichtige Rolle spielen sollte.1534 
In Deutschland ist die Urbanisierungsrate bereits sehr hoch &#8211; mit steigender Tendenz: In den gr&#246;&#223;ten St&#228;dten des
Landes, in Berlin, Hamburg, M&#252;nchen, K&#246;ln oder Frankfurt, in verschiedenen kleineren und mittelgro&#223;en
Gro&#223;st&#228;dten wie z. B. Freiburg, M&#252;nster oder Regensburg und in einigen suburbanen Regionen zum Beispiel in 
Oberbayern w&#228;chst derzeit die Bev&#246;lkerung stetig, w&#228;hrend in zahlreichen l&#228;ndlichen Regionen und auch in
vielen Klein- und manchen Mittelst&#228;dten die Bev&#246;lkerungszahlen sinken.1535 Der Anteil der st&#228;dtischen
Bev&#246;lkerung an der deutschen Gesamtbev&#246;lkerung liegt mit Stand des Jahres 2018 bei 77,3 Prozent.1536 Prognosen
zufolge wird dieser Anteil bis 2035 auf &#252;ber 80 Prozent ansteigen.1537 Diese Entwicklung zwingt zu einem
Umdenken im Mobilit&#228;tssektor, wenn die Menschen sowohl mobil als auch gesundheits- und umweltvertr&#228;glich in 
St&#228;dten leben wollen. Sie profitieren bereits heute von Navigationsdiensten und unterschiedlichen Sharing-
Angeboten insbesondere im urbanen Raum. In Teilen wird hier bereits heute &#252;ber die reine Digitalisierung hinaus
KI eingesetzt.
Die Verkehrswende ist eine der zentralen Herausforderungen und gilt als wichtiger Baustein auf dem Weg zum
Erreichen der internationalen und nationalen Klimaziele. Rund 22 Prozent der energiebedingten CO2-Emissionen
in Deutschland entfallen auf den Stra&#223;enverkehr.1538 Durch digitalisierte Vorg&#228;nge und die Anwendung von
Maschinellem Lernen1539 k&#246;nnen entscheidende Effekte entstehen, die die Ziele des Pariser Klimaabkommens von
2015 unterst&#252;tzen.
Die Vision f&#252;r eine zukunftsf&#228;hige Mobilit&#228;t l&#228;sst sich somit wie folgt zusammenfassen: komfortable und
gleichzeitig klima- und umweltfreundliche, sozial gerechte, barrierefreie und bezahlbare Mobilit&#228;t f&#252;r alle Menschen
und Nutzergruppen. Mobilit&#228;t der Zukunft soll eine effiziente, klima- und umweltfreundliche G&#252;terlogistik
erm&#246;glichen und unn&#246;tige Verkehrsbewegungen vermeiden. Dieser Bericht er&#246;rtert, wie KI-Anwendungen dazu
beitragen k&#246;nnen, dass diese Vision verwirklicht wird. Deutschland soll sowohl etablierten Unternehmen als
auch Start-ups die entsprechenden Rahmenbedingungen f&#252;r einen Heimatmarkt f&#252;r entsprechende Innovationen 
schaffen.
Markt
F&#252;r zahlreiche Anwendungen in den Bereichen &#214;PNV, Bahn- und Flugverkehr, Logistik und Schiffsverkehr, im
Bereich Automobil und Kraftrad sowie ganz zentral f&#252;r die intelligente Vernetzung unterschiedlicher
Verkehrstr&#228;ger k&#246;nnen Anwendungen aus dem Bereich KI helfen, auf die eingangs skizzierten Herausforderungen zu
reagieren. Entsprechend ver&#228;ndert sich der Mobilit&#228;tsmarkt. Maschinelles Lernen kann eine sicherere, flexiblere,
kosteng&#252;nstigere und umweltvertr&#228;glichere Fortbewegung auf der Stra&#223;e, der Schiene sowie im Luft- und 
Schiffsverkehr erm&#246;glichen. Lernende Systeme k&#246;nnen die Nutzung von Plattformen unterst&#252;tzen und dadurch
1532 Vgl. Lobig et al. (2016): Verkehrsverlagerungspotenzial auf den Schieneng&#252;terverkehr in Deutschland.
1533 Vgl. TomTom: Traffic Index.
1534 Die Plattform f&#252;r K&#252;nstliche Intelligenz, eine gemeinsame Initiative des Bundesministeriums f&#252;r Bildung und Forschung und der
Deutschen Akademie der Wissenschaften zum Wissenschaftsjahr 2019 bietet eine umfangreiche &#220;bersicht &#252;ber die Anwendung von
KI im Mobilit&#228;tsbereich. Diese ist in ihrer Qualit&#228;t hervorzuheben und stellt dementsprechend eine gute Grundlage f&#252;r diesen
Berichtsteil dar, vgl. Plattform Lernende Systeme (2019): Auf dem Weg zu einem intelligenten Mobilit&#228;tsraum.
1535 Vgl. Bundesministerium des Innern, f&#252;r Bau und Heimat (2019): Binnenwanderung.
1536 Vgl. Weltbank (2018): Urban population (% of total population) &#8211; Germany.
1537 Vgl. Statista (2018): Anteil von Stadt- und Landbewohnern in Deutschland von 1990 bis 2015 und Prognose bis 2050.
1538 Vgl. Umweltbundesamt (2020): Energiebedingte Emissionen.
1539 Siehe auch Kapitel 1.1 [KI-Systeme und KI-Arten] und Kapitel 1.2 [Training von lernenden KI-Systemen] des Mantelberichts.
neue individuelle oder kollektive M&#246;glichkeiten erschlie&#223;en. Dazu geh&#246;rt, dass Individual- und
Kollektivverhalten umfangreich analysiert und somit nutzbar gemacht wird.
Diese Potenziale lassen sich nicht nur im Personen-, sondern auch im G&#252;terverkehr identifizieren. Durch
vernetzte, inter- und multimodale Mobilit&#228;t l&#228;sst sich der G&#252;terverkehr effizienter und somit auch umweltschonender
gestalten. Diese Effekte lassen sich bereits heute in der Logistik erkennen. Gerade hinsichtlich der Nutzung des 
Maschinellen Lernens muss das Potenzial der Mobilit&#228;tsoptionen noch weiter und vernetzter gedacht werden.
Sowohl bei der Verkehrssteuerung und Auslastung als auch bei Begleitfaktoren wie bei b&#252;rokratischen
Anforderungen und Dokumentationspflichten, Warenverarbeitung und Abfertigungen k&#246;nnen noch deutliche Effekte
erzielt werden.
Im Energiebereich, u. a. beim Rollout1540 der Elektromobilit&#228;t, unterst&#252;tzt KI insbesondere die
&#8222;Sektorkopplung&#8220;1541 zwischen dem Verkehrs- und Energiesektor durch die smarte Steuerung von Ladevorg&#228;ngen oder die
Bereitstellung von Regelenergie aus den Batterien von Elektrofahrzeugen.
Politik
Auf Bundesebene gibt es verschiedene, von der Bundesregierung formulierte Mobilit&#228;tsziele, die, wie oben
beschrieben, im Koalitionsvertrag verankert wurden. Obgleich der Bereich KI im Mobilit&#228;tssektor noch kein
umfangreicher Aspekt ist, werden andere Themen wie der Rechtsrahmen f&#252;r potenzielle Nutzungen autonomen
Fahrens, die F&#246;rderung f&#252;r Forschung und die Erweiterung von Mobilit&#228;tsoptionen genannt. Die Bundesregierung
plant u. a. die Einrichtung neuer digitaler Testfelder f&#252;r das autonome Fahren. Hierf&#252;r sollen die n&#246;tigen
rechtlichen Voraussetzungen f&#252;r die Erprobung und Weiterentwicklung des autonomen Fahrens auf allen
Verkehrstr&#228;gern geschaffen werden. Zus&#228;tzlich soll der Rechtsrahmen f&#252;r neue Mobilit&#228;tsangebote mit
Steuerungsm&#246;glichkeiten durch die Kommunen ge&#246;ffnet werden.1542 
Die bundespolitische Arbeit fokussiert sich hierbei besonders auf den Forschungsbereich. So wurde in einem
&#252;bergreifenden Aktionsplan zum Thema &#8222;Forschung f&#252;r autonomes Fahren&#8220; zusammen mit den
Bundesministerien f&#252;r Bildung und Forschung (BMBF), Wirtschaft und Energie (BMWi) sowie dem BMVI im Juli 2019 ein
Rahmen geschaffen.1543 Die Hightech-Strategie (HTS) soll als ressort&#252;bergreifende Forschungs- und
Innovationsstrategie weiterentwickelt und auf die gro&#223;en Herausforderungen, u. a. die der Digitalisierung und Mobilit&#228;t,
ausgerichtet werden. Es wird verst&#228;rkt die gesamte Breite von Mobilit&#228;tsangeboten auch unter klimapolitischen
sowie gesellschafts- und sozialwissenschaftlichen Aspekten betrachtet.1544 
Dar&#252;ber hinaus besitzt KI das Potenzial der erh&#246;hten Verkehrssicherheit. Sie kann helfen, das Ziel zu erreichen, 
das im Jahr 2007 vom Deutschen Verkehrssicherheitsrat (DVR) in der &#8222;Vision Zero&#8220; formuliert wurde, n&#228;mlich 
keine Toten und Schwerverletzten im Stra&#223;enverkehr mehr zu haben.1545 Die Bundesregierung verpflichtet sich 
der &#8222;Vision Zero&#8220;.1546 Die Bedeutung von KI-Anwendungen f&#252;r die Stra&#223;enverkehrssicherheit wird dabei z. B. 
in der Debatte um einen besseren Schutz von Radfahrerinnen und Radfahrern oder Fu&#223;g&#228;ngerinnen und
Fu&#223;g&#228;ngern im Stra&#223;enverkehr durch die Einf&#252;hrung von Abbiegeassistenten f&#252;r LKW, wie sie auch der Deutsche
Bundestag fordert, deutlich.1547 So k&#246;nnten nach Angaben der Unfallforschung der Versicherer (UDV) in
Deutschland durch elektronische Abbiegeassistenten 60 Prozent der Unf&#228;lle zwischen Lkw und Radfahrerinnen bzw.
Radfahrern verhindert oder zumindest abgeschw&#228;cht werden.1548 
1540 Roll-Out bezeichnet hier die Markteinf&#252;hrung.
1541 Unter Sektorkopplung versteht man die Vernetzung der Sektoren der Energiewirtschaft sowie der Industrie, die gekoppelt, also in
einem ganzheitlichen Ansatz optimiert werden sollen. Durch den verst&#228;rkten Einsatz von Strom aus Erneuerbaren Energien als Ersatz 
f&#252;r fossile Energietr&#228;ger in den Sektoren Verkehr, W&#228;rme und Industrie soll ein Beitrag zum Erreichen der Klimaschutzziele geleistet
werden; vgl. Wietschel et al. (2018): Sektorkopplung.
1542 Vgl. CDU, CSU, SPD (2018): Ein neuer Aufbruch f&#252;r Europa Eine neue Dynamik f&#252;r Deutschland Ein neuer Zusammenhalt f&#252;r 
unser Land.
1543 Vgl. Bundesministerium f&#252;r Bildung und Forschung; Bundesministerium f&#252;r Wirtschaft und Energie; Bundesministerium f&#252;r Verkehr
und digitale Infrastruktur (2019): Forschung f&#252;r autonomes Fahren.
1544 Vgl. Bundesministerium f&#252;r Bildung und Forschung (2018): Forschung und Innovation f&#252;r die Menschen.
1545 Vgl. Deutscher Verkehrssicherheitsrat: Vision Zero.
1546 Vgl. CDU, CSU, SPD (2018): Ein neuer Aufbruch f&#252;r Europa Eine neue Dynamik f&#252;r Deutschland Ein neuer Zusammenhalt f&#252;r
unser Land, S. 79.
1547 Vgl. interfraktioneller Antrag auf Bundestagsdrucksache 19/2984.
1548 Vgl. Unfallforschung der Versicherer (2017): Unf&#228;lle mit schweren Lkw enden oft t&#246;dlich. UDV: Technische Ma&#223;nahmen schnell
umsetzen.
Der Aspekt der Infrastruktur wird auf politischer Ebene ebenfalls als bedeutender Faktor herausgestellt. Neben
Investitionen in die Verkehrstechnik muss weiter an dem z&#252;gigen Ausbau der Informations- und
Kommunikationstechnik gearbeitet werden. Dies betrifft neben einem Breitband-Gigabit- und einem 4G-Netz insbesondere
die Mobilfunktechnologie 5G. Im Zuge der vergangenen Frequenzvergabe wurden die Auflagen geschaffen, im
l&#228;ndlichen Raum, an Bundesfernstra&#223;en, dann auch im nachgeordneten Stra&#223;ennetz und schlie&#223;lich an allen
Bahnstrecken den Empfang dauerhaft sicherzustellen, um so innovative und zukunftsf&#228;hige Mobilit&#228;tsangebote
zu etablieren.1549 
4.1.2 Anwendungsbeispiele, Trends und Ausblicke der einzelnen Themenfelder
Im Folgenden werden einleitend erste Anwendungsbeispiele, Trends und Ausblicke f&#252;r die einzelnen
Themenbereiche der Projektgruppe Mobilit&#228;t, sprich die Sektoren &#8222;Intermodalit&#228;t und Plattformen&#8220;, &#8222;Stra&#223;e&#8220;, &#8222;Schiene&#8220;, 
&#8222;Luftfahrt&#8220; und &#8222;Schiffsverkehr&#8220; dargestellt. So soll ein erster &#220;berblick geschaffen werden, um anschlie&#223;end 
in den darauffolgenden Berichtsabschnitten n&#228;her auf die einzelnen Aspekte einzugehen.
Vernetzung und Intermodalit&#228;t in der Mobilit&#228;t
KI-Anwendungen kommt insbesondere bei der l&#252;ckenlosen intermodalen Vernetzung unterschiedlicher
Verkehrstr&#228;ger und der geteilten Nutzung von Fahrzeugen eine Schl&#252;sselrolle zu. Letztlich handelt es hierbei um
eine Optimierungsfrage &#8211; also Vorschlag und Auswahl (bei Bedarf inklusive Ticketbuchung) eines Weges von
A nach B, wobei alle verf&#252;gbaren Verkehrsmittel einbezogen werden: der taktgebundene &#246;ffentliche
Personennah- und Fernverkehr, der geteilte und eigene PKW, motorisierte Zweir&#228;der oder Fahrr&#228;der und neuartige On-
Demand- und Ridesharing-Angebote. Daneben werden auch Parameter wie Dauer, Kosten, Qualit&#228;t1550 und
eventuell weitere wie der &#246;kologische Fu&#223;abdruck ber&#252;cksichtigt.
Dar&#252;ber hinausdenkend werden potenziell auch weitere Verkehrstr&#228;ger immer mehr in die Vernetzung
eingebunden, so zum Beispiel der Flugverkehr durch den Einsatz von Drohnen oder Flugtaxis. Der G&#252;terverkehr und der
Logistikbereich lassen sich ebenfalls &#252;ber Vernetzung und Intermodalit&#228;t optimieren, sei es bei LKW- und
Schienenverkehr, aber auch bei Luft- und Schiffsfracht.
Neben der Verbindung unterschiedlicher Verkehrstr&#228;ger und der Schaffung echter Interoperabilit&#228;t spielen KI-
Anwendungen f&#252;r jeden einzelnen Verkehrstr&#228;ger selbst eine Rolle bei der Optimierung der Nutzung, der
Verbesserung von Sicherheit und Komfort des Reisens, der Sicherstellung von Betriebsstabilit&#228;t und der
Minimierung von Ausf&#228;llen und Verschlei&#223;.1551 
Das Kapitel 4.2 dieses Projektgruppenberichts [Intermodalit&#228;t und Plattformen] befasst sich mit den
unterschiedlichen Anwendungsbereichen z. B. im innerst&#228;dtischen Raum und im l&#228;ndlichen Raum, aber auch mit den
M&#246;glichkeiten einer gemeinn&#252;tzigen KI-L&#246;sung zur St&#228;rkung des &#214;PNV sowie des Fu&#223;- und Radverkehrs.
Stra&#223;e
Schon heute kommen auf den Stra&#223;en immer mehr automatisierte und vernetzte Anwendungen zum Einsatz, so
z. B. personalisierte Navigationssysteme f&#252;r Routenempfehlungen. Dadurch wird der Verkehr individuell bereits
effizienter gestaltet. Autonom fahrende Kleinbusse, die schon heute in Modellversuchen an verschiedenen Orten
in Deutschland und anderswo getestet werden, k&#246;nnten zuk&#252;nftig kosteng&#252;nstig und nachfrageorientiert
Busverkehr auch dort erm&#246;glichen, wo heute oftmals kein ausreichendes &#214;PNV-Angebot bereitgestellt wird &#8211; auf
weitl&#228;ufigen Werks- und Gewerbegel&#228;nden, in einer Kleinstadt oder zur Anbindung einer Wohnsiedlung oder eines
Universit&#228;tscampus an den n&#228;chsten Schienenverkehrshalt. F&#252;r kurze Entfernungen, auf bekanntem bzw.
trainiertem Terrain und mit geringen Geschwindigkeiten werden derartige selbstfahrende Fahrzeuge technisch
bereits erprobt und kurz- bis mittelfristig unter ausgew&#228;hlten Rahmenbedingungen eingesetzt werden.1552 Gerade
f&#252;r Menschen, die nicht gut zu Fu&#223; bzw. die mit Gep&#228;ck oder Eink&#228;ufen unterwegs sind, kann dies einen
erheblichen Gewinn an Mobilit&#228;t bedeuten. KI-Anwendungen spielen hierbei nicht nur f&#252;r die autonome
Fahrzeugsteuerung eine zentrale Rolle, sondern sind auch f&#252;r die flexible Nachfragesteuerung von gro&#223;er Bedeutung.
1549 Vgl. Bundesnetzagentur (2020): Mobiles Breitband.
1550 Unter Qualit&#228;t k&#246;nnen verschiedene Aspekte der Mobilit&#228;t stehen: Komfort, Flexibilit&#228;t oder auch Service durch Vernetzung.
1551 Vgl. Bundesministerium f&#252;r Verkehr und digitale Infrastruktur (2018): Digitalisierung und K&#252;nstliche Intelligenz in der Mobilit&#228;t,
S. 17. Darstellung von Dr. Thomas Thiele (Think Tank Digitalisierung &amp; Technik (TA) &amp; Data Intelligence Center (TDXD) &#8211; House
of AI Deutsche Bahn AG) in der Sitzung der Projektgruppe KI und Mobilit&#228;t am 11. November 2019.
1552 Weitere Informationen dazu unter: https://www.vdv.de/liste-autonome-shuttle-bus-projekte.aspx (zuletzt abgerufen am 24. Juli 2020).
Au&#223;erdem ergeben sich durch KI im Personen- wie auch im Warenverkehr Optimierungspotenziale,
insbesondere angesichts des Personalmangels bei Verkehrs- und Logistikunternehmen.1553 Die Digitalisierung und
Vernetzung des Verkehrsraums erm&#246;glichen es zus&#228;tzlich, die physische Infrastruktur kostensparend und flexibel zu
nutzen. Zu der Frage, wann ein vollst&#228;ndig autonom fahrender PKW f&#252;r die komplexen Verkehrsverh&#228;ltnisse in 
Deutschland und Europa, im Stadtverkehr in Interaktion mit Fu&#223;g&#228;ngerinnen und Fu&#223;g&#228;ngern sowie
Radfahrerinnen und Radfahrern, auf teils engen und schmalen Stra&#223;en, serienm&#228;&#223;ig zum Einsatz kommen kann, gehen die
Einsch&#228;tzungen von Fachleuten und Autoindustrie teils weit auseinander.1554 Langfristig ist es auch in Europa
Ziel, vollst&#228;ndig autonomes Fahren zu erm&#246;glichen. Aber bereits unterhalb der Schwelle zur vollst&#228;ndigen
Autonomie k&#246;nnen KI-Anwendungen im PKW dazu beitragen, die Sicherheit des Stra&#223;enverkehrs zu verbessern,
Brems- und Beschleunigungsvorg&#228;nge zu verringern, den Verkehr dadurch fl&#252;ssiger zu machen und so auch den
Energieaufwand von Fahrzeugen zu reduzieren.
Bevor diese Potenziale realisiert werden k&#246;nnen, m&#252;ssen aber verschiedene rechtliche Fragen hinsichtlich des
vollautonomen Fahrens gekl&#228;rt werden. Hierzu sieht das Stra&#223;enverkehrsgesetz (StVG) bislang noch keine klaren
Regularien vor. Hier m&#252;ssen die entsprechenden Bundestagsaussch&#252;sse zukunftsorientiert an L&#246;sungen arbeiten,
um den Rechtsrahmen nicht zu einem Innovationshemmnis zu machen. Zwar wurde mit &#167; 1a Absatz 1 StVG ab
dem 21. Juni 2017 der Betrieb eines Kraftfahrzeugs &#8222;mittels hoch- oder vollautomatisierter Fahrfunktion&#8220;
grunds&#228;tzlich zul&#228;ssig, dies gilt jedoch nur dann, wenn die Funktion &#8222;bestimmungsgem&#228;&#223; verwendet&#8220;1555 wird. Die
Person am Steuer d&#252;rfe sich w&#228;hrend des Betriebs dieser Fahrfunktion vom Verkehrsgeschehen und der
Fahrzeugsteuerung abwenden. Sie m&#252;sse aber &#8222;wahrnehmungsbereit&#8220; bleiben, sodass sie die Fahrzeugsteuerung
unverz&#252;glich &#252;bernehmen k&#246;nne, wenn sie das System dazu auffordere. Automatisiertes Fahren auf den Stufen 3
und 4 werde somit erm&#246;glicht, jedoch nicht das &#8222;vollautonome Fahren&#8220; auf Stufe 5.1556 
Das autonome Fahren stellt in Kapitel 4.3 dieses Projektgruppenberichts [Stra&#223;enverkehr] einen Kernaspekt dar.
Dar&#252;ber hinaus werden die Organisation der Stra&#223;e im Bereich der KI, die Frage der Sicherheitserh&#246;hung sowie
der Personen- und G&#252;terverkehr behandelt.
Bahnverkehr
Ein wesentliches Einsatzfeld von Lernenden Systemen im Schienenverkehr ist auch hier das automatisierte bzw.
fahrerlose Fahren. Solches Fahren erm&#246;glicht bei Stra&#223;enbahnen, U-Bahnen, S-Bahnen und anderen Z&#252;gen des
Personen- und G&#252;terverkehrs eine h&#246;here Kapazit&#228;t des Schienennetzes. Dar&#252;ber hinaus kann das
Verkehrssystem besser auf den Bedarf der Kundinnen und Kunden zugeschnitten und optimiert werden. Beispielhaft hierf&#252;r
sind flexiblere und k&#252;rzere Taktungen des &#246;ffentlichen Verkehrs und eine angepasste Bef&#246;rderungskapazit&#228;t.
Durch KI-Einsatz in der Fahrzeugwartung lassen sich Fahrzeugausf&#228;lle reduzieren, die Betriebsstabilit&#228;t erh&#246;hen
und Zugausf&#228;lle und Versp&#228;tungen vermeiden. Die Schweiz hat sich zum Ziel gesetzt, die Auslastung ihres
bereits dicht befahrenen Streckennetzes mittels KI um 30 Prozent zu steigern1557 &#8211; KI in der Leitstelle kann z. B. 
den Fahrplan laufend &#252;berpr&#252;fen und Unregelm&#228;&#223;igkeiten beheben, was die Stabilit&#228;t des Fahrplans erh&#246;ht.
Automatisierte, fahrerlose Schienensysteme werden weltweit bereits bei U-Bahnen1558 oder an Flugh&#228;fen
eingesetzt. Auch gibt es infrastrukturintensive Sicherungssysteme (z. B. das European Train Control System &#8211;
ETCS1559) welche die Automatisierung im Schienenverkehr regeln. Diese werden vor allem in abgeschlossenen 
Systemen verwendet, d. h. solchen, die keine Wechselwirkung mit anderen Transportmodalit&#228;ten aufweisen. Im
Mischverkehr oder auf Strecken, die mit weniger Sicherungsinfrastruktur ausgestattet sind, ben&#246;tigt das
automatisierte Fahren im Vergleich dazu bisher nach wie vor auch den Menschen im Fahrzeug. Hier besteht ein
zuk&#252;nftiger Ansatz darin, dass die Technologie entsprechend den heutigen T&#228;tigkeiten der Person, die das Triebfahrzeug
1553 Vgl. Kohl und Pfretzschner: Logistikmonitor 2018.
1554 Diese Schlussfolgerung zieht z. B. der Automobilhersteller Toyota. Einige Sch&#228;tzungen gehen von 2025 aus, andere wiederum von 
2030, vgl. Toyota: Selbstfahrende Autos.
1555 Eine bestimmungsgem&#228;&#223;e Verwendung liegt z. B. nicht vor, wenn der Hersteller die automatische Fahrfunktion nur f&#252;r den Einsatz 
auf der Autobahn vorsieht, die Fahrerin oder der Fahrer sie aber auch auf der Landstra&#223;e verwendet.
1556 Vgl. Die Wissenschaftlichen Dienste des Deutschen Bundestags (2018): Autonomes und automatisiertes Fahren auf der Stra&#223;e &#8211;
rechtlicher Rahmen.
1557 Vgl. Heiniger (2019): SBB, BLS und SOB bauen an der Bahn der Zukunft.
1558 So verkehrt die Linie U2 der N&#252;rnberger U-Bahn seit 2008 im automatisierten Betrieb, vgl. Stadt N&#252;rnberg (2018): Echtes
Pionierst&#252;ck: N&#252;rnbergs automatische U-Bahn.
1559 Das ETCS definiert verschiedene Level, f&#252;r die streckenspezifische Anforderungen gelten, vgl. DB Netz AG (2014): European Train 
Control System (ETCS) bei der DB Netz AG.
f&#252;hrt, die Verkehrssituation beobachten und erfassen und somit deren Entwicklung vorhersagen und das
Schienenfahrzeug entsprechend vorausschauend steuern kann.1560 Im Zuge dessen gilt es, die technologischen
Entwicklungen und rechtlichen Rahmenbedingungen in der Praxis weiter voranzutreiben, z. B. die Reaktion von
Stra&#223;enbahnen unter vollautonomer F&#252;hrung in Notfallsituationen oder das Verhalten bei Interaktionen mit
Fu&#223;g&#228;ngerinnen und Fu&#223;g&#228;ngern.
Eine Schienenvernetzung k&#246;nnte analog zur Automobilkommunikation (d. h. Kommunikation der
Schieneninfrastruktur mit der Umwelt) auch eine mobilit&#228;ts&#252;bergreifende Kommunikation erm&#246;glichen. Neue Zugbildungs-
und Zugsicherungssysteme in Verbindung mit optimierten, lernenden Logistiksystemen und neu gestalteten
automatisierten Umschlagterminals k&#246;nnten einen Effizienzgewinn und eine Verlagerung von Verkehr von der
Stra&#223;e auf die Schiene erm&#246;glichen. Entsprechend werden sich zuk&#252;nftig auch die Arbeitspl&#228;tze und -
bedingungen von Fahrdienstleiterinnen und -leitern ver&#228;ndern. Mithilfe Lernender Assistenz- und
Automatisierungssysteme k&#246;nnen sie ihre Aufgaben ebenfalls effizienter gestalten.1561 
Gerade im Zusammenhang mit der klimapolitischen Debatte spielt die Weiterentwicklung von KI im
Bahnverkehr eine besonders wichtige Rolle. Diese wird auch im sp&#228;teren Bericht zum Themenblock &#8222;Schiene&#8220; n&#228;her
erl&#228;utert.
Flugverkehr
Maschinelles Lernen in der Luftfahrtindustrie kann zu Einsparungen durch Prozessoptimierung &#8211; insbesondere
zu kleineren Crews1562, zu Reduzierung der Ausbildungskosten und weniger Pilotinnen und Piloten &#8211; f&#252;hren.1563 
Dabei sind die rechtlichen und regulatorischen Herausforderungen gro&#223;. Die nationale Luftverkehrsordnung, die
Vorschriften der Internationalen Zivilluftfahrt-Organisation (International Civil Aviation Organization, ICAO)
und die Luftraumordnung basieren auf der Annahme, dass Menschen die Verantwortung innehaben. Dies spiegelt
sich z. B. in der Rolle der Sichtweite in den Luftr&#228;umen1564 sowie in der Verwendung optischer Signale als
R&#252;ckfallmechanismus bei einem Ausfall der Funkverbindung wider. Diese Aspekte werden bei der Betrachtung
mitdiskutiert. Zus&#228;tzlich zeigt sich auch, dass der Akzeptanzgedanke bei komplett autonomen Luftfahrzeugen im
Vergleich zu anderen Verkehrstr&#228;gern weniger positiv ausf&#228;llt: Einer Studie zufolge &#228;u&#223;erten 54 Prozent von
8 000 Befragten, dass sie nicht ohne eine Pilotin bzw. einen Piloten fliegen wollten. Lediglich 18 Prozent konnten
sich dies vorstellen.1565 
In Anbetracht dessen erscheint es sinnvoll, noch mehr Erfahrungsdaten &#252;ber die Zuverl&#228;ssigkeit von Sensoren
sowie von Systemen, die zur Autonomie bef&#228;higt sind, zu sammeln, bevor die rechtlichen und regulatorischen
Aspekte bearbeitet werden. Die M&#246;glichkeiten m&#252;ssen jedoch bereits jetzt mitgedacht werden und unmittelbar
in rechtliche und regulatorische &#220;berlegungen einflie&#223;en. Zus&#228;tzlich bleibt nach wie vor offen, ob und wie
bestimmte Bereiche innerhalb des Flugbetriebs durch KI profitieren k&#246;nnen. Ein Bereich ist u. a. die Luftfahrzeug-
Instandhaltung (der sogenannte Flugzeug-/Mechanik-Check) direkt vor Abflug, wo zum heutigen Zeitpunkt der
Mensch noch unerl&#228;sslich zu sein scheint.
Im Bereich des Flugverkehrs liegt der Fokus der KI auf dem Potenzial des autonomen Fliegens, der sogenannten
Urban Air Mobility1566 sowie auf der Optimierung der Nutzung des Luftraums. Diese Aspekte werden in Kapitel
4.5 dieses Projektgruppenberichts [Luftverkehr] n&#228;her dargestellt.
1560 Vgl. Plattform Lernende Systeme (2019): Auf dem Weg zu einem intelligenten Mobilit&#228;tsraum.
1561 Vgl. Plattform Lernende Systeme (2019): Auf dem Weg zu einem intelligenten Mobilit&#228;tsraum.
1562 In der Sitzung der Projektgruppe KI und Mobilit&#228;t vom 9. Dezember 2019 erl&#228;uterte Dr. Christian Seidel (Airbus Helicopters
Deutschland GmbH) die Entwicklung der Crew-Anzahl im Laufe der Jahre von urspr&#252;nglich vier Personen auf in Zukunft eine
Person, die durch KI unterst&#252;tzt wird.
1563 Vgl. Castle et al. (2017): Flying solo &#8211; how far are we down the path towards pilotless planes?
1564 Vgl. &#167; 10 der Luftverkehrs-Ordnung (LuftVO).
1565 Vgl. Castle et al. (2017): Flying solo &#8211; how far are we down the path towards pilotless planes?; Plattform Lernende Systeme (2019):
Auf dem Weg zu einem intelligenten Mobilit&#228;tsraum.
1566 Der Begriff &#8222;Urban Air Mobility&#8220; (auf Deutsch sinngem&#228;&#223;: &#8222;Mobilit&#228;t im urbanen Luftraum&#8220; oder &#8222;Urbaner Lufttransport&#8220;)
bezeichnet die Erweiterung st&#228;dtischer Transportsysteme in den Luftraum; vgl. Deutsches Zentrum f&#252;r Luft- und Raumfahrt e. V.: Der urbane
Luftverkehr.
Schiffsverkehr
&#196;hnlich wie bei den anderen Verkehrsbereichen k&#246;nnen Fahrassistenzsysteme bis hin zu hochautomatisiert
fahrenden Schiffen f&#252;r einen Sicherheitsgewinn sorgen, denn auch im Schiffsverkehr werden die meisten Unf&#228;lle 
und Kollisionen durch menschliches Versagen verursacht.1567 Des Weiteren k&#246;nnten auch hier Betriebskosten
reduziert und der Fachkr&#228;ftemangel ausgeglichen werden.1568 
Autonome und intelligente Assistenzsysteme erweitern immer mehr die Methoden der Schiffsf&#252;hrung, wodurch
die vorhandene Infrastruktur effizienter genutzt werden k&#246;nnte. Insbesondere die Binnenschifffahrt kann hier
aufgrund ihrer geschlossenen Flusswege profitieren.
Beispiele f&#252;r autonome Schiffe gibt es bereits: In Norwegen wird der Frachter Yara Birkeland innerhalb der
12-Meilen-Zone Norwegens eingesetzt.1569 In Gro&#223;britannien wurde bereits 2017 das hochautomatisierte
Forschungsschiff C-Worker 7 registriert.1570 Im zivilen Bereich sind die Aktivit&#228;ten zurzeit im Wesentlichen auf
nationale Gew&#228;sser beschr&#228;nkt. Zudem gibt es weitere Initiativen z. B. in S&#252;dkorea und China.1571 
Wie auch in der Luftfahrt gibt es regulatorische Herausforderungen: Die Internationale Seeschifffahrts-
Organisation (International Maritime Organization, IMO) erarbeitet geeignete Spezifikationen. Die durch die IMO
festgelegten Regeln und Verhaltensweisen basieren auf seem&#228;nnischer Praxis, der sogenannten Seemannschaft, wie
sie z. B. in der Kollisionsverh&#252;tungsordnung (COLREG1572) festgehalten ist. Sie beinhaltet bestimmte
Grundannahmen, die im Falle hochautomatisierter Systeme nicht mehr erf&#252;llt w&#228;ren. So sehen die Regelwerke etwa eine
Kapit&#228;nin oder einen Kapit&#228;n vor. Diese verantworten Schiff, Besatzung und Ladung und k&#246;nnen gegen&#252;ber
allen Autorit&#228;ten als Bevollm&#228;chtigte auftreten. Eine Auflistung regulatorischer Hemmnisse, die &#252;ber die IMO
gel&#246;st werden m&#252;ssten, wurde in einer Studie der d&#228;nischen Marineautorit&#228;t erstellt.1573 
Weiterhin gibt es technische Risiken, die sich auch auf den Betrieb und die Wartung von empfindlichen,
sensorbasierten Systemen unter extremen Einsatzbedingungen erstrecken. Zudem gilt es, Fragen der
Langzeitautonomie und der Resilienz bei technischen St&#246;rungen zu l&#246;sen.
Der Wettbewerb im internationalen Schiffsverkehr setzt die Branche unter Kostendruck und Innovationszwang.
Hochautomatisierte Systeme versprechen eine Entlastung: Studien zeigen, dass hochautomatisierte Frachter &#252;ber
eine Dauer von 25 Jahren 4,3 Millionen US-Dollar einsparen k&#246;nnen.1574 Offen ist, ob hier und in anderen
Sektoren die Risiken und Betriebskosten der Technologie ad&#228;quat eingesch&#228;tzt werden k&#246;nnen. Hierzu w&#228;ren weitere
Prognosen, Studien und Chancen-Risiko-Absch&#228;tzungen erforderlich.
Wie in den zuvor genannten Sektoren besitzt KI auch im Bereich des Schiffsverkehrs viele Potenziale. Gerade
die Binnenschifffahrt als geschlossenes System sowie der dazugeh&#246;rige Logistikbereich sind vielversprechende
Bereiche, die im Kapitel 4.6 dieses Projektgruppenberichts [Schiffsverkehr] n&#228;her erl&#228;utert werden.
4.1.3 Handlungsempfehlungen1575 
Mobilit&#228;t ganzheitlich betrachten
Die Mobilit&#228;t der Zukunft muss ganzheitlich betrachtet werden. KI-Anwendungen im Mobilit&#228;tssektor sind mehr
als die Vision des selbstfahrenden PKW. Vielmehr m&#252;ssen die Potenziale sowie der F&#246;rder-, Steuerungs- und 
Regulierungsbedarf von KI-Anwendungen f&#252;r alle Mobilit&#228;tsformen betrachtet werden. Dies beinhaltet u. a. die 
Bereiche &#214;PNV, Schienenverkehr, Luftfahrt, maritime Wirtschaft, Logistik und auch die Vernetzung
verschiedener Verkehrstr&#228;ger und Sharing-Angebote.
1567 Vgl. European Maritime Safety Agency (2016): Annual Overview of marine casualties and incidents 2016.
1568 Vgl. Lockwood et al. (2017): Global Marine Technology Trends 2030.
1569 Vgl. Kongsberg Maritime: Autonomous ship project, key facts about Yara Birkeland.
1570 Vgl. Paton (2018): UK&#8217;s first fully autonomous vessel the C-Worker 7 is launched.
1571 Vgl. Plattform Lernende Systeme (2019): Auf dem Weg zu einem intelligenten Mobilit&#228;tsraum.
1572 International Regulations for Preventing Collisions at Sea, 1972.
1573 Vgl. Danish Maritime Authority (2017): Analysis of regulatory barriers to the use of autonomous ships; Plattform Lernende Systeme 
(2019): Auf dem Weg zu einem intelligenten Mobilit&#228;tsraum.
1574 Vgl. Kretschmann et al. (2017): Analyzing the economic benefit of unmanned autonomous ships: An exploratory cost-comparison 
between an autonomous and a conventional bulk carrier.
1575 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion der FDP vor [Sondervotum zu Kapitel 4.1.3 des Berichts der
Projektgruppe 5 &#8222;KI und Mobilit&#228;t&#8220; (&#8222; Zukunft der Mobilit&#228;t &#8211; Handlungsempfehlungen &#8220;) der Abgeordneten Mario Brandenburg, Carl-
Julius Cronenberg und Daniela Kluckert sowie der sachverst&#228;ndigen Mitglieder Dr. Aljoscha Burchardt und Andrea Martin].
Alle Lebensr&#228;ume einbeziehen
KI-Anwendungen im Mobilit&#228;tssektor m&#252;ssen gleicherma&#223;en f&#252;r die spezifischen Problemlagen,
Herausforderungen und Potenziale von urban verdichteten R&#228;umen, f&#252;r &#220;bergangsr&#228;ume zwischen Stadt und Land,
suburbane R&#228;ume und Mittelst&#228;dte sowie f&#252;r d&#252;nn besiedelte l&#228;ndliche Regionen, kurz, f&#252;r alle Lebensr&#228;ume
betrachtet werden. Die Herausforderungen m&#252;ssen gerade auch im Kontext der demografischen Entwicklung und der
Urbanisierung in Deutschland gesehen werden. So muss etwa die Frage ber&#252;cksichtigt werden, wie die Mobilit&#228;t
der Zukunft auch Pendlerstrecken effizienter gestalten kann. Es bedarf auf kommunaler Ebene und auf
L&#228;nderebene einer abgestimmten und ineinandergreifenden Strategie, um zu identifizieren, in welchen
Mobilit&#228;tsbereichen KI optimal eingesetzt werden kann. Hierbei m&#252;ssen auch Kooperationen zwischen privaten und &#246;ffentlichen
Mobilit&#228;tsdienstleistern diskutiert und vorangetrieben werden.
Deutschland zum Motor eines europ&#228;ischen Weges machen
Basierend auf den spezifischen Anforderungen, die sich aus der Diversit&#228;t europ&#228;ischer St&#228;dte und Regionen mit
ihren je eigenen gewachsenen Strukturen und Mischverkehren aus dem &#246;ffentlichen Verkehr, motorisiertem
Individualverkehr sowie Rad- und Fu&#223;verkehr ergeben, muss ein spezifischer europ&#228;ischer Weg f&#252;r KI-
Anwendungen entwickelt werden. Es ist notwendig, mehr Testfelder als bisher zu realisieren, um den genannten
Anforderungen gerecht zu werden. F&#252;r die Nutzung von lernenden Systemen, speziell im Kontext des
vollautomatisierten Fahrens (Stufe 4&#8211;5), ist der Rechtsrahmen bislang noch unterschiedlich und l&#252;ckenhaft. Dies umfasst u. a.
Vorschriften f&#252;r die Zulassung und den Betrieb von selbstfahrenden PKW und Bussen und schlie&#223;t auch
verhaltensrechtliche Vorschriften ein. Auch hier muss Europa eine Vorreiterrolle einnehmen. Die Beachtung
datenschutzrechtlicher Standards, wettbewerbsrechtlicher Vorgaben sowie die Akteursvielfalt auf Anbieterseite, von
kommunalen Verkehrsverb&#252;nden &#252;ber Automobilhersteller bis zu Startups, gilt es f&#252;r einen europ&#228;ischen Weg
ebenfalls sicherzustellen. Europ&#228;ische Standards sind, auch und gerade im Wettbewerb mit China und den USA,
obligatorisch. Deutschland muss Motor dieses Vorhabens sein.
M&#246;gliche Rebound-Effekte beachten
KI-Anwendungen k&#246;nnen einen erheblichen Beitrag leisten, den Verkehr nachhaltiger zu organisieren oder ihn
gar zu reduzieren &#8211; gleichzeitig f&#246;rdert der Komfortgewinn eine erh&#246;hte Nutzung und datengetriebene
Energieverbr&#228;uche, was sogenannte Rebound-Effekte ausl&#246;sen kann. Entsprechend muss beides, z. B. das Potenzial von
KI-Anwendungen zur Erreichung von Klimazielen im Verkehrssektor wie auch die Gefahr von steigenden
Verbr&#228;uchen durch Rebound-Effekte, Gegenstand verkehrspolitischer Entscheidungen sein. F&#252;r die Mobilit&#228;t der
Zukunft, bei der KI eingesetzt wird, sollten die Wechselbeziehungen und Wechselwirkungen somit in der Tiefe
betrachtet und auch hinterfragt werden. Es braucht immer ein stringentes Gesamtkonzept, um Rebound-Effekte
so weit wie m&#246;glich zu vermeiden. Dabei sollte immer das Gesamtsystem betrachtet und nicht nur anhand
einzelner Technologien entschieden werden.
Der Mensch steht im Mittelpunkt (an Bed&#252;rfnissen der Menschen ausrichten)
Es ist wichtig, dass die Gesellschaft Akzeptanz und Vertrauen in neue, KI-basierte Mobilit&#228;tsl&#246;sungen auf- und 
ausbaut. Alle KI-Anwendungen in der Mobilit&#228;t m&#252;ssen auf den Nutzen f&#252;r die Menschen ausgerichtet sein.
Entsprechend sind bei der Entwicklung und Nutzung von KI-Anwendungen der Zugang zu Systemen,
Transparenz sowie Fragen von Selbstbestimmung und Sicherheit zentral. Ein besonderer Fokus muss dabei auf den
Mobilit&#228;tsanforderungen, Bed&#252;rfnissen und der Sicherheit von Kindern, Jugendlichen, &#228;lteren Menschen sowie auf
Barrierefreiheit gelegt werden. Hierbei spielt neben ethischen Aspekten auch das Verst&#228;ndnis von Mobilit&#228;t im
Allgemeinen eine entscheidende Rolle. Neue Mobilit&#228;tskonzepte m&#252;ssen den Bedarf der Gesellschaft abdecken:
sowohl im st&#228;dtischen und l&#228;ndlichen Verkehr als auch bei Individualreisen. Es muss darauf geachtet werden,
wie die Akzeptanz f&#252;r neue Konzepte erh&#246;ht werden kann, wohlwissend, dass sich das Individualverhalten im
Verkehr zunehmend ver&#228;ndert.1576 
1576 Zu einer m&#246;glichen Akzeptanzgef&#228;hrdung kann es z. B. durch eine Reiz&#252;berflutung durch Lichtsensorik oder Hinweist&#246;ne kommen,
die die Fu&#223;g&#228;ngerinnen und Fu&#223;g&#228;nger &#252;berfordern k&#246;nnte.
Nutzung von Daten erm&#246;glichen
Die erweiterte datenbasierte Nutzung und Steuerung von Infrastrukturen und vorhandenen Ressourcen kann die
Mobilit&#228;t z. B. im Transportmanagement des G&#252;terverkehrs, aber auch im Personenverkehr optimieren und
klimaschonender organisieren. Vernetzte Logistiksysteme und Plattformangebote k&#246;nnen die bestehenden
Kapazit&#228;ten von G&#252;terverkehrsdienstleistern auf Basis von Echtzeitdaten verbessern. Im Personalverkehr sind
Datenerhebung und -analyse zentrale Wettbewerbsfaktoren f&#252;r Mobilit&#228;tsanbieter. Der Datenzugang f&#252;r Dritte ist das
bestimmende Grundthema der Daten&#246;konomie. Bestehende Interessenkonflikte zwischen rechtlichen
Einschr&#228;nkungen des Daten-Zugriffs (Datenschutz, Geheimnisschutz, Eigentumsrechte) und Zugangsbegehren von
Drittanbietern bzw. Wettbewerbern m&#252;ssen regulativ gel&#246;st werden. Verkehrsdaten, die aus &#246;ffentlicher Hand
finanziert sind, m&#252;ssen konsequent als Open Data zug&#228;nglich gemacht werden.
Digitale Infrastruktur ausbauen
Neben dringenden Investitionen in neue Kommunikationsinfrastrukturen wie z. B. das 5G-Netz, sind auch
Investitionen in bislang verbreitete Technologien wie das LTE-Netz erforderlich. Hierzu geh&#246;rt die Anwendung
des LTE-Netzes (fl&#228;chendeckend) f&#252;r die Kommunikation zwischen den Fahrzeugen oder die Nutzung von 
WLAN insbesondere im innerst&#228;dtischen Bereich. Technische, rechtliche und planerische Voraussetzungen f&#252;r
intermodale und autonome Mobilit&#228;tsangebote im Personenverkehr m&#252;ssen verst&#228;rkt getestet und definiert
werden, damit geeignete Rahmenbedingungen f&#252;r Anbieter etabliert werden k&#246;nnen. Hier gilt: Je mehr Testfelder,
desto besser. Der europ&#228;ische Raum erm&#246;glicht durch seine Diversit&#228;t eine Vielzahl von unterschiedlichsten
Testoptionen. Wenn Deutschland im europ&#228;ischen Ausbau- und Entwicklungsverfahren Vorreiter sein will, muss
der Ausbau von Netz- und Testfeldern massiv vorangetrieben werden.
Intermodalit&#228;t und Plattformen
4.2.1 Definitionen
Intermodaler vs. multimodaler Verkehr
Multimodaler Transport wird im Bereich G&#252;terverkehr von der Konferenz der Vereinten Nationen f&#252;r Handel
und Entwicklung (UNCTAD) als Transport von G&#252;tern mit zwei oder mehreren verschiedenen Verkehrstr&#228;gern
definiert.1577 In einer aktuelleren, weiter gefassten Definition, die sich nicht nur auf den Transport von G&#252;tern 
bezieht, wird Multimodalit&#228;t als &#8222;die grunds&#228;tzliche Option f&#252;r Nutzerinnen und Nutzer, verschiedene
Verkehrsmittel zu verwenden&#8220;, betrachtet.1578 Multimodalit&#228;t ist demnach ein Verkehrsverhalten, bei dem verschiedene 
Verkehrsmittel in einem bestimmten Zeitraum (z. B. Tag, Woche etc.) verwendet werden.
Eine Sonderform der multimodalen Verkehrsnutzung ist die intermodale Verkehrsnutzung, die als die &#8222;Nutzung 
unterschiedlicher Verkehrsmittel im Verlauf eines Weges&#8220;1579 definiert wird. Auf den Personenverkehr bezogen
k&#246;nnen Verkehrsmittel von einer Person auf einer Strecke somit beliebig gewechselt werden (z. B. vom Fahrrad
zum Bus). Die Wirtschaftskommission f&#252;r Europa der Vereinten Nationen (UN/ECE) definiert intermodalen
G&#252;terverkehr als &#8222;Transport von G&#252;tern in ein und derselben Ladeeinheit oder demselben Stra&#223;enfahrzeug mit zwei
oder mehreren Verkehrstr&#228;gern, wobei ein Wechsel der Ladeeinheit1580, aber kein Umschlag der transportierten
G&#252;ter selbst erfolgt&#8220;1581. Die multimodale und die intermodale Bef&#246;rderung stehen im Gegensatz zur
monomodalen Bef&#246;rderung, die nur einen Verkehrstr&#228;ger erfasst.
&#220;bergreifende Definition von Mobilit&#228;tsplattformen
Mobilit&#228;tsplattformen sind Intermedi&#228;re, die Nutzerinnen und Nutzer (Verbraucherinnen und Verbraucher oder
Unternehmen) und Anbieter f&#252;r Mobilit&#228;tsdienstleistungen zusammenf&#252;hren. Nutzerinnen und Nutzer sowie
Anbieter von Verkehrstr&#228;gern (z. B. &#214;PNV, E-Bikes, Scooter, Car-/Ridesharing, Auto, Taxi) k&#246;nnen durch Angebot
1577 United Nations (1980): United Nations Convention on International Multimodal Transport of Goods, abrufbar unter:
https://unctad.org/en/PublicationsLibrary/tdmtconf17_en.pdf (zuletzt abgerufen am 31. August 2020).
1578 Vgl. Ruhren et al. (2005): Bestimmung multimodaler Personengruppen, S. 5.
1579 Vgl. Ruhren et al. (2005): Bestimmung multimodaler Personengruppen, S. 5.
1580 Zum Beispiel Wechselbeh&#228;lter, Sattelanh&#228;nger oder Container.
1581 United Nations. Economic Commission for Europe, European Commission (2001): Terminologie des kombinierten Verkehrs.
und Nachfrage &#252;ber eine entsprechende Plattform zusammengebracht werden. Eine im Auftrag des BMVI
verfasste Studie definiert digitale Mobilit&#228;tsplattformen als virtuelle Marktpl&#228;tze, auf denen &#8222;Verkehrsangebot und
Verkehrsnachfrage digital zusammengef&#252;hrt werden&#8220;1582.
Unterscheidungen zwischen verschiedenen Mobilit&#228;tsplattformen
Wie die Fokusgruppe &#8222;Intelligente Mobilit&#228;t&#8220; darlegt, k&#246;nnen Mobilit&#228;tsformen unterschiedliche Nutzergruppen
ansprechen.1583 Plattformen f&#252;r den Individualverkehr betreffen vornehmlich Beziehungen zwischen
Konsumentinnen und Konsumenten bzw. B&#252;rgerinnen und B&#252;rgern zu Unternehmen (Business-to-Consumer &#8211; B2C).
Plattformen f&#252;r Unternehmen, speziell im Bereich der G&#252;terbef&#246;rderung, erfassen vornehmlich Unternehmen
(Business-to-Business &#8211; B2B). Ebenso ist die Beziehung von Konsumentinnen und Konsumenten zu Konsumentinnen 
und Konsumenten (Consumer-to-Consumer, C2C) zu betrachten.
Mobilit&#228;tsplattformen unterscheiden sich zudem in Funktionsumfang (Wertsch&#246;pfungstiefe, Umfang an
Information, Tiefe der kundenspezifischen Empfehlungen, Buchung etc.) geografischem Angebot (lokal, regional und
&#252;berregional) und Modalit&#228;t (erfasste Verkehrsmittel1584).1585 
Mit Blick auf Mobilit&#228;tsplattformen, die sich vornehmlich an Verbraucherinnen und Verbraucher richten, gilt es
hinsichtlich der ausge&#252;bten Gesch&#228;ftsmodelle zwischen Dienstleistern reiner Vermittlungsdienste und
Vermittlern von Bef&#246;rderungsleistungen zu unterscheiden. Beide sind bislang rechtlich voneinander abgegrenzt:
Digitale Mobilit&#228;tsplattformen, die als Bef&#246;rderer im Sinne des Personenbef&#246;rderungsgesetzes (PBefG)
betrachtet werden, fallen unter das Regelungsregime des PBefG. Diese Form der Mobilit&#228;tsplattform unternimmt die
Vermittlung der Bef&#246;rderungsleistung, tritt zudem aber auch als Vertragspartner und Bef&#246;rderer der Fahrg&#228;ste
auf.1586 Digitale Mobilit&#228;tsplattformen, die sich auf die Vermittlung von Personenbef&#246;rderungsleistungen als
Gesch&#228;ftsmodell begrenzen lassen, fallen nicht unter das PBefG, da sie keine eigene Bef&#246;rderungsleistung bieten.
Dar&#252;ber hinaus gilt es, branchenbezogene Mobilit&#228;tsplattformen f&#252;r Gesch&#228;ftskunden (B2B) zu betrachten.
Solche L&#246;sungen sind speziell in der Logistikbranche im Einsatz. Logistikplattformen k&#246;nnen durch den Einsatz
von Maschinellem Lernen (KI) Mustererkennungen durchf&#252;hren und somit Prozesse optimieren. Konkret k&#246;nnen
Logistikplattformen technische und organisatorische St&#246;rungen in den Lieferketten minimieren,
Planungssicherheit in den Transportfl&#252;ssen erh&#246;hen und Wirtschaftlichkeit in der Lagerhaltung, dem G&#252;terumschlag und der
Transportsteuerung maximieren sowie multimodalen Verkehr beg&#252;nstigen.
4.2.2 Status quo
Gesellschaft
Plattform&#246;konomie ver&#228;ndert auch au&#223;erhalb der urbanen Zentren das Konsum- und Kommunikationsverhalten
der B&#252;rgerinnen und B&#252;rger in vielerlei Hinsicht: Kontakte zu pflegen ist durch die sozialen Medien auch &#252;ber
gr&#246;&#223;ere Distanzen ungleich einfacher geworden. &#220;ber Online-Marktpl&#228;tze und -Shops hat man auch in
strukturschwachen Regionen den gleichen Zugang zur Warenvielfalt wie in der Stadt. Diese Ver&#228;nderung hat sich bereits
so stark etabliert, dass dies inzwischen oftmals als gegeben und nicht mehr als Neuerung gesehen wird. Im
Bereich Mobilit&#228;t dagegen ist der Unterschied zwischen Stadt und Land nach wie vor deutlich. W&#228;hrend etwa
Carsharing in der Gro&#223;stadt l&#228;ngst Alltag geworden ist, sind B&#252;rgerinnen und B&#252;rger au&#223;erhalb urbaner Zentren von
dieser Art der Mobilit&#228;t quasi ausgeschlossen. Zwar hat man auch im l&#228;ndlichen Raum die M&#246;glichkeit, Autos
privat zu teilen und Mitfahrgelegenheiten zu suchen. Meist ist die Nachfrage hier jedoch nicht ausreichend und
der dann oftmals l&#228;ngere Weg zum n&#228;chsten Verkehrszentrum bleibt unumg&#228;nglich. Insbesondere f&#252;r Menschen,
die berufsbedingt pendeln, fehlen sinnvolle Plattformangebote, um auf den privaten PKW verzichten zu k&#246;nnen.
F&#252;r die Zukunft sollten deshalb im l&#228;ndlichen Raum die M&#246;glichkeiten nicht-kommerzieller und kommerzieller
Plattformen verst&#228;rkt in den Fokus genommen werden. In den gro&#223;en St&#228;dten zeigt sich dagegen ein v&#246;llig
anderes Bild: Zahllose Apps vergleichen automatisch Fahrzeiten zwischen Auto, Fahrrad und &#214;PNV. Man kann
1582 Rodi et al. (2017): Digitale Mobilit&#228;tsplattformen.
1583 Vgl. Digital-Gipfel Plattform &#8222;Digitale Netze und Mobilit&#228;t&#8220; (2019): Thesenpapier der Fokusgruppe &#8222;Intelligente Mobilit&#228;t&#8220;.
1584 Multimodale Mobilit&#228;tsplattformen bieten z. B. verschiedene Verkehrstr&#228;ger an (Fernbusse, Fernz&#252;ge, Sharing-Dienste, Auto,
Luftverkehr, Taxen/Mietwagen usw.). Monomodale Mobilit&#228;tsplattformen hingegen bieten nur eine spezifische Verkehrstr&#228;gerart an
(z.&#8201;B. nur &#214;PNV, Fahrr&#228;der, Scooter usw.).
1585 Vgl. Digital-Gipfel Plattform &#8222;Digitale Netze und Mobilit&#228;t&#8220; (2019): Thesenpapier der Fokusgruppe &#8222;Intelligente Mobilit&#228;t&#8220;.
1586 Vgl. Rodi et al. (2017): Digitale Mobilit&#228;tsplattformen.
neben &#214;PNV-Angeboten aus unterschiedlichsten Car-, Fahrrad- und Roller-Sharing-Angeboten w&#228;hlen. Die
Intermodalit&#228;t zwischen den verschiedenen Verkehrstr&#228;gern ist &#8211; zumindest in den Innenstadtbereichen der
Gro&#223;st&#228;dte &#8211; l&#228;ngst zur Realit&#228;t geworden. Allerdings ist hier eine Anwendung der KI bei derartigen Anwendungen
noch nicht erkennbar. Z. B. werden bei intermodalen Routenplanern meist lange Fu&#223;wege f&#252;r die letzte Meile
als einzige Option vorgeschlagen.
Markt
Die Marktsituation f&#252;r Anbieter aus dem Bereich Mobilit&#228;tsplattformen und intermodale Verkehre erscheint
derzeit un&#252;bersichtlich. Wie oben beschrieben, konzentrieren sich Angebote derzeit vorrangig auf Gro&#223;st&#228;dte und
dort meist auf die innerst&#228;dtischen Bereiche. Doch selbst dort schreiben z. B. Carsharing-Anbieter1587 oder
Anbieter von Sammeltaxi-und Ridesharing-Angeboten1588 bei derzeitigen Marktbedingungen und derzeitigem
Preisgef&#252;ge offenbar keine schwarzen Zahlen. Die B&#246;rseng&#228;nge von zwei global agierenden Mobilit&#228;tsplattformen
im Jahr 2019 zeigten geringes Marktvertrauen in Gesch&#228;ftszahlen und Marktpotenziale.1589 Dem stehen Studien 
gegen&#252;ber, die f&#252;r 2030 ein erhebliches globales Marktvolumen im Bereich Mobilit&#228;tsdienstleistungen
prognostizieren.1590 
Politik
Grunds&#228;tzlich haben Plattformen in den letzten Jahren die Stellung der Verbraucherinnen und Verbraucher bzw.
der Nutzerinnen und Nutzer deutlich ver&#228;ndert. Sowohl die Verf&#252;gbarkeit von Informationen, Waren und
Dienstleistungen als auch die Preistransparenz hat sich deutlich erh&#246;ht. Nutzerinnen und Nutzer sowie Anbieter k&#246;nnen
beiderseits von Netzwerkeffekten profitieren. Da allerdings eine Plattform umso attraktiver wird, je mehr
Nutzerinnen und Nutzer sich beteiligen bzw. je mehr Angebote verf&#252;gbar sind, birgt diese Form der &#214;konomie die
Gefahr, hochkonzentrierte Netzwerke und damit Monopolstellungen auszubilden. Damit einher geht die
umfangreiche Sammlung von Daten. Personenbezogene Daten k&#246;nnen unter Beachtung der DSGVO-Vorgaben zur
Profilbildung genutzt werden. Nicht-personenbezogene Daten, von denen auch Dritte (zum Beispiel &#214;PNV-
Anbieter) profitieren k&#246;nnten, werden wiederum nicht als Open Data zur Verf&#252;gung gestellt. Der Gesetzgeber hat
darauf bereits vor einigen Jahren mit der 9. Novelle des Gesetzes gegen Wettbewerbsbeschr&#228;nkungen (GWB)
reagiert. Eine 10. GWB-Novelle zur Modernisierung des Kartellrechts ist in Arbeit.1591 
Im Bereich der intermodalen Mobilit&#228;t gibt es ebenfalls eine deutliche Angebotserweiterung. Die rechtlichen
Rahmenbedingungen behindern derzeit an einigen Punkten die weitere Entwicklung bzw. den weiteren Ausbau
solcher Mobilit&#228;tsangebote. Zus&#228;tzlich beschr&#228;nken sich diese fast ausschlie&#223;lich auf die Ballungszentren. In der
Praxis sind die letzten Jahre gepr&#228;gt von Pr&#228;zedenzf&#228;llen und rechtlichen Unklarheiten, die immer wieder durch
Gerichtsentscheidungen gekl&#228;rt werden m&#252;ssen. Es gibt sowohl im Bereich B2B als auch C2C Unklarheiten, die
eine weitere Entwicklung sowohl im Angebots- als auch im technischen Bereich ausbremsen, sei es die f&#252;r viele
nicht eindeutig beantwortete Frage der Haftung sowohl im laufenden Betrieb als auch bei Pilot- und Testbetrieben
oder auch die vieldiskutierte R&#252;ckkehrpflicht von Mietwagen. Diese erschwert es Firmen insbesondere im
l&#228;ndlichen Raum, das Mobilit&#228;tsangebot auszubauen: W&#228;hrend in Ballungszentren die R&#252;ckkehrpflicht durch kurze
Wege abgefangen werden kann, macht diese den Vorsto&#223; in den l&#228;ndlichen Raum faktisch unm&#246;glich.
Die rechtlichen Rahmenbedingungen behindern derzeit an einigen Punkten die weitere Entwicklung bzw. den
weiteren Ausbau von Mobilit&#228;tsangeboten.
Ein anderer Punkt ist die Diskussion um Daten und Datenverf&#252;gbarkeit: Der Kern eines offenen Marktes auch
im Bereich Mobilit&#228;t ist der Zugang zu Daten.
Eine zentrale Frage ist, ob Daten &#8222;wesentliche Einrichtungen&#8220; im Sinne des Kartellrechts (&#8222;Essential Facility
Doctrine&#8220;) sind. Diese Frage gilt es politisch zu definieren. Denn der Zugang zu Netzen und anderen wesentlichen
Einrichtungen ist Bestandteil der kartellrechtlichen Missbrauchsaufsicht des Bundeskartellamtes. Wird diese
Frage positiv beantwortet, m&#252;ssen Daten unter bestimmten Voraussetzungen allen Marktteilnehmern zur Verf&#252;-
1587 Vgl. Dahlmann (2019): Deutsche Carsharing-Anbieter stehen vor einem Dilemma.
1588 Vgl. Adam (2020): Die BVG k&#246;nnte beim Berlk&#246;nig zu hoch gepokert haben.
1589 Vgl. Conradi (2019): Uber stemmt Mega-B&#246;rsengang &#8211; und entt&#228;uscht trotzdem; Schmieder (2019): Uber hat&#180;s versemmelt; La
Monica (2019): Uber and Lyft both hit all-time lows and continue to struggle since their IPOs.
1590 Vgl. Schmidt et al. (2019): Mobility Services: the consumer perspective.
1591 Siehe auch Kapitel 5.4 des Mantelberichts [Wettbewerbsrecht].
gung gestellt werden &#8211; auch und gerade, um einer Monopolbildung entgegenzuwirken und gleichzeitig
maximales Optimierungspotenzial zu bieten. Weitere Ausf&#252;hrungen dazu finden sich im Kapitel 2 des Mantelberichts
[KI und Daten].
Optimierungspotenziale von KI
Aktuell finden Verbesserungen im Mobilit&#228;tsangebot kaum plattform&#252;bergreifend statt. Einzelne
Mobilit&#228;tsdienstleister versuchen eher, ihre eigenen Abl&#228;ufe wie Routenplanung, Zuverl&#228;ssigkeit und Preisgestaltung zu
optimieren. Dabei kommt es bei einer intermodalen Perspektive auf die bewegte Ware oder die sich
fortbewegende Person zu etlichen Br&#252;chen in ihrer Mobilit&#228;tskette, der Gesamtprozess der Fortbewegung spielt bisher
nur eine untergeordnete Rolle. Der Einsatz von KI bietet hier ein Optimierungspotenzial, um mithilfe von
Mobilit&#228;tsplattformen den intermodalen Verkehr aus Sicht der zu bewegenden Person oder Ware zu organisieren und 
zu verbessern und dabei auch einen positiven Beitrag zur CO2-Reduktion zu leisten: unmittelbar durch optimierte
Routenf&#252;hrung und mittelbar durch bessere Intermodalit&#228;ts-Angebote.
Logistikunternehmen werden k&#252;nftig noch st&#228;rker sich flexibel &#228;ndernden Kundennachfragen und externen
Einfl&#252;ssen begegnen und deshalb zeitn&#228;her und schneller reagieren m&#252;ssen. Zur Optimierung anpassungsf&#228;higer
Liefernetzwerke wird es eine Vielzahl von dezentralen Planungen geben m&#252;ssen, die &#252;bergeordnet optimal
koordiniert werden. Diese &#252;berordnete Koordinierung und Planung kann durch KI-Einsatz sinnvoll auf Basis von 
hochwertigen Echtzeit-Daten in Planungsalgorithmen integriert und umgesetzt werden, um mit
Simulationsmodellen das Verhalten von Logistiknetzwerken zu verstehen und deren Struktur zu verbessern. Ziel ist dabei, die
Anzahl von Leerfahrten zu senken und Laderaum optimal auszunutzen.
Erste KI-Anwendungen erm&#246;glichen es, den intermodalen Verkehr auch aus Sicht der Fahrg&#228;ste abzubilden, zu
analysieren und weiterzuentwickeln. KI-Systeme sind in der Lage, verbesserte r&#228;umlich-zeitliche Vorhersagen
f&#252;r hohe Nachfragegebiete zu erstellen. Dadurch k&#246;nnen fr&#252;hzeitig Pooling-Angebote in Nachfragegebiete
gelenkt werden, um Wartezeiten und Leerfahrten zu reduzieren. Datenanalyse und Simulationen durch KI-
induzierte Systeme erlauben zudem eine bessere Infrastruktur- und Betriebsplanung f&#252;r den &#214;PNV. Durch KI k&#246;nnen
Verkehrsplanung und Verkehrslenkung schneller an den tats&#228;chlichen Bedarf vor Ort angepasst werden; so l&#228;sst
sich z. B. fr&#252;hzeitig Stau vermeiden; auch k&#246;nnen Menschen zur Wahl umweltfreundlicher Verkehrsmittel
animiert werden.
4.2.3 Mobilit&#228;t im innerst&#228;dtischen Raum
Insbesondere im innerst&#228;dtischen Verkehr kann sich eine intermodale Routenplanung positiv auswirken. Bei
optimaler Nutzung l&#228;sst sich der Verkehr in der Innenstadt reduzieren und die Mobilit&#228;t beibehalten, wie sich in
einer Studie f&#252;r die Stadt Lissabon zeigte.1592 Um den bereits vorhandenen Mobilit&#228;tsbedarf der Bev&#246;lkerung zu
decken, w&#228;ren nach Erkenntnissen der Studie tats&#228;chlich nur 10 Prozent der vorhandenen Pkw notwendig. Ein
effizienterer Ressourceneinsatz k&#246;nnte zu kosteng&#252;nstigeren Mobilit&#228;tsangeboten und Emissionseinsparungen
f&#252;hren. Bisher l&#228;sst sich allerdings nicht feststellen, dass Carsharing- oder Ridepooling-Angebote1593 zur
signifikanten Reduzierung des Pkw-Besitzes f&#252;hren w&#252;rden, jedoch kann gegebenenfalls durch KI-Systeme eine
effizientere Auslastung des existierenden Pkw-Bestands erreicht werden &#8211; sowohl privat als auch gewerblich.
Aktuelle gewerbliche Carpooling-Angebote belegen derzeit nur eine marginale Verbesserung im Vergleich zum
bestehenden Einzeltransport. &#214;PNV-on-Demand-Angebote k&#246;nnten eine entscheidende Verbesserung bieten. &#220;ber
eine App k&#246;nnen dabei die Fahrg&#228;ste ihre Anfrage platzieren und das Deep-Learning-System (KI) der Plattform 
berechnet entsprechende Routen. Grundlage f&#252;r den fl&#228;chendeckenden Einsatz von Carsharing- und Ridepooling-
Angeboten werden auf lange Sicht autonome Fahrzeuge sein. Zum einen k&#246;nnen vernetzte autonome Fahrten
besser durch KI-Systeme optimiert werden, zum anderen bieten autonome Fahrzeuge eine L&#246;sung f&#252;r die hohen
Personalkosten und die erheblichen Personalengp&#228;sse. Aktuell operierende Plattformanbieter stehen vor dem
Problem, dass nicht ausreichend Fahrerinnen und Fahrer vorhanden sind, um das Angebot der Plattform
auszubauen. Erst mit dem Einsatz von autonomen Fahrzeugen k&#246;nnen diese als gr&#246;&#223;ter Kostenfaktor f&#252;r
Plattformbetreiber entfallen.
1592 Vgl. D&#246;rnemann und Gertz (2016): Wirkungen des autonomen/fahrerlosen Fahrens in der Stadt.
1593 Carsharing ist nach &#167; 2 des Carsharinggesetzes die organisierte, gemeinschaftliche Nutzung eines oder mehrerer Automobile auf der
Grundlage einer Rahmenvereinbarung. Ridepooling ist eine Dienstleistung der Personenbef&#246;rderung, bei der die individuelle
Bef&#246;rderung mehrerer Personen aus Effizienzgr&#252;nden zu einer Fahrt zusammengefasst wird. Ridesharing ist Ridepooling im privaten
Bereich: Es handelt sich um eine nicht-kommerzielle gemeinsame Fahrt mehrerer Personen, bei der verschiedene Wegstrecken aus
Effizienzgr&#252;nden zusammengefasst werden.
4.2.4 Gemeinn&#252;tzige KI-L&#246;sungen
KI-gest&#252;tzte Mobilit&#228;tsplattformen eignen sich zudem, um individuelle Mobilit&#228;tspr&#228;ferenzen intermodal zu
realisieren. Mit der entsprechenden Datenbasis sind KI-gest&#252;tzte Mobilit&#228;tsplattformen in der Lage, f&#252;r
Nutzerinnen und Nutzer neben den bereits etablierten Optionen &#8222;schnellste Route&#8220; und &#8222;k&#252;rzeste Route&#8220; auch die
kinderfreundlichste, barriere&#228;rmste oder klimafreundlichste Route zu berechnen.
Im Idealfall sollten KI-L&#246;sungen dazu beitragen, &#214;PNV sowie Fu&#223;- und Radverkehr zu st&#228;rken. Dadurch kann 
sich gleichzeitig der motorisierte Individualverkehr reduzieren. Dies h&#228;tte auch zur Folge, dass Ressourcen
geschont w&#252;rden und die Umweltbelastung reduziert w&#252;rde. Dabei gehen die Meinungen auseinander, wie dies
erreicht werden kann. W&#228;hrend die einen hier die Marktteilnehmer in der Pflicht sehen, entsprechende Angebote
zu schaffen, glauben andere, dass zus&#228;tzlich zu privaten Anbietern die &#246;ffentliche Hand als Daseinsvorsorge eine 
nationale oder europaweite Mobilit&#228;tsplattform entwickeln k&#246;nnte, insbesondere wenn in l&#228;ndlichen Gebieten
eine Anbindung &#252;ber gewerbliche Anbieter fehlt. Bef&#252;rwortende dieser staatlichen Einrichtung argumentieren, 
dass so eine Gemeinwohlorientierung sichergestellt und dabei insbesondere in der Fl&#228;che intermodaler Verkehr
organisiert werden k&#246;nnte. Im gesellschaftlichen Diskurs muss insofern erarbeitet werden, ob der Staat lediglich
die Standards f&#252;r entsprechende Angebote setzt oder als Betreiber derartiger Angebote und Plattformen aktiv in 
den Markt eingreift.
In diesem Sinne muss auch eine weitere Problematik in der Praxis beachtet werden: Plattformanbieter k&#246;nnen
&#252;ber erfasste Mobilit&#228;tsdaten das (Fahr-)Verhalten der eigenen Arbeitnehmerinnen und Arbeitnehmer
analysieren. Dies erh&#246;ht zwar die Sicherheit, kann allerdings auch negative Folgen f&#252;r die Betroffenen haben.
Grunds&#228;tzlich sollte KI nicht dazu genutzt werden, Arbeitsbedingungen zu verschlechtern. Die Tarifpartner stehen in der
Pflicht, dies sicherzustellen. Die Vorgaben des gesetzlichen Datenschutzes m&#252;ssen gewahrt bleiben (siehe hierzu
auch den Bericht der Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220; in Kapitel C. V. [K&#252;nstliche Intelligenz
und Arbeit (Projektgruppe 4). 
4.2.5 Mobilit&#228;t im l&#228;ndlichen Raum
Im urbanen Bereich ist ein Mix verschiedener Verkehrstr&#228;ger insofern einfacher zu realisieren, als die
notwendige h&#246;here Auslastung durch die gegebene Bev&#246;lkerungsdichte einfacher zu erzielen ist. Im l&#228;ndlichen Raum
einen &#228;hnlichen Grad an mobiler Verf&#252;gbarkeit zu erreichen, ist ohne autonomes Fahren schwierig. Was im
innerst&#228;dtischen Bereich noch als &#8222;letzte Meile&#8220; bezeichnet und mittlerweile &#252;ber Fahrr&#228;der, E-Scooter oder auch
Fahrservices als Erg&#228;nzung zum &#214;PNV geschlossen wird bzw. bereits geschlossen wurde, wird im l&#228;ndlichen 
Bereich wegen der strukturellen Gegebenheiten auf Dauer eben nicht &#8222;die letzte Meile&#8220;, sondern es werden
oftmals &#8222;die letzten zehn Kilometer&#8220; bleiben. Eine L&#246;sung w&#228;re, die letzten Kilometer so auszubauen, dass
autonome &#214;NPV-Fahrzeuge darauf fahren k&#246;nnen.
Selbst wenn &#252;ber erweiterte KI-Algorithmen die Bewegungsstrukturen verkehrstr&#228;ger&#252;bergreifend f&#252;r alle
Marktteilnehmer und Anbieter verf&#252;gbar w&#228;ren, lie&#223;e es sich aufgrund der zu erwartenden geringeren Auslastung
kaum bewerkstelligen, dass verschiedene Verkehrstr&#228;ger in jeder Ortschaft mit einem &#228;hnlichen Komfort zur
Verf&#252;gung st&#252;nden, wie es etwa das eigene Auto bietet. Auf absehbare Zeit wird sich etwa kommerzielles
Carsharing im l&#228;ndlichen Raum aufgrund der geringeren Auslastung nicht kostendeckend betreiben lassen k&#246;nnen.
Da aber im Sinne des Artikels 72 Absatz 2 des Grundgesetzes (GG) gleichwertige Lebensverh&#228;ltnisse auch in 
Zukunft als politische Ma&#223;gabe zu gew&#228;hrleisten sind, sollte zwangsl&#228;ufig der Bereich autonomes Fahren /
autonome Bewegung unterst&#252;tzt und vorangetrieben werden, um &#252;berhaupt in Zukunft eine intermodale Mobilit&#228;t
im l&#228;ndlichen Raum realisieren zu k&#246;nnen. Auch k&#246;nnten die Potenziale f&#252;r nicht-kommerzielles Carsharing und
&#214;PNV-on-Demand gef&#246;rdert werden.
Die Chancen gehen hier noch weiter: Es bietet sich zuk&#252;nftig die M&#246;glichkeit, Zuzugsdruck von den
Ballungszentren zu nehmen. Mobilit&#228;t im l&#228;ndlichen Raum k&#246;nnte das erste Mal &#252;berhaupt zu der in den Gro&#223;st&#228;dten
aufschlie&#223;en. Wenn es gelingt, diesen Punkt &#252;ber technische Innovationen zu l&#246;sen, w&#252;rde dies zu einer v&#246;llig 
neuen Aufwertung des l&#228;ndlichen Raums f&#252;hren.
Nach derzeitigem Kenntnisstand ist technisch leider noch nicht abzusehen, bis wann ein solches Szenario zu
realisieren ist. Insofern muss &#252;berlegt werden, inwiefern KI in der Zwischenzeit besser genutzt werden kann, um
aufbauend auf der jetzigen Situation die Mobilit&#228;t im l&#228;ndlichen Raum zu verbessern. Aufgrund der geringeren
Verkehrskomplexit&#228;t im l&#228;ndlichen Raum muss zuk&#252;nftig dessen Anbindung und Nutzung f&#252;r
Experimentierr&#228;ume in Bezug auf autonomes Fahren deutliche Priorit&#228;t einger&#228;umt werden. 
4.2.6 Plattformen: Tendenz zur Bildung von Monopolen und Oligopolen
Mobilit&#228;tsplattformen generieren wie andere Plattformen gro&#223;e Datenmengen. Netzwerkeffekte beg&#252;nstigen
dabei das Sammeln immer gr&#246;&#223;erer Datenmengen, die u. a. zur Verkehrsprognose, Verkehrsbedarfsbestimmung 
und Optimierung der Fahrtrouten genutzt werden k&#246;nnen. Diese Datens&#228;tze stellen einen enormen
Wettbewerbsvorteil f&#252;r Plattformbetreiber dar und tragen so zur Monopol- und Oligopolbildung von Dienstleistungsanbietern
im jeweiligen Sektor und &#252;ber Marktgrenzen hinaus bei. Plattformanbieter tendieren deshalb nicht nur zur
Monopolbildung, sondern auch zu konglomeraten Unternehmensstrukturen, sodass u. a. das Anbieten einer
Mobilit&#228;tsplattform durch andere Einnahmenquellen querfinanziert werden kann. Somit k&#246;nnen reichweitestarke, gro&#223;e
Plattformen preislichen Druck auf neue Wettbewerber im Markt oder Anbieter klassischer
Mobilit&#228;tsdienstleistungen aus&#252;ben. Dadurch werden Monopolisierungstendenzen im Markt weiter verst&#228;rkt (siehe auch das Kapitel
2 des Mantelberichts [KI und Daten]).1594 
4.2.7 Handlungsempfehlungen
Allgemein gilt: Der Einsatz von KI-L&#246;sungen sollte dazu beitragen, M&#246;glichkeiten der Intermodalit&#228;t bei
Mobilit&#228;tsplattformen auszusch&#246;pfen. Dabei kann es eine Angleichung von Mobilit&#228;t zwischen Stadt und Land nur
geben, wenn entsprechend autonome Fahrzeuge auch im l&#228;ndlichen Raum zur Verf&#252;gung stehen. Die Chancen,
die der l&#228;ndliche Raum aufgrund der geringen Komplexit&#228;t des Verkehrsaufkommens bietet, sollten unbedingt
genutzt werden. KI-L&#246;sungen f&#252;r Intermodalit&#228;t und Plattformen sollten zudem einen Beitrag zum Klimaschutz
leisten, d. h., sie sollten die Nutzbarkeit und Verbreitung von emissionsarmer Mobilit&#228;t erh&#246;hen und zur
Reduktion von Individualverkehr beitragen, indem der &#214;PNV, der Radverkehr und andere Fortbewegungsmittel
attraktiver gemacht und st&#228;rker genutzt werden.
Forschungsf&#246;rderung ausbauen
Es bedarf weiterer Forschung, wie KI im intermodalen Verkehr dabei unterst&#252;tzen kann, soziale und &#246;kologische
Ziele zu erreichen, wie die Maximierung von barrierefreier Mobilit&#228;t bei guter Bezahlbarkeit f&#252;r alle und
gleichzeitiger Reduktion von CO2-Emmissionen und insgesamt einer Verkehrsminderung.
Carsharing- und Ridepooling-Angebote f&#246;rdern
Soweit auf kommerzielles Carsharing im l&#228;ndlichen Raum nicht zur&#252;ckgegriffen werden kann, k&#246;nnen
subventionierte Angebote erg&#228;nzend zur Verf&#252;gung gestellt werden. Ein weiterer Weg kann im Ausbau von privatem
Carsharing liegen. Denn auch im l&#228;ndlichen Raum wird das private Kfz die &#252;berwiegende Zeit nicht bewegt und
k&#246;nnte anderweitig genutzt werden. Es muss eine bessere rechtliche Regelung getroffen werden, um privates
Carsharing und Carpooling zu f&#246;rdern. Derzeit &#252;berwiegen die Bedenken in Bezug auf Haftung und sonstige
Nachteile, w&#228;hrend die Vorteile entweder marginal oder kaum erkennbar sind. Der Gesetzgeber sollte hier
eindeutige Anreize setzen, etwa &#252;ber steuerliche Vorteile oder verg&#252;nstigte Mobilit&#228;tsangebote.
&#214;PNV in Mobilit&#228;tsplattformen integrieren
Der Einsatz von KI auf Mobilit&#228;tsplattformen kann durch Integration von Angeboten des &#214;PNV zu einer
Ausweitung der Nutzung &#246;ffentlicher Verkehrsmittel im l&#228;ndlichen Raum f&#252;hren, vor allem dann, wenn diese
autonom und dem Bedarf entsprechend angeboten werden, also auch auf dem Land eine hohe Flexibilit&#228;t in der
Mobilit&#228;t erm&#246;glichen. Aber auch feste Routen und Fahrzeiten, z. B. f&#252;r die letzten Kilometer bis zu den n&#228;chsten
Verkehrszentren gerade zu den Hauptverkehrszentren, k&#246;nnen bereits Verbesserungen und damit eine sinnvolle
Integration in Mobilit&#228;tsplattformen erm&#246;glichen. Im urbanen Bereich gibt es bereits erste autonome Fahrten im
Regelbetrieb des &#214;PNV auf festgelegten Routen, im l&#228;ndlichen Raum gibt es in Deutschland vorerst nur
Pilotprojekte, deren Ausbau und &#220;berf&#252;hrung in den Regelbetrieb Ziel weiterer Planungen sein sollte.
1594 Vgl. Schallbruch et al. (2019): Ein neuer Wettbewerbsrahmen f&#252;r die Digitalwirtschaft. Bericht der Kommission
Wettbewerbsrecht 4.0, S. 12 ff.
Monopolbildung verhindern
Negativen Folgen durch Monopolbildung bei Mobilit&#228;tsplattformen sollte entgegengewirkt werden, indem
Verhaltensregeln f&#252;r marktbeherrschende Plattformen auf europ&#228;ischer Ebene eingef&#252;hrt werden. Insbesondere gilt
es, die Frage nach einem Datenzugangsrecht f&#252;r Wettbewerber zu kl&#228;ren. Weiteren Kl&#228;rungsbedarf gibt es bei
Vorgaben f&#252;r Dateninteroperabilit&#228;t und -portabilit&#228;t. Bei &#246;ffentlichen Mobilit&#228;tsanbietern sollte das Open-Data-
Potenzial ausgesch&#246;pft werden (siehe auch Kapitel 2.2 des AG-Berichts 2 der Projektgruppe &#8222;KI und Staat&#8220;
[Thematischer Schwerpunkt]).
Das Wettbewerbsrecht muss weiterentwickelt werden, um fairen Datenaustausch und faire Nutzung zu
gew&#228;hrleisten. Es sollten au&#223;erdem M&#246;glichkeiten geschaffen werden, um gemeinschaftlich Daten in Kooperationen
nutzen zu k&#246;nnen.
Rechtliche Klarheit schaffen
Im Allgemeinen m&#252;ssen Regelungen getroffen werden, die ein innovationsfreundliches Klima schaffen und die
klare und eindeutige Rahmenbedingungen im Bereich KI allgemein und im Bereich Mobilit&#228;t im Besonderen
setzen. Nur so kann allen Marktteilnehmern eine m&#246;glichst umfassende Rechtssicherheit gew&#228;hrt werden,
insbesondere im Hinblick auf Angebot, Nutzung und Haftung. Der Gesetzgeber ist insofern dazu angehalten, die
Gesetzgebung in diesem Bereich derart zu gestalten, dass Unklarheiten m&#246;glichst vermieden werden, damit nicht
mehr Einzelentscheidungen als n&#246;tig ex-post von den Gerichten getroffen werden m&#252;ssen. Gerade im Hinblick
auf technische Neuerungen und private Beteiligung m&#252;ssen hier eindeutige Rahmenbedingungen gesetzt werden. 
Um eine gesunde und vor allem z&#252;gige weitere Entwicklung voranzubringen, d&#252;rfen diese Entscheidungen nicht
auf die Jurisdiktion &#252;bertragen werden.
Reallabore und Testfelder f&#252;r den Einsatz von intermodalen Plattformen f&#246;rdern und ausbauen
Auf Basis der Strategie &#8222;Reallabore &#8211; Testr&#228;ume f&#252;r Innovation und Regulierung&#8220; des BMWi sollten neue
Reallabore und Testfelder KI-basierte Use Cases im Verkehrs- und Logistikbereich erprobt werden, z. B. in
gemeinsamer Durchf&#252;hrung mit Landkreisen, Kommunen und St&#228;dten. Unter realistischen Bedingungen k&#246;nnten
kontrolliert Ergebnisse aus der theoretischen Forschung mit Blick auf anwendungsorientierte technische und
regulatorische Aspekte erprobt werden. Somit k&#246;nnten neue Innovationen schneller zur Anwendung bzw. in den
Regelbetrieb gebracht werden, Verkehrsfl&#252;sse verbessert und Leerfahrten im G&#252;terverkehr auf der Stra&#223;e minimiert
werden.1595 
Mobilit&#228;tscluster zur Verzahnung von Forschung und Anwendung f&#246;rdern
Digitale Planungstools auf Basis von KI k&#246;nnen dabei helfen, m&#246;gliche Ver&#228;nderungen zu simulieren und
zuk&#252;nftige Verkehrs- und G&#252;terstr&#246;me zu antizipieren. Autonomes Fahren und speziell die Wirkung von
intermodalen Mobilit&#228;tsplattformen k&#246;nnen dazu beitragen, Verkehrsfl&#252;sse zu optimieren, Leerfahrten von
G&#252;terverkehrstr&#228;gern zu vermeiden und somit Umwelt- und L&#228;rmbelastungen f&#252;r B&#252;rgerinnen und B&#252;rger zu senken.
Erkenntnisse aus der Wissenschaft sollten anwendungsnah und unter realen Bedingungen erprobt werden
k&#246;nnen, um rasch in die st&#228;dteplanerische Praxis &#252;bernommen zu werden. Es gilt speziell Einrichtungen zu f&#246;rdern,
die Unternehmensgr&#252;nder und Forschungsinstitute zusammenbringen, wie z. B. zur gemeinsamen Forschung und
Entwicklung neuer plattformbasierter Mobilit&#228;tsl&#246;sungen im Bereich der Stadt- und Verkehrsplanung.
Stra&#223;enverkehr
4.3.1 KI und Mobilit&#228;t: Automobil und Stra&#223;enverkehr
Wie im Kapitel 4.1 dieses Projektgruppenberichts [Zukunft der Mobilit&#228;t], erw&#228;hnt, zeigt sich anhand der
Erhebungen zur Mobilit&#228;t in Deutschland (MiD), dass &#252;ber alle Verkehrsmittel t&#228;glich 3,2 Milliarden Kilometer
zur&#252;ckgelegt werden.1596 Ein Gro&#223;teil dieser Entwicklung l&#228;sst sich insbesondere auf den Stra&#223;ensektor
zur&#252;ckf&#252;hren. Beruflich bedingte Wegstrecken stiegen um 13 Prozent an. Zus&#228;tzlich w&#228;chst der Lieferverkehr immer
mehr.1597 Diese Entwicklung unterstreicht die Notwendigkeit von Innovationen im Stra&#223;ensektor.
1595 Vgl. Bundesministerium f&#252;r Wirtschaft und Energie: Die Reallabore-Strategie des BMWi.
1596 Vgl. Bundesministerium f&#252;r Verkehr und digitale Infrastruktur (2020): Mobilit&#228;t in Deutschland.
1597 Vgl. Nobis et al. (2019): Mobilit&#228;t in Deutschland, S. 60.
Im Bereich &#8222;Stra&#223;enverkehr&#8220; konzentriert sich dieser Berichtsteil inhaltlich auf die potenzielle Nutzung des
autonomen und vernetzten Fahrens, die Anwendung von Sensorik sowie die Effizienzsteigerung im Logistikbereich 
mithilfe von KI. Dabei gilt es, beim autonomen Fahren darauf zu achten, wie unterschiedlich sich die Regionen
f&#252;r eine potenzielle Nutzung eignen. Die &#220;berlastung in Metropolregionen spielt hier genauso eine Rolle wie die
individuellen Mobilit&#228;tsanforderungen in l&#228;ndlichen Regionen, die mit heutigem klassischen &#214;PNV oft nicht
erf&#252;llt werden k&#246;nnen. Bei Pilotprojekten gab es Stand Dezember 2019 unterschiedliche Anwendungsbereiche
z. B. auf Autobahnabschnitten, innerhalb von Wohngebieten in Gro&#223;st&#228;dten sowie auf Landstra&#223;en oder in
industriellen Gebieten.
4.3.2 Begriffsbestimmungen
Als wesentliche Teilnehmer am Verkehrssystem &#8222;Stra&#223;e&#8220; werden insbesondere Verkehrsmittel wie durch
Menschen und/oder Maschinen gesteuerte Pkw, Lkw, Busse, Motorr&#228;der, Fahrr&#228;der, E-Roller und Sonderfahrzeuge,
aber auch Fu&#223;g&#228;ngerinnen und Fu&#223;g&#228;nger in die Betrachtungen einbezogen. Die sich ebenfalls mehrheitlich im
Bereich der Stra&#223;e bewegenden &#8222;Stra&#223;enbahnen&#8220; werden haupts&#228;chlich im Teilgebiet &#8222;Schienenverkehr&#8220;
einbezogen. Das Gleiche gilt f&#252;r die Luft- und Wasserverkehrsmittel im Teilgebiet &#8222;Luftverkehr und Schiffsverkehr&#8220;.
Im Rahmen des Themenbereichs &#8222;Stra&#223;enverkehr&#8220; m&#252;ssen zus&#228;tzlich zu Beginn die aktuellen
Automatisierungsgrade des autonomen Fahrens n&#228;her erl&#228;utert werden:
In der Automobilbranche wird zurzeit zwischen f&#252;nf Stufen unterschieden. Stufe 1 bis Stufe 3 beinhalten nach
wie vor das menschliche Eingreifen. Erst ab Stufe 4 kommt es zum &#8222;vollautomatisierten&#8220; Fahren, sprich, das
System kann in einem eingeschr&#228;nkten Kreis von Anwendungsf&#228;llen alle Situationen automatisch bew&#228;ltigen. 
Mit der Stufe 5 &#252;bernimmt das Fahrzeug vollst&#228;ndig alle Fahrt&#228;tigkeiten, unabh&#228;ngig von Stra&#223;entyp,
Geschwindigkeit und anderen &#228;u&#223;eren Bedingungen.1598 
Abbildung 3
Automatisierungsgrade des automatisierten Fahrens1599 
1598 Vgl. Ethik-Kommission (2017): Automatisiertes und Vernetztes Fahren, S. 14.
1599 Ethik-Kommission (2017): Automatisiertes und Vernetztes Fahren, S. 14.
4.3.3 Status quo
Gesellschaft
F&#252;r den Verkehrsbereich Stra&#223;e ist im Zusammenhang potenzieller KI-Anwendungen das am h&#228;ufigsten
diskutierte Thema das autonome Fahren. Umfragen zufolge sind viele Personen in der Bev&#246;lkerung noch
unentschlossen, wenn es um die potenzielle Nutzung von autonom fahrenden Autos geht. Knapp 29 Prozent sprechen sich
gar gegen und nur 18 Prozent f&#252;r eine Nutzung aus. Circa 53 Prozent k&#246;nnen hierzu keine Aussage treffen.1600 
Akzeptanzprobleme k&#246;nnen u. a. durch die Angst vor Manipulation, fehlendes Vertrauen in die Technik oder das
Gef&#252;hl, &#252;berwacht zu werden, entstehen.1601 Ein Ziel ist es somit, Vertrauen zu schaffen, damit KI zum Beispiel 
im Bereich des autonomen Fahrens auch tats&#228;chlich angewendet wird.
KI kann weiterhin den Stra&#223;enverkehr erheblich sicherer gestalten. Die Unfallstatistik zeigt, dass nach wie vor
das menschliche Versagen die Ursache f&#252;r 90 Prozent aller Unf&#228;lle ist. Je nach Stufe der Automatisierung und
Unterst&#252;tzung durch Assistenzsysteme kann sich die Zahl der Unf&#228;lle weiter reduzieren. Eine gro&#223;e
Herausforderung ist folglich, technisches Versagen oder das falsche Einsch&#228;tzen von Verkehrssituationen zu
verhindern.1602 
Je nach Region und Verkehrsmittel unterscheidet sich auch im Bereich &#8222;Stra&#223;e&#8220; die Verkehrsentwicklung
erheblich. W&#228;hrend in l&#228;ndlichen Regionen der Individualverkehr nach wie vor ein wichtiger Bestandteil f&#252;r viele ist,
kommt es in Gro&#223;st&#228;dten und Metropolregionen zu immer mehr &#220;berlastungen. Der G&#252;tertransport wie auch die
Infrastruktur sind neben den technischen M&#246;glichkeiten des Automobils wichtige Faktoren, die durch neue
Technologien wie die KI verbessert werden k&#246;nnen.
Markt
Die Ver&#228;nderungen der Stra&#223;enmobilit&#228;t werden die Industrie vor die Herausforderung stellen, die Fahrzeuge f&#252;r
die Stra&#223;en der Zukunft zu produzieren. Der moderne Stra&#223;enverkehr stellt schon jetzt ein komplexes, in Teilen 
auch chaotisches System dar. Das System &#8222;Stra&#223;e&#8220; steht dar&#252;ber hinaus in Verbindung mit anderen Systemen
der Verkehrsinfrastruktur wie &#8222;Schiene&#8220;, &#8222;Wasser&#8220; und &#8222;Luft&#8220;. Dieses System wird sich mit gro&#223;er
Wahrscheinlichkeit weiter diversifizieren und stark multimodal entwickeln. Eine pr&#228;zise Vorhersage &#252;ber die Struktur der
zuk&#252;nftigen Stra&#223;enmobilit&#228;t l&#228;sst sich deswegen kaum treffen. Sicher ist, dass auch in der Zukunft Waren und
Menschen von Fahrzeugen transportiert werden.1603 
Die &#252;ber Jahrzehnte gewachsene und nachgewiesene technologische Kompetenz deutscher Fahrzeughersteller
kann genutzt werden, um einen Marktvorteil im Bereich Mobilit&#228;t der Zukunft zu erzielen. In Europa m&#252;ssen
auch zuk&#252;nftig Fahrzeuge zu marktf&#228;higen Konditionen hergestellt werden. Herausforderungen auf dem Weg zu
einer guten Marktposition deutscher Hersteller sind die zunehmende Digitalisierung und Vernetzung,
Diversifizierung, der Wettbewerb um Fachkr&#228;fte, Nachhaltigkeit und positive &#246;kologische Bilanzen. Die globalen
Wertsch&#246;pfungsketten und die vernetzte Verkehrsstruktur der Zukunft sind Marktbedingungen, die hohe Flexibilit&#228;t
und erstklassiges Datenmanagement verlangen. Der Standort Deutschland verf&#252;gt &#252;ber eine ausgezeichnete
Position, den &#220;bergang zur Verkehrsstruktur von morgen als Gewinner zu meistern, ihn stringent auszubauen und
auch in den europ&#228;ischen Kontext einzubetten.1604 
Politik
Der politische Aspekt wurde in einigen Teilen bereits im ersten Bericht &#8222;Zukunft der Mobilit&#228;t&#8220; betrachtet. Der
&#220;bersicht halber wird hier nochmals auf die Mobilit&#228;tsziele der Bundesregierung verwiesen, die sich
insbesondere auf den Rechtrahmen f&#252;r potenzielle Nutzungen des autonomen Fahrens, die F&#246;rderung f&#252;r Forschung und
die Erweiterung von Mobilit&#228;tsoptionen konzentriert.1605 Letzteres wird in Kapitel 4.2 dieses
Projektgruppenberichts [Intermodalit&#228;t und Plattformen] eingehend beleuchtet. 
1600 Vgl. Statista (2019): W&#252;rden Sie ein autonom fahrendes Auto nutzen?; Aral Aktiengesellschaft (2019): Trends beim Autokauf 2019.
1601 Vgl. Statista (2019): Welche Akzeptanzprobleme sehen Sie beim Autonomen Fahren?
1602 Vgl. Rudschies und Kroher (2019): Autonomes Fahren: Digital entspannt in die Zukunft.
1603 Vgl. Litman (2017): Autonomous Vehicle Implementation Predictions.
1604 Vgl. Fraunhofer-Allianz autoMOBILproduktion (2019): Mobilit&#228;t der Zukunft muss produziert werden.
1605 Siehe auch Kapitel 4.1.1 dieses Projektgruppenberichts [Vision KI und Mobilit&#228;t &#8211; Status quo], Abschnitt &#8222;Politik&#8220;.
Die Bundesregierung befasst sich im Bereich des autonomen Fahrens auch mit ethischen Problemstellungen, ein
Aspekt, der vielfach wissenschaftlich und auch gesellschaftlich diskutiert wird. Im Jahre 2017 wurde im
Nachgang des Berichts der &#8222;Ethik-Kommission Automatisiertes und Vernetztes Fahren&#8220; hierzu ein Ma&#223;nahmenplan
beschlossen. Dazu geh&#246;rt u. a., dass &#8222;automatisierte und vernetzte Systeme, insbesondere lernende und
selbstlernende Systeme, [&#8230;] nicht zu einer totalen &#220;berwachung der Verkehrsteilnehmer f&#252;hren [d&#252;rfen]&#8220;1606. Zus&#228;tzlich
m&#252;ssen sie &#8222;zuverl&#228;ssig hohe Sicherheitsanforderungen an fahrzeugsteuerungsrelevante Funktionen erf&#252;llen,
einschlie&#223;lich des Schutzes vor Manipulationen der Fahrzeugsteuerung, und m&#252;ssen die Ethik-Leitlinien
beachten&#8220;1607. Es gilt auch bei der Erarbeitung des Rechtsrahmens die Pr&#228;misse, dass die Vermeidung eines
Personenschadens stets Vorrang vor der Vermeidung eines Sachschadens hat.1608 Diese Ma&#223;nahmen entsprechen den
Ergebnissen der Ethik-Kommission.1609 
Ein weiterer besonderer Fokus liegt auf den &#8222;digitalen Testfeldern&#8220;. Das BMVI unterscheidet zwischen den
Testfeldern auf Autobahnen, in St&#228;dten und im l&#228;ndlichen Raum sowie innerhalb internationaler Kooperationen z. B.
mit Frankreich und Luxemburg. Berlin, Braunschweig, Dresden, D&#252;sseldorf, Hamburg, Ingolstadt, Kassel und
M&#252;nchen sind hier als Testregionen zu nennen. Die F&#246;rderungen erfolgen &#252;ber das Forschungsprogramm zur
Automatisierung und Vernetzung des Stra&#223;enverkehrs. Die Regelungen f&#252;r Erprobungsfahrten sind an den
stra&#223;enverkehrsrechtlichen Vorschriften ausgerichtet, insbesondere an der Stra&#223;enverkehrs-Zulassungs-Ordnung
(StVZO). Das geltende Recht sieht vor, dass in der Praxis Erprobungsfahrten von Fahrzeugen mit automatisierten
Fahrfunktionen im &#246;ffentlichen Verkehrsraum mit st&#228;ndig eingriffsbereiten Fahrerinnen bzw. Fahrern
durchgef&#252;hrt werden m&#252;ssen. Die Fahrzeugsysteme m&#252;ssen somit entweder &#252;bersteuerbar1610 oder abschaltbar sein.1611 
&#167; 1a Absatz 1 StVG hat ab dem 21. Juni 2017 den Betrieb eines Kraftfahrzeugs &#8222;mittels hoch- oder
vollautomatisierter Fahrfunktion&#8220; zwar grunds&#228;tzlich zugelassen, dies gilt jedoch nur dann, wenn die Funktion
&#8222;bestimmungsgem&#228;&#223; verwendet&#8220;1612 wird. Das bedeutet, dass die Person, die das Fahrzeug f&#252;hrt, sich w&#228;hrend des
Betriebs dieser Fahrfunktion vom Verkehrsgeschehen und der Fahrzeugsteuerung zwar abwenden kann, aber
&#8222;wahrnehmungsbereit&#8220; bleiben muss, sodass sie die Fahrzeugsteuerung ohne schuldhaftes Z&#246;gern &#252;bernehmen kann,
wenn das System sie dazu auffordert. Automatisiertes Fahren auf den Stufen 3 und 4 wird somit erm&#246;glicht, 
jedoch nicht das &#8222;vollautonome Fahren&#8220; auf Stufe 5.1613 
Die Betrachtung der Testfelder zeigt, dass sich die Arbeit stark auf den Forschungsbereich sowie die
darauffolgende praktische Testanwendung fokussiert. Der bereits genannte Aktionsplan zum Thema &#8222;Forschung f&#252;r
autonomes Fahren&#8220; f&#246;rdert diese Vorhaben ebenfalls. Hier kooperiert das BMBF mit dem BMVI und dem BMWi.
4.3.4 KI und autonome Automobile
Die Forschung und Entwicklung des autonomen Fahrens sind den Anfangsstadien entwachsen. Da das autonome
Fahren bereits von der reinen Hochschulforschung in die Anwendung geht, sind Patente mittlerweile zum
besseren Gradmesser f&#252;r die Position Deutschlands in der Welt geworden als Ver&#246;ffentlichungen.1614 Daraus resultiert
auch, dass es auf diesem Gebiet eine starke Industrieforschung gibt. Es werden Milliarden investiert,
wohlwissend, dass der Weg noch sehr weit ist.1615 Neben den klassischen Automobilherstellern sind es auch
Zuliefererunternehmen sowie gro&#223;e US-Tech-Firmen, die in den Bereichen weiter forschen. Autonomes und vernetztes
Fahren wird die komplexeste Funktion sein, die je im Automobilkontext entwickelt wurde. Gleichzeitig wird sie
die Gesch&#228;ftsmodelle der Automobilindustrie st&#228;rker beeinflussen und ver&#228;ndern, als dies die Elektromobilit&#228;t
1606 Bundesministerium f&#252;r Verkehr und digitale Infrastruktur (2017): Ma&#223;nahmenplan der Bundesregierung zum Bericht der Ethik-
Kommission Automatisiertes und Vernetztes Fahren, S. 6.
1607 Bundesministerium f&#252;r Verkehr und digitale Infrastruktur (2017): Ma&#223;nahmenplan der Bundesregierung zum Bericht der Ethik-
Kommission Automatisiertes und Vernetztes Fahren, S. 6.
1608 Vgl. Bundesministerium f&#252;r Verkehr und digitale Infrastruktur (2017): Ma&#223;nahmenplan der Bundesregierung zum Bericht der Ethik-
Kommission Automatisiertes und Vernetztes Fahren.
1609 Vgl. Ethik-Kommission (2017): Automatisiertes und Vernetztes Fahren.
1610 &#8222;&#220;bersteuerbar&#8220; bedeutet, dass der Mensch die KI notfalls &#252;berstimmen und in den Geschehensablauf eingreifen kann.
1611 Vgl. Bundesministerium f&#252;r Verkehr und digitale Infrastruktur: Digitale Testfelder.
1612 Eine bestimmungsgem&#228;&#223;e Verwendung liegt z. B. nicht vor, wenn der Hersteller die automatische Fahrfunktion nur f&#252;r den Einsatz 
auf der Autobahn vorsieht, die Fahrerin oder der Fahrer sie aber auch auf der Landstra&#223;e verwendet. Dieser Aspekt wurde bereits in
Kapitel 4.1 dieses Projektgruppenberichts [Zukunft der Mobilit&#228;t] angesprochen.
1613 Vgl. Die Wissenschaftlichen Dienste des Deutschen Bundestags (2018): Autonomes und automatisiertes Fahren auf der Stra&#223;e &#8211;
rechtlicher Rahmen.
1614 Darstellung von Prof. Dr. Thomas Form (Leiter des Forschungsfeldes &#8222;Elektronik und Fahrzeug&#8220; in der Konzernforschung,
Volkswagen AG) in der Sitzung der Projektgruppe KI und Mobilit&#228;t am 16. Dezember 2019.
1615 In der Sitzung der Projektgruppe am 16. Dezember 2019 wurde der Vergleich mit einer &#8222;Marsmission&#8220; aufgestellt.
tut bzw. tun wird.1616 Im autonomen Fahren gibt es eine Mischung aus den Komponenten der regelbasierten
1617Anwendung1618 und der KI im Allgemeinen.1619 Es muss verdeutlicht werden, dass im autonomen Fahren KI
auf der Sensorseite und regelbasiert auf der Entscheidungsseite einzuordnen ist. Die fachliche Einordnung der
Sachverst&#228;ndigen in der Projektgruppe &#8222;Mobilit&#228;t&#8220; kommt zu dem Schluss, dass bei der Steuerung im Bereich 
des autonomen Fahrens &#8222;Regeln&#8220; im Sinne der regelbasierten Anwendung und bei der Verarbeitung von Daten
vermehrt Maschinelles Lernen im Sinne von &#8222;Deep Learning&#8220; (KI) zum Einsatz kommen.
Ebenfalls von Bedeutung ist die technische Unterscheidung zwischen Systemen, die votingbasiert entscheiden, 
und Systemen, die &#252;ber eine statistische Analyse ihre Entscheidungen treffen. Bei redundanten Systemen sind 
die mit statistischen Sicherheiten versehenen Aussagen von Vorteil.1620 Es sind viele Herausforderungen beim
autonomen Fahren zu bew&#228;ltigen, denn Fehlverhalten ist in diesem Bereich keine Option: Die Aufgabe des
autonomen Fahrens ist in sich hochkomplex, sie besteht aus vielen Teilaufgaben, noch stehen keine ausreichenden
Daten zur Verf&#252;gung und noch ist die Datenlage vielschichtig: Es gibt somit &#8222;viele (un)bekannte
Unbekannte&#8220;1621.
Eine der gr&#246;&#223;ten Herausforderungen ist die Validierung:1622 Der Mensch f&#228;hrt nicht reproduzierbar und kann sich
an Situationen anpassen. Die Maschine f&#228;hrt reproduzierbar, scheitert aber an unbekannten Situationen. Dies
f&#252;hrt zu einem wichtigen Umstand: Es fehlen messbare Konzepte f&#252;r de facto alle Qualit&#228;tsindikatoren: Daten-
Coverage, Messen und Definition von ODDs1623. Es stellen sich hier mehrere Fragen: Was ist Erkl&#228;rbarkeit? Wie 
k&#246;nnen unterschiedliche L&#246;sungen verglichen werden? Wie l&#228;sst sich der Abstand bei der Einstellung der
Samples der Sensordaten messen? Wie misst man die Kapazit&#228;t eines Modells? Hierzu werden eine Systematik,
Leitlinien und KPIs (Leistungskennzahlen) ben&#246;tigt, um Qualit&#228;t zu messen. Das ist ein extrem wichtiges Feld f&#252;r
die KI-Grundlagenforschung im Bereich des autonomen Fahrens. Auf einen Blick sind die folgenden Aspekte
f&#252;r die Entwicklung in diesem Bereich von Bedeutung:
&#8226; Verhaltensmodelle: Diese werden in Zukunft verst&#228;rkt ben&#246;tigt, auch, weil noch nicht genug Realdaten zur
Verf&#252;gung stehen. Aus diesem Grund wird besonders mit synthetischen Daten gearbeitet.
&#8226; Synthetische Daten: Diese werden durch Simulation von Verhaltensmodellen erstellt. Wie werden hier
G&#252;te- und Qualit&#228;tskriterien festgelegt? Es werden mehr synthetische Daten durch einen synthetischen
Optimierungsprozess erzeugt.
&#8226; Datenverf&#252;gbarkeit und Qualit&#228;t: Qualit&#228;t, Verl&#228;sslichkeit und Verifizierbarkeit von Daten sind
unabdingbar f&#252;r lernende Systeme im Mobilit&#228;tsraum.
&#8226; Lernen: Das Lernen muss organisiert und anhand geeigneter Qualit&#228;tskriterien und Regeln &#252;berwacht
werden, sodass sich auch f&#252;r unbekannte Szenarien ein gew&#252;nschtes, sicheres Verhalten ergibt.
&#8226; Sicherheit und Robustheit: Sicherheit und Robustheit gegen Fehler, St&#246;rungen und Angriffe ist zu
gew&#228;hrleisten. Es bedarf genauer Anforderungen f&#252;r durchweg definierte Betriebszust&#228;nde, auch muss es
Konzepte f&#252;r den Notbetrieb und die Wiederaufnahme des Betriebs nach St&#246;rungen oder Ausf&#228;llen geben.1624 
1616 Darstellung von Prof. Dr. Thomas Form (Leiter des Forschungsfeldes &#8222;Elektronik und Fahrzeug&#8220; in der Konzernforschung,
Volkswagen AG) in der Sitzung der Projektgruppe KI und Mobilit&#228;t am 16. Dezember 2019.
1617 Regeln sind ein Wenn-dann-Formalismus. Um ein Beispiel zu geben: Wenn eine Geschwindigkeitsbeschr&#228;nkung von 60 km/h
erkannt wurde und das Fahrzeug schneller als 60 km/h f&#228;hrt, dann ist ein Bremsvorgang einzuleiten. Die Gesamtzahl der Regeln
bestimmt das Verhalten des Autos. So kann es noch andere Regeln geben, die festlegen, dass das Auto bremsen soll.
1618 Die Enquete-Kommission schlie&#223;t die regelbasierte Anwendung in ihrer Definition von KI mit ein. In dem Zusammenhang ist die
von Prof. Dr.-Ing. Thomas Form gebrauchte Formulierung &#8222;KI im Allgemeinen&#8220; als &#8222;tiefes Maschinelles Lernen&#8220; zu lesen.
1619 Darstellung von Prof. Dr.-Ing. Thomas Form (Leiter des Forschungsfeldes &#8222;Elektronik und Fahrzeug&#8220; in der Konzernforschung,
Volkswagen AG) in der Sitzung der Projektgruppe KI und Mobilit&#228;t am 16. Dezember 2019.
1620 Im Zuge der KI-Entwicklung wird mehr und mehr die statistische Analyse angewandt. Dies wurde in den anderen Projektgruppen
ebenfalls thematisiert. Nach Auffassung von Prof. Dr.-Ing. Thomas Form soll der Automatismus im Fall zweier unsicherer &#8222;Ja&#8220; und
eines sicheren &#8222;Nein&#8220; dennoch f&#252;r &#8222;Nein entscheiden k&#246;nnen; Darstellung von Prof. Dr. Thomas Form (Leiter des Forschungsfeldes
&#8222;Elektronik und Fahrzeug&#8220; in der Konzernforschung, Volkswagen AG) in der Sitzung der Projektgruppe KI und Mobilit&#228;t am 16.
Dezember 2019. 
1621 Darstellung von Prof. Dr. Thomas Form (Leiter des Forschungsfeldes &#8222;Elektronik und Fahrzeug&#8220; in der Konzernforschung,
Volkswagen AG) in der Sitzung der Projektgruppe KI und Mobilit&#228;t am 16. Dezember 2019.
1622 Darstellung von Prof. Dr. Thomas Form (Leiter des Forschungsfeldes &#8222;Elektronik und Fahrzeug&#8220; in der Konzernforschung,
Volkswagen AG) in der Sitzung der Projektgruppe KI und Mobilit&#228;t am 16. Dezember 2019.
1623 ODD: Abk&#252;rzung f&#252;r Operational Design Domain. Dabei handelt es sich um das Umfeld, f&#252;r das die Anwendung entwickelt
wurde, z. B. Tageszeit, Jahreszeit (und davon abh&#228;ngig Sonne, Regen, Nebel usw.), Ort auf der Welt, Autobahn oder Sandpiste,
Rechts-/Links-Verkehr etc.
1624 Vgl. Plattform Lernende Systeme (2019): Auf dem Weg zu einem intelligenten Mobilit&#228;tsraum.
Bereits heute gibt es erfolgreiche Anwendungen des autonomen Fahrens in begrenzten R&#228;umen.1625 Aus Sicht
der Anh&#246;rperson der Automobilbranche muss hierbei die Sicherheit aus dem Auto heraus kommen.1626 Damit 
einhergehend ist es Fakt, dass f&#252;r das autonome Fahren eine umfangreiche Sensorik am Fahrzeug ben&#246;tigt wird.
Mithilfe der Sensortechnik kann eine KI die Umgebung wahrnehmen und verstehen. Die KI kann den Standort
bestimmen und die Fahrfunktionen ausf&#252;hren sowie das Verhalten des eigenen Fahrzeugs und das Verhalten
anderer Personen vorhersagen, die am Verkehr teilnehmen. Der technische Zustand des Fahrzeugs kann weiterhin
&#252;berwacht und Instandsetzungen k&#246;nnen geplant werden.1627 
Trotz dieser Fortschritte gibt es dennoch potenzielle Herausforderungen. Angriffe auf die Datenverarbeitung
autonomer Fahrzeuge stellen ein Sicherheitsproblem dar, diese werden in Kapitel 4.7.2 dieses
Projektgruppenberichts [KI mit Blick auf &#214;konomie und Wettbewerb] umfassender behandelt. Zu diesen geh&#246;rt z. B. das
sogenannte Adversarial Attack bzw. Adversarial Machine Learning. Adversarial Machine Learning ist insbesondere
aufgrund des Black-Box-Ansatzes der KI problematisch.1628 Die Aussage der Anh&#246;rperson aus der
Automobilbranche (&#8222;Sicherheit muss aus dem Auto heraus kommen.&#8220;) wird zus&#228;tzlich aus der Perspektive der Zulieferer
anders zugeordnet:1629 Autonomes Fahren ist hier nur dann erfolgreich, wenn die Umwelt von der KI einfacher
erfasst werden kann. Objekterkennungen sollen so z. B. &#252;ber Smart City-Infrastrukturen laufen.1630 Wichtig ist
also &#8222;das &#214;kosystem&#8220;1631.
Diskutiert wird dabei die Rolle von fahrzeugbezogenen und infrastrukturbezogenen Aspekten. F&#252;r die
Automobilbranche ist es naheliegend, dass das Fahrzeug in jeder Infrastruktur autonom fahren soll bzw. muss.
Gleichzeitig unterscheidet sich jedoch die Infrastruktur weltweit voneinander, wodurch die Herausforderungen des
autonom fahrenden Fahrzeugs auch unterschiedlich ausfallen. In Deutschland und Europa ist es durchaus denkbar,
dass die Infrastruktur, die den Verkehrsfluss (mit KI) verbessert, auch dem Fahrzeug direkt Daten &#252;bermittelt,
um diesem das autonome Fahren zu erleichtern (ein Beispiel hierf&#252;r sind Verkehrszeichen, die zus&#228;tzlich &#252;ber
Funk &#252;bertragen werden). Schlussfolgernd l&#228;sst sich somit sagen, dass sowohl die Technik aus dem Auto heraus
als auch die Umgebung als &#8222;&#214;kosystem&#8220; wichtige Aspekte im Gesamtkontext des autonomen Fahrens sind.
Vielfach in der Wissenschaft und Gesellschaft diskutiert werden dar&#252;ber hinaus die ethischen Punkte des
autonomen Fahrens, insbesondere der Aspekt, wie die KI im Falle eines Unfalls reagieren muss. Die Diskussion, wen
ein Auto im Fall eines unausweichlichen Unfalls erfasst, wird akademisch gef&#252;hrt. Mit Verweis auf den eingangs
erw&#228;hnten Bericht der &#8222;Ethik-Kommission Automatisiertes und Vernetztes Fahren&#8220; ist der aktuelle Stand der,
dass die Vermeidung eines Personenschadens stets Vorrang vor der Vermeidung eines Sachschadens hat.
Dar&#252;ber hinaus ist ein weiterer Aspekt der Diskussion im Bereich des autonomen Fahrens die Frage der Haftung
und wie diese juristisch geregelt werden kann.
Mit der Einf&#252;hrung automatisierter und autonomer Systeme sowohl in Fahrzeugen als auch &#252;bergreifend im
Stra&#223;enverkehr geht die Frage einher, wie in Zukunft die Haftung f&#252;r Sch&#228;den angemessen verteilt werden soll. Als
Haftungsadressaten bei automatisierten und vernetzten Fahrsystemen kommen Fahrerinnen und Fahrer,
Hersteller und Betreiber der erforderlichen technischen Systeme sowohl im Fahrzeug selbst als auch der sonst
notwendigen Infrastruktur und Fahrzeughalter in Betracht. Gesetzliche Haftungsregelungen und ihre Konkretisierung in 
der gerichtlichen Entscheidungspraxis m&#252;ssen diesem &#220;bergang hinreichend gerecht werden. Derzeit ist
allerdings keine Notwendigkeit ersichtlich, Anpassungen im geltenden Haftungsrecht vorzunehmen. F&#252;r die Haftung
1625 Darstellung von Dr. Manuel G&#246;tz (Head of AI &amp; Cyber Security Technology Center, ZF Friedrichshafen) in der Sitzung der
Projektgruppe KI und Mobilit&#228;t am 16. Dezember 2019.
1626 Darstellung von Prof. Dr. Thomas Form (Leiter des Forschungsfeldes &#8222;Elektronik und Fahrzeug&#8220; in der Konzernforschung,
Volkswagen AG) in der Sitzung der Projektgruppe KI und Mobilit&#228;t am 16. Dezember 2019.
1627 Vgl. Fraunhofer-Institut f&#252;r sichere Informationstechnologie (2019): SeDaFa.
1628 Das Problem der KI ist, dass nicht f&#252;r jeden Fall und im Vorhinein festgestellt werden kann, wie sich eine trainierte KI verh&#228;lt und 
warum sie sich so verh&#228;lt. So ist z. B. nicht klar, warum eine KI eine Geschwindigkeitsbeschr&#228;nkung auf 60 km/h erkennt. Neural
Hacking macht sich das zunutze und experimentiert so lange, bis eine optische Darstellung gefunden wird, die der Mensch als 60 km/h 
und die KI zum Beispiel als 90 km/h erkennt. Die Erkl&#228;rbarkeit der KI, die heute in aller Munde ist, kann nur im Nachhinein erkl&#228;ren,
warum die KI in dem oben genannten Fall 90 km/h erkannt hat. Dies ist aber nicht ausreichend, um im Vorhinein sicherzustellen,
dass eine KI ein Verkehrsschild immer richtig erkennt.
1629 Darstellung von Demetrio Aiello (Head of the Artificial Intelligence &amp; Robotics Labs Cross Divisional Systems &amp; Technology
Corporate Systems &amp; Technology, Continental AG) in der Sitzung der Projektgruppe KI und Mobilit&#228;t am 16. Dezember 2019.
1630 Darstellung von Demetrio Aiello (Head of the Artificial Intelligence &amp; Robotics Labs Cross Divisional Systems &amp; Technology
Corporate Systems &amp; Technology, Continental AG) in der Sitzung der Projektgruppe KI und Mobilit&#228;t am 16. Dezember 2019.
1631 &#214;kosystem in diesem Kontext bezeichnet z. B. Karten f&#252;r das Auto, GPS, Trainingsdaten, Sensoren &#8211; alles, was man zum autonomen 
Fahren braucht; Darstellung von Dr. Manuel G&#246;tz (Head of AI &amp; Cyber Security Technology Center, ZF Friedrichshafen) in der
Sitzung der Projektgruppe KI und Mobilit&#228;t am 16. Dezember 2019.
f&#252;r Sch&#228;den durch aktivierte automatisierte Fahrsysteme gelten dieselben Grunds&#228;tze wie in der &#252;brigen
Produkthaftung. Daraus folgt, dass Hersteller oder Betreiber verpflichtet sind, ihre Systeme fortlaufend zu optimieren 
und auch bereits ausgelieferte Systeme zu beobachten und zu verbessern, wo dies technisch m&#246;glich und
zumutbar ist.1632 
Der aktuelle Stand ist somit der, dass bei fahrerlosen Systemen und bestimmungsgem&#228;&#223;em Gebrauch die
Verantwortung beim Hersteller und Betreiber liegt. In allen anderen F&#228;llen teil- oder vollautomatisierter Fahrsysteme
sind die Verantwortungssph&#228;ren von Hersteller und Betreiber einerseits und Fahrerinnen und Fahrern
andererseits abzugrenzen. Es muss daher klar zu unterscheiden sein, ob ein fahrerloses System genutzt wird oder eine
Fahrerin oder ein Fahrer mit der M&#246;glichkeit des &#220;bersteuerns oder Abschaltens Verantwortung beh&#228;lt. Bei
nicht-fahrerlosen Systemen muss die Mensch-Maschine-Schnittstelle so ausgelegt sein, dass zu jedem Zeitpunkt
klar geregelt und erkennbar ist, welche Zust&#228;ndigkeiten auf welcher Seite liegen. Dies gilt insbesondere f&#252;r die
Kontrolle.1633 
Dazu geh&#246;rt auch, dass die Person, die das Fahrzeug f&#252;hrt, in den Geschehensablauf eingreifen kann, wenn das
technische System ihre Sicherheit nicht mehr gew&#228;hrleisten kann. Eine abrupte &#220;bergabe kann jedoch auch dazu
f&#252;hren, dass sie keinen Nutzen mehr aus dem hochautomatisierten Fahren ziehen kann. Sofern eine &#220;bergabe an
die Person zeitlich nicht mehr m&#246;glich ist, muss zuk&#252;nftig in Ausnahme- und Notsituationen die Kontrolle zur
Herstellung eines sicheren Fahrzeugzustands beim Fahrzeug bleiben, sofern damit eine gr&#246;&#223;tm&#246;gliche Sicherheit
der Nutzerinnen und Nutzer sowie anderer Betroffener gewahrt bleibt. Diese Schlussfolgerungen wurden
ebenfalls bereits im Bericht der Ethikkommission im Auftrag des BMVI vom Juni 2017 erarbeitet und
ver&#246;ffentlicht.1634 
Die Ethikkommission lehnt es weiterhin ab, daraus zu folgern, dass das Leben von Menschen in Notsituationen
mit dem anderer Menschen &#8222;verrechnet&#8220; werden darf. Sie qualifiziert die T&#246;tung bzw. schwere Verletzung von 
Personen durch autonome Fahrzeugsysteme ausnahmslos als Unrecht. 
In Bezug auf den ethischen Aspekt des autonomen Fahrens k&#246;nnte dann anders zu entscheiden sein, wenn
mehrere Leben unmittelbar bedroht sind und es nur darum geht, so viele Unschuldige wie m&#246;glich zu retten. Wie die
Ethikkommission in ihrem Bericht festgestellt hat1635, gibt es in derartigen Situationen kein ethisch richtiges oder
falsches Verhalten, da Menschenleben nicht gegeneinander aufgewogen werden d&#252;rfen. Hier hatte die
Ethikkommission ihre Diskussion noch nicht befriedigend und auch nicht in jeder Hinsicht einvernehmlich zu Ende f&#252;hren
k&#246;nnen. Es wurden vertiefende Untersuchungen angeregt, deren Erforderlichkeit von den Mitgliedern der
Enquete-Kommission K&#252;nstliche Intelligenz noch einmal untermauert wird.
In der Gesamtheit der Fragen muss darauf geachtet werden, welche juristischen Regularien bereits vorhanden 
sind1636 und genutzt werden k&#246;nnen, wenn es z. B. um eine Standardisierung geht, und in welchen Bereichen
gesetzlich nachjustiert werden muss.
4.3.5 KI und Organisation der Stra&#223;e
Bez&#252;glich der Organisation der Stra&#223;e im Bereich KI sagt das Fraunhofer IAIS eine lange &#220;bergangsphase
voraus, die durch ein Nebeneinander von autonomen oder KI-gesteuerten Systemen und herk&#246;mmlichen
Steuertechnologien gekennzeichnet sein wird.1637 Die kombinierte Nutzung von bemannten und (teilautonomen)
Fahrzeugen, wie sie bereits in milit&#228;rischen Forschungsprojekten getestet wird, kann als Modell f&#252;r den zivilen
Stra&#223;enverkehr, besonders w&#228;hrend der &#220;bergangsphase, fungieren.1638 Die fl&#228;chendeckende Verf&#252;gbarkeit einer
ad&#228;quaten Daten&#252;bertragungsinfrastruktur ist essenziell f&#252;r die Einf&#252;hrung intelligenter Stra&#223;enmobilit&#228;t und die
Steigerung des Autonomiegrades. Die Daten, die von modernen mobilen Verkehrstr&#228;gersystemen generiert
werden, &#252;bersteigen die Kapazit&#228;ten bestehender Netzwerke bei Weitem. Die Betreiber von Verkehrsinfrastrukturen
1632 Vgl. Ethik-Kommission (2017): Automatisiertes und Vernetztes Fahren.
1633 Vgl. Ethik-Kommission (2017): Automatisiertes und Vernetztes Fahren.
1634 Vgl. Ethik-Kommission (2017): Automatisiertes und Vernetztes Fahren.
1635 Vgl. Ethik-Kommission (2017): Automatisiertes und Vernetztes Fahren, S. 11, Nr. 8.
1636 Wie zuvor im Kapitel 4.3.3 dieses Projektgruppenberichts [Status quo] beschrieben muss nach aktuellem Recht eine
&#8222;bestimmungsgem&#228;&#223;e Verwendung&#8220; gem&#228;&#223; &#167; 1a Absatz 1 StVG gew&#228;hrleistet sein. Zus&#228;tzlich wurde mit dem Gesetzentwurf zur &#196;nderung des
sogenannten Wiener &#220;bereinkommens &#252;ber den Stra&#223;enverkehr bereits 2016 eine erste Rechtssicherheit f&#252;r die Nutzerinnen und 
Nutzer von Assistenz- bzw. automatisierten Fahrsystemen geschaffen, vgl. Bundesregierung (2016): Rechtssicherheit f&#252;r
automatisiertes Fahren.
1637 Vgl. Hecker (2019): KI made in Germany.
1638 Vgl. Universit&#228;t der Bundeswehr: MUM-T.
und Industrieanlagen w&#252;nschen sich einen l&#252;ckenlosen Ausbau des Mobilfunknetzes mit dem Ziel, LTE als
Standard zu etablieren, und die Implementierung von lokal verf&#252;gbaren 5G-Netzen.1639 Im Zuge der 5G-
Frequenzversteigerungen im Jahr 2019 wurden hier die n&#246;tigen Ausbauauflagen vorgegeben.1640 Gleichzeitig kann KI
helfen, Verkehrsstr&#246;me besser zu verstehen und bei der Planung von Verkehrsinfrastruktur und der Organisation
des Stra&#223;enverkehrs unterst&#252;tzen. So nutzt die britische Verkehrsbeh&#246;rde Transport for London (TfL) KI zur 
Erkennung von Radfahrerinnen und Radfahrern, Fu&#223;g&#228;ngerinnen und Fu&#223;g&#228;ngern, Pkw und Lkw, um
Ausbaubedarf f&#252;r Fahrradinfrastruktur zielgenau ermitteln zu k&#246;nnen.1641 
4.3.6 KI und Organisation der Mobilit&#228;t
Datenerzeugung und -nutzung
Vernetzte Fahrzeuge sind in der Lage, permanent gro&#223;e Datenmengen aus ihrer internen Sensorik an potenzielle
Nutzerinnen und Nutzer zu senden.1642 Die K&#228;ufer der in den Fahrzeugen gewonnenen Datenpakete k&#246;nnen aus
den Informationen einen Mehrwert generieren. M&#246;gliche K&#228;ufer fahrzeuginterner Sensorprotokolle k&#246;nnten
Werkst&#228;tten, Ersatzteilproduzenten, Fahrzeughersteller, Versicherungen oder Beh&#246;rden sein. Die neuen
Anwendungen und Gesch&#228;ftsmodelle bergen zahlreiche Risiken f&#252;r den Datenschutz der B&#252;rgerinnen und B&#252;rger.
Ein Beispiel f&#252;r problematische Folgen des intelligenten Fahrens aus dem Bereich Predictive Maintenance ist die 
Erfassung des Bremsverhaltens und der m&#246;glichen Folgen. Es besteht ein gro&#223;es Interesse verschiedener Akteure,
das Bremsverhalten und den Verschlei&#223; der Bremsgruppe im Fahrzeug zu erfassen. Hersteller oder
Servicewerkst&#228;tten k&#246;nnen der Fahrerin oder dem Fahrer eine Nachricht senden, sobald die Bremsen ein kritisches
Verschlei&#223;niveau erreicht haben, und eine Instandsetzung veranlassen. Allerdings gilt das Bremsverhalten auch als
Parameter, &#252;ber den sich die Sicherheit und Versiertheit der Fahrerin oder des Fahrers einsch&#228;tzen l&#228;sst.1643 Es 
ist denkbar, dass Versicherungsunternehmen diese Daten erwerben und dass der oder dem Einzelnen Nachteile
aus dieser Datenbereitstellung entstehen. &#196;hnliches gilt f&#252;r fahrzeuginterne Optronik, die den Wachzustand oder
die K&#246;rperposition der Fahrerin oder des Fahrers, errechnete Verhaltens- oder Bewegungsmuster sowie eine
Vielzahl anderer fahrzeuggebundener Datens&#228;tze erfasst.1644 Hier gilt es festzustellen, inwiefern die generierten
Daten im Rahmen der Datenschutzgrundverordnung weiterverarbeitet werden d&#252;rfen.
Die Entwicklung von Software-Applikationen, die Infrastruktur und die grundlegende Konfiguration der
Fahrzeuge m&#252;ssen so gestaltet sein, dass ein datenschutzfreundlicher Betrieb m&#246;glich wird. Das bedeutet vor allem,
dass Nutzerinnen und Nutzer l&#252;ckenlos und transparent dar&#252;ber informiert werden m&#252;ssen, welche Daten
&#252;bertragen werden und wer sie wozu nutzt. Die gr&#246;&#223;tm&#246;gliche Daten&#252;bertragung unter datenschutzrechtlich
einwandfreien Bedingungen sollte angestrebt werden (Beispiel: Projekt Fraunhofer SIT, SEDAFA1645).
Institutionen wie zum Beispiel der Verkehrsclub Deutschland e. V. (VCD) warnen vor zunehmenden
Systemabh&#228;ngigkeiten und der Gefahr von Cyberangriffen auf das System der Verkehrssteuerung.1646 Neben den
potenziellen Angriffen auf die Verkehrssteuerung muss auch auf die wachsende Gefahr von Cyberangriffen direkt auf
voll- und teilautonome Fahrzeuge geachtet werden.
1639 Vgl. Fraunhofer-Allianz autoMOBILproduktion (2019): Mobilit&#228;t der Zukunft muss produziert werden.
1640 Vgl. Bundesnetzagentur: Frequenzaktion 2019.
1641 Vgl. Fahrradportal (2020): K&#252;nstliche Intelligenz hilft Verkehrsstr&#246;me in London besser zu verstehen; zu TfL vgl. Mayor of London
(2020): Artificial intelligence to help fuel London&#8217;s cycling boom.
1642 Vgl. Fridman et al. (2019): MIT Advanced Vehicle Technology Study: Large-Scale Naturalistic Driving Study of Driver Behavior
and Interaction With Automation.
1643 Darstellung von Christoph Weigler (General Manager, Uber Germany) in der Sitzung der Projektgruppe KI und Mobilit&#228;t am 13.
Januar 2020.
1644 Vgl. Fridman et al. (2019): MIT Advanced Vehicle Technology Study: Large-Scale Naturalistic Driving Study of Driver Behavior
and Interaction With Automation.
1645 Vgl. Fraunhofer-Institut f&#252;r sichere Informationstechnologie (2019): SeDaFa.
1646 Stellungnahme von Dr. Uwe B&#246;hme (Projektleiter &#8222;Autonom unterwegs in der Stadt&#8220; des Verkehrsclub Deutschland e. V.),
Projektgruppendrucksache 19(27)PG 5-26 vom 21. Januar 2020.
G&#252;ter
Im Themenbereich Logistik/G&#252;ter kann eine mit KI optimierte Disposition zu einer h&#246;heren und somit auch
effektiveren Auslastung f&#252;hren.1647 Eine bessere L&#246;sung mittels KI zu finden ist im Vergleich zur klassischen
Optimierung sehr vielversprechend. In einem Umfeld mit vielen Unsicherheiten (z. B. Staus auf der geplanten
Strecke) kann durch KI wahrscheinlich ein Optimum gefunden werden.1648 Eine Erh&#246;hung der Auslastung hat
&#246;konomisches und &#246;kologisches Potenzial. Noch gr&#246;&#223;er ist dieses Potenzial, wenn der Transport von G&#252;tern auf
Schiene und Stra&#223;e gemeinsam betrachtet wird. Deshalb w&#228;re ein ganzheitlicher Optimierungsansatz f&#252;r den
G&#252;tertransport extrem wichtig.
4.3.7 Die Erh&#246;hung der Sicherheit und die ganzheitliche Betrachtung der Mobilit&#228;t
In den KI-Technologien steckt gro&#223;es Potenzial f&#252;r die Erh&#246;hung der allgemeinen Verkehrssicherheit. Dem Ziel
der im Jahr 2007 vom Deutschen Verkehrssicherheitsrat (DVR) formulierten &#8222;Vision Zero&#8220;, keine Toten und
Schwerverletzten im Stra&#223;enverkehr mehr zu haben, l&#228;sst sich mithilfe von KI n&#228;herkommen.1649 Die
M&#246;glichkeiten von KI, Unf&#228;lle zu verhindern und Leib und Leben von Personen zu sichern, die ein Fahrzeug f&#252;hren, 
wurden auch in der Sitzung der Projektgruppe angesprochen.
Hohe Geschwindigkeit und unangepasstes Verhalten sind Ursachen f&#252;r t&#246;dliche Unf&#228;lle und Unf&#228;lle mit
schwerverletzten Personen.1650 Der Einsatz von KI kann hier als Warnsystem agieren und vorausschauend unterst&#252;tzen,
wie z. B. bei der Fahrer&#252;berwachung. Durch diese soll zum Beispiel bei M&#252;digkeit eingegriffen oder Ablenkung
vermieden werden.1651 
Vollautonomes Fahren kann k&#252;nftig t&#246;dliche Unf&#228;lle verhindern.1652 Der Verkehrsclub Deutschland e. V. geht in 
seiner Stellungnahme vom Januar 2020 ebenfalls von einer Erh&#246;hung der Verkehrssicherheit durch autonome
oder KI-unterst&#252;tzte Fahrzeuge aus.1653 Zus&#228;tzlich muss in diesem Kontext auch auf die zuvor genannte Aussage
des Sachverst&#228;ndigen aus der Automobilbranche verwiesen werden, dass ein &#8222;Fehlverhalten&#8220; der Technik im 
Bereich des autonomen Fahrens &#8222;keine Option&#8220; ist.1654 Diskutiert wurde mit Blick auf eine ganzheitliche
Betrachtung der Mobilit&#228;t auch der Vorschlag einer flexibleren und offeneren, st&#228;rker als bisher vernetzten
Organisation von Logistik, um z. B. lange Leerfahrten und Mehrfachlieferungen an gleiche Adressen zu verringern und
damit auch das Verkehrsaufkommen wie auch den CO2-Aussto&#223; zu verringern, gleichzeitig aber hohe
Leistungsf&#228;higkeit in der Logistik zu gew&#228;hrleisten.1655 
4.3.8 Handlungsempfehlungen
Deutschland bzw. Europa stehen im globalen Wettbewerb insbesondere mit Unternehmen aus einem nicht-
automobilen Umfeld. Die Komplexit&#228;t der Funktionen, die notwendigen Absicherungsverfahren und die noch nicht
in ausreichendem Umfang vorhandenen Normen zur Definition eines anerkannten Stands der Technik und
Zulassungsrichtlinien erfordern verschiedenste Ma&#223;nahmen.
Zusammenarbeit zwischen Herstellern und Forschung f&#246;rdern
Es bedarf einer intensiven hersteller&#252;bergreifenden vorwettbewerblichen Zusammenarbeit von Industrie
(Fahrzeughersteller und Zulieferindustrie), Forschungseinrichtungen und Beh&#246;rden.
1647 Darstellung von Andreas Karanas (Gr&#252;nder und Gesch&#228;ftsf&#252;hrer der Carrypicker GmbH) in der Sitzung der Projektgruppe KI und
Mobilit&#228;t am 16. Dezember 2019.
1648 Darstellung von Andreas Karanas (Gr&#252;nder und Gesch&#228;ftsf&#252;hrer der Carrypicker GmbH) in der Sitzung der Projektgruppe KI und
Mobilit&#228;t am 16. Dezember 2019.
1649 Vgl. Deutscher Verkehrssicherheitsrat: Vision Zero.
1650 Vgl. spiegel.de (2020): Hohes Tempo Hauptgrund f&#252;r Verkehrstote.
1651 Darstellung von Dr. Manuel G&#246;tz (Head of AI &amp; Cyber Security Technology Center, ZF Friedrichshafen) in der Sitzung der
Projektgruppe KI und Mobilit&#228;t am 16. Dezember 2019.
1652 Darstellung von Christoph Weigler (General Manager, Uber Germany) in der Sitzung der Projektgruppe KI und Mobilit&#228;t am 13.
Januar 2020.
1653 Stellungnahme von Dr. Uwe B&#246;hme (Projektleiter &#8222;Autonom unterwegs in der Stadt&#8220; des Verkehrsclub Deutschland e. V.),
Projektgruppendrucksache 19(27)PG 5-26 vom 21. Januar 2020.
1654 Darstellung von Prof. Dr. Thomas Form (Leiter des Forschungsfeldes &#8222;Elektronik und Fahrzeug&#8220; in der Konzernforschung,
Volkswagen AG) in der Sitzung der Projektgruppe KI und Mobilit&#228;t am 16. Dezember 2019.
1655 Darstellung von Dr. Manuel G&#246;tz (Head of AI &amp; Cyber Security Technology Center, ZF Friedrichshafen) in der Sitzung der
Projektgruppe KI und Mobilit&#228;t am 16. Dezember 2019.
Ressort&#252;bergreifende F&#246;rderung st&#228;rken
Weiterhin ist eine st&#228;rkere ressort&#252;bergreifende Synchronisierung und Fokussierung der F&#246;rderlandschaft n&#246;tig,
was bereits in vielversprechenden Ans&#228;tzen mit BMWi, BMVI und BMBF &#252;ber die VDA-Leitinitiative begonnen
wurde.
F&#246;rderrichtlinien anpassen
Angesichts der Komplexit&#228;t der Aufgabe sollten die F&#246;rderrichtlinien bez&#252;glich Hochschulen &#252;berdacht
100-Prozent-F&#246;rderung im Zusammenhang mit Gro&#223;projekten), bez&#252;glich notwendiger KMU-Quoten
angepasst bzw. reduziert und f&#252;r die einfachere Teilnahme von Beh&#246;rden (z. B. BASt1656 oder KBA1657) angepasst
werden. Deren Teilnahme hat sich in der Vergangenheit wegen haushalts- und anderer rechtlicher
Herausforderungen vielfach problematisch gestaltet. 
Rechtliche Klarheit in der Zusammenarbeit schaffen
Bei der vorwettbewerblichen hersteller&#252;bergreifenden Zusammenarbeit erweist sich weniger die Einigung auf
die technischen Projektziele/-inhalte als Herausforderung als vielmehr die Einigung auf eine subjektive, rechtlich
einwandfreie Vertragsgestaltung zwischen Forschungseinrichtungen, Beh&#246;rden und Industrie. Hier gilt es, ein
einheitliches System zu etablieren, um die Kooperationen zu st&#228;rken und rechtliche Klarheit zu schaffen.
Insbesondere beim autonomen Fahren spielt dies eine extrem wichtige Rolle.
Einen europ&#228;ischen Weg gew&#228;hrleisten
Die Beachtung datenschutzrechtlicher Standards, wettbewerbsrechtlicher Vorgaben sowie die Akteursvielfalt auf
Anbieterseite &#8211; von kommunalen Verkehrsverb&#252;nden &#252;ber Automobilherstellern bis zu Start-ups &#8211; gilt es f&#252;r 
einen europ&#228;ischen Weg ebenfalls zu gew&#228;hrleisten. Dies kann eine Herausforderung, aber auch eine gro&#223;e
Chance gerade gegen&#252;ber der weltweiten Konkurrenz sein.
Der Mensch steht im Mittelpunkt
Bei allen KI-Anwendungen in der Mobilit&#228;t &#8211; und hier im Bereich Stra&#223;e &#8211; muss der Mensch im Mittelpunkt
stehen. Dabei ist die Besonderheit, dass im Verkehrsbereich eine enge Koexistenz von KI- und Nicht-KI-
L&#246;sungen erwartet wird. Entsprechend sind bei der Entwicklung und Nutzung von KI-Anwendungen der Zugang zu
Systemen, Transparenz, der Zugang zur Nutzung von Anwendungen sowie Fragen von Selbstbestimmung und
Sicherheit zentral.
Digitale Infrastruktur ausbauen
F&#252;r die Mobilit&#228;t der Zukunft, insbesondere im Bereich der Stra&#223;e, muss der Infrastrukturaspekt diskutiert
werden. Trotz aktueller Diskussionen und des beginnenden Ausbaus des 5G-Netzes muss betrachtet werden, welche
M&#246;glichkeiten bereits mit der vorhandenen Infrastruktur realisiert werden k&#246;nnen. Neben dem LTE-Netz f&#252;r die
Kommunikation zwischen den Fahrzeugen muss auch die Nutzung von WLAN, insbesondere im innerst&#228;dtischen
Bereich, ausgebaut werden.
Rahmenbedingungen etablieren
Technische, rechtliche und planerische Voraussetzungen f&#252;r autonome Mobilit&#228;tsangebote im Personenverkehr
m&#252;ssen getestet und definiert werden, damit geeignete Rahmenbedingungen f&#252;r Anbieter etabliert werden
k&#246;nnen. Hier gilt: Je mehr Testfelder, desto besser. Der europ&#228;ische Raum erm&#246;glicht durch seine Diversit&#228;t eine 
Vielzahl von unterschiedlichsten Testoptionen.
1656 BASt: Abk&#252;rzung f&#252;r Bundesamt f&#252;r Stra&#223;enwesen, weitere Informationen dazu unter:
https://www.bast.de/BASt_2017/DE/Home/home_node.html (zuletzt abgerufen am 10. September 2020).
1657 KBA: Abk&#252;rzung f&#252;r Kraftfahrt-Bundesamt, weitere Informationen dazu unter: https://www.kba.de/DE/Home/home_node.html 
(zuletzt abgerufen am 10. September 2020).
Entwicklung im Sicherheitsbereich vorantreiben
Das Potenzial von KI zur Erreichung der Vision Zero muss bei der Entwicklung von KI-Anwendungen im
Mobilit&#228;tsbereich eine besondere Position einnehmen. Dabei ist es wichtig, die Entwicklung von KI-Systemen nicht 
nur auf das Fahrzeug zu beschr&#228;nken, sondern die damit verbundene Weiterentwicklung des Rechtsrahmens vor
allem auch auf Aspekte der der Sicherheit des Umfelds hin zu &#252;berpr&#252;fen.
Schienenverkehr
4.4.1 Status quo und Politik
Gesellschaft
Die Errungenschaften des Auf- und Ausbaus des Schienen- und Nahverkehrs f&#252;r Gesellschaft und Wirtschaft
stellen uns heute aufgrund steigender Komplexit&#228;t vor neue Herausforderungen. Die Netzbelastung der deutschen
Eisenbahninfrastruktur ist in den letzten Jahren stark gestiegen.1658 Die Zunahme des Verh&#228;ltnisses Zugfahrten
pro Streckenl&#228;nge (Trassenkilometer je Kilometer Betriebsl&#228;nge) erh&#246;hte sich von 1999 bis 2017 um &#252;ber 23
Prozent.
Da in der Vergangenheit Strecken stillgelegt wurden, das Verkehrsaufkommen aber gleichzeitig zunahm,
konzentriert sich der Verkehr auf bestimmte Korridore. 85 Prozent des Verkehrs konzentriert sich etwa auf ca.
60 Prozent des Netzes.
Gleichwohl gilt es, den Zugang zu Mobilit&#228;t auf der Schiene sicherzustellen und sich weiteren
Herausforderungen stellen zu k&#246;nnen: Die weiterf&#252;hrende Digitalisierung und Implementierung von KI in der Mobilit&#228;t kann
auch und vor allem im Bereich der Schiene zu erheblichen Fortschritten in der Sicherheit, Effizienz, Planbarkeit
und Zuverl&#228;ssigkeit sowie nicht zuletzt in der &#214;kologie f&#252;hren.
Markt
Im September 2018 gab es in Deutschland 448 zugelassene &#246;ffentliche Eisenbahnverkehrsunternehmen. Sie
bieten f&#252;r jeden zug&#228;ngliche Personen- oder G&#252;terverkehrsdienste auf der Schiene an oder sind im Bereich
&#246;ffentlicher Schieneninfrastruktur t&#228;tig.
Das gr&#246;&#223;te Eisenbahnverkehrsunternehmen in Deutschland ist die bundeseigene Deutsche Bahn AG. Der Anteil
der Deutschen Bahn an der Verkehrsleistung im Schienenpersonenfernverkehr in Deutschland betrug 2018 laut
Bundesnetzagentur marktbeherrschende 99 Prozent.1659 
Das Schienennetz der Deutschen Bahn ist das gr&#246;&#223;te Europas &#8211; rund 33 400 Kilometer betrug die im Betrieb
befindliche L&#228;nge im Jahr 2019.1660 
Den &#214;PNV nutzten 2018 rund 10,5 Milliarden Fahrg&#228;ste.1661 Werden dabei die Transporte mit Bussen
ausgenommen, so nutzten 6,3 Milliarden Fahrg&#228;ste entweder Z&#252;ge oder Stra&#223;enbahnen. Rund 2,6 Milliarden Reisende
z&#228;hlte davon allein die Deutsche Bahn AG im Jahr 2019.1662 Erkl&#228;rtes Ziel der Unternehmen, aber auch der
Politik in Deutschland ist ein weiterer Zuwachs des Personen- und G&#252;terverkehrs auf der Schiene. Dieses
Vorhaben geht aus gesellschaftlicher Sicht &#252;ber die unternehmerische Gewinn- und Effizienzsteigerung hinaus, da
man sich einen starken Beitrag zur Bew&#228;ltigung der &#246;kologischen Herausforderungen unserer Zeit erwartet.
Die Herausforderungen wiederum, denen sich die Betreiber des Personenverkehrs gegen&#252;bersehen, sind
mannigfaltig:
&#8226; die gr&#246;&#223;ere Zunahme der Anzahl der Fahrg&#228;ste im Vergleich zur Zunahme der Flottenkapazit&#228;t
&#8226; die Notwendigkeit des Ausbaus und Modernisierung der Infrastruktur (Hardware)
&#8226; die Instandhaltung und Weiterentwicklung der Flottenfahrzeuge
&#8226; die &#220;berlastung der Netze
&#8226; das Vorantreiben der digitalen Infrastruktur inkl. 5G
1658 Vgl. Ferlemann: Gemeinsam auf dem Weg zum Schienenverkehr der Zukunft &#8211; erste Ergebnisse des Zukunftsb&#252;ndnis Schiene.
1659 Vgl. Bundesnetzagentur (2018): Jahresbericht 2018, S. 115.
1660 Vgl. Deutsche Bahn AG (2019): Integrierter Zwischenbericht Januar &#8211; Juni 2019.
1661 Vgl. Verband Deutscher Verkehrsunternehmen (2019): 2018 &#8211; Statistik.
1662 Vgl. Deutsche Bahn AG (2019): Integrierter Zwischenbericht anuar &#8211; Juni 2019.
&#8226; die Notwendigkeit der Entwicklung neuer Pr&#252;f- und Zertifizierungsmethoden f&#252;r digitale Anwendungen
&#8226; die Nutzung von Daten f&#252;r die Weiterentwicklung der Angebote
&#8226; die Aus- und Weiterbildung des Personals
&#8226; die Gewinnung, Aus- und Weiterbildung des Personals von morgen
Neben dem Personennahverkehr spielt auch der G&#252;terverkehr f&#252;r Deutschland als Transitland eine zentrale Rolle.
Ein erkl&#228;rtes Ziel in der Mobilit&#228;tsplanung ist es seit Jahren, mehr G&#252;terverkehr von der Stra&#223;e auf die Schiene
zu verlagern. Mit einem Marktanteil von knapp 50 Prozent auf der Schiene ist die Deutsche Bahn AG hierzulande
auch in diesem Bereich unbestrittener Marktf&#252;hrer und spielt auch in Europa eine gro&#223;e Rolle. In 17 L&#228;ndern ist
DB Cargo selbst, &#252;ber Tochterunternehmen oder mit Partnerbahnen aktiv. Bei einem Unternehmen dieser Gr&#246;&#223;e
und entsprechender internationaler Vernetzung spielt die Frage der Implementierung der KI eine zentrale Rolle.
Mehr als 60 Prozent des G&#252;terverkehrs der Deutschen Bahn &#252;berquert mindestens eine Grenze. Allerdings ist
ihre Transportleistung seit Jahren r&#252;ckl&#228;ufig, 2018 waren es noch rund 256 Millionen Tonnen und damit 6
Prozent weniger G&#252;ter als ein Jahr zuvor &#8211; zu Beginn dieses Jahrzehnts waren mehr als 400 Millionen Tonnen &#252;blich,
der operative Verlust betrug im Jahr 2018 190 Millionen Euro.1663 
Um die Wettbewerbsf&#228;higkeit und Attraktivit&#228;t der Schiene im G&#252;terverkehr zu steigern und wieder mehr G&#252;ter
auf die Schiene zu bekommen, sind mannigfaltige Herausforderungen in den n&#228;chsten Jahren zu bew&#228;ltigen:
&#8226; Notwendiger Aufbau von neuen Verladestellen und &#220;berholgleisen
&#8226; Optimierung von Logistikstrecken unter intermodalen Gesichtspunkten (Einbeziehen von Bahn und LKW)
Technologien aus dem KI-Umfeld werden in vielen dieser Bereiche eine wichtige Komponente f&#252;r die L&#246;sung 
der heutigen Herausforderungen darstellen. Dar&#252;ber hinaus bieten KI-Technologien das Potenzial,
zukunftsf&#228;hige Strategien und Visionen f&#252;r den Sektor des Schienenverkehrs zu entwickeln &#8211; sowohl f&#252;r den Personen- als
auch den G&#252;terverkehr.
Politik
Die Politik hat sich im Bereich der Mobilit&#228;t in den vergangenen Jahren der Herausforderungen angenommen
und entsprechende Initiativen ins Leben gerufen.
F&#252;r den Bereich Schiene sind besonders der &#8222;Aktionsplan Schiene&#8220; sowie das &#8222;Zukunftsb&#252;ndnis Schiene&#8220; des 
Bundesministeriums f&#252;r Verkehr und digitale Infrastruktur (BMVI) zu nennen. Letzteres beinhaltet neben dem
Ziel eines p&#252;nktlicheren, zuverl&#228;ssigeren und flexibleren Bahnverkehrs auch das Ziel eines innovativeren
Bahnverkehrs, der f&#252;r die Zukunft ger&#252;stet sein soll.1664 
Der Aktionsplan soll f&#252;r deutlich h&#246;here Investitionen im Bahnsektor sorgen, um diesen zu modernisieren und
zu digitalisieren.1665 
Ein weiterer Aktionsplan des BMVI (&#8222;Digitalisierung und K&#252;nstliche Intelligenz in der Mobilit&#228;t&#8220;) besch&#228;ftigt
sich u. a. mit dem European Train Control System (ETCS), welches in der neuesten Generation das deutsche
Schienennetz weiter modernisieren und digitalisieren soll. Auf ETCS wird im Kapitel 4.4.2 dieses
Projektgruppenberichts [Potenziale] noch n&#228;her eingegangen.
Weiterhin soll die digitale Instandhaltung (Inspektion, Wartung und Instandsetzung) mit der Deutsche Bahn AG
vertieft werden. &#220;ber entsprechende Sensorik in &#8222;intelligenten Weichen&#8220; und die Diagnose- und
Analyseplattform DIANA1666 k&#246;nnen sich anbahnende Probleme eigenst&#228;ndig und fr&#252;hzeitig erkannt und gemeldet werden.
Dar&#252;ber hinaus spielt das autonome Fahren f&#252;r die Schiene k&#252;nftig eine gro&#223;e Rolle. Hierzu geh&#246;rt z. B. das
Erkennen von und Reagieren auf Gefahrensituationen. In einem ersten Schritt hat das BMVI in einem
Forschungsvorhaben Potenziale bewertet, Sicherheitsanforderungen analysiert sowie die &#220;bertragbarkeit auf das
deutsche Eisenbahnsystem gepr&#252;ft.1667 
1663 Vgl. dpa (2019): Jede Fahrt eine planerische Herausforderung.
1664 Vgl. Bundesministerium f&#252;r Verkehr und digitale Infrastruktur: Der Schienenpakt steht! Die Schiene ist f&#252;r uns der Verkehrstr&#228;ger
Nummer Eins.
1665 Vgl. Bundesministerium f&#252;r Verkehr und digitale Infrastruktur: Aktionsplan Schiene: Investieren, modernisieren, digitalisieren.
1666 Vgl. DB Vertrieb (2020): Digitale Weichendiagnose mit DIANA.
1667 Vgl. Bundesministerium f&#252;r Verkehr und digitale Infrastruktur (2018): Digitalisierung und K&#252;nstliche Intelligenz in der Mobilit&#228;t.
Die politischen Initiativen, Rahmenbedingungen, die Gesetzeslage sowie die Einbindung in den europ&#228;ischen 
Kontext werden fortw&#228;hrend evaluiert und weiterentwickelt.
4.4.2 Potenziale
Schon heute zeigen sich die vielf&#228;ltigen M&#246;glichkeiten der Effizienzsteigerung durch Digitalisierung und den
beginnenden Einsatz von KI. So kann die Wartung von Z&#252;gen durch digitale anstelle manueller &#220;berpr&#252;fung
beschleunigt und deutlich verbessert werden und so zugleich Mitarbeiterinnen und Mitarbeiter von k&#246;rperlich
anstrengenden Aufgaben entlasten. Gleiches gilt f&#252;r die Kontrolle von Schienen und Weichen, welche durch die
Implementierung von KI in Z&#252;gen des bestehenden Schienenverkehrs den Zeit- und Ressourcenaufwand um ein
Vielfaches verkleinern w&#252;rde, wobei KI als Erg&#228;nzung dienen kann. Gemeint sind hiermit zum Beispiel an
Radachsen angebrachte Sensoren, die Bild- und Tonmaterial in Echtzeit liefern k&#246;nnen.
Von der Analyse bis hin zur eigentlichen Wartung kann KI durch automatisierte Kommunikation zwischen
Daten, die von der Schiene gelesen werden, &#252;ber Schaltstellen bis hin zur ausf&#252;hrenden Einheit nicht nur
beschleunigen, sondern eine l&#228;ngerfristige Planung erm&#246;glichen. Somit wird die Logistik (z. B. Bestellverfahren von
Ersatzteilen, Planbarkeit von Bau- und Reparaturma&#223;nahmen) erleichtert und der Effizienzverlust minimiert.
Gleiches gilt im Bereich der Sicherheit auf der Schiene. Von witterungsbedingten Szenarien bis zu
personenverursachten Risiken in Bahnh&#246;fen und auf Gleisen sind intelligente Systeme bereits heute in der Lage, Gefahren
zu erkennen und nahezu umgehend (ohne menschliche Reaktionszeitverluste) sicherheitsrelevante Schritte wie
fr&#252;hzeitige Bremsman&#246;ver einzuleiten.
Autonomie ist ein Schl&#252;sselfeld f&#252;r den Schienenverkehr, um die Schienen- und Bef&#246;rderungskapazit&#228;t
signifikant zu erh&#246;hen. Gerade in diesem Bereich bietet die Autonomie schneller umsetzbare M&#246;glichkeiten, da
Sicherheitsaspekte bei dem &#8222;gef&#252;hrten Fahren&#8220; auf der Schiene leichter zu bew&#228;ltigen sind als beim PKW oder in der
Luft. Das European Train Control System (ETCS) zeigt bereits heute Wege auf, welche kontinuierlich
weiterentwickelt zu einer Sicherheits- und Effizienzsteigerung f&#252;hren, die mit Humanressourcen allein undenkbar
w&#228;re.1668 
Die Auspr&#228;gungen von ETCS werden in verschiedenen Ebenen (&#8222;Levels&#8220;) und Betriebsarten beschrieben und
umgesetzt. Mithilfe von KI sollten die Anwendungsauspr&#228;gungen von ETCS beschleunigt, ausgebaut und
weiterentwickelt werden, damit das Schienennetz bei der Mobilit&#228;t hohe Akzeptanz finden kann.
Auch im Bereich des Nahverkehrs halten KI-Technologien bereits Einzug
Im Segment der Stra&#223;enbahnen werden seit 2017 erste KI-Anwendungen zur Unterst&#252;tzung der Bahnf&#252;hrerin
bzw. des Bahnf&#252;hrers in Fahrerassistenzsystemen eingesetzt; beispielhaft wurde dies durch KI-Stra&#223;enbahn-
Tests von Siemens auf der Messe f&#252;r Verkehrstechnik InnoTrans 2018 in Potsdam demonstriert (6 Kilometer
Teststrecke).1669 Hindernisse im Fahrweg werden durch diese Assistenzsysteme fr&#252;hzeitig erkannt und
erm&#246;glichen, dass der Bremsvorgang automatisch ausgel&#246;st wird. Zuk&#252;nftig sollen diese Systeme auch detaillierter
zwischen unterschiedlichen Objekten wie Fu&#223;g&#228;ngerinnen und Fu&#223;g&#228;ngern, Signalen und Weichenanlagen
unterscheiden k&#246;nnen.
Die im Bereich Stra&#223;enbahnen bekannten Pilotprojekte zum autonomen Fahren, wie z. B. der 2018 vorgestellte
Prototyp von Siemens oder das Beispielprojekt von Thales in Karlsruhe, zielen derzeit noch prinzipiell darauf
ab, die Machbarkeit eines autonomen Fahrbetriebs einer Schienenbahn nachzuweisen.1670 Die technischen
Herausforderungen sind hier gro&#223;, da Stra&#223;enbahnen sich in der Regel in sehr offenen Infrastrukturen bewegen, sodass
die Fahr- und Umweltsituation st&#228;ndig neu prognostiziert und bewertet werden muss. Der Einsatz von autonom
fahrenden Stra&#223;enbahnen wird kurz- und mittelfristig als vielversprechend gesehen. Dies gilt insbesondere bei
Stra&#223;enbahn-Neubauprojekten, bei denen ein verkehrlicher und st&#228;dtebaulicher Rahmen zur Verf&#252;gung gestellt
wird, um die Vorteile einer autonomen Betriebsabwicklung ausnutzen zu k&#246;nnen. Hierbei sind die Komplexit&#228;t
und die Dynamik der Stra&#223;enbahnumwelt beherrschbarer.1671 
1668 Vgl. Bundesministerium f&#252;r Verkehr und digitale Infrastruktur (2018): Machbarkeitsstudie zum Projekt Zukunft Bahn (ETCS/NeuPro).
1669 Vgl. St&#252;ber (2018): Siemens zeigt in Potsdam erste fahrerlose Tram der Welt.
1670 Vgl. Verband Deutscher Verkehrsunternehmen (2019): Autonomer Fahrbetrieb bei Stra&#223;enbahnen, S. 4.
1671 Vgl. Verband Deutscher Verkehrsunternehmen (2019): Autonomer Fahrbetrieb bei Stra&#223;enbahnen, S. 8.
Dies deckt sich auch mit der Verbreitung von autonom fahrenden U-Bahnen. So ist in N&#252;rnberg bereits seit 2008
die erste autonom gesteuerte U-Bahn Deutschlands in Betrieb. Das hierf&#252;r notwendige &#8222;Automatic Train
Control&#8220;-System umfasst neben neuen Technologien in den Z&#252;gen diverse Komponenten in der Infrastruktur sowie
die Ausstattung der Haltestellen mit Kameras und Radaranlagen. Erst hierdurch konnte ein gemischt
automatisierter und manueller Betrieb erm&#246;glicht und die gesamte U-Bahn-Infrastruktur in einer digitalen Leitstelle
gesteuert werden.
4.4.3 Handlungsempfehlungen
Um in Deutschland die Potenziale von KI im Schienenverkehr umzusetzen, bedarf es Entschlossenheit,
vorrausschauender Planung und der Bereitschaft, branchen&#252;bergreifend zu denken. Es ben&#246;tigt eine enge Kooperation
der internen Akteure bei der Deutschen Bahn AG, der externen Akteure wie Nahverkehrsanbieter oder anderer
Wettbewerber, der Forschungsinstitute und der Politik.
Weiterentwicklung fordern, Einflussm&#246;glichkeiten nutzen
Die Bundesregierung und der Gesetzgeber haben die Aufgabe, ihre Einflussm&#246;glichkeiten auf die von ihnen
ma&#223;geblich gef&#246;rderten sowie als Hauptanteilseigner mit entsprechenden Ma&#223;nahmen zu ert&#252;chtigen. So soll die
Deutsche Bahn AG aufgefordert und verpflichtet werden, Meilensteine f&#252;r den zuk&#252;nftigen Einsatz von KI zu
erarbeiten und zu kommunizieren sowie die bereits vorhandenen Instrumente / M&#246;glichkeiten der KI
schnellstm&#246;glich zu nutzen.
B&#252;rokratische Hindernisse abbauen
B&#252;rokratische Hindernisse sind zu identifizieren und ebenso abzubauen wie politische Hemmnisse f&#252;r die
Zusammenarbeit europ&#228;ischer Schl&#252;sselunternehmen. Dies muss in aller Sorgfalt, aber schnellstm&#246;glich beraten
und umgesetzt werden.
Forschung weiter vorantreiben
Es gibt bereits heute Leuchtturmprojekte und zukunftsweisende Forschungs- und Entwicklungsprojekte, welche
im Bereich der KI Meilensteine setzen k&#246;nnen und werden. Dementsprechend gilt es, weitere B&#252;ndelungen der
Anstrengungen in gemeinsamen Forschungsclustern aktiv voranzutreiben; ein Beispiel daf&#252;r ist das 2019
er&#246;ffnete Zentrum f&#252;r Schienenverkehrsforschung (DZSF) in Dresden.
Open-Data-Strategien entwickeln
Es gilt zu &#252;berdenken, ob neben Anreizen f&#252;r das Teilen von Daten (&#8222;Data Sharing&#8220;) in manchen Bereichen auch
eine politische Anordnung m&#246;glich ist. Deutschland darf nicht weiter zur&#252;ckfallen, wir m&#252;ssen entschlossener,
offener und vertrauensvoller mit dem Thema Daten umgehen. Vor allem im Bereich Schiene sind h&#228;ufig keine
personenbezogenen Daten betroffen. 
Alle Handlungsempfehlungen sind obligatorisch im Hinblick auf eine verst&#228;rkte europ&#228;ische
Gemeinschaftsanstrengung zu betrachten und voranzutreiben.
Luftverkehr
4.5.1 Status quo
Gesellschaft
Der Luftverkehr ist mit &#246;kologischen Belastungen verbunden. Das umfasst sowohl die Emission
klimasch&#228;dlicher Treibhausgase als auch den Aussto&#223; lokaler Luftschadstoffe und die Schallbelastung von Personen, die an
Verkehrsflugh&#228;fen wohnen. Der Luftverkehr ist am CO2-Aussto&#223;, der Deutschland zuzuschreiben ist, mit 
2,175 Millionen Tonnen beteiligt, das sind 0,25 Prozent der deutschen Gesamtemissionen.1672 Weltweit betr&#228;gt
der Emissionsanteil des Luftverkehrs rund 3 Prozent der emittierten CO2&#228;qu-Gesamtmenge.
1672 Vgl. Umweltbundesamt (2019): Berichterstattung unter der Klimarahmenkonvention der Vereinten Nationen und dem Kyoto-
Protokoll 2019, S. 208, Tabelle 56.
&#196;hnlich wie im Stra&#223;en- oder Schiffsverkehr stellt das autonome Fliegen und insbesondere die Nutzung von
UAV (unpiloted / unmanned aerial vehicles), landl&#228;ufig Drohnen genannt, ein wichtiges Feld dar. Dadurch
entstehen neue Herausforderungen, bei denen auf komplexe Umgebungen und im Voraus kaum bestimmbare
Einfl&#252;sse reagiert werden muss. Auf internationaler Ebene zeigen Prognosen zum Wachstum der urbanen Zentren
zus&#228;tzlich, dass eine Erschlie&#223;ung der sogenannten dritten Dimension, also die Nutzung von allt&#228;glichen
Verkehrsm&#246;glichkeiten &#252;ber die Luft, immer konkreter wird. Bis zum Jahr 2025 soll es weltweit 40 St&#228;dte geben,
die mehr als zehn Millionen Einwohnerinnen und Einwohner haben.1673 Bei all diesen Herausforderungen k&#246;nnte
KI zur L&#246;sung beitragen.
Markt
Das Luftverkehrsaufkommen in Deutschland w&#228;chst seit Jahren und soll laut Prognosen am Beginn des Jahres
2020 auch in den kommenden Jahren weiter zunehmen. Die Deutsche Flugsicherung (DFS) hat 2018 im
deutschen Luftraum mehr als 3,3 Millionen Fl&#252;ge kontrolliert und abgewickelt.1674 Das sind 4,2 Prozent mehr als im
Jahr zuvor. Durch die geographische Lage Deutschlands im Herzen Europas gibt es hierzulande deutlich mehr
Flugbewegungen als in den meisten L&#228;ndern Europas. Der Luftraum &#252;ber Deutschland geh&#246;rt damit zu den am
st&#228;rksten frequentierten Luftr&#228;umen weltweit. Im Jahr 2019 wurden auf deutschen Flugh&#228;fen 248 Millionen
Passagiere abgefertigt.1675 Die Luftfracht macht in Tonnage aller im- und exportierten Waren nur rund 3 Prozent
aus, der Wertanteil liegt allerdings bei 31 Prozent. Per Cargo werden wertvolle G&#252;ter und Waren wie
elektronische Ger&#228;te und Bauteile, pharmazeutische Produkte und Just-in-time-Maschinenteile transportiert.1676 
Deutschland ist als global vernetzte Volkswirtschaft auf ein leistungsf&#228;higes Luftverkehrssystem angewiesen. Es
erm&#246;glicht den Transport von G&#252;tern und Personen &#252;ber gr&#246;&#223;ere und mittlere Entfernungen, tr&#228;gt zur
Wertsch&#246;pfung bei und sichert Besch&#228;ftigung.
Der Luftverkehrsbetrieb ist zudem ein wichtiger Arbeitsmarkt in Deutschland. Ein in Deutschland stationiertes
Kurzstreckenflugzeug ist vom Umsatz her mit der Ansiedlung eines mittelst&#228;ndischen Unternehmens
vergleichbar. Ein Langstreckenflugzeug ist dagegen in Hinsicht auf den generierten Umsatz gleichbedeutend mit der
Ansiedlung eines Gro&#223;unternehmens.1677 Insgesamt h&#228;ngen direkt und indirekt rund 850 000 Arbeitspl&#228;tze in 
Deutschland vom Luftverkehr ab.1678 
Politik
Der erste Zwischenbericht der KI-Strategie der Bundesregierung hat sich mit den Anwendungsgebieten der KI
im Zivilluftverkehr besch&#228;ftigt. Im gef&#246;rderten Reallabor-Portfolio sind Projekte wie Jettainer, ein
Expertensystem zur Optimierung von Cargo-Prozessen, sowie mit CO2-Teams ein Vorhaben, das letztlich eine Roadmap f&#252;r
das autonome Fliegen entwickeln soll.1679 Parallel dazu f&#246;rdert die Bundesregierung auch Modellprojekte im
Bereich Urban Air Mobility. Aufgrund der hohen Verkehrsdichte in den Ballungsr&#228;umen werden das Potenzial
von elektrisch angetriebenen Drohnen und Flugtaxen zur Verbesserung des Verkehrsflusses in den St&#228;dten, aber
auch m&#246;gliche neue Interessenkonflikte diskutiert.1680 
4.5.2 Potenziale von KI in der Luftfahrt
Der Forschungs- und Industriestandort Deutschland bietet die Voraussetzungen, KI f&#252;r immer mehr
Anwendungsf&#228;lle in der Luftfahrt weiterzuentwickeln.
F&#252;r Hersteller aus dem Bereich Luftfahrtindustrie bietet KI insgesamt ein gro&#223;es Potenzial. Die sehr hohen
Sicherheitsanforderungen der Luftfahrt machen ein kontinuierliches, striktes und systematisches Monitoring
verschiedener Flugzeug-Komponenten, etwa der Turbinen, notwendig. Vor allem gro&#223;e Tech-Firmen investieren
j&#228;hrlich Milliarden in den KI-Sektor, wodurch bereits heute die n&#246;tigen Technologien und Systeme zur
Verf&#252;gung stehen. Sogenannte OEM (Original Equipment Manufacturers), also Luftfahrzeughersteller wie Airbus,
1673 Vortrag von Dr. Christian Seidel (Manager Avionics Strategy, Airbus Helicopters Deutschland GmbH), Projektgruppendrucksache
19(27)PG 5-12 vom 9. Dezember 2019.
1674 Vgl. Deutsche Flugsicherung (2019): Luftverkehr in Deutschland, S. 5.
1675 Vgl. Arbeitsgemeinschaft Deutscher Verkehrsflugh&#228;fen (ADV) (2020): ADV-Monatsstatistik, S. 2.
1676 Vgl. Bundesverband der Deutschen Luftverkehrswirtschaft (2018): Was bedeutet Luftfracht f&#252;r Deutschland?
1677 Vgl. Bundesverband der Deutschen Luftverkehrswirtschaft: Luftfahrt sichert mehr als 800 000 Arbeitspl&#228;tze in Deutschland.
1678 Vgl. Bundesverband der Deutschen Luftverkehrswirtschaft: Luftfahrt sichert mehr als 800 000 Arbeitspl&#228;tze in Deutschland.
1679 Weitere Informationen dazu unter: https://www.plattform-lernende-systeme.de/ki-landkarte.html (zuletzt abgerufen am 3. August 2020).
1680 Vgl. Presse- und Informationsamt der Bundesregierung (2018): Der n&#228;chste Schritt zur Erprobung von Flugtaxis in Deutschland.
k&#246;nnen mittlerweile enorme Datenmengen, seien es Nutzungsdaten oder freie Daten aus dem Internet, f&#252;r ihre
Zwecke heranziehen.1681 
Die Herausforderungen im Bereich Klimaschutz und die hohe Preissensibilit&#228;t der Luftfahrt bei Ver&#228;nderungen
von Kraftstoffpreisen zwingen die Unternehmen der Branche zur kontinuierlichen Optimierung und
Effizienzsteigerung. So hat das international t&#228;tige britische Unternehmen Rolls Royce Group als einer der drei weltweit
f&#252;hrenden Hersteller von Flugzeugturbinen im Januar 2018 in Dahlewitz bei Berlin ein KI-Zentrum er&#246;ffnet.1682 
Dort werden rund 30 Terabyte Daten ausgewertet, die die Triebwerke das Jahr &#252;ber mittels Sensoren sammeln.
Die Maschinendaten sind im Zentrum in Echtzeit verf&#252;gbar und geben unmittelbaren Aufschluss &#252;ber den Status
der real montierten Turbine. Aus den Daten werden Muster gebildet, die, mit Soll-Daten abgeglichen, geringste
Abweichungen diagnostizierbar machen und damit die Basis bilden, vorausschauende Wartungen (Predictive
Maintenance) auszul&#246;sen. Das wirtschaftliche Interesse ist gekoppelt mit dem technischen Erkenntnisinteresse,
aus sich wiederholenden Fehlern zu lernen. Anhand integraler Parameter, wie z. B. Vibrationen, kann ein
lernendes System Voraussagen dar&#252;ber ableiten, wann bestimmte Bauteile ausfallen. Durch diese vorausschauende
Betrachtung kann bei Fehlerlokalisierungen, Zustandskontrollen und Ersatzteilprognosen Zeit und Geld
eingespart und die Verf&#252;gbarkeit der Maschinen erh&#246;ht werden. Dabei muss sich die Sensorik in den Luftfahrzeugen
noch weiter verbessern. Die vorausschauende Instandhaltung f&#252;hrt indes bei Zustandskontrollen und
Ersatzteilprognosen zu einer Zeitersparnis, was wiederum die Verf&#252;gbarkeit der Luftfahrzeuge erh&#246;ht. Zu diesem Zweck 
setzt z. B. der Flugzeughersteller Airbus bereits das Big-Data-Analysesystem &#8222;Skywise&#8220; ein.1683 
Die Datenauswertung, die Mustererkennung und die Predictive-Maintenance-Planung sind nur mithilfe
Maschinellen Lernens und anderer Verfahren der Informatik leistbar.
Lernen und Designen am Avatar
Zus&#228;tzlich kann im Rolls-Royce-KI-Hub ein komplettes Triebwerk als holografischer Avatar 1:1 in einen Raum
projiziert werden. Alle komplexen Vorg&#228;nge sind auf diese Weise simulierbar und im w&#246;rtlichen Sinne &#8222;zu
greifen&#8220;, auch wenn der Triebswerksavatar unter Vollschub &#8222;l&#228;uft&#8220;. Auch sind die jeweiligen digitalen Zwillinge der
realen Turbinen darstellbar, und zwar in dem technischen Zustand, in dem sie sich an Verkehrsflugzeugen aktuell
befinden. Die Software wertet die gewonnenen realen Ist-Daten aus und zeigt in der holografischen Darstellung
die potenziellen Fehlerquellen.1684 
In der Summe k&#246;nnen die Entwicklerinnen und Entwickler so am Avatar &#252;ber Designtools Ver&#228;nderungen
vornehmen und digitale Probel&#228;ufe machen. Auf diese Weise erh&#246;ht KI den Fehleridentifikations- und
-behebungsprozess und tr&#228;gt zur Flugsicherheit bei. KI erm&#246;glicht zudem verbesserte physikalische
Simulationen, also etwa die z&#252;gige Berechnung der Str&#246;mungsdynamik eines Bauteils oder gar die aerodynamischen
Eigenschaften eines Flugzeugmodells. Sie unterst&#252;tzt den Entwicklungsbereich auch dahingehend, dass zu
Nachbardisziplinen und den dort entwickelten L&#246;sungsans&#228;tzen eine gr&#246;&#223;ere N&#228;he entsteht.1685 
ZAL &#8211; Zentrum f&#252;r angewandte Luftfahrtforschung
Ein weiteres Beispiel im Entwicklungsbereich findet sich im Zentrum f&#252;r angewandte Luftfahrtforschung
(ZAL)1686 in Hamburg-Finkenwerder, welches in Kooperation zwischen der Stadt Hamburg, der Airbus
Operations GmbH und der Lufthansa Technik AG betrieben wird.
Das Zentrum stellt z. B. in einer Halle einen leeren Flugzeugrumpf zur Verf&#252;gung, in dessen H&#252;lle &#252;ber 3-D-
Datenbrillen unterschiedliche Kabineninterieurs visualisiert und projiziert werden. So k&#246;nnen ad hoc
verschiedene Einstellungen angepasst werden, die f&#252;r einen potenziellen Kunden sofort sichtbar und nach Wunsch
aktualisierbar sind. Dar&#252;ber hinaus kann durch das Zentrum erprobt werden, wie bestimmte Teile einer Kabine
optimal und kraftschonend eingebaut werden k&#246;nnen.
1681 Vortrag von Dr. Christian Seidel (Manager Avionics Strategy, Airbus Helicopters Deutschland GmbH), Projektgruppendrucksache
19(27)PG 5-12 vom 9. Dezember 2019.
1682 Weitere Informationen zu den KI-Zentren von Rolls Royce unter: https://www.rolls-royce.com/products-and-services/ecosys-
tem.aspx (zuletzt abgerufen am 10. August 2020).
1683 Vortrag von Dr. Christian Seidel (Manager Avionics Strategy, Airbus Helicopters Deutschland GmbH), Projektgruppendrucksache
19(27)PG 5-12 vom 9. Dezember 2019.
1684 Vgl. St&#252;ber (2018): Rolls-Royce schafft ein Forschungszentrum f&#252;r K&#252;nstliche Intelligenz.
1685 Vortrag von Dr. Christian Seidel (Manager Avionics Strategy, Airbus Helicopters Deutschland GmbH), Projektgruppendrucksache
19(27)PG 5-12 vom 9. Dezember 2019.
1686 Weitere Informationen dazu unter: https://zal.aero/ (zuletzt abgerufen am 3. August 2020).
Der 3-D-Druck (Additive Manufacturing (AM)) spielt im Luftfahrtlabor ebenfalls eine gro&#223;e Rolle. Der Rechner
entwirft und druckt 3-D-Formen, die wesentlich leichter sind als die klassisch am 3-D-Drucker gefertigten, weil
der Materialmasseaufwand bei identischer Stabilit&#228;t mehr als halbiert werden kann. Durch das reduzierte
Gesamtgewicht wird weniger Kerosin ben&#246;tigt und eine h&#246;here Zuladung erm&#246;glicht. Bei einem Kostenanteil von
25 Prozent f&#252;r Treibstoff pro Flug ist dieser Faktor von hoher Bedeutung. Durch intelligente AM-Algorithmen 
k&#246;nnen Muster aus der Natur analysiert, die Formen kopiert, deren Stabilit&#228;t gemessen und in bionische Formen
aus Aluminium, Titan oder Kohlefaserstoffen &#252;bertragen werden. Dadurch l&#228;sst sich in der Gesamtheit die
Effektivit&#228;t deutlich erh&#246;hen.
SPO und autonomes Fliegen
Eine wichtige Rolle kommt KI auch im Bereich des autonomen Fliegens zu. Das Konzept &#8222;Single Pilot
Operation&#8220; bzw. &#8222;Reduced Pilot Operation&#8220;, also der Wegfall zus&#228;tzlicher Pilotinnen oder Piloten, ist nur mit
Unterst&#252;tzung von KI-Systemen denkbar. Es muss sichergestellt sein, dass das fliegende Objekt &#8211; Flugzeug oder UAV
(Drohne) &#8211; bei einem Ausfall der menschlichen Kraft in einen sicheren Modus gebracht werden kann. Das hei&#223;t,
die KI muss das Objekt sicher landen k&#246;nnen. F&#252;r die zivile Luftfahrt ist dies noch Zukunftsmusik mit einem
Zeithorizont von einem Jahrzehnt, sehr wohl aber ist es f&#252;r unbemannte Luftfahrzeuge, die sogenannte &#8222;Urban 
Air Mobility&#8220;, eine durchaus realistische Perspektive. Airbus und andere Hersteller &#8211; zum Beispiel Volocopter
oder Lilium &#8211; arbeiten mit unterschiedlichen flugtechnischen Ans&#228;tzen an letztlich autonom fliegenden
&#8222;Flugtaxis&#8220; f&#252;r die Kurz- und Mittelstrecke. Autonome Drohnen sind auch in anderen Szenarien interessant und werden
dort auch schon eingesetzt. Man kann mit ihnen Waren zustellen, in der Intralogistik Teile aus Hochregallagern
&#8222;herbeifliegen&#8220; &#8211; am Fraunhofer IML in Dortmund wird daran geforscht1687 &#8211; oder Inspektionen von
Bahntrassen1688, Windkraftanlagen1689 und anderen Einrichtungen standardisiert vornehmen. Die Deutsche Flugsicherung
erarbeitet zurzeit Modelle und Verfahren, um Drohnen in den kontrollierten Luftraum zu integrieren.1690 
KI zur Optimierung des Luftraums
Die Schaffung eines einheitlichen europ&#228;ischen Luftraums (Single European Sky &#8211; SES) ist erkl&#228;rtes Ziel der
EU &#8211; und das bereits seit dem Jahr 1999. Damit soll sich die Effizienz des Flugverkehrsmanagements (Air Traffic
Management &#8211; ATM) und der Flugsicherungsdienste (Air Navigation Services &#8211; ANS) erh&#246;hen.1691 Hierzu
k&#246;nnte KI einen wichtigen Beitrag leisten. Um die daf&#252;r erforderlichen Detailfunktionen im ben&#246;tigten
Industrialisierungsgrad bereitzustellen, bedarf es sowohl bei den Luftfahrzeugherstellern als auch bei den Zulieferern
noch weiterer Forschung. Auch f&#252;r eine Gew&#228;hrleistung der n&#246;tigen Anwendungsreife muss
branchen&#252;bergreifend die L&#252;cke zwischen Industrie und Forschung geschlossen werden. Da Deep-Learning-Algorithmen
insbesondere f&#252;r Aufgaben wie Hinderniserkennung, automatisches Starten und Landen oder Positionsbestimmung 
auf Trainingsdaten in ausreichender Menge angewiesen sind, wird es k&#252;nftig zudem von entscheidender
Bedeutung sein, dass gro&#223;e Datenbest&#228;nde angelegt und dass Daten zwischen unterschiedlichen Luftfahrt-Akteuren 
ausgetauscht werden.1692 
In dem Fall w&#252;rde eine KI-gest&#252;tzte weitere Vereinheitlichung des Luftraums in Europa nicht nur die bereits
hohe Sicherheit im Zivilluftverkehr weiter steigern, indem der Kontrollaufwand sinkt, sondern auch dazu
beitragen, Flugrouten zu verk&#252;rzen und damit Kraftstoff zu sparen. Insgesamt k&#246;nnten mit dem einheitlichen
europ&#228;ischen Luftraum so j&#228;hrlich bis zu 16 Millionen Tonnen CO2 eingespart werden.1693 
Und auch wirtschaftlich h&#228;tte es einen enormen Nutzen. Rund 17 000 Fluglotsinnen und Fluglotsen koordinieren 
die knapp 10 Millionen Flugbewegungen europaweit. Dazu sind die rund 10,8 Millionen Quadratkilometer eu-
1687 Vgl. Fraunhofer-Institut f&#252;r Materialfluss und Logistik: Drohnentechnik.
1688 Vgl. Deutsche Bahn AG: Ferndiagnose per Flugger&#228;t.
1689 Vgl. T&#220;V S&#220;D: T&#220;V S&#220;D testet neue Methode zur Inspektion von Rotorbl&#228;ttern.
1690 Antwort der Bundesregierung auf die Kleine Anfrage der Abgeordneten Bernd Reuther, Frank Sitta, Torsten Herbst, weiterer
Abgeordneter und der Fraktion der FDP auf Bundestagsdrucksache 19/10478.
1691 Vgl. Deutsche Flugsicherung: Single European Sky.
1692 Vortrag von Dr. Christian Seidel (Manager Avionics Strategy, Airbus Helicopters Deutschland GmbH), Projektgruppendrucksache
19(27)PG 5-12 vom 9. Dezember 2019.
1693 Vgl. Bundesverband der Deutschen Fluggesellschaften (2017): Single European Sky &#8211; Europas gr&#246;&#223;tes CO2-Senkungsprojekt.
rop&#228;ischer Luftraum in 60 Kontrollcenter fragmentiert. K&#246;nnte man den Luftraum vereinheitlichen, also
tats&#228;chlich den Single European Sky (SES) realisieren, erg&#228;be sich, so eine Sch&#228;tzung der EU, ein Einsparvolumen von 
rund 4 Milliarden Euro. Die Kontrolle w&#252;rde preiswerter und die Treibstoffkosten k&#246;nnten deutlich sinken.1694 
Der Luftraum ist zugleich auch der Wetterraum und das Fliegen ist unmittelbar von der meteorologischen Lage
betroffen. Die Prognosemodelle werden immer pr&#228;ziser. Die KI-gest&#252;tzte Wettervorhersage wird zuk&#252;nftig in
der Lage sein, auch lokale Wetterph&#228;nomene zu prognostizieren; damit wird sie das Fliegen noch sicherer
machen k&#246;nnen. Zum Beispiel zielt das Projekt SINFONY des DWD (Deutscher Wetterdienst) u. a. auf die
Integration von KI, um&#8211; auch lokale &#8211; kurzfristige Vorhersagen treffender zu machen.1695 
4.5.3 Handlungsempfehlungen
Europ&#228;ische Perspektive der KI-Potenziale st&#228;rken
Die Europ&#228;ische Agentur f&#252;r Flugsicherheit (EASA) sollte sich noch st&#228;rker als bisher mit den Potenzialen der
KI f&#252;r die Vereinheitlichung des europ&#228;ischen Luftraums besch&#228;ftigen. Au&#223;erdem sollte sich die EASA st&#228;rker
in die Diskussion der Voraussetzungen f&#252;r die &#8222;Single Pilot Operation&#8220; bzw. die &#8222;Reduced Pilot Operation&#8220;
einbringen.
Branchen&#252;bergreifend Synergieeffekte realisieren
Es m&#252;ssen die n&#246;tigen Bedingungen geschaffen werden, dass sowohl bei den Luftfahrzeugherstellern als auch
bei den Zulieferern branchen&#252;bergreifend die L&#252;cke zwischen Industrie und Forschung geschlossen wird.
Dadurch k&#246;nnen Synergieeffekte zur weiteren Entwicklung der KI geschaffen werden.
Hohe ethische und sicherheitstechnische Standards f&#252;r das autonome Fliegen setzen
Gerade in der Luftfahrt ist die Akzeptanz f&#252;r autonome Systeme im Vergleich zu anderen Verkehrstr&#228;gern
weniger ausgepr&#228;gt. Um in der Gesellschaft Vertrauen in und Akzeptanz f&#252;r KI herzustellen, m&#252;ssten f&#252;r die weitere
Entwicklung der Technologie hohe ethische Standards gesetzt werden. Politik und Gesellschaft m&#252;ssen dieses
Thema debattieren, um schlie&#223;lich Leitlinien und Rahmen &#8211; wie etwa die &#8222;Ethik-Leitlinien f&#252;r eine
vertrauensw&#252;rdige KI&#8220; der High-Level Expert Group der EU &#8211; vorzugeben.
Testfelder und Reallabore schaffen
Es m&#252;ssen Testfelder und Reallabore gef&#246;rdert werden, in denen das Potenzial f&#252;r die Erh&#246;hung von Effizienz
und Sicherheit durch KI im Luftverkehr untersucht werden kann.
Interoperabilit&#228;t der technischen Systeme sichern
Die Interoperabilit&#228;t der Systeme muss gesichert sein. Es muss auf ICAO-Ebene vereinbarte weltweit
verbindliche Normen und Standards geben.
Anwendungsorientierte Forschung st&#228;rken
Der konstruktive Dialog zwischen Forschung und Anwendern muss verst&#228;rkt vorangetrieben werden. Insofern
m&#252;ssen Modelle wie das ZAL-Modell ausgeweitet werden. Ebenso sollte die Forschung an KI-basierten
Systemen st&#228;rker gef&#246;rdert werden. Das existierende Luftfahrtforschungsprogramm (LuFo) ist hier ein gutes Beispiel
und sollte ausgeweitet werden. Diese Projektsystematik muss verst&#228;rkt, die Kooperation mit Wissenschaft und
Wirtschaft ausgebaut werden.
Single European Sky vollenden
Die Vereinheitlichung des Luftraums in Europa zum Single European Sky (SES) muss weiterhin gezielt gef&#246;rdert
werden, um Synergien zu erm&#246;glichen. Die Zusammenf&#252;hrung und die Vereinheitlichung k&#246;nnten einen gro&#223;en
Beitrag zur Kostensenkung wie auch zur Steigerung der Effizienz im Luftfahrbetrieb leisten. Ein
gesamteurop&#228;isches Luftraumkonzept wie SES kann nur funktionieren, wenn es KI-basiert ist.
1694 Vgl. Europ&#228;ische Kommission (2020): Single European Sky.
1695 Vgl. Deutscher Wetterdienst: Entwicklung des Integrierten Vorhersagesystems SINFONY.
Schiffsverkehr
4.6.1 Status quo
Gesellschaft
Die See- und Binnenh&#228;fen in Deutschland und Europa erarbeiten und implementieren digitale operative
Strategien, um Logistikketten und Arbeitsabl&#228;ufe zu optimieren.
Zu nennen ist hier beispielhaft das Projekt Elbe 4.0. Das Deutsche Zentrum f&#252;r innovative Binnenschifffahrt
(D-ZIB) in Leer hat, gef&#246;rdert durch die Europ&#228;ische Kommission, im Februar 2019 zu dem Thema eine
umfassende Studie vorgelegt.1696 Am Entwicklungszentrum f&#252;r Schiffstechnik und Transportsysteme (DST), einem
An-Institut der Universit&#228;t Duisburg/Essen, wird in Kooperation mit der RWTH Aachen ein Versuchs- und 
Leitungszentrum Autonome Binnenschiffe aufgebaut. Die Ruhr-IHK (Zusammenschluss der IHKs in der
gesamten Region Ruhrgebiet) hat in Zusammenarbeit mit dem Duisburger DST eine Machbarkeitsstudie f&#252;r ein
Testfeld Autonomes Binnenschiff auf dem westdeutschen Kanalnetz einschlie&#223;lich des Rheins vorgelegt.1697 Das 
westdeutsche Kanalnetz ist das meist befahrene Wasserstra&#223;ennetz in Europa.
Markt
In der Branche steht das Thema KI noch verh&#228;ltnism&#228;&#223;ig am Anfang, weist jedoch eine hohe Dynamik in der
Entwicklung von L&#246;sungen in einzelnen Prozessbereichen auf. Viele Anwendungen sind noch in einem fr&#252;hen 
Entwicklungsstadium und d&#252;rften zurzeit nur bei einzelnen Marktteilnehmern verwendet werden. 
Die Seefahrt selbst kann nach Einsatzzwecken in die kommerzielle und nicht-kommerzielle, wie zum Beispiel
die private Schifffahrt, unterteilt werden. Innerhalb der kommerziellen Schifffahrt weist die Handelsschifffahrt
im Vergleich zur Passagierschifffahrt, F&#228;hrschifffahrt oder der Hochseefischerei sehr gro&#223;e Kapazit&#228;ten auf. Im
Jahr 2019 wurden in deutschen Seeh&#228;fen 294,5 Millionen Tonnen G&#252;ter umgeschlagen. In der Binnenschifffahrt
liegt dieser Wert bei 223 Millionen Tonnen.1698 J&#228;hrlich werden 19,6 Millionen Container umgeschlagen, welche
zusammengenommen eine Container-Kette von rund 120 000 Kilometer darstellen. Bei einer Standard-Zugl&#228;nge
von 740 Metern entspr&#228;che dies rund 85 000 G&#252;terz&#252;gen pro Jahr. Als Beispiel betreibt die Duisburger Hafen
AG mit dem Duisport den gr&#246;&#223;ten Binnenhafen Europas und mit einem Umschlag von 4,1 Millionen 20-Fu&#223;-
ISO-Containern (Twenty-foot equivalent unit &#8211; TEU) auch den weltweit gr&#246;&#223;ten Containerbinnenhafen. Acht
Terminals mit 21 Containerbr&#252;cken bew&#228;ltigen rund um die Uhr die trimodale Verladung vom Schiff auf Zug
und Lkw &#8211; und umgekehrt. Die meisten Container kommen per Schiff &#252;ber den Fluss aus Rotterdam, dem
K&#252;stengegenst&#252;ck zum Duisport an der M&#252;ndung des Rheins. Doch schon heute erreichen pro Woche 35 bis
40 G&#252;terz&#252;ge aus China den Duisport. Insgesamt werden 25 000 Z&#252;ge pro Jahr abgefertigt, also rund 70 am Tag,
und &#8211; das Kerngesch&#228;ft eines Hafens &#8211; es werden 20 000 Schiffe pro Jahr umgeschlagen. Dies ist eine Aufgabe,
bei der KI eine wesentliche Hilfe sein kann, um Prozesse &#246;konomisch wie auch &#246;kologisch zu optimieren.
Politik
In Deutschland und Europa hat die Handelsschifffahrt mit Blick auf verkehrs- und umweltpolitische Ma&#223;nahmen
eine wichtige Rolle. Die Verlagerung des Verkehrs von der Stra&#223;e (Lkw) auf Wasserwege und Schiene ist ein
zentrales Ziel der Verkehrs- und Umweltpolitik der Bundesregierung. Diese Ma&#223;nahmen betreffen den
Hafenbetrieb wie auch den Binnenschiffsverkehr.
Der aktuelle Bundesverkehrswegeplan geht davon aus, dass der G&#252;terverkehr im Planungszeitraum bis 2030
insgesamt um 38 Prozent zunehmen wird.1699 Aus diesem Grund m&#252;ssen die bestehenden Wasserstra&#223;en wie
auch unsere See- und Binnenh&#228;fen effizienter werden. Der zu erwartende Anstieg des Verkehrsaufkommens auf
unseren See- und Binnenwasserstra&#223;en erfordert neue Ans&#228;tze und den Einsatz digitaler Anwendungen, um
Engp&#228;sse1700 zu vermeiden und um Sicherheit und Effizienz zu verbessern. Im Zuge dessen wurde im Mai 2019 der
&#8222;Masterplan Binnenschifffahrt&#8220; ver&#246;ffentlicht, der sich unter anderem mit m&#246;glichen Ma&#223;nahmen zur
Bew&#228;ltigung der digitalen Herausforderungen, z. B. der Optimierung von Prozessen an Schleusen, aber auch mit dem
1696 Vgl. Ninnemann et al. (2019): Digitalisierung in der Binnenschifffahrt.
1697 Vgl. Henn und Holtmann (2018): Autonomes Fahren in der Binnenschifffahrt.
1698 Vgl. Statistisches Bundesamt (2020): Seeverkehr 2019.
1699 Vgl. Bundesministerium f&#252;r Verkehr und digitale Infrastruktur: Bundesverkehrswegeplan 2030.
1700 Die Vermeidung von Engp&#228;ssen ist die zentrale Bewertungskategorie im Bundesverkehrswegeplan.
automatisierten und vernetzten Fahren und der Einrichtung digitaler Plattformen bzw. ihrer Weiterentwicklung
besch&#228;ftigt.1701 
Einen weiteren interessanten Ansatz verfolgt das Projekt &#8222;A SWARM&#8220;, ein Citylogistikvorhaben der BEHALA
(Berliner Hafen- und Lagerhausgesellschaft) in Kooperation mit der Schiffbau-Versuchsanstalt Potsdam, der
Infineon Technologies GmbH, Veinland (ein Spezialausr&#252;ster f&#252;r Schiffselektronik), dem Institut f&#252;r
Automatisierungstechnik an der Universit&#228;t Rostock und dem Fachgebiet Entwurf und Betrieb Maritimer Systeme an der TU
Berlin. Ziel ist es, ein wasserstra&#223;enbasiertes Citylogistikkonzept umzusetzen, welches auf automatisierte
Fahrzeuge setzt.1702 
In der Forschungsstrategie, die das Entwicklungszentrum f&#252;r Schiffstechnik und Transportsysteme (DST)
zusammen mit allen relevanten nationalen Forschungspartnern im Forschungsprogramm &#8222;Maritime Technologien&#8220;
vorgestellt hat, wird eine Reihe von Forschungsvorhaben beschrieben, die zielstrebig zum autonomen
Binnenschiff f&#252;hren. Das erste Vorhaben aus dieser Strategie hat im M&#228;rz 2020 begonnen. Bereits seit Oktober 2019
l&#228;uft zus&#228;tzlich ein Forschungsprojekt am DST, in dem ein autonomes Binnenschiff f&#252;r die Kanalfahrt entwickelt
wird.1703 Einige Fachleute gehen davon aus, dass in ca. zehn Jahren ein Schiff vollautomatisiert (Stufe 5) fahren
kann. Bis zur Markteinf&#252;hrung kommerzieller Systeme werden dann sicherlich noch einige Jahre vergehen. Vor
allem m&#252;ssen die rechtlichen Rahmenbedingungen gekl&#228;rt werden.
4.6.2 Potenziale und Beispiele
KI und Stauplanung (Stowage Planning)
KI k&#246;nnte dazu beitragen, dass die Logistik in der Schifffahrt effizienter gestaltet wird. Gro&#223;es Potenzial bietet
sich im Rahmen der Stauplanung (Stowage Planning), also f&#252;r die KI-gest&#252;tzte Be- und Entladung sowie
Lagerung von Waren. Lagerungskosten stellen f&#252;r Unternehmen einen &#246;konomischen Anreiz dar, die Verweilzeit von
Waren so kurz wie m&#246;glich zu halten. Mithilfe von KI lassen sich auch die Bewegungen der Portalkr&#228;ne
zeitoptimiert gestalten.
Insofern fahren bereits heute alle Z&#252;ge zun&#228;chst an den Hafentoren durch sogenannte Railgates. Das sind
intelligente Scanner, die erkennen, in welcher Reihenfolge und mit welchen Containergr&#246;&#223;en einfahrende Z&#252;ge
beladen sind. Dadurch ist es m&#246;glich, sie so auf den Verladegleisen zu platzieren, dass die Kr&#228;ne stets die k&#252;rzesten
Wege fahren k&#246;nnen. Die Kr&#228;ne stapeln die Container so, dass sie f&#252;r die Weiterverladung auf das Binnenschiff
am richtigen Platz stehen.
Alle Container haben eine Kennnummer. W&#228;ren alle Container &#252;berdies mit weltweit einheitlichen Transpondern 
versehen und g&#228;be es heute schon durchg&#228;ngig aussagekr&#228;ftige elektronische Frachtbriefe, k&#246;nnten die Stowage-
Prozesse noch weiter optimiert werden. Zurzeit erweisen sich die Frachtdaten, die an den Hafen &#252;bermittelt
werden, hin und wieder als nicht identisch mit den Warenmengen/Containern, die tats&#228;chlich den Hafen erreichen.
Das hei&#223;t zum Beispiel, dass Stauraum reserviert wird, den man gar nicht gebraucht h&#228;tte, oder zu wenig
Lagerfl&#228;che eingeplant ist. Elektronische, &#252;ber eine Cloud abrufbare Frachtpapiere bergen zuk&#252;nftig, intelligent zeit-
und wegeoptimiert, nicht nur &#246;konomisches Potenzial, sondern k&#246;nnen auch dazu beitragen, den CO2-
Fu&#223;abdruck von Transportketten zu verringern, weil jeder Fracht automatisch der nachhaltigste Weg zugewiesen
werden kann. Mithilfe eines cloudbasierten weltweit vernetzten Systems k&#246;nnte z. B. auch ein Informationsaustausch 
zwischen H&#228;fen hergestellt werden. So k&#246;nnten Informationen &#252;ber Inhalt oder Zielbestimmung eines
Containers, der im hochmodernen Containerterminal Massvlakte II in Rotterdam ankommt und von Transpondern
erfasst wurde, unmittelbar an den automatisierten Kran in Duisburg &#252;bermittelt werden. Das birgt zeitliches und
damit betriebswirtschaftliches Optimierungspotenzial.
Radio-Frequency Identification (RFID)1704 
Zuk&#252;nftig sollten Unternehmen in den Lieferketten und -netzwerken st&#228;rker kooperieren. RFID-Etiketten k&#246;nnen
daf&#252;r sorgen, dass intelligente Zustellservices f&#252;r eine B&#252;ndelung der Pakete sorgen. Dieses Lieferketten-
Management w&#252;rde helfen, die Luftqualit&#228;t weiter zu verbessern und die Treibausgasemission zu senken.
1701 Bundesministerium f&#252;r Verkehr und digitale Infrastruktur (2019): Masterplan Binnenschifffahrt.
1702 Vgl. dvz.de (2019): Behala und Partner schicken den Schwarm aufs Wasser.
1703 Bekanntmachung zur F&#246;rderung von Forschung, Entwicklung und Innovation im Rahmen des &#8222;Maritimen Forschungsprogramms&#8220;
der Bundesregierung durch das Bundesministerium f&#252;r Wirtschaft und Energie, Bunddesanzeiger vom 7. Dezember 2017.
1704 Radio-Frequency Identification bezeichnet eine Technologie f&#252;r Sender-Empf&#228;nger-Systeme zum automatischen und
ber&#252;hrungslosen Identifizieren und Lokalisieren von Objekten und Lebewesen mit Radiowellen.
RFID-Chips sind kaum gr&#246;&#223;er als eine Briefmarke und enthalten alle notwendigen Informationen &#252;ber die Ware.
Sensoren lesen das Etikett und eine dahinter liegende intelligente Software entscheidet, mit welchen anderen
Warensendungen eine Lieferung geb&#252;ndelt und verladen wird. Die Lieferkette wird so zum zeit-, entfernungs-
und CO2-optimierten Transportweg. Transportweg&#252;bergreifende digitale Logistik-Plattformen werden zuk&#252;nftig
mithilfe von KI-Methoden die Warenzuteilung steuern. Es kann automatisiert disponiert werden, welches Paket
mit welchem passenden Transportmittel zugestellt werden soll. So werden in globalen Logistikketten
automatisiert Paletten und/oder Container zusammengestellt, ganze Z&#252;ge oder Schiffsladungen konfiguriert. Am Ende
der Kette stellen zuk&#252;nftig autonome Roboterl&#246;sungen f&#252;r die letzte Meile Endkundinnen oder Endkunden
p&#252;nktlich die Sendung zu, nachdem dieser rechtzeitig und ebenfalls automatisiert &#252;ber die Lieferung auf ihren
Smartphones benachrichtigt worden sind.1705 
Predictive Maintenance
Auch in der Wartung innerhalb der Schifffahrt birgt KI Potenziale zur Steigerung von Effizienz und Sicherheit. 
Zum Beispiel brauchen die Verladesysteme Wartung. Der potenzielle Ausfall einer Verladebr&#252;cke aufgrund von
&#220;berbelastung bedeutet, dass die Umschlagzeiten l&#228;nger werden. Bei jedem Hub wird beim Verladevorgang das
Gewicht der Last und damit auch die Beanspruchung der Verschlei&#223;materialien ermittelt. Verbaute Sensoren
erheben &#252;berdies ein Belastungs- und Zustandsprofil, das es erm&#246;glicht, Teile zu warten oder gar auszutauschen,
bevor der Schaden entsteht.
F&#252;hrte man alle Lademaschinen in einem System als digitalen Zwilling, der digital alle Bewegungen des realen
Krans simuliert, w&#228;re es m&#246;glich, reale Verschlei&#223;erfahrungswerte zu hinterlegen und so zum Beispiel ein Lager
an einer Kranrolle auszutauschen, bevor ein langwierigerer Reparaturstillstand eintritt. Predictive Maintenance
ist hier das Stichwort. Sie wird in Perfektion erst durch KI m&#246;glich. Der Reparaturzeitpunkt kann so exakt
bestimmt werden. Die klassischen &#8222;analogen&#8220; Wartungszyklen geh&#246;rten somit der Vergangenheit an.
4.6.3 Handlungsempfehlungen
Forschungsbedarf formulieren
Angesichts zunehmender intermodaler und flexibler Logistikketten besteht Forschungsbedarf; es ist notwendig,
die Flexibilit&#228;t und Wandlungsf&#228;higkeit und die darin enthaltenen Potenziale unter anderem im Schiffsverkehr
weiter zu untersuchen. Die Forschung sollte dabei auch europ&#228;isch vernetzt sein.
Forschungs- und Entwicklungsergebnisse in Anwendungen &#252;berf&#252;hren
Es liegen bereits umfangreiche Konzepte und auch Anwendungsbeispiele vor. So wirbt das Fraunhofer-Institut 
f&#252;r Materialfluss und Logistik (IML) in Dortmund mit dem Motto &#8222;Mehr Forschung, die bewegt&#8220; und meint
damit den Wissens- und Anwendungstransfer, insbesondere f&#252;r kleinere und mittlere Unternehmen. In diesen
anwendungsorientierten Sektor sollte mehr investiert werden.1706 
Lieferketten optimieren
Zuk&#252;nftig werden KI-Werkzeuge es erm&#246;glichen, die Lieferketten CO2- und wegeoptimiert zu verbessern. Auch
hier besteht Forschungs- und Umsetzungsbedarf, welcher sich perfekt in der maritimen Wirtschaft nutzen l&#228;sst.
Intermodale Logistikketten etablieren
Die zuk&#252;nftig vermehrte Intermodalit&#228;t der Logistikketten macht trimodale Systeme (Schiff, Bahn, Lkw) und
Umschlagstrukturen notwendig. Diese Intermodalit&#228;t zu verbessern bedeutet, Materialfluss und Logistik
allgemein zu einem vernetzten System zu machen. Hierbei bietet KI ein gro&#223;es Potenzial, welches nicht nur im
Transportbereich auf der Stra&#223;e und der Schiene, sondern auch auf dem Wasser genutzt werden muss.
1705 Vgl. Schreier (2020): Last Mile: Autonome Lieferroboter als Milliarden-Markt?
1706 Weitere Informationen dazu unter: https://www.iml.fraunhofer.de/ (zuletzt abgerufen am 3. August 2020).
&#220;bergreifende Themen (&#214;konomie und Wettbewerb, Stadtentwicklung)
4.7.1 Status quo
Gesellschaft
Die Technologien entwickeln sich rasant weiter, Unternehmen und Menschen setzen sie weltweit immer h&#228;ufiger
und vielf&#228;ltiger ein. Dabei erwarten viele B&#252;rgerinnen und B&#252;rger, dass St&#228;dte und Gemeinden sich diese neuen
M&#246;glichkeiten zunutze machen, um auch im Bereich der Mobilit&#228;t bzw. im Bereich der verschiedenen
Verkehrssysteme Verbesserungen herbeizuf&#252;hren. Neben den zuvor in diesem Bericht dargestellten Themenbereichen wie 
der Intermodalit&#228;t, dem Schiffs- oder dem Stra&#223;enverkehr gibt es weitere &#252;bergreifende Themen, die im
Mobilit&#228;tsbereich anzusiedeln sind. Die Projektgruppe &#8222;KI und Mobilit&#228;t&#8220; hat diese in die Bereiche &#8222;Wettbewerb und
&#214;konomie&#8220; [KI mit Blick auf &#214;konomie und Wettbewerb], &#8222;Stadtentwicklung&#8220; [KI und Stadtentwicklung] sowie
&#8222;Sicherheit&#8220; bzw. &#8222;Standards&#8220; [Sicherheit bei KI-gest&#252;tzter Mobilit&#228;t] eingeordnet und in diesem Berichtsteil
dargestellt. Dabei werden zuvor je nach &#252;bergreifendem Themenbereich neben der gesellschaftlichen auch die
politische sowie die den Markt betreffende Komponente beleuchtet.
Im gesellschaftlichen Kontext spielt als &#252;bergreifender Komplex der IT-Sicherheitsaspekt eine wichtige Rolle.
Es gilt, im Zuge der sehr schnellen technischen Entwicklung eine m&#246;glichst breite Akzeptanz in der Bev&#246;lkerung
zu schaffen. Dabei ist es auch wichtig, eine Nachvollziehbarkeit in der Anwendung von KI, z. B. im Bereich des
autonomen Fahrens, zu gew&#228;hrleisten, aber auch in der Anwendung Sicherheit zu etablieren, welche sich an dem
des eigenst&#228;ndigen Fahrens orientiert. Entsprechend sind bei der Entwicklung und Nutzung von KI-
Anwendungen die Zug&#228;nglichkeit zu Systemen und die Nutzung von Anwendungen, Transparenz sowie Fragen von
Selbstbestimmung und Sicherheit zentral.
Wie bereits im Kapitel 4.3 dieses Projektgruppenberichts [Stra&#223;enverkehr] erw&#228;hnt, zeigen Studien im Bereich
des Stra&#223;enverkehrs, dass die Sicherheitsthematik f&#252;r Anwenderinnen und Anwender von hoher Bedeutung ist.
Dabei sind viele Personen in der Bev&#246;lkerung noch unentschlossen, wenn es um die potenzielle Nutzung von
autonom fahrenden Autos geht. Knapp 29 Prozent sprechen sich sogar dagegen und nur 18 Prozent daf&#252;r aus.
Circa 53 Prozent k&#246;nnen hierzu keine Aussage treffen.1707 Akzeptanzprobleme k&#246;nnen unter anderem durch die
Angst vor Manipulation, das fehlende Vertrauen in die Technik oder das Gef&#252;hl, &#252;berwacht zu werden,
entstehen.1708 Eine Bitkom-Studie aus dem Jahr 2018 unterstreicht dies zus&#228;tzlich. Obwohl 60 Prozent der Befragten
sich mehr Sicherheit f&#252;r alle erhoffen, die am Verkehr teilnehmen, haben 68 Prozent auch Angst vor technischen
Problemen.1709
Wie im Bereich des Stra&#223;enverkehrs gibt es z. B. auch in der Luftfahrt eine Akzeptanzdebatte. Dabei f&#228;llt diese,
wie zuvor erw&#228;hnt, bei komplett autonomen Luftfahrzeugen im Vergleich zu anderen Verkehrstr&#228;gern noch
weniger positiv aus: Einer Studie zufolge &#228;u&#223;erten 54 Prozent von 8 000 Befragten, dass sie nicht ohne Pilotinnen
oder Piloten fliegen wollten. Lediglich 18 Prozent konnten sich dies vorstellen.1710
Als ein Ziel gilt es somit nach wie vor, Vertrauen zu schaffen, um die Anwendung von KI, hier beispielhaft f&#252;r
den Bereich des Stra&#223;enverkehrs und der Luftfahrt, zu verwirklichen. Die Erarbeitung von Standards kann helfen,
diese Entwicklung weiter zu begleiten und dieses Ziel zu erreichen. Die Einbindung von neutralen Expertinnen
und Experten (z. B. &#252;ber den T&#220;V) kann zus&#228;tzlich helfen, auf Fragen und Bedenken aller Bev&#246;lkerungskreise
einzugehen, um einen breiten Konsens bei der Entwicklung zu erreichen. Allgemeine technische Standards
k&#246;nnen langfristig Vorteile bieten, sowohl technologisch bzgl. Sicherheit und Umweltschutz als auch &#246;konomisch. 
Auf der anderen Seite k&#246;nnen unterschiedliche Standards den technischen Fortschritt gar bremsen. Bei alledem
muss dennoch darauf geachtet werden, welche Standards bereits vorhanden sind und sich f&#252;r die kommende
Entwicklung nutzen lassen, ohne f&#252;r eine &#220;berregulierung zu sorgen.1711 
1707 Vgl. Aral Aktiengesellschaft (2019): Trends beim Autokauf 2019.
1708 Vgl. Reidel (2019): Ohne Fahrer? Vorstellbar Autonome Autos: Die Akzeptanz w&#228;chst, das Marketing steht vor Herausforderungen
&#8211; eine Studie der DHBW Ravensburg.
1709 Vgl. B&#252;hler und Rohleder (2018): Autonomes Fahren und vernetzte Mobilit&#228;t.
1710 Vgl. Castle et al. (2017): Flying solo &#8211; how far are we down the path towards pilotless planes?; Plattform Lernende Systeme (2019):
Auf dem Weg zu einem intelligenten Mobilit&#228;tsraum.
1711 Stellungnahme der T&#220;V NORD AG, Projektgruppendrucksache 19(27)PG 5-38 vom 26. Februar 2020.
Es wird entscheidend auf die Akzeptanz durch der potenziellen Nutzerinnen und Nutzern und insbesondere der
Bev&#246;lkerung insgesamt ankommen. Dieser Aspekt zeigt sich ebenso z. B. in der Digitalisierung in den
Kommunen, in der &#246;ffentliche Daten genutzt werden.1712 Es muss daf&#252;r gesorgt werden, dass die Kommunen nicht nur
Akteure der Stadtentwicklung, sondern auch Akteure der Digitalisierung werden und bleiben. Die Nutzung von
&#246;ffentlichen Daten und die Anwendung von Mobilit&#228;ts-Plattformen spielen eine bedeutende Rolle, die im
darauffolgenden Kapitel unter einer marktwirtschaftlichen Perspektive betrachtet wird. Dabei k&#246;nnen auch
Chancen f&#252;r eine Verkehrswende und verbesserte Mobilit&#228;t unter den Aspekten der Inklusion identifiziert werden.1713 
Markt
Aktuell werden im Allgemeinen die digitalen M&#228;rkte von amerikanischen und asiatischen Internetdiensten
beherrscht. Die sieben wertvollsten Unternehmen der Welt sind digitale Plattformunternehmen aus den USA und
China. Es zeigt sich, dass mittel- und langfristig Strukturreformen erforderlich sind, die Europas Stellung und
Wettbewerbsf&#228;higkeit gerade im Bereich digitaler M&#228;rkte auf internationaler Ebene sichern und damit zugleich
unseren &#246;konomischen und gesellschaftlichen Wohlstand bewahren. Eine wichtige Initialz&#252;ndung f&#252;r die weitere
Entwicklung in Europa und ein positives Beispiel f&#252;r den internationalen Digitalmarkt ist in diesem
Zusammenhang das vom BMWi initiierte Projekt GAIA-X, welches als vernetzte Dateninfrastruktur einen eigenen
europ&#228;ischen Weg geht. Hier werden beispielhaft auch Herausforderungen und dazugeh&#246;rige L&#246;sungsm&#246;glichkeiten, 
u. a. in der Darstellung von Verkehrsmodellen, aufgezeigt. So k&#246;nnten zum Beispiel Datenbest&#228;nde aus der
Erdbeobachtung und der &#246;ffentlichen Verwaltung ausgewertet werden, um Datensilos aufzubrechen und
ma&#223;geschneiderte Informationen f&#252;r die Stadtentwicklung und/oder neue digitale Modelle anzubieten.1714 
Neben diesem Projekt hat es sich die Bundesregierung dar&#252;ber hinaus zum Ziel gesetzt, aufgrund der
Marktentwicklungen das Wettbewerbsrecht zu modernisieren sowie dessen rechtliche Grundlagen im Digitalbereich zu
harmonisieren bzw. zusammenzuf&#252;hren. Zu diesem Zweck setzte sie im Jahr 2018 die &#8222;Kommission
Wettbewerbsrecht 4.0&#8220; ein, die im September 2019 ihren Abschlussbericht mit ihren Ergebnissen vorlegte. Die
Kommission diente als rechtspolitische Plattform f&#252;r eine Debatte zur Weiterentwicklung insbesondere auch des
europ&#228;ischen Wettbewerbsrechts und befasste sich mit den wettbewerbspolitischen Fragestellungen, die sich durch
die fortschreitende Entwicklung der Daten&#246;konomie, die Verbreitung von Plattformm&#228;rkten und durch die
Industrie 4.0 ergeben.1715 
Die Ergebnisse lassen sich wie folgt &#8211; auch mit dem Bezug zum Verkehrssektor und der Mobilit&#228;t &#8211;
zusammenfassen: 1716 
Beim Datenzugang schl&#228;gt die Kommission vor, den Zugang zu Verbraucherdaten zu erleichtern. Nach dem
Vorbild der Zahlungsdienste-M&#228;rkte k&#246;nne Regulierung das Recht der Konsumentinnen und Konsumenten
vorsehen, Drittanbietern den Zugriff auf ihr Nutzerkonto zu gew&#228;hren. Zudem wird vorgeschlagen, die Etablierung
von Datentreuh&#228;ndern zu f&#246;rdern, die im Auftrag und nach den Vorgaben der Konsumentinnen und Konsumenten
Datenzug&#228;nge f&#252;r Unternehmen einr&#228;umen k&#246;nnen. F&#252;r marktbeherrschende Plattformen wird daher eine
Versch&#228;rfung der im Datenschutzrecht bereits angelegten Pflicht zur Gew&#228;hrleistung von Datenportabilit&#228;t
vorgeschlagen. Die &#246;ffentliche Hand soll verpflichtet werden, die Daten des &#246;ffentlichen Sektors, z. B. im Rahmen der
Daseinsvorsorge, auch Dritten zur Nutzung zur Verf&#252;gung zu stellen (Open Data). Aus der wachsenden Menge
an Daten in verschiedenen Bereichen folgen auch neue M&#246;glichkeiten ihrer Nutzung f&#252;r &#246;ffentliche,
gemeinwohlorientierte oder gemeinwohlf&#246;rderliche Zwecke. Zu diesen z&#228;hlen etwa staatliche Planungsprozesse. Mit
Mobilit&#228;tsdaten k&#246;nnen so z. B. die Verkehrsplanung und das Angebot multimodaler Verkehrsdienstleistungen
sowie die Parkraumbewirtschaftung verbessert werden.1717 
1712 Vgl. Bundesinstitut f&#252;r Bau-, Stadt- und Raumforschung im Bundesamt f&#252;r Bauwesen und Raumordnung: Smart City Charta.
1713 Siehe hierzu auch den AG-Bericht 2 des Berichts der Projektgruppe &#8222;KI und Staat&#8220; [Thematischer Schwerpunkt].
1714 Vgl. Bundesministerium f&#252;r Wirtschaft und Energie (2019): Das Projekt GAIA-X.
1715 Vgl. Bundesministerium f&#252;r Wirtschaft und Energie: Kommission Wettbewerbsrecht 4.0.
1716 Vgl. Schallbruch et al. (2019): Ein neuer Wettbewerbsrahmen f&#252;r die Digitalwirtschaft. Bericht der Kommission Wettbewerbsrecht 4.0.
1717 Vgl. Schallbruch et al. (2019): Ein neuer Wettbewerbsrahmen f&#252;r die Digitalwirtschaft. Bericht der Kommission Wettbewerbsrecht 4.0.
Im Hinblick auf Plattformm&#228;rkte schl&#228;gt die Kommission klare Verhaltensregeln f&#252;r marktbeherrschende
Online-Plattformen im Rahmen einer Plattform-Verordnung vor, um die Bestreitbarkeit bestehender
Machtpositionen und einen unverf&#228;lschten Wettbewerb auf der Plattform sowie auf und um angrenzende M&#228;rkte zu
gew&#228;hrleisten. Darin sollen insbesondere das Verbot der Selbstbeg&#252;nstigung eigener Dienste im Verh&#228;ltnis zu
Drittanbietern sowie eine Pflicht zur Gew&#228;hrleistung erweiterter Datenportabilit&#228;t in Echtzeit und interoperablen
Datenformaten enthalten sein. Schlie&#223;lich sollen die etablierten Plattformen verpflichtet werden, alternative
Streitbeilegungsverfahren f&#252;r Streitigkeiten &#252;ber Inhalte und Gegenst&#228;nde, die &#252;ber die Plattform angeboten werden,
einzurichten. Diese Regelungen lassen sich auch auf die Plattformangebote im Mobilit&#228;tsbereich anwenden.
Um eine vernetzte Digitalregulierung zu erreichen, sollen zwei neue Institutionen eingerichtet werden: zum einen
ein &#8222;Digital Markets Board&#8220;, das beim Generalsekretariat der EU-Kommission anzusiedeln w&#228;re, zum anderen
eine (befristete) EU-Agentur f&#252;r die Begleitung der Digitalisierung der M&#228;rkte (&#8222;Digital Markets Transformation
Agency&#8220;), um eine bessere Vernetzung der Aufsichtsstrukturen zu erreichen.
Zum Thema Rechtssicherheit bei Kooperationen bemerkt die Wettbewerbskommission in ihrem Bericht, dass
sowohl &#8222;Datenkooperationen &#8211; also Vereinbarungen zwischen Unternehmen &#252;ber das Austauschen, Teilen und
Zusammenf&#252;hren von Daten &#8211; als auch Kooperationen beim gemeinsamen Aufbau von Plattformen, digitalen
Netzwerken und &#214;kosystemen schwierige kartellrechtliche Fragen aufwerfen, die Kooperationsbereitschaft
bremsen&#8220;1718.
Die Kommission Wettbewerbsrecht 4.0 pl&#228;diert daher f&#252;r neue verfahrensrechtliche Instrumente, um
Unternehmen die M&#246;glichkeit zu geben, Rechtssicherheit &#252;ber die kartellrechtliche Zul&#228;ssigkeit neuartiger Kooperationen 
zu erlangen. Vorgeschlagen wird daher, auf europ&#228;ischer Ebene ein freiwilliges Anmeldeverfahren f&#252;r
Kooperationen einzuf&#252;hren, die offene Rechtsfragen aufwerfen und von erheblicher wirtschaftlicher Bedeutung sind. Die
Generaldirektion Wettbewerb sollte dann innerhalb von 90 Arbeitstagen &#252;ber die Zul&#228;ssigkeit einer
angemeldeten Kooperation entscheiden.
Zu erw&#228;hnen ist noch der Vorschlag der Wettbewerbskommission, das Konzept der Marktabgrenzung
anzupassen und zu diesem Zweck die aus dem Jahr 1997 stammende Bekanntmachung &#252;ber die Definition des relevanten
Marktes zu &#252;berarbeiten.1719 Es soll auch eine neue Mitteilung &#252;ber die Marktabgrenzung und
Marktmachtfeststellung bei digitalen Plattformen erarbeitet werden. Durch die Marktentwicklung sind neue konzeptionelle
Fragen aufgrund der Mehrseitigkeit digitaler Plattformen aufgeworfen worden. Es soll gekl&#228;rt werden, unter welchen
Bedingungen von einem plattformseiten&#252;bergreifenden Markt oder aber von separaten M&#228;rkten auf den
jeweiligen Plattformseiten auszugehen ist. Dies betrifft ebenfalls den Mobilit&#228;tssektor, der insbesondere im Bereich der
Intermodalit&#228;t von Plattformen gepr&#228;gt ist.1720 
Bei der Fusionskontrolle r&#228;t die Kommission davon ab, auf EU-Ebene einen Transaktionsschwellenwert wie im
deutschen Recht einzuf&#252;hren. Auch soll von einer Ex-post-Kontrolle von Zusammenschl&#252;ssen derzeit abgesehen
werden. Der Aufkauf innovativer Start-ups mit der Intention einer Marktverdr&#228;ngung (&#8222;killer acquisitions&#8220;) soll
nicht untersagt, sondern in erster Linie einer Beobachtung unterstellt werden. Allerdings empfiehlt die
Kommission, zu diesem Bereich Leitlinien zu entwickeln und dabei die g&#228;ngigen und anerkannten Schadenstheorien zu
beachten.1721 Im darauffolgenden Kapitel wird auf politischer Ebene als ein zus&#228;tzlicher Themenaspekt die
Stadtentwicklung mit seinem Status quo betrachtet.
Politik
Im politischen Sinne ist ein gewichtiger Entwicklungsteil in der Stadtentwicklung der Bereich Smart City. Die
Bundesregierung hat 2016 auf Beschluss des Staatssekret&#228;rsausschusses f&#252;r nachhaltige Entwicklung die
Dialogplattform Smart Cities eingerichtet. Die Dialogplattform f&#246;rdert die Befassung mit Fragen der Digitalisierung
der Mobilit&#228;t auf kommunaler Ebene, die Identifizierung von Chancen und Risiken sowie den nationalen und
internationalen Austausch zu stadtentwicklungspolitischen Fragen der Digitalisierung. Darin enthalten ist auch
die Verkehrsplanung, in welcher die effektive Ausgestaltung und die Steuerung der Mobilit&#228;t profitieren
k&#246;nnen.1722 In der Smart City Charta aus dem Jahre 2017 wurden weiterhin Leitlinien z. B. zur fr&#252;hzeitigen
Erkennung von strategischen Handlungsfeldern erarbeitet. Ein Schwerpunkt liegt auch in optimierten Mobilit&#228;ts- und
1718 Schallbruch et al. (2019): Ein neuer Wettbewerbsrahmen f&#252;r die Digitalwirtschaft. Bericht der Kommission Wettbewerbsrecht 4.0., S. 5.
1719 Vgl. Schallbruch et al. (2019): Ein neuer Wettbewerbsrahmen f&#252;r die Digitalwirtschaft. Bericht der Kommission Wettbewerbsrecht 4.0.
1720 Vgl. Schallbruch et al. (2019): Ein neuer Wettbewerbsrahmen f&#252;r die Digitalwirtschaft. Bericht der Kommission Wettbewerbsrecht 4.0.
1721 Vgl. Schallbruch et al. (2019): Ein neuer Wettbewerbsrahmen f&#252;r die Digitalwirtschaft. Bericht der Kommission Wettbewerbsrecht 4.0.
1722 Vgl. Bundesministerium des Innern, f&#252;r Bau und Heimat: Smart Cities: Stadtentwicklung im digitalen Zeitalter.
Verkehrsabl&#228;ufen. Dabei sollen m&#246;gliche r&#228;umliche Wirkungen der Digitalisierung wie ver&#228;nderter
Verkehrsaufwand, andere Fl&#228;chenbedarfe oder neue Stadtumbaupotenziale ber&#252;cksichtigt werden.1723 
Zur Umsetzung des Koalitionsvertrages f&#246;rdert das Bundesministerium des Innern, f&#252;r Bau und Heimat (BMI) 
seit 2019 Smart-City-Modellprojekte und baut den nationalen und internationalen Erfahrungsaustausch zu
stadtentwicklungspolitischen Fragen der Digitalisierung aus (Smart-City-Dialog).1724 Gef&#246;rdert werden integrierte
Smart-City-Strategien und deren Umsetzung mit Investitionen in Modellkommunen, der Wissenstransfer und 
Kompetenzaufbau sowie eine Begleitforschung und Evaluation der Projekte. Dabei wurden im Juli 2019
verschieden gro&#223;e St&#228;dte und Gemeinden sowie interkommunale Kooperationen ausgew&#228;hlt (u. a. Ulm und
Wolfsburg, aber auch Grevesm&#252;hlen, Soest und Ha&#223;furt).1725 Zur Unterst&#252;tzung des Erfahrungsaustausches wird die
Nationale Dialogplattform Smart Cities fortgesetzt und ein internationales Smart-City-Netzwerk mit
ausgew&#228;hlten Partnerl&#228;ndern aufgebaut. Die Ziele lauten:
&#8226; Kommunen sollen bef&#228;higt werden, die Digitalisierung im Sinne einer nachhaltigen und integrierten
Stadtentwicklung in St&#228;dten, Gemeinden und Kreisen (Smart Cities) strategisch zu gestalten.
&#8226; Lebenswerte Kommunen sollen geschaffen und erhalten werden. Dies beinhaltet z. B. auch einen einfachen,
barrierefreien Zugang zum &#214;PNV sowie andere verkehrstechnische Anbindungen.
&#8226; Technik soll in den Dienst der Menschen gestellt, Freir&#228;ume erhalten und die digitale Spaltung der
Gesellschaft vermieden werden. Hier kann KI vielf&#228;ltig dazu beitragen, die Mobilit&#228;t vertr&#228;glich auszugestalten.
In Anbetracht dieser Zielsetzungen spielen die Mobilit&#228;tsbereiche eine wichtige Rolle, um z. B. durch einen
besseren Zugang zum &#214;PNV die Kommunen lebenswerter oder durch Vernetzung nachhaltiger zu gestalten. Die
Planungen f&#252;r das Jahr 2020 umfassen den Start der zweiten F&#246;rderstaffel mit rund zehn Modellprojekten, die
Intensivierung des Wissenstransfers und des internationalen Austausches sowie die Fortf&#252;hrung und den Ausbau 
des Smart-City-Dialogs.1726 
Dar&#252;ber hinaus zeigen sich in der Nationalen KI-Strategie der Bundesregierung zus&#228;tzliche Zielsetzungen im
Bereich der Stadtentwicklung, die jedoch im Vergleich weniger umfangreich geb&#252;ndelt werden.
Durch eine verst&#228;rkte F&#246;rderung von Forschung und Entwicklung in der Analyse und Bewertung von Daten und
Informationen (z. B. Geoinformationen) m&#252;ssen neue spezifische KI-Verfahren entwickelt werden. In diesen
Gebieten k&#246;nnen umweltschonende Entwicklungen im Bereich von Stadtentwicklung, Verkehr und Mobilit&#228;t
unterst&#252;tzt und verbesserte Aussagen &#252;ber die effektive Nutzung nat&#252;rlicher Ressourcen (z. B. Landnutzung,
Wassernutzung, Entwaldung, u. a. durch Land-/Forstwirtschaft und Rohstoffabbau) getroffen werden.1727 
Die Politik setzt einen breiten Fokus auf den Bereich Smart City. KI kann einen wichtigen Beitrag zur weiteren 
Digitalisierung in der Stadtentwicklung leisten. Hierbei gilt, dass u. a. eine leichtere Nutzung von kombinierten 
Dienstleistungen z. B. &#252;ber Plattformen, eine verbesserte Steuerung des Verkehrs, aber auch z. B. eine bessere
Parkraumbewirtschaftung etabliert werden sollen. Dar&#252;ber hinaus werden auch weitere Bereiche mithilfe der KI
profitieren, wenn es z. B. um die Sensorik zur Messung von Stra&#223;enbel&#228;gen geht. Es zeigt sich, dass eine Vielzahl
von M&#246;glichkeiten vorhanden ist, KI in der Stadtentwicklung zu nutzen, um eine umweltschonendere und
allgemein h&#246;here Lebensqualit&#228;t zu etablieren &#8211; sowohl f&#252;r diejenigen, die in einer Stadt, Gemeinde oder Kommune
leben, als auch f&#252;r diejenigen, die dort nur zu Besuch sind. Im Folgenden werden die drei Themenbereiche
&#8222;&#214;konomie/Wettbewerb&#8220;, &#8222;Stadtentwicklung&#8220; sowie &#8222;Sicherheit/Standards&#8220; mit ihren Ergebnissen der
Projektgruppensitzung eingehender erl&#228;utert.
4.7.2 KI mit Blick auf &#214;konomie und Wettbewerb
Wichtige und der Allgemeinheit bereits bekannte Bereiche der Mobilit&#228;t, bei denen KI eingesetzt wird, sind zum
Beispiel die Navigation, das autonomes Fahren, das Smart Parking, die intelligente Verkehrslenkung, der
verkehrsanbieter&#252;bergreifende Ticketverkauf und die daraus folgende bessere Nutzung der knappen Verkehrsr&#228;ume.
Zuk&#252;nftig verspricht man sich, dass KI es erm&#246;glichen wird, dass Fahrzeugflotten noch besser genutzt und
Routen effizienter ausgew&#228;hlt werden k&#246;nnen.
1723 Vgl. Bundesinstitut f&#252;r Bau-, Stadt- und Raumforschung im Bundesamt f&#252;r Bauwesen und Raumordnung: Smart City Charta.
1724 Vgl. Bundesregierung (2020): Digitale Stadtentwicklung und F&#246;rderung von Smart Cities.
1725 Vgl. Bundesministerium des Innern, f&#252;r Bau und Heimat (2019): 13 Modellprojekte Smart Cities ausgew&#228;hlt.
1726 Vgl. Bundesregierung (2020): Digitale Stadtentwicklung und F&#246;rderung von Smart Cities.
1727 Vgl. Bundesregierung (2018): Strategie K&#252;nstliche Intelligenz der Bundesregierung.
Es ist festzuhalten, dass aus &#246;konomischer Betrachtungsweise die effiziente Nutzung der knappen Ressourcen,
z. B. Fahrzeuge und Verkehrswege, w&#252;nschenswert ist, da es die bestm&#246;gliche Verwendung und Auslastung
verspricht. Um dieses angestrebte Ergebnis zu erreichen, geht die wirtschaftswissenschaftliche Forschung im
Allgemeinen davon aus, dass Wettbewerb als Innovationstreiber wirkt. Dar&#252;ber hinaus sollte der Staat als Teil
der Daseinsvorsorge Mobilit&#228;tsangebote finanzieren oder selbst bereitstellen.
Dieser Wettbewerb, bei dem mehrere Anbieter mit verschiedenen Produkten um die Gunst der Nutzerinnen und
Nutzer werben, kann jedoch in wenigen F&#228;llen auch nachteilig sein, insbesondere wenn es um Netze geht. Als
Beispiel sei das Schienennetz angef&#252;hrt: Der Bau und die Erhaltung des Schienennetzes sind kostenintensiv und
aufwendig; es ergibt keinen Sinn, neben dem Netz, auf dem die Deutsche Bahn AG ihre Z&#252;ge betreibt, ein zweites
Schienennetz zu erschaffen und zu nutzen. Zudem profitieren gr&#246;&#223;ere Netze von Netzwerkeffekten: &#220;ber gr&#246;&#223;ere
Mengen beim Einkauf lassen sich die Beschaffungskosten teils erheblich senken. Dies gibt einem Unternehmen
Raum, mehr Investitionen zu t&#228;tigen.
Aus dem Gutachten der deutschen Monopolkommission von 2014/2015 geht allerdings hervor, dass auch
au&#223;erhalb von Netzen Monopole entstehen k&#246;nnen, wie zum Beispiel bei weltweit agierenden Anbietern. Hier liegen
die Kostenstruktur f&#252;r die Entwicklung und Betreibung ihrer Produkte und die Kostenstruktur eines Netzes nah
beieinander: Die hohen Kosten machen die Entwicklung einer &#228;hnlichen Dienstleistung gleicher Qualit&#228;t
wirtschaftlich unrentabel (z. B. Bing, die Suchmaschine von Microsoft).
Es l&#228;sst sich anf&#252;hren, dass dieser Netzwerkeffekt, welcher zu einem Lock-in-Effekt f&#252;hrt, die Bildung von
Monopolen f&#246;rdert: So kann z. B. ein Anbieter von Navigationsdienstleistungen, der ein sehr gro&#223;es Aufkommen an
Bewegungsdaten hat, bessere Vorhersagen treffen als kleinere Anbieter. Durch Maschinelles Lernen kann eine
Maschine immer genauere Muster erkennen und von diesen lernen: Die Effekte ihrer eigenen Empfehlungen zum
Beispiel auf Verkehrsstr&#246;me kann sie analysieren und so weitere, neue R&#252;ckschl&#252;sse ziehen und diese f&#252;r ihre
zuk&#252;nftigen Empfehlungen verwenden. Die daf&#252;r notwendigen, f&#252;r die Betreibung von KI erforderlichen gro&#223;en
Datenmengen bekommt sie durch ihre hohe Anzahl an Nutzerinnen und Nutzern. Dies f&#252;hrt f&#252;r die als
Plattformen ausgestalteten Produkte dazu, dass ein einzelner Anbieter sich z&#252;gig als Marktf&#252;hrer etabliert und diesen
Markt schlie&#223;lich beherrscht &#8211; dies muss nicht geschehen, weil der Marktteilnehmer den Wettbewerb unlauter
beeinflusst, sondern weil er ab dem Moment, in dem er eine kritische Gr&#246;&#223;e erreicht, den Nutzerinnen und
Nutzern zun&#228;chst das qualitativ beste Produkt anbietet.
Gesetzt also den Fall, dass alle Verbraucherinnen und Verbraucher einem Anbieter vertrauen, findet mangels
konkurrierender Anbieter kein Wettbewerb mehr statt, der Markt ist au&#223;er Kraft gesetzt.
Wirtschaftswissenschaftler halten dieses Ergebnis im Allgemeinen f&#252;r insofern ertr&#228;glich, als dass dies &#8211; wie oben angedeutet &#8211;
nicht auf unlautere Weise geschieht.
Sie gehen allerdings davon aus, dass in einem monopolitischen Markt die Marktmacht missbraucht werden kann
und weniger Notwendigkeit f&#252;r Innovationen besteht. Bisher wird dem h&#228;ufig mit spezialgesetzlichen
Regelungen zu begegnen versucht, indem bestimmte Unternehmen durch eigens f&#252;r sie geschaffene Gesetze reguliert
werden, z. B. die Deutsche Post und die Deutsche Bahn AG. Wie in vorangegangenen Kapiteln bereits
beschrieben, bedarf es einer genauen Betrachtung des Umgangs mit Daten auf einem freien Markt. Hierf&#252;r m&#252;sste der
Rechtsrahmen angepasst werden. Unternehmen w&#228;ren dann zu neuen Innovationen gezwungen und k&#246;nnten sich
nicht lediglich auf einem Datenschatz als Grundlage ihres Gesch&#228;ftsmodells ausruhen. Zu empfehlen sei
jedenfalls, dass ein Markt offen f&#252;r neue Technologien sein m&#252;sse. Es sei zu beobachten, dass auf diese Weise ein
Wettbewerb um den Markt statt auf dem Markt selbst entstehe.
Gro&#223;e Vorteile sieht man durch KI und selbstlernende Algorithmen beim gemeinsamen Nutzen von Fahrdiensten 
durch mehrere Nutzerinnen und Nutzer (sogenanntes Ridepooling oder auch der &#214;PNV). Dies gilt auch f&#252;r den
individuellen Privatverkehr. In den Bereichen Wasser, Schiene und Luft k&#246;nnen eine bessere Routenplanung &#8211;
direkt durch KI oder indirekt durch KI-basierte Predictive Maintenance &#8211; sowie die Optimierung von
Logistikketten ebenfalls f&#252;r Zeit- und Kostenersparnis und eine Entlastung von Verkehrswegen und Umwelt sorgen.
4.7.3 KI und Stadtentwicklung
Bereits heute werden im Auto zahlreiche Fahrassistenzsysteme verwendet (ESP, ABS, Parkassistent). Auch die
adaptive Steuerung von Signalanlagen und Parkleitsystemen wird bereits seit l&#228;ngerer Zeit erforscht und teils
auch umgesetzt, steckt allerdings noch in den Kinderschuhen. F&#252;r zuk&#252;nftige Generationen gilt es, die Teilnahme
und gleichwertige Erreichbarkeit von Angeboten in unterschiedlichen R&#228;umen des Landes zu gew&#228;hrleisten. KI
er&#246;ffnet dabei vielf&#228;ltige Chancen, die einen langen Weg einer kontrollierten Umsetzung voraussetzen und
holistische Ans&#228;tze verfolgen, sodass kontraproduktive Rahmenbedingungen vermieden werden.
Dies macht ein Zusammenwirken aller Interessengruppen erforderlich: vom Fahrzeughersteller &#252;ber
Mobilit&#228;tsdienstleister bis hin zu Planungstr&#228;gern sowie Nutzerinnen und Nutzern. Es lassen sich unterschiedliche
Organisations- und Optimierungskriterien aufzeigen, nach denen man den Einsatz von KI zur Verkehrsplanung
beurteilen kann:
&#8226; Erreichbarkeit und Zug&#228;nglichkeit des Mobilit&#228;tsangebots
&#8226; Funktionst&#252;chtigkeit/Wirkungsgrad (Bedarfsorientierung)
&#8226; Effizienz des Fahrzeugeinsatzes und der Infrastrukturnutzung
&#8226; Ressourcensparsamkeit, Umweltvertr&#228;glichkeit
&#8226; Klimavertr&#228;glichkeit
&#8226; Raumvertr&#228;glichkeit und Stadt(raum)qualit&#228;ten
F&#252;r Nutzerinnen und Nutzer ist insbesondere relevant, dass Mobilit&#228;t verkehrstr&#228;ger&#252;bergreifend ist und Ziele
schnell und bequem erreicht werden. Verkehrstr&#228;ger&#252;bergreifende Mobilit&#228;t kann dabei unterst&#252;tzen, dieses Ziel
zu erreichen. Dazu geh&#246;rt die Verzahnung von &#214;PNV und individueller Mobilit&#228;t wie E-Scootern und kleinen
Shuttles. Automatisierung und KI k&#246;nnen dabei unterst&#252;tzend wirken, etwa indem durch automatisierte
Parkh&#228;user und intelligente Parkleitsysteme das Parkraum-Management optimiert wird.
KI-unterst&#252;tzte Verkehrssteuerung kann schlie&#223;lich durch Anreize den Umstieg auf andere Verkehrsmittel
f&#246;rdern und so den Verkehr r&#228;umlich und zeitlich entzerren &#8211; auch durch dynamische Preisgestaltung. Die
Bundesrepublik Deutschland darf es dabei allerdings nicht zu einer Art Zwei-Klassen-Mobilit&#228;t kommen lassen. Der
Staat als Tr&#228;ger der &#246;ffentlichen Daseinsvorsorge ist und bleibt dem Gleichheitsgrundsatz verpflichtet.
Gleichzeitig kommt es h&#228;ufig dazu, dass neue Technologien bei ihrer Einf&#252;hrung zu Bedenken und &#196;ngsten
f&#252;hren. Es ist daher von besonderer Wichtigkeit, dass f&#252;r alle Teilnehmerinnen und Teilnehmer sowie alle
Nutzerinnen und Nutzer von KI-gest&#252;tzten Mobilit&#228;tsl&#246;sungen die Sicherheit der eigenen Person wie auch der
eigenen Daten im Vordergrund steht. Die Vorbehalte der Nutzerinnen und Nutzer lassen sich grob in zwei Gruppen
einteilen: zum einen solche, die dem System inh&#228;rent sind oder stark vom System bedingt sind, und zum anderen
solche, die als Konsequenzen der Nutzung von KI-Systemen in der Mobilit&#228;t entstehen.
Zur ersten Gruppe geh&#246;ren die Sorgen, dass die komplexen Systeme selbst kompromittiert (gehackt) werden 
k&#246;nnten, dass KI bei sicherheitskritischen Anwendungen (z. B. bei autonomen Fahrzeugen) Fehler macht oder
dass Menschen durch KI zu manipulieren versucht werden.
Zur zweiten Gruppe z&#228;hlen die &#196;ngste, dass die Menschen noch st&#228;rker als bisher von digitaler Technologie
abh&#228;ngig sein werden, dass KI-Anwendungen falsche Entscheidungen treffen und insbesondere dass Menschen
m&#246;glicherweise durch KI-Systeme diskriminiert oder &#252;bervorteilt werden.
Damit neue Mobilit&#228;tsl&#246;sungen, die von KI unterst&#252;tzt und angetrieben werden, von der Mehrheit der
Nutzerinnen und Nutzer angenommen werden, m&#252;ssen die aufgef&#252;hrten Sorgen ernst genommen werden. Die offene
Kommunikation und Transparenz sowie das Heranf&#252;hren der Nutzerinnen und Nutzer an die Verwendung der
Technologien werden von zentraler Bedeutung sein. Parallel dazu sollte eine Vision von
verkehrstr&#228;ger&#252;bergreifender Mobilit&#228;t entworfen werden, die einen w&#252;nschenswerten, m&#246;glichst nahtlosen Verkehr beschreibt.
Um diese Entwicklung anzusto&#223;en, die sowohl eine breite gesellschaftliche Debatte als auch reale Tests der neuen
KI-L&#246;sungen beinhaltet, lassen sich die folgenden Voraussetzungen f&#252;r einen nebenwirkungsfreien Auf- und 
Ausbau vortragen:
&#8226; Sicherstellen von Zuverl&#228;ssigkeit der Technik
&#8226; Datenschutz und -sicherheit
&#8226; Sicherung eines innovationsoffenen Rechtsrahmens
&#8226; Einsatz von &#8222;Anwendungslaboren&#8220;
&#8226; Gew&#246;hnung an den Einsatz von KI in Geb&#228;uden und St&#228;dten
4.7.4 Sicherheit bei KI-gest&#252;tzter Mobilit&#228;t
Die Sicherheit von KI-gest&#252;tzter Mobilit&#228;t ist noch in vielen Bereichen ungekl&#228;rt. Deutschland k&#246;nnte einen
Vorsprung im KI-Einsatz f&#252;r sicherheitskritische Anwendungen gewinnen, sofern daf&#252;r z&#252;gig sichere und
zugleich praktikable L&#246;sungen gefunden w&#252;rden. Dabei kann auf Erfahrungen mit Standards und Normung im
Verkehrsbereich aufgesetzt werden. F&#252;r nicht-KI-gest&#252;tzte Mobilit&#228;t gibt es die Standards ISO 26262 f&#252;r
Stra&#223;enfahrzeuge, DO178B f&#252;r Flugzeuge, EN50128 f&#252;r Schienenfahrzeuge und &#252;bergreifend IEC 61508 zur
Entwicklung von elektrischen, elektronischen und programmierbaren elektronischen Systemen, die eine
Sicherheitsfunktion ausf&#252;hren. Dar&#252;ber hinaus gibt es noch weitere grundlegende Standards wie ISO/IEC 9126 f&#252;r
Softwarequalit&#228;t. Die genannten Standards schlie&#223;en jedoch KI-Verfahren nicht ein und zum Teil auch explizit aus.
Die existierenden Standards zeigen einen Weg f&#252;r KI-gest&#252;tzte Mobilit&#228;t auf: Die Einf&#252;hrung von Redundanzen
in KI-Systeme sind ein in den Standards genanntes Konzept, um ausreichend Sicherheit zu gew&#228;hrleisten.
&#8226; Ein redundantes Nicht-KI-System kann ein KI-System &#252;berwachen, um so f&#252;r eine eingeschr&#228;nkte Zeit eine,
wenn auch eingeschr&#228;nkte Funktionalit&#228;t sicherzustellen.
&#8226; Redundanz ist gefordert, wenn Sensoren Daten aufnehmen und Aktuatoren1728 Aktionen in der realen Welt
ausl&#246;sen. Dies gilt f&#252;r KI-Systeme wie auch Nicht-KI-Systeme.
&#8226; Redundanz ist auch das Mittel, um zuf&#228;llige Fehler zu erkennen und die Folgen zu korrigieren. Betrachtet
man KI-Systeme als ein auszuf&#252;hrendes Softwaresystem, dann k&#246;nnen dieselben Mechanismen, die die
Ausf&#252;hrung von Nicht-KI-Systemen sicherstellen auch die Ausf&#252;hrung von KI-Systemen sicherstellen.
Der gro&#223;e offene Punkt sind systematische Fehler, d. h. Entwurfsfehler1729. So sehr sich die Verfahren zur
Erstellung von KI-Produkten verbessert haben, so wenig wurde in die Verifikation und Validierung der gelernten
L&#246;sungen investiert. Deshalb hinkt die Grundlagenforschung auf dem Gebiet der Verifikation und Validierung
hinterher. Ein generischer Standard vergleichbar mit ISO/IEC 9126 f&#252;r Softwarequalit&#228;t kann erst dann
angegangen werden.
Eine exemplarische Funktionswahrscheinlichkeit von 95 bis 98 Prozent wird als sehr gut angenommen. Diese
Betrachtung entspricht einem sogenannten Smoke- oder Anwendungs-Test in der Software, erlaubt aber keine 
systematische Betrachtung von Grenzf&#228;llen, die f&#252;r sicherheitsrelevante Systeme notwendig ist.
Erkl&#228;rbarkeit ist nur ein erster und kleiner Schritt in die Richtung, denn sie hilft zu verstehen, warum die KI in
einem bestimmten Fall zu einer Aussage gekommen ist. Verifikation und Validierung m&#252;ssen nachweisen, dass
in m&#246;glichst allen F&#228;llen die Aussage und die davon abgeleiteten Aktionen richtig sind.
Weitere Punkte sind die Ausgestaltung der oben genannten redundanzbasierten L&#246;sungen. Verfahren zur
Auswirkung von Betriebsfehlern auf KI sind zu entwickeln, um an KI angepasste &#8211; und damit effizientere &#8211;
Redundanzmechanismen einsetzen zu k&#246;nnen. Die &#220;berwachung von KI-Teilsystemen durch Nicht-KI-Teilsysteme
muss systematisiert, der dadurch gewonnene Sicherheitsgewinn quantifiziert werden. Zuletzt sind Verfahren zur
Sensitivit&#228;tsanalyse von KI-Systemen notwendig, um die Auswirkungen der Schwankungen der Umwelt auf ein
KI-System (beim Auto z. B. Temperatur oder Sensor-Verschmutzung) bewerten zu k&#246;nnen.
4.7.5 Handlungsempfehlungen
Die Kr&#228;fte des Wettbewerbs nutzen und dezentrale L&#246;sungen verfolgen
Der Wettbewerb ist und bleibt der wichtigste Antrieb f&#252;r Innovationen und neue Dienstleistungen, die mithilfe
von KI neue Mobilit&#228;tsans&#228;tze vorantreiben. Ihn gilt es zu f&#246;rdern, indem Anreize f&#252;r die Entwicklung neuer
Produkte und die stetige Verbesserung aktueller Produkte gesetzt werden. Unternehmen, die eine
Monopolstellung erlangt haben, sollten durch die gezielte F&#246;rderung dezentraler L&#246;sungen von neuen Ideen auf europ&#228;ischer
Ebene zu Engagement herausgefordert werden. 
Sobald Regulierungen erforderlich sind &#8211; zum Beispiel, um Sicherheitsanforderungen zu schaffen und
Haftungsfragen zu kl&#228;ren &#8211; sollten diese auf europ&#228;ischer Ebene ausgestaltet werden. Solch eine EU-Regulierung hat zwei
Vorteile: Zum einen werden nationale Flickenteppiche vermieden, die Unternehmen vor Schwierigkeiten stellen;
1728 Beispiele f&#252;r Aktuatoren sind Motoren, Pumpen, gesteuerte Ventile usw.
1729 Prof. Dr. Thomas Form (Autonomous Driving K-GX, Volkswagen AG) dr&#252;ckte diesen Sachverhalt in der Sitzung der Projektgruppe
KI und Mobilit&#228;t am 16. Dezember 2019 so aus: &#8222;Wir wissen nicht, was wir nicht wissen.&#8220;.
        
 
 
  
   
 
 
 
   
          
    
 
  
 
           
  
   
 
 
   
 
   
  
  
 
        
 
    
  
 
   
   
  
  
      
 
   
      
                                               
      
   
  
      
   
   
    
         
       
1
zum anderen darf man sich erhoffen, neue Standards zu etablieren wie mit der DSGVO. Nur so kann im Bereich
KI der &#8222;European Third Way&#8220; beschritten werden.
Zielgerichtete Experimentierr&#228;ume im Verkehr schaffen
Neue Anwendungen von KI sollten in Reallaboren ausgiebig im Hinblick auf ihre Interoperabilit&#228;t, Sicherheit
und Nutzerfreundlichkeit getestet werden. Hierzu bietet es sich an, sowohl im st&#228;dtischen als auch im l&#228;ndlichen
Raum designierte R&#228;ume zu erschlie&#223;en, in denen Technologien real erprobt werden k&#246;nnen, bevor diese auf das
ganze Bundesgebiet ausgerollt werden. Wenn Anwendungen hier im Testbett f&#252;r weitere technische L&#246;sungen
mit KI in der Verkehrsplanung gut umgesetzt werden, werden weitere zuk&#252;nftige Entwicklungen bei Netzen,
Fahrzeugen und Verkehrswegen von Nutzerinnen und Nutzern gut angenommen werden.
Definierte Regeln, Normen und Standards anwenden
Auch in KI-Laboren sollen zumindest die in diesem Rahmen definierten Regeln, Normen und Standards f&#252;r
Nicht-KI-Produkte angewendet werden (z. B: ISO 26262 f&#252;r autonomes Fahren). Wo vorhanden, sollen Nicht-
KI-Anwendungen die Aktionen von KI-Anwendungen kontrollieren (z. B. Bremsassistenz f&#252;r ein autonom
fahrendes Auto).1730 Dies sollte zu keiner &#220;berregulierung f&#252;hren, da entsprechende Verfahren in der deutschen
Automobilindustrie bereits eingef&#252;hrt wurden.
Zertifizierung &#252;ber existierende Standards vornehmen
Die Zertifizierung von KI-Produkten soll bei den existierenden Standards f&#252;r Nicht-KI-Systeme beginnen. KI-
Systeme sind auch Software-Systeme und ben&#246;tigen wie Software Prozessoren und im zunehmenden Ma&#223;e
Spezial-Hardware zur Ausf&#252;hrung. Das L&#246;sen von eingeschr&#228;nkten Problemstellungen grenzt den L&#246;sungsraum ein 
und hilft so, sichere KI-L&#246;sungen zu finden. Erst dann sollten generische Problemstellungen adressiert werden.
Ein Forschungsprogramm zur Verifizierung und Validierung initiieren
Auch wenn es Fortschritte bei der erkl&#228;rbaren KI gibt, so ist die Verifizierung und die Validierung von KI-
Systemen ein weitgehend unbearbeitetes Forschungsfeld. Es wird empfohlen, ein Forschungsprogramm
aufzulegen, das mit einem Grundlagenforschungsprogramm der Deutschen Forschungsgemeinschaft (DFG) gekoppelt
ist.
VII. K&#252;nstliche Intelligenz und Medien (Projektgruppe 6)1731 
Kurzfassung des Projektgruppenberichts1732 
Kontext
Die Projektgruppe &#8222;KI und Medien (Social Media, Meinungsbildung und Demokratie)&#8220; setzt sich mit bereits
eingetretenen und m&#246;glichen Auswirkungen von K&#252;nstlicher Intelligenz (KI) auf Journalismus, Medienpolitik 
und Meinungsbildung auseinander. Insbesondere geht es um Fragen der Produktion und Distribution von
Medieninhalten unter Zuhilfenahme von KI sowie um dazugeh&#246;rige Regulierungsfragen.
KI spielt bereits heute in der Produktion und Distribution von Medieninhalten eine wichtige Rolle. Beispielsweise
werden schon jetzt Nachrichtentexte mithilfe von KI automatisch produziert. In der Distribution von
Medieninhalten sind soziale Netzwerke, Suchmaschinen, Videoportale und andere digitale Plattformen nicht mehr aus dem
Alltag vieler Menschen wegzudenken.
Solche digitalen Plattformanbieter nutzen gro&#223;e Mengen pers&#246;nlicher Verhaltensdaten von B&#252;rgerinnen und
B&#252;rgern, um ihnen Inhalte auszuspielen, von denen KI-Systeme vermuten, dass sie das &#8222;Engagement&#8220; der Nutzenden
1730 Die Untersuchung eines Unfalls zeigte, dass beim KI-basierten autonomen Fahren nicht einmal die Sicherheitskriterien f&#252;r autonome,
aber nicht-KI-basierte Verfahren (z. B. ABS) zum Einsatz kamen. Des Weiteren war ein klassisch implementiertes automatisches
Bremssystem ausgeschaltet.
1731 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion B&#220;NDNIS 90/DIE GR&#220;NEN vor [Sondervotum zu Kapitel C. VII.
&#8222;K&#252;nstliche Intelligenz und Medien (Projektgruppe 6)&#8220; der Abgeordneten Tabea R&#246;&#223;ner, Dr. Petra Sitte und Jessica Tatti und der 
sachverst&#228;ndigen Mitglieder Dr. Florian Butollo und Dr. Stefan Heumann].
1732 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion der AfD vor [Sondervotum zu den Kapiteln 1 und 4.3 des Berichts der
Projektgruppe 6 &#8222;KI und Medien&#8220; (&#8222;Kurzfassung des Projektgruppenberichts &#8220; und &#8222;Ziele und Aufgaben von Medienpolitik &#8220;) der
Abgeordneten Joana Cotar sowie der Abgeordneten Peter Felser und Dr. Marc Jongen].
erh&#246;hen. Die algorithmenbasierte Personalisierung von Medieninhalten bezieht sich dabei nicht nur auf triviale
Alltagsfragen wie den Kino- oder Restaurantbesuch, sondern auch auf Diskussionen zu Wahlentscheidungen und
politischen Positionen, die f&#252;r demokratische Prozesse bedeutsam sind. Diese KI-gesteuerten Empfehlungs- und
Filtersysteme bieten neue M&#246;glichkeiten f&#252;r B&#252;rgerinnen und B&#252;rger, sich an politischen Diskussionen zu
beteiligen, bergen jedoch auch Risiken hinsichtlich stark personalisierter Informationsr&#228;ume, die vornehmlich auf das
gezielte Platzieren verhaltensbasierter Werbung ausgerichtet sind. Dies markiert einen bedeutsamen Unterschied
zu analogen werbegetriebenen Medienangeboten, die weder auf eine F&#252;lle pers&#246;nlicher Verhaltensdaten noch
auf propriet&#228;re KI-Systeme zur zielgenauen Ausspielung von Inhalten basierend auf diesen Daten zur&#252;ckgreifen.
Zudem sind die KI-Systeme weder f&#252;r Nutzende noch f&#252;r Forschende noch f&#252;r Aufsichtsbeh&#246;rden transparent
und verst&#228;ndlich.
Daraus ergibt sich die Notwendigkeit, Medienpolitik und Regulierung im Medienbereich zu &#252;berdenken. Dies
gilt insbesondere, da gerade j&#252;ngere Menschen digitale, KI-gesteuerte Medienangebote schon heute nutzen und
solche Angebote in Zukunft eher an Bedeutung gewinnen werden. 
Die Projektgruppe sieht daher zwei &#252;bergreifende Handlungsfelder f&#252;r Politik und Gesellschaft. Zum einen muss
Medienpolitik im Blick haben, unabh&#228;ngigen Journalismus und eine pluralistische &#214;ffentlichkeit zu
gew&#228;hrleisten und zu f&#246;rdern. Wichtig erscheint dabei, dass &#246;ffentlich-rechtliche Medien auch k&#252;nftig relevant und
akzeptiert bleiben &#8211; und zwar &#252;ber alle Altersgruppen und sozialen Schichten hinweg. Die Auffindbarkeit von Inhalten 
der Verlage, des &#246;ffentlich-rechtlichen Rundfunks und von anderen Qualit&#228;tsmedien &#8211; auch aus dem privaten 
Bereich &#8211; muss in allen Netzen durch geeignete Ma&#223;nahmen sichergestellt werden, um Netzneutralit&#228;t und
Diskriminierungsfreiheit zu gew&#228;hrleisten. Zum anderen ist sich die Projektgruppe einig, dass die die Kompetenzen
der B&#252;rgerinnen und B&#252;rger im Umgang mit digitalen Nachrichten dauerhaft und permanent gest&#228;rkt werden
m&#252;ssen.
Die Erzeugung von Inhalten durch KI-Systeme, ihre Verteilung durch Empfehlungssysteme und ihre
automatische Analyse durch KI-Systeme bed&#252;rfen spezieller digitaler bzw. medialer Kompetenzen. Wichtig dabei ist die
objektive Vermittlung von Chancen und Risiken des KI-Einsatzes im Medienbereich sowie von Kenntnissen &#252;ber
die Funktionsweise von KI-Anwendungen, wie Empfehlungssystemen oder Sprachassistenzsystemen. F&#252;r die
Wirkung von KI-Systemen im Bereich Medien sind daher Bildungsangebote f&#252;r Menschen aller Altersstufen zu
entwickeln, damit B&#252;rgerinnen und B&#252;rger sich ihrer M&#246;glichkeiten bewusst sind. 
Mediale Inhalte werden auf Medienm&#228;rkten gehandelt. Im Internet herrscht nur eine scheinbare Gratiskultur,
tats&#228;chlich bezahlen die Nutzenden mit ihren Daten, von deren Sammlung, Speicherung, Auswertung und
Reproduktion via KI sich nur wenige einen Begriff machen. Die aggregierten Daten werden von den Intermedi&#228;ren 
zu Werbezwecken verkauft, gleichzeitig dienen sie als Referenzgr&#246;&#223;e f&#252;r neue Inhalte. Die Hebelwirkung des
Einsatzes von KI bei Empfehlungssystemen ist evident und st&#228;rkt insbesondere Intermedi&#228;re in den
Medienm&#228;rkten, selbst wenn diese keine eigenen medialen Inhalte anbieten.
Will man die Medienvielfalt erhalten, bleibt aus dieser Perspektive als sinnvolles Instrument &#8211; neben einer
entsprechenden Anpassung des Kartellrechts &#8211; die Schaffung von Fonds, aus denen F&#246;rderprojekte im Sinne der
Medienvielfalt finanziert werden.
Produktion
Digitale Technologien haben Produktion und Nutzung von Medien in den letzten Jahrzehnten massiv ver&#228;ndert.
In diesem Kontext hat sich auch die journalistische Arbeit ver&#228;ndert. Einerseits hat KI gro&#223;es Potenzial, neue
Datenquellen automatisiert zu erfassen und auszuwerten. Anderseits ist der Einsatz von KI im Mediensektor auch
vor dem gestiegenen Kostendruck zu sehen und k&#246;nnte so den Qualit&#228;tsjournalismus weiter unter Druck setzen. 
Der gesellschaftliche und &#246;konomische Kontext ist daher auch hier f&#252;r die Bewertung von Chancen und Risiken
entscheidend. 
Der Roboterjournalismus arbeitet mit symbolischen Verfahren, die als Eingabe tabellarische Verkehrs- und
Wetterdaten oder Sportergebnisse bekommen. G&#228;ngige Textbausteine dieser Genres werden in einer Datenbank
gesammelt, Algorithmen setzen bei Bedarf aktuelle Zahlen und Namen ein und generieren einen neuen Text. Die
f&#252;r das automatisierte Schreiben notwendigen Daten liegen meist in den Datenbanken kommerzieller Anbieter.
Daher betrachtet die Projektgruppe die Schaffung und den Ausbau von Open-Data-Best&#228;nden durch staatliche
Einrichtungen als notwendigen Schritt, um k&#252;nftige KI-Projekte im Bereich der Medien voranzutreiben.
Das automatisierte Schreiben &#252;bernimmt nach jetzigem Entwicklungsstand lediglich Routinearbeiten wie das
Produzieren kurzer standardisierter Texte, die auf dichtem Zahlenmaterial und stetig wiederkehrenden Strukturen
beruhen. Recherchen, Informantengespr&#228;che, Vor-Ort-Reportagen und engagierte Kommentare lassen sich bis
auf Weiteres nicht an Algorithmen delegieren. Um die Glaubw&#252;rdigkeit journalistischer Arbeit zu gew&#228;hrleisten,
die neben dem Ort der Publikation nicht zuletzt am Namen des jeweiligen Autors oder der jeweiligen Autorin
h&#228;ngt, empfiehlt die Projektgruppe eine konsequente einheitliche Kennzeichnung KI-generierter Texte.
Der Begriff Deep Fake beschreibt das Resultat der Erstellung oder Manipulation von Audio- und Videoinhalten,
die &#196;u&#223;erungen oder Handlungen real existierender Personen wiedergeben, die diese in Wahrheit nicht get&#228;tigt
haben. Seit den 1990er Jahren stehen vermehrt Computerprogramme zur Verf&#252;gung, mit denen digitale Bilder
und Videomaterial (nach)bearbeitet werden k&#246;nnen. Mit dem Einsatz K&#252;nstlicher Intelligenz &#228;ndert sich jedoch
die Pr&#228;zision der Manipulation, die nun t&#228;uschend echt wirkt, ohne sichtbare Spuren der Bearbeitung
aufzuweisen. Zudem verringern sich Aufwand und Kosten der Bearbeitung.
Hier muss eine F&#228;lschung kontextuell wie technisch nachweisbar sein. Die Projektgruppe empfiehlt den Aufbau
einer unabh&#228;ngigen Einrichtung, die die technische Pr&#252;fung von Medieninhalten unterst&#252;tzt. Ursprung,
Authentizit&#228;t und Aussagekraft von Mediendaten m&#252;ssen in verschiedenen Handlungsfeldern &#252;berpr&#252;ft werden. Dies
betrifft neben dem Journalismus auch Strafverfolgungsbeh&#246;rden, Privatunternehmen mit medienbasierten
Gesch&#228;ftsprozessen und politische Institutionen, die die Dienste einer solchen Einrichtung in Anspruch nehmen
k&#246;nnen. Dar&#252;ber hinaus empfiehlt die Projektgruppe, die Forschungsf&#246;rderung auf dem Feld von Deep Fakes zu 
erh&#246;hen.
Dem journalistischen Einsatz von KI liegen gro&#223;e Mengen maschinenlesbarer Daten zugrunde, die sich in den
H&#228;nden einiger weniger (in der Regel kommerzieller) Anbieter konzentrieren. Vor diesem Hintergrund sind nach
Ansicht der Projektgruppe Ans&#228;tze zu diskutieren, wie zu reichweitenstarken Intermedi&#228;ren offene Schnittstellen
geschaffen werden k&#246;nnen, &#252;ber die ausgew&#228;hlte Journalistinnen und Journalisten, Wissenschaftlerinnen und
Wissenschaftler sowie Marktaufsichtsbeh&#246;rden Zugriff auf die ausgew&#228;hlten Datenpools bekommen, ohne dass
hierbei Bestimmungen des Datenschutzes verletzt werden. Dies ist notwendig, um ihre Aufgaben der Information
der &#214;ffentlichkeit sowie der Forschung und Kontrolle angemessen wahrnehmen zu k&#246;nnen.
Dabei ist zu pr&#252;fen, wem Zugang zu welchen Daten gew&#228;hrt werden soll und welche Speicher-, Dokumentations-
und Nutzungspflichten dabei auferlegt werden sollen.
Distribution
Mit dem Aufkommen des Internets und neuen Formaten wie Blogs, Online-Foren etc. wurde die Wirkung von
Massenmedien als &#8222;Gatekeeper&#8220; deutlich reduziert. Durch personalisierte Empfehlungen unterst&#252;tzen KI-
Technologien Nutzende dabei, sich in der F&#252;lle der im Internet und auf sozialen Medien verf&#252;gbaren
Medienangeboten zu orientieren. Die Tatsache, dass die Empfehlungen in der Regel keinen journalistischen Standards, sondern
eher den Gesch&#228;ftsinteressen der Unternehmen folgen, wirft Fragen zum Einfluss von Intermedi&#228;ren auf die
politische Meinungsbildung auf.
Die Auswahl und Ausgabe von Nachrichten erfolgt aufgrund der gro&#223;en Menge verf&#252;gbarer Information h&#228;ufig 
algorithmisch gesteuert.
Insbesondere Medienintermedi&#228;re (dazu geh&#246;ren auch Sprachassistenten) setzen KI-basierte
Empfehlungssysteme ein, die die Inhalte, mit denen die Nutzerinnen und Nutzer interagieren, in einer hochgradig personalisierten
Art und Weise ausw&#228;hlen und verbreiten &#8211; die Rede ist dann von algorithmisch personalisierten
Nachrichtenkan&#228;len (APN).
Die Entscheidungen &#252;ber die Nachrichtenauswahl k&#246;nnen Vielfalt und Charakter des &#246;ffentlichen Diskurses
bestimmen und damit auch die politische Kommunikation. Im Zusammenhang mit APN hat das politische
Microtargeting gro&#223;e Aufmerksamkeit erfahren. Dabei handelt es sich um eine personalisierte Kommunikation, bei der
Informationen &#252;ber Personen gesammelt und dann im Rahmen eines Predictive-Analytics-Verfahrens dazu
verwendet werden, zielgruppenspezifisch politische Werbung zu zeigen. 
Die dringendste Aufgabe aus Sicht der Projektgruppe ist die interdisziplin&#228;re Erforschung der Ph&#228;nomene und
der Auswirkung sowohl von APN auf die politische Meinungsbildung als auch von politischem Microtargeting 
auf Wahlentscheidungen. Hier sieht die Projektgruppe insbesondere dominierende Intermedi&#228;re in der Pflicht, 
eine solche qualitative und quantitative Forschung &#252;ber die Bereitstellung von Schnittstellen zu erm&#246;glichen.
Ratsam ist zudem eine verpflichtende Begrenzung der pers&#246;nlichen Verhaltensdaten, die f&#252;r politisches
Microtargeting genutzt werden k&#246;nnen.
Als besonders heikel gilt die Verteilung politischer Inhalte, wenn Nutzerinnen und Nutzer aufgrund der
Personalisierung ihrer Empfehlungssysteme nur noch Meldungen aus ihrem jeweiligen politischen Milieu bekommen
&#8211; eine Filterblase oder auch Echokammer. Diese Begriffe bezeichnen das kontrovers diskutierte Ph&#228;nomen von
Menschengruppen, die sich auf Netzwerkplattformen austauschen und die so homogen sind, dass eine vertretene
Position von allen Seiten best&#228;tigt wird. Diese Ph&#228;nomene k&#246;nnen technisch das Resultat von Algorithmen sein, 
die jene Themen selektieren, mit denen Nutzerinnen und Nutzer sich schon vorher viel besch&#228;ftigt haben. Werden
doch einmal kontroverse Positionen ausgespielt, k&#246;nnte dies eher zu einer weiteren Spaltung als zur Erweiterung
des eigenen politischen Spektrums beitragen.
Die einseitige Wahrnehmung und Meinungsvermittlung bei politischen Themen werden in der Wissenschaft und
in den Medien kontrovers diskutiert. Da im deutschen und europ&#228;ischen Raum bislang nicht systematisch
analysiert wurde, ob und wie es zur Bildung von Filterblasen in sozialen Medien kommt und welche (Langzeit-)Effekte
dies auf die Meinungsbildung hat, sieht die Projektgruppe die weitere Forschung f&#252;r dringend geboten. Hier sind
ihrer Ansicht nach die gro&#223;en Informationsintermedi&#228;re hinsichtlich einer gr&#246;&#223;eren Transparenz ihrer
algorithmischen Empfehlungssysteme in die Verantwortung zu nehmen.
Social Bots sind manuell erstellte Agenten, die teilweise menschlich anmuten. Sie werden zuweilen mit dem Ziel 
programmiert, durch Kommentare auf sozialen Plattformen die politische Diskussion zu beeinflussen.
Die Projektgruppe geht der Frage nach, ob KI-gest&#252;tzte Social Bots nachgewiesen werden k&#246;nnen und, wenn ja,
welches Potenzial sie auf die politische Meinungsbildung oder gar auf Entscheidungen entfalten k&#246;nnen.
Die zur Beantwortung dieser Fragen eingeholten Stellungnahmen von Fachleuten aus der Wissenschaft, den
Sicherheitsbeh&#246;rden und der Zivilgesellschaft fallen ausgesprochen unterschiedlich aus. Aus technischer Sicht gilt
es heute als h&#246;chst unwahrscheinlich, dass ein Social Bot durch permanentes Posten automatisch generierter
Inhalte eine politische Diskussion beeinflussen kann &#8211; dem stehen allein die Kontextsensitivit&#228;t politischer
Debatten und eine dynamische Verwendung von Begrifflichkeiten entgegen.
Da die momentan zur Verf&#252;gung stehende Datenbasis nicht ausreicht, um die tats&#228;chliche Bedrohung durch
Social Bots nachzuweisen, erscheint der Projektgruppe eine Zusammenarbeit mit den Plattformbetreibern
notwendig. Auch vor diesem Hintergrund erscheint es erforderlich, dass die Intermedi&#228;re ihre Schnittstellen der 
wissenschaftlichen Forschung mehr als bisher zur Verf&#252;gung stellen.
Regulierung
Bei der Regulierung international operierender Informationsintermedi&#228;re greifen Gesetze und Verordnungen der
Europ&#228;ischen Union (EU), des Bundes und der L&#228;nder ineinander; au&#223;erdem nehmen die
Informationsintermedi&#228;re an Einrichtungen zur regulierten Selbstregulierung teil. Die Projektgruppe diskutiert zum einen, was der
Einsatz von Algorithmen innerhalb medienregelnder Verfahren zu leisten vermag; zum anderen geht es um
gesetzliche Bestrebungen zur Regulierung von Einsatz und Wirkung von KI-L&#246;sungen im Bereich des
Medienrechts, des Urheberrechts und der Medienpolitik. Auch Fragen des Datenschutzes und der Meinungsfreiheit sind
hier unmittelbar ber&#252;hrt. 
Der neue Medienstaatsvertrag, der den Rundfunkstaatsvertrag abl&#246;st, bezieht in die Medienregulierung erstmals
auch Intermedi&#228;re mit ein.
Im Entwurf des Medienstaatsvertrags1733 finden sich eindeutige Regelungen, die auf die zunehmende Bedeutung
digitaler Medien und die Rolle von KI bei der Distribution von Medieninhalten eingehen. Geregelt sind nun
insbesondere Transparenzpflichten f&#252;r Medienintermedi&#228;re wie Suchmaschinen oder soziale Netzwerke. Sie 
m&#252;ssen offenlegen, nach welchen Kriterien sie Inhalte selektieren und pr&#228;sentieren. Damit soll KI-basierte
Mediendistribution adressiert werden. Allerdings ist das Medienkonzentrationsrecht im Medienstaatsvertrag noch
nicht an die Ver&#228;nderungen der Medienm&#228;rkte angepasst worden.
Die Projektgruppe empfiehlt eine Modernisierung und St&#228;rkung der Landesmedienanstalten. Hier gilt es, &#252;ber
die fachliche Expertise in den Anstalten und die Zusammensetzung der Gremien nachzudenken. Die Erweiterung
des Anwendungsbereichs auf neue Angebotsformate verweist einmal mehr auf m&#246;gliche &#220;berlappungsbereiche
der Medienregulierung mit Regelungsaspekten, f&#252;r die gegebenenfalls eine Bundeskompetenz besteht
(Telekommunikation, Wirtschaft, Kartellrecht, &#246;ffentliche F&#252;rsorge, Strafrecht). Eine bessere Koordination und
Abstimmung zwischen Bund und L&#228;ndern auch zur Vermeidung von Doppelstrukturen erscheint n&#246;tig.
Die Projektgruppe diskutierte im Bereich Urheberrecht die Erkennung urheberrechtlich gesch&#252;tzter Werke
mittels KI-basierter Filter. Wie andere Filtertechniken betrifft dies vor allem Plattformen oder Video-Sharing-
1733 Zahlreiche L&#228;nderparlamente haben dem Entwurf des Medienstaatsvertrags inzwischen zugestimmt; er soll im Herbst 2020 in Kraft
treten.
Dienste, auf denen Inhalte hochgeladen werden k&#246;nnen, das Volumen aber eine manuelle Pr&#252;fung unm&#246;glich
macht. Im Kontext der Frage nach urheberrechtlich gesch&#252;tzten Werken ist das Thema deutlich in den Fokus
ger&#252;ckt. Besondere &#246;ffentliche Aufmerksamkeit gibt es hier im Zusammenhang mit der EU-
Urheberrechtsrichtlinie 2019/790, deren Artikel 17 Plattformen verpflichtet, Ma&#223;nahmen gegen das Hochladen urheberrechtlich
gesch&#252;tzter Werke zu ergreifen, f&#252;r die keine Nutzungserlaubnis besteht. 
Zu &#252;berpr&#252;fen, ob ein in digitaler Form vorliegendes Film- oder Tonwerk das Gleiche wie ein vorliegendes
Referenzwerk oder ein Ausschnitt davon ist &#8211; unabh&#228;ngig davon, ob es sich um die gleiche Datei handelt oder
oberfl&#228;chliche Modifikationen wie Spiegelung oder eine &#196;nderung durch Verrauschen vorgenommen wurden &#8211;, 
kann dabei als technisch weitgehend gel&#246;stes Problem angesehen werden. Es handelt sich um eine Aufgabe, f&#252;r
die heutige Methoden der Mustererkennung durch Maschinelles Lernen gut geeignet sind.
KI-basierte Uploadfilter1734 sind nach &#220;berzeugung der Projektgruppe zum gegenw&#228;rtigen Zeitpunkt allerdings
nicht geeignet, Urheberrechtsverletzungen im juristischen Sinne sicher festzustellen. Solange kontextuelle
Bez&#252;ge bzw. bestehende Lizenzierungen nicht eindeutig erkennbar sind oder kenntlich gemacht werden k&#246;nnen, ist
von einem routinierten Einsatz von KI-Uploadfiltern ohne menschliche Kontrolle und Evaluation dringend
abzuraten, um die Meinungs- und Informationsfreiheit im Internet auch k&#252;nftig zu bewahren.
Die Projektgruppe setzt sich bei Fragen der Moderation von Inhalten intensiv damit auseinander, inwieweit KI-
L&#246;sungen beim Umgang mit dem Ph&#228;nomen der sogenannten Hassrede helfen k&#246;nnen. Betreiber gro&#223;er sozialer
Netzwerke, Videoportale und Suchmaschinen haben sich Richtlinien gegeben, um mit Hassrede auf ihren
Plattformen umzugehen, doch diese werden oftmals nicht konsistent und mit der n&#246;tigen Transparenz angewandt.
Zus&#228;tzlich sind sie gem&#228;&#223; dem Gesetz zur Verbesserung der Rechtsdurchsetzung in sozialen Netzwerken dazu
verpflichtet, mutma&#223;lich rechtswidrige Inhalte innerhalb von 24 Stunden nach Eingang der Beschwerde zu
entfernen oder zu sperren. Bei der Vielzahl t&#228;glicher Diskussionsbeitr&#228;ge und Kommentare setzen die Intermedi&#228;re 
bei dieser Aufgabe auch auf den Einsatz von Algorithmen. 
Gegenw&#228;rtig sind automatische Filter zum Erkennen und Aussortieren von Hassrede nicht zuverl&#228;ssig einsetzbar,
gerade wenn Grenzf&#228;lle (Ironie, Anspielung, &#220;bertreibung, Spott, Parodie, Zitat, Soziolekt) betroffen sind, die
kontextuell beurteilt werden m&#252;ssen. Eine Vorfilterung ist bereits technisch machbar, die Trefferquote sollte nach 
und nach verbessert werden.
Die Projektgruppe weist auf Schw&#228;chen der KI-Systeme im Hinblick auf das Verstehen und Auswerten von
Zusammenh&#228;ngen hin, daher sollte die Forschung in diesem semantischen Bereich forciert werden. Bei einem
k&#252;nftigen Einsatz von Filtern ist darauf zu achten, dass im Effekt keinesfalls die Meinungsfreiheit beschnitten
wird, also einwandfreie Kommentare nicht indexiert oder gar automatisch blockiert werden. 
Es bleibt Folgendes festzuhalten: Die Transformation der Medien durch KI findet bereits in vielf&#228;ltiger Weise 
statt, von digitalen Assistenten, die journalistische Inhalte vermitteln und dadurch den klassischen Journalismus
in einigen Bereichen verdr&#228;ngen, &#252;ber Medienangebote, die mittels KI hochspezifisch individualisiert werden,
bis hin zu neuen Werkzeugen, die perspektivisch zur Erkennung von negativen Anwendungen wie Hassrede,
Deep Fakes oder Urheberrechtsverletzungen eingesetzt werden k&#246;nnen. Im Medienbereich bieten sich einerseits
durch die technologischen Entwicklungen neue M&#246;glichkeiten zu neuen Gesch&#228;ftsmodellen und Kooperationen,
andererseits beg&#252;nstigen diese auch das Entstehen gro&#223;er Einheiten. Denn wer selbst &#252;ber viele Daten verf&#252;gt
und weniger auf Daten Dritter angewiesen ist, profitiert im zunehmend KI-getriebenen Journalismus. Damit
verbunden sind Fragen nach der Sicherung der Vielfalt oder nach dem Datenschutz. Denn Medienkunden sollen
nicht nur den verbreiteten Inhalten trauen k&#246;nnen, sondern m&#252;ssen sich auch darauf verlassen k&#246;nnen, dass ihre
Daten nicht missbraucht werden. Die Medienpolitik sorgt daf&#252;r, die medialen Grundprinzipien zu sichern, die
entscheidend f&#252;r Demokratie und Meinungsfreiheit auch im KI-Zeitalter sind. In vielen Bereichen stellt die
Projektgruppe fest, dass noch hoher Forschungs- und Aufkl&#228;rungsbedarf besteht, um die Auswirkungen von KI-
Systemen auf die (politische) Meinungsbildung nachzuvollziehen. Hier ist eine st&#228;rkere Kooperation der Politik
und Wissenschaft insbesondere mit den gro&#223;en Intermedi&#228;ren und eine &#214;ffnung ihrer Daten- und
Informationsquellen anzustreben.
1734 Upload-Filter sind Software-Elemente, die hochzuladende Dateien inhaltlich &#252;berpr&#252;fen und unter bestimmten Umst&#228;nden
automatisiert das Hochladen verhindern.
Im Folgenden werden St&#228;rken und Schw&#228;chen, Chancen und Risiken von KI im medialen Bereich dargestellt. 
STRENGTHS (St&#228;rken) 
Starke demokratische Basis durch 
Presse- und Meinungsfreiheit auf 
Grundlage des Grundgesetzes (siehe 
auch Kapitel 4.3 [Ziele und Aufgaben 
von Medienpolitik]) 
Vielf&#228;ltiges Angebot von Anbietenden 
&#252;ber alle klassischen und modernen 
Medien (siehe auch Kapitel 4.3 [Ziele 
und Aufgaben von Medienpolitik]) 
Unabh&#228;ngiger Journalismus erm&#246;glicht
eine pluralistische &#214;ffentlichkeit (siehe 
auch Kapitel 4.3 [Ziele und Aufgaben 
von Medienpolitik]) 
Ausgeglichenes, duales Rundfunksystem 
von privatem und &#246;ffentlich-rechtlichem 
Rundfunk (siehe auch Kapitel 4.2.2 
[Qualit&#228;t und Ethik des Journalismus]) 
WEAKNESSES (Schw&#228;chen) 
Daten-, Urheber-, Medien- und 
Wettbewerbsrecht sind teils noch nicht 
an das moderne Medienzeitalter 
angepasst (siehe auch Kapitel 6.2 
[Nationale Regulierung]) 
Landesmedienanstalten sind noch nicht 
modernisiert (fehlende fachliche 
Expertise, veraltete Angebotsformate) 
(siehe auch Kapitel 7.2.1 [Medienrecht 
(Medienstaatsvertrag)]) 
Ausbauf&#228;hige Digitalkompetenz in allen 
Alters- und Bev&#246;lkerungsschichten. 
Technischer Sachverstand hinsichtlich 
KI-Anwendungen aufseiten des 
Gesetzgebers, der Bundes- und 
 
 
  
    
 
 
 
  
 
 
 
 
 
  
   
 
 
 
  
 
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
  
 
  
   
 
  
 
  
 
  
 
  
 
 
 
 
 
 
   
 
 
 
 
 
Anbieter aus Drittstaaten ziehen zumeist
&#246;konomischen Nutzen aus
Datensammlung, -speicherung und 
-verarbeitung, Durchsetzung der DSGVO
meist erschwert, KI-Anwendungen in
deutschen Medien sind oft von diesen 
Unternehmen abh&#228;ngig oder richten sich 
mindestens danach (siehe auch Kapitel 
5.4 [Datenzugang als Voraussetzung f&#252;r
Datenanalyse] und Kapitel 6.1
[Internationale Regulierung])
Einfache redaktionelle Texte (Wetter,
Staumeldungen, schnellere Recherche 
etc.) k&#246;nnen h&#228;ufiger und schneller
produziert werden, Nischenthemen wie
Randsportarten lassen sich automatisiert 
leichter erstellen und verbreiten (siehe 
auch Kapitel 3.1.1 [Exemplarische 
Betrachtung des Zusammenhangs
Medien und KI])
Deutschland kann individuellere 
Angebote f&#252;r Konsumentinnen und 
Konsumenten als USP und dadurch 
einen gr&#246;&#223;eren Meinungsmarkt (z. B. via
Medienavatar) generieren (siehe auch
Kapitel 3.1.1.2 [Moderation und 
Avatare])
Fehlender Zugang zu Daten f&#252;r
Forschungszwecke im Bereich KI und
Medien (siehe auch Kapitel 6.1
[Internationale Regulierung])
Erweiterung der M&#246;glichkeiten f&#252;r
Journalisten, die sozialen Medien als
Quelle auszuwerten (siehe auch
Kapitel 5.5 [Datenanalyse: KI als
Werkzeug f&#252;r den Journalismus])
KI-Anwendungen k&#246;nnen dazu genutzt
werden, sogenannte Fakes zu
identifizieren und automatisiert kenntlich
zu machen, gleichzeitig k&#246;nnten sie ein
hilfreiches Tool gegen Hassrede im
Internet sein (siehe auch Kapitel 7.4.2
[Hassrede])
Landesregierungen und Verwaltung noch
nicht ausreichend vorhanden (siehe auch
Kapitel 5.3.3 [Methoden zur Erkennung
von Deep Fakes])
Aktuell existierende Kompetenzen zur
Medienpr&#252;fung liegen verstreut &#252;ber
Fachabteilungen in der Forschung, bei
Redaktionsnetzen oder dem
Bundeskriminalamt (siehe auch Kapitel 
5.3.3 [Methoden zur Erkennung von 
Deep Fakes])
KI-Anwendungen k&#246;nnten analysieren,
ob sich Nutzende in Filterblase bewegen
und Empfehlungen danach anpassen 
(siehe auch Kapitel 6.2.3 [Milieubildung: 
Filterblasen und Echokammern])
Aufbau einer unabh&#228;ngigen Einrichtung
zur Unterst&#252;tzung der technischen 
Pr&#252;fung von Medieninhalten (siehe auch
Kapitel 5.3.3 [Methoden zur Erkennung
von Deep Fakes])
OPPORTUNITIES (Chancen)
        
 
 
 
   
  
  
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
  
 
 
 
 
 
 
 
  
   
    
   
     
     
 
 
  
 
 
             
 
    
 
           
   
 
   
  
     
  
  
  
  
  
  
                                               
   
 
     
2
Algorithmen k&#246;nnen zur &#220;berwachung
von algorithmischen
Empfehlungssystemen eingesetzt werden &#8211;
Governance by Algorithms (siehe auch
Kapitel 5.3.2 [Technische M&#246;glichkeiten
der Governance von KI-Systemen in der
Produktion und Verteilung von Medien 
durch Software (Governance by
algorithms)])
KI erm&#246;glicht neue Gesch&#228;ftsmodelle 
und neue Kooperationen zwischen 
klassischen Medienh&#228;usern und Tech-
Unternehmen
KI-Anwendungen k&#246;nnen dazu genutzt
werden, sogenannte Deep Fakes zu
identifizieren; weiterhin k&#246;nnen KI-
Anwendungen dabei unterst&#252;tzen,
unerw&#252;nschte oder widerrechtliche 
Inhalte zu identifizieren und f&#252;r eine
menschliche &#220;berpr&#252;fung vorzufiltern.
THREATS (Risiken)
Medienkonzentration bzw. zunehmende 
Marktmacht einzelner Intermedi&#228;re 
(siehe auch Kapitel 4.2.5 
[Marktwirtschaftliche Einordnung der
KI-Relevanz in den Medien]) 
Filterblasen und politisches
Microtargeting k&#246;nnen 
Radikalisierungstendenzen verst&#228;rken
und zu Missbrauch in der
Datenverarbeitung bis hin zu gezielten
Desinformationskampagnen f&#252;hren 
(siehe auch Kapitel 6.2 
[Personalisierung])
Overblocking von Inhalten durch nicht
ausgereifte automatisierte L&#246;sungen
k&#246;nnen die freie Meinungs&#228;u&#223;erung
gef&#228;hrden. Es besteht dar&#252;ber hinaus das
Risiko, die Rechtsdurchsetzung auf
Algorithmen bzw. privatwirtschaftliche
Unternehmen auszulagern (siehe auch
Kapitel 7.4 [Uploadfilter])
Vorbemerkungen
Am 14. Januar 2019 hat die Enquete-Kommission die Einrichtung von sechs Projektgruppen beschlossen, unter
anderem die Bildung einer Projektgruppe 6 &#8222;KI und Medien (Social Media, Meinungsbildung, Demokratie)&#8220;.1735 
Die Enquete-Kommission tr&#228;gt damit dem Antrag auf Einsetzung einer Enquete-Kommission &#8222;K&#252;nstliche
Intelligenz &#8211; Gesellschaftliche Verantwortung und wirtschaftliche, soziale und &#246;kologische Potenziale&#8220; vom
26. Juni 2018 Rechnung, nach dem unter anderem auch die &#8222;Auswirkungen der KI auf demokratische Prozesse&#8220;
untersucht werden sollen.1736 
Politische Meinungs- und Willensbildung findet heute zunehmend &#252;ber digitale Kommunikationsmedien statt, 
die wiederum einem KI-getriebenen Transformationsprozess ausgesetzt sind. Der Raum des &#246;ffentlichen
Gespr&#228;chs, unabdingbar f&#252;r eine pluralistische demokratische Gesellschaft, ver&#228;ndert sich unter dem wachsenden
Einfluss kommerziell orientierter Plattformen, die &#252;ber gewaltige Datenmengen verf&#252;gen und zugleich die
internationale Forschung zur KI dominieren. Die Arbeit der PG &#8222;KI und Medien&#8220; setzte sich daher konsequent mit
den horizontalen Themen der Demokratierelevanz von KI und dem generellen Vertrauen in Medien auseinander.
Vor dem Hintergrund der Einrichtung weiterer Projektgruppen wurden einige die Medien betreffende KI-Themen 
hier nicht im Detail betrachtet, da sie schwerpunktm&#228;&#223;ig in anderen Projektgruppen behandelt werden sollten.
Das betrifft insbesondere die m&#246;glichen Auswirkungen von KI auf die Besch&#228;ftigung (siehe die Projektgruppe
&#8222;KI und Arbeit&#8220;) und Fragen politischer Partizipation via KI (siehe die Projektgruppe &#8222;KI und Staat&#8220;). Weiterhin
wurden &#252;bergreifende Themen wie Daten, Ethik, Recht und Gesellschaft, die in allen Projektgruppen verhandelt
wurden, explizit auf der Ebene der Gesamt-Enquete besprochen und in einem Mantelbericht zusammengefasst.   
Um das sehr umfangreiche Thema &#8222;KI und Medien&#8220; im Rahmen verh&#228;ltnism&#228;&#223;ig weniger
Projektgruppensitzungen angemessen zu erschlie&#223;en, setzte die Projektgruppe den Fokus auf die folgenden drei Themenkomplexe, zu
welchen sowohl Abgeordnete und Sachverst&#228;ndige der Enquete-Kommission als auch ausgesuchte externe
Anh&#246;rpersonen in Vortr&#228;gen und anschlie&#223;enden Diskussionen mit der Projektgruppe Impulse lieferten. Dabei
wurden sowohl der jeweilige Status quo abgebildet als auch dynamische Perspektiven in den Blick genommen:
&#8226; Produktion und Management von Informationen
&#8226; Distribution, Sichtbarmachung und Auffindbarkeit von Nachrichten
&#8226; Regulierung (internationale Regulierungsbestrebungen, Informationsfreiheit, Medienrecht,
Wettbewerbsrecht und Urheberrecht)
1735 Beschluss &#252;ber die Arbeitsstruktur und die Einsetzung der Projektgruppen der Enquete-Kommission, Kommissionsdrucksache
19(27)17 vom 14. Januar 2019.
1736 Vgl. Bundestagsdrucksache 19/2978.
Die ersten beiden Sitzungen am 11. Oktober 2019 und am 4. November 2019 dienten einer Analyse des Status
quo. Im Rahmen dieser Sitzungen trugen die folgenden sachverst&#228;ndigen Mitglieder der Enquete-Kommission
zu Empfehlungssystemen und zur Sprachanalyse vor:
&#8226; Prof. Dr. J&#246;rg M&#252;ller-Lietzkow und Prof. Dr. Alexander Filipovi&#263; aus sozialwissenschaftlich-empirischer
Perspektive sowie 
&#8226; Prof. Dr. Katharina Zweig und Dr. Aljoscha Burchardt aus der Perspektive der Informatik und der
Computerlinguistik .
In der Sitzung am 9. Dezember 2019 wurden folgende Impulsvortr&#228;ge zum Themenkomplex &#8222;Produktion und
Management von Informationen&#8220; gehalten:
&#8226; Clemens Boisser&#233;e, Rheinische Post: KI und Medien &#8211; Anwendungen bei der Rheinischen Post
&#8226; Christian Daubner, Bayerischer Rundfunk: Wie setzt der Bayerische Rundfunk KI ein?
&#8226; Prof. Dr. Klaus Goldhammer, FU Berlin: KI und Medien
&#8226; Dr.-Ing. Christian Riess, Universit&#228;t Erlangen-N&#252;rnberg: Medienforensik im journalistischen Kontext
In der Sitzung am 16. Dezember 2019 wurden folgende Impulsvortr&#228;ge zum Themenkomplex &#8222;Distribution,
Sichtbarmachung und Auffindbarkeit von Nachrichten&#8220; gehalten:
&#8226; Prof. Dr. Christian St&#246;cker, HAW Hamburg: Automatisierte Sortierung von Medieninhalten
&#8226; Orestis Papakyriakopoulos, HfP M&#252;nchen: Die algorithmische Verzerrung der politischen Kommunikation 
auf sozialen Medien
&#8226; Dr. Tina Kl&#252;wer, sachverst&#228;ndiges Mitglied der Enquete-Kommission: Chatbots, Social-Media-Monitoring
und Sprachassistenten
&#8226; Jens Redmer, Google Inc.: Einsatz von Algorithmen bei der Google-Suche
&#8226; Dr. Aljoscha Burchardt, sachverst&#228;ndiges Mitglied: NLP-Forschungsperspektive auf Hate Speech
In der Sitzung am 10. Februar 2020 wurden folgende Impulsvortr&#228;ge zum Themenkomplex &#8222;Regulierung &#8211;
internationale Regulierungsbestrebungen, Informationsfreiheit, Medienrecht, Wettbewerbsrecht und
Urheberrecht&#8220; gehalten bzw. sollten gehalten werden:
&#8226; Dr. Anja Zimmer, mabb: Regulierung von Medienintermedi&#228;ren
&#8226; Lennart Wetzel, Microsoft Deutschland: KI-L&#246;sungen bei der Bilderkennung1737 
&#8226; Christian Mihr, Reporter ohne Grenzen: K&#252;nstliche Intelligenz und Informationsfreiheit
&#8226; Ben Scott, Luminate: KI und die Verbreitung von Desinformation im Wahlkampf1738
&#8226; Prof. Dr. Rupprecht Podszun, HHU D&#252;sseldorf: KI und Medien &#8211; Wettbewerbsrecht1739 
In der Sitzung am 2. M&#228;rz 2020 wurden folgende Impulsvortr&#228;ge zum Themenkomplex &#8222;Urheberrecht&#8220; gehalten:
&#8226; Prof. Dr. Jan Bernd Nordemann, LL.M., HU Berlin: KI und Urheberrecht, die nationale Perspektive
&#8226; Prof. Dr. Anne Lauber-R&#246;nsberg, TU Dresden: KI und Urheberrecht, die internationale Perspektive
Die Sitzungen am 13. Januar 2020 sowie am 9. und 23. M&#228;rz 2020 dienten der Erarbeitung und Redaktion des
Projektgruppenberichtes sowie der intensiven Diskussion &#252;ber die abzugebenden Handlungsempfehlungen.
Durch die Auswirkungen der Corona-Pandemie fanden die Sitzungen am 20. April, 11. Mai, 25. Mai und 
15. Juni 2020 als Videokonferenzen statt. 
1737 Die angefragten Unternehmen Facebook, Amazon, Twitter, Alibaba und Tencent haben die M&#246;glichkeit einer schriftlichen
Stellungnahme nicht wahrgenommen.
1738 Der Referent war kurzfristig verhindert; seine Thesen trug stellvertretend Dr. Stefan Heumann, sachverst&#228;ndiges Mitglied der
Enquete-Kommission, vor.
1739 Der Referent konnte wetterbedingt nicht zur Sitzung in Berlin anreisen, hat seinen Vortrag aber den Mitgliedern der Projektgruppe
elektronisch zug&#228;nglich gemacht.
        
 
 
  
  
  
  
  
   
 
  
  
    
   
    
 
    
   
  
   
  
 
     
   
 
    
   
 
    
    
 
   
    
  
 
 
 
  
    
 
 
 
     
  
 
 
 
   
3
Ausgehend von den Inputvortr&#228;gen und den kontroversen wie konstruktiven Diskussionen in der Projektgruppe
sowie paralleler Literaturrecherche verfassten Teams aus Autorinnen und Autoren einzelne Textabschnitte f&#252;r
den vorliegenden Projektgruppenbericht. Darauf aufbauend wurde dieser Bericht im Zuge einer intensiven
Feedback- und Konsolidierungsphase von der Projektgruppe redigiert, um einen m&#246;glichst breiten Konsens unter den 
Mitgliedern herzustellen. Ein nicht aufl&#246;sbarer Dissens in einzelnen Fragen ist im Text ausgewiesen. 
An der Projektgruppe und ihrem Bericht wirkten mit
f&#252;r die Fraktion der CDU/CSU:
&#8226; der Abgeordnete Hansj&#246;rg Durz
&#8226; die Abgeordnete Ronja Kemmer
&#8226; Prof. Dr. Alexander Filipovi&#263; als sachverst&#228;ndiges Mitglied
&#8226; Dr. Tina Kl&#252;wer als sachverst&#228;ndiges Mitglied
&#8226; Prof. Dr. J&#246;rg M&#252;ller-Lietzkow als sachverst&#228;ndiges Mitglied
f&#252;r die Fraktion der SPD:
&#8226; die Abgeordnete Saskia Esken (bis Januar 2020)
&#8226; die Abgeordnete Elvan Korkmaz-Emre (ab Januar 2020)
&#8226; Jan Kuhlen als sachverst&#228;ndiges Mitglied
&#8226; der Abgeordnete Falko Mohrs als stellvertretendes Mitglied (ab Juni 2020)
&#8226; Lena-Sophie M&#252;ller als sachverst&#228;ndiges Mitglied
f&#252;r die Fraktion der AfD:
&#8226; die Abgeordnete Joana Cotar als Vorsitzende der Projektgruppe
&#8226; der Abgeordnete Dr. Marc Jongen
f&#252;r die Fraktion der FDP:
&#8226; Dr. Aljoscha Burchardt als sachverst&#228;ndiges Mitglied
&#8226; der Abgeordnete Mario Brandenburg als stellvertretendes Mitglied
f&#252;r die Fraktion DIE LINKE.:
&#8226; die Abgeordnete Dr. Petra Sitte
&#8226; Prof. Dr. Katharina Zweig als sachverst&#228;ndiges und stellvertretendes Mitglied
f&#252;r die Fraktion B&#220;NDNIS 90/DIE GR&#220;NEN:
&#8226; die Abgeordnete Tabea R&#246;&#223;ner
&#8226; Dr. Stefan Heumann als sachverst&#228;ndiges und stellvertretendes Mitglied
Einf&#252;hrung 
Ein vielf&#228;ltiges Medienangebot ist f&#252;r eine freie, demokratische Meinungsbildung der B&#252;rgerinnen und B&#252;rger
von zentraler Bedeutung. Das vorliegende Kapitel hat vor allem Medien mit hoher Relevanz f&#252;r die politische
Meinungsbildung im Blick. Selbst mit dieser Schwerpunktsetzung besteht die Herausforderung, die vielf&#228;ltigen 
Nutzungsm&#246;glichkeiten von KI in den Medien zu erfassen und in Bezug auf ihre Implikationen f&#252;r die politische
Meinungsbildung hin zu untersuchen und zu bewerten. Der Berichtsteil erhebt keinen Anspruch darauf, dieses
Feld vollst&#228;ndig bearbeitet zu haben. Es wurden drei ma&#223;gebliche Themenfelder im Bereich KI und Medien
ausgemacht, die aus Sicht der Autoren besonders wichtig sind und dem Bericht Struktur verleihen sollen. 
Es wird im Bericht einerseits zwischen dem Einsatz von KI zur Produktion und Bearbeitung von medialen
Inhalten und Informationen und andererseits dem Einsatz von KI zur Distribution von medialen Inhalten und
Informationen unterschieden, insbesondere zum Empfehlen, f&#252;r das Ranking und zum Auffindbar-Machen. Bei der
Produktion geht es vor allem um KI-Anwendungen, die journalistische Arbeit unterst&#252;tzen, aber auch
gegebenenfalls automatisieren und ersetzen k&#246;nnen, und um damit verbundene Chancen und Risiken. Im Bereich der
Distribution stehen vor allem die gro&#223;en Internetplattformen im Mittelpunkt. Die digitale Transformation des
Mediensektors hat die Bedeutung von Internetsuche, sozialen Medien oder anderen Medienplattformen f&#252;r die
politische Meinungsbildung drastisch verst&#228;rkt. Auch dieses Kapitel besch&#228;ftigt sich mit den Chancen und
Risiken, die mit dem Einsatz von KI-Technologien bei der Distribution von medialen Inhalten und Informationen auf
den Internetintermedi&#228;ren verkn&#252;pft sind. Der dritte Themenschwerpunkt liegt auf bereits bestehender
Regulierung bez&#252;glich des Einsatzes von KI im Mediensektor. Neben vielen unterschiedlichen regulatorischen
Herausforderungen wird hierbei insbesondere deutlich, wie viele unterschiedliche Regulierungsfelder beim Thema KI
und Medien auf komplexe Weise miteinander verwoben sind.
Grundlagen und Sachstandskl&#228;rung
In den letzten Jahrzehnten haben die Digitalisierung insgesamt, das Internet und vor allem die Entwicklungen
rund um die KI die Medien grundlegend zu einer Transformation gezwungen. Waren noch in den 1970er- und 
1980er-Jahren die Medien klar voneinander abzugrenzen, h&#228;ufig auch noch datentr&#228;gerbasiert, und war die
Bedeutung von Digitaltechnologien sowohl f&#252;r die Produktion als auch den Konsum von Medien beschr&#228;nkt, haben
sp&#228;testens die digitalen Technologien und Speicherkapazit&#228;ten der 1990er-Jahre zu einem transformativen
Umdenken bei den Medien, sowohl der Produktion als auch der Distribution, gef&#252;hrt. Insbesondere die neu
gewonnenen Speichermedien bzw. Kapazit&#228;ten der fr&#252;hen 1990er-Jahre sowie das Aufkommen des Internets Mitte der
1990er-Jahre haben zu einer signifikanten Ver&#228;nderung gef&#252;hrt. Leitgedanke dieser Zeit war die Konvergenz,
prim&#228;r gepr&#228;gt durch die Endger&#228;te bzw. die Option, nun auch mediale Inhalte digital auf einem Endger&#228;t (dem
Computer, sp&#228;ter dem Smartphone oder Tablet) zu konsumieren. 
Diese Entwicklung der Multikonvergenz auf unterschiedlichsten Endger&#228;ten hat bis heute alle Medienarten und
-typen erreicht. Die immer st&#228;rkere Vernetzung inklusive des Aufkommens neuer medialer Plattformen bzw.
B&#252;ndelungsformen im Internet bedeutet dar&#252;ber hinaus vielmehr, dass noch mehr medialer Konsum gem&#228;&#223; dem
virtuellen Paradigma &#8222;anytime &#8211; anyplace &#8211; anyhow&#8220; m&#246;glich geworden ist und auch zus&#228;tzliche Formate,
insbesondere mit den sozialen Medien, aufgekommen sind. Damit einher geht allerdings h&#228;ufig die irrige Annahme,
dass die neuen Medien die alten vollst&#228;ndig verdr&#228;ngt h&#228;tten. Vielmehr haben sich zwar Marktanteile signifikant
verschoben und die Finanzierungs- und Produktionsmodelle der Medien haben sich ver&#228;ndert, aber die
Artenvielfalt hat darunter nicht gelitten. Anders sieht dies aus, betrachtet man die Frage der Medienqualit&#228;ten, von 
denen Stephan Ru&#223;-Mohl einmal behauptete, dass deren Bestimmung schwieriger sei, als einen Pudding an die
Wand zu nageln.1740 Auch dies entspricht nur der halben Wahrheit. Man kann heute zunehmend einen deutlichen
Ver&#228;nderungstrend in Richtung Entertainisierung der Medien beobachten. Die Rolle der sogenannten
(journalistischen) Qualit&#228;tsmedien hat unter den Entwicklungen zumindest &#246;konomisch signifikant gelitten, wohingegen
die Unterhaltungsmedienanbieter bzw. -distributoren durch geschickte Transformation der Gesch&#228;ftsmodelle am
Medienmarkt partizipieren konnten. Will man also eine wesentliche Ver&#228;nderung bei den Medien beobachten,
sind es nicht die Kerne, sondern die Distributionsformen, die &#246;konomisch profitablen Schwerpunkte und
Qualit&#228;ten, die sich ver&#228;ndert haben. 
Dennoch sind prinzipiell dadurch (noch) nicht die Kerne der Medien bzw. Medieninhalte und Medienarten
abhandengekommen. Die folgende Ordnungslogik soll im Rahmen dieses Berichts dazu beitragen, dass die
wesentlichen Medienarten bzw. Medienteilm&#228;rkte benannt werden und deren Bezug zur K&#252;nstlichen Intelligenz
hergestellt wird. Dabei wird zun&#228;chst von einer relativ trivialen Aufteilung in verschiedene Sektoren ausgegangen, die
im Kern aber teilweise starke &#220;berschneidungen aufweisen.
1740 Vgl. Ru&#223;-Mohl (1992): Am eigenen Schopfe &#8230; Qualit&#228;tssicherung im Journalismus &#8212; Grundfragen, Ans&#228;tze, N&#228;herungsversuche,
S. 85.
Abbi ldung 4 
Digitale Konvergenz der Medien
Print Audio Audiovisuell Digital
Zeitungen H&#246;rfunk Film Websites
Zeitschriften Musik Fernsehen Social Media
Buch Audiobooks DVD/Blu-Ray Spiele
Fachmedien Sonstige Streaming / IPTV Mobile Media
Werbemedien /
Marketing
Werbung / Marketing Werbung / Marketing Werbung / Marketing
Info- und Edutainment
Apps *
* Im weitesten Sinne geh&#246;ren auch andere Softwareapplikationen zu &#8222;Medien&#8220;, z. B. Foto- oder Musik-Apps, die der Produktion und
Modifikation dienen. Gerade bei Foto-Apps spielt KI zunehmend eine gro&#223;e Rolle. Dennoch wird solche Art von Software &#8211; selbst
wenn das Endprodukt ein mediales ist &#8211; eher selten in den Kreis der inhaltlich dominierten Medien verordnet und deshalb an dieser
Stelle auch nicht weiter als einzelne Applikation bzw. einzelnes Medium betrachtet. Im Kontext spielen diese allerdings auch hier als 
technische Werkzeuge eine Rolle.
Ausgehend von dieser Logik kann man feindifferenzieren. Die Feindifferenzierung kennt dabei viele Optionen.
Fr&#252;her wurde sehr h&#228;ufig z. B. nach der Frage der Datentr&#228;gerbindung unterschieden oder auch im Hinblick auf
Informations- und Unterhaltungsmedien. Die dichotomen Differenzierungsformen eignen sich aber nicht in
Zeiten, in denen die Multikonvergenz und Vernetzung sowie der kontinuierliche Abschied von der traditionellen 
Datentr&#228;gerbindung durch Digitalisierungsprozesse voranschreiten. Nun, in den sp&#228;ten 2010er- und zu Beginn
der 2020er-Jahre, gewinnt mit der K&#252;nstlichen Intelligenz eine weitere Schl&#252;sseltechnologie einen zunehmend 
gro&#223;en Einfluss auf die Medienm&#228;rkte, wenngleich einzelne Teilm&#228;rkte, insbesondere die Computer- und
Videospielindustrie sowie der ganze Bereich der sozialen Medien, schon vergleichsweise lange im Zusammenhang mit
KI genannt werden. 
Bei der Betrachtung des Verh&#228;ltnisses von Medien und K&#252;nstlicher Intelligenz erscheint daher eine Ordnung
anhand Medienarten hilfreich, selbst wenn dies immer noch recht grob nur die tats&#228;chlichen Medient&#228;tigkeiten
erfasst (z. B. findet Journalismus nicht nur in Printmedien oder nur in Fernsehmedien statt). Entscheidet man sich
aber dennoch f&#252;r die Differenzierung nach Medienarten, kann man die Kerne den Medienarten nach oben
stehender Ordnungslogik zuordnen.
3.1.1 Exemplarische Betrachtung des Zusammenhangs Medien und KI
Exemplarisch kann man einzelne T&#228;tigkeitsbereiche in den Medien identifizieren, bei denen besonders die
Auswirkungen der K&#252;nstlichen Intelligenz zu vermerken sind. Explizit ausgeschlossen werden bei dieser Betrachtung
zun&#228;chst alle Formen von Social Media, da diese im weiteren Berichtsverlauf noch mehrfach aufgegriffen
werden.
3.1.1.1 Journalismus
Der Journalismus ist ein sehr weites Feld, obschon es in der &#246;ffentlichen Wahrnehmung stark durch Print-
Journalistinnen und -Journalisten gepr&#228;gt ist. Nat&#252;rlich sind aber auch diejenigen, die f&#252;r audiovisuelle oder
Webmedien arbeiten, journalistisch t&#228;tig. Das deutsche Mediensystem ist dabei vor allem durch den &#246;ffentlich-
rechtlichen Rundfunk nicht rein privatwirtschaftlich organisiert. Wie zentral und wichtig die Demokratie- und
Informationsfunktionen des Journalismus in allen Feldern heute sind, muss an dieser Stelle nicht weiter ausgef&#252;hrt
werden. Dennoch soll zumindest der Verweis auf die Bedeutung des Journalismus im Kontext des investigativen 
Journalismus erw&#228;hnt werden, denn der unmittelbare Bezug zu dem weiter unten behandelten Thema Fake News
bzw. auch Filterblasen findet seinen Kontrastpunkt eben in dieser Form des Journalismus.
Wesentlicher erscheint es, in dem Zusammenhang zu erw&#228;hnen, dass es eine immer weiter aufgehende Schere
zwischen dem angebotenen journalistischen Portfolio und der Zahlungsbereitschaft der Menschen f&#252;r
journalistische Leistungen gibt. Nicht erst mit der Digitalisierung, wohl aber beg&#252;nstigt durch diese, hat erstens die
grunds&#228;tzliche Anzahl journalistischer Medien deutlich abgenommen, und zweitens sind vor allem im
Printbereich die Auflagenzahlen sowohl der Tagespresse als auch der Zeitschriften in nahezu allen Segmenten teilweise
dramatisch r&#252;ckl&#228;ufig. Die Hoffnung schon seit den 1990er-Jahren, sp&#228;testens 2000er-Jahren, dass der Trend
durch digitale journalistische Angebote, die auch entsprechend verg&#252;tet werden, kompensiert w&#252;rde, hat sich
nachdr&#252;cklich als nicht zutreffend herausgestellt. Die Folgen &#8211; nicht nur f&#252;r den Printjournalismus, sondern f&#252;r
das Feld insgesamt &#8211; sind gravierend. Nicht zuletzt bedeutet dies, dass der Kostendruck enorm zugenommen hat.
An dieser Stelle setzt nun die Frage der Nutzung von KI ein, die die journalistische Arbeit erheblich unterst&#252;tzen,
gleichzeitig aber auch zunehmend rationalisieren kann. 
3.1.1.2 Moderation und Avatare
Ankn&#252;pfend an den Journalismus werden auch zunehmend Moderationsformate in verschiedensten Facetten von
KI-Einfl&#252;ssen erfasst. An dieser Stelle sollen allerdings nicht umf&#228;nglich einzelne Technologien, z. B. bei der
Pr&#228;sentation der Inhalte, aufgegriffen werden, sondern es soll nur exemplarisch auf die kommende Generation 
virtueller Charaktere verwiesen werden, die ausschlie&#223;lich KI-basierte Moderationsleistungen erbringen k&#246;nnen. 
Was noch vor wenigen Jahren wie aus einem schlechten Science-Fiction-Film stammend klang, ist 2018 schon
in China Realit&#228;t geworden.1741 Der virtuelle Moderator kann theoretisch durchg&#228;ngig Nachrichten, die durch
eine KI im Hintergrund erzeugt wird, vermitteln. Sowohl die Pr&#228;sentation als auch die Nachrichtengenese sind
damit automatisiert. Auch wenn es noch relativ leichtf&#228;llt, den Avatar zu identifizieren, d&#252;rfte es nur eine Frage
weniger Jahre sein, bis genau diese Unterscheidung eben keine triviale mehr ist. Die damit einhergehenden
Fragen, die sich sowohl auf die Nachrichtenqualit&#228;t als auch auf die Seriosit&#228;t beziehen, sind ebenso relevant wie
auch die zu erwartenden &#246;konomischen Folgen einer solchen Transformation der medialen Moderation. Nat&#252;rlich
bedeutet dies heute noch nicht, dass in naher Zukunft menschliche Pr&#228;senz in medialen Inhalten keine Rolle mehr
spielen wird, aber die Entwicklung (Stichwort: Deep Fake) macht auch hier nicht halt.1742 KI-basierte
Avatartechnologien werden daher nicht nur in narrativen oder interaktiven Kontexten, z. B. Film, Serien oder Games,
sondern auch in informativen Medien zuk&#252;nftig zu radikalen Ver&#228;nderungen f&#252;hren. Politisch gesehen folgen
daraus Herausforderungen an die Absicherung nicht nur der Qualit&#228;t, sondern auch der Authentizit&#228;tssicherung,
insbesondere bei journalistischen Medien.  
3.1.1.3 Musikproduktion und -distribution
Schon vor einigen Jahren zeichnete sich ab, dass KI nicht nur im Bereich der Kunst1743, sondern auch im Bereich 
der Musik immer gr&#246;&#223;ere Bedeutung gewinnt.1744 Verfahren basierend auf Maschinellem Lernen erlauben es
heute, dass Melodien zumindest hinsichtlich Rhythmen und kompositorischer Anteile mittels Deep Learning
eigenst&#228;ndig generiert werden k&#246;nnen. Dabei k&#246;nnen &#8211; wie in der Kunst &#8211; ganze Stile bekannter Komponisten
kopiert und in Form neuer St&#252;ck produziert werden.1745 Insgesamt erweitert KI somit das Gesamtspektrum der
Kulturproduktion und k&#252;nstlerischen Ausdrucksformen. Dies geschieht keinesfalls nur ersetzend, sondern kann
auch erg&#228;nzend stattfinden.1746 Umgekehrt deuten musikalische Wettbewerbe zur KI-generierten Musik an, dass
vor allem Ko-Produktionen (Mensch-Maschine) eine Erweiterung des Kulturspektrums darstellen werden.1747 
Die Bewertung der N&#252;tzlichkeit derartig komponierter und interpretierter Musik f&#228;llt dabei unterschiedlich aus.
W&#228;hrend die einen gro&#223;e Sorgen um die Musik an sich haben1748, k&#246;nnen andere von derart generierter Musik 
gut profitieren, z. B. wenn damit St&#252;cke entstehen, die urheberrechtsfrei in anderen medialen Kontexten
verwendet werden k&#246;nnen. Dar&#252;ber hinaus gilt auch f&#252;r professionelle Musikerinnen und Musiker, dass die Nutzung
1741 Vgl. Kremp (2018): Dieser Nachrichtensprecher kommt aus dem Computer.
1742 Selbige oder artverwandte Technologien k&#246;nnen und werden nat&#252;rlich auch bei Chatbots (zum Begriff: Bendel (2018): Definition:
Was ist &#8222;Chatbot&#8220;?), die mit Avataren arbeiten, zunehmend eingesetzt.
1743 Vgl. &#193;lvarez (2020): Kreative KI &#8211; Wenn Computer Kunst schaffen.
1744 Vgl. K&#252;hl (2017): KI will rock you.
1745 Vgl. Bundesregierung (2020): KI spielt die Musik.
1746 Vgl. Bundesregierung (2020): KI spielt die Musik.
1747 Vgl. Deutschlandradio (2019): Das digitale Bandmitglied.
1748 Insbesondere die Frage der Qualit&#228;t derart generierter Musik wird infrage gestellt, vgl. Birkholz (2019): Warum es f&#252;r Musik mehr
braucht als K&#252;nstliche Intelligenz.
von KI bei der eigenen Arbeit unterst&#252;tzend eingesetzt werden kann. Mittelfristig sind bei steigender
Leistungsf&#228;higkeit der KI-Systeme auch St&#252;cke zu erwarten, die zumindest kommerziellen Erfolg erlauben und damit
Auswirkungen auf die Musikindustrie1749 an sich sowie auch abgeleitete Industriezweige (z. B. Werbejingles,
Film- und Fernsehmusik etc.) haben. 
Neben der Musikproduktion ist nat&#252;rlich im Zusammenhang mit der digitalen Musikdistribution auch das
Segment der Plattformen und Streaming-Services betroffen. Ein einfaches Beispiel f&#252;r den Einsatz von KI stellt hier
die Zusammenstellung von individualisierten, automatisch generierten Playlisten(-Vorschl&#228;gen) auf Basis der
Auswertung der H&#246;rgewohnheiten der vielen Millionen Nutzerinnen und Nutzer der Plattformen dar.1750
Umgekehrt kann KI heute schon anhand kurzer Ausschnitte Musikst&#252;cke vollst&#228;ndig erkennen und identifizieren.1751 
Andere Systeme gehen noch weiter und sollen auch ohne permanenten Netzzugang die Erkennung von
Musikst&#252;cken in offline gespeicherten Systemen erlauben.1752 Schlie&#223;lich kommt es auch h&#228;ufiger vor, dass weder ein
Sample noch eine Kenntnis der genauen Kennung von Musikst&#252;cken vorliegt. Hierbei hilft heute die
Spracherkennung von Sprachassistenzsystemen, die an Musikdatenbanken angebunden sind, auch anhand nur einzelner
bekannter Textfragmente Musikst&#252;cke zu identifizieren und abzuspielen. 
Zusammengefasst bedeuten sowohl die Optionen, mit und durch KI Musik zu komponieren und zu entwickeln,
als auch die Nutzung von KI in der Musikdistribution in unterschiedlichsten Formen einerseits neue
kommerzielle und k&#252;nstlerische Optionen; andererseits nimmt KI somit insgesamt erheblichen Einfluss auf die Nutzung
und den Konsum von Musik.
3.1.1.4 Film- und Serienproduktion 
Besonders naheliegend im Zusammenhang von Filmen und Serien sowie KI sind sicherlich die zahllosen
Produktionen, bei denen KI als Thema gew&#228;hlt wird. Auch wenn dies nat&#252;rlich nicht unmittelbar bedeutet, dass KI
in der Produktion eingesetzt wird, ist es doch (schon lange) ein erheblich wirksames Thema, welches einige der
gr&#246;&#223;ten Film-Franchise-Unternehmen beg&#252;nstigt1753 und zudem das Meinungsbild &#252;ber KI mit gepr&#228;gt hat.1754 
Wichtiger aber ist die Frage, welche Rolle KI im Rahmen der Produktion an sich spielen wird. Wie stark die KI
in die Filmproduktion eingreifen wird, ist heute noch nicht genau abzusehen. Klar d&#252;rfte sein, dass z. B. die
Integration verstorbener Schauspielerinnen und Schauspieler oder die Verj&#252;ngung von Akteuren &#252;ber
entsprechende Software heute schon in vielen F&#228;llen stattfindet.1755 Ebenso k&#246;nnen durch KI und andere digitale
Aufnahmeformate hochdynamische Umwelten, die dann in das Filmmaterial einf&#252;gt werden, entstehen, deren
Realismus deutlich &#252;ber bisherigen Ergebnissen liegt. Insgesamt sind es die Bereiche Virtual Reality (VR) und
Augmented Reality (AR), die hier stark als Treiber wirken.1756 Zunehmend wird auch im Bereich des Narrativen mit
KI-Technologien experimentiert, sprich, Drehb&#252;cher sollen von einer KI auf Basis entweder bestehender
literarischer Vorlagen entstehen oder es sollen g&#228;nzlich neue Geschichten durch KI generiert werden.1757 
Dass neue KI-Technologien &#252;brigens nicht nur Unterhaltungsprodukte betreffen, sondern auch der Sortierung1758 
oder der (neuen) Nutzung filmischen Archivmaterials dienen k&#246;nnen, zeigt ein Projekt des historischen
Filmmuseums Amsterdam: 
Die KI namens Jan Bot produziert im Eye Film Museum jeden Tag mehrere kleine Filme aus Archivmaterial.
Dabei handelt es sich um Open-Source-Tools zur Bilderkennung und Sprachenanalyse. Dies wird als
&#8222;automatisierter Surrealismus von Algorithmen&#8220; angesehen.1759 
1749 Vgl. Dredge (2017): AI and music: will we be slaves to the algorithm?
1750 Vgl. Scanu (2018): Musik und KI: Wie Streaming-Dienste die k&#252;nstliche Intelligenz nutzen.
1751 Vgl. Schuck (2018): Wie Shazam Songs erkennt.
1752 Vgl. Bauer (2018): Sound Search: Google verwendet seine KI-Song-Erkennung des Pixels 2.
1753 Vgl. Schreiner (2020): Filme &#252;ber K&#252;nstliche Intelligenz: Sieben Meilensteine der KI-Filmgeschichte; moviepilot.de: Die besten 
Filme &#8211; K&#252;nstliche Intelligenz; &#8288;Herget (2018): K&#252;nstliche Intelligenz im Kino: Die 10 spannendsten Filme mit KI.
1754 Vgl. Rei&#223;mann (2019): Warum wir oft ein falsches Bild von k&#252;nstlicher Intelligenz haben.
1755 Vgl. Schuler (2020): So macht KI Filme erfolgreich.
1756 Anzumerken ist, dass hierbei nicht nur KI-Technologien von besonderer Bedeutung sind, sondern vor allem auch die Rechen- und 
Speicherkapazit&#228;ten, vgl. Mainzer: Filmproduktion: Schritt f&#252;r Schritt in die Cloud.
1757 Vgl. Schmiechen (2016): Dieser Film ist von einer k&#252;nstlichen Intelligenz geschrieben worden.
1758 Vgl. Telekom Deutschland GmbH (2018): Beginn einer neuen Medien&#228;ra: Mehr M&#246;glichkeiten Dank Cloud Computing.
1759 Vgl. Lueken (2019): Kunstwerk ohne Rechte.
Viele der Ausf&#252;hrungen lassen sich auch heute auf Serienproduktionen &#252;bertragen. Da dort naturgem&#228;&#223; die
Produktionsbudgets h&#228;ufig deutlich geringer (pro Folge) ausfallen, bleibt zu erwarten, dass gerade vor dem
Hintergrund &#246;konomischer Produktionsoptimierung entsprechende Verfahren verst&#228;rkt eingesetzt werden. 
Differenzierter f&#228;llt n&#228;mlich die Nutzung von KI in der Filmproduktion an anderen Stellen aus. Geht man vom
hohen finanziellen Risiko der Filmproduktion aus, sind es gerade die gro&#223;en Studios bzw. Medienkonzerne, die
KI-Systeme einsetzen, um zunehmend &#252;ber Prognosemodelle den m&#246;glichen kommerziellen Erfolg zu sch&#228;tzen
und danach erstens &#252;berhaupt Produktionen freizugeben und zweitens die H&#246;he von Budgets festzulegen.1760 Die
gro&#223;e Hoffnung, insbesondere bei den gro&#223;en Studios, liegt also darin, dass ein jahrelang anderweitig &#252;ber
Datenmodelle erforschtes Ph&#228;nomen, n&#228;mlich die Prognostizierbarkeit eines m&#246;glichen Filmerfolges, nun durch
entsprechende KI-Algorithmen mit deutlich h&#246;herer Vorhersagekraft geleistet werden kann.1761 Sollten solche
Modelle greifen, wird es zumindest Fragen geben, ob nicht darunter mittelfristig die kulturellen Aspekte des
Films massiv leiden, denn schon heute dominieren unter rein wirtschaftlichen Aspekten regelm&#228;&#223;ig
Fortsetzungsreihen die Charts. In der Medienpolitik wird das More-of-the-same-Problem mangelnder Medienvielfalt daher
schon l&#228;nger diskutiert.
3.1.1.5 Digitale Spiele
Im Kontext KI und Medien stellen digitale Spiele eine Besonderheit dar. Anders als bei typisch eher passiv
rezipierten Medien bedeutet die Interaktion im digitalen Raum an sich schon einen anderen Medientypus. Sieht man 
nun, dass Spiele meistens in die Richtung entwickelt werden, dass Spielende sich z. B. gegen eine Maschine
durchsetzen, diese schlagen bzw. besiegen wollen, bedarf es entsprechenden Verhaltens. Waren es in den fr&#252;hen
Jahren der Industrie (1970er bis 1980er Jahre) vor allem vorgeschriebene Routinen, die man ausrechnen konnte, 
waren es in den 1990er Jahren die ersten KI-Engines, die adaptives Verhalten entfalten konnten, das hei&#223;t, die
das Spieleverhalten analysieren und das Verhalten der digitalen Charaktere anpassen konnten. Ebenso konnten
damit dynamisch-adaptive Umwelten geschaffen werden. Da dies sehr h&#228;ufig mit der visuellen Pr&#228;sentation der
Spiele einherging, waren und sind es vor allem Grafik-Engines, in die die KI-Engines eingebettet wurden und
werden. Heute ist die Nutzung von KI in Spielen Standard1762 und nahezu jedes Spiel nutzt daf&#252;r bestehende
Game-Engines oder es werden auch neue entwickelt. 
Dabei ist das Thema an sich teilweise umstritten, obschon gerade Spiele wie Starcraft II dazu gef&#252;hrt haben, dass
sich die KI-Forschung in den letzten Jahren intensiv damit auseinandergesetzt hat.1763 Dies hat mehrere Gr&#252;nde:
Erstens gilt es in der Szene als umstritten, welche Auswirkungen z. B. der Einsatz von KI-Systemen f&#252;r
nichtspielbare Charaktere h&#228;tte, die dadurch dennoch Einfluss auf den Spielverlauf nehmen. Dann ist meist nicht mehr
durch die Entwicklerinnen und Entwickler sicherzustellen, dass das Spiel fehlerfrei abl&#228;uft, d. h., dass der Sinn
und die Funktionalit&#228;t erhalten bleiben.1764 
Ein weiteres bekanntes Thema ist, dass in der Szene h&#228;ufig zwar die Eigenschaften der KI debattiert werden, es
vielfach aber Ziel und Sinn ist, dass die Spielenden ein erreichbares Spielerlebnis haben, also sich die KI
entsprechend zur&#252;cknimmt. Somit wird im Zweifel eben nicht das volle m&#246;gliche Lernpotenzial ausgesch&#246;pft.1765 
Ein drittes Ph&#228;nomen ist, dass die verwendete KI-Engine zu stark werden kann. Dann stellen sich bei Spielenden
h&#228;ufig schnell Frusterlebnisse ein und die KI verfehlt ihren Zweck.1766 
Neben dem Haupteinsatzfeld, n&#228;mlich der Gestaltung von Gegnerverhalten, wird KI in Spielen aber auch zur
Gestaltung dynamischer Umwelten eingesetzt, die ein reales Szenario adaptiert an das Spielerverhalten
simulieren, z. B. Jubeln in der Sportsimulation bei gegl&#252;ckten Aktionen, Pfeifkonzerte bei Fouls etc. Ganz besonders
1760 Vgl. Rotter (2020): Warner Bros.: KI entscheidet, welche Filme produziert werden sollten; Siegel (2020): Warner Bros. Signs Deal
for AI-Driven Film Management System (Exclusive); hr info (2020): K&#252;nstliche Intelligenz in Hollywood &#8211; Wie man Filme auf
Erfolg programmiert.
1761 Vgl. Moorstedt (2019): Algorithmen f&#252;r die Filmbranche &#8211; Chris Hemsworth + Scarlett Johansson + Action = $$$; &#228;hnliche Modelle
werden dar&#252;ber hinaus auch zunehmend in den Bereichen Musik und Literatur eingesetzt.
1762 Vgl. Mathur (2018): Best game engines for Artificial Intelligence game development.
1763 Vgl. Krempl (2019): Starcraft 2: Verbesserte DeepMind-KI schl&#228;gt 99,8 % der menschlichen Spieler; Podbregar (2019): KI meistert
&#8222;StarCraft II&#8220;. Angemerkt werden muss, dass das Ziel des eingesetzten KI-Systems DeepMind aber eben auch nicht die Verbesserung
des Spiels betrifft, sondern dass ausschlie&#223;lich eine KI entwickelt wurde, die trainiert mit Spieldaten in der Lage ist, die weltbesten
menschlichen Spielerinnen und Spieler zu schlagen.
1764 Vgl. Heck (2019): Wenn eine KI die wichtigen Charaktere im Computerspiel umbringt; B&#252;ttner (2018): KI in Computerspielen und
was sie uns &#252;ber KI in der Gesch&#228;ftswelt lehren kann.
1765 Vgl. Bojarin (2014): K&#252;nstliche Intelligenz in Spielen &#8211; Die KI ist so intelligent wie ihre Entwickler.
1766 Vgl. Scheuch (2018): Zocken auf schmalem Grat &#8211; Wie KI die Games-Branche erobert.
wirken solche Systeme, wenn es sich um sogenannte Open-World-Games handelt, bei denen besonders viele
Freiheitsgrade f&#252;r die handelnden Spielenden bestehen.1767 
Eine weitere Eigenschaft nutzen die Anbieter von Spielen zunehmend aus. Mit KI lassen sich auch bereits f&#252;r
&#228;ltere Systeme bestehende Spiele grafisch f&#252;r nachfolgende Systeme hochskalieren und optisch ver&#228;ndern. Das
klingt zun&#228;chst wenig innovativ, bedenkt man aber, dass h&#228;ufig gerade bei Spielkonsolen Technologiezyklen 
&#252;ber viele Jahre dauern (also zwischen zwei Konsolengenerationen f&#252;nf bis sieben Jahre liegen), Spieleserien
sich aber hoher Beliebtheit erfreuen, lohnte es sich lange nicht, daf&#252;r Entwicklerkapazit&#228;t in Form gr&#246;&#223;erer
Teams zu investieren, die dann die Spiele auf den neusten technischen Stand brachten. Nun aber &#252;bernimmt die
Hauptlast eine KI-Technologie1768, sodass sich die Entwicklerinnen und Entwickler auf einen Feinschliff und
ggf. notwendige Anpassungen beschr&#228;nken k&#246;nnen. Die Folge ist, dass auch alte Spiele profitabel auf neuen
Systemen angeboten werden k&#246;nnen. 
Ohne alle m&#246;glichen Einsatzfelder von KI in Spielen auff&#252;hren zu wollen, zeigt schon dieser &#220;berblick, dass KI
nicht nur in den Spielen zum Einsatz kommt, sondern ihr auch im Rahmen der Produktion von Computer- und
Videospielen eine zunehmend wichtige, nicht nur kostensparende Rolle zukommt. 
3.1.2 Neue Akteure: Social Media und Informationsintermedi&#228;re
Die zuvor beschriebenen Wandlungsprozesse f&#252;hren auch zu neuen Akteuren im Feld der medienvermittelten 
&#246;ffentlichen Kommunikation. Sogenannte Informationsintermedi&#228;re1769, etwa Social-Media-Plattformen,
erzeugen Aufmerksamkeit f&#252;r Inhalte und pr&#228;gen den Zugang zu Wissen, Austausch und Kommunikation. Der
Ausdruck &#8222;Social Media&#8220; betont vor allem soziale Online-Praktiken wie das Liken und Folgen. In dem Bericht geht
es aber vor allem um eine Betrachtung von Informationen und (politischer) Meinungsbildung im Hinblick auf
die Rolle von KI-Systemen, sodass diese sozialen Praktiken im engeren Sinne hier nicht weiter vertieft werden,
obwohl sie mit Wissens-, Meinungs- und Informationsfunktionen verkn&#252;pft sind.
Gattungen von solchen Informationsintermedi&#228;ren sind vor allem Suchmaschinen, Netzwerkplattformen,
Multimediaplattformen und Instant-Messaging-Dienste.1770 Solche &#8222;Intermedi&#228;re vermitteln zwischen Menschen und
[&#8230;] vorfindbaren Informationen und Inhalten aller Art&#8220;1771. Sie arbeiten dabei mit sogenannten
Empfehlungsalgorithmen, die wesentlich von KI-Technologien profitieren. Die Dienste nennen sich selbst &#8222;Plattformen&#8220; und 
bieten in der Regel keine eigenen Inhalte an, sodass sie bisher auch regulatorisch nicht als Medien etwa im
presserechtlichen Sinne gelten.1772 Wie stark der Einfluss dieser Plattformen auf Wissensfl&#252;sse und Meinungsbildung
ist, ist nur schwer zu greifen. Das erfolgreiche Gesch&#228;ftsmodell ist die personalisierte Ausspielung von Werbung
basierend auf pers&#246;nlichen Verhaltensdaten, bei gleichzeitigem Nutzen f&#252;r die Kundinnen und Kunden, die die
Dienstleistungen (oft unbewusst) mit ihren Nutzungsdaten &#8222;bezahlen&#8220;.
Hier teilen sich Facebook und Google mittlerweile &#252;ber 80 Prozent des Online-Werbemarkts &#8211; bei Facebook 
durch Werbung auf der Plattform &#8211; Google hingegen stark auch als Auktionsplattform zum Ausspielen von
Werbung auf Webseiten Dritter. Das Gesch&#228;ftsmodell beruht auf der Erfassung, Speicherung und Auswertung des
Nutzerverhaltens auf den Plattformen und im Internet insgesamt. Die politischen und sozialen Folgen dieser
Informationsintermedi&#228;re &#8211; man spricht auch von &#8222;Plattformisierung&#8220; der medial vermittelten &#246;ffentlichen
Kommunikation &#8211; bilden den Hauptgegenstand dieses Berichtsteils, insofern KI-Technologie ein wichtiger
technischer Baustein f&#252;r die Informationsintermedi&#228;re ist.
1767 Dabei k&#246;nnen ganze Spielwelten durch die KI heute schon generiert werden, vgl. F&#246;rtsch (2018): Diese Videospiel-Stadt wurde von
einer K&#252;nstlichen Intelligenz erschaffen. In absehbarer Zeit geht man davon aus, dass somit vor allem Game- und Leveldesignerinnen
und -designer neue, m&#228;chtige Werkzeuge erhalten, die es erlauben, wesentlich komplexere Spielwelten in deutlich k&#252;rzerer Zeit zu
entwickeln.
1768 Vgl. Der Standard (2019): K&#252;nstliche Intelligenz l&#228;sst alte Videospiele fast wie neu aussehen.
1769 Vgl. Die Wissenschaftlichen Dienste des Deutschen Bundestags (2018): Regulierung von Intermedi&#228;ren, S. 5. Dort wird ausgef&#252;hrt:
&#8222;Intermedi&#228;r bedeutet &#8222;dazwischenliegend&#8220;. Davon ausgehend werden unter dem Begriff &#8222;Intermedi&#228;re&#8220; (Online-)Dienste
bezeichnet, die eine Vermittlungsfunktion zwischen digitalen Inhalten und Nutzer wahrnehmen. Sie bieten dabei in der Regel keine eigenen 
Inhalte an, sondern lenken die Aufmerksamkeit durch Aggregation, Selektion und Pr&#228;sentation auf von Dritten erstellte (und
gegebenenfalls eigene) Inhalte.&#8220;
1770 Vgl. Schmidt et al. (2017): Zur Relevanz von Online-Intermedi&#228;ren f&#252;r die Meinungsbildung, S. 14.
1771 Schmidt et al. (2017): Zur Relevanz von Online-Intermedi&#228;ren f&#252;r die Meinungsbildung, S. 20.
1772 Im Entwurf f&#252;r den neuen Medienstaatsvertrag (Fassung vom 5. Dezember 2019) werden &#8222;Telemedien&#8220; nunmehr beschrieben als
rundfunk&#228;hnliche Telemedien, Medienplattformen und Benutzeroberfl&#228;chen sowie Medienintermedi&#228;re.
Diese politisch-soziale Perspektive sieht in der Demokratie den normativen Pr&#252;fstein f&#252;r die Beurteilung von KI-
Technologien im Bereich der Medien und den daraus abgeleiteten Handlungsempfehlungen. Demokratie ist die
politische Form gesellschaftlicher Selbstbestimmung.
Die Menschen in einer Demokratie sind f&#252;r den Gebrauch ihrer Autonomie angewiesen auf (authentische)
Informationen (Meinungsbildung), die unter anderem durch private und &#246;ffentlich-rechtliche Medien zur Verf&#252;gung
gestellt werden. In der &#214;ffentlichkeit, die in dieser Weise durch Medien hergestellt wird, werden Informationen 
ausgetauscht und Meinungen kundgegeben. So sollen die B&#252;rgerinnen und B&#252;rger sich ihre Meinungen frei
bilden k&#246;nnen.
Einf&#252;hrung in die technischen Grundlagen
3.2.1 Sprachverarbeitung
Im Bereich Medien spielen bereits heute verschiedene Formen der Sprachverarbeitung eine Rolle, die so g&#228;ngig
sind, dass sie kaum noch als solche sichtbar sind, wie etwa die Websuche oder die maschinelle &#220;bersetzung bei
der Recherche. Im Laufe dieses Berichtes werden verschiedene Sprachtechnologien besprochen, wie Filter zum
Erkennen von Hassrede. In diesem Kapitel werden zun&#228;chst kurz die Grundlagen von Sprachtechnologie skizziert
und als eine hier besonders relevante Anwendung werden dann Sprachassistenzsysteme eingef&#252;hrt.
Grundlagen
Sprache ist ein Schl&#252;ssel sowohl zu Wissen als auch zu Kommunikation. Die maschinelle Erfassung von Texten
und Sprache, die Verarbeitung und Extraktion von relevanten Informationen oder die maschinelle &#220;bersetzung
machen Sprachverarbeitung zu einem Kernthema der KI. Sprachtechnologie ist die anwendungsnahe Schwester
des Forschungsgebiets Computerlinguistik und wird gelegentlich auch als Natural Language Processing (NLP)
bezeichnet. Im vorliegenden Bericht spielen eine ganze Reihe verschiedener Sprachtechnologien eine Rolle, z. B.
Dialogsysteme (Chatbots) oder Systeme, die Beleidigungen aufsp&#252;ren. 
Aus Computersicht ist Sprache, z. B. in Form eines Textes, zun&#228;chst einmal unstrukturierte Information, letztlich 
besteht sie aus &#8222;Nullen und Einsen&#8221;. Es ist die Aufgabe der Sprachtechnologie, den Computern das f&#252;r eine
bestimmte Aufgabe ben&#246;tigte menschliche Wissen &#252;ber die Sprache selbst (z. B.: Es gibt Wortarten wie
Adjektive, die sich &#228;hnlich verhalten) oder &#252;ber die Welt (z. B.: Alles f&#228;llt nach unten, &#8222;Idiot&#8221; ist eine Beleidigung etc.)
zug&#228;nglich zu machen. Auf der technischen Seite gibt es im Wesentlichen drei Ans&#228;tze:
Symbolische Wissensverarbeitung ist eine traditionelle Methode der NLP, in der notwendiges Wissen explizit in 
strukturierter Form, z. B. in Grammatik-Regeln oder Wenn-dann-Regeln, repr&#228;sentiert wird. Diese Regelwerke
werden von menschlichen Entwicklerinnen und Entwicklern definiert und implementiert. Symbolische Systeme
sind gut kontrollierbar und transparent, allerdings ist die Skalierbarkeit h&#228;ufig zu gering, da alles Wissen in der
Entwicklung &#8222;vorausgedacht&#8220; werden muss. Situationen, die nicht vorab bedacht und implementiert wurden,
stehen dem System zur Laufzeit nicht zur Verf&#252;gung und k&#246;nnen nicht bearbeitet werden.
Klassisches Maschinelles Lernen (ML) abstrahiert von dieser expliziten Modellierung und &#252;bertr&#228;gt die
Aufgaben in den Bereich der Statistik, indem z. B. Texte als &#8222;Bag of Words&#8220; betrachtet werden und man &#252;ber
statistische H&#228;ufigkeiten und Indizes die &#196;hnlichkeit von Texten ermittelt oder f&#252;r Suchbegriffe passende
Antwortdokumente ermittelt. ML-Systeme werden anhand von Datenbeispielen trainiert. Um beispielsweise zu entscheiden,
ob ein Text eine Beleidigung enth&#228;lt oder nicht, wird das System mit vielen verschiedenen Texten &#8222;gef&#252;ttert&#8220;, 
jeweils immer mit der Zusatzinformation, ob der Text eine Beleidigung enth&#228;lt oder nicht (&#8222;Labels&#8220;). Au&#223;erdem
werden die Eigenschaften (&#8222;Features&#8220;) von Texten, auf die das System w&#228;hrend des Trainings achten soll, vorab 
definiert, z. B. die L&#228;nge des Textes oder das Auftreten von vielen Ausrufezeichen. Durch die vielen
Beispieltexte w&#228;hrend des Trainings lernt das System dann, was typische Merkmale von beleidigenden Texten sind, und
es kann zur Laufzeit auch Situationen verarbeiten, die zur Entwicklungszeit unbekannt waren, indem es misst,
wie &#228;hnlich die Eigenschaften des aktuellen Textes den Eigenschaften der Trainingstexte sind. Die ersten
Suchmaschinen verwendeten diese Technologie und auch heute noch sind statistische Klassifizierer h&#228;ufig verwendete
Technologien. Vorteile dieser klassischen Technologien sind, dass sie relativ transparent sind und h&#228;ufig mit 
weniger Trainingsdaten funktionieren als neuronale Netze (s. u.). Ein Nachteil ist aber auch hier die
Skalierbarkeit. Beispielsweise werden alternative Formulierungen (Arzt &#8211; Doktor), die in den Trainingsdaten nicht
enthalten waren, nicht automatisch aus dem Kontext erkannt. Diese m&#252;ssen eigens modelliert werden, zum Beispiel
durch Synonym-Lexika. Problematisch ist insbesondere auch, dass die KI Subtext (z. B. Ironie) nicht erkennt;
auch erkennt sie beleidigende Inhalte nicht, wenn die Worte geschickt gew&#228;hlt werden. Den Subtext oder die
Beleidigung kann dann nur der Mensch erkennen.1773 
Neuronale Netze zeigen in der Sprachtechnologie wie in vielen anderen Gebieten der KI die beste Performanz,
Flexibilit&#228;t und Skalierbarkeit. Bei diesem Ansatz werden typischerweise &#8222;Word Embeddings&#8220; verwendet, bei
denen W&#246;rter als &#8222;Wortwolken&#8220; ihrer umgebenden W&#246;rter repr&#228;sentiert werden. Auch neuronale Netze werden
mit Daten trainiert. Der Vorteil ist aber, dass diese Daten nicht zwingend mit Labels ausgestattet werden m&#252;ssen,
wie es noch bei den klassischen statistischen Verfahren der Fall war, und dass die Eigenschaften vorab nicht von 
Menschen definiert werden. Das System eignet sich die relevanten Merkmale (Features) selbst an. Ein
&#220;bersetzungssystem wird z. B. mit von Menschen &#252;bersetzten Texten satzweise trainiert, immer ein Satz in der
Ausgangs- und ein Satz in der Zielsprache ohne weitere Vorverarbeitung. Daf&#252;r sind gro&#223;e Datenmengen notwendig, 
aber die Muster in den Daten k&#246;nnen gut ausgenutzt werden. Es ist nur eingeschr&#228;nkt m&#246;glich, solche Systeme
im Nachhinein zu kontrollieren und ihre Funktionsweise nachzuvollziehen. Hierzu gibt es umfangreiche Literatur
unter dem Stichwort &#8222;Explainable AI&#8220;.
Je nach Datenlage, vorhandenen Wissensquellen, Formalisierbarkeit der Aufgabe, Einsatzm&#246;glichkeiten von
&#8222;Human-in-the-Loop&#8220;1774, Anforderungen an Kontrolle und Transparenz muss aus den vielen NLP-Technologien
die passende gefunden werden. Zwei zentrale Parameter sind hierbei Precision und Recall. Beispielsweise bei
einem System zum Auffinden von Beleidigungen in einer Plattform w&#252;rde die Precision angeben, wie viele der
vom System gemeldeten Beleidigungen wirklich Beleidigungen sind, w&#228;hrend der Recall angeben w&#252;rde, wie
viele der in der Plattform vorhandenen Beleidigungen gefunden werden.   
Sprachassistenzsysteme
Sprachassistenzsysteme b&#252;ndeln als Anwendungsfall viele typische Aufgaben der Sprachverarbeitung. Im
Bereich der Medien kommt ihnen vor allem bei der Vermittlung von Inhalten beispielsweise Smart Speaker eine
besondere Bedeutung zu.
Sprachassistenzsysteme sind sprachf&#228;hige Software-Systeme, die in verschiedenen Ger&#228;ten auf dem Markt
verf&#252;gbar sind. Sprachassistenzsysteme sind sprachf&#228;hige Software-Systeme, die in verschiedene Ger&#228;te eingebaut
auf dem Markt verf&#252;gbar sind. Sie sind sprachbasierte Schnittstellen zu Ger&#228;ten, also eine Erscheinungsform der
Mensch-Maschine-Interaktion und bieten den Benutzerinnen und Benutzern eine komfortable
Benutzerschnittstelle, die auf dem menschlichen Kommunikationskanal Sprache basiert. Das Ziel ist es, die Benutzung eines 
Ger&#228;tes so einfach und niedrigschwellig wie m&#246;glich zu gestalten. Im Bereich der Barrierefreiheit k&#246;nnen
Sprachassistenzsysteme daher beispielsweise f&#252;r Blinde und Sehbehinderte eine wichtige Schnittstelle zu
Funktionen wie Kalendern etc. bieten.
Die bekanntesten Sprachassistenzsysteme sind sicherlich die Sprachassistenten der gro&#223;en amerikanischen
Anbieter wie Apples &#8222;Siri&#8220;, Amazons &#8222;Alexa&#8220;, Googles &#8222;Google Assistant&#8220; sowie Microsofts &#8222;Cortana&#8220;. Diese 
Assistenten sind in etliche Smartphones und Anwendungen integriert, aber auch in die Smart Speaker der
Anbieter eingebunden: Apples &#8222;HomePod&#8220; basiert auf Siri, Amazons &#8222;Echo&#8220; nutzt Alexa und Googles &#8222;Home&#8220; den 
Google Assistant.
Sprachassistenzsysteme stecken aber auch in vielen anderen Ger&#228;ten, beispielsweise im Bereich Smart Home 
(K&#252;hlschr&#228;nke, Thermostate usw.) oder auch in Autos. Bereits seit den 1980er Jahren forscht die
Automobilbranche an Sprachassistenten und entwickelt diese, damit Fahrerinnen und Fahrer die Elektronik des Wagens w&#228;hrend
der Fahrt nicht selbst von Hand bedienen m&#252;ssen.1775 
Es ist grunds&#228;tzlich zu beobachten, dass Hersteller von Ger&#228;ten (Autos eingeschlossen) die teure und aufwendige
Eigenentwicklung eines Sprachassistenzsystems scheuen und stattdessen auf eines der Angebot der gro&#223;en
Anbieter zur&#252;ckgreifen.  
Technisch steckt in Sprachassistenzsystemen eine gro&#223;e Vielzahl verschiedener Ans&#228;tze. Grunds&#228;tzlich aber
steckt hinter einem Sprachassistenzsystem ein Dialogsystem, das mindestens aus drei Modulen besteht: einer
1773 Vgl. Matsakis (2018): To Break a Hate-Speech Detection Algorithm, Try 'Love'.
1774 Mit &#8222;Human-in-the-Loop&#8221; ist die Frage gemeint, ob ein menschlicher Entscheider die Ergebnisse des KI-Systems noch einmal
beurteilt, also ob beispielsweise eine maschinelle &#220;bersetzung noch einmal auf Fehler &#252;berpr&#252;ft wird oder ob das Ergebnis direkt an die
Leser geht.
1775 So beispielsweise das deutsche Unternehmen semvox. Der Markt konsolidiert sich aber auch hier mehr und mehr zugunsten der
gro&#223;en Anbieter. So nutzt beispielsweise Audi Amazon f&#252;r die Sprachassistenzfunktion in seiner E-tron-Reihe. Mercedes hingehen
bietet mit seinem System MBUX eine eigene sprachgesteuerte Bordelektronik.
Komponente, die eingehende Sprache &#8222;versteht&#8220; (Analyse), einer Komponente, die eine Handlung ausf&#252;hren
kann (Business-Logik), und einer Komponente, die eine Antwort geben kann (Generierung). So verf&#252;gt
beispielsweise ein simples Ger&#228;t wie ein Thermostat &#252;ber ein Analysemodul, das nur eine limitierte Kommando-Sprache 
verarbeiten kann und das technisch &#252;ber eine Stichwort-Analyse oder die Beherrschung einer einfachen
Grammatik nicht hinausgeht. Falls das Ger&#228;t gar keine Antwort gibt, entf&#228;llt das Generierungsmodul komplett. Auf
der anderen Seite stehen die virtuellen Assistenten der Smartphones und Smart-Home-Devices, die &#252;ber
ausgepr&#228;gte Analysef&#228;higkeiten und Generierungsmodule verf&#252;gen. Diese Assistenten nutzen Methoden der
K&#252;nstlichen Intelligenz, vor allem Maschinelles Lernen bzw. Deep Learning, f&#252;r die Analyse und Generierung von
Sprache. Je komplexer und umfangreicher der Anwendungsbereich der Sprachassistenten wird, desto besser
m&#252;ssen die einzelnen Sprachkomponenten funktionieren. Sowohl Amazon als auch Google und Microsoft bieten 
externen Anbietern die M&#246;glichkeit, auf der Plattform ihres Assistenten eigene kleine Anwendungen (Apps,
Skills) bereitzustellen. Dadurch wird der Leistungsumfang der Assistenten sehr gro&#223;. Bereits im September 2018 
waren laut Aussage von Daniel Rausch, dem Vizepr&#228;sidenten von Smart Home bei Amazon, 50 000 Skills im
Alexa-Marketplace verf&#252;gbar, die meisten stammen von externen Entwicklerinnen und Entwicklern bzw.
Anbietern.1776 
Amazon hat mit dem Smart Speaker &#8222;Echo&#8220; und dessen integriertem Sprachassistenten Alexa als erstes
Unternehmen ein Sprachassistenzsystem inklusive des kompletten &#214;kosystems und Skill-Marketplace auf den Markt
gebracht. Amazon hat weiterhin die globale Marktf&#252;hrerschaft mit einem Marktanteil von mehr als 30 Prozent, 
dicht gefolgt von Google. Weitere Anbieter mit kleineren, aber relevanten Marktanteilen sind Alibaba, Baidu
und Apple.1777 W&#228;hrend der Smart-Speaker-Markt noch 2018 rasant gewachsen ist, ist das Wachstum 2019
moderater. Es ist eine Verschiebung der Marktanteile zuungunsten von Amazon zu beobachten. Doch auch wenn
der Markt grunds&#228;tzlich moderat w&#228;chst, bieten die Smart Speaker den Anbietern die M&#246;glichkeit, ihr eigenes
Plattform-Angebot einfach mit zu vermarkten, beispielsweise im Fall von Amazon das Streaming-Angebot
Amazon Prime Music und Amazon Shopping.  
Auch im Bereich der Vermittlung von Medieninhalten und Nachrichten werden die Smart Speaker und
Sprachassistenten eingesetzt. So bieten die meisten Smart Speaker eine Funktion, die die Nachrichten des Tages vorliest.
Die Quellen f&#252;r die Nachrichten sind dabei einstellbar und kombinierbar. Alexa beispielsweise kommt
standardm&#228;&#223;ig mit einer Anbindung an die ARD-Nachrichten, kann aber mit diversen Sprachangeboten von anderen
Nachrichten-Anbietern erweitert werden. Viele deutsche Radiosender, Zeitungen und Fernsehsender bieten
inzwischen eigene Anwendungen f&#252;r die Smart Speaker. Eine Herausforderung stellt die Vielfalt f&#252;r Smart Speaker
dar, da sie &#252;blicherweise keine Auswahl an Inhalten ausgeben k&#246;nnen wie Suchmaschinen. Es bleibt den
Nutzenden &#252;berlassen, diese Vielfalt aktiv einzufordern.
Sprachassistenzsysteme sollten als Unterst&#252;tzungssysteme zur Bek&#228;mpfung von Beleidigungen, Hassrede und
anderen strafbaren Inhalten weiter erforscht und entwickelt sowie Regelungen f&#252;r Hassrede auf Sprachassistenten
festgelegt werden. Hersteller von Sprachassistenzsystemen im privaten Bereich sind aufgefordert, Ma&#223;nahmen
zu entwickeln, die eine mediale Vielfalt f&#252;r die Nutzenden gew&#228;hrleisten.
3.2.2 System zur Inhaltsgenerierung
Durch die gro&#223;e Geschwindigkeit der Inhalte, Themen und Diskussionen in den sozialen Medien und Online-
Medien stehen viele Anbieter von Inhalten unter Zugzwang, regelm&#228;&#223;ig Inhalte anbieten zu k&#246;nnen. So ist es
beispielsweise f&#252;r viele Unternehmen wichtig, im Zuge ihrer Marketingarbeit f&#252;r ihre Kunden regelm&#228;&#223;ig
m&#246;glichst qualitativ hochwertige Inhalte zur Verf&#252;gung zu stellen. In der gro&#223;en Menge der verf&#252;gbaren Inhalte reicht
es f&#252;r viele Anbieter nicht mehr, nur alle paar Wochen eine Mitteilung zu posten. Das gilt genauso f&#252;r
Organisationen, die Politik und Einzelne, die das Ziel verfolgen, in digitalen Inhalten auffindbar zu sein. Auch Zeitungen
und andere Anbieter von Online-Medien sind sehr gefordert. Hier kann Software, die KI-Technologien nutzt,
helfen, Inhalte entweder voll- oder teilautomatisch zu generieren (siehe auch Kapitel 5.2 dieses
Projektgruppenberichts [Automated Writing, redaktionelle Qualit&#228;tskontrolle]).1778 Von Systemen unterst&#252;tzte
Inhaltsgenerierung kann auch eine Chance f&#252;r die Barrierefreiheit bedeuten. So k&#246;nnen beispielsweise Systeme automatisch 
1776 Vgl. Rubin (2018): Amazon's Alexa assistant now works with over 20K devices.
1777 Vgl. Statista (2020): Amazon &#8211; Nummer 1 mit knappem Vorsprung&#8288;; Statista (2018): Konkurrenz nimmt Amazon weiter Marktanteile
ab.
1778 So nutzt beispielsweise die Washington Post das interne Tool Heliograf, um automatisch Sportreports zu generieren. Auch Bloomberg 
und viele andere Anbieter nutzen inzwischen Software f&#252;r die Unterst&#252;tzung bei der automatischen Generierung von Inhalten, f&#252;r
die sonst die Ressourcen fehlen w&#252;rden. Vgl. contentmanager.de (2018): Drei Use Cases f&#252;r K&#252;nstliche Intelligenz im Digital
Publishing &#8211; Was wir von gro&#223;en Medienh&#228;usern lernen k&#246;nnen.
die Untertitelung von Videos erm&#246;glichen, und bislang eher vernachl&#228;ssigte Themen wie Regional- oder
Nischensportarten k&#246;nnen an Sichtbarkeit gewinnen. 
Systeme zur automatischen Inhaltsgenerierung k&#246;nnen aber auch Risiken bedeuten. Falsche Informationen 
(&#8222;Fake News&#8221;) sind bereits jetzt ein breit diskutiertes Ph&#228;nomen.1779 Bis jetzt werden Fake News vor allem von
menschlichen Benutzerinnen und Benutzern generiert. Systeme, die mittels KI-Technologie Inhalte generieren, 
k&#246;nnen theoretisch Fake News in gro&#223;er Menge und in kurzer Zeit generieren, statt sie wie bisher aufwendig
h&#228;ndisch von Menschen schreiben zu lassen. Besonders riskant erscheint der Einsatz von Fake News in
demokratischen Prozessen. Im Jahr 2017 musste Facebook beispielsweise eingestehen, dass im Rahmen der
Pr&#228;sidentschaftswahlen in den USA im Jahr 2016 eine Reihe von politischen Werbeanzeigen mit falschen bzw.
irref&#252;hrenden Inhalten von einer Kreml-nahen Quelle gesponsert wurde.1780 Dar&#252;ber hinaus ist es mittels Methoden der
KI m&#246;glich, nicht nur Texte, sondern auch Bild- und Videomaterial k&#252;nstlich zu erstellen (siehe Kapitel 5.3
dieses Projektgruppenberichts [Deep Fake erkennen, Medienforensik]). Im Gegensatz zu Inhalten, die mittels
herk&#246;mmlicher Bildbearbeitungsans&#228;tze, beispielsweise klassischer Bildbearbeitungssoftware, produziert
wurden, k&#246;nnen durch KI-Technologie generierte Inhalte eine bessere Qualit&#228;t aufweisen und damit k&#246;nnen auch
F&#228;lschungen von Bild- und Videomaterial erstellt werden, die kaum noch als F&#228;lschung erkennbar sind. 
3.2.3 Personalisierte Empfehlungssysteme in den digitalen Medien
Dank digitaler Technologie k&#246;nnen Menschen heute aus einer viel gr&#246;&#223;eren Anzahl von Nachrichtenquellen ihre
Informationen beziehen, als es jemals zuvor in der Geschichte der Menschheit der Fall war. Da Menschen
Nachrichten aber im Wesentlichen nur nacheinander ansehen k&#246;nnen und daf&#252;r pro Tag nur ein eingeschr&#228;nktes
Zeitbudget haben, bedarf es pro Kanal jeweils eines ordnenden Systems, das alle verf&#252;gbaren Nachrichten bewertet
und hintereinander reiht oder auf einer Seite anordnet: Waren es in klassischen Redaktionen pro Tag noch wenige
Nachrichten, gab es die M&#246;glichkeit, die Regeln f&#252;r die Auswahl und Anordnung relativ einfach zu halten durch
eine fixe Reihenfolge von Ressorts und mit einer nach Wichtigkeit oder anderen Kriterien sortierten Reihenfolge
der Artikel innerhalb dieses Ressorts. Die digitale Vielfalt an Nachrichtenquellen zusammen mit den genannten
menschlichen Einschr&#228;nkungen und dem Wunsch nach Personalisierung f&#252;hren nun h&#228;ufig dazu, dass die Filter
und Sortierregeln zunehmend automatisiert werden. Menschliche Arbeitsschritte der Auswahl und Gewichtung
k&#246;nnen dabei eingebunden werden, m&#252;ssen es aber nicht. 
Systeme, die digitale Inhalte filtern und anordnen, werden allgemein als Empfehlungssysteme bezeichnet. Im
Wesentlichen sind also sehr verschiedene Dienste Empfehlungssysteme: Sowohl Suchmaschinen als auch
Produktempfehlungssysteme als auch Newsfeeds und Timelines auf Social Media oder News-Apps. Sie alle
funktionieren nach demselben Prinzip: Sie suchen nach Mustern menschlichen Verhaltens, um die Inhalte zu ordnen. 
Manche nutzen die digitalen Verhaltensspuren von Lesenden, um Filter und Sortierregeln individuell an deren
Lesegewohnheiten anzupassen. Dies wird als Personalisierung bezeichnet. Da somit das Ergebnis von
Empfehlungssystemen sowohl von der grundlegenden Programmierung &#8211; und damit den Selektions- und
Sortierungskriterien des Auftraggebers &#8211; als auch vom menschlichen Verhalten abh&#228;ngt, kann das Resultat nur dann richtig
verstanden werden, wenn Produzenten des Inhalts, die Software und ihre Nutzerinnen und Nutzer in dem daraus
entstehenden sozio-technischen Gesamtsystem gemeinsam betrachtet werden.
3.2.4 Technische Grundlagen von Empfehlungssystemen
Grunds&#228;tzlich beruhen alle Empfehlungssysteme auf einer Datenbasis, die unterschiedliche Arten von
Informationen beinhaltet:
1) grundlegende Informationen &#252;ber die zu empfehlenden digitalen Inhalte (z. B. seit wann im Angebot, von
wem eingestellt, Kategorien, Stichw&#246;rter, Beschreibungen etc.); diese werden meistens von den
Produzenten der Inhalte bereitgestellt,
2) m&#246;glichst detaillierte Informationen &#252;ber die Nutzerinnen und Nutzer (z. B. Alter, Geschlecht etc.),
3) meistens auch Interaktionsinformationen aus der Vergangenheit, also wann welche Person mit welchem
digitalen Inhalt wie interagiert hat. Diese Informationen enthalten meist nur indirekte Hinweise auf eine
Besch&#228;ftigung mit dem Gezeigten, z. B. das Anklicken eines Inhaltes, das Weiterverteilen (&#8222;Sharing&#8220;), die
Verweilzeit auf einer Webseite oder einem digitalen Inhalt oder die Angabe, dass einem der Inhalt gef&#228;llt
1779 Vgl. S&#228;ngerlaub (2017): Deutschland vor der Bundestagswahl: &#220;berall Fake News?!, S. 5&#8211;7.
1780 Vgl. Shane (2017): These Are the Ads Russia Bought on Facebook in 2016. Vgl. zudem Hurtz (2019): Facebook darf keine
L&#252;genschleuder f&#252;r Politiker sein.
(&#8222;Liking&#8220;). Erst mit zuk&#252;nftigen Sensoren wird es vielleicht m&#246;glich sein, zuverl&#228;ssig zu messen, ob sich 
eine Person tats&#228;chlich mit den Inhalten auseinandergesetzt hat (z. B. Eye-Tracking, Hirnstrommessungen).
Abbildung 5
Grunds&#228;tzliche Funktion von algorithmischen Empfehlungssystemen
Sie bekommen Input von zwei Quellen, den Produzentinnen und Produzenten von digitalen Inhalten und 
den Nutzerinnen und Nutzern, um die digitalen Inhalte f&#252;r letztere zu selektieren und anzuordnen.
Ganz einfache Systeme k&#246;nnten Inhalte nach dem Datum anbieten, an dem die Inhalte in die Datenbasis kamen.
Diese Sortierung ist effizient und transparent; lange wurde beispielsweise bei Twitter die sogenannte Timeline
in genau dieser Art von Sortierung angezeigt. Insbesondere bei Nachrichten und anderen digitalen Inhalten auf
sozialen Medien berichten die gro&#223;en Anbieter davon, dass die Personalisierung der Inhalte die Nutzerzahlen
und / oder die Nutzungsdauer erh&#246;ht.1781 Die &#252;berall verbreitete Anwendung von personalisierten Newsfeeds und 
Timelines kann daher als Evidenz f&#252;r die praktische Relevanz dieser Empfehlungssysteme gelten.
Die meisten Empfehlungssysteme versuchen daher, solche Inhalte, mit denen die Nutzerinnen und Nutzer stark
interagieren, f&#252;r den jeweiligen Nutzer oder die jeweilige Nutzerin nach vorne zu sortieren. Solche Interaktionen 
werden so interpretiert, dass die Nutzerinnen und Nutzer damit anzeigen, dass der Inhalt f&#252;r sie &#8222;relevant&#8220; ist.1782 
Dieses Kriterium kann gemischt werden mit (z. B. &#246;konomischen) Auswahlkriterien des Anbieters. Dabei dienen
z. B. die Nutzeranzahlen, die Nutzungsdauer oder auch Werbeeinnahmen als einfache Richtschnur. Ob aber ein
Inhalt wirklich relevant f&#252;r eine Person ist, kann nicht direkt gemessen werden. Eine Befragung w&#228;re hilfreich,
kann aber aus Effizienzgr&#252;nden weder f&#252;r jeden Nutzer oder jede Nutzerin noch f&#252;r jeden digitalen Inhalt
durchgef&#252;hrt werden. Daf&#252;r muss die Relevanz eines digitalen Inhaltes digital messbar gemacht werden &#8211; die
Messbarmachung eines nicht direkt messbaren Konzeptes nennt man Operationalisierung1783 und sie ist in der Regel
schwierig. Die Relevanz von Nachrichten f&#252;r die Nutzerinnen und Nutzer wird beispielsweise anhand vieler
verschiedener digital messbarer oder verf&#252;gbarer Informationen abgesch&#228;tzt:
1) der Anzahl an Klicks auf den Inhalt
1781 Vgl. Liu et al. (2010): Personalized news recommendation based on click behavior.
1782 Dass &#8222;Relevanz&#8220; bei der Sortierung ein Kriterium sein kann, kann beispielsweise einer Patentbeschreibung von Facebook entnommen
werden, die die sogenannte Timeline beschreibt: &#8222;The system then selects one or more of these pieces of data and/or activities from
a certain time period and gathers them into timeline units based on their relatedness and their relevance to users&#8220; (Piantino et al.
(2014): Selecting social networking system user information for display via a timeline interface).
1783 Deming nennt es auch eine &#8222;operationale Definition&#8220;: &#8222;An operational definition is a procedure agreed upon for translation of a 
concept into measurement of some kind&#8220; aus Deming (2000): The new economics, S. 105.
2) der Anzahl an Links auf den Inhalt1784 
3) der Anzahl an Minuten, die eine Nutzerin oder ein Nutzer auf einer Webseite verbracht hat
4) der Anzahl an Klicks, Links oder Minuten, die andere Nutzerinnen und Nutzer auf einer Webseite verbracht
haben
5) Interaktion mit Inhalten (Likes, Kommentare, Shares)
Es ist offensichtlich, dass keines dieser Ma&#223;e tats&#228;chlich direkt die Relevanz misst: Leserinnen und Leser k&#246;nnen
auf Webseiten klicken und dort Zeit verbringen, ohne diese beispielsweise f&#252;r ihre Meinungsbildung f&#252;r relevant
zu halten. Die Operationalisierung von Relevanz &#8211; also die Entscheidung, wie diese gemessen wird &#8211; ist also
erstens nicht eindeutig, sondern kann vielf&#228;ltig erfolgen und ist zweitens wichtig f&#252;r die genaue Anordnung der
digitalen Inhalte, da sie als Richtschnur dient.
Empfehlungssysteme nutzen meistens Verfahren des &#8222;kollaborativen Filterns&#8220;, bei denen die Anordnung von
digitalen Inhalten f&#252;r eine Nutzerin oder einen Nutzer vom Verhalten &#228;hnlicher Nutzerinnen und Nutzern
abh&#228;ngt: Was diese f&#252;r &#8222;relevant&#8220; hielten, wird dann auch dieser Nutzerin beziehungsweise diesem Nutzer
angezeigt. Dabei muss das Algorithmendesign-Team entscheiden, wie man die &#196;hnlichkeit zweier Nutzender misst
(eine weitere Operationalisierung) und wie die davon abgeleiteten &#8222;relevanten&#8220; Inhalte dann angeordnet werden
sollen. In den meisten F&#228;llen haben Empfehlungssysteme daher viele Parameter, deren Werte dar&#252;ber
entscheiden, wie genau Auswahl und Anordnung erfolgen.
Diese Werte der Parameter k&#246;nnen best&#228;ndig angepasst werden &#8211; in Abh&#228;ngigkeit vom Feedback der
Nutzerinnen und Nutzer. Werden die obersten ihnen angezeigten digitalen Inhalte konsumiert, sind die gew&#228;hlten Werte
optimal. Verl&#228;sst eine Nutzerin oder ein Nutzer dagegen die Webseite oder bricht das Streaming eines digitalen
Inhaltes ab, sucht nach einem weiteren Begriff oder klickt einen weiter unten stehenden Link an, werden die
Gewichte angepasst, um diesen Link h&#246;her anzuordnen oder insgesamt andere Links nach oben anzuordnen. 
Werden diese Gewichte f&#252;r jede individuelle Nutzerin oder jeden individuellen Nutzer einzeln angepasst, spricht
man von einem personalisierten Empfehlungssystem. F&#252;r solche Systeme kann eine Nutzerin oder ein Nutzer
zudem meistens noch weitere Einstellungen machen, z. B. die Kategorien von Nachrichten angeben, die sie oder 
ihn besonders interessieren. 
Das resultierende Empfehlungssystem ist auf der einen Seite beeinflusst von den vielf&#228;ltigen Entscheidungen des
Entwicklerteams &#8211; sie w&#228;hlten die grunds&#228;tzliche Methode der Empfehlung aus, definierten, wie Relevanz und
&#196;hnlichkeit gemessen werden und wie und wie oft Parameter angepasst werden. Auf der anderen Seite wird es
vom Verhalten der Nutzerinnen und Nutzer beeinflusst, indem dieses die Werte der Parameter ver&#228;ndert &#8211; was
f&#252;r diese allerdings meistens nicht nachvollziehbar ist. Nicht zuletzt k&#246;nnen Produzenten von Inhalten und
Anbieter versuchen, das System zu manipulieren, z. B. indem sie durch sogenannte Clickbait-&#220;berschriften1785 viele
Klicks auf ihre Webseiten provozieren.
3.2.5 Monitoring-Systeme
Die gro&#223;e Menge digitaler Inhalte und Angebote macht es unm&#246;glich, sie mit manuellen Methoden zu kuratieren.
Daher hat sich ein Software-Bereich f&#252;r das automatische Monitoring von digitalen Inhalten wie Social-Media-
Posts und Inhalten der Online-Medien gebildet.1786 Solche Monitoring-L&#246;sungen werden weltweit verwendet.
Die Menge der Anwendungsf&#228;lle ist gro&#223;, es geht aber im Kern immer darum, Informationen aus der gro&#223;en
Menge von Inhalten zu filtern, die man sonst verpassen w&#252;rde. Nutzerinnen und Nutzer sind sowohl
Unternehmen, die mit ihren Kundinnen und Kunden &#252;ber soziale Medien kommunizieren, als auch Politik, Organisationen
und einzelne Privatpersonen. Auch f&#252;r die Generierung von journalistischen Inhalten sind Monitoring-Systeme 
relevant. Sie k&#246;nnen beispielsweise von kleinen Redaktionen genutzt werden, relevante Diskussionen und
Themen aus der Region zu identifizieren. Social-Media-Monitoring-Systeme k&#246;nnen dar&#252;ber hinaus helfen, wichtige
Diskussionen um die eigene Person, Marke oder Organisation mitzubekommen und mitgestalten zu k&#246;nnen. Sie
1784 Googles PageRank-Algorithmus verwendete die Link-Struktur von Webseiten, um diese anzuordnen. Vgl. Brin und Page: The
anatomy of a large-scale hypertextual Web search engine, S. 107&#8211;117.
1785 Unter &#8222;Clickbait&#8220; versteht man &#220;berschriften, die das Sensationsbed&#252;rfnis ansprechen und Neugier wecken auf einen Inhalt, der die
Aufmerksamkeit nicht verdient hat. Ein typisches Beispiel daf&#252;r ist die folgende Zeile: &#8222;Das verschweigt Ihnen der Stromanbieter
mit Absicht!&#8220; oder &#8222;Essen Sie keinen Kurkuma mehr, bevor Sie nicht die folgenden Hinweise gelesen haben!&#8220;.
1786 Das System &#8222;Echobot&#8220;, eine Social-Media-Monitoring-Software, untersucht pro Tag beispielsweise mehr als 5,5 Millionen Social-
Media-Posts nur im DACH-Raum (Deutschland, &#214;sterreich und der Schweiz), um nach bestimmten Erw&#228;hnungen und Themen
Ausschau zu halten.
werden au&#223;erdem genutzt, einen sogenannten &#8222;Shitstorm&#8220; in sozialen Medien fr&#252;hzeitig zu erkennen und
gegenzusteuern. Des Weiteren werden Monitoring-Algorithmen f&#252;r das Aufsp&#252;ren von kriminellen Inhalten wie
extremistischen Texten oder kinderpornographischem Bildmaterial eingesetzt.
4 Hintergrund
Medienkonsum und Nutzungsverhalten
4.1.1 Mediennutzung
Um eine genaue Einsch&#228;tzung vornehmen zu k&#246;nnen, wie gro&#223; Hebeleffekte von KI-Systemen im Medienbereich
sein k&#246;nnen, bedarf es auch eines Blicks auf das (generelle) Mediennutzungsverhalten, welches in Deutschland
in verschiedenen Facetten sehr intensiv erforscht wird. Die quantitative Forschung konzentriert sich dabei auf
wesentliche Kerngr&#246;&#223;en:
&#8226; Erstens werden die Zug&#228;nge zu medialen Inhalten sehr genau hinsichtlich Relevanz, Nutzungszeiten und
Verf&#252;gbarkeiten untersucht. 
&#8226; Zweitens werden Ver&#228;nderungswirkungen durch z. B. den Wechsel des Distributionskanals sehr genau
untersucht und hinsichtlich offenkundiger Irritationen analysiert. 
Sehr leicht l&#228;sst sich dies am Wandel der Musikindustrie festmachen, wo durch die Digitalisierung und damit
einhergehender Piraterieeffekte lange Zeit starke Schwankungen zwischen Umsatzdaten und Musikkonsum zu 
beobachten waren. Inzwischen bedeuten Flatrates, dass sich bezahlter Konsum und Nutzungsverhalten wieder
aneinander angen&#228;hert haben. Schlie&#223;lich werden im Rahmen der Nutzungsstudien auch noch sehr h&#228;ufig damit
einhergehende Einstellungsfragen der Nutzerinnen und Nutzer erhoben. Im Kern geht es dabei um Vertrauen in
journalistische Leistungen oder auch die Frage von Parallelnutzung und Aufmerksamkeit. Neben der nationalen
Mediennutzung interessiert gerade im Zusammenhang mit der zunehmenden Digitalisierung und Vernetzung der
Medien die internationale Mediennutzung in ausgew&#228;hlten L&#228;ndern. Hinsichtlich des Hauptthemas Medien und
KI sind an der Stelle diejenigen L&#228;nder (Heimatm&#228;rkte) besonders relevant, die auch im Rahmen der KI-
Entwicklung eine besondere Rolle spielen (heute USA und China).
Berechtigt erscheint die Frage, warum zumindest quantitative Mediennutzungsdaten im Rahmen eines solchen
Berichts zu KI und Medien aufgenommen werden. Dies hat zwei gewichtige Gr&#252;nde:
&#8226; Erstens veranschaulicht Nutzungsverhalten weit mehr die Wirkmacht von Technologien, da neben der
einfachen Nutzung z. B. Komponenten wie Zeit und Intensit&#228;t gemessen bzw. erfasst werden. Damit lassen
sich wesentlich eindeutiger R&#252;ckschl&#252;sse auf die Wirkung von KI in den Medien erfassen. 
&#8226; Zweitens decken Mediennutzungsdaten (bei L&#228;ngsschnittdaten) auch Ver&#228;nderungen im
Mediennutzungsverhalten auf.
Am Beispiel der Streaming-Services, die vielfach KI-basierte Verfahren einsetzen, wird schnell klar, dass bei
Zunahme dieser Angebote zumindest ein Wirkungsfaktor der KI angenommen werden kann, auch wenn dieser
ohne gesonderte Untersuchungen nicht in seiner quantitativen Gr&#246;&#223;e bestimmbar ist. Dennoch sind dies wichtige
Indikatoren, ob und, wenn ja, unter welchen Umst&#228;nden KI in den Medien Wirkung entfaltet. 
4.1.2 Die Mediennutzung in Deutschland
Zun&#228;chst sollen aber f&#252;r Deutschland einige Eckdaten festgehalten werden, wobei die verf&#252;gbaren Daten immer
nur begrenzt vergleichbar sind. Dar&#252;ber hinaus handelt es sich gerade bei der quantitativen
Mediennutzungsforschung nicht um rein akademische Daten, sondern Erhebungen von Meinungsforschungsinstituten,
Medienanbietern oder Beratungsunternehmen. 
Im Hinblick auf die allgemeine Mediennutzung l&#228;sst sich zun&#228;chst eine Verschiebung beobachten. Die Grafik
zeigt, dass Zeitungs- und Zeitschriftenkonsum deutlich abnehmen, die Nutzung von Online-Videos deutlich
zunimmt.1787 
1787 Vgl. Statista (2019): Weitester Nutzerkreis (Nutzung mindestens selten) ausgew&#228;hlter Medien in Deutschland in den Jahren 2014 bis
2019.
Dieser Trend l&#228;sst sich in Bezug auf Zeitungen am deutlichen R&#252;ckgang der Gesamtverkaufszahlen der
Tageszeitungen zeigen: Die Zahl der verkauften Exemplare pro Tag lag 2008 bei ca. 23,4 Millionen, 2019 bei nur noch
14,9 Millionen.1788 
Auch im Hinblick auf die Bewegtbildnutzung (Video) lassen sich &#228;hnliche Entwicklungen feststellen. W&#228;hrend
hier &#8222;klassisches&#8220; Bewegtbild, d. h. TV und Speichermedien (z. B. DVD), noch immer bei der Mehrheit der
Bev&#246;lkerung dominant ist, hat sich das Bewegtbild im Internet (ohne Live-TV) bei der j&#252;ngeren Generation (14-
bis 21-J&#228;hrige) jedoch im Vergleich zu den &#252;ber 70-J&#228;hrigen mehr als verdoppelt.1789 
Abbildung 6
Weitester Nutzerkreis ausgew&#228;hlter Medien in Deutschland
1788 Vgl. Informationsgemeinschaft zur Feststellung der Verbreitung von Werbetr&#228;gern e. V. (IVW) (2020): Gesch&#228;ftsbericht der IVW
2019, 2020, 38 ff.
1789 Vgl. Egger und Gerhard (2019): Ergebnisse der ARD/ZDF-Massenkommunikation Trends und der ARD/ZDF-Onlinestudie &#8211;
Bewegtbildnutzung 2019, S. 389&#8211;405.
        
 
 
 
   
 
   
         
  
    
   
   
     
  
    
                                               
   
   
      
     
            &#8201;
Abbildung 7
Entwicklung t&#228;glicher Nutzungsdauer des Internets
&#220;ber alle Altersgruppen hinweg steigt in den letzten Jahren die durchschnittliche t&#228;gliche Nutzungsdauer des
Internets deutlich.1790 Unterschiede gibt es in den Altersgruppen: 100 Prozent der 14- bis 29-J&#228;hrigen nutzten
2019 das Internet mindestens einmal t&#228;glich, bei den 60- bis 69-J&#228;hrigen waren es 85 Prozent.1791 
Die Nutzung des Internets ist naturgem&#228;&#223; sehr heterogen: 82 Prozent nutzen Suchmaschinen (55 Prozent nutzen
sie ein- oder mehrmals pro Woche). Sieben von zehn B&#252;rgerinnen und B&#252;rgern in Deutschland nutzen soziale
Medien, das ist ein Anstieg um 5 Prozentpunkte im Vergleich zum Vorjahr. Bei den unter 30-J&#228;hrigen sind es
mit 95 Prozent nahezu alle. Konkret: 71 Prozent nutzen soziale Medien (allerdings mit gro&#223;en Unterschieden,
wenn es um die konkreten Anwendungen geht: 2 Prozent TikTok, 9 Prozent Twitter, 42 Prozent Facebook,
64 Prozent WhatsApp, 40 Prozent YouTube).1792 
1790 Vgl. Statista (2020): Entwicklung der durchschnittlichen t&#228;glichen Nutzungsdauer des Internets in Deutschland in den Jahren 2000 
bis 2018 (in Minuten).
1791 Vgl. Bleisch et al. (2019): Aktuelle Aspekte der Internetnutzung in Deutschland &#8211; ARD/ZDF-Onlinestudie 2019: Mediale
Internetnutzung und Video-on Demand gewinnen weiter an Bedeutung, S. 374&#8211;388.
1792 Vgl. Initiative D21 e. V. (2020): Wie digital ist Deutschland? &#8211; D21 Digital Index 19/20 &#8211; J&#228;hrliches Lagebild zur Digitalen
Gesellschaft, S. 22&#8211;24.
4.1.3 Nachrichtennutzung
Abbildung 8
Hauptnachrichtenquelle 2019 (nach Alter, in Prozent) 1793 
Unter Nachrichten (&#8222;News&#8220;) versteht man die Berichterstattung &#252;ber aktuelle Ereignisse aus Politik, Kultur,
Wirtschaft usw. Wie diverse aktuelle Studien zeigen, verschiebt sich die Nachrichtennutzung zum Teil in die
digitalen Medien.1794 W&#228;hrend Personen &#252;ber 55 Jahre zu 60 Prozent das Fernsehen als Hauptnachrichtenquelle
nennen, informieren sich 18- bis 24-J&#228;hrige zu 70 Prozent im Internet (aus verschiedenen Quellen) &#252;ber
Nachrichten.1795 
Auch die Zunahme von Smart Devices, vor allem Smartphones, zeigt sich in der Medien- und
Nachrichtennutzung. Immer mehr Menschen verwenden das Smartphone und soziale Medien, um Nachrichten zu lesen. 2019
gaben bei einer Umfrage 16 Prozent der Befragten aus Deutschland an, WhatsApp f&#252;r Nachrichten zu nutzen,
w&#228;hrend 19 Prozent YouTube und 22 Prozent Facebook nannten.1796 5 Prozent der 18- bis 24-J&#228;hrigen sehen 
soziale Medien sogar als ihre einzige Nachrichtenquelle.1797 
Ein weiterer Aspekt ist das Vertrauen in Nachrichten. Hier ist ein Vertrauensverlust zu beobachten: Im Jahr 2015
vertrauten noch 60 Prozent der Befragten allgemein den Nachrichten, wohingegen dies im Jahr 2019 noch 47
Prozent der Befragten angaben.1798 Dabei zeigt sich das Vertrauen in die selbst genutzten Nachrichten als deutlich
st&#228;rker: 60 Prozent vertrauen den Nachrichtenquellen, die sie selbst nutzen.1799 
1793 H&#246;lig und Hasebrink (2019): Reuters Institute Digital News Report 2019 &#8211; Ergebnisse f&#252;r Deutschland, S. 20.
1794 Vgl. Gleich (2020): Nachrichtennutzung im Internet, S. 33&#8211;38.
1795 Vgl. H&#246;lig und Hasebrink (2019): Reuters Institute Digital News Report 2019 &#8211; Ergebnisse f&#252;r Deutschland, S. 20.
1796 Vgl. H&#246;lig und Hasebrink (2019): Reuters Institute Digital News Report 2019 &#8211; Ergebnisse f&#252;r Deutschland, S. 45.
1797 Vgl. H&#246;lig und Hasebrink (2019): Reuters Institute Digital News Report 2019 &#8211; Ergebnisse f&#252;r Deutschland, S. 22.
1798 Das Vertrauen in Medien ist komplex und m&#252;sste differenzierter dargestellt werden. Viele Studien, vor allem die Mainzer
Vertrauensstudie, zeigen, dass Vertrauen keineswegs erodiert, sondern recht stabil ist und dass vor allem dem &#246;ffentlich-rechtlichen
Rundfunk noch immer stark vertraut wird. Vgl. Jackob et al. (2019): Mainzer Langzeitstudie Medienvertrauen 2018 &#8211; Medienvertrauen 
im Zeitalter der Polarisierung, S. 210&#8211;220&#8288;; Jackob et al. (2019): Medienskepsis und Medienzynismus. Funktionale und
dysfunktionale Formen von Medienkritik, S. 19&#8211;35.
1799 Vgl. H&#246;lig und Hasebrink (2019): Reuters Institute Digital News Report 2019 &#8211; Ergebnisse f&#252;r Deutschland, S. 27.
Medienm&#228;rke und KI
Wie in allen Branchen hat der KI-Einsatz auch einen hohen wirtschaftlichen Effekt f&#252;r die Medienm&#228;rkte.1800 
Neben den reinen Digitalm&#228;rkten sind es schlie&#223;lich die Medien, die durch die generelle Digitalisierung die
gr&#246;&#223;ten Skaleneffekte aufweisen. Dass KI dabei zunehmend eine bedeutsame Rolle einnimmt, haben die
vorherigen Abschnitte belegt. Ob es zu so gravierenden Auswirkungen wie durch das Internet kommt, bleibt aber
abzuwarten.1801 Nun gilt es, auch ausgehend von der eingangs erl&#228;uterten Ordnungslogik, die wichtigsten
Medienteilm&#228;rkte mit KI-Bezug &#246;konomisch durch Daten und Fakten zu rahmen. In dem Zusammenhang stellt sich 
aber die Frage, welche Daten man zurate zieht. Wichtige &#246;konomische Kennzahlen sind, wie bei allen
Wirtschaftsakteuren, betriebswirtschaftliche Kennziffern, z. B. Ums&#228;tze, Renditen, Aktienkurse, Mitarbeiterzahlen.
Hinzu kommt aber, dass man bei den Informationsintermedi&#228;ren als den schnell wachsenden Anbietern im
Mediensektor, die KI nutzen, auch die Investitionsgr&#246;&#223;en &#8211; nicht nur im Bereich Content, sondern ebenfalls im
Bereich KI-Technologien &#8211; sehen muss. Im Zweifel werden dabei enorme Summen investiert, die sich eben nicht
unmittelbar in den genannten betriebswirtschaftlich relevanten Kennziffern ausdr&#252;cken. Diese Kosten gleichen
sich eher in l&#228;ngeren Zeitspannen, die derzeitige Projektionen nicht abdecken k&#246;nnen, aus. Sie stellen aber einen
wesentlichen Indikator f&#252;r den Einfluss von KI in den Medien, spezifischer bei Intermedi&#228;ren, dar. Noch
schwieriger wird es, wenn nicht die Inhalte, sondern die Kommunikation &#8211; wie bei den gro&#223;en Social-Media-Konzernen
&#8211; im Mittelpunkt steht. Diese investieren prim&#228;r in (KI-)Technologien, also die technische Plattform; aufgrund 
des prim&#228;r werbebasierten Gesch&#228;ftsmodells sind Aussagen anhand harter &#246;konomischer Daten hinsichtlich KI
bzw. deren &#246;konomischer Wirkung bei den Medien nur schwer m&#246;glich, da KI immanenter Bestandteil der
Plattform ist. Dies rechtfertigt es zumindest bei den Informationsintermedi&#228;ren, die im Kerngesch&#228;ft soziale Medien
betreiben, davon auszugehen, dass diese Dimensionen ohne KI nicht erreichbar w&#228;ren. Insgesamt aber gilt,
&#228;hnlich der Betrachtung von Daten zum Mediennutzungsverhalten, dass auch die bekannten &#246;konomischen
Inputwie Output-Daten nur indirekt Aufschluss dar&#252;ber geben, welche Wirkmacht und Hebelwirkung KI in
Mediensegmenten erreichen kann.
F&#252;r die nachfolgende Betrachtung sollen im Kern M&#228;rkte unterschieden werden, bei denen
&#8226; die Medien origin&#228;re inhaltliche Anbieter (im weitesten Sinne der Massenmedien) sind, 
&#8226; Inhalte von Medien genutzt, aber nicht selbst produziert werden bzw. Anbieter erst nach und nach in diese
M&#228;rkte eingestiegen sind (Plattformen) und 
&#8226; die Eigenproduktion von medialen Inhalten durch die Nutzenden im Mittelpunkt steht (z. B. soziale Medien
etc.), insbesondere unter dem Aspekt der Plattform&#246;konomie (definiert hier im Sinne der Intermedi&#228;re).
Man kann zun&#228;chst festhalten, dass aufgrund der Multikonvergenz sowohl im Endger&#228;temarkt als auch in der
Mehrfachverwertung von Inhalten die Grenzen zunehmend erodieren, da vor allem gro&#223;e Plattformanbieter
(Audio- und audiovisuelle Streaming-Anbieter) auch zunehmend in das Gesch&#228;ft eigener Inhaltsproduktionen
(insbesondere im Unterhaltungsmediensektor) einsteigen.1802 
Hinsichtlich der Social-Media-M&#228;rkte an sich gilt es zus&#228;tzlich zu unterscheiden zwischen der interpersonellen
Kommunikation (z. B. wenn Privatpersonen sich austauschen), den werbenden Informationen bzw. Inhalten und
der Distribution medialer Inhalte. Aus einer &#246;konomischen Perspektive kann die Bewertung aber genau diese
Feindifferenzierung nicht leisten; es kann nicht angegeben werden, welche Wirkung KI hier in welchem Kontext
entfaltet, da das Kennzeichen der Social-Media-M&#228;rkte in der Konvergenz liegt. 
4.2.1 Anbieter von Medieninhalten
Zur Einordnung der herangezogenen &#246;konomischen Gr&#246;&#223;en sind einige Bemerkungen zur Struktur der in der
Ordnungslogik beschriebenen Medienteilm&#228;rkte voranzustellen. Um sich ein Bild davon zu machen, welche
&#246;konomische Dimension die Medienteilm&#228;rkte insgesamt annehmen, lohnt ein Blick auf die zehn st&#228;rksten globalen
M&#228;rkte. Allein in diesen zehn M&#228;rkten kommt ein Gesamtvolumen von j&#228;hrlich ca. 1,663 Billionen US-Dollar,
also ungef&#228;hr 1,5 Billionen Euro, zusammen. 
1800 Zum allgemeinen Stand: Bundesministerium f&#252;r Wirtschaft und Energie (2020): Einsatz von K&#252;nstlicher Intelligenz in der Deutschen
Wirtschaft &#8211; Stand der KI-Nutzung im Jahr 2019.
1801 Weitere Informationen dazu unter: https://www.ai-united.de/ki-in-medien/ (zuletzt abgerufen am 31. August 2020).
1802 Verzichtet wird an dieser Stelle auf Ausf&#252;hrungen zum Endger&#228;temarkt, selbst wenn dieser an sich KI-Elemente beinhaltet, sowie 
zur gesamten Frage der Medienrechteverwertung, auch wenn gerade die Diskussion nach den Reformen des Urheberrechts auf
europ&#228;ischer Ebene dies nahelegen k&#246;nnte, insbesondere im Zusammenhang mit dem Aufsp&#252;ren von Urheberrechtsverletzungen. Zu 
Letzterem wird im Kapitel 7.4.1 dieses Projektgruppenberichts [Filter bei der Umsetzung von Urheberrecht] Stellung bezogen.
Abbildung 9
Prognose der L&#228;nder mit den h&#246;chsten Ums&#228;tzen der Medien- und Unterhaltungsbranche
weltweit im Jahr 2019 (in Milliarden US-Dollar)1803 
0 100 200 300 400 500 600 700 800 
USA 
China 
Japan 
Vereinigtes K&#246;nigreich 
Deutschland 
Frankreich 
Brasilien 
S&#252;dkorea 
Kanada 
Italien 
723,38 
235,71 
165,02 
109,79 
109,28 
86,02 
68,77 
63,49 
55,44 
46,98 
Die traditionellen Medienm&#228;rkte sind im Kern durch eine hohe Medienkonzentration gepr&#228;gt, d. h., wenige
Anbieter (x &lt; 10) bedienen signifikante Marktanteile (CR &gt; 0,8). Das bedeutet im Umkehrschluss, dass es h&#228;ufig zu 
harten Verdr&#228;ngungswettbewerben kommt und eine neue Schl&#252;sseltechnologie vor allem jenen n&#252;tzt, die daraus
f&#252;r ihre Wettbewerbsposition Vorteile entwickeln k&#246;nnen. Derzeitige Gewinner, wie sich auch im folgenden
Abschnitt zu den Medienkonzernen zeigt, sind meist in der westlichen Welt die amerikanischen Gro&#223;konzerne, die
im globalen Wettbewerb signifikant von ihrer F&#228;higkeit profitiert haben, Digitaltechnologien, insbesondere auch 
KI, zu nutzen.
Auch wenn hierzu noch kein eindeutiger zahlenm&#228;&#223;iger Beleg vorliegt, zeigen die insgesamt r&#252;ckl&#228;ufigen
Entwicklungen der traditionellen, h&#228;ufig noch datentr&#228;gergebundenen Medienteilm&#228;rkte exakt auf, welche
Wirkungen der generelle Einsatz digitaler Technologien hat. Signifikante Beispiele sind der Musikmarkt, der z. B. noch
in den 1990er-Jahren einen Umsatz zwischen 2,7 und 3,0 Milliarden Euro verzeichnen konnte, heute aber
kumuliert (analog und digital) nur noch bei knapp 1,6 Milliarden Euro liegt (von denen heute &#252;ber 1 Milliarde Euro
digital und davon wiederum gut 900 Millionen Euro durch Streaming erwirtschaftet werden, dies entspricht mit
wachsender Tendenz 65 Prozent des Gesamtmarktes1804). Allerdings hat sich durch den Einsatz von neuen
Gesch&#228;ftsmodellen und Digitaltechnologien inklusive KI-Technologien bei den Plattformanbietern der Umsatz hier
seit ca. 2010 stabilisiert.1805 Noch deutlicher zeigt sich dies im Vergleich beim Kino- und Homevideomarkt. 
W&#228;hrend die Kinom&#228;rkte von der Serialit&#228;t der Blockbuster und dem Eventcharakter in den R&#228;umlichkeiten der
gro&#223;en Kinos leben und die Digitalisierung hier bisher keine signifikanten Auswirkungen gehabt hat, bedeuten
die Markteintritte der Plattformanbieter einen deutlichen Umsatzr&#252;ckgang des bisherigen Verleih- bzw.
Verkaufsgesch&#228;ftes. Die Gesch&#228;ftsmodelle der Plattformanbieter mit durchg&#228;ngigen Flatrates und, wie weiter unten
beschrieben, zunehmendem Einsatz von KI bedeuten, dass die alten Gesch&#228;ftsmodelle zunehmend r&#252;ckl&#228;ufig
sind. Gewinner sind in den Medienm&#228;rkten diejenigen, die &#252;ber digitale Plattformtechnologien Konsumentinnen 
und Konsumenten &#8211; auch mithilfe von KI &#8211; deutlich attraktivere skalierende Modelle anbieten k&#246;nnen. Im Jahr
2018 haben die Nutzerzahlen von Streaming-Anbietern erstmals alle alternativen Distributionsformen mit knapp
12 Millionen Nutzerkonten (bei ggf. Mehrfachnutzung) &#252;berholt, und der Digitalumsatz machte 2018 schon
knapp 60 Prozent des Gesamtumsatzes aus.
1803 Statista (2015): Prognose der L&#228;nder mit den h&#246;chsten Ums&#228;tzen der Medien- und Unterhaltungsbranche weltweit im Jahr 2019 (in
Milliarden US-Dollar).
1804 Marktf&#252;hrend als Musikdistributoren sind Spotify (ca. 6,7 Milliarden Euro Jahresumsatz bei ca. 200 Millionen Euro Verlust), Amazon
Music und Apple Music. Hier l&#228;uft es auf eine starke Anbieterkonzentration hinaus. Die Konzentration auf wenige Labels auf der 
Produzentenseite verst&#228;rkt diesen Trend. &#8222;Die Umsatzprognose f&#252;r das Gesamtjahr korrigierte Spotify wegen der Unsicherheiten
rund um die Pandemie auf 7,6 bis 8,0 Milliarden Euro.&#8220; Steuer (2020): Spotify &#252;bertrifft Erwartungen &#8211; verdient aber noch immer
kein Geld.
1805 Bundesverband Musikindustrie e. V.; GfK Entertainment GmbH (2019): Umsatz.
Abbildung 10
Ums&#228;tze im Home-Video-Markt und im Kinomarkt in Deutschland in den Jahren 2000 bis 20191806 
500 
700 
900 
1.100 
1.300 
1.500 
1.700 
1.900 
U
m
sa
tz
 in
 M
illi
on
en
 E
ur
o 
Home-Video-Markt Kinomarkt 
Wie stark der Print-Journalismus an dieser Stelle getroffen wird, l&#228;sst sich ebenfalls erkennen. Erstens sprechen
die Auflagenzahlen eine deutliche Sprache. Allein die verkaufte Auflage deutscher Tageszeitungen hat sich seit
1995 von 25 Millionen t&#228;glich auf 13,5 Millionen im Jahr 2019 fast halbiert.1807 Umgekehrt nimmt seit einigen
Jahren kontinuierlich der Verkauf digitaler Zeitungen zu (1,8 Millionen). Dabei konzentriert sich der
Verlagsmarkt stark. Die gr&#246;&#223;ten sechs Verlage teilten sich 2018 ann&#228;hernd 60 Prozent des Gesamtmarktes.1808
Kombiniert mit der Tatsache, dass immer mehr Menschen ihre Hauptinformationen online im Freemium-Modell1809 
beziehen, wird schnell klar, dass die Auswirkungen der Digitalisierungen im Generellen und der Einsatz von KI-
Systemen alternativer journalistischer Anbieter im Speziellen zu einer radikalen Ver&#228;nderung der M&#228;rkte f&#252;hren
und weiter f&#252;hren werden. Hier zeigt sich dar&#252;ber hinaus, betrachtet man allein die Reichweite journalistischer
Medien im Juni 2020, dass es nicht mehr nur die &#252;blichen Tageszeitungsanbieter, sondern zunehmend andere
Anbieter sind, die den Markt bestimmen. Entsprechend verschieben sich auch die Werbeeinnahmen. In nur zehn
Jahren sind diese von einem Niveau von ca. 3,7 Milliarden Euro pro Jahr auf knapp 2,4 Milliarden Euro pro Jahr
zur&#252;ckgegangen, und auch die Ums&#228;tze sowohl der verkauften Auflagen als auch der Online-Angebote
kompensieren diese Verluste nicht. Insgesamt gesehen, insbesondere im Zusammenhang mit den Ausf&#252;hrungen zum
automatisierten Journalismus, bleibt zu bef&#252;rchten, dass zuk&#252;nftig, um sich im &#246;konomischen Wettbewerb zu
behaupten, die journalistische Qualit&#228;t sinken oder ggf. auch die Vielfalt im Journalismus weiter zur&#252;ckgehen
wird. 
1806 Statista (2020): Ums&#228;tze im Home-Video-Markt und im Kinomarkt in Deutschland in den Jahren 2000 bis 2019 (in Millionen Euro).
1807 Vgl. Statista (2019): Entwicklung der verkauften Auflage der Tageszeitungen in Deutschland in ausgew&#228;hlten Jahren von 1991 bis
2019.
1808 Vgl. R&#246;per (2018): Zeitungsmarkt 2018: Pressekonzentration steigt rasant.
1809 Unter &#8222;Freemium&#8220; wird verstanden, dass ein Anteil der Informationen frei verf&#252;gbar ist, ein anderer Anteil hinter einer Paywall
zur&#252;ckgehalten und nur gegen Zahlung freigegeben wird.
Abbildung 11
Reichweite in Millionen Unique Usern von Nachrichtenwebsites in Deutschland im Juni 20201810 
0 5 10 15 20 25 30 35 
T-Online 28,83 
FOCUS Online 26,62 
BILD 24,99 
WELT.de 24,03 
DER SPIEGEL SPM 23 
WEB.DE 22,16 
CHIP 21,89 
N-TV IPD 20,86 
RTL IPD 17,57 
STERN EMS 17,11 
RND 16,77 
FUNKE MEDIEN NRW 16,69 
S&#252;ddeutsche.de 16 
FAZ.NET 15,52 
ZEIT ONLINE 15,07 
Jenseits des Print-Journalismus l&#228;sst sich dies, unabh&#228;ngig von der Medienausrichtung (Informationsmedien, 
Info- / Edutainment, Unterhaltungsmedien) f&#252;r fast alle Medienteilm&#228;rkte mehr oder weniger stark beobachten.
Der Umkehrschluss legt nahe, dass trotz der Ver&#228;nderung in den Produktionsmethoden, der weiter oben
beschrieben wurde, die Dominanz in den Medienm&#228;rkten zunehmend bei den Plattformanbietern angesiedelt ist. Man
k&#246;nnte etwas lakonisch fragen: &#8222;Is content still the king?&#8220;, in Abgrenzung zu dem lange geltenden Paradigma
der Medienindustrie. Die Prognosen sind jedenfalls eindeutig und zeigen f&#252;r alle Bereiche, in denen Plattformen
und somit auch KI-Technologien eine Rolle spielen, dass die Umsatzdominanz auch zu einer neuen
Gesamtmarktlogik f&#252;hren wird. 
Dabei kann man unterscheiden: In den Informationsmedienm&#228;rkten spielt dies national eine gro&#223;e Rolle und die
Konzentrationswirkung ist kleinteiliger. Global gesehen sind es insbesondere die Unterhaltungsmedienm&#228;rkte
(inklusive Info- / Edutainment), bei denen eine hohe Konzentrationsrate mit einem zunehmend harten
Verdr&#228;ngungswettbewerb zugunsten der Plattformanbieter zu beobachten ist. Welche Rolle KI-Technologien hierbei als
Empfehlungssystem spielen, wird an sp&#228;terer Stelle noch weiter ausgef&#252;hrt. 
Exkurs: Games 
Eine Sonderstellung nehmen die Anbieter von Computer- und Videospielen ein. Anders als z. B. bei Printmedien
oder audiovisuellen Medien handelt es sich generisch um digitale Medien in einem stetig wachsenden
Gesamtmarkt von weltweit 140 Milliarden US-Dollar,1811 wobei die Marktforschung insofern schwankt, als dass nicht
immer klar zwischen Gesamtumsatz und reinem Umsatz mit Software unterschieden wird. Hier liegen die
Sch&#228;tzungen bei ca. 100 Milliarden US-Dollar im Jahr 2019.1812 Aktuelle Sch&#228;tzungen gehen f&#252;r 2020 sogar von einem
Umsatz von 160 Milliarden US-Dollar aus, wobei dann ein signifikantes Umsatzwachstum bei der Software
unterstellt wird.1813 Die Industrie hat recht fr&#252;hzeitig diese Trends erkannt und entsprechend eigene Portale
aufgebaut. Au&#223;erdem haben die gro&#223;en Plattformanbieter (Microsoft, Sony, Nintendo) aufgrund der propriet&#228;ren 
1810 Statista (2020): Reichweite der Top-15-Nachrichtenseiten in Deutschland im Juni 2020.
1811 Vgl. Anderton (2019): The Business Of Video Games: Market Share For Gaming Platforms in 2019.
1812 Vgl. DFC Intelligence (2015): DFC Inteligence Forecasts Global Video Game Software Industry to reach $100B in 2019.
1813 Vgl. Wijman (2019): Newzoo&#8217;s Games Trends to Watch in 2020.
Spielsysteme die Chance, in einer geschlossenen &#214;kologie ihre eigenen Plattformen zu generieren.1814 Auch hier
werden zunehmend entsprechende KI-Empfehlungssysteme eingesetzt. Insgesamt w&#228;chst die Branche aber auch
nach 50 Jahren kontinuierlich an. KI-Systeme haben hier eine besondere Bedeutung, will man den enormen
Erfolg der sogenannten Free-to-play-M&#228;rkte erkl&#228;ren. In diesen ist das Spielen grunds&#228;tzlich kostenlos, allerdings
bekommen die Anbieter viele Daten. Aus dem Nutzungsverhalten werden die entsprechenden Informationen 
extrahiert und &#252;ber Algorithmen wird das Verhalten so vorweggenommen, dass individualisiert entsprechende
Leistungsangebote gemacht werden, die die Spielenden doch zu Zahlungen im Spielverlauf animieren. Die
Ums&#228;tze dieses Gesch&#228;ftsmodells machen heute schon gesch&#228;tzt gut ein Viertel des Gesamtumsatzes aus. Im
Umkehrschluss bedeutet dies, dass zu erwarten ist, dass KI-Technologien noch mehr Einfluss als zuvor beschrieben
auf die inhaltliche Gestaltung von Spielen nehmen werden.
Zusammengefasst zeigen sich erhebliche Auswirkungen durch den generellen Einsatz von digitalen
Technologien im Mediensektor. In einigen Bereichen, wie bei Games oder auch bei Intermedi&#228;ren, bedeutet dies seit
Jahren ein stetiges Wachstum. F&#252;r andere, insbesondere die Anbieter von journalistischen Inhalten, gehen die
Ums&#228;tze signifikant zur&#252;ck. Inwiefern KI-Technologien in Zukunft diese Trends noch weiter versch&#228;rfen, h&#228;ngt u. a.
vom Einsatzgebiet ab. Werden die Technologien zur Kostensenkung bei der Produktion &#8211; wie schon ausgef&#252;hrt
&#8211; eingesetzt, k&#246;nnen gegebenenfalls die entfallenden Ums&#228;tze teilweise kompensiert werden. Konzentrieren sich
die Eins&#228;tze von KI-Technologien auf die Distribution, bleibt zu erwarten, dass sich insbesondere im
Informationsmediensektor die Lage weiter versch&#228;rfen wird. Wie schon festgestellt wurde, bedeutet dies grunds&#228;tzlich
auch, dass die Konzentration in den Medienm&#228;rkten ansteigt. Daher lohnt ein weiterer Blick auf die
Medienkonzerne.
4.2.2 Medienkonzerne
Neben der vorangegangenen Betrachtung der M&#228;rkte ist eine weitere wichtige Unterteilung demnach auch
danach vorzunehmen, ob die Medienangebote eher auf einen Sprach- und Kulturraum bezogen sind, d. h. prim&#228;r 
im Inland produziert werden, oder ob es sich meist um die Unterhaltungsmedienangebote multinationaler
Konzerne handelt. Neben den noch zu behandelnden Plattformanbietern hat dabei die Konzentration gerade im
internationalen Markt seit Jahren deutlich zugenommen. Eine feindifferenzierte Betrachtung der einzelnen Teilm&#228;rkte 
muss an dieser Stelle ausbleiben, allerdings zeigt schon der Blick auf die Entwicklung der Marktkapitalisierung
der globalen Medienkonzerne deutliche Tendenzen. Wie stark dabei generell die Rolle der Digitalisierung und 
insbesondere die der KI ist, ergibt sich letzten Endes auch aus den Angeboten. 
Ein Blick auf die aktuellen globalen Top-50-Medienkonzerne1815 zeigt deutlich, wie stark dabei heute schon die
Medienintermedi&#228;re das Gesch&#228;ft bestimmen. Weiterhin ist zu beobachten, wie gro&#223; inzwischen die
Umsatzdimensionen der globalen Medienkonzerne im Zehnjahresvergleich sind. Lagen die Ums&#228;tze der damaligen
&#8222;Spitzenreiter&#8220; im Jahr 20081816 mit Time Warner (ca. 34 Milliarden Euro Umsatz) und Disney (ca. 25 Milliarden
Euro Umsatz) noch in Gr&#246;&#223;endimensionen, die auch der national gr&#246;&#223;te Medienkonzern, Bertelsmann 
(ca. 19 Milliarden Euro), erreichen konnte, sind die heutigen globalen Markf&#252;hrer mit AT&amp;T (ca. 145 Milliarden
Euro) und Alphabet (bzw. Google ca. 116 Milliarden Euro) signifikant gr&#246;&#223;er, wohingegen Bertelsmann immer
noch bei ca. 18 Milliarden Euro Jahresumsatz verharrt.
1814 Vgl. DFC Intelligence (2019): Online console video game sales expected to pass packaged sales in 2019.
1815 Vgl. Bundeszentrale f&#252;r politische Bildung (2018): Ranking &#8211; Die 50 gr&#246;&#223;ten Medienkonzerne 2018 sowie Bundeszentrale f&#252;r
politische Bildung (2019): US-Dominanz an der Spitze: Neues Ranking der gr&#246;&#223;ten Medien- und Wissenskonzerne der Welt 2018. Es
fehlen in der Beurteilung allerdings einige indische Anbieter, deren Marktdaten nicht offenliegen. Dar&#252;ber hinaus fehlen auch
Angaben &#252;ber die staatlichen Fernsehkonzerne Chinas (CCTV), die im Zweifel noch viel gr&#246;&#223;er ausfallen. Auch unklar ist, warum Japans
gr&#246;&#223;ter Medienkonzern, Nippon T&amp;T Corp. nicht in der Liste auftaucht.
1816 Vgl. Institut f&#252;r Medien- und Kommunikationspolitik gGmbH (2008): Ranking &#8211; Die 50 gr&#246;&#223;ten Medienkonzerne 2008.
Abbildung 12 
Ranking der gr&#246;&#223;ten Medienkonzerne weltweit nach Umsatz in Milliarden Euro 20181817 
0 20 40 60 80 100 120 140 160 
AT&amp;T Inc. (Dallas / USA) 
News Corp. Ltd. / 21st Century Fox (New York&#8230; 
 
 
   
 
     
     
 
   
   
    
 
       
  
                                               
       
 
 
 
 
 
 
 
  
144,59 
Alphabet Inc. (Mountain View / USA) 115,85 
Comcast (Philadelphia / USA) 80,02 
The Walt Disney Company (Burbank / USA) 50,33 
Facebook, Inc. (Palo Alto/ USA) 47,28 
Tencent Holdings Ltd. (Shenzen / China) 40,05 
Charter Comm. Inc. (St. Louis/ USA) 36,93 
33,38 
Apple Inc. (Cupertino / USA) 31,49 
Sony Entertainment (Tokyo / JP ) 31,48 
Viacom Inc./CBS Corp. (New York / USA) 23,25 
Altice Europe N.V./Altice USA, Inc.&#8230; 22,19 
Amazon.com Inc. (Seattle / USA) 20,56 
Liberty/Qurate Retail; Inc. (Eaglewood, CO /&#8230; 18,71 
Cox Communications, Inc. (Atlanta / USA) 17,78 
Diese Entwicklung sieht man f&#252;r ganz Europa, wie der Blick auf Europas Top 50 verdeutlicht. Offenkundig
haben die US- und asiatischen, prim&#228;r chinesischen Konzerne &#252;berproportional deutlich von der Digitalisierung
bzw. der Transformation der Medienm&#228;rkte profitiert, wohingegen die europ&#228;ischen Medienkonzerne ihre
Ums&#228;tze kaum signifikant vergr&#246;&#223;ern konnten. Diese Entwicklungen sind nicht direkt auf den Einsatz von KI-
Technologien &#252;bertragbar. Es zeigt sich aber, dass europ&#228;ische oder auch nationale Konzerne die Digitalisierung im
internationalen Gesch&#228;ft nicht nutzen konnten. Dies f&#252;hrt mittelfristig zu einem doppelten Dilemma: Einerseits
verst&#228;rken sich aufgrund immer st&#228;rker wachsender Kapitalkraft die Tendenzen zur Konzentration, und
andererseits wird auch ein &#8222;Aufholen&#8220;, wie immer man dies definieren mag, immer unwahrscheinlicher. Wenn aber die
global agierenden Konzerne die Dominanz ausbauen k&#246;nnen, dabei die Steuersysteme weiter gegeneinander
ausspielen und durch den Einsatz von KI-Systemen auch noch die Kosten senken, sind fehlende Steuereinnahmen
und Arbeitsplatzabbau in den nationalen Medienunternehmen die logische wirtschaftliche Folge. 
1817 Statista (2018): Ranking der gr&#246;&#223;ten Medienkonzerne weltweit nach Umsatz 2018.
Abbildung 13
Ranking der gr&#246;&#223;ten Medienkonzerne in Europa nach ihrem Umsatz im Jahr 2018
(in Milliarde Euro)1818
0 5 10 15 20 25 
Altice Group (Amsterdam / Niederlande) 22,19 
Bertelsmann SE &amp; Co. KGaA (G&#252;tersloh /&#8230; 17,67 
Vivendi S.A. (Paris / Frankreich) 13,93 
RELX Group (London / Gro&#223;britannien) 8,47 
Lagard&#232;re Media (Paris / Fankreich) 7,26 
ARD (Berlin, M&#252;nchen / Deutschland) 6,61 
BBC (London/ Gro&#223;britannien) 5,7 
Nielsen Holdings plc (Haarlem / Niederlande) 5,52 
Spotify AB (Stockholm / SWE) 5,26 
Pearson plc (London/ Vereinigtes K&#246;nigreich) 4,67 
Wolters Kluwer nv (Amsterdam/ Niederlande) 4,26 
ProSiebenSat.1 SE (Unterf&#246;hring / Deutschland) 4,01 
ITV plc (London / Gro&#223;britannien) 3,63 
Wie angedeutet, k&#246;nnen nicht alle Teilsegmente der Medien hier betrachtet werden. Aber die bei Anbietern von
Inhalten sicherlich am st&#228;rksten zu beobachtende Tendenz liegt im Bereich der Serienangebote bei den
audiovisuellen Medien und daran gekoppelten neuen, prim&#228;r webbasierten Distributionskan&#228;len &#252;ber Portale bzw.
Plattformen. Hier wird das Zusammenspiel zwischen den gro&#223;en Plattformanbietern und den Anbietern von
Medieninhalten besonders deutlich. Nachdem letztere die daraus resultierende Profitabilit&#228;t erkannt haben, setzen auch
sie verst&#228;rkt auf den Einsatz solcher Plattformen, wie j&#252;ngst z. B. Disney, einer der weltweit gr&#246;&#223;ten
Unterhaltungsmedienkonzerne, mit seiner eigenen Streaming-Plattform Disney Plus. Diese steht synonym f&#252;r eine ganze
Reihe weiterer Entwicklungen auf diesem Gebiet. Dabei geht es eben nicht nur um die digitale Transformation
der Medien(teil)industrien, sondern auch um die Frage, wie Medienkonzerne mit starken Eigenmarken ebenso
an werthaltiges Datenmaterial und somit an die Grundlage f&#252;r die Nutzung von KI kommen k&#246;nnen wie die
Plattformanbieter.
Umgekehrt verlieren solche Konzerne, wie der weltweit umsatzst&#228;rkste, AT&amp;T1819, immer mehr Kundinnen und
Kunden im Bereich des klassischen Fernsehens. Etwas verk&#252;rzt formuliert sind die Tendenzen, die f&#252;r die
nationalen Medienm&#228;rkte beschrieben wurden, nat&#252;rlich auch &#8211; wenngleich f&#252;r andere Segmente &#8211; in internationalen
M&#228;rkten zu beobachten. Bricht man die damit verbundene Herausforderung auf eine strategische Fragestellung
herunter, stellt sich die Frage, wie schnell und wie effektiv im Vergleich zu den bisherigen Gesch&#228;ftsmodellen
der Umbau der Konzerne in Richtung digitalbasierter Gesch&#228;ftsmodelle erfolgt. Dabei kann KI ein wesentlicher
Treiber sein.
1818 Statista (2019): Ranking der gr&#246;&#223;ten Medienkonzerne in Europa nach ihrem Umsatz im Jahr 2018 (in Milliarden Euro).
1819 Wie stark dabei die &#220;bernahme von Time Warner f&#252;r die globale Medienindustrie wirkte, kann man an daraus weiter zunehmenden
Konzentrationstendenzen sehen. Vgl. Jahn (2018): Die Medienbranche steht nach dem AT&amp;T Urteil vor einer Fusionswelle.
4.2.3 Intermedi&#228;re: Plattformen und soziale Medien
Intermedi&#228;re: Plattformen
Grunds&#228;tzlich kann man die Informationsintermedi&#228;re im Zusammenhang mit Medien &#246;konomisch recht sauber
in zwei Klassen unterteilen: Dies sind einerseits diejenigen Plattformanbieter, die prim&#228;r Distributionsfunktionen
wahrnehmen, insbesondere Streaming-Plattformen. Diese sollen als Intermedi&#228;re (Plattformen) bezeichnet
werden. Andererseits gibt es diejenigen Social-Media-Plattformen, die sich schwerpunktm&#228;&#223;ig auf kommunikative
Aufgaben beziehen. Diese sollen hier als Intermedi&#228;re (soziale Medien) beschrieben werden. &#214;konomisch
betrachtet unterscheiden sich die Gesch&#228;ftsmodelle der beiden Intermedi&#228;rtypen, was sich, zumindest sekund&#228;r,
auch auf den Einsatz von KI auswirkt. W&#228;hrend Intermedi&#228;re (Plattformen) h&#228;ufig Mischfinanzierungsmodelle
aufweisen (Abonnement, Einmalkauf, Werbung), konzentrieren sich Intermedi&#228;re (soziale Medien) im
Normalfall allein auf den Werbemarkt. 
Folglich bedeutet dies f&#252;r Intermedi&#228;re (Plattformen), dass sie Kundenbed&#252;rfnisse befriedigen. Ein Beispiel: Eine
Streaming-Plattform1820 f&#252;r audiovisuelle Inhalte mit einem Abonnement-Gesch&#228;ftsmodell wird &#252;ber KI-
Mechanismen zur Vorauswahl bestimmte Serien-Angebote weiterentwickeln; andere, die das Publikum ablehnt, eher
nicht. Handelt es sich dabei um Eigenproduktionen, werden diese gestoppt. Handelt es sich hingegen um
zugekaufte Inhalte (also &#252;bernimmt die Plattform nur distributive Funktionen), werden im Zweifel Inhalte nicht weiter
eingekauft oder es werden auf Basis der sehr genauen Datenauswertungen Produktionen beendet.1821 Dabei wird
aber nicht nur das Auswahlverhalten beobachtet, sondern auch, nach welchen Stichworten dabei gesucht wird, 
zus&#228;tzliche Metadaten (u. a. demografische Angaben, zus&#228;tzliche exogene Daten (Wetter, Ort, Uhrzeit etc.)
sowie Nutzungsintensit&#228;ten, Zeiten etc. Mit diesen Daten werden die Recommendation-Engines gef&#252;ttert.1822 Auf 
dieser Basis lassen sich entsprechende Klassifizierungssysteme bauen und die Bibliotheken, auch vor dem
Hintergrund entsprechender Investitionen, aber auch Zuschauerstr&#246;me organisieren.1823 Dar&#252;ber hinaus &#252;bernimmt
die KI ebenfalls im Hintergrund die Steuerung der Bildkompressions-Qualit&#228;t der zur Verf&#252;gung gestellten
audiovisuellen Inhalte, was zur Folge hat, dass damit auch der Datenstrom stark beeinflusst werden kann. Aus
&#246;konomischer Sicht sind dies alles wichtige Parameter, will man die Tragkraft von KI im Zusammenhang
bewerten, denn neben der Investition in Inhalte investieren die Intermedi&#228;re (Plattformen) gerade an der Stelle sehr
viel Geld, damit sie auf valider Datenbasis bzw. durch die Nutzung von KI-Technologien entsprechend profitabel
agieren k&#246;nnen. In Deutschland dominieren derzeit fast ausschlie&#223;lich US-amerikanische Anbieter das Gesch&#228;ft
im Audio- und audiovisuellen Bereich.
Allein der Blick auf den Marktwert der gr&#246;&#223;ten Internetunternehmen weltweit im Jahr 2019 zeigt auch indirekt
die enorme Bedeutung der Intermedi&#228;re f&#252;r die Medien(teil)m&#228;rkte. Allein die ersten acht in dieser Liste
aufgef&#252;hrten Konzerne bieten alle in unterschiedlichen Formen in vielen Teilm&#228;rkten mediale Inhalte an. Dabei
beschr&#228;nken sich die Konzerne nicht mehr ausschlie&#223;lich auf die Mediendistribution, sondern sind hochaktiv auch 
in die Medienproduktion verschiedenster audiovisueller Medieninhalte (z. B. Serien, News, Shows) sowie
digitaler Medieninhalte (z. B. Games) eingebunden. Anders als die reinen Medienkonzerne haben die Intermedi&#228;re
den gro&#223;en Wettbewerbsvorteil, dass sie schon sehr gro&#223;es Wissen &#252;ber KI im Feldeinsatz haben. Dar&#252;ber hinaus
besitzen diese Intermedi&#228;re erhebliche Daten, sodass Programmangebote stark zielgruppengerecht aufbereitet
und &#252;ber die jeweiligen Plattformen beworben werden k&#246;nnen.
1820 Das beschriebene Gesch&#228;ftsmodell bedeutet in realen Zahlen heute f&#252;r Netflix einen Umsatz von ca. 20 Milliarden US-Dollar bei
ca. 2 Milliarden US-Dollar Gewinn. F&#252;r Amazon Prime oder auch f&#252;r Apple TV Plus liegen keine Werte vor.
1821 Vgl. Rodriguez (2019): Wie Netflix euch beim Streaming zuschaut &#8211; und damit euer Sehverhalten massiv beeinflusst.
1822 Vgl. fuse-ai.de (2019): K&#252;nstliche Intelligenz &#8211; Individualsiertes Netflix.
1823 Vgl. Vena (2018): Netflix bekommt ein Upgrade von der K&#252;nstlichen Intelligenz.
Abbildung 14
Marktwert in Milliarden US-Dollar nach B&#246;rsenkapitalisierung 20191824 
0 200 400 600 800 1000 1200 
1.007 
888 
875 
741 
495 
402 
398 
158 
136 
134 
125 
77 
75 
52 
51 
Microsoft 
Amazon 
Apple 
Alphabet 
Facebook 
Alibaba 
Tencent 
Netflix 
Adobe 
PayPal 
Salesforce 
Booking.com 
Uber 
Recruit Holdings 
Service Now 
Wie schon angedeutet, ist es nur in den seltensten F&#228;llen m&#246;glich, den Markteffekt des Einsatzes von KI allein
zu benennen. Allerdings sieht man recht deutlich, wie stark die Plattformunternehmen hier auch ihre eigenen
Technologien und Datengrundlagen f&#252;r unterschiedliche Zwecke skalieren k&#246;nnen. Im Umkehrschluss gilt, dass
reine Medienanbieter sehr h&#228;ufig in konkrete KI-Technologien investieren m&#252;ssen, wohingegen diese
Plattformen generische Technologien entwickeln, die sie dann &#252;ber die verschiedenen Gesch&#228;ftsbereiche
gewinnbringend einsetzen k&#246;nnen. 
1824 Statista (2019): Marktwert der gr&#246;&#223;ten Internetunternehmen weltweit im Juni 2019.
Abbildung 15
Umsatz von ausgew&#228;hlten Internet- und Tech-Unternehmen weltweit im Jahr 20191825
300 
250 
200 
150 
100 
50 
0 
Alphabet Microsoft Facebook 
Eine gewisse Sonderstellung nehmen in dieser Konstellation Microsoft und Google ein. Microsoft h&#228;lt sich in
den Medienm&#228;rkten relativ zur&#252;ck und bietet lediglich &#252;ber seine Spieleplattform Xbox auch eigene Inhalte an,
beschr&#228;nkt sich aber im Kern auf das Softwaregesch&#228;ft. Auff&#228;lliger hingegen ist das Gesch&#228;ftsmodell bei
Alphabet bzw. Google. Laut Firmenangaben stammen trotz der enormen Gr&#246;&#223;e und Diversifikation des
Technologiekonzerns von den 162 Milliarden US-Dollar Jahresumsatz gut 160 Milliarden (davon allein 135 Milliarden US-
Dollar aus dem Werbemarkt) aus dem Google-Kerngesch&#228;ft, wobei auch YouTube dazugeh&#246;rt. Geht man davon
aus, dass Google im Rahmen seiner Suchmaschine1826 extrem stark auf KI baut, ist deren Einfluss auf die
Medienteilm&#228;rkte nicht zu untersch&#228;tzen. Insbesondere auf den Nachrichten- und Informationsmarkt wirkt sich dies
aus.1827 Googles Sonderstellung f&#252;r die Entwicklung der Medienm&#228;rkte ist aber nicht nur durch die
Suchmaschine, die auf KI basiert, gegeben, sondern auch durch den massiven KI-Einsatz bei der Videoplattform
YouTube, die im Jahr 2019 mit &#252;ber 2 Milliarden regelm&#228;&#223;ig Nutzenden (CNET; YouTube 2020) zu Recht als
gr&#246;&#223;te Plattform weltweit gilt. Neben dem Premium-Angebot sind auf der Plattform sehr viele urheberrechtlich
gesch&#252;tzte Werke gut zug&#228;nglich verf&#252;gbar. Dar&#252;ber hinaus produzieren zahllose Nutzerinnen und Nutzer
permanent neue Inhalte.1828 Googles dritter Zugang zu den Medienm&#228;rkten ist insbesondere der Markt f&#252;r Games, 
aber auch f&#252;r andere Medienanwendungen &#252;ber den PlayStore, welcher der prim&#228;re Zugang zu Applikationen
und Inhalten f&#252;r mobile Endger&#228;te ist. Auch hier produziert Google im Kern nur f&#252;r das Betriebssystem Android
notwendige Applikationen selbst, &#252;berl&#228;sst aber das Portal unter Gewinnbeteiligung Dritten. Fasst man
zusammen, so ist es ein Charakteristikum von Google bzw. Alphabet, im Kern von den medialen Leistungen Dritter zu 
profitieren und KI im Wesentlichen einzusetzen, um Inhalte zu sortieren und zur Verf&#252;gung zu stellen. Trotz
dieser Beschr&#228;nkung ist aufgrund der hohen Marktdominanz von Googles KI-basierter Suchmaschine ein
erheblicher, wenn nicht monopolartiger Einfluss auf alle Medienm&#228;rkte gegeben; deswegen profitiert Google damit
&#252;berproportional vom Werbemarkt.
281 
Amazon 
260 
162 
126 
71 
Apple 
U
m
sa
tz
 in
 M
illi
ar
de
n 
U
S-
D
ol
la
r 
1825 Statista (2019): Umsatz von ausgew&#228;hlten Internet- und Tech-Unternehmen weltweit im Jahr 2019.
1826 Laut NetMarketShare liegt der Marktanteil der Suchmaschine im Jahr 2020 bei ca. 70 Prozent bei Computern und bei 90 Prozent bei
mobilen Endger&#228;ten, was nicht zuletzt nat&#252;rlich mit der Dominanz des Betriebssystems Android zusammenh&#228;ngt. Vgl. Statista
(2020): Marktanteile der Suchmaschinen weltweit nach mobiler und station&#228;rer Nutzung im Juni 2020.
1827 Die damit zusammenh&#228;ngende Marktmacht und daraus generierte Werbeeinnahmen wurden vielfach kritisiert. Ein Ergebnis dieser
Proteste ist das sowohl in Deutschland schon eingef&#252;hrte, nun auch europ&#228;isch verankerte, aber ebenso umstrittene
Leistungsschutzrecht. Vgl. Institut f&#252;r Urheber- und Medienrecht e. V.: Leistungsschutzrecht f&#252;r Presseverleger.
1828 Wie umstritten insbesondere die Nutzung neuen urheberrechtlich gesch&#252;tzten Materials dabei ist, zeigte der erbitterte Streit im
Rahmen der Nivellierung der EU-Urheberrechtrichtlinie im Jahr 2019.
Intermedi&#228;re: soziale Medien 
Die Intermedi&#228;re (soziale Medien), die Soziale-Medien-Konzerne, verfolgen einen anderen Ansatz. Kern des 
Angebotes sind nicht den Massenmedien vergleichbare 1:n-Medienbeziehungen, sondern vor allem auf
Interaktion angelegte, reziproke m:n-Medienbeziehungen. Ca. 3,5 bis 3,8 Milliarden Menschen (Hootsuite 2020) nutzen 
dabei im Jahr 2020 regelm&#228;&#223;ig diverse Social-Media-Angebote. Globaler Spitzenreiter ist dabei der asiatische 
Raum mit weit &#252;ber 1,5 Milliarden Nutzenden. 
Abbildung 16 
Ranking der gr&#246;&#223;ten Social Networks und Messenger nach der Anzahl der Nutzer im Januar 2020 
weltweit (in Millionen) 1829 
Facebook 
YouTube 
WhatsApp* 
Facebook Messenger* 
Weixin/WeChat 
Instagram* 
Douyin/TikTok 
QQ 
QZone 
Sina Weibo 
Reddit 
Snapchat** 
Twitter** 
Pinterest 
Kuaishou 
 
 
 
 
  
    
   
    
 
 
                                               
       
2.000 
1.600 
1.300 
1.151 
1.000 
800 
731 
517 
497 
430 
382 
340 
322 
316 
2.449 
* Die Plattform hat in den vergangenen zw&#246;lf Monaten keine Nutzer-Zahlen ver&#246;ffentlicht, sodass es m&#246;glich ist, dass die Werte nicht
auf dem aktuellsten Stand sind.
** Es werden von der Plattform keine Daten zu den monatlich aktiven Nutzern ver&#246;ffentlicht. Die Angabe f&#252;r Twitter und Snapchat
basieren auf den aktuellsten Angaben zur Reichweite des Werbepublikums.
National wie auch international dominiert der Facebook-Konzern den Markt. Der Umsatz von Facebook hat sich 
dabei in nur knapp zehn Jahren um den Faktor 35 erh&#246;ht.
1829 Statista (2020): Social Networks mit den meisten Nutzern weltweit 2020.
Abbildung 17
Marktanteile von Social-Media-Portalen in Deutschland von M&#228;rz 2019 bis August 2020 1830 
0,0% 
10,0% 
20,0% 
30,0% 
40,0% 
50,0% 
60,0% 
70,0% 
80,0% 
90,0% 
100,0% 
M&#228;r 
'19 
Apr 
'19 
Mai 
'19 
Jun 
'19 
Jul 
'19 
Aug 
'19 
Sep 
'19 
Okt 
'19 
Nov 
'19 
Dez 
'19 
Jan 
'20 
Feb 
'20 
M&#228;r 
'20 
Apr 
'20 
Mai 
'20 
Jun 
'20 
An
te
il 
an
 d
en
 P
ag
e 
Vi
ew
s 
Facebook Pinterest YouTube Twitter Instagram Tumblr LinkedIn reddit Andere 
Wies Facebook im Jahr 2010 einen Umsatz von ca. 2 Milliarden US-Dollar aus, waren es im Jahr 2019 nach
eigenen Angaben ca. 70,5 Milliarden US-Dollar bei einem ausgewiesenen Gewinn von ca. 18,5 Milliarden
US-Dollar. Dies ist umso erstaunlicher, als Facebook &#8211; trotz des Cambridge-Analytica-Skandals im Jahr
2017/2018 &#8211; nach eigenen Angaben seitdem seine Nutzerbasis weiter auf 2,6 Milliarden Nutzende weltweit
ausbauen konnte. Das Kerngesch&#228;ft ist, wie bei fast allen Social-Media-Angeboten, schwerpunktm&#228;&#223;ig ein rein
werbebasiertes Gesch&#228;ftsmodell, sodass fast 100 Prozent der Einnahmen als Werbeeinnahmen anzusehen sind.
Welche Rolle KI hier bei der personalisierten Werbung spielt, l&#228;sst sich zwar nicht genau ermitteln, aber der hohe
Personalisierungsgrad wird allen Nutzenden schnell deutlich. Das Hauptgesch&#228;ft hat sich dabei immer st&#228;rker
auf den mobilen Sektor verlagert. Es wird prognostiziert, dass das Verh&#228;ltnis inzwischen bei 3:1 liegt, sprich &#252;ber
75 Prozent der Social-Media-Nutzung mit mobilen Endger&#228;ten erfolgt. Neben der Tatsache, dass damit soziale
Medien im Gegensatz zu den traditionellen Medienm&#228;rkten sehr stark von den Entwicklungen im
Mobilfunksektor profitieren, bedeutet dies auch, dass Social-Media-Anbieter permanent ihre Angebote platzieren k&#246;nnen.
Wenngleich nicht in derselben Gr&#246;&#223;endimension, so wachsen neben dem Kerngesch&#228;ft &#8222;Facebook&#8220; auch weitere
Gesch&#228;ftsbereiche zusehends (z. B. Instagram). F&#252;r den westlichen Kulturraum von einer Monopolstellung zu
sprechen, w&#228;re nicht unangebracht. Durch die enormen Datenvolumina, die Facebook aus dem Kern sowie seinen 
Derivaten, inklusive angeschlossener Messenger-Dienste, gewinnen kann, ist der Konzern privilegiert, was die
Nutzung von KI-Algorithmen zur St&#228;rkung des Umsatzes betrifft. 
Die meisten Social-Media-Anbieter profitieren also in zweiseitigen M&#228;rkten doppelt durch die Nutzung von KI-
basierten Empfehlungssystemen. Einerseits k&#246;nnen sie den Nutzenden ein individualisiertes und demnach
durchaus attraktives Angebot unterbreiten und gleichzeitig selbige Systeme auch f&#252;r die Befriedigung ihrer
Werbekunden nutzen.1831 Schmalensee und Evans sprechen in dem Zusammenhang von einem &#8222;Catalyst System&#8220;.1832 
Neben den Kommunikationsfunktionen (egal ob Wort, Bild, Video, Audio etc.) im Sinne der interpersonellen
Kommunikation profitiert Facebook insbesondere auch davon, seit einigen Jahren zu einem der wichtigsten
Nachrichtenportale aufgestiegen zu sein.1833 Dabei steuern die Algorithmen letzten Endes
Verbreitungsgeschwindigkeiten von Inhalten, die Nutzende ein- oder bereitgestellt haben. Dies scheint aber nicht genug: Facebook
experimentiert derzeit weiter damit, sich als Nachrichtenaggregator zu positionieren und selbst aktiv
Medieninhalte zu verbreiten.1834 
1830 Statista (2020): Marktanteile von Social-Media-Portalen in Deutschland von M&#228;rz 2019 bis Juni 2020.
1831 Vgl. Kwong et al. (2012): Facebook: Data Mining the World&#8217;s Largest Focus Group.
1832 Evans und Schmalensee (2007): Catalyst code.
1833 Vgl. welt.de (2015): Facebook mutiert zum Nachrichtenportal.
1834 Vgl. zeit.de (2019): Facebook startet neues Nachrichtenangebot f&#252;r seine App; Ohne zu tief in eine Facebook-Analyse abzugleiten,
l&#228;sst sich damit aber festhalten, dass der h&#228;ufig seitens des Konzerns betonte Charakter, ein technologiegetriebenes
Plattformunternehmen zu sein, zumindest an der Stelle erodiert. Die Folge aus regulatorischer Perspektive w&#228;re, dass man Facebook dann der
Medienregulation deutlich leichter unterwerfen k&#246;nnte.
4.2.4 Exkurs: KI im medialen Marketing (Werbung)
Nicht vergessen werden darf ein weiterer Faktor im Zusammenhang mit KI und Medien. Aufgrund der Struktur
der Medienteilm&#228;rkte ist es relevant, sich auch dar&#252;ber klar zu werden, welchen enormen Einfluss KI auf die 
Personalisierung von Werbung in den Medienm&#228;rkten nimmt und weiter nehmen wird.1835 Ausgehend von der
Bedeutung der Werbem&#228;rkte f&#252;r die Medienfinanzierung wird es zuk&#252;nftig interessant sein, ob und wie diese
sich entwickeln. Das Daten- und Statistikportal Statista legt dazu aktuell folgende Prognosen vor:
Abbildung 18
Ausgaben f&#252;r Suchmaschinenwerbung weltweit in den Jahren 2017 und 2018 sowie
eine Prognose bis 2023 (in Millionen Euro)1836
Desktop Mobil 
160000 
63.172 69.167 
75.456 81.289 
86.076 89.642 92.051 27.053 
32.481 
37.782 
42.567 46.575 
49.689 52.036 
0 
20000 
40000 
60000 
80000 
100000 
120000 
140000 
Au
sg
ab
en
 in
 M
illi
on
en
 E
ur
o 
2017 2018 2019* 2020* 2021* 2022* 2023* 
* Prognose
Abbildung 19
Ausgaben f&#252;r Social-Media-Werbung weltweit in den Jahren 2017 und 2018 
sowie eine Prognose bis 2023 (in Millionen Euro)1837
Desktop Mobil 
18.673 20.805 22.320 23.758 
25.080 26.125 26.831 
36.725 
46.699 
57.302 
66.834 
74.512 
80.242 84.298 
0 
20000 
40000 
60000 
80000 
100000 
120000 
Au
sg
ab
en
 in
 M
illi
on
en
 E
ur
o 
2017 2018 2019* 2020* 2021* 2022* 2023* 
* Prognose
1835 Vgl. Moses (2019): Immer weniger Interesse an Werbung: So will die Industrie mit KI k&#252;nftig Bannerblindheit bek&#228;mpfen.
1836 Statista (2019): Prognose der weltweiten Ausgaben f&#252;r Suchmaschinenwerbung bis 2023.
1837 Statista (2019): Ausgaben f&#252;r Social-Media-Werbung weltweit in den Jahren 2017 und 2018 sowie eine Prognose bis 2023.
Verglichen mit &#228;hnlichen Prognosen scheint dies eher eine konservative Sch&#228;tzung. Das kontinuierliche
Wachstum bedeutet aber, dass an anderen Stellen stark eingespart wird, denn die Ausgaben der Werbetreibenden sind
letztlich begrenzt. Aufgrund des h&#246;heren Wertes der Online-Werbung durch die zielgenaue Positionierung im
Vergleich zur Streuwirkung der traditionellen Werbeformen zeigen sich signifikante Auswirkungen auf
traditionelle Medienangebote, die bereits weiter oben thematisiert wurden.1838 Letzten Endes schaffen somit auch die
Informationsintermedi&#228;re, insbesondere die Social-Media-Anbieter, Werberaum, der durch KI-Systeme eine
zielgenaue Ansprache von Kundinnen und Kunden zul&#228;sst. Insgesamt sch&#228;tzen die Expertinnen und Experten von
Statista, dass der digitale Werbemarkt im Jahr 2020 ca. 365 Milliarden US-Dollar ausmacht, Tendenz
steigend.1839 
4.2.5 Marktwirtschaftliche Einordnung der KI-Relevanz in den Medien
Sowohl in den traditionellen Mediensegmenten als auch in den fr&#252;her als &#8222;Neue Medien&#8220; bezeichneten digitalen
Mediensegmenten folgt nahtlos auf die starke Digitalisierungswelle die KI-Welle. Wie schon skizziert, wandeln
sich Produktions- und Distributionsmethoden in und um die Medien durch KI stark. Die wirtschaftlichen
Auswirkungen sind bis heute nicht exakt auf KI-Effekte r&#252;ckf&#252;hrbar und statistisch erfassbar, wie die &#246;konomischen 
Rahmendaten veranschaulichen. Wohl aber ist absch&#228;tzbar, dass sich die Anforderungen an die Arbeitspl&#228;tze in
den Medien signifikant ver&#228;ndern werden, gegebenenfalls werden auch Arbeitspl&#228;tze wegfallen durch
Automatisierungsprozesse und Kostendruck. Auch ist offenkundig, dass sich der Wettbewerb und somit in einzelnen
Segmenten die Medienkonzentration durch den Einfluss von KI signifikant versch&#228;rfen. Insbesondere auf
Medienplattformen sind die durch KI m&#246;glichen Personalisierungen des Angebotes durch Empfehlungssysteme und
deren Einfluss auf m&#246;gliche Produktionsentscheidungen dabei von hoher Relevanz. 
Ein bisher (viel zu) wenig betrachtetes Segment ist die Finanzierung der Medienproduktionen. Auch wenn dies
nicht prim&#228;r im Zusammenhang mit KI und Medien zu vermuten ist, stellt sich die Frage doch. Denn einerseits,
wie angedeutet, werden zunehmend Finanzierungsentscheidungen auf Basis von KI-basierten Systemen
getroffen (wie es heute schon einige Studios und Streaming-Plattformen vormachen), andererseits gilt es aber auch zu
&#252;berpr&#252;fen, ob und, wenn ja, welche Auswirkungen z. B. die Nutzung von KI f&#252;r die Entwicklung von
Medienprodukten hinsichtlich der Senkung von Kosten real haben kann. Daran schlie&#223;t sich unmittelbar die Frage 
der Nutzung bzw. der Kriterien &#246;ffentlicher F&#246;rderung von Medienproduktionen an. Dies betrifft nicht nur die
Film-1840, sondern auch andere Medienf&#246;rderungen, z. B. in Deutschland die Gamesf&#246;rderung1841. Die hohe
Relevanz, sich mit dieser Frage zu besch&#228;ftigen, leitet sich auch daraus ab, dass vielfach Medienf&#246;rderung zu
globalen Wettbewerbssituationen f&#252;hrt, z. B. in den USA durch gro&#223;e Steuererleichterungen 1842 oder eben, wie
vielfach in Europa, durch direkte Subventionen oder Mischmodelle. KI kann und wird dabei in
unterschiedlichsten Formen zum Kriterium werden: Aspekte der Technologief&#246;rderung, Aspekte der Kostenreduktion, Aspekte
der Qualit&#228;t und Meritorik etc. Schlie&#223;lich &#8211; und darin liegen heute schon die gr&#246;&#223;ten Hebelwirkungen des
Einsatzes von KI-Technologien in den Medien &#8211; wird zu beobachten sein, inwiefern sich die Gesch&#228;ftsmodelle
ver&#228;ndern werden. 
Erstens: Bisherige Mischfinanzierungen durch Verkauf und Werbung oder auch rein werbebasierte
Gesch&#228;ftsmodelle werden sich ver&#228;ndern (m&#252;ssen). Der Einbruch der Werbem&#228;rkte bei den klassischen Printmedien
veranschaulicht sehr gut, dass in Zukunft nur diejenigen am Werbemarkt partizipieren werden, die in der Lage sind,
auch hier kompatible Schnittstellen zu bieten, sodass auch Werbetreibende entsprechende Vorteile von KI nutzen
k&#246;nnen &#8211; folglich ist dies f&#252;r traditionelle datentr&#228;gergebundene Medien ein schrumpfender Markt. Dies wird
aber im Umkehrschluss politisch gesehen erhebliche Fragen hinsichtlich des Datenschutzes aufwerfen. Heute
1838 Vgl. Pietras (2019): Wie KI Werbung besser machen soll.
1839 Am konkreten Beispiel wird es schnell klarer: Die Ausgaben f&#252;r Social Media-Werbung liegen im Jahr 2020 bei ca. 3 Milliarden
Euro in Deutschland. Vgl. Statista (2019): Ausgaben f&#252;r Social-Media-Werbung in Deutschland in den Jahren 2017 und 2018 sowie
eine Prognose bis 2023. Gleichzeitig bricht der Markt f&#252;r Printwerbung stark ein. Die Nettowerbeeinnahmen der Tageszeitungen 
lagen in Deutschland im Jahr 2019 bei rund 2,08 Milliarden Euro, zehn Jahre zuvor waren es noch rund 3,7 Milliarden Euro. Vgl.
Statista (2020): Nettowerbeeinnahmen der Tageszeitungen in Deutschland in den Jahren 1995 bis 2019 (in Millionen Euro). Auch
wenn es sich sicherlich nicht um einen direkten Transfer der Gelder handelt, d&#252;rfte doch offenkundig sein, dass damit Werbegelder,
die bisher zur Finanzierung medialer Informationsangebote eingesetzt werden, nun prim&#228;r in die Genese von technologischen
Plattformen eingehen.
1840 Weitere Informationen dazu unter: https://www.bundesregierung.de/breg-de/bundesregierung/staatsministerin-fuer-kultur-und-me-
dien/medien/filmfoerderung (zuletzt abgerufen am 13. August 2020).
1841 Weitere Informationen dazu unter: https://www.bmvi.de/DE/Themen/Digitales/Computerspielefoerderung/computerspielefoerde-
rung.html (zuletzt abgerufen am 13. August 2020).
1842 Vgl. Wikipedia, Die freie Enzyklop&#228;die (2020): Movie production incentives in the United States.
schon kann man bei Social-Media-Plattformen erkennen, wie genau und differenziert personalisierte Werbung
hier ausf&#228;llt.
Zweitens: KI leistet heute schon der Entertainisierung Vorschub. Der Vorsprung, den sich die US-Konzerne
derzeit erarbeiten, bedeutet politisch gesehen f&#252;r die nationalen Medienanbieter erhebliche Herausforderungen.
Wirtschaftlich gesehen darf man dies gleich aus mehreren Gr&#252;nden nicht aus dem Auge verlieren. Prinzipiell
h&#228;ngt eine erhebliche Anzahl Arbeitspl&#228;tze direkt oder indirekt von der Medienproduktion auch in Deutschland
ab. Die stetige Bedeutung des Mediensektors durch den insgesamt gestiegenen Medienkonsum und damit
einhergehend der Bedarf nach Inhalten ist zwar prinzipiell eine Chance, aber die nationalen Produzenten von
Inhalten k&#246;nnen kaum die erforderlichen Produktionsbudgets aufbringen, um mit den internationalen
Gro&#223;produktionen mitzuhalten. Der zweite Aspekt ist die Frage der l&#228;ngerfristigen Positionierung in einem immer gr&#246;&#223;er
werdenden weltweiten Medienmarkt. Heute schon ist ein starker Wettbewerb um die Medienproduktion entstanden,
da man davon ausgeht, dass &#252;ber Skalierungseffekte gro&#223;e Erfolge im Umkehrschluss zu den voran
beschriebenen Arbeitspl&#228;tzen geschaffen werden. Durch den Einsatz von KI-Systemen versch&#228;rft und verteuert sich auch
dieser Wettbewerb. Heutige Medienf&#246;rdersysteme sind auf diese Entwicklungen noch gar nicht ausgerichtet.
Verschwimmen aber die Grenzen zwischen Medien und Mediendienstleistungen auf Plattformen immer weiter
und k&#246;nnen KI-Systeme bzw. auch die dazu notwendigen Entwicklungsexpertinnen und -experten sich quasi
aussuchen, wo Medienproduktionsstandorte entstehen, wird es sehr wichtig sein, diese Entwicklung in den
F&#246;rdersystemen fr&#252;hzeitig vorwegzunehmen. Am Beispiel wird klar: In Deutschland hat es fast f&#252;nfzehn Jahre
gedauert, bis eine anderen Standorten vergleichbare F&#246;rderung f&#252;r die Entwicklung von Computer- und
Videospielen aufgebaut wurde. Die Standorte, die lange vor Deutschland solche Systeme etabliert hatten, profitieren heute
nicht nur von der Wachstumsindustrie, sondern auch von dem damit gewachsenen generellen Digitalwissen
dieser Branche.
Abschlie&#223;end l&#228;sst sich also festhalten, dass eine Konzentration auf Plattform&#246;konomie zu kurz greift; bei dem
Thema KI und Medien geht es um weitaus mehr. Die ausschlie&#223;liche Betrachtung von Algorithmen der Steuerung
von Social-Media-Aktivit&#228;ten w&#252;rde ebenso wenig ausreichen wie der ausschlie&#223;liche Blick auf
Negativph&#228;nomene des Missbrauchs von KI-Technologien in sozialen Medien. Dies ist f&#252;r alle Stufen der Wertsch&#246;pfung von
Medien relevant und ver&#228;ndert die M&#228;rkte von Grund auf. Die Politik ist gefordert, nun geeignete Ma&#223;nahmen 
zur Modernisierung zu entwickeln, sodass auch in Deutschland der Einsatz von KI-Systemen zur Prosperit&#228;t der
Medienm&#228;rkte beitr&#228;gt und sie nicht weiter schrumpfen.
4.2.6 Handlungsempfehlungen1843 
Die enge Wechselwirkung zwischen KI und Medien wurde sowohl hinsichtlich des Einflusses von KI auf die
Produktion als auch auf die Distribution der Medien veranschaulicht (Ordnungslogik). Der Wirkungsgrad bzw.
die Hebelwirkung des Einsatzes von KI bei Empfehlungssystemen ist evident und st&#228;rkt insbesondere
Intermedi&#228;re in den Medienm&#228;rkten, selbst wenn sie keine eigenen medialen Inhalte anbieten. Eine beobachtbare
(globale) Tendenz, die schon mit der Digitalisierung der Medienm&#228;rkte einhergegangen ist, n&#228;mlich eine
zunehmende Medienkonzentration bzw. zunehmende Marktmacht einzelner Intermedi&#228;rer (sowohl Plattformen als
auch sozialer Medien) verst&#228;rkt sich dadurch sowohl in den Informations- als auch den
Unterhaltungsmedienm&#228;rkten. Eingef&#252;hrte Instrumente wie das Leistungsschutzrecht bleiben an der Stelle wirkungslos, da gro&#223;e
Plattformanbieter dies m&#252;helos umgehen k&#246;nnen bzw. die Inhalteanbieter darauf quasi angewiesen sind und
dementsprechend auf diese Einnahmen verzichten. Dasselbe gilt auch bei Social-Media-Angeboten. Will man die
Medienvielfalt erhalten, bleibt aus dieser Perspektive als sinnvolles Instrument &#8211; neben der Anwendung des
Kartellrechts &#8211; die Einf&#252;hrung einer Digitalsteuer auf die KI-basierten Dienste der Plattform- und Social-Media-
Anbieter, die dadurch &#252;berproportional an den Werbem&#228;rkten teilhaben. 
1843 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion der CDU/CSU vor [Sondervotum zu Kapitel 6 der Kurzfassung des
Berichts (&#8222;Mensch und Gesellschaft &#8220;) sowie Kapitel 4.2.6 des Berichts der Projektgruppe 6 &#8222;KI und Medien&#8220; (&#8222;Medienm&#228;rkte und KI
&#8211; Handlungsempfehlungen &#8220;) der Abgeordneten Ronja Kemmer und der Abgeordneten Marc Biadacz, Hansj&#246;rg Durz, Jan Metzler,
Stefan Sauer, Andreas Steier, Prof. Dr. Claudia Schmidtke und Nadine Sch&#246;n sowie der sachverst&#228;ndigen Mitglieder Susanne
Dehmel, Prof. Dr. Wolfgang Ecker, Prof. Dr. Antonio Kr&#252;ger und Dr. Sebastian Wieczorek].
Ziele und Aufgaben von Medienpolitik1844 
Kernaufgabe der Medienpolitik in Deutschland ist die Sicherung des freien demokratischen
Meinungsbildungsprozesses. Daf&#252;r m&#252;ssen neben der Sicherung des Zugangs zu Medien die Medienfreiheit (Presse- und
Rundfunkfreiheit), Staatsferne, Vielfaltssicherung sowie Verhinderung von Meinungsmacht und die pr&#228;ventive
Gefahrenabwehr von Missbrauch und Manipulation gew&#228;hrleistet werden. 
Die Medienlandschaft hat sich &#8211; wie zuvor ausf&#252;hrlich dargestellt1845 &#8211; dahingehend entwickelt, dass sie eine
komplexe Angebotsvielfalt aufweist; dies ist das Ergebnis der Integration neuer Medien, der Substitution
bestehender Medien, der Kombination von neuen und alten Medienakteuren etc. In Wechselwirkung mit der
fortschreitenden Konvergenz der Medien ver&#228;ndert sich das Mediennutzungsverhalten der Menschen, die
&#220;bertragungswege wachsen zusammen und auch die Medienm&#228;rkte sind immer enger verbunden.1846 Dadurch hat sich
auch die Medienpolitik bereits st&#228;rker international ausgerichtet und mit anderen Politikfeldern verkn&#252;pft. Sie ist
zu einem komplexen und fragmentierten Aufgabenfeld mit vielen unterschiedlichen Inhalten (Film, Fernsehen, 
Online-Anwendungen, Telekommunikation, Presse) geworden. Gleichzeitig ist sie durch eine Vielfalt von 
Akteuren (Organisationen, Institutionen, Unternehmen, sozialen Bewegungen, staatlichen Organen) auf
verschiedenen politischen Ebenen (L&#228;nder, Bund, EU) gepr&#228;gt. Der Staat kann in seinem Auftrag handelnde
Regulierungsbeh&#246;rden sowie nicht-staatlichen Akteuren bestimmte Gestaltungsspielr&#228;ume zuweisen. So werden
beispielsweise privaten Akteuren in Form der Ko-Regulierung zumindest Teile des Regulierungsprozesses
&#252;berantwortet und zivilgesellschaftliche Akteure werden in Aufsichts- und Kontrollinstanzen eingebunden.1847 
Die medienpolitischen Regulierungsfragen reichen von der rechtlichen Zuordnung von Angeboten &#252;ber die
Sicherung der journalistischen Qualit&#228;t bis zur Konzentrationskontrolle und den Regeln f&#252;r den Zugang zu
Internetplattformen. Ein betr&#228;chtlicher Teil medienpolitischer Entscheidungen in Deutschland wird mittlerweile durch
die Europ&#228;ische Union (mit-)gepr&#228;gt, etwa durch die Datenschutz-Grundverordnung (DSGVO) oder die
Richtlinie &#252;ber audiovisuelle Mediendienste. Dort, wo es an europapolitischer Durchsetzung mangelt, ist weiterhin
Dynamik aus den Einzelstaaten gefragt.1848 
Deutschland steht vor der Herausforderung, den rasanten Fortschritt der Informationsverarbeitung und
-verbreitung so zu gestalten, dass eine vielf&#228;ltige Medienlandschaft erhalten und der demokratische Diskurs
gew&#228;hrleistet wird. Zugleich m&#252;ssen innovative und konkurrenzf&#228;hige Medienmodelle gef&#246;rdert werden. Folglich 
m&#252;ssen &#246;konomische Interessen, Wahrung der B&#252;rgerrechte und Verbraucherschutz, Innovationsf&#246;rderung
sowie kommunikations- und kulturpolitische Ziele in Einklang gebracht werden. Dies gilt f&#252;r den Bereich der
internetbasierten, interaktiven neuen Medien ebenso wie f&#252;r den &#246;ffentlich-rechtlichen und privaten Rundfunk
sowie Printmedien mit Online-Pr&#228;senzen.
Zweifelsohne erfordern neue Aggregatsformen f&#252;r publizistische Inhalte auch neue medienpolitische
Denkweisen, Strategien und Regelwerke. Denn die bestehenden Grunds&#228;tze der Medienregulierung werden von den neuen
Akteuren, insbesondere durch die Marktmacht von einigen wenigen Informationsintermedi&#228;ren, herausgefordert.
Die Dynamik auf dem internationalen Medienparkett, technologische Weiterentwicklungen &#8211; wie der Einsatz
von KI-Systemen &#8211; und Warnungen vor einer &#8222;Schweigespirale 2.0&#8220;1849 fordern zur sensiblen Pr&#252;fung der
Rahmenbedingungen auf. 
Eine der wichtigen Fragen ist dabei, wie ein diskriminierungsfreier Zugang zu einem vielf&#228;ltigen Angebot an 
Information, Kultur und Unterhaltung zur Sicherung demokratischer Grunds&#228;tze erhalten werden kann und
wie es gelingen kann, Manipulation und Missbrauch zu verhindern. Dabei ist fortlaufend zu pr&#252;fen, ob die
vorhandenen Instrumente der Medienpolitik auch zuk&#252;nftig vor dem Hintergrund weiterer Ausbreitungen von KI-
1844 Zu diesem Kapitel liegt ein Sondervotum aus der Fraktion der AfD vor [Sondervotum zu den Kapiteln 1 und 4.3 des Berichts der
Projektgruppe 6 &#8222;KI und Medien&#8220; (&#8222;Kurzfassung des Projektgruppenberichts &#8220; und &#8222;Ziele und Aufgaben von Medienpolitik &#8220;) der
Abgeordneten Joana Cotar sowie der Abgeordneten Peter Felser und Dr. Marc Jongen].
1845 Siehe auch Kapitel 3.1 dieses Projektgruppenberichts [Grundlagen und Sachstandskl&#228;rung].
1846 Medienkonvergenz bezeichnet also auch das Zusammenwachsen bisher getrennt betrachteter Kommunikations- oder
Medienbereiche. Zum Grad der Konvergenz vgl. die medienanstalten &#8211; ALM GbR (2020): Medienvielfaltsmonitor 2019-II.
1847 Zu Grunds&#228;tzen der Medienpolitik siehe Hachmeister et al. (2018): Ein Vakuum aus Kalk&#252;l &#8211; Zum Zustand der deutschen und
europ&#228;ischen Medienpolitik, S. 4&#8211;10.
1848 Gestalt und Abl&#228;ufe der Medienpolitik sind abh&#228;ngig von der historischen Entwicklung der jeweiligen nationalen Mediensysteme 
sowie von der Struktur des politischen Systems. So ist die Medienpolitik in Frankreich eher etatistisch-pr&#228;sidentiell gepr&#228;gt, w&#228;hrend
in Deutschland F&#246;deralismus und Verfassungsrecht die Regeln und Handlungsabl&#228;ufe in der Medienpolitik bestimmen.
Gro&#223;britannien verf&#252;gt hingegen &#252;ber ein System der &#8222;checks and balances&#8220; mit zahlreichen Kommissionen und Selbstverpflichtungen.
1849 Vgl. Kreutzer (2014): Studie zu sozialen Medien &#8211; Auch im Netz regiert die Schweigespirale.
        
 
 
    
     
  
   
   
  
 
 
   
  
       
  
  
   
  
 
  
 
 
   
    
  
 
    
 
           
 
  
  
  
  
   
      
 
  
 
   
 
   
   
 
                                               
      
    
 
        
      
    
5
Systemen in der Medienwelt ausreichend sein werden. Aber &#8211; und das muss betont werden &#8211; &#252;ber allen
Regulierungszielen steht das Recht auf freie Meinungs&#228;u&#223;erung (Artikel 5 Absatz 1 des Grundgesetzes). Eingriffe in 
dieses Recht d&#252;rfen nur ausnahmsweise vorgenommen werden; daher m&#252;ssen Forderungen nach Regulierungen
auch differenziert betrachtet werden.1850 
Mit Blick auf eine m&#246;gliche Regulierung des Einsatzes von KI-Systemen kristallisiert sich f&#252;r die Medienpolitik
eine Kernaufgabe heraus, n&#228;mlich durch die Schaffung gezielter Transparenzregeln, z. B. durch unabh&#228;ngige
Datenzug&#228;nge und verpflichtende, unabh&#228;ngig &#252;berpr&#252;fbare Transparenzberichte, eine bessere
Nachvollziehbarkeit herzustellen. Denn Analysen zu etwaigen Nebenwirkungen von algorithmischen Empfehlungssystemen wie
Microtargeting, Filterblasen oder Social Bots1851 sto&#223;en stets auf den Punkt, dass das Datenmaterial, das die
Plattformen der Forschung oder den Aufsichtsbeh&#246;rden zur Verf&#252;gung gestellt haben, nicht ausreichend ist
und/oder sich seine Validit&#228;t nicht ausreichend &#252;berpr&#252;fen l&#228;sst. Mit solchen sensiblen Schnittstellen zwischen
dem Recht auf freie Meinungs&#228;u&#223;erung, Datenschutz und etwaiger destabilisierender Manipulation &#8211; die im Zuge
von digitalen Medien und KI-Einsatz hinzukommen &#8211; muss sich Medienpolitik auseinandersetzen. 
Zudem m&#252;ssen Einsatzgebiete und Implementierungsgrad ber&#252;cksichtigt werden. Die Haupt-Implementierung 
von KI-Systemen findet sicherlich im Platzieren von Inhalten bei Online-Intermedi&#228;ren statt &#8211; ebenso dort bei
der automatisierten Erkennung von illegalem Nutzerverhalten oder Verst&#246;&#223;en gegen die Nutzerbedingungen.
Hieran er&#246;ffnen sich Kontroversen, die an sp&#228;terer Stelle des Berichts vertieft werden sollen.1852 
W&#252;nschenswert ist, dass KI-Systeme im Medienbereich vor allem daf&#252;r eingesetzt werden, ein qualitativ
hochwertiges, pluralistisches Angebot sicherzustellen und Abl&#228;ufe zu verbessern. Kritisch bewertet wird dagegen,
wenn mittels KI-Systemen Inhalte bestimmt werden, denn Plattformen, Browser oder Betriebssysteme haben es
als Gatekeeper in der Hand, den Zugang zu Medieninhalten, deren Auffindbarkeit und Vermarktung zu steuern.
Ein wesentliches Ziel muss es daher im europ&#228;ischen wie im nationalen Recht sein, den Zugang und die
Auffindbarkeit zu Inhalten in der Regel diskriminierungsfrei und chancengleich zu gestalten und zu gew&#228;hrleisten.
Neue technische Vorg&#228;nge haben im Mediensektor gro&#223;e gesellschaftliche Relevanz und stellen f&#252;r Politik und
(Selbst-)Regulierung eine qualitativ neue Herausforderung dar, Werte wie Meinungsfreiheit und
Vielfaltsicherung oder Normen und Standards wie Jugend- und Verbraucherschutz, Transparenz und das
Diskriminierungsverbot effektiv durchzusetzen. Dabei besteht die Gefahr, sowohl mit einer zu strikten Medienregulierung
innovationshemmend zu wirken, als auch die Instrumente der Medienpolitik nicht flexibel genug an die rasanten
technologischen Entwicklungen anpassen zu k&#246;nnen. 
Produktion
Technologien haben Produktion und Nutzung von Medien in den letzten Jahrzehnten massiv ver&#228;ndert.
Besondere Bedeutung kommt hierbei der immer st&#228;rkeren Nutzung von digitalen Medien zu. In diesem Kontext hat
sich auch die journalistische Arbeit ver&#228;ndert. Die Nutzung von KI f&#252;r Recherche, Aufbereitung und Erstellung
medialer Inhalte muss vor diesem Hintergrund betrachtet werden. Einerseits hat KI gro&#223;es Potenzial, neue
Datenquellen automatisiert zu erfassen und auszuwerten oder einfache Texte automatisiert zu generieren. Anderseits
ist der Einsatz von KI im Mediensektor auch vor dem gestiegenen Kostendruck zu sehen und k&#246;nnte so den
Qualit&#228;tsjournalismus weiter unter Druck setzen. Der gesellschaftliche und &#246;konomische Kontext ist daher auch 
hier f&#252;r die Bewertung von Chancen und Risiken entscheidend. KI kann zur St&#228;rkung von Medienvielfalt in der
Produktion f&#252;hren. KI kann aber auch eingesetzt werden, um mit Sparzw&#228;ngen in Redaktionen umzugehen und
den Trend weg von zeit- und arbeitsintensivem Investigativ-Journalismus hin zu Formaten zu verst&#228;rken, die
darauf ausgelegt sind, schnell Aufmerksamkeit zu erlangen. Zus&#228;tzlich k&#246;nnen KI-Technologien auch zur
Manipulation &#246;ffentlicher Diskurse genutzt werden, da sie neue M&#246;glichkeiten bieten, mit geringem Aufwand und
geringen Kosten Medieninhalte mit hoher Qualit&#228;t zu f&#228;lschen oder zu manipulieren.
1850 Allgemein verbreitete Einschr&#228;nkungen des Rechts auf freie Meinungs&#228;u&#223;erung (nicht abschlie&#223;end) ergeben sich in Deutschland
aus der Schranke des Artikels 5 Absatz 2 des Grundgesetzes. Zu den Beschr&#228;nkungen geh&#246;ren unter anderem Meinungs&#228;u&#223;erungen,
die Grenzen des Jugendschutzes oder der &#246;ffentlichen Sicherheit &#252;berschreiten, oder auch die nichtautorisierte Weitergabe
urheberrechtlich gesch&#252;tzter Informationen.
1851 Siehe auch Kapitel 6.2.3 [Milieubildung: Filterblasen und Echokammern] und Kapitel 6.3 [Social Bots] dieses Projektgruppenberichts.
1852 Darstellung Clemens Boisser&#233;e (Rheinische Post) in der Sitzung der Projektgruppe KI und Medien am 9. Dezember 2019; Zu den
M&#246;glichkeiten vgl. Lossau (2018): Wie K&#252;nstliche Intelligenz die Medien ver&#228;ndert.
Analyse des Einsatzes von KI im klassischen Journalismus
5.1.1 Funktionen des Journalismus1853 
In liberalen demokratischen Gesellschaften misst man dem Journalismus gemeinhin eine informierende,
meinungsbildende, vermittelnde und eine kontrollierende Funktion zu. So formuliert das ber&#252;hmte Spiegel-Urteil 
des Bundesverfassungsgerichts: &#8222;Eine freie, nicht von der &#246;ffentlichen Gewalt gelenkte, keiner Zensur
unterworfene Presse ist ein Wesenselement des freiheitlichen Staates; insbesondere ist eine freie, regelm&#228;&#223;ig erscheinende 
politische Presse f&#252;r die moderne Demokratie unentbehrlich. Soll der B&#252;rger politische Entscheidungen treffen,
muss er umfassend informiert sein, aber auch die Meinungen kennen und gegeneinander abw&#228;gen k&#246;nnen, die
andere sich gebildet haben.&#8220;1854 In diesem Urteil &#8211; man kann f&#252;r &#8222;Presse&#8220; hier sinngem&#228;&#223; &#8222;Journalismus&#8220;
einsetzen &#8211; wird zun&#228;chst die informierende und meinungsbildende Funktion betont. Als Vermittlungsfunktion
bezeichnet das Urteil die Leistung des Journalismus, Meinungen und Diskurse an das politische System
heranzutragen. Schlie&#223;lich versteht man unter der kontrollierenden Funktion eine machtkritische Leistung des
Journalismus: Der Journalismus beobachtet das Parlament, die Regierung und die Rechtsprechung kritisch und deckt
Missst&#228;nde auf. Zwar ist die Bezeichnung des Journalismus als &#8222;vierter Gewalt&#8220; etwas unscharf (weil die drei
politischen Gewalten durch die Verfassung einen anderen Status haben als der Journalismus), aber die Bedeutung
dieser Kontrollfunktion in modernen Demokratien erweist sich immer wieder. Diese Kontrollfunktion beschr&#228;nkt
sich dabei nicht auf den politisch-staatlichen Bereich, sondern der Journalismus beobachtet etwa auch
wirtschaftliche Akteure und deckt zum Beispiel Korruption oder Missbrauch auf. 
Hierbei gilt es zu unterstreichen, dass von seri&#246;sen Journalistinnen und Journalisten und Redaktionen
unabh&#228;ngiges wie &#252;berparteiliches Arbeiten im Dienst der Demokratie erwartet werden darf. Dazu geh&#246;ren das saubere
Trennen zwischen Nachricht und Kommentar ebenso wie das ausgewogene Darstellen und Einordnen eines
Sachverhaltes aus der Beobachter- und nicht der Teilnehmerperspektive. Gerade journalistische Arbeit im politischen
Bereich ist ein Mediendienst an B&#252;rgerinnen und B&#252;rgern, Kundinnen und Kunden bzw. an den Lesenden, die
sich auf Grundlage der pr&#228;sentierten und gewichteten Fakten eine eigene Meinung bilden k&#246;nnen und wollen.
5.1.2 Qualit&#228;t und Ethik des Journalismus1855 
Michael Haller &#252;bersetzt die im vorigen Kapitel dargestellten Funktionsbeschreibungen in eine
Erwartungsformel des Journalismus und gibt diesem damit auch einen ethischen Rahmen: &#8222;Unter normativ-
demokratietheoretischer Sicht soll der Journalismus die Erwachsenenbev&#246;lkerung &#252;ber das (tages-)aktuelle Geschehen m&#246;glichst
zutreffend orientieren &#8211; wobei das Verb &#8218;orientieren&#8217; als Konglomerat aus Informieren, Einordnen, Bewerten
und Beurteilen zu verstehen ist.&#8220;1856 &#196;hnlich und mit expliziter Erw&#228;hnung des Partizipationsbegriffs formuliert
Horst P&#246;ttker: &#8222;Die zentrale Aufgabe des Journalismus ist die Komplexit&#228;ts&#252;berbr&#252;ckung, die Vermittlung
zwischen den voneinander geschiedenen Lebenswirklichkeiten, die &#220;bertragung des jeweils isolierten
Erfahrungswissens in eine jedermann zug&#228;ngliche, eben ,offene&#8216; Sph&#228;re, um so f&#252;r alle die M&#246;glichkeit der Partizipation 
am gesellschaftlichen Ganzen zu sichern.&#8220; 1857 
1853 Zu diesem Kapitel liegen Sondervoten aus der Fraktion der AfD [Sondervotum zu den Kapiteln 5.1.1 bis 5.1.3 des Berichts der
Projektgruppe 6 &#8222;KI und Medien&#8220; (&#8222;Funktionen des Journalismus &#8220;, &#8222;Qualit&#228;t und Ethik des Journalismus &#8220; und &#8222;Herausforderungen 
durch die Digitalisierung &#8220;) des Abgeordneten Dr. Marc Jongen sowie der Abgeordneten Joana Cotar und Peter Felser und
Sondervotum zu den Kapiteln 5.1.1 bis 5.1.3 des Berichts der Projektgruppe 6 &#8222;KI und Medien (&#8222;Funktionen des Journalismus &#8220;, &#8222;Qualit&#228;t 
und Ethik des Journalismus &#8220; und &#8222;Herausforderungen durch die Digitalisierung &#8220;) des Abgeordneten Dr. Marc Jongen sowie der
Abgeordneten Joana Cotar und Peter Felser] vor.
1854 Teilurteil des Bundesverfassungsgerichts vom 5. August 1966 (Az.: 1 BvR 586/62, 610/63 und 512/64).
1855 Zu diesem Kapitel liegen Sondervoten aus der Fraktion der AfD [Sondervotum zu den Kapiteln 5.1.1 bis 5.1.3 des Berichts der
Projektgruppe 6 &#8222;KI und Medien&#8220; (&#8222;Funktionen des Journalismus &#8220;, &#8222;Qualit&#228;t und Ethik des Journalismus &#8220; und &#8222;Herausforderungen 
durch die Digitalisierung &#8220;) des Abgeordneten Dr. Marc Jongen sowie der Abgeordneten Joana Cotar und Peter Felser und
Sondervotum zu den Kapiteln 5.1.1 bis 5.1.3 des Berichts der Projektgruppe 6 &#8222;KI und Medien (&#8222;Funktionen des Journalismus &#8220;, &#8222;Qualit&#228;t 
und Ethik des Journalismus &#8220; und &#8222;Herausforderungen durch die Digitalisierung &#8220;) des Abgeordneten Dr. Marc Jongen sowie der
Abgeordneten Joana Cotar und Peter Felser] vor.
1856 Haller (2010): Ethik und Qualit&#228;t, S. 348&#8211;361.
1857 P&#246;ttker (2000): Kompensation von Komplexit&#228;t, S. 375&#8211;390.
Die meistzitierte Quelle1858 in Deutschland mit dem Anspruch einer Sammlung ethischer Richtlinien des
Journalismus ist der sogenannte Pressekodex, der erstmals im Jahr 1973 vom Deutschen Presserat vorgelegt wurde.1859 
Dieser dient zur freiwilligen Selbstkontrolle von Journalistinnen und Journalisten in Print- und Online-
Medien.1860 Rechtlich bindende qualitative Standards f&#252;r den &#246;ffentlich-rechtlich organisierten Journalismus enth&#228;lt
der Rundfunkstaatsvertrag, die wichtigste rechtliche Grundlage f&#252;r das duale Rundfunksystem1861; er wurde im
September 2020 durch den Medienstaatsvertrag ersetzt.1862 Konkretisiert werden die Standards im
&#246;ffentlichrechtlichen Rundfunk zudem durch Selbstverpflichtungserkl&#228;rungen, wie sie beispielsweise das ZDF regelm&#228;&#223;ig 
aktualisiert.1863 
Pr&#228;gend f&#252;r den klassischen Journalismus in Deutschland sind im Weiteren die sogenannten Leitmedien. Diese
zeichnen sich vor allem dadurch aus, dass ihnen &#8211; neben einer hohen Gesamtzahl an Rezipientinnen und
Rezipienten in der Bev&#246;lkerung und unter Entscheidungstr&#228;gern in Politik, Wirtschaft und Verwaltung &#8211; vor allem das
Prestige bei sowie die Nutzung und Zitation durch andere Journalistinnen und Journalisten zukommt.1864
Journalistinnen und Journalisten der Leitmedien wird in ihrem Berufsfeld ein &#8222;Vorsprung an Professionalit&#228;t,
Kompetenz, Wissen, Beurteilungsverm&#246;gen o. &#196;.&#8220; zugeschrieben, weshalb sie einen &#8222;Einfluss auf ihre Kollegen
aus&#252;ben und deren Auswahl oder Framing von Themen mitbestimmen&#8220;1865.
Die ethischen und qualitativen Ma&#223;st&#228;be des Journalismus sind vielf&#228;ltig, lassen sich aber letztlich alle
zur&#252;ckf&#252;hren auf die demokratische Funktion des Journalismus. Richtigkeit, Objektivit&#228;t, Sorgfalt, Unabh&#228;ngigkeit, 
Fairness, Verzicht auf sensationalistische Darstellung, Schutz von Pers&#246;nlichkeitsrechten usw. sind solche
ethischen Qualit&#228;tsma&#223;st&#228;be.
5.1.3 Herausforderungen durch die Digitalisierung1866 
Jeder technische Wandel ver&#228;ndert den Journalismus. Auch Ver&#228;nderungen im politischen System, etwa der
Zustand der Demokratie, stellen eine Herausforderung f&#252;r den Journalismus dar. 
In der normativen Demokratietheorie gibt es eine Wechselwirkung zwischen dem demokratischen Zustand eines
Gemeinwesens und einem frei und unabh&#228;ngig arbeitenden Journalismus. Die gr&#246;&#223;te Ver&#228;nderung, die im Zuge
der Digitalisierung und mit ihr der Nutzung von KI-Systemen im Journalismus festzustellen ist, bezieht sich auf
die Reichweite von Zeitungen, Rundfunkanstalten und Fernsehsendern und die Pluralit&#228;t publizierender Akteure.
Wie bereits in der Einleitung erw&#228;hnt werden die Auswirkungen der Digitalisierungen auf die Medien und den
Journalismus breit diskutiert. In diesem Zusammenhang sind, wie bereits angesprochen, unter anderem die
sozialen Netzwerke und die Inhalte, die &#252;ber sie verbreitet werden, zu nennen, die die journalistische Arbeitsweise
in erheblicher Weise ver&#228;ndern. Technisch ist es heute quasi von jedem Punkt der Erde aus m&#246;glich &#8211; sofern eine
Internetverbindung besteht &#8211;, Inhalte einer breiten &#214;ffentlichkeit zug&#228;nglich zu machen. Das ver&#228;ndert auch die
Art und Weise, wie Journalismus betrieben wird und wie er verf&#252;gbar ist.1867 Viele Medienh&#228;user haben die
sozialen Medien deshalb bereits in ihre Organisationsstruktur integriert.
Journalistinnen und Journalisten stehen mit Blick auf die sich immer weiter fragmentierende und
ausdifferenzierende &#214;ffentlichkeit unter anderem vor der Aufgabe, den Wahrheitsgehalt von Informationen, die &#252;ber die
sozialen Netzwerke transportiert werden, zu evaluieren, sprich Unwahrheiten, &#8222;Fake News&#8220;, Propaganda oder
Verleumdungen zu identifizieren. Hierf&#252;r stehen ihnen (zumindest im angels&#228;chsischen Sprachraum) mittlerweile
1858 Vgl. Linke (2006): Presse- und Radiokodex.
1859 Pressekodex online verf&#252;gbar unter: https://www.presserat.de/files/presserat/dokumente/download/Pressekodex2017light_web.pdf
(zuletzt abgerufen am 10. August 2020).
1860 Vgl. Deutscher Presserat (2020): Aufgaben des Presserats.
1861 Vgl. ard.de (2019): Rundfunkstaatsvertrag.
1862 Vgl. tagesschau.de (2019): Medienstaatsvertrag &#8211; Grundregeln f&#252;r die digitale Welt.
1863 Vgl. zdf.de (2020): Rechtsgrundlagen und Vorschriften.
1864 Vgl. Kr&#252;ger (2019): Meinungsmacht, S. 96 f.
1865 Vgl. Kr&#252;ger (2019): Meinungsmacht, S. 96 f.
1866 Zu diesem Kapitel liegen Sondervoten aus der Fraktion der AfD [Sondervotum zu den Kapiteln 5.1.1 bis 5.1.3 des Berichts der
Projektgruppe 6 &#8222;KI und Medien&#8220; (&#8222;Funktionen des Journalismus &#8220;, &#8222;Qualit&#228;t und Ethik des Journalismus &#8220; und &#8222;Herausforderungen 
durch die Digitalisierung &#8220;) des Abgeordneten Dr. Marc Jongen sowie der Abgeordneten Joana Cotar und Peter Felser und
Sondervotum zu den Kapiteln 5.1.1 bis 5.1.3 des Berichts der Projektgruppe 6 &#8222;KI und Medien (&#8222;Funktionen des Journalismus &#8220;, &#8222;Qualit&#228;t 
und Ethik des Journalismus &#8220; und &#8222;Herausforderungen durch die Digitalisierung &#8220;) des Abgeordneten Dr. Marc Jongen sowie der
Abgeordneten Joana Cotar und Peter Felser] vor.
1867 Vgl. Spangenberg (2015): Soziale Medien und journalistische Berichterstattung, S. 110 f.
Einrichtungen bzw. Organisationen1868 zur Verf&#252;gung; in der Regel erfolgt dieses Faktenchecking aber noch 
manuell. Der Einsatz von KI steht hier noch am Anfang, d&#252;rfte aber weiter zunehmen. Darauf wird im Folgenden
noch n&#228;her einzugehen sein.
Insgesamt gesehen besteht die Herausforderung darin, in einer technisch und gesellschaftlich ver&#228;nderten
Situation weiterhin auf einen qualitativ hochwertigen Journalismus zur&#252;ckgreifen zu k&#246;nnen. An der
demokratischpolitischen Bedeutung des Journalismus hat sich im Zuge der Digitalisierung nichts ge&#228;ndert. Auch der Einsatz
von KI-Technologie im Journalismus muss sich an diesen demokratischen Anforderungen messen lassen.
Automated Writing, redaktionelle Qualit&#228;tskontrolle
Zu den Kernaufgaben des journalistischen Arbeitens z&#228;hlt das Verfassen von Artikeln auf der Basis
recherchierter, strukturierter und &#252;berpr&#252;fter Informationen. In der Regel wird ein Artikel in der gedruckten Zeitung wie
auch in der Onlineversion namentlich und zum Teil auch mit einem Foto der Autorin oder des Autors
gekennzeichnet, dadurch bekommt der Text einen Verantwortlichen, der ebenso wichtig ist f&#252;r seine Glaubw&#252;rdigkeit
wie der Ort der Publikation.1869 
Dass Algorithmen selbstst&#228;ndig Texte &#8222;verfassen&#8220;, ist ein vergleichsweise junges Ph&#228;nomen in der Geschichte
des Journalismus. Im Jahr 2010 haben sich vier Studenten der Northwestern University in Illinois in einem
Projekt damit besch&#228;ftigt, einem Algorithmus das &#8222;Verstehen&#8220; und &#8222;Interpretieren&#8220; von Daten beizubringen. Aus
dieser Studie entwickelte sich das Unternehmen Automated Insights,1870 das neben Narrative Science1871 in den 
USA zu den Pionieren des automatisierten Schreibens z&#228;hlt. Automated Insights entwickelte gemeinsam mit der
Los Angeles Times einen Algorithmus, der Texte f&#252;r Erdbebenwarnungen generiert. Dieser &#8222;Quakebot&#8220; kam im 
Jahr 2014 erstmals zum Einsatz.1872 In den USA wie auch in Deutschland werden Schreibprogramme dieser Art
(bislang) nicht von gro&#223;en Verlagen und Medienh&#228;usern entwickelt, sondern von Start-ups, zu deren Kunden
dann angestammte Redaktionen z&#228;hlen.1873 
Man kann ganz grob zwei Techniken des automatisierten Schreibens unterscheiden. Der klassische
Roboterjournalismus arbeitet mit symbolischen Verfahren, die als Eingabe etwa tabellarische Verkehrs- und Wetterdaten 
oder Sportergebnisse bekommen. G&#228;ngige Textbausteine dieser Genres werden in einer Datenbank gesammelt;
der Algorithmus setzt im Bedarfsfall aktuelle Zahlen und Namen ein und generiert einen neuen Text. In der
redaktionellen Praxis wird die Qualit&#228;t des Textes im Anschluss an seine Erstellung von einem Menschen
kontrolliert, bevor der Artikel online freigeschaltet wird, so das Verfahren der Rheinischen Post.1874 Diese Systeme
sind gut kontrollierbar, transparent und im besten Fall sogar beweisbar fehlerfrei. 
Die Qualit&#228;t KI-basierter Texte ist mittlerweile so ausgereift, dass es nur einer Minderheit befragter Leserinnen
und Leser (39 Prozent) auff&#228;llt, dass ein vorliegender Text nicht von einem Menschen geschrieben, sondern von
einem Algorithmus generiert wurde.1875 &#220;berdies sind rund 43 Prozent der befragten Leserinnen und Leser bereit,
einer automatisch generierten Nachricht Vertrauen zu schenken.1876 Das automatisierte Schreiben bzw. der
Roboterjournalismus ver&#228;ndert qualitativ wie quantitativ nach jetzigem Kenntnisstand lediglich Randbereiche der
Profession, &#252;bernommen werden Routinearbeiten wie das Produzieren kurzer standardisierter Texte, die auf
dichtem Zahlenmaterial und stetig wiederkehrenden Strukturen beruhen,1877 was der Redaktion hilft, Zeit und
Ressourcen zu sparen. Hier ist sicher mit einem Zuwachs computergenerierter Nachrichten zu rechnen.1878 Au&#223;erdem
kann das redaktionelle Angebot auf lokale Ereignisse ausgeweitet werden, die anderweitig nicht erw&#228;hnt worden
w&#228;ren, f&#252;r die Bev&#246;lkerung in diesem Gebiet aber durchaus von Interesse sind.
1868 Hier sind zum Beispiel PolitiFact oder FactCheck.org zu nennen.
1869 &#8222;Autor&#8220; und &#8222;Autorit&#228;t&#8220; haben im Lateinischen dieselbe Wurzel: auctor = Urheber, Gr&#252;nder; ein Nomen Agentis zu augere =
vermehren, f&#246;rdern; vgl. Kluge und Seebold (2011): Etymologisches W&#246;rterbuch der deutschen Sprache, S. 78 f.
1870 Weitere Informationen dazu unter: https://automatedinsights.com/ (zuletzt abgerufen am 30. Juli 2020).
1871 Weitere Informationen dazu unter: https://automatedinsights.com/ (zuletzt abgerufen am 30. Juli 2020).
1872 Vgl. Habel (2019): Roboterjournalismus, S. 17 f.
1873 Dar&#252;ber hinaus kommt die Dienstleistung des automatisierten Schreibens auch bei anderen Gelegenheiten zum Einsatz, etwa bei der 
Erstellung von Gesch&#228;ftsberichten, dem F&#252;hren von Patientenakten, bei der Produktbeschreibung oder im E-Commerce, vgl. Kaiser 
(2018): Roboterjournalismus.
1874 Pr&#228;sentation von Clemens Boisser&#233;e (Rheinische Post), Projektgruppendrucksache 19(27)PG 6-8 vom 9. Dezember 2019.
1875 Vgl. Bartl (2019): Studie: Nicht einmal jeder Zweite erkennt einen Text von einer KI.
1876 Vgl. Bartl (2019): Studie: Nicht einmal jeder Zweite erkennt einen Text von einer KI.
1877 Vgl. Reichelt (2017): Einf&#252;hrung in den Roboterjournalismus, S. 27 ff.
1878 Die BBC geht davon aus, dass noch im laufenden Jahrzehnt bis zu 90 Prozent aller &#8222;News&#8220; von Rechnern geschrieben werden,
vgl. Zehrt: Roboterjournalismus? Journalisten nutzen Robots!.
Die neueren, datenbasierten Systeme, die meist auf neuronalen Netzen aufbauen, werden mit einer gro&#223;en Menge
vorhandener Texte trainiert. Danach sind sie beispielsweise in der Lage, aus einer beliebigen Eingabe in Form
von wenigen S&#228;tzen einen im Prinzip beliebig langen Text zu generieren, der auf den ersten Blick von einem
Menschen geschrieben sein k&#246;nnte. Ein Beispiel ist Open AI1879, welches sehr medienwirksam vor der eigenen 
Entwicklung warnte.1880 Da die heutigen Lernverfahren jedoch alle nur &#252;ber ein begrenztes Ged&#228;chtnis verf&#252;gen,
k&#246;nnen l&#228;ngere Texte nicht mehr koh&#228;rent geschrieben werden. Zudem ist es nicht m&#246;glich, die generierten
Inhalte im Vorfeld zu kontrollieren. Basierend auf den heutigen Verfahren ist es also unwahrscheinlich, dass die
Systeme eine Grundlage f&#252;r zuk&#252;nftige journalistische Arbeit darstellen k&#246;nnen.
Insgesamt wird der Einsatz von KI im Journalismus daher bis auf Weiteres eher als Unterst&#252;tzung bei der
Recherche sowie beim Aufbereiten und Kuratieren von Inhalten (z. B. Erstellung von Timelines, Finden von
illustrativen Bildern, Erstellen von Infografiken, Videos, &#220;bersetzungen, m&#246;glicherweise Faktencheck etc.) zum
Einsatz kommen. Im klassischen Journalismus und seiner Texterstellung gibt es viele Arbeitsschritte, die auf
absehbare Zeit von Algorithmen nicht geleistet werden k&#246;nnen. Dazu z&#228;hlen Hintergrundgespr&#228;che mit
Informantinnen und Informanten, Vor-Ort-Reportagen mit Stimmungs- und Atmosph&#228;renschilderung sowie das Verstehen,
Einordnen und Kommentieren der Inhalte in ihrem Kontext.1881 
5.2.1 Handlungsempfehlungen
Automatisierte Texte auf Grundlage von Daten und KI werden l&#228;ngst nicht immer auch als solche ausgewiesen.
Um die Glaubw&#252;rdigkeit journalistischer Arbeit auch weiterhin zu gew&#228;hrleisten, erscheint aus redaktioneller
Sicht eine konsequente einheitliche Kennzeichnung KI-generierter Texte w&#252;nschenswert.1882 F&#252;r den
Gesetzgeber denkbar ist die Ausweitung von Regelungen &#252;ber die Kenntlichmachung automatisierter Kommunikation im
Allgemeinen &#8211; vergleichbar mit der allerdings sektorspezifischen Regelung f&#252;r automatisierte Berichte &#252;ber
B&#246;rsenthemen.
Die kritische Frage des automatisierten Schreibens in der Berichterstattung betrifft weniger das Programmieren
eines lernenden Algorithmus als vielmehr die Verf&#252;gbarkeit der Daten, deren sich dieser bedienen kann.
Datenbanken mit Echtzeitdaten zu Verkehr, Wetter, Veranstaltungen, Sport und Sicherheit werden meist von
kommerziellen Anbietern betrieben. Daher wird die Schaffung von Open-Data-Portalen in staatlichen Einrichtungen als
ein notwendiger Schritt betrachtet, um k&#252;nftige KI-Projekte im Bereich der Medien anzutreiben.1883 F&#252;r den 
Einsatz von KI im Journalismus sollte es Richtlinien &#8211; analog dem Pressecodex &#8211; geben bzw. es w&#228;re zu pr&#252;fen,
inwieweit Verpflichtungen in den bestehenden Pressekodex integriert werden k&#246;nnen.
Deep Fake erkennen, Medienforensik
5.3.1 Definition, Funktionsweise und Anwendungsfelder
Der Begriff &#8222;Deep Fake&#8220; wurde gebildet aus den englischen Begriffen &#8222;Deep Learning&#8220;, einer bestimmten Art
Maschinellen Lernens, und &#8222;Fake&#8220;, dem Wort f&#252;r F&#228;lschung. Er beschreibt das Resultat der Erstellung oder
Manipulation von Audio- und Videoinhalten, die &#196;u&#223;erungen oder Handlungen real existierender Personen
wiedergeben, die diese in Wahrheit nicht von sich gegeben bzw. ausgef&#252;hrt haben.1884 Der Begriff kam Ende 2017
auf.1885 
1879 &#8222;Open AI&#8220; bezieht sich an dieser Stelle auf das Unternehmen Open AI LP, welches sich mit der Erforschung von KI besch&#228;ftigt.
Zentrale Geldgeber der Organisation sind der Investor und Unternehmer Elon Musk sowie das Unternehmen Microsoft.
1880 Vgl. Lenzen (2019): Open AI warnt vor GPT-2: Supertrolle am Start.
1881 Pr&#228;sentation von Clemens Boisser&#233;e (Rheinische Post), Projektgruppendrucksache 19(27)PG 6-8 vom 9. Dezember 2019.
1882 Handlungsempfehlungen von Clemens Boisser&#233;e (Rheinische Post), Projektgruppendrucksache 19(27)PG 6-11 vom 9. Dezember
2019.
1883 Handlungsempfehlungen von Clemens Boisser&#233;e (Rheinische Post), Projektgruppendrucksache 19(27)PG 6-11 vom 9. Dezember
2019.
1884 Vgl. Lossau (2020): Deep Fake: Gefahren, Herausforderungen und L&#246;sungswege, S. 2&#8288;; Chesney und Citron (2019): Deepfakes and
the New Disinformation War &#8211; The Coming Age of Post-Truth Geopolitics, S. 147 f.&#8288;; Bovenschulte (2019): Deepfakes &#8211;
Manipulation von Filmsequenzen, S. 1. Davon abzugrenzen sind sogenannte Cheap Fakes, bei deren Erstellung nicht notwendigerweise
Maschinelles Lernen angewendet wird. Beispielhaft steht daf&#252;r der Fall von Nancy Pelosi, die in einem Video scheinbar angetrunken in
ein Mikrofon spricht. Dieser Effekt wurde durch eine leicht verringerte Abspielgeschwindigkeit erzeugt (Lossau (2020): Deep Fake:
Gefahren, Herausforderungen und L&#246;sungswege, S. 5).
1885 Weitere Informationen zum Aufkommen des Begriffes &#8222;Deep Fake&#8220; abrufbar unter: https://trends.google.de/trends/ex-
plore?date=all&amp;q=Deepfake (zuletzt abgerufen am 30. Juli 2020).
Das Nachbearbeiten und Verf&#228;lschen von Informationen ist kein neuartiger Vorgang. Bereits seit Erfindung der
Fotografie wurden Bilder nachtr&#228;glich bearbeitet. Seit den 1990er-Jahren stehen vermehrt Computerprogramme
zur Verf&#252;gung, mit denen digitale Bilder bearbeitet werden k&#246;nnen, ohne sichtbare Spuren zu hinterlassen.
Daraufhin wurden Strategien entwickelt, um die Authentizit&#228;t von digitalen Bildern sicherzustellen &#8211; z. B. durch
den Einsatz sogenannter digitaler Wasserzeichen.1886 
Auch Videomaterial wurde in der Vergangenheit nachbearbeitet, z. B. in Form von Spezialeffekten in Filmen. 
Deep Fakes stehen somit in einer langen Tradition der Bearbeitung von Medieninhalten. Mit dem Einsatz von KI
&#228;ndert sich jedoch die Pr&#228;zision der Manipulation &#8211; sie wirkt nun t&#228;uschend echt. Au&#223;erdem verringert sich der
Aufwand, der f&#252;r die &#196;nderung von Video- und Audiofrequenzen notwendig ist. Die daf&#252;r n&#246;tige Software ist
zunehmend auf dem freien Markt erh&#228;ltlich, zum Teil sogar kostenfrei. F&#252;r das Erstellen einer unechten
Videofrequenz wird z. B. eine kritische Masse an Rohdaten in Form von Bild- und Videodaten ben&#246;tigt. Sind
hinreichend Fotos von einer Person vorhanden, k&#246;nnen Algorithmen errechnen, wie die Mimik einer Person aus einem
bestimmten Blickwinkel aussehen wird. F&#252;r die Produktion von Deep Fakes wird oftmals ein Generative
Adversarial Network (GAN) verwendet, das eine bestimmte Art des Deep Learnings bezeichnet. Dabei produziert der
eine Algorithmus z. B. neue Videofrequenzen, w&#228;hrend ein zweiter Algorithmus die k&#252;nstlich erzeugten
Frequenzen zu erkennen versucht, indem er diese mit den Rohdaten abgleicht. Ziel des ersten Algorithmus ist es,
t&#228;uschend echte Daten zu produzieren, die vom pr&#252;fenden Algorithmus nicht mehr als solche erkannt werden
k&#246;nnen. Auf gleiche Weise kann auch mit Audiodaten verfahren werden. Im Ergebnis erh&#228;lt man einen Deep
Fake, also eine schwer zu erkennende F&#228;lschung oder Bearbeitung von Video- und Audiodateien.1887 
Nicht nur Deep Fakes k&#246;nnen mit dieser Technik produziert werden, sondern es k&#246;nnen auch Produktionsschritte
bestimmter Branchen verbessert oder ersetzt werden. So setzen beispielsweise die Film- und Gamingbranchen
auf Deep-Learning-Algorithmen, um z. B. das Drehbuch in ein Storyboard1888 zu &#252;bersetzen, Kinotrailer zu
produzieren, Filmmusik zu komponieren oder die virtuelle Welt von Onlinespielen zu gestalten. Auch zur kreativen 
Vermittlung von Bildungsinhalten ist eine solche Technik einsetzbar: So k&#246;nnen historische Pers&#246;nlichkeiten
digital zum Leben erweckt und Lehrbuchtexte vorgetragen werden, um Unterricht interessanter zu gestalten.
Gleichzeitig ist jedoch auch eine Deep-Fake-Erstellung zu k&#252;nstlerischen oder satirischen Zwecken denkbar.1889 
Die Nutzung von Maschinellem Lernen zur Erzeugung von Deep Fakes kann hingegen sowohl auf
Privatpersonen als auch Personen des &#246;ffentlichen Lebens erhebliche Auswirkungen haben. Neben kommerziellen Modellen
entf&#228;llt ein Gro&#223;teil der erzeugten Deep Fakes bisher auf die Pornobranche, in der sowohl die Gesichtsz&#252;ge von
Ber&#252;hmtheiten als auch von Privatpersonen anstelle des Gesichts von Darstellerinnen bzw. Darstellern im Video
gezeigt werden. Motive f&#252;r die Erstellung solcher Deep Fakes sind sowohl die Diffamierung von Personen als
auch das Erpressen von Geldforderungen, indem mit Ver&#246;ffentlichung eines solchen Videos gedroht wird.1890 
Daneben besteht zurzeit vorrangig f&#252;r Personen des &#246;ffentlichen Lebens die Gefahr, Opfer eines Deep Fakes zu
werden, der ihnen fremde &#196;u&#223;erungen in den Mund legt. Prominentes Beispiel ist der Deep Fake des US-
Comedians Jordan Peele mit Barack Obama aus dem Jahr 2018. Deep Fakes, die insbesondere Entscheidungstr&#228;ger der
Politik, Wirtschaft sowie Wissenschaft zum Inhalt haben, k&#246;nnen im schlimmsten Fall zu Versuchen f&#252;hren,
Wahlen zu beeinflussen, Vertrauen in demokratische Institutionen zu untergraben, die nationale Sicherheit zu 
gef&#228;hrden und Staatskrisen auszul&#246;sen. Insgesamt stellen Deep Fakes &#8222;bislang noch kein Massenph&#228;nomen dar,
sondern vor allem eine zuk&#252;nftige Herausforderung&#8220;1891. Dennoch haben sie das Potenzial, die Glaubw&#252;rdigkeit
selbst von nicht-manipulierten Bewegtbildinhalten und Tonaufnahmen zu beeintr&#228;chtigen, indem der Verdacht
von m&#246;glicher Manipulation ge&#228;u&#223;ert wird.1892 
1886 Vgl. Lossau (2020): Deep Fake: Gefahren, Herausforderungen und L&#246;sungswege, S. 2 f.
1887 Vgl. Lossau (2020): Deep Fake: Gefahren, Herausforderungen und L&#246;sungswege, S. 2&#8288;; Chesney und Citron (2019): Deepfakes and
the New Disinformation War &#8211; The Coming Age of Post-Truth Geopolitics, S. 148.
1888 Ein Storyboard ist die Darstellung der Abfolge eines Films in Einzelbildern zur Erl&#228;uterung des Drehbuchs.
1889 Pr&#228;sentation des sachverst&#228;ndigen Mitglieds Prof. Dr. M&#252;ller-Lietzkow, Projektgruppendrucksache 19(27)PG 6-3 vom 4. November
2019; Chesney und Citron (2019): Deepfakes and the New Disinformation War &#8211; The Coming Age of Post-Truth Geopolitics, S. 148.
1890 Vgl. Lossau (2020): Deep Fake: Gefahren, Herausforderungen und L&#246;sungswege, S. 3 f.
1891 Bovenschulte (2019): Deepfakes &#8211; Manipulation von Filmsequenzen, S. 4.
1892 Pr&#228;sentation von Dr. Christian Riess (Friedrich-Alexander-Universit&#228;t Erlangen-N&#252;rnberg), Projektgruppendrucksache 19(27)PG 6-
6 vom 9. Dezember 2019; Lossau (2020): Deep Fake: Gefahren, Herausforderungen und L&#246;sungswege, S. 3; Bovenschulte (2019):
Deepfakes &#8211; Manipulation von Filmsequenzen, S. 3.
5.3.2 Statistische H&#228;ufigkeit von Deep Fakes
Eine Studie1893 aus dem September 2019 identifizierte und untersuchte rund 14 000 Deep-Fake-Videos, die online
zu sehen waren. Das entspricht nahezu einer Verdopplung des Volumens im Vergleich zur ersten Z&#228;hlung Ende
2018. Von diesen rund 14 000 Videos lassen sich 96 Prozent dem Pornografie-Genre zuordnen, hiervon sind laut
der Studie ausschlie&#223;lich Frauen als Opfer betroffen. Hierbei werden die K&#246;pfe prominenter S&#228;ngerinnen,
Schauspielerinnen und Moderatorinnen auf weibliche K&#246;rper in pornografischen Szenen montiert. Es scheint sich ein
Untergenre der Deep-Fake-Pornografie zu entwickeln; so hatten die vier meistbesuchten Webseiten dieses
Genres (deren &#228;lteste im Februar 2018 registriert wurde) zum Zeitpunkt der Erhebung Insgesamt circa 134 Millionen
Zugriffe.
Deep Fakes, die keine pornografischen Konstellationen abbilden, vielmehr Personen in Zusammenh&#228;nge
montieren, in denen sie real nicht waren, und die in der genannten Studie auf der Videoplattform YouTube analysiert
wurden, haben zu 61 Prozent M&#228;nner zum Zielobjekt; zu 81 Prozent stammen diese Personen aus dem Bereich
der Unterhaltung und zu 12 Prozent aus dem politischen Umfeld. Speziell hier k&#246;nnen Deep Fakes, in destruktiver
Absicht produziert und eingesetzt, Teil einer Fake-News-Kampagne sein. Deep Fake kann als ein globales
Ph&#228;nomen beschrieben werden, mit einem klaren Schwerpunkt in den USA, Westeuropa und S&#252;dkorea.1894 Zum
Zeitpunkt der Erhebung wurden 20 Webseiten samt angeschlossener Communities mit insgesamt knapp
100 000 Mitgliedern gez&#228;hlt, die sich unter anderem der Produktion, dem Tausch und der Verbreitung von Deep-
Fake-Videos widmen, einige davon (4chan; 8kun, ehemals 8chan) ber&#252;chtigt f&#252;r das Hosting illegaler Angebote.
Zur quantitativen Einordnung dieser Zahlen lohnt ein Blick auf die allgemeine Nutzung der Videoplattform
YouTube. Sie z&#228;hlt zu den gr&#246;&#223;ten globalen sozialen Netzwerken mit monatlich rund 1,9 Milliarden aktiven 
Nutzerinnen und Nutzern weltweit im Jahr 2019 und einem Werbeumsatz allein in den USA von gegenw&#228;rtig
prognostizierten 6,12 Milliarden US-Dollar.1895 Im Februar 2020 verzeichnete YouTube zehn Videos mit jeweils
mehr als 3 Milliarden Aufrufen weltweit. Im 3. Quartal 2019 wurden hier 11 Millionen Videos wegen &#8222;sexueller
Inhalte&#8220; und 2,7 Millionen wegen &#8222;Kindesmissbrauchs&#8220; beanstandet. Zweifellos weist das Werkzeug Deep Fake
im kriminellen Kontext ein erhebliches Missbrauchspotenzial auf, der Ruf einer in der &#214;ffentlichkeit stehenden
Person kann nachhaltig gesch&#228;digt werden. Sehr viel gr&#246;&#223;er aber ist die Zahl jener (in der Regel nicht-
prominenter) Menschen, die ohne ihr Wissen und/oder ihre Zustimmung in sexuellen Kontexten gefilmt werden. Wenn
diese Videos gegen ihren Willen ver&#246;ffentlicht werden, ist das rechtswidrig und eine Verletzung der Intimsph&#228;re.
5.3.3 Methoden zur Erkennung von Deep Fakes
Klassische Ans&#228;tze der Medienforensik beim Aufsp&#252;ren von Bild- und Videomanipulationen, genannt Deep
Fakes, gehen von der Annahme aus, dass jeder Verarbeitungsschritt nat&#252;rliche Spuren in den digitalen
Bilddateien hinterl&#228;sst.1896 Das fertige Bild bzw. die Datei schlie&#223;lich kann Montagen aufweisen, Skalierungen und 
Kompressionen. Ein moderner Ansatz der Medienforensik untersucht das statistische Paket aller Spuren via
Maschinellen Lernens auf Unregelm&#228;&#223;igkeiten. Der Erfolg der Medienforensik h&#228;ngt jedoch wesentlich von
Rahmenbedingungen ab, etwa dem Vorliegen von RAW-Bildern1897, dem Zugriff auf die Aufnahmekamera, der
Intaktheit der Metadaten, der Anzahl der Editionen des Bildes bzw. des Videos sowie dem Teilen und Verbreiten
des Bildes &#252;ber soziale Netzwerke. Generell gilt, dass bei stark verkleinerten und komprimierten Bildern der
Pr&#252;ferfolg wegen des inh&#228;renten Datenverlustes ungewiss ist. 
Dar&#252;ber hinaus steht ein zu pr&#252;fendes Bild bzw. dessen Motiv stets in einem konkreten Kontext und kann auf
physikalische Merkmale wie Sonnenstand, Schattenl&#228;nge, Tageszeit, Vegetation oder Niederschlag hin
untersucht werden. Ebenso geben markante Bauwerke, Pl&#228;tze oder Landschaften eine geeignete Pr&#252;freferenz ab.
Dar&#252;ber hinaus lassen sich Ort und Zeit der Ver&#246;ffentlichung sowie das Umfeld und die Kommunikationsgrafen
1893 Vgl. Ajder et al. (2019): The State of Deepfakes: Landscape, Threats, and Impact.
1894 Hier werden sich sowohl die absolute und die relative Internetnutzung der genannten L&#228;nder im internationalen Kontext
widerspiegeln als auch die Verbreitung technologischer Hard- wie Software.
1895 Hier und im Folgenden vgl. Statista (2020): Statista-Dossier zu YouTube.
1896 Hier und in der Folge Pr&#228;sentation von Dr. Christian Riess (Friedrich-Alexander-Universit&#228;t Erlangen-N&#252;rnberg),
Projektgruppendrucksache 19(27)PG 6-6 vom 9. Dezember 2019.
1897 RAW ist ein Dateiformat zum Speichern von Bildern. Hier hat noch keine technische Bearbeitung der Datei stattgefunden, RAW
ben&#246;tigt aber deutlich mehr Speicherplatz als die Formate JPG oder PNG. Vgl. hierzu Aschermann (2018): Was ist RAW? Einfach
und verst&#228;ndlich erkl&#228;rt.
der Autorinnen und Autoren bzw. Produzentinnen und Produzenten einem Plausibilit&#228;tstest unterziehen, um
Deep Fakes zu erkennen.1898
Die automatisierten Editier-Werkzeuge der ersten Generation (d. h. bis 2018) weisen typische Schw&#228;chen wie
etwa Geometriefehler auf; da kein menschliches Gesicht aus zwei komplett symmetrischen H&#228;lften besteht,
wirken synthetisch montierte oder erzeugte Gesichter maskenhaft glatt und leblos. Schwierig wird es, wenn
Bildoder Videodateien nur auf einigen wenigen Pixeln manipuliert wurden. F&#252;r die Medienforensik wird es mit der
technologischen Weiterentwicklung der Generierungssoftware zur Herausforderung, echte und
computergefertigte Videos visuell voneinander zu unterscheiden. Deshalb entsteht derzeit ein &#8222;Wettlauf zwischen Verfahren
zur Erkennung von Deep Fakes und deren Entlarvung&#8220;1899. Kommt dann noch die Distribution &#252;ber soziale
Netzwerke hinzu, sind derlei manipulierte Videos nach aktuellem Forschungsstand schwer aufzudecken. F&#252;r eine
manuelle Analyse fraglicher Dateien ist das Volumen schlicht zu hoch, vollautomatisierte Verfahren hingegen
stolpern in die semantische L&#252;cke, indem sie z. B. humoristische Darstellungen nicht als solche erkennen. 
Die bisherige Medienforensik ist ein eher kleines Forschungsfeld, das seinen Ursprung in der Entwicklung von 
Algorithmen f&#252;r die &#220;berpr&#252;fung von Bildmaterial f&#252;r Strafverfolgungsbeh&#246;rden hat. Weltweit sind etwa
15 Gruppen in der Medienforensik t&#228;tig, auch in Deutschland.1900 Um der rapiden Steigerung der Produktion und
Verbreitung von Deep Fakes auf der Basis von KI zu begegnen, haben f&#252;hrende Intermedi&#228;re, Redaktionen und 
Forschungsinstitute die Deep-Fake-Detection-Challenge ausgerufen.1901 Von Dezember 2019 bis Ende M&#228;rz
2020 waren Personen aus dem Bereich Programmierung, Software-Engineering weltweit aufgerufen, sich
projektweise an der Entwicklung KI-gest&#252;tzter L&#246;sungen zum Finden und Entlarven von Deep Fakes zu beteiligen.
Als Preis f&#252;r diese erfolgreiche Programmierarbeit wurden bis zu 1 Million US-Dollar ausgelobt, weitere
Forschungen zum Aufsp&#252;ren von Deep Fakes sollen mit 10 Millionen US-Dollar gef&#246;rdert werden.1902 F&#252;r den
Wettbewerb wurde ein spezielles Trainingsset an Videos kreiert, die anschlie&#223;end mit verschiedenen KI-Techniken
bearbeitet und ver&#228;ndert wurden; dabei wurden keine Daten bestehender Profile oder Kan&#228;le realer Nutzerinnen
und Nutzer herangezogen.1903
5.3.4 Handlungsempfehlungen
Es wird die F&#246;rderung unabh&#228;ngiger Einrichtungen zur Unterst&#252;tzung der technischen Pr&#252;fung von
Medieninhalten empfohlen. Ursprung, Authentizit&#228;t und Aussagekraft von Mediendaten m&#252;ssen in verschiedenen
Handlungsfeldern &#252;berpr&#252;ft werden. Dies betrifft neben dem Journalismus auch Strafverfolgungsbeh&#246;rden,
Privatunternehmen mit medienbasierten Gesch&#228;ftsprozessen und politische Institutionen wie etwa Ministerien, die die
Dienste einer solchen Einrichtung in Anspruch nehmen k&#246;nnen. Aktuell existierende Kompetenzen zur
Medienpr&#252;fung liegen verstreut &#252;ber Fachabteilungen in der Forschung, bei Redaktionsnetzen oder beim
Bundeskriminalamt.1904 
Kooperationen der bestehenden Institutionen m&#252;ssen rechtlich und technisch erm&#246;glicht werden, um die
bestehenden Kompetenzen zu b&#252;ndeln. Dies kann die derzeitige Pr&#252;fpraxis erheblich schlagkr&#228;ftiger machen und die
Glaubw&#252;rdigkeit der Pr&#252;fergebnisse sicherstellen. Die Pr&#252;feinrichtungen m&#252;ssen mit entsprechenden Mitteln und
Personal ausgestattet werden, um mit der technologischen Entwicklung Schritt halten und in kurzer Zeit technisch
anspruchsvolle Fragen beantworten zu k&#246;nnen. Empfohlen wird, dass die Branche (bzw. der Presserat)
Qualit&#228;tsstandards entwickelt, die dann im Rahmen von Sorgfaltspflichten durch die Medien zu beachten sind.
1898 Die Journalistin Julia Bayer (Deutsche Welle) hat sich eine Webseite personalisiert, auf der zahlreiche Anwendungen und Werkzeuge 
zur inhaltlichen, technischen und kontextuellen Verifikation/Falsifikation einer Bilddatei aufgelistet sind:
https://start.me/p/ZGAzN7/verification-toolset (zuletzt abgerufen am 13. August 2020).
1899 Bovenschulte (2019): Deepfakes &#8211; Manipulation von Filmsequenzen, S. 3.
1900 Pr&#228;sentation von Dr. Christian Riess (Friedrich-Alexander-Universit&#228;t Erlangen-N&#252;rnberg), Projektgruppendrucksache 19(27)PG 6-
6 vom 9. Dezember 2019.
1901 Weitere Informationen dazu unter: https://deepfakedetectionchallenge.ai/ (zuletzt abgerufen am 30. Juli 2020). Zum
Steuerungskomitee dieser Initiative z&#228;hlen neben Amazon Web Services, Facebook und Microsoft auch die New York Times und die BBC sowie
die Universit&#228;ten von Berkeley, Neapel und Oxford.
1902 Zum Stichtag am 31. M&#228;rz 2020 haben insgesamt 2 265 Teams Programmierl&#246;sungen eingereicht, die f&#252;nf Bestplatzierten des
Wettbewerbs wurden mit Preisen ausgezeichnet. Weitere Informationen dazu unter: https://www.kaggle.com/c/deepfake-detection-chal-
lenge/discussion/157925 (zuletzt abgerufen am 30. Juli 2020).
1903 So die Aussage des Chief Technology Officer bei Facebook, das bei der Erstellung der Videos f&#252;r die Datenbank, die mit einer
Gesichtserkennungssoftware manipuliert wurden, mit professionellen Schauspielerinnen gearbeitet hat. Vgl. Schroepfer (2019):
Creating a data set and a challenge for deepfakes.
1904 Handlungsempfehlungen von Dr. Christian Riess (Friedrich-Alexander-Universit&#228;t Erlangen-N&#252;rnberg), Projektgruppendruckssache
19(27)PG-6-5 vom 9. Dezember 2020.
Dar&#252;ber hinaus muss es ein st&#228;rkeres Engagement in der Forschungsf&#246;rderung im Hinblick auf die Erkennung
von Deep Fakes in Deutschland geben. Dies ergibt sich aus der Tatsache, dass das Forschungsfeld der
Medienforensik weltweit bisher nur wenig ausgepr&#228;gt ist. Der Bund sollte die L&#228;nder darin unterst&#252;tzen, dass die
medienforensischen F&#228;higkeiten an deutschen Hochschulen ausgebaut werden. Das hei&#223;t, Deutschland sollte &#252;ber die
digitale Kompetenz verf&#252;gen, Deep Fakes zu erkennen, insbesondere bei Deep Fakes mit Inhalt eines hohen
&#246;ffentlichen, politischen und wirtschaftlichen Interesses. Hierzu sollte auch Aufkl&#228;rung betrieben werden.
Datenzugang als Voraussetzung f&#252;r Datenanalyse 
Der Zugang zu Daten sowie deren Verarbeitung spielen f&#252;r Akteure der Medienbranche eine bedeutende Rolle. 
Denn wie in anderen Feldern der Digitalwirtschaft sind Daten die Grundlage f&#252;r digitale Gesch&#228;ftsmodelle. Dabei
werden sowohl Prim&#228;r- als auch Sekund&#228;rdaten verwendet.
Datennutzung
Im Bereich des Journalismus nutzen die Medien bereits heute digitale Daten, um zum Beispiel automatisiert neue
Inhalte zu generieren. Dies gelingt vor allem in Newsbereichen, die bereits stark auf der Beschreibung eines
quantitativen Datensatzes beruhen. Dies ist unter anderem bei Verkehrs- und Wettermeldungen, bei
Sportveranstaltungen oder bei B&#246;rsenberichten der Fall. In diesen F&#228;llen werden Daten ausgewertet, um sie mit
Textbausteinen zu verbinden, woraus letztlich ein Bericht entsteht. Gleiches geschieht auch in der
Bewegtbildberichterstattung, wo auf Grundlage von Bilddatenbanken kurze Videos passend zur textbasierten Nachricht automatisch 
generiert werden. Von 14 europ&#228;ischen Nachrichtenagenturen setzten bereits im Jahre 2017 elf von ihnen
automatische Nachrichtenerstellung ein.1905 
F&#252;r die Steuerung des inhaltlichen Angebotes auf Webseiten erheben klassische Medienkonzerne selbst Daten.
Diese werden genutzt, um z. B. zu entscheiden, welche Artikel kostenpflichtig angeboten werden, zur
Individualisierung der Webseiten oder f&#252;r die Schaltung personalisierter Werbung. F&#252;r diesen Zweck werden
vornehmlich Prim&#228;rdaten verwendet, die von den Medienunternehmen von denjenigen erhoben werden, die die Seiten
besuchen. &#196;hnlich ist es bei den Anbietern von sozialen Medien. Die Intermedi&#228;re erheben eine Vielzahl von
Daten, um die Relevanz von Beitr&#228;gen zu bestimmen und zu entscheiden, welche (Werbe-)Inhalte wem angezeigt
werden. Analysiert werden daf&#252;r Nutzerdaten (Verweildauer, Engagement etc.), Daten &#252;ber die Quelle eines
Inhaltes, die nach Vertrauensw&#252;rdigkeit bewertet wird, sowie das Nutzerverhalten auf Webseiten Dritter
(Tracking).1906 
Sowohl im Journalismus als auch in der &#214;ffentlichkeitsarbeit von Unternehmen werden Daten genutzt, um eine
Auswertung der Aktivit&#228;ten in sozialen Medien sowie &#252;briger Ver&#246;ffentlichungen im Netz vorzunehmen. Ziel
ist sowohl eine Unterst&#252;tzung bei der Recherche &#8211; z. B. indem in sozialen Medien besprochenen Themen
identifiziert und Diskussionen nachvollzogen werden &#8211; als auch eine Beobachtung der Kommunikation von
Wettbewerbern oder das Erkennen von Stimmungen und Meinungen. Dabei wird der Austausch von Nutzerinnen und
Nutzern sozialer Medien nach bestimmten Stichworten durchsucht.1907
Um Nutzerbeitr&#228;ge zu kuratieren, nutzen sowohl klassische Medienh&#228;user als auch Anbieter sozialer Medien
Algorithmen zum Erkennen von Inhalten, die nicht den Allgemeinen Gesch&#228;ftsbedingungen entsprechen und
strafbar sind, zur Bek&#228;mpfung von Hassrede oder zur Erkennung von Urheberrechtsverletzungen. Daf&#252;r werden
sowohl Texte als auch Ton- und Bildmaterial der Nutzerinnen und Nutzer als Prim&#228;rdaten herangezogen, um die
Absicht von Beitr&#228;gen zu erfassen.1908
1905 Pr&#228;sentation von Clemens Boisser&#233;e (Rheinische Post), Projektgruppendrucksache 19(27)PG 6-8 vom 9. Dezember 2019 sowie
Pr&#228;sentation von Prof. Dr. Goldhammer (Goldmedia GmbH Strategy Consulting), Projektgruppendrucksache 19(27)PG 6-7 vom 9.
Dezember 2019.
1906 Pr&#228;sentation von Clemens Boisser&#233;e (Rheinische Post), Projektgruppendrucksache 19(27)PG 6-8 vom 9. Dezember 2019;
Pr&#228;sentation von Prof. Dr. Goldhammer (Goldmedia GmbH Strategy Consulting), Projektgruppendrucksache 19(27)PG 6-7 vom 9. Dezember
2019; Pr&#228;sentation von Dr. Anja Zimmer (Medienanstalt Berlin-Brandenburg), Projektgruppendrucksache 19(27)PG 6-22 vom
10. Februar 2020 und Pr&#228;sentation von Orestis Papakyriakopoulos (Hochschule f&#252;r Politik M&#252;nchen an der Technischen Universit&#228;t
M&#252;nchen), Projektgruppendrucksache 19(27)PG 6-13 vom 13. Dezember 2019.
1907 Pr&#228;sentation von Clemens Boisser&#233;e (Rheinische Post), Projektgruppendrucksache 19(27)PG 6-8 vom 9. Dezember 2019 und
Pr&#228;sentation von Dr. Tina Kl&#252;wer (sachverst&#228;ndiges Mitglied der Enquete-Kommission), Projektgruppendrucksache 19(27)PG 6-16 
vom 19. Dezember 2019.
1908 Pr&#228;sentation von Clemens Boisser&#233;e (Rheinische Post), Projektgruppendrucksache 19(27)PG 6-8 vom 9. Dezember 2019 und
Pr&#228;sentation von Dr. Tina Kl&#252;wer (sachverst&#228;ndiges Mitglied der Enquete-Kommission), Projektgruppendrucksache 19(27)PG 6-16 
vom 19. Dezember 2019.
Datenzugang
Der Zugang zu einer hinreichenden Menge qualitativ hochwertiger Daten ist f&#252;r die Produktion, die Verarbeitung
sowie die Darstellung medialer Inhalte mithilfe von KI von gro&#223;er Bedeutung. Insbesondere f&#252;r die
Individualisierung und Effizienzsteigerung von Produkten haben Daten einen gro&#223;en Wert.1909 Dabei gelangen Akteure vor
allem wie folgt an Daten: durch eigene Datenerhebung (Datenerhebung durch die Nutzerinnen und Nutzer ihres
Produkts), durch Daten der &#246;ffentlichen Hand oder durch Datenpools aus privater Hand (wie z. B. Unternehmen).
Das Akquirieren von Nutzerdaten geschieht mithilfe der Nutzungsbedingungen der jeweiligen Medienprodukte.
Teilweise bieten Medienanbieter dabei den Nutzenden an, in Einstellungen zur Privatsph&#228;re den Datenzugang zu
regulieren; in einigen F&#228;llen ist dies gar verpflichtend. Teilweise geh&#246;rt das Erheben von Nutzerdaten auch zum
Gesch&#228;ftsmodell des Anbieters.
Dar&#252;ber hinaus werden f&#252;r die Produktion von KI-generierten Nachrichten sowie im Rahmen von
Datenjournalismus teilweise Daten der &#246;ffentlichen Hand ben&#246;tigt. Insbesondere in Newsbereichen wie Verkehr, Wohnen
oder Sicherheit sind &#246;ffentliche Daten f&#252;r die Berichterstattung von Interesse. Da der Zugang zu &#246;ffentlichen
Daten nicht ausreichend gegeben ist, stammen solche Daten zurzeit oftmals von privaten Anbietern, wobei die
Quellenlage unklar ist.1910 Der Bundestag hat 2017 ein erstes Open-Data-Gesetz verabschiedet, das den
Bundesbeh&#246;rden die Ver&#246;ffentlichung ihrer Rohdaten auftr&#228;gt. Die Bundesregierung bereitet derzeit ein zweites Open-
Data-Gesetz vor.
Einen weiteren Datenzugang k&#246;nnen Schnittstellen zu Datenpools von Unternehmen bieten. Im Mediensektor
sind vor allem die Daten von Intermedi&#228;ren wie sozialen Netzwerken relevant. Sowohl Journalistinnen und
Journalisten, die &#252;ber Vorg&#228;nge in sozialen Netzwerken oder deren Einfluss auf bestimmte Ereignisse berichten
wollen, als auch f&#252;r Wissenschaftlerinnen und Wissenschaftler, die die Kommunikation auf sozialen Medien
erforschen wollen, und f&#252;r Vertreterinnen und Vertreter von (Marktaufsichts-)Beh&#246;rden bleibt ein Datenzugang
unerl&#228;sslich. Derzeit sei dieser jedoch nicht ausreichend gew&#228;hrleistet, da die Anbieter sozialer Netzwerke
eigenh&#228;ndig bestimmen, wer Zugang zu ihren Daten erh&#228;lt. F&#252;r viele Projekte ist dabei ein Datenzugang in Echtzeit
erforderlich.1911 
Im Rahmen einer &#196;nderung des deutschen und europ&#228;ischen Wettbewerbsrechts wird derzeit ein verbesserter 
Zugang zu Daten der &#246;ffentlichen Hand diskutiert sowie ein Zugang zu Daten von Unternehmen mit &#252;berragender
markt&#252;bergreifender Bedeutung.1912
Die Ausweitung der M&#246;glichkeiten zum Datenzugang kann mit dem Datenschutz, der Wahrung der
Nutzersouver&#228;nit&#228;t und dem Schutz von Gesch&#228;ftsgeheimnissen in Konflikt stehen. Zur L&#246;sung dieser Probleme k&#246;nnten
unter anderem der Einsatz von Datentreuh&#228;ndern, Clearingstellen oder Ombudsverfahren beitragen.1913 
5.4.1 Handlungsempfehlungen
Es sind offene Schnittstelle bei Anbietern reichweitenstarker sozialer Medien zu schaffen, &#252;ber die
Journalistinnen und Journalisten sowie Wissenschaftlerinnen und Wissenschaftler sowie Marktaufsichtsbeh&#246;rden Zugriff auf
den Datenpool dieser Anbieter haben.1914 Dabei ist zu pr&#252;fen, unter welchen Umst&#228;nden Zugang zu welchen
Daten gew&#228;hrt werden soll und welchen Speicher-, Dokumentations- und Nutzungspflichten Journalistinnen und
Journalisten, Wissenschaftlerinnen und Wissenschaftler und &#246;ffentliche Stellen bei Nutzung dieser Daten
unterliegen. Dies ist notwendig, um ihre Aufgabe, die &#214;ffentlichkeit zu informieren und zu forschen, angemessen 
wahrnehmen zu k&#246;nnen. Dabei ist zu ber&#252;cksichtigen, dass Datenschutzrechte und Gesch&#228;ftsgeheimnisse
gewahrt bleiben m&#252;ssen. Es ist zu &#252;berlegen, inwiefern eine unabh&#228;ngige Instanz zu installieren ist, die den Zugang
1909 Vgl. Schallbruch et al. (2019): Ein neuer Wettbewerbsrahmen f&#252;r die Digitalwirtschaft. Bericht der Kommission
Wettbewerbsrecht 4.0, S. 13 f.
1910 Handlungsempfehlungen von Clemens Boisser&#233;e (Rheinische Post), Projektgruppendrucksache 19(27)PG 6-11 vom 9. Dezember
2019 sowie Maztat (2011): Datenjournalismus.
1911 Pr&#228;sentation von Clemens Boisser&#233;e (Rheinische Post), Projektgruppendrucksache 19(27)PG 6-8 vom 9. Dezember 2019 und
Pr&#228;sentation von Dr. Anja Zimmer (Medienanstalt Berlin-Brandenburg), Projektgruppendrucksache 19(27)PG 6-22 vom 7. Februar
2020. Dar&#252;ber hinaus hat Facebook im Rahmen eines Forschungsprojektes erstmals Wissenschaftlern einen Zugang zu
Unternehmensdaten verschafft, vgl. B&#252;nte (2019): Wahlbeeinflussung durch Social Media: Facebook liefert Daten f&#252;r Studie.
1912 Vgl. Schallbruch et al. (2019): Ein neuer Wettbewerbsrahmen f&#252;r die Digitalwirtschaft. Bericht der Kommission Wettbewerbsrecht
4.0, S. 45 ff.; Siehe auch Kapitel 7.2.2 dieses Projektgruppenberichts [Wettbewerbsrecht]. 
1913 Pr&#228;sentation von Prof. Dr. Rupprecht Podszun (Heinreich Heine Universit&#228;t D&#252;sseldorf), Projektgruppendrucksache 19(27)PG 6-20 
vom 7. Februar 2020. Siehe auch Kapitel 5.4 des Mantelberichts [Wettbewerbsrecht].
1914 Zu beantworten ist dabei aber die Frage, wie man &#8222;Journalistinnen und Journalisten&#8220; definiert, denn die Berufsbezeichnung ist nicht
gesch&#252;tzt; Journalistenausweise als Nachweis sind nicht unumstritten.
zu solchen Daten durchsetzen kann, an denen ein hohes gesellschaftliches Interesse besteht.1915 Es muss
sichergestellt werden, dass die Berufung auf den Datenschutz einen (neu geschaffenen) Datenzugangsanspruch nicht
wieder zunichte macht, etwa weil die Plattformbetreiber als einzige den Kontakt zu Nutzerinnen und Nutzern
haben und Einwilligungen einholen k&#246;nnen, w&#228;hrend anderen das nicht m&#246;glich w&#228;re.
Daten von &#246;ffentlichen und &#246;ffentlich gef&#246;rderten Einrichtungen sollten in Einklang mit der Datenstrategie der
EU frei und leicht verwertbar in maschinenlesbarer Form zur Verf&#252;gung gestellt werden. Dabei muss eine hohe
Datenqualit&#228;t gew&#228;hrleistet werden, um KI-generierte Informationsangebote zu erm&#246;glichen. Das betrifft die
Verwertung in generierten Nachrichten, soll aber au&#223;erdem Inklusion und Integration f&#246;rdern und digitale
Barrierefreiheit garantieren. &#220;ber die Daten sollten auch KI-Simultan&#252;bersetzungstools bei jedem Beh&#246;rdenkontakt
zum Standard werden oder Texte auf Webseiten automatisiert in einfache Sprache &#252;bertragen werden k&#246;nnen.
Der Staat ben&#246;tigt derartige Leuchtt&#252;rme.
Im Privatsektor ist der Aufbau offener Datenportale zu unterst&#252;tzen, auf denen Unternehmen und Institutionen 
ihre Daten der Allgemeinheit zur Verf&#252;gung stellen k&#246;nnen.1916 
Datenanalyse: KI als Werkzeug f&#252;r den Journalismus 
Weitere Bereiche des journalistischen Arbeitens, in dem KI-gest&#252;tzte Software an Bedeutung zunimmt, sind die
Recherchehilfe bzw. das &#220;berwachen (&#8222;Monitoring&#8220;) und die Analyse von Informationen. Durch die immense
Vielfalt der jeden Tag zur Verf&#252;gung stehenden Informationen in traditionellen Medien sowie in den sozialen
Medien sind Redaktionen vor die gro&#223;e Herausforderung gestellt, relevante Informationen aufzusp&#252;ren, den 
&#220;berblick &#252;ber bestimmte Themengebiete zu strukturieren und wichtige Neuigkeiten rechtzeitig zu erfahren. Vor
diesen Aufgaben stehen auch andere Stakeholder, beispielsweise Unternehmen, Organisationen, politische
Parteien oder einzelne medial aktive B&#252;rgerinnen und B&#252;rger, die an medialen Debatten teilnehmen k&#246;nnen.
F&#252;r diesen Zweck haben sich Software-Tools auf dem Markt etabliert, die in der Lage sind, in hoher
Geschwindigkeit gro&#223;e Mengen an digitalen Inhalten zu verarbeiten und auf die Nennung bestimmter Themen, Personen
und anderer Konzepte hin zu analysieren.
Ein Beispiel f&#252;r den Einsatz im klassischen Journalismus ist die automatische Analyse und Durchsuchung von
(sozialen) Medien und anderen Web-Inhalten. Dazu gibt es verschiedene Software-L&#246;sungen, die entsprechende
Seiten und Mediendienste nach relevanten Themen durchsuchen und automatisierte Reports generieren.1917 Diese 
Reports k&#246;nnen mehrfach t&#228;glich Zusammenfassungen an die Redaktionen liefern. Au&#223;erdem k&#246;nnen bestimmte
Themen und Schl&#252;sselw&#246;rter automatisch nachverfolgt und in Live-Ansichten dargestellt werden.1918 Solche
Software beinhaltet h&#228;ufig Sprachverstehen und andere KI-Anwendungsfelder und somit auch oft KI-Technologie.
Au&#223;erhalb der journalistischen Arbeit sind solche Software-L&#246;sungen unter der Bezeichnung &#8222;Social-Media-
Monitoring&#8220; auf dem Markt verf&#252;gbar. Sie dienen der zielgerichteten Beobachtung von Unternehmens-,
Markenoder Produktnennungen und werden in der Marketing-Abteilung von vielen Unternehmen genutzt, um die
Stimmung gegen&#252;ber den eigenen Produkten und Angeboten zu erfassen und auf Kunden und potenzielle Kunden
m&#246;glichst schnell eingehen zu k&#246;nnen. Alle Akteure, die ihre Inhalte in den sozialen Medien verbreiten, k&#246;nnen
mittels dieser Werkzeuge Nennungen ihres eigenen Namens und damit ihres Brands beobachten.
1915 Handlungsempfehlungen von Dr. Christian Riess (Friedrich-Alexander-Universit&#228;t Erlangen-N&#252;rnberg), Projektgruppendrucksache
19(27)PG 6-5 vom 9. Dezember 2019; Handlungsempfehlungen von Orestis Papakyriakopoulos (Hochschule f&#252;r Politik M&#252;nchen 
an der Technischen Universit&#228;t M&#252;nchen), Projektgruppendrucksache 19(27)PG 6-15 vom 16. Dezember 2019;
Handlungsempfehlungen von Prof. Dr. Rupprecht Podszun (Heinrich Heine Universit&#228;t D&#252;sseldorf), Projektgruppendrucksache 19(27)PG 6-21 vom
7. Februar 2020; Handlungsempfehlungen von Dr. Anja Zimmer (Medienanstalt Berlin-Brandenburg), Projektgruppendrucksache
19(27)PG 6-23 vom 7. Februar 2020.
1916 Handlungsempfehlungen von Clemens Boisser&#233;e (Rheinische Post), Projektgruppendrucksache 19(27)PG 6-11 vom 9. Dezember
2019.
1917 Die Rheinische Post und der Bayerische Rundfunk beispielsweise haben daf&#252;r ein so genanntes &#8222;Listening Center&#8221; aufgesetzt. Die
Rheinische Post ist eine der gr&#246;&#223;ten Tageszeitungsverlage Deutschlands. Mit 1,7 Millionen t&#228;glichen Lesern im Bereich der
Tageszeitung und 30 Millionen monatlichen Besuchen online z&#228;hlt sie zu den reichweitenst&#228;rksten Medien des Landes. Das Listening
Center ist bei der Rheinischen Post seit drei Jahren und seit etwa einem Jahr beim Bayerischen Rundfunk im Einsatz. Pr&#228;sentation 
von Clemens Boisser&#233;e (Rheinische Post), Projektgruppendrucksache 19(27)PG 6-8, S. 5 und Darstellung von Christian Daubner
(Bayerischer Rundfunk) in der Sitzung der Projektgruppe KI und Medien am 9. Dezember 2019. 
1918 F&#252;r den Bayerischen Rundfunk werden durch das Listening Center &#252;ber 400 Millionen Quellen (u. a. Facebook) anhand von
bestimmten &#8222;Key Words&#8220; gescannt, die f&#252;r die B&#252;rger in Bayern relevant sein k&#246;nnten, um mit dieser Hilfe spannende Inhalte zu
identifzieren und auch darauf aufbauend Inhalt zu generieren - Darstellung von Christian Daubner (Bayerischer Rundfunk) in der
Sitzung der Projektgruppe KI und Medien am 9. Dezember 2019.
        
 
 
 
 
 
  
  
  
 
 
      
   
  
 
    
     
  
 
 
  
  
 
          
   
  
 
 
  
 
  
 
  
 
  
      
    
  
 
 
                                               
    
  
     
  
 
    
      
             
6
Die Bandbreite der L&#246;sungen f&#252;r ein Social-Media-Monitoring und ein Web-Monitoring ist gro&#223; und reicht von 
kleinen, kostenlosen Diensten, die auf einzelne Stichworte durchsuchen, bis zu gro&#223;en, umfassenden Systemen, 
die komplexe Inhalte analysieren, aufbereiten und zusammenfassen. W&#228;hrend die einfachsten L&#246;sungen keine
KI-Technologie einsetzen, nutzen viele umfassendere Systeme verschiedene KI-Technologien, um Texte, Bilder
und Videos automatisch auszuwerten und zusammenzufassen.
Die verwendeten Technologien werden au&#223;erdem daf&#252;r genutzt, zus&#228;tzliche Analysen &#252;ber Daten zu generieren,
die selbst schon einen journalistischen Inhalt darstellen. So k&#246;nnen beispielsweise KI-gest&#252;tzte Analyseverfahren
gro&#223;e &#246;ffentliche Datenmengen durchsuchen und Muster erkennen, die dann als Basis f&#252;r journalistische Inhalte
herangezogen werden. Beispiele f&#252;r die Verwendung solcher Technologien sind unter anderem die automatisierte
Auswertung von Wahldaten und die darauf aufbauende Visualisierung dieser Daten, um den
Medienkonsumentinnen und -konsumenten einfache Bilder von den Ergebnissen einer Wahl anbieten zu k&#246;nnen.1919 Aber auch
viele andere Daten k&#246;nnen mit solchen Verfahren aufbereitet und visualisiert werden.1920
Ein weiterer Einsatzbereich von KI-Technologie ist die Strukturierung von intern vorliegenden Inhalten. Im
Gegenteil zu Social-Media-Monitoring und Web-Monitoring werden hier keine externen Quellen von Inhalten
analysiert und &#252;berwacht, sondern die eigenen, intern vorliegenden Inhalte wie Blogbeitr&#228;ge, Artikel auf der Online-
Seite einer Zeitung, Produktdokumentationen etc. strukturiert und nutzbar gemacht. Auch hierf&#252;r gibt es etliche
kommerzielle L&#246;sungen, die als Knowledge-Management-Systeme bezeichnet werden. Ziel dieser L&#246;sungen ist
es, gro&#223;e Mengen unstrukturiert vorliegender Informationen wie Texte oder Bilder automatisch zu
verschlagworten und in einem Wissensbaum verwaltbar und auffindbar zu machen. So kann auf einer Blog-Seite ein
Algorithmus die verf&#252;gbaren Inhalte analysieren und Meta-Informationen &#252;ber die Inhalte generieren. Dieses
Wissen &#252;ber die Inhalte steht dann im weiteren Verlauf zur Verf&#252;gung, um passgenaue Inhalte f&#252;r Suchen anzubieten.
Auch viele Software-Dienste wie Content-Management-Systeme1921 und Wikis beinhalten bereits solche
Algorithmen, um Inhalte automatisch zu strukturieren. Viele Suchalgorithmen fallen ebenfalls in den Bereich der KI
und sind f&#252;r das Auffinden von passenden Inhalten unerl&#228;sslich. Auch die Nutzung von Algorithmen zur
Empfehlung von passenden Inhalten wird h&#228;ufig &#252;ber KI-Technologie gel&#246;st und in Kapitel 3.2.4 dieses
Projektgruppenberichts [Technische Grundlagen von Empfehlungssystemen] umfassend behandelt.
Die in den Wissensdatenbanken verwalteten Inhalte werden auf Webseiten oder in Messenger-Diensten h&#228;ufig
mit Chatbots kombiniert, um die Besucherinnen und Besucher schnell an die Inhalte weiterzuleiten, die sie
interessieren. Dabei agiert der Chatbot einerseits als Schnittstelle zur Benutzerin oder zum Benutzer, die mittels
nat&#252;rlicher Sprache bedient wird und durch KI-Methoden der Sprachverarbeitung ausgewertet werden, und
andererseits als Schnittstelle zu den dahinterliegenden Medieninhalten und Wissensdatenbanken. Nachdem er die
Interessen der Benutzerin oder des Benutzers aufgenommen hat, kann er diese mit der Wissensdatenbank
abgleichen und dann die passenden Inhalte heraussuchen. In der Regel l&#246;sen Chatbot-Systeme nur den interaktiven
Gespr&#228;chsanteil mit der Benutzerin oder dem Benutzer, bei manchen sehr umfassenden Bot-Angeboten ist die
Wissensverwaltung aber auch inklusive.
Distribution
Die Medienm&#228;rkte haben sich in den letzten Jahrzehnten im Zuge der Digitalisierung tiefgreifend ver&#228;ndert. 
Journalistische Medienangebote in Print, Fernsehen und Radio haben ihre zentrale &#8222;Gatekeeper&#8220;-Rolle verloren.
Mediale Inhalte und Informationen konnten schon immer au&#223;erhalb journalistischer Medien erzeugt werden.
Allerdings fehlten M&#246;glichkeiten, diese Inhalte kosteng&#252;nstig zu verbreiten. Das hat sich mit der massenhaften
Verbreitung und Nutzung des Internets und sozialer Medien grundlegend ver&#228;ndert. Jedem Erzeuger und jeder
Erzeugerin medialer Inhalte stehen Distributionskan&#228;le mit dem Potenzial globaler Reichweite zur Verf&#252;gung.
Bez&#252;glich der Reichweite von Medien auf Internetplattformen spielt KI mittlerweile eine zentrale Rolle. KI-
Technologien bestimmen, welche Inhalte Nutzerinnen oder Nutzern prominent angezeigt werden, und &#252;ben damit
gro&#223;en Einfluss auf die Reichweite aus. In Form von personalisierten Empfehlungen unterst&#252;tzen KI-Technolo-
1919 Automatisierte Auswertungen von Wahldaten wurden beispielsweise durch die WELT bereits zur Europawahl und von der
S&#252;ddeutschen Zeitung zur Bayrischen Landtagswahl durchgef&#252;hrt; Darstellung von Clemens Boisser&#233;e (Rheinische Post) in der Sitzung der
Projektgruppe KI und Medien am 9. Dezember 2019.
1920 Die Rheinische Post hat einen Monat lang die Verkehrsdaten des &#246;ffentlichen Personennahverkehrs in einer bestimmten Region 
erfasst und anschlie&#223;end automatisiert ausgewertet, welche Versp&#228;tungen dabei aufgetreten sind. Die Auswertung bezog sich auf
etwa 100 000 Fahrten und war in dieser Form nur mithilfe von KI m&#246;glich; Darstellung von Clemens Boisser&#233;e (Rheinische Post) in
der Sitzung der Projektgruppe KI und Medien am 9. Dezember 2019.
1921 Ein Content-Management-System (CMS) ist ein Redaktionssystem, mit dessen Hilfe der Inhalt, z. B. von Websites, verwaltet wird.
gien dabei, sich in der F&#252;lle der im Internet und auf sozialen Medien verf&#252;gbaren Medien- und
Informationsangebote zu orientieren. Aufgrund der Gr&#246;&#223;e der Plattformen wird &#252;ber diese Empfehlungssysteme auch starke
Marktmacht ausge&#252;bt. Auch die Tatsache, dass die Empfehlungen in der Regel nicht journalistischen Standards,
sondern haupts&#228;chlich den Gesch&#228;ftsinteressen der Unternehmen folgen, wirft schwierige Fragen zum Einfluss
von Internetplattformen auf die politische Meinungsbildung auf.  
Problematische Aspekte von Empfehlungssystemen
Empfehlungssysteme, deren technologische Grundlagen im Kapitel 3.2.4 dieses Projektgruppenberichts [
Technische Grundlagen von Empfehlungssystemen] beschrieben wurden, sind inzwischen aus der digitalen Welt nicht
mehr wegzudenken. Insbesondere Streaming-Anbieter wie Apple Music, Spotify oder auch Medienanbietern wie
YouTube und News-Apps nutzen Empfehlungssysteme, um den Nutzerinnen und Nutzern weitere Musik, Videos
oder andere Inhalte anzubieten.
Empfehlungssysteme bieten auf der einen Seite die M&#246;glichkeit, in einer riesigen Menge digitaler Inhalte das zu
finden, was f&#252;r Nutzerinnen und Nutzer relevant ist. Ohne algorithmische Unterst&#252;tzung w&#228;re eine
Personalisierung von digitalen Inhalten kaum m&#246;glich. Auf der anderen Seite bergen gerade Empfehlungssysteme gro&#223;e
Risiken. In den letzten Jahren wurde immer deutlicher, dass algorithmische Empfehlungssysteme merkbare
soziale Nebenwirkungen haben k&#246;nnen oder k&#246;nnten.1922 Das liegt insbesondere auch daran, dass es mindestens
drei Akteure gibt, die ihr Verhalten so anpassen k&#246;nnen, dass die resultierende Anordnung der Inhalte
weitestgehend ihren Vorstellungen entspricht:
1. die Entwickler des Systems. So hat z. B. YouTube mehrere Jahre lang die &#8222;Relevanz&#8220; der Inhalte und damit
den Erfolg seines Vorschlagssystems daran gemessen, wie viele Stunden die Nutzerinnen und Nutzer
weltweit auf der Plattform mit dem Schauen von Videos verbracht haben.1923 Es mehren sich die Hinweise, dass 
diese Festlegung dazu gef&#252;hrt hat, dass die Autoplay-Funktion von YouTube, ein automatisches
Empfehlungssystem, tendenziell mehr aggressive und verschw&#246;rungstheoretische Inhalte empfahl.1924 YouTube hat
daraufhin mit &#196;nderungen an verschiedenen Stellen reagiert,1925 
2. die Produzentinnen und Produzenten von digitalen Inhalten. Sie sorgen beispielsweise mit gekauften
Linkstrukturen, mit irref&#252;hrenden Informationen &#252;ber die von ihnen erstellten Inhalte und/oder mit
Clickbait-&#220;berschriften daf&#252;r, dass deutlich mehr Nutzerinnen und Nutzer auf ihre Inhalte klicken als eigentlich
Interesse daran haben. Damit manipulieren sie den Rang ihrer Produkte, weswegen sich Anbieter wie
Google auch dagegen wehren.1926 Hier stecken vor allen Dingen &#246;konomische Motive hinter dem Verhalten,
3. Teilgruppen von Nutzerinnen und Nutzer, die beispielsweise aus politischen Motiven mit Inhalten so
interagieren, dass ein gro&#223;es Interesse an diesen Inhalten vorget&#228;uscht wird, damit sie an m&#246;glichst viele andere
Nutzerinnen und Nutzer verteilt werden. Dies wird insbesondere im Bereich der Fake News
professionalisiert.
Ein Beispiel f&#252;r Nebenwirkungen von Empfehlungssystemen zeigte sich auf YouTube. Im Jahr 2017 verwies
James Bridle in einem aufsehenerregenden Artikel auf eine Reihe von Videos, die YouTube seinen j&#252;ngsten
Zuschauerinnen und Zuschauer empfahl, die f&#252;r diese aber v&#246;llig ungeeignet waren.1927 Daf&#252;r startete er mit
einem f&#252;r Kleinkinder geeigneten Video und lie&#223; YouTube mit der Autoplay-Funktion automatisch entscheiden,
was als N&#228;chstes gezeigt wird. Nach einigen Episoden verschlechterte sich die Qualit&#228;t der Videos dramatisch
und sie zeigten f&#252;r Kleinkinder v&#246;llig ungeeignete Inhalte, die aber oft mit den bekannten Charakteren aus
Kleinkindserien dargestellt wurden, beispielsweise blutende Mickym&#228;use oder Grabsteine f&#252;r Figuren aus der Serie
Paw Patrol. Vermutlich werden hier durch Inhaltsanbieter Videos mehr oder weniger automatisch aus relativ
zuf&#228;lligen Videos von anderen Anbietern zusammengeschnitten. Da Kleinkinder teilweise vor den Ger&#228;ten allein
1922 Vgl. Noble (2018): Algorithms of oppression; Thompson (2017): Our Minds Have Been Hijacked by Our Phones. Tristan Harris
Wants to Rescue Them; Wu (2017): The attention merchants; Alter (2017): Irresistible.
1923 Vgl. Doerr (2018): OKR, Kapitel 14 &#8222;Die YouTube-Geschichte&#8220;.
1924 Vgl. Bridle (2017): Something is wrong on the internet &#8288;; Lewis und McCormick (2018): How an ex-YouTube insider investigated its
secret algorithm. F&#252;r weitere Informationen dazu auch die Webseite von Guillaume Chaslot, der eine Reihe von jeweils viel
empfohlenen Videos pro Tag ver&#246;ffentlicht: https://algotransparency.org/?date=04-05-2020&amp;keyword= (zuletzt abgerufen am 11. August
2020).
1925 Vgl. Wojcicki (2017): Expanding our work against abuse of our platform.
1926 Weitere Informationen zu den von Google nicht empfohlenen Praktiken der Inhaltebewerbung unter: https://support.google.com/web-
masters/answer/35769 (zuletzt abgerufen am 11. August 2020).
1927 Vgl. Bridle (2017): Something is wrong on the internet.
gelassen werden, schalten sie diese Inhalte nicht ab &#8211; der Algorithmus h&#228;lt sie also weiter f&#252;r relevant, best&#252;ckt
sie weiterhin mit Werbung und empfiehlt sie weiter. Dadurch k&#246;nnen Inhaltsproduzenten auch mit Videos dieser
Art noch Werbeeinnahmen erzielen. Auch f&#252;r Erwachsene hat die Ausspielung von immer radikaleren,
extremeren und polarisierenderen Inhalten mit zunehmender Nutzung Auswirkungen auf die Debattenqualit&#228;t sowie
Meinungsbildung. 
6.1.1 Handlungsempfehlungen
In Kapitel 6.1 dieses Projektgruppenberichts [Problematische Aspekte von Empfehlungssystemen] wurde
insbesondere darauf hingewiesen, dass Empfehlungssysteme auch nicht-jugendgerechte Inhalte an jugendliche Nutzer
ausspielen. 
Daher m&#252;ssen die Institutionen des Kinder- und Jugendschutzes inhaltlich wie personell die notwendige
Kompetenzerweiterung bekommen, um zu &#252;berpr&#252;fen, ob Kinder und Jugendliche vor f&#252;r sie nicht geeigneten
Inhalten gesch&#252;tzt sind, die durch KI-Systeme erzeugt und / oder ausgew&#228;hlt werden. Zus&#228;tzlich bedarf es der
notwendigen Strukturen, um Verst&#246;&#223;e gegen den Kinder- und Jugendschutz zu ahnden und deren Beseitigung
durchzusetzen. Zudem sollten Verbraucherinnen und Verbraucher dar&#252;ber aufgekl&#228;rt werden, wie
Empfehlungssysteme wirken k&#246;nnen und dass beispielsweise Kleinkinder nicht alleine vor YouTube oder &#228;hnliche
Videoplattformen gesetzt werden d&#252;rfen, auch wenn z. B. YouTube bereits ein Jugendschutzsystem einsetzt, das eine
Filterung von Inhalten vornimmt, die f&#252;r bestimmte Altersstufen geeignet sind. Vor allem jedoch sollten die
Plattformen ihre Verantwortung wahrnehmen: Eine systematische Kontrolle der Inhalte durch Jugendsch&#252;tzer und
reaktive Ansprechpartnerinnen und -partner auf den Plattformen, die Inhalte aus Empfehlungslisten f&#252;r Kinder
und Jugendliche nehmen k&#246;nnen, w&#228;ren w&#252;nschenswert.1928 Angesichts der gro&#223;en Mengen an Inhalten, die
t&#228;glich auf den Plattformen hochgeladen werden, ist eine Pr&#252;fung von allen Inhalten durch Jugendsch&#252;tzern eine
gro&#223;e Herausforderung.
Personalisierung
6.2.1 Algorithmisch personalisierte Nachrichtenkan&#228;le und politisches Microtargeting
Algorithmisch personalisierte Nachrichtenkan&#228;le
Die Auswahl und Ausgabe von Nachrichten erfolgt aufgrund der gro&#223;en Menge verf&#252;gbarer Information in der
Medien&#246;ffentlichkeit durch sogenannte Gatekeeper.1929 Sie entscheiden nach bestimmten Kriterien, welche
Informationen relevant sind. Dabei ver&#228;ndert sich nach und nach die mediale Relevanz.1930 Fr&#252;her war gem&#228;&#223; der
sogenannten Nachrichtenwerttheorie vorrangig die journalistische Auswahl nach Nachrichtenfaktoren
(Bedeutung: Ausma&#223; und Konsequenzen; Publikumsinteresse: r&#228;umliche und psychologische Nahe, Prominenz,
Aktualit&#228;t, Human Interest)1931 entscheidend. Heutzutage erfolgt der Zugang oft digital und den Angesprochenen
bieten sich deutlich mehr Wahlm&#246;glichkeiten f&#252;r den Nachrichtenzugang. Im Rahmen der Angebote findet dabei
h&#228;ufig eine algorithmisch gesteuerte Auswahl statt (Suchmaschine und Thema, Aggregatoren, soziale
Netzwerke). Dabei erfolgt nur die Informationsausgabe automatisch. Ausschlaggebend ist die steuerbare Vorgabe,
was einbezogen wird und was nicht &#8211; und wie es f&#252;r die Ausgabe gewichtet wird. Insbesondere
Medienintermedi&#228;re setzen KI-basierte Empfehlungssysteme ein, die die Inhalte, mit denen die Nutzerinnen und Nutzer
interagieren, in einer hochgradig personalisierten Art und Weise verbreiten.
Von algorithmisch personalisierten Nachrichtenkan&#228;len ist dann die Rede, wenn ein System auf der Basis
nutzerbasierter Personalisierung zus&#228;tzlich selbst aktiv wird und die pr&#228;sentierten Inhalte mittels Algorithmen auf
Basis von Bed&#252;rfnissen, die aus Nutzerdaten automatisiert abgeleitet werden, ausw&#228;hlt und priorisiert.1932 KI
1928 M&#246;glichkeiten zum Umgang mit den Risiken von APN unabh&#228;ngig vom Jugendschutz werden im folgenden Kapitel 6.2 dieses
Projektgruppenberichts [Personalisierung] aufgegriffen.
1929 Der Gatekeeping-Ansatz ist umstritten. Stellvertretend f&#252;r viele Engelmann (2016): Gatekeeping: &#8222;Der Gatekeeping-Ansatz ist einer
der prominentesten Ans&#228;tze der Nachrichtenauswahl. Urspr&#252;nglich besch&#228;ftigte sich der Ansatz mit der Frage, welche Informationen
f&#252;r die &#246;ffentliche Verbreitung ausgew&#228;hlt werden und welche Einflussfaktoren dabei eine Rolle spielen. Im Internet filtern
zunehmend auch das Publikum und technische Auswahlhilfen relevante Informationen heraus und bet&#228;tigen sich damit als Gatekeeper.&#8220;.
1930 Pr&#228;sentation von Prof. Dr. Christian St&#246;cker (Hochschule f&#252;r Angewandte Wissenschaften Hamburg), Projektgruppendrucksache
19(27)PG 6-17 vom 16. Dezember 2019.
1931 Vgl. Weischenberg und Rakers (2001): Nachrichten-Journalismus, S. 26 ff.
1932 Vgl. Schweiger et al. (2019): Algorithmisch personalisierte Nachrichtenkan&#228;le, S. 7&#8211;8.
wird sowohl bei der Berechnung von Nutzerinteressen als auch bei der Bewertung der Relevanz von
Medieninhalten eingesetzt.1933 Anders als traditionelle Medien (Zeitungen, TV) k&#246;nnen mediale Intermedi&#228;re automatisiert
mithilfe detaillierter Profilbildung die Auswahl medialer Inhalte auf jeden einzelnen Nutzenden individuell
zuschneiden. Die Relevanz der Inhalte wird z. B. bei Facebook nicht nach journalistischen Ma&#223;st&#228;ben bestimmt, 
sondern unter anderem aus dem User-Engagement oder sogenannten &#8222;meaningful interactions&#8220; &#8211; also Reaktionen 
wie Likes, Shares und Kommentaren &#8211; abgeleitet. Google bestimmt Relevanz mit &#8222;User-Signals1934&#8222; (Click-
1936 In-Through-Rate, Bounce-Rate, Direct-/Repeat-Traffic und Dwell-Time) und YouTube mit Watch-Time1935. 
zwischen ist die algorithmisch personalisierte Auswahl bei j&#252;ngeren Zielgruppen (18 bis 24 Jahre) der am
h&#228;ufigsten verwendete Zugangsweg zu Nachrichten; insgesamt greifen die meisten Menschen aber weiterhin direkt
und ohne Umwege auf ein Nachrichtenangebot zu, also auf die Webseite oder die App einer
Nachrichtenmarke.1937 Facebook ist nach eigenen Angaben zwar inzwischen wichtiger als z. B. Google, aber damit gemeint
ist eigentlich nur die Funktion, &#252;ber Teaser1938 auf entsprechende mediale Angebote weiterzuleiten.
Die Entscheidungen &#252;ber die Nachrichtenauswahl bestimmen jedenfalls Vielfalt und Charakter des &#246;ffentlichen
Diskurses. Egal ob sie von Redakteurinnen und Redakteuren oder von den automatisierten Ein- und
Ausgabewerkzeugen eines Medienintermedi&#228;rs getroffen werden, sie setzen die Standards f&#252;r lebhafte Debatten und
best&#228;tigen dadurch deren Legitimit&#228;t und Aussage.1939 Engagement, Watch-Time, Dwell-Time1940 etc. sind aber
nicht das Gleiche wie Relevanz oder gar Qualit&#228;t, denn deskriptive Ans&#228;tze &#8211; wie gro&#223;teils bei algorithmisch
personalisierten Nachrichtenkan&#228;len bestimmend &#8211; unterscheiden sich von normativen Ans&#228;tzen.1941 
Die Algorithmen beeinflussen insofern auch die politische Kommunikation. Zus&#228;tzlich lassen sich die derzeitigen
Empfehlungssysteme leicht manipulieren.1942 Zwar handelt es sich um sogenannte Black Boxes,1943 da nicht
nachvollziehbar ist, welche Kriterien genau mit welcher Gewichtung verarbeitet werden, aber es sind wenige
Nutzerinnen und Nutzer f&#252;r die Mehrzahl der Inhalte verantwortlich. So generieren in Deutschland 20 Prozent
der Nutzerinnen und Nutzer etwa 56 Prozent der Inhalte (in &#214;sterreich: 20 Prozent der Nutzerinnen und Nutzer
etwa 73 Prozent der Inhalte; in den USA: 10 Prozent der Nutzerinnen und Nutzer etwa 80 Prozent der Inhalte).1944 
Ist &#8222;meaningful interaction&#8220; nun die Kerngr&#246;&#223;e, die der Algorithmus zu optimieren versucht, bedeutet dies: Wenn
Posts zehnmal mehr Reaktionen erzeugen, dann werden diese Inhalte auch als zehnmal wichtiger eingestuft und 
immer mehr Menschen ungefragt in den Newsfeed eingeblendet.1945 Diese wenigen hyperaktiven Nutzerinnen
und Nutzer bringen insofern andere Pr&#228;ferenzen in die Sortierung ein als der Rest. 
Es muss grunds&#228;tzlich festgehalten werden, dass algorithmisch personalisierte Nachrichtenkan&#228;le sowohl
positive als auch negative Auswirkungen auf die Demokratie haben k&#246;nnen.1946 Deshalb ist Folgendes wichtig: Es
gibt keinen monokausalen Zusammenhang zwischen personalisierten Angeboten und einer Spaltung der
Gesellschaft, die den demokratischen Zusammenhalt gef&#228;hrdet. Dennoch erscheint es angebracht, die Technologie mit
1933 Zu den technischen Grundlagen von Empfehlungssystemen siehe auch Kapitel 3.2.4 dieses Projektgruppenberichts [Technische
Grundlagen von Empfehlungssystemen].
1934 Als &#8222;User Signals&#8220; werden alle Signale bezeichnet, die Internetnutzende durch die Art und Weise erzeugen, wie sie eine Webseite 
nutzen.
1935 Die Watch-Time misst, wie lange ein Video angeschaut wurde.
1936 Pr&#228;sentation von Prof. Dr. Christian St&#246;cker (Hochschule f&#252;r Angewandte Wissenschaften Hamburg), Projektgruppendrucksache
19(27)PG 6-17 vom 16. Dezember 2019.
1937 Vgl. H&#246;lig und Hasebrink (2019): Reuters Institute Digital News Report 2019 &#8211; Ergebnisse f&#252;r Deutschland, S. 39 f.
1938 Ein Teaser ist ein kurzes Text- oder Bildelement, das zum Weiterlesen, -h&#246;ren, -sehen, -klicken verleiten soll.
1939 Vgl. Gillespie (2014): The Relevance of Algorithms.
1940 Dwell-Time beschreibt das jeweilige Zeitfenster, in dem eine Besucherin oder ein Besucher auf einer durch eine Suchmaschine 
gefundenen Webseite verweilt, bevor diese bzw. dieser sie wieder verl&#228;sst und zu der Suchmaschinen-Ergebnisseite zur&#252;ckkehrt.
1941 Pr&#228;sentation von Prof. Dr. Christian St&#246;cker (Hochschule f&#252;r Angewandte Wissenschaften Hamburg), Projektgruppendrucksache
19(27)PG 6-17 vom 16. Dezember 2019.
1942 Pr&#228;sentation von Orestis Papakyriakopoulos (Hochschule f&#252;r Politik M&#252;nchen an der Technischen Universit&#228;t M&#252;nchen),
Projektgruppendrucksache 19(27)PG 6-13 vom 13.Dezember 2019; siehe auch Kapitel 6.1 dieses Projektgruppenberichts [Problematische
Aspekte von Empfehlungssystemen].
1943 Siehe auch Kapitel 4.2 des Mantelberichts [Transparenz, Nachvollziehbarkeit und Erkl&#228;rbarkeit] und auch Kapitel 7.3.2 dieses
Projektgruppenberichts [Technische M&#246;glichkeiten der Governance von ADM-Systemen].
1944 Pr&#228;sentation von Orestis Papakyriakopoulos (Hochschule f&#252;r Politik M&#252;nchen an der Technischen Universit&#228;t M&#252;nchen),
Projektgruppendrucksache 19(27)PG 6-13 vom 13. Dezember 2019.
1945 Vgl. Hegelich und Serrano (2019): Microtargeting in Deutschland bei der Europawahl 2019, S. 14.
1946 Inputpapier von Dr. Ben Scott (Policy &amp; Advocacy), Projektgruppendrucksache 19(27)PG 6-19 vom 7. Februar 2020.
einem tiefen Verst&#228;ndnis der demokratischen Werte umzusetzen, denen auch algorithmische Empfehlungen
dienen k&#246;nnten &#8211; entscheidend ist die Art und Weise, wie die Technologie angewandt wird.1947 Zwar werden die 
Systeme zum Gro&#223;teil nicht in Europa entwickelt, wohl aber hier eingesetzt. Derzeitige algorithmisch
personalisierte Nachrichtenkan&#228;le m&#252;ssten anders gestaltet werden, wenn sie sich besser f&#252;r die politische Kommunikation
eignen sollen. Denn allzu oft werden Nachrichtenempfehlungen mit rein kommerziellen Zielen entwickelt, die
auf Aufmerksamkeit ausgerichtet sind. Ihre Ausrichtung anhand von aus dem Marketing stammenden
Gesichtspunkten widerspricht den Grundvoraussetzungen f&#252;r Kommunikation, die in Wahrhaftigkeit, Vertrauen und
Realit&#228;tsbezug liegen.1948 
Politisches Microtargeting
Im Zusammenhang mit algorithmisch personalisierten Nachrichtenkan&#228;len hat vor allem das sogenannte
politische Microtargeting gro&#223;e mediale Aufmerksamkeit erfahren. Dabei handelt es sich um eine Art personalisierter
Kommunikation, bei der Informationen &#252;ber Personen gesammelt und dann im Rahmen eines Predictive-
Analytics-Verfahrens dazu verwendet werden, zielgruppenspezifische politische Werbung zu zeigen und die Personen
damit zu beeinflussen.1949 Bekannt geworden ist das Verfahren im Zusammenhang mit dem Skandal um die
Firma Cambridge Analytica, die behauptet hatte, die US-Pr&#228;sidentschaftswahl im Jahr 2016 zugunsten von
Donald Trump und im gleichen Jahr das Brexit-Referendum zugunsten derjenigen beeinflusst zu haben, die den
Brexit bef&#252;rworteten.1950 Risiken durch datengesteuertes Microtargeting werden insbesondere f&#252;r die
Meinungsbildungsfreiheit der B&#252;rgerinnen und B&#252;rger und die Wahlgrunds&#228;tze gesehen.1951 Ob KI-basiertes
Microtargeting allerdings &#252;berhaupt wirkt, konnte bisher nicht festgestellt werden.1952 Seine Grenzen findet es in Europa
vor allem durch das Datenschutzrecht,1953 auch wenn es nach der DSGVO nicht explizit ausgeschlossen ist, und
durch sogenanntes Data-Bias,1954 also &#8222;falsche&#8220; Datengrundlagen, die daf&#252;r sorgen, dass das Ergebnis nicht zu
den Angesprochenen &#8222;passt&#8220;. Da das Thema jedoch sehr gro&#223;e Aufmerksamkeit erfuhr, haben die Intermedi&#228;re
reagiert: Twitter untersagt politische Werbung inzwischen,1955 Facebook hat als Transparenzmechanismus eine 
AdLibrary eingef&#252;hrt,1956 um sich nicht mehr vorwerfen lassen zu m&#252;ssen, sogenannte DarkAds &#8211; also nur den
Angesprochen bekannte Werbung &#8211; zu erm&#246;glichen, und Google ver&#246;ffentlicht jetzt unter anderem einen
Transparenzbericht &#252;ber politische Werbung.1957 Diese Ma&#223;nahmen stehen in der Kritik, unter anderem, da die
Werbeanzeigen nicht immer pers&#246;nlich gepr&#252;ft werden und somit diejenigen, die Werbung buchen, entscheiden, ob
es sich um politische Werbung handelt oder nicht und es in der Praxis viele weitere M&#228;ngel bei der Umsetzung
gibt.1958 Im Gegensatz zu klassischen Medien bestehen keine f&#252;r Intermedi&#228;re angepassten gesetzlichen Regeln
f&#252;r politische Werbung.
Der Zugang zu Informationen und der Austausch &#252;ber Medienintermedi&#228;re haben zu einer neuen Art des
politischen Austauschs gef&#252;hrt, in der Nutzerinnen und Nutzer sowie politische Akteure auf die klassischen
Gatekeeper verzichten und sich aufgrund anderer Gemeinsamkeiten organisieren (lassen). Allerdings ist der so
entstandene Diskurs anhand von Kriterien gestaltet, die aus der Aufmerksamkeits&#246;konomie stammen. Dieses Modell ist 
zwar zu gro&#223;en Teilen im t&#228;glichen Leben akzeptiert, in dem die Bev&#246;lkerung st&#228;ndig einer Beeinflussung durch
1947 Vgl. Helberger (2019): On the Democratic Role of News Recommenders, S. 993&#8211;1012.
1948 Vgl. Nida-R&#252;melin (2019): Medientage M&#252;nchen 2019 vom 23. bis 25. Oktober Zur Ethik der Kommunikation in der digitalen
Lebenswelt.
1949 Vgl. Zuiderveen Borgesius et al. (2018): Online Political Microtargeting: Promises and Threats for Democracy, S. 82 f.
1950 Ausf&#252;hrlich dazu und mit weiteren Nachweisen Christl (2019): Microtargeting, Pers&#246;nliche Daten als politische W&#228;hrung, S. 42 f.
1951 Vgl. Gr&#228;fe (2018): Webtracking und Microtargeting als Gefahr f&#252;r Demokratie und Medien, S. 8 f.
1952 Vgl. Baum et al. (2019): Do they really care about targeted political ads? Investigation of user privacy concerns and preferences; vgl.
auch Hegelich und Serrano (2019): Microtargeting in Deutschland bei der Europawahl 2019, S. 14, danach sorgen hyperaktive
Userinnen bzw. User und politisch gebrandete Profile f&#252;r mehr Aufmerksamkeit als einfache bezahlte Werbeanzeigen.
1953 Vgl. Ebers (2018): Beeinflussung und Manipulation von Kunden durch Behavioral Microtargeting, S. 425&#8288;; Klaas (2019):
Demokratieprinzip im Spannungsfeld mit k&#252;nstlicher Intelligenz: demokratische Entscheidungsfindung durch und mithilfe von
selbstlernenden Algorithmen, S. 89.
1954 Vgl. Papakyriakopoulos et al. (2018): Social media and microtargeting: Political data processing and the consequences for Germany, S. 3.
1955 Vgl. Twitter ads policies, prohibited content, weitere Informationen dazu unter: https://business.twitter.com/en/help/ads-policies/pro-
hibited-content-policies/political-content.html (zuletzt abgerufen am 3. August 2020).
1956 Vgl. Facebook-Werbebibliothek, weitere Informationen dazu unter: https://www.facebook.com/ads/library (zuletzt abgerufen am
3. August 2020).
1957 Vgl. Spencer (2019): An update on our political ads policy.
1958 Vgl. Smith (2020): The UK Election Showed Just How Unreliable Facebook&#8217;s Security System For Elections Really Is &#8288;; Boyd (2020):
Facebook's New Transparency Updates: Helpful, But Not Exhaustive.
(kommerzielle) Interessen ausgesetzt ist. Allerdings lehnt eine Mehrheit von in Deutschland befragten
B&#252;rgerinnen und B&#252;rgern die Personalisierung politischer Botschaften ab.1959 
Das gemeinsame Hauptproblem von algorithmisch personalisierten Nachrichtenkan&#228;len und Microtargeting liegt
darin, dass eine Angst besteht, dass intransparente Systeme und gezielte Beeinflussung durch
Vorhersagemethoden dem Leitbild des &#246;ffentlich gef&#252;hrten Meinungskampfes entgegenstehen. Zudem bergen algorithmisch
personalisierte Nachrichtenkan&#228;le und verhaltensbasiertes Microtargeting erhebliche Diskriminierungsrisiken, die
gesellschaftliche Spaltungen versch&#228;rfen k&#246;nnen.1960 Beispielsweise war es eine Zeit lang m&#246;glich, Anzeigen bei
Facebook zu posten, die sich explizit an Antisemitinnen und Antisemiten richteten, bis dies durch investigative
Recherchen aufgedeckt wurde.1961 Versuche, &#252;ber automatisierte Systeme Spam zu filtern, k&#246;nnen dazu f&#252;hren,
dass Inhalte von Minderheiten nicht angezeigt werden (&#8222;shadow banning&#8220;).1962 Aufgabe der Gesellschaft ist es 
deshalb, zu diskutieren und letztendlich festzulegen, ob ein Level Playing-Field &#8211; etwa im Sinne eines Standards
&#8211; f&#252;r algorithmisch personalisierte Nachrichtenkan&#228;le und Microtargeting festgesetzt werden muss. Erste Ans&#228;tze
hierzu gibt es im Entwurf des Medienstaatsvertrags, der Transparenzpflichten vorschreibt, die jedoch nicht mehr
als ein erster Anfang sind. In jedem Fall brauchen Politik und Gesellschaft ein tieferes Verst&#228;ndnis der
Auswirkungen, insbesondere auf die demokratischen Prozesse, sodass die M&#246;glichkeit zu interdisziplin&#228;rer Erforschung
der Ph&#228;nomene an erster Stelle stehen muss.
6.2.2 Handlungsempfehlungen
Es gibt noch keine hinreichenden wissenschaftlichen Erkenntnisse &#252;ber die genauen Folgen von Microtargeting
f&#252;r die &#246;ffentliche Meinungsbildung. Der Einfluss auf den Wettbewerb der Meinungen l&#228;sst sich aber ebenso
wenig leugnen. Das erschwert eine angemessene Bewertung potenzieller Regulierung. Aufgrund des noch
herrschenden Wissensdefizits erscheint eine weitere Regulierung von algorithmisch personalisierten
Nachrichtenkan&#228;len deshalb noch nicht sinnvoll und zielf&#252;hrend. Die dringendste Aufgabe ist die weitere interdisziplin&#228;re
Erforschung der Ph&#228;nomene, also sowohl der Auswirkung von algorithmisch personalisierten Nachrichtenkan&#228;len
auf die Meinungsbildung als auch von politischem Microtargeting auf Wahlentscheidungen. Sinnvoll w&#228;re eine 
Verbindung kommunikations-, politik-, rechts- und informations-/datenwissenschaftlicher Methoden und
Erkenntnisse. Das derzeitig zu l&#246;sende Problem ist, wie der systematische und permanente Zugang zu den
gesammelten und von den Plattformen benutzten Daten f&#252;r die Forschung gew&#228;hrleistet werden kann.1963 Schlie&#223;lich
ist an eine F&#246;rderung zur Ausweitung bestehender Public-Private-Partnership-Vereinbarungen zu denken sowie
an deren rechtliche Erm&#246;glichung. Zudem sollte es &#228;hnlich wie bei der personalisierten Ansprache im Offline-
Bereich (etwa bei postalischer Wahlwerbung) Begrenzungen daf&#252;r geben, welche pers&#246;nlichen Verhaltensdaten
f&#252;r politisches Microtargeting genutzt werden d&#252;rfen. Diese Begrenzung sollte sowohl f&#252;r das Targeting (durch
die Werbetreibenden) als auch f&#252;r das Anzeigen von Werbung (durch die KI der Plattformen) gelten. Hier sollten 
gesetzliche Regeln die freiwilligen Ma&#223;nahmen einiger Plattformen (z. B. Google) ersetzen. Durch solche Regeln
kann verhindert werden, dass kleinen, homogenen Nutzergruppen gezielt solche bezahlten Botschaften angezeigt
werden, von der KI-Systeme vermuten, dass sie deren Meinungen und &#196;ngste verst&#228;rken und so zu
&#8222;Engagement&#8220; f&#252;hren.
Der Entwurf des Medienstaatsvertrags sieht f&#252;r Medienintermedi&#228;re spezielle Transparenzpflichten vor und die
DSGVO schr&#228;nkt den Einsatz von Microtargeting ein. Weiterf&#252;hrende Informationen speziell beim politischen
Microtargeting vorzuschreiben ist aber gut denkbar. Die Kennzeichnungspflichten f&#252;r politische Werbung
m&#252;ssen gerade f&#252;r den Online-Bereich ausgebaut werden. Diese sollten sowohl f&#252;r eine deutliche (visuelle)
Unterscheidung zwischen bezahlten und unbezahlten Inhalten sorgen als auch Informationen zur Ausspielung der
Werbung enthalten. Aufgrund der verhaltensbasierten, KI-gesteuerten Platzierung politischer Online-Werbung
m&#252;ssen Nutzerinnen und Nutzer die Option haben, mehr Informationen &#252;ber die Kriterien f&#252;r Targeting und
Ausspielung von Werbung zu erhalten, als dies offline der Fall ist. Hierf&#252;r sind gesetzliche Vorgaben n&#246;tig, die aber
auch unterschiedliche Gr&#246;&#223;en und Nutzungsarten der Plattformen ber&#252;cksichtigen. Gut erg&#228;nzen w&#252;rden sich ein
&#246;ffentliches Register &#8211; im Sinne einer Pflicht zur Publizit&#228;t &#8211; und die Pflicht, die Angesprochenen dar&#252;ber zu
informieren, wie die Werbeauswahl zustande kam &#8211; im Sinne einer Transparenzpflicht. Denkbar w&#228;re es, die 
1959 Vgl. Kozyreva et al. (2020): Artificial intelligence in online environments: Representative survey of public attitudes in Germany.
1960 Vgl. Ranking Digital Rights (2019): Consultation Draft &#8211; Human rights risk scenarios: Algorithms, machine learning and automated 
decision-making&#8288;; Ranking Digital Rights (2019): Consultation Draft &#8211; Human Rights Risk Scenarios: Targeted Advertising.
1961 Vgl. Angwin et al. (2020): Facebook Enabled Advertisers to Reach &#8216;Jew Haters&#8217;.
1962 Vgl. Erlick (2018): How Instagram May Be Unwittingly Censoring the Queer Community.
1963 Siehe auch Kapitel 5.4 dieses Projektgruppenberichst [Datenzugang als Voraussetzung f&#252;r Datenanalyse], zweiter Abschnitt:
Datenzugang.
Angesprochenen gesondert dar&#252;ber zu informieren, warum sie diesen bestimmten politischen Inhalt sehen, oder
einen allgemeinen Wahlwerbehinweis einzublenden, wie er im Rundfunk &#252;blich ist. Da es au&#223;erdem fraglich ist, 
ob der Gesetzgeber mit seinem Instrumentarium in der Lage ist, verdeckte gezielte Desinformationskampagnen
zu verhindern, scheint ein Verbot von Microtargeting nur eine Scheinl&#246;sung zu sein. Viele B&#252;rgerinnen und 
B&#252;rger lehnen Microtargeting jedenfalls ab, das zeigt eine Umfrage: Die Befragten sprachen sich mehrheitlich
gegen personalisierte Werbung aus, aber auch gegen ma&#223;geschneiderte Social-Media-Feeds und gegen eine
Personalisierung in Online-Zeitungen. Das zeigt, dass Menschen realisieren, dass f&#252;r das Funktionieren einer
Gesellschaft eine unabh&#228;ngige politische Meinungsbildung wichtig ist. Ebenso sieht die Projektgruppe den Bedarf,
Microtargeting im politischen Bereich &#8211; soweit es dort angewendet werden soll &#8211; transparent zu gestalten.
Zudem ist zu fordern, dass allgemein mehr Aufkl&#228;rung bzgl. Microtargeting betrieben wird, denn die Studie stellt
auch fest, dass Menschen oftmals nicht klar ist, welche pers&#246;nlichen Daten Unternehmen verwenden, um
passende Empfehlungen anzuzeigen.1964 Sinnvoll w&#228;re es allerdings, wenn s&#228;mtliche Werbung im
gesellschaftlichpolitischen Bereich &#246;ffentlich nachvollziehbar bleibt und f&#252;r direkte Wahlwerbung &#8211; unabh&#228;ngig vom
Verbreitungsweg &#8211; eine allgemeine Regel besteht. &#214;ffentlichkeit und Transparenz m&#252;ssen evaluier- und durchsetzbar
sein. 
6.2.3 Milieubildung: Filterblasen und Echokammern
Im Jahr 2011 warnte Eli Pariser1965 davor, dass personalisierte Nachrichten-Empfehlungssysteme dazu f&#252;hren 
k&#246;nnten, dass Nutzerinnen und Nutzer nur noch Inhalte sehen, die zu ihren schon gefassten Meinungen passen.
Er befand dabei insbesondere die Verteilung von politischen Nachrichten als kritisch, wenn alle Nutzerinnen und
Nutzer aufgrund der Personalisierung ihrer Empfehlungssysteme nur noch Meinungen aus ihrem jeweiligen
politischen Spektrum bekommen &#8211; ein Ph&#228;nomen, das er als Filterblase bezeichnete. Verwandt damit ist der Begriff
der Echokammer. Er bezeichnet eine Gruppe von Menschen, mit denen man sich z. B. auf sozialen
Netzwerkplattformen austauscht und die so homogen ist, dass man von allen Seiten die eigene Meinung best&#228;tigt bekommt,
anstatt auch kontroverse Positionen zur Kenntnis zu nehmen.
Beide Ph&#228;nomene, Filterblase und Echokammer, sind einerseits das Resultat von Algorithmen, die personalisiert 
dasjenige ausw&#228;hlen und hoch anordnen, mit dem Nutzerinnen und Nutzer sich schon vorher viel besch&#228;ftigt
haben, und andererseits das Resultat der Tatsache, dass der Mensch Homogenit&#228;t im Bekanntenkreis sch&#228;tzt und
gerne seine eigenen Meinungen best&#228;tigt sieht.1966 
So werden etwa bei Google-Suchanfragen oder im Newsfeed von sozialen Medien Nutzerinnen und Nutzern
Informationen angezeigt, die ein Algorithmus f&#252;r sie vorausgew&#228;hlt hat. Daraus ergibt sich ein komplexes
Problem: Diese Angebote sind auf mutma&#223;liche Interessen abgestimmt. Die Betroffenen haben kaum Einfluss auf
die erhobenen Daten. Input und Output sowie die Funktionsweisen dieser komplexen Entscheidungsprozesse
sind f&#252;r die Mehrheit nicht transparent. Sie wissen gegebenenfalls noch nicht mal, dass eine Vorauswahl
stattgefunden hat, und gehen davon aus, ein ungefiltertes Informationsangebot zu erhalten. Weiterhin divergieren die
von den Plattformen verwendeten Systeme; so scheint es bei Facebook nicht so sehr auf die algorithmische Filterung
anzukommen, sondern auf das Verhalten des eigenen Netzwerks.1967 
Vor allem die einseitige Wahrnehmung und Meinungsvermittlung bei politischen Themen werden in der
Wissenschaft und in den Medien diskutiert. Man kann davon ausgehen, dass die personalisierten Nachrichtenquellen
eine konstruktive Auseinandersetzung mit politischen Fremdmeinungen verhindern; darin besteht eine
potenzielle Gefahr f&#252;r die Demokratie und den Zusammenhalt in der Gesellschaft.1968 Wenn also einer Person einseitig
Informationen angezeigt werden und / oder sie sich in einer Echokammer bewegt, also beispielsweise in R&#228;umen
von Facebook, in denen ihr ausschlie&#223;lich und wiederholt Inhalte angeboten werden, die nur eigene Meinungen
verst&#228;rken, dann verzerrt dies die Sicht auf die Agenda der Allgemeinheit, insbesondere wenn die Haltung
hinzukommt, sich anderen Informationsquellen weitestgehend zu verschlie&#223;en. Andere wiederum halten den Effekt
1964 Vgl. Hegemann (2020): Personalisierung ja, aber bitte nicht mit meinen Daten!.
1965 Vgl. Pariser (2012): Filter Bubble.
1966 Im Folgenden wird nicht weiter bzgl. der beiden Ph&#228;nomene differenziert. Es soll an dieser Stelle jedoch darauf hingewiesen werden,
dass beide Ph&#228;nomene zwar auf sozialen Strukturen basieren, die systematisch Informationsquellen ausschlie&#223;en und Nutzerinnen
und Nutzer in einseitigen &#220;berzeugungen st&#228;rken, aber auf verschiedene Arten arbeiten, und dass daher aus soziokultureller Sicht
auch verschiedene Interventionsans&#228;tze existieren. Einen &#220;berblick gibt Nguyen (2020): Escape the echo chamber.
1967 Einen &#220;berblick &#252;ber die wissenschaftliche Diskussion hierzu bietet Ovens (2017): Filterblasen &#8211; Ausgangspunkte einer neuen,
fremdverschuldeten Unm&#252;ndigkeit?
1968 Vgl. Ovens (2017): Filterblasen &#8211; Ausgangspunkte einer neuen, fremdverschuldeten Unm&#252;ndigkeit? &#8288;.
f&#252;r &#252;bersch&#228;tzt.1969 Das liegt vor allem daran, dass sich Benutzerinnen und Benutzer doch weitergehend
informieren, in viele verschiedene Kommunikationsnetzwerke eingebunden sind oder auch weiterhin mehrere
klassische und somit ausgewogene Quellen nutzen.1970 Au&#223;erdem kommunizieren Menschen auch pers&#246;nlich
miteinander und nicht nur &#252;ber soziale Netzwerke. Die tats&#228;chliche Wirkung bleibt somit weiter zu untersuchen.1971 
Die Annahme, dass eine Meinung umso einseitiger gebildet wird, je weniger verschiedene Informationsquellen
aufgenommen werden, ist nicht neu. Sie traf auch schon in Zeiten des analogen Medienangebots ohne soziale
Medien und KI mit Blick auf solche Nutzergruppen zu, die sich absichtlich oder unabsichtlich, z. B. aufgrund
eines geringeren Bildungsniveaus, nur aus wenigen gleichgerichteten Quellen informierten.1972 Neu sind aber der
interaktive Charakter der sozialen Medien, der eine permanente gegenseitige Best&#228;tigung erm&#246;glicht, und KI-
gesteuerte Filterungsmechanismen, die das Ph&#228;nomen verst&#228;rken k&#246;nnen. Auch legen Untersuchungen nahe, dass
verschiedene Nutzergruppen unterschiedlich stark betroffen sein k&#246;nnten.
So kommt eine aktuelle Studie der Universit&#228;t Ulm zu dem Ergebnis, dass algorithmische Filterung die
Ph&#228;nomene von Filterblasen und Echokammern verst&#228;rkt: Menschen, die sich ausschlie&#223;lich aus dem Newsfeed
sozialer Medien informieren, haben demnach das gr&#246;&#223;te Risiko, in einer Blase oder Echokammer zu landen, wenn
sie nur eine Art von Nachrichtenquelle nutzen, in der auch noch potenziell stark selektierte Informationen
angeboten werden. Dazu kommt die f&#252;r soziale Medien typische eigene Auswahl, die die Vorauswahl durch
Algorithmen noch einmal potenzieren kann.1973 Zwar ist diese Nutzergruppe noch in der Minderheit (bei den
Probandinnen und Probanden unter 5 Prozent1974); gekoppelt mit der Erkenntnis, dass sich solche Newsfeed-
Nutzergruppen vorwiegend aus jungen Erwachsenen zusammensetzen sowie aus solchen mit eher autorit&#228;ren
Einstellungen, muss dies aber weiter beobachtet werden &#8211; zumal wenn man annimmt, dass sich die Faktoren tendenziell
verst&#228;rken, also dass der personalisierte Medienkonsum zunimmt, der Anteil der Newsfeed-Gruppe steigt und
sich die Software und daran beteiligte KI-Systeme immer weiter verfeinern.
Um Missverst&#228;ndnissen vorzubeugen, sei darauf hingewiesen, dass das Filterblasen-Konzept in seiner
Ausschlie&#223;lichkeit, wie es Eli Pariser beschrieben hat, von der Projektgruppe nicht gesehen wird. Vielmehr folgt sie
der Auffassung, dass zur &#246;ffentlichen Meinungsbildung andere Kommunikationsstrukturen einen st&#228;rkeren
Einfluss auf die &#246;ffentliche Meinungsbildung durch Plattformen haben k&#246;nnen als durch algorithmische
Filterung.1975 Folglich k&#246;nnen vermeintliche Filterblasen, etwa in Suchalgorithmen, nicht als eigentliche Ursache f&#252;r
Nebenwirkungen wie Hassrede, Populismus oder Fake News betrachtet werden. Auch ist empirisch nicht belegt, 
dass sich Menschen ausschlie&#223;lich &#252;ber soziale Medien informieren. Denn auch wenn soziale Medien im Leben 
gerade vieler junger Menschen eine wichtige Rolle einnehmen, werden sie in der Regel nicht zum Zweck der
Informationsbeschaffung genutzt.1976 Viel deutet darauf hin, dass die St&#228;rke der Motivation, Informationen so
auszuw&#228;hlen, dass sie zum eigenen Weltbild passen, von einer Reihe von Rahmenbedingungen abh&#228;ngt. Zudem
sind Menschen in einer Demokratie nicht hilflos gegen&#252;ber Informationsblasen und Echo-Kammern, denn sie
haben stets die Wahl, aktiv daraus auszubrechen, auch wenn das voraussetzt, dass Menschen diese Ph&#228;nomene
kennen und sich in der konkreten Situation bewusst sind, dass dieser Effekt gerade auf sie wirkt.
Festzuhalten bleibt aber, dass es bei einer Kumulation verschiedener Faktoren, zu denen eben auch die zuvor
beschriebene Filterung in sozialen Medien z&#228;hlt, zu einer Wahrnehmungsverzerrung von Menschen kommen 
kann und dann entsprechend Leitwerte wie Orientierung an validen, faktenbasierten Quellen oder Diversit&#228;t in
den Hintergrund treten k&#246;nnen.1977 Medienkompetenz und Transparenz solcher Systeme erscheinen daher
wichtig, damit sich die gesellschaftlichen Diskussionen nicht weiter verengen.   
1969 Vgl. Stark et al. (2017): Ganz meine Meinung?
1970 Vgl. Fletcher (2020): The truth behind filter bubbles: Bursting some myths.
1971 Wie etwa von Algorithmwatch und anderen, vgl. https://algorithmwatch.org/?s=Filterblasen (zuletzt abgerufen am 3. August 2020).
1972 Vgl. Warner und Neville-Shepard (2011): The Polarizing Influence of Fragmented Media: Lessons From Howard Dean, S. 201&#8211;215.
1973 An der Universit&#228;t Ulm haben Psychologinnen und Psychologen die Anzahl der genutzten Nachrichtenquellen im Online- und
Offlinebereich als Indikator f&#252;r dieses Risiko erhoben und zus&#228;tzlich die Zusammenh&#228;nge mit demografischen, geschlechtsspezifischen,
politischen u. a. Einstellungen untersucht; vgl. Sindermann et al. (2020): Age, gender, personality, ideological attitudes and individual
differences in a person's news spectrum: how many and who might be prone to &#8222;filterbubbles&#8220; and &#8222;echo chambers&#8220; online?
1974 &#196;hnliche Anteile werden auch gesamtgesellschaftlich angenommen. Siehe auch Kapitel 4.1 diess Projektgruppenberichts [
Medienkonsum und Nutzungsverhalten].
1975 Vgl. Haim et al. (2018): Burst of the Filter Bubble?, S. 330&#8211;343.
1976 Siehe auch Kapitel 4.1.1 dieses Projektgruppenberichts [Mediennutzung]; vgl. Newman et al. (2019): Reuters Institute Digital News
Report 2019, S. 85 f.
1977 Vgl. Yang et al. (2020): Die gefilterte Realit&#228;t &#8211; Welchen Anteil haben wir selbst an der Entstehung von Echo-Kammern?
6.2.4 Handlungsempfehlungen
Da eine gut informierte &#214;ffentlichkeit und ein vielseitiger Diskurs eine demokratische Gesellschaft n&#228;hren, sind
Ma&#223;nahmen zu ergreifen, die vermeiden, dass sich &#8211; soweit vorhanden &#8211; Filterblasen und Echokammern
etablieren bzw. vergr&#246;&#223;ern k&#246;nnen und sich Menschen daran binden. 
Notwendig erscheint es auf jeden Fall, die Bev&#246;lkerung st&#228;rker &#252;ber Filtersysteme aufzukl&#228;ren und in den Bereich
der Medienkompetenz aller B&#252;rgerinnen und B&#252;rger zu investieren. Junge Menschen sollten dazu bef&#228;higt
werden, Informationen und Quellen kritisch zu hinterfragen sowie sich vielseitig &#252;ber digitale und/oder analoge
Kan&#228;le zu informieren. Dies muss Bestandteil einer modernen Schulbildung sein, und zwar fach&#252;bergreifend.
Dar&#252;ber hinaus muss insbesondere &#228;lteren Menschen eine M&#246;glichkeit gegeben werden, ihre digitale
Nachrichtenkompetenz im Alter zu erhalten und aktiv zu verbessern. Staatliche F&#246;rderung f&#252;r Programme f&#252;r diese
Altersgruppe sind ratsam.
Mehr Transparenz durch eine Kombination aus freiwilligen Selbstverpflichtungen und im Zweifel auch
regulatorischen Ma&#223;nahmen k&#246;nnte m&#246;gliche Gefahren eind&#228;mmen und k&#246;nnte auch helfen, algorithmische Systeme
st&#228;rker auf gesellschaftliche Teilhabe hin zu optimieren. Dazu geh&#246;rt etwa der h&#228;ufig genannte L&#246;sungsvorschlag
eines transparenten Umgangs der Anbieter mit Personalisierungen und Filtern. So k&#246;nnten Anbieter z. B.
Nutzerinnen und Nutzer darauf hinweisen, dass angezeigte Inhalte durch bestimmte Eigenschaften gefiltert wurden.
Zudem wird dar&#252;ber diskutiert, ob Nachrichten-Empfehlungssysteme neben der Relevanz von Nachrichten auch
deren Vielfalt optimieren sollten &#8211; &#228;hnlich wie es bei privaten Fernsehsendern gefordert und von den
Landesmedienanstalten durchgesetzt wird. Hierbei ist jedoch zu bedenken, dass der Begriff &#8222;Vielfalt&#8220; wom&#246;glich schwer
messbar ist. L&#246;sungen k&#246;nnten daran ansetzen, allgemein anerkannte Leitwerte zu verankern, etwa durch eine
Entwickler- und Berufsethik, vergleichbar dem Pressekodex, damit Relevanzsignale und Filterfunktionen
gesellschaftlich w&#252;nschenswerten Kriterien folgen.1978 
Als weitere Empfehlung wird die &#220;berwachung (und gegebenenfalls sogar Einschr&#228;nkung) der zugrunde
liegenden Personalisierungsmethode von Nachrichten-Empfehlungssystemen erwogen, denn es gibt die M&#246;glichkeit,
Algorithmen zur &#220;berwachung von algorithmischen Entscheidungssystemen einzusetzen (Governance by
algorithms). Die Projektgruppe ist jedoch der Meinung, dass eine staatliche Regulierung in diesem Bereich erst
erfolgen sollte, wenn das tats&#228;chliche Ausma&#223; von Filterblasen und vor allem ihre Auswirkung auf die Gesellschaft
und das Individuum n&#228;her untersucht und sicher belegt sind.1979 Denn &#8211; wie eingangs dargelegt &#8211;, ist die Technik
lediglich ein Teil des Problems; andere Faktoren, wie das Verhalten der Nutzerinnen und Nutzer, die
Gesch&#228;ftsmodelle der Plattformen und die in der Gesellschaft vermeintlich zunehmenden extremen Positionen, wirken sich
ebenso aus.
Da im deutschen und europ&#228;ischen Raum bislang nur vereinzelt und nicht systematisch analysiert wurde, ob und
wie es zur Bildung von Filterblasen in digitalen sozialen Medien kommt und welche (Langzeit-)Effekte dies auf 
die Meinungsbildung hat, wird stark bef&#252;rwortet, dass dies weiter erforscht wird. Insbesondere sollten weitere
Studien durchgef&#252;hrt (und gef&#246;rdert) werden, die Methoden der Psychologie und Informatik kombinieren, auch 
um den Zusammenhang mit demografischen Merkmalen, politischen Ausrichtungen und Wahlentscheidungen
zu untersuchen.  
In jedem Fall ist es hilfreich &#8211; wie bereits an anderer Stelle verlangt &#8211; von den Intermedi&#228;ren eine gr&#246;&#223;ere
Transparenz der verwendeten algorithmischen Empfehlungssysteme einzufordern. Denn eine bessere Erforschbarkeit
f&#246;rdert eine sachliche und l&#246;sungsorientierte Debatte und erm&#246;glicht es, neue L&#246;sungswege aufzuzeigen und
m&#246;gliche Gefahren fr&#252;hzeitig zu erkennen.
Social Bots
In den Medien werden bei den verschiedensten Gelegenheiten Studien zitiert, die von sogenannten Social Bots
sprechen, die angeblich politische Entscheidungen manipulieren k&#246;nnten.1980 Dabei wird suggeriert, dass es sich
bei diesen Social Bots um Accounts auf den sozialen Netzwerkplattformen wie Twitter, Instagram oder Facebook 
handelt, die quasi autonom in politische Diskussionen eingreifen und dabei vorgeben, Menschen zu sein; ihr
Verhalten l&#228;sst sich auf den ersten Blick von menschlichem Kommunikationsverhalten nicht unterscheiden. An
1978 Vgl. dazu Vorschl&#228;ge von Lischka und St&#246;cker (2017): Digitale &#214;ffentlichkeit: Schauen wir den Algorithmen auf die Finger.
1979 Vgl. beispielsweise Boutin (2011): Your Results May Vary.
1980 F&#252;r einen &#220;berblick vgl. Gallwitz (2019): Die M&#228;r von &#8222;Social Bots&#8220;.
diesen Studien gibt es inzwischen erhebliche Zweifel. Bestritten wird, dass dieser antizipierte und diskutierte
Grad von Autonomie heutzutage technisch m&#246;glich ist und dass belastbare Belege vorgelegt wurden.1981 
Vor diesem Hintergrund hat sich die Projektgruppe &#8222;KI und Medien&#8220; mit Social Bots besch&#228;ftigt. Sie ging der
Frage nach, ob KI-gest&#252;tzte Social Bots hierzulande zum Einsatz kommen bzw. nachgewiesen werden k&#246;nnen
und, wenn ja, welches Potenzial sie insbesondere auf politische Meinungsbildung oder gar Entscheidungen
entfalten k&#246;nnen, wie sie effektiv aufgesp&#252;rt und kontrolliert werden k&#246;nnen und welche Ma&#223;nahmen
gegebenenfalls zu ergreifen sind, um negativen Effekten vorzubeugen. 
Die Projektgruppe &#8222;KI und Medien&#8220; setzte dabei auf den bereits im Deutschen Bundestag vorliegenden
Erkenntnissen zu Social Bots auf1982 und konzentrierte sich auf KI-spezifische Aspekte. Im Bewusstsein der &#246;ffentlich
polarisiert gef&#252;hrten Debatte zu Social Bots wurden schriftliche Stellungnahmen von verschiedenen Expertinnen
und Experten eingeholt und ausgewertet.1983 
Die Antworten waren sehr ausf&#252;hrlich und fielen erwartungsgem&#228;&#223; heterogen aus. Nach W&#252;rdigung der
Stellungnahmen hat sich die Projektgruppe (mehrheitlich) auf folgende Sichtweise geeinigt:
Ein Bot ist zun&#228;chst einmal nur als Hilfsmittel zu sehen, um Informationen schnell und automatisiert zu
verbreiten. Das Wort &#8222;Bot&#8220; in &#8222;Social Bot&#8220; ist die Kurzform von englisch &#8222;robot&#8220; (Roboter); mit &#8222;social&#8220; wird auf die
sozialen Medien als den Bereich verwiesen, in dem Bots vorkommen bzw. vermutet werden. Die Definition bzw.
Abgrenzung von Social Bots wird indes unterschiedlich gehandhabt und Social Bots werden damit auch in ihrer
Existenz und Wirkung unterschiedlich bewertet.
Dazu soll im Folgenden zun&#228;chst einmal kurz dargestellt werden, welche technologischen M&#246;glichkeiten heute
bestehen und welche in Zukunft eingesetzt werden k&#246;nnten. Dabei folgt die Projektgruppe den befragten
Expertinnen und Experten, die mehrheitlich die Auffassung vertreten, dass voll- oder auch nur teilautomatisierte
Accounts, die sich leitend in politische Diskussionen einmischen, momentan eher unwahrscheinlich sind.
Unbestritten ist dagegen, dass es Gruppen von menschlich dirigierten Accounts gibt, die konzertiert und unterst&#252;tzt durch 
automatisierbare Aspekte versuchen, die politische Meinungsbildung zu manipulieren. 
Technologische M&#246;glichkeit von Social Bots
Es ist leicht m&#246;glich, sehr einfache Bot-Accounts zu bauen, die beispielsweise auf Nachrichten automatisiert
reagieren. Diese Chat-Bots machen wenig mehr, als auf eine Reihe von vorher gespeicherten Antworten
zur&#252;ckzugreifen und diese automatisiert an die Person zu senden, die sich mit einer Nachricht an einen Account
gewendet hat, der z. B. nachts nicht von einem Menschen moderiert wird. Es gibt Automatisierungstools, mit denen 
vorher vorbereitete Nachrichten zu einem bestimmten Zeitpunkt gesendet werden k&#246;nnen &#8211; diese werden
meistens genutzt, um vermeintlich besonders wertvolle Zeitpunkte f&#252;r Nutzerinteraktionen nicht zu verpassen. Nicht
zuletzt kann man einfach Accounts bauen oder bestehende Accounts mit Bots anreichern, die beispielsweise alle
eingehenden Nachrichten erst einmal &#8222;liken&#8220; oder Nachrichten mit einem bestimmten Stichwort weiterleiten. Die
Regeln f&#252;r dieses Verhalten k&#246;nnen im Wesentlichen direkt codiert werden &#8211; es bedarf keiner Methode des
Maschinellen Lernens. 
Von Interesse ist daher, ob es der Einsatz von KI auf der Basis des Maschinellen Lernens erlauben k&#246;nnte, &#252;ber
einfaches, regelbasiertes Verhalten hinaus in manipulativer, autonomer Weise in politische Diskussionen
einzugreifen. Es ist tats&#228;chlich heute in begrenztem Ma&#223;e technisch m&#246;glich, semantisch sinnvolle Texte k&#252;nstlich
1981 Vgl. Kind et al. (2017): Social Bots.
1982 Vgl. Kind et al. (2017): Social Bots sowie Dokumentation des &#246;ffentlichen Fachgespr&#228;chs vom 26. Januar 2017 des Ausschusses f&#252;r
Bildung und Forschung (weitere Informationen dazu unter: https://www.bundestag.de/dokumente/textarchiv/2017/kw04-pa-bildung-
forschung-social-bots-488818, zuletzt abgerufen am 1. September 2020) und des &#246;ffentlichen Fachgespr&#228;chs des Ausschusses
Digitale Agenda am 25. Januar 2017 (weitere Informationen dazu unter: https://www.bundestag.de/dokumente/textarchiv/2017/kw04-pa-
digitale-agenda-489302, zuletzt abgerufen am 1. September 2020).
1983 Folgende Personen, Institutionen und Unternehmen wurden zur Existenz und Wirkung von Social Bots in Verbindung mit KI befragt
und nahmen zum 17. Februar 2020 schriftlich Stellung:
&#8722; botswatch Technologies GmbH (Tabea Wilke, Gesch&#228;ftsf&#252;hrerin), Projektgruppendrucksache 19(27)PG 6-28
&#8722; Bundesamt f&#252;r Sicherheit in der Informationstechnik (Dr. Gerhard Schabh&#252;ser, Vizepr&#228;sident), Projektgruppendrucksache 
19(27)PG 6-29
&#8722; Bundeskriminalamt (Dicker, RL/FBL KI-Koordinierung), Projektgruppendrucksache 19(27)PG 6-31
&#8722; Bundeswahlleiter (Dr. Georg Thiel), Projektgruppendrucksache 19(27)PG 6-30
&#8722; Hochschule f&#252;r Politik M&#252;nchen (Prof. Dr. Simon Hegelich, Political Science), Projektgruppendrucksache 19(27)PG 6-27
&#8722; Technische Hochschule N&#252;rnberg (Prof. Dr. Florian Gallwitz), Projektgruppendrucksache 19(27)PG 6-26.
erstellen zu lassen. Dies ist umso einfacher machbar, je klarer die erwartete Struktur eines solchen Textes ist.1984 
Aber selbst die fortgeschrittenen Methoden des Maschinellen Lernens haben nur begrenzte
Erinnerungsm&#246;glichkeiten.1985 
Hinzu kommt, dass politische Diskussionen sehr kontextsensitiv sind und sich st&#228;ndig neue Begrifflichkeiten
bilden oder sich die Verwendung von Begrifflichkeiten ver&#228;ndert. Nicht zuletzt brauchen Methoden des
Maschinellen Lernens Feedback dar&#252;ber, ob ihre Nachrichten in die richtige Richtung gef&#252;hrt haben oder nicht. Es ist
kaum zu erwarten, dass es einfache M&#246;glichkeiten gibt, ein solches Feedback auf eine automatisch generierte
Nachricht w&#228;hrend des laufenden Betriebs zu bekommen. Damit bleiben im Wesentlichen nur ausgelernte
Verfahren, die wiederum auf die dynamischen Verwendungen von Begrifflichkeiten in politischen Diskussionen
kaum reagieren k&#246;nnten. 
Um also politische Meinungsbildung klug leiten zu k&#246;nnen, bedarf es einer kontextsensitiven Erstellung von
Texten, bei denen die Struktur nicht klar vorgegeben ist, die zudem auf die sich dynamisch ver&#228;ndernden
Diskussionsbedingungen eingehen k&#246;nnen. 
Basierend auf dem dargelegten &#8222;State of the Art&#8220; ist es also einerseits h&#246;chst unwahrscheinlich, dass ein gelerntes
oder auch ein lernendes System dies zur Zufriedenheit der Personen, die das &#8222;Bot-System&#8220; dirigieren, erledigen
kann. Zudem gibt es andererseits gen&#252;gend Menschen, die konzertiert dazu angeleitet werden k&#246;nnen, sich in
Diskussionen aller Art in einer bestimmten Art und Weise einzumischen. Diese k&#246;nnen erstens mehrere Accounts
gleichzeitig f&#252;hren und sich dabei auch bei einfachen T&#228;tigkeiten (&#8222;Liken&#8220;, Weiterverteilen von Nachrichten,
zeitlich verz&#246;gertes Antworten etc.) durch Bots unterst&#252;tzen lassen.
Durch die Direktion und Konzertierung kann es bei Rezipientinnen und Rezipienten dazu kommen, dass sich die
Wahrnehmung der unterschiedlichen Positionen verschiebt. Es kann so wirken, als w&#228;re fast jede und jeder in 
der eigenen Freundessph&#228;re (Timeline, Kontaktliste usw.) einer bestimmten politischen Ansicht, obwohl es in
Wahrheit nur wenige Personen sind, die dieser Ansicht sind. Damit sind Gruppen von Accounts, die dirigiert
werden und konzertiert an einer bestimmten Darstellung oder sogar an kontrastierenden Darstellungen in
unterschiedlichen Bev&#246;lkerungsgruppen arbeiten, potenziell eine Bedrohung f&#252;r Demokratien &#8211; unabh&#228;ngig vom Grad 
der Automatisierung und / oder dem Ausma&#223; des KI-Einsatzes.
M&#246;glichkeiten f&#252;r das Aufsp&#252;ren von Social Bots
Die Stellungnahmen variieren in der Definition von Social Bots; die Aussagen lassen sich jedoch wie folgt
zusammenfassen:
1. Es sind automatisierte Accounts (zumindest zum &#252;berwiegenden Teil), also ohne bzw. kaum menschliche
Eingriffen, wenn sie erst einmal aufgesetzt sind.
2. Sie geben vor, echte Menschen zu sein und unabh&#228;ngige Meinungen zu vertreten.
3. Sie mischen sich in politische Diskussionen ein.
Wenn es diese Accounts so g&#228;be, w&#252;rde dies Einzelpersonen erm&#246;glichen, mit relativ wenig Aufwand ihre eigene
Meinung beliebig in Zeit und Raum zu vertreten und zu verst&#228;rken. Die obige Zusammenfassung des Stands der
Technik l&#228;sst vermuten, dass es solche Accountfarmen mit diesem hohen Autonomiegrad momentan nicht gibt.
Wahrscheinlicher sind Hybride, d. h., dass Menschen angeheuert werden, die mit verschiedenen Werkzeugen in
ihrer manipulativen Arbeit unterst&#252;tzt werden. Daf&#252;r, dass es Accounts gibt, die sich in konzertierter Art und
Weise in Entscheidungen einmischen, gibt es auf jeden Fall Hinweise, wie einige Expertinnen und Experten in
ihren Gutachten darlegen. Dazu werden Muster ermittelt, die statistisch sehr unwahrscheinlich sind, wie das
Einmischen einer Gruppe von Accounts in sehr unterschiedliche Diskussionen in verschiedenen L&#228;ndern, die alle in
derselben Reihenfolge erfolgen, und das &#252;ber Jahre hinweg. 
Die oben genannte Definition hingegen ist sehr schwierig von au&#223;en zu bewerten: Wie hoch ist der
Automatisierungsgrad eines Accounts? Gibt der Account nur vor, von einem Menschen betrieben zu werden, oder wird er
1984 Daher ist es heute m&#246;glich, Sportereignisse auch f&#252;r sehr kleine, lokale Events produzieren zu lassen, wenn bekannt ist, welche
Mannschaften mit welchen Ergebnissen gegeneinander gespielt haben. Auch &#252;ber Finanzereignisse von Firmen kann heutzutage 
automatisiert in ganzen S&#228;tzen berichtet werden.
1985 Das zeigen Shane und Sands (2019) eindrucksvoll: Nachdem neuronale Netze auf Kochrezepten trainiert wurden, lie&#223; sie diese eigene 
Rezepte generieren. Dabei klappt das Auflisten von Zutaten noch leidlich, aber mit einiger Wahrscheinlichkeit f&#228;ngt das neuronale
Netzwerk oben mit Kuchenzutaten an, um dann unvermittelt in die Zubereitung eines deftigen Gerichts zu wechseln. Dabei kommen
weder alle Zutaten, die in der Zutatenliste genannt wurden, im Zubereitungsteil vor, noch sind alle Zutaten, die im Zubereitungsteil
genannt werden, auch Teil der Zutatenliste. Dies stellt somit den State of the Art im Bereich generativer Texte dar.
&#8211; wenigstens teilweise &#8211; von einem Menschen gesteuert? Tats&#228;chlich sind diese beiden Elemente aber f&#252;r die
dirigierten und konzertierten Gruppen von Accounts, die damit eine Manipulation von politischen Meinungen
erreichen wollen, nicht notwendig. Die Kosten f&#252;r die Entwicklung einer KI, die das k&#246;nnte, sind im Moment
hoch und es ist unwahrscheinlich, dass es auch mit einer h&#246;chstentwickelten KI m&#246;glich ist, Accounts so fein zu
steuern, wie es f&#252;r den Zweck notwendig w&#228;re. Damit sind die Kosten f&#252;r menschliche Unterst&#252;tzung vermutlich
weitaus geringer &#8211; auch wenn dadurch die Anzahl der Mitwissenden stark steigt. 
Aufgrund dieser &#220;berlegungen erscheint der Begriff &#8222;Social Bot&#8220;, wie er in den vergangenen Jahren genutzt
wurde, zu &#252;berladen, um in der weiteren Diskussion von Nutzen zu sein. Der Einfluss von teilautomatisierten,
dirigierten und konzertiert arbeitenden Accounts kann aber durchaus als besorgniserregend eingesch&#228;tzt werden.
Diese Accounts lassen sich einigerma&#223;en gut erkennen, da sie aus &#246;konomischen Gr&#252;nden immer noch gewissen
Mustern folgen, die statistisch unwahrscheinlich sind. Weil es aber heute keine einfachen Zugriffsm&#246;glichkeiten 
auf die Daten der sozialen Netzwerkplattformen gibt und deren Betreiber einige Accounts schon direkt sperren,
ist es heute f&#252;r die Regierung und NGOs nahezu unm&#246;glich, das Ausma&#223; der versuchten Manipulation
kosteng&#252;nstig und effizient zu erfassen.
Die Abw&#228;gung der Argumente aus den verschiedenen Gutachten f&#252;hrt zur &#220;berzeugung, dass die Situation
&#8211; auch wenn stichhaltige Belege f&#252;r Social Bots bislang fehlen &#8211; ernst genommen werden sollte.1986 
Mehr Transparenz und Nachvollziehbarkeit ist w&#252;nschenswert, um das Ausma&#223; einer potenziellen Bedrohung
ausreichend absch&#228;tzen zu k&#246;nnen. Leider werden viele Accounts schon von den Betreibern der sozialen
Netzwerkplattformen gel&#246;scht und die daf&#252;r angewandten Entscheidungsprozesse nicht offengelegt. 
6.3.1 Handlungsempfehlungen
Da die momentan zur Verf&#252;gung stehende Datenbasis nicht ausreicht, um die tats&#228;chliche Bedrohung durch
Social Bots nachzuweisen, erscheint eine Zusammenarbeit mit den Plattformbetreibern notwendig.1987 So
k&#246;nnten effektive Detektions- und Mitigationsma&#223;nahmen (einschlie&#223;lich des Deaktivierens und L&#246;schens von
Accounts) entwickelt werden. 
Die zugrunde liegenden Mechanismen m&#252;ssen dringend weiter erforscht werden, allerdings mit neuen Ans&#228;tzen
und nicht auf Basis der bisherigen Social-Bot-Annahmen, die in eine Sackgasse gef&#252;hrt haben. Andererseits
m&#252;ssen Methoden zur Erkennung von Social Bots sowie zur Messbarkeit ihrer Auswirkungen auf die politische
Meinungsbildung weiterentwickelt werden. Dazu ist sowohl mehr Forschung im Bereich der KI als auch in der
Kommunikationswissenschaft erforderlich. Da die bisherigen Methoden f&#252;r eine vollautomatisierte
Identifikation von Social Bots als zu unzuverl&#228;ssig eingesch&#228;tzt werden, erscheint ein hybrider Ansatz zur Erkennung von
Social Bots sinnvoll, wie er im Gutachten des Bundesamts f&#252;r Sicherheit in der Informationstechnik (BSI)
beschrieben wird.1988 
Die Betreiber sozialer Medien sollten dazu veranlasst werden, ihre Schnittstellen weiter als bisher f&#252;r
wissenschaftliche Forschung zu &#246;ffnen. Hier ist der Gesetzgeber gefragt, den Zugriff auf Daten gesetzlich zu Zwecken
der Forschung und Aufkl&#228;rung zu garantieren. Da es aber um pers&#246;nliche Informationen von menschlichen
Accountbetreibern geht, muss eine M&#246;glichkeit geschaffen werden, die den Datenzugriff erm&#246;glicht, deren
&#252;berm&#228;&#223;ige Nutzung aber technologisch dauerhaft und unumkehrbar verhindert wird. 
Die Kennzeichnungspflicht f&#252;r Accounts mit Einsatz von Bots (Flagging) wird als Ma&#223;nahme nur zur&#252;ckhaltend
empfohlen, da derzeit keine Methode existiert, um Social Bots zuverl&#228;ssig zu identifizieren. Insofern w&#252;rde die
Kennzeichnungspflicht gegebenenfalls nur eine tr&#252;gerische Sicherheit bieten. Auch erscheinen Aufwand und
Kosten f&#252;r die Kontrolle des Flaggings noch hoch und es ist unklar, wie eine Rechtsdurchsetzung erfolgen k&#246;nnte.
Vorgeschlagen wird eine freiwillige Absprache der Parteien, w&#228;hrend des Wahlkampfes auf Instrumente zu
verzichten, welche die Integrit&#228;t und Authentizit&#228;t des Informationsraumes gef&#228;hrden. 
1986 Zu diesem Ergebnis kommt auch das BSI, vgl. Beantwortung der Fragen der Projektgruppe KI und Medien von Dr. Gerhard
Schabh&#252;ser (Vizepr&#228;sident des BSI), Projektgruppendrucksache 19(27)PG 6-29 vom 17. Februar 2020, S. 5.
1987 Es sei hier beispielsweise auf die Initiative von Facebook hingewiesen, weitere Informationen dazu unter: https://socialscience.one/
(zuletzt abgerufen am 1. September 2020).
1988 Beantwortung der Fragen der Projektgruppe KI und Medien von Dr. Gerhard Schabh&#252;ser (Vizepr&#228;sident des BSI),
Projektgruppendrucksache 19(27)PG 6-29 vom 17. Februar 2020.
        
 
 
  
      
 
      
      
  
  
  
 
   
 
     
 
 
     
  
 
  
 
 
  
  
 
     
  
  
  
      
     
 
  
  
 
        
  
 
    
   
                                               
    
  
     
       
               
          
       
        
      
    
  
          
             
7
Regulierung
Der Einsatz von KI im Medienbereich &#8211; ob zur Produktion oder Distribution &#8211; wird bereits von der bestehenden
Regulierung erfasst. Hinzu kommen neue Regulierungsvorst&#246;&#223;e, um insbesondere neue, von KI-Technologien
aufgeworfene Herausforderungen zu erfassen. Das Kapitel untersucht sowohl neue Entwicklungen in der
internationalen Regulierungsdebatte als auch die wichtigsten nationalen Regulierungsans&#228;tze in Bezug auf Einsatz
und Nutzung von KI-Technologien im Mediensektor. Das Kapitel verdeutlicht die Komplexit&#228;t von
Medienregulierung. Neben schwierigen Interessenabw&#228;gungen liegt das vor allem am mangelnden Zugang zu genaueren
und unabh&#228;ngigen Informationen &#252;ber die Funktionsweise der auf den Internetplattformen eingesetzten KI-
Systeme und der Fragmentierung von Zust&#228;ndigkeiten &#252;ber viele unterschiedliche Rechtsgebiete und Politikfelder
hinweg. 
Internationale Regulierung
International gibt es zahlreiche Bestrebungen, Internetplattformen in Bezug auf den Einsatz von KI st&#228;rker zu
kontrollieren und zu regulieren.1989 Grundlage ist die Bedeutung dieser sogenannten Informationsintermedi&#228;re
f&#252;r digitale Diskursr&#228;ume. Vielfach werden sie mittlerweile als kritische Infrastruktur f&#252;r Meinungsbildung und
Demokratie betrachtet.1990 Suchmaschinen, Informationsplattformen, soziale Medien und Sprachassistenten
personalisieren Informationsfl&#252;sse, beeinflussen die Reichweite von Inhalten und Nutzerkommentaren und
entfernen Inhalte, die gegen nationale Gesetze oder die Nutzungsbedingungen der Plattformen versto&#223;en. In allen
diesen Bereichen spielt KI eine wichtige Rolle. Welche Auswirkungen diese Prozesse auf den
Meinungsbildungsprozess haben, ist bisher wenig erforscht. Die Funktionsweise der Plattformen und ihre Implikationen lassen sich
nur mithilfe von Daten analysieren, die Aufschluss dar&#252;ber geben, wie sich Inhalte auf den Plattformen
verbreiten, wie sie konsumiert werden und welche breiteren gesellschaftlichen und politischen Auswirkungen damit
verbunden sind. Diese Datenzug&#228;nge gibt es allerdings nur sehr begrenzt und sie variieren stark je nach Plattform.
So gilt zum Beispiel die Initiative von Facebook und zahlreichen gro&#223;en Stiftungen, Facebook-Daten f&#252;r
unabh&#228;ngige Forschung zur Verf&#252;gung zu stellen, mittlerweile weitgehend als gescheitert.1991 Ans&#228;tze der Ko-
Regulierung wie der &#8222;Code of Practice on Disinformation&#8220; der EU haben zwar neue Verpflichtungen f&#252;r die
Plattformen definiert.1992 Allerdings zeigt sich selbst die EU-Kommission angesichts der Umsetzung mittlerweile
skeptisch.1993 Mit dem Digital Service Act k&#246;nnte die EU rechtlich verbindliche Vorgaben f&#252;r
Informationsintermedi&#228;re definieren.
Zus&#228;tzlich wird auch in EU-Mitgliedsstaaten und vielen weiteren L&#228;ndern an Regulierungsans&#228;tzen gearbeitet:
Am weitesten fortgeschritten ist die Diskussion in Gro&#223;britannien. Ausgel&#246;st wurde die Regulierungsdebatte von 
Enth&#252;llungen und Untersuchungen bez&#252;glich der Verbreitung von Desinformation &#252;ber Medienintermedi&#228;re im
Zuge der Brexit-Debatte. Hierzu hat das britische Parlament einen viel beachteten Bericht ver&#246;ffentlicht.1994 Die 
Debatte geht mittlerweile allerdings weit &#252;ber das Problem der Verbreitung von Desinformation hinaus und
betrifft einige wichtige Aspekte mit hohem Bezug zu KI, insbesondere bei der gezielten Ausspielung von Werbung
und Inhalten an Nutzerinnen und Nutzer. Im April 2019 ver&#246;ffentlichten das britische Innenministerium und das
Ministerium f&#252;r Digitales, Kultur, Medien und Sport ein Wei&#223;buch &#252;ber m&#246;gliche Regulierungsans&#228;tze f&#252;r
Internetplattformen.1995 Im Mittelpunkt steht das Konzept des Online-Harm, gesellschaftlich sch&#228;dliche Online-
Probleme, f&#252;r die die Plattformen verantwortlich gemacht werden. Hierzu z&#228;hlt die digitale Verbreitung von
illegalen Inhalten wie Kinderpornografie ebenso wie Cyber-Mobbing und die Verbreitung von Terrorpropaganda
oder Desinformation auf den Plattformen. Gesellschaftlicher Schaden geht demnach nicht nur von der Verbrei-
1989 Neben Regulierung kann der Staat auch &#252;ber F&#246;rderungen und finanzielle Anreize versuchen, bestimmte politische Ziele zu erreichen.
Es wurde hier der Schwerpunkt auf die internationale Regulierungsdiskussion gelegt. Regulatorische Ans&#228;tze stehen insbesondere in 
Bezug auf den Einsatz von KI auf den gro&#223;en Internetplattformen auch im Mittelpunkt der internationalen regulatorischen Debatte. 
1990 Vgl. Datenethikkommission der Bundesregierung (2019): Gutachten der Datenethikkommission der Bundesregierung, S. 207 ff., 
Ziffer 6&#8288; &#8288; 's Not Just; Tufekci (2018): How social media took us from Tahrir Square to Donald Trump; Mar&#233;chal und Biddle (2020): It 
the Content, It' &#8288;s the Business Model: Democracy&#8217;s Online Speech Challenge; Zuckerman (2020): The Case for Digital Public
Infrastructure&#8288;; Rahman und Teachout (2020): From Private Bads to Public Goods.
1991 Vgl. Pasternack (2019): Frustrated funders exit Facebook&#8217;s election transparency project.
1992 Vgl. Europ&#228;ische Kommission (2018): Code of Practice on Disinformation.
1993 Vgl. Europ&#228;ische Kommission (2019): Code of Practice on Disinformation one year on: online platforms submit self-assessment
reports.
1994 Vgl. UK Parliament (2019): Disinformation and &#8216;fake news&#8217;: Final Report published.
1995 Vgl. Great Britain. Department for Culture, Media and Sport (2019): Online harms white paper.
tung von illegalen Inhalten aus &#8211; daher soll mit dem Konzept des Online-Harm die Verantwortung der
Plattformen viel weiter gefasst werden. Um solche Sch&#228;den zu vermeiden, sollen Unternehmen zu einer &#8222;Duty of Care&#8220;
verpflichtet werden, die Bek&#228;mpfung dieser negativen gesellschaftlichen Auswirkungen in Angriff zu nehmen.
Eine unabh&#228;ngige Regulierungsbeh&#246;rde soll beaufsichtigen, ob Unternehmen ihrer &#8222;Duty of Care&#8220;-Verpflichtung
im ausreichenden Ma&#223; nachkommen. Zur Durchf&#252;hrung dieser Aufgabe soll die Regulierungsbeh&#246;rde
weitreichende Befugnisse im Hinblick auf den Zugang zu Informationen und Daten erhalten. Die &#8222;Duty of Care&#8220;-Doktrin 
w&#252;rde den Einsatz von KI betreffen &#8211; sowohl als Problemfeld (Einsatz von KI-Technologien zur Verbreitung
sch&#228;dlicher Inhalte) als auch als L&#246;sungsansatz (Einsatz von KI-Technologien zur Erkennung sch&#228;dlicher
Inhalte).
Der regierungsnahe britische Thinktank &#8222;Centre for Data Ethics and Innovation&#8220; hat sich ausdr&#252;cklich mit dem
Einsatz von KI bei der automatisierten Identifizierung und Ansprache von Zielgruppen im Online-Marketing 
befasst.1996 Der daraus resultierende Bericht &#8222;Review of Online Targeting: Final Report and Recommendations&#8220;
fordert mehr Befugnisse f&#252;r Aufsichtsbeh&#246;rden, das sogenannte Online-Targeting und seine Auswirkungen zu
untersuchen. Der Bericht schl&#228;gt zus&#228;tzlich vor, h&#246;here Transparenzanforderungen f&#252;r den Einsatz solcher
Technologien zu stellen und m&#246;gliche Ans&#228;tze zu untersuchen, wie die Verbraucherinnen und Verbraucher wieder
mehr Kontrolle &#252;ber die Nutzung ihrer Daten erlangen k&#246;nnen. 
Ein Wei&#223;buch der franz&#246;sischen Regierung analysiert die Auswirkungen des Einsatzes von Algorithmen in den 
sozialen Medien.1997 Die Regulierungsvorschl&#228;ge zielen auf h&#246;here Transparenz und unabh&#228;ngige Kontrolle der
Algorithmen, die von sozialen Medien eingesetzt werden, insbesondere der Algorithmen, die Sichtbarkeit von
Inhalten f&#252;r die Nutzerin oder den Nutzer bestimmen. Ziel ist es, die den Algorithmen zugrunde liegende Logik
verst&#228;ndlich und &#252;berpr&#252;fbar zu machen. Frankreich will das Herkunftslandprinzip in diesem Bereich durch das
Marktortprinzip abl&#246;sen, das hei&#223;t, anstatt des EU-Mitgliedsstaats, in dem ein soziales Netzwerk seinen Sitz hat,
soll jeder EU-Mitgliedstaat, in dem m&#246;gliche Probleme auftreten, die Zust&#228;ndigkeit f&#252;r Regulierung und
Kontrolle der Plattformen erhalten. Kanada hat sich mit der Digital Charter Grundprinzipien f&#252;r die Regulierung
digitaler Technologien und KI gegeben.1998 Zu diesen Prinzipien z&#228;hlt die St&#228;rkung von Demokratie. Hierbei
sollen die Meinungsfreiheit einerseits, aber auch der Schutz der Integrit&#228;t der Wahlen z. B. durch die Verbreitung
von Desinformation anderseits gew&#228;hrleistet werden. Zus&#228;tzlich soll die Verbreitung von Hass, gewaltbereitem
Extremismus und illegalen Inhalten unterbunden werden. Die australische Wettbewerbs- und
Verbraucherkommission hat sich in einem ausf&#252;hrlichen Bericht mit digitalen Plattformen auseinandergesetzt.1999 Der Bericht
befasst sich vor allem mit den negativen Auswirkungen der Marktkonzentration in der digitalen Medienbranche.
Auch in den Vereinigten Staaten steht die Marktkonzentration der gro&#223;en Internetplattformen mittlerweile im
Fokus von Politik und Aufsichtsbeh&#246;rden. So haben die Generalstaatsanw&#228;ltinnen und -anw&#228;lte von 40 US-
Bundesstaaten gemeinsame kartellrechtliche Untersuchungen gegen Google und Facebook eingeleitet.2000 
In Deutschland stehen sich aufgrund der f&#246;deralen Medienordnung verschiedene Regulierungsans&#228;tze
gegen&#252;ber. So befindet sich der von der Ministerpr&#228;sidentenkonferenz verabschiedete Entwurf des
Medienstaatsvertrags, der erstmals Intermedi&#228;re in das Regulierungsregime auf L&#228;nderebene mit aufnimmt und eine St&#228;rkung der
Aufsicht durch die Landesmedienanstalten vorsieht, in der parlamentarischen Abstimmung.2001 Dar&#252;ber hinaus
gibt es mit dem Telemediengesetz und dem Netzwerkdurchsetzungsgesetz (NetzDG) ein Regulierungsregime auf
Bundesebene. Es gilt, diese unterschiedlichen Regulierungsans&#228;tze in ein koh&#228;rentes Regulierungsregime zu 
&#252;berf&#252;hren.
Zus&#228;tzlich gibt es unter den Medienintermedi&#228;ren auch Initiativen der Selbstregulierung.2002 Facebook hat z. B. 
mit einem &#8222;Oversight Board&#8220; ein globales Gremium von Expertinnen und Experten f&#252;r freie Meinungs&#228;u&#223;erung
installiert.2003 Die Wirkung dieses Gremiums kann noch nicht abgesch&#228;tzt werden. Es ist allerdings fraglich, ob
1996 Vgl. Centre for Data Ethics and Innovation (2020): Review of online targeting: Final report and recommendations.
1997 Vgl. Franz&#246;sische Regierung (2019): Creating a French framework to make social media platforms more accountable: Acting in
France with a European vision.
1998 Vgl. Kanadische Regierung (2020): Canada's Digital Charter: Trust in a digital world.
1999 Vgl. Australian Competition and Consumer Commission (2019): Digital Platforms Inquiry.
2000 Vgl. Lohr (2019): Google Antitrust Investigation Outlined by State Attorneys General.
2001 Vgl. Entwurf des Medienstaatsvertrags, abrufbar unter: https://www.rlp.de/fileadmin/rlp-stk/pdf-Dateien/Medienpoli-
tik/ModStV_MStV_und_JMStV_2019-12-05_MPK.pdf (zuletzt abgerufen am 4. August 2020).
2002 Vgl. Kettemann und Schulz (2020): Setting Rules for 2.7 Billion. A (First) Look into Facebook&#8217;s Norm-Making System: Results of
a Pilot Study.
2003 Weitere Informationen dazu unter: https://www.oversightboard.com/news/announcing-the-first-members-of-the-oversight-board/
(zuletzt abgerufen am 4. August 2020).
der aktuelle, sehr begrenzte Fokus auf einzelnen Entscheidungen zur Moderation von Inhalten eine
Auseinandersetzung &#252;ber die zugrunde liegende KI-gesteuerte Inhaltemoderation erm&#246;glichen wird.2004 Dem Oversight Board
k&#246;nnen schwierige Fragen der L&#246;schung oder Nichtl&#246;schung von Inhalten vorgelegt werden und es kann
Facebook Empfehlungen hinsichtlich der anzuwendenden Regeln f&#252;r die Inhaltsmoderation geben. 
7.1.1 Handlungsempfehlungen
Da die Medien- und Intermedi&#228;rsentwicklung gerade mit zunehmendem Einsatz von KI weiter internationalisiert
wird, besteht ein gro&#223;es Bed&#252;rfnis, regulatorisch weiterhin den Vorgaben des Artikel 5 GG gerecht zu werden.
Die sich daraus ergebenden Spannungsfelder sind gemeinsam mit den europ&#228;ischen Partnern anzugehen, um eine
europarechtsfreundliche, aber positive Medienregulierung aufrecht zu erhalten &#8211; unter Beachtung der nationalen
Verfassungsprinzipien und unter Beachtung von Artikel 11 der Europ&#228;ischen Grundrechtecharta (Freiheit der
Meinungs&#228;u&#223;erung und Informationsfreiheit). Die Bundesregierung muss sich daf&#252;r einsetzen, dass Leitbilder
und Verpflichtungen im Medienbereich, die auf den Erfahrungen deutscher Geschichte gr&#252;nden und hierzulande
im Pressekodex festgeschrieben wurden, und auch in anderen L&#228;ndern als Ehrenkodizes existieren, in Bereichen
Geltung erlangen, in denen KI angewendet wird.
Nationale Regulierung
7.2.1 Medienrecht (Medienstaatsvertrag) 
Der Medienstaatsvertrag soll den im Jahr 1991 geschlossenen Rundfunkstaatsvertrag abl&#246;sen und nicht wie der
zwischen 1997 und 2007 geltende Staatsvertrag &#252;ber Mediendienste neben dem Rundfunkstaatsvertrag stehen. 
Er soll nicht nur f&#252;r den &#246;ffentlich-rechtlichen und privaten Rundfunk, sondern nunmehr auch f&#252;r sogenannte
Medienplattformen, Intermedi&#228;re und Benutzeroberfl&#228;chen gelten. Die Sicherung der Vielfalt im Medienbereich
f&#228;llt in die Gesetzgebungszust&#228;ndigkeit der L&#228;nder.2005 Der Beschluss zum Medienstaatsvertrag erfolgt durch die 
gesetzgebenden L&#228;nder, der sodann durch die europ&#228;ische Kommission &#8211; nach Pr&#252;fung auf Vereinbarkeit mit
europ&#228;ischem Recht &#8211; notifiziert und von den Landtagen ratifiziert wird. Derzeit liegt der Entwurf des
Medienstaatsvertrags2006 vor, der f&#252;r die Veranstaltung und das Angebot, die Verbreitung und die Zug&#228;nglichmachung
von Rundfunk und Telemedien in Deutschland gelten soll. 
Im Entwurf des Medienstaatsvertrags (MStV-E) finden sich Regelungen, die auf die zunehmende Bedeutung von
digitalen Medien und die Rolle von KI bei der Distribution von Medieninhalten eingehen. Geregelt sind nun
insbesondere Transparenzpflichten f&#252;r Medienintermedi&#228;re wie Suchmaschinen oder soziale Netzwerke. Sie 
m&#252;ssen offenlegen, nach welchen Kriterien sie Inhalte selektieren und pr&#228;sentieren. Damit soll KI-basierte
Mediendistribution thematisiert werden. Medienplattformen und Benutzeroberfl&#228;chen unterliegen bestimmten 
Nichtdiskriminierungspflichten, die sich auf den Inhalt beziehen; diese sollen nicht gelten, wenn sie sachlich
gerechtfertigt sind.
&#167; 18 Absatz 3 MStV-E regelt au&#223;erdem f&#252;r Telemedienanbieter eine Kennzeichnungspflicht f&#252;r den Fall, dass
Webseitenanbieter in sozialen Netzwerken Automatisierungswerkzeuge zur Erstellung und Verbreitung von
Inhalten oder Mitteilungen benutzen. Gemeinhin zielt die Regelung auf sogenannte &#8211; momentan noch umstrittene
&#8211; Social Bots ab, da sie nur eingreift, wenn das genutzte Konto seinem &#228;u&#223;eren Erscheinungsbild nach f&#252;r die
Nutzung durch nat&#252;rliche Personen bereitgestellt wurde. Dann soll dem geteilten Inhalt oder der Mitteilung ein
gut lesbarer Hinweis beigef&#252;gt werden, dass bei der automatisierten Erstellung und Versendung des Inhalts ein 
Computerprogramm eingesetzt wurde, das das Nutzerkonto steuert.
Die beste Voraussetzung, um sich seine Meinung frei bilden zu k&#246;nnen, liegt nach g&#228;ngigem Verst&#228;ndnis darin,
dass m&#246;glichst gro&#223;e Informationsvielfalt herrscht und wahrgenommen werden kann. Neben der
Meinungsfreiheit umfasst Artikel 5 Absatz 1 Satz 1 GG noch die Informationsfreiheit, die gerade die Rezeptionsm&#246;glichkeit
frei zug&#228;nglicher Informationen sch&#252;tzt. Aus diesem Zusammenspiel ergibt sich, dass eine Regulierung sozialer
Netzwerke durchaus imstande ist, die pers&#246;nliche Meinungs&#228;u&#223;erungsfreiheit zu ber&#252;hren. Derartige Eingriffe
gilt es, verfassungskonform abzuw&#228;gen. Die m&#246;gliche Regulierung von sozialen Netzwerken sollte mit einem
2004 Vgl. Douek (2020): What Kind of Oversight Board Have You Given Us?
2005 Vgl. Urteil des Bundesverfassungsgerichts vom 28. Februar 1961 (Az.: 2 BvG 1/60, 2 BvG 2/60). Die Entscheidung wird auch als
Magna Charta des Rundfunks bezeichnet.
2006 Entwurf des Medienstaatsvertrags vom 5. Dezember 2019, abrufbar unter https://www.rlp.de/fileadmin/rlp-stk/pdf-Dateien/Medien-
politik/ModStV_MStV_und_JMStV_2019-12-05_MPK.pdf (zuletzt abgerufen am 4. August 2020). Zahlreiche L&#228;nderparlamente 
haben dem Entwurf inzwischen zugestimmt; er soll im Herbst in Kraft treten.
kontinuierlichen und strategischen Prozess verbunden sein, in dem der Bek&#228;mpfung von illegalen Inhalten sowie
der Sicherung der Meinungs- und Pressefreiheit Rechnung getragen wird.
Um Transparenz zu gew&#228;hrleisten, haben Medienintermedi&#228;re gem&#228;&#223; &#167; 93 MStV-E zur Sicherung der
Meinungsvielfalt folgende Informationen leicht wahrnehmbar, unmittelbar erreichbar und st&#228;ndig verf&#252;gbar zu halten:
&#8226; die Kriterien, die &#252;ber den Zugang eines Inhalts zu einem Medienintermedi&#228;r und &#252;ber den Verbleib
entscheiden, sowie
&#8226; die zentralen Kriterien einer Aggregation, Auswahl und Pr&#228;sentation von Inhalten und ihre Gewichtung
einschlie&#223;lich Informationen &#252;ber die Funktionsweise der eingesetzten Algorithmen in verst&#228;ndlicher Sprache
&#196;nderungen der genannten Kriterien sind unverz&#252;glich in derselben Weise wahrnehmbar zu machen.2007 Die
Kennzeichnungspflicht aus &#167; 18 Absatz 3 MStV-E m&#252;sste dann wohl ebenfalls Informationen &#252;ber die
genannten Kriterien fordern.2008 
Zusammenfassend bedeutet dies in formeller Hinsicht, dass die Informationen im Rahmen der Nutzung der
Dienste &#8211; unter Ber&#252;cksichtigung des Kontextes der jeweiligen Nutzungssituation &#8211; ohne Weiteres wahrnehmbar
gestaltet2009 bzw. einsehbar gehalten werden m&#252;ssen2010 und w&#228;hrend der gesamten Nutzung des Dienstes
verf&#252;gbar bleiben.2011 In inhaltlicher Hinsicht sollten Medienintermedi&#228;re jedenfalls die Parameter darlegen m&#252;ssen,
die sie zur Bereitstellung ihrer Dienste und Funktionen in ihrem Datenpool ber&#252;cksichtigen,2012 sowie die Regeln
offenlegen, nach denen &#8211; spiegelbildlich zum Zugang von Inhalten &#8211; verf&#252;gbar gemachte Inhalte aus dem
Suchindex des Medienintermedi&#228;rs entfernt werden.
Wie genau diese Pflichten zu Transparenz und Diskriminierungsfreiheit allerdings zu erf&#252;llen sind, m&#252;ssen die
Landesmedienanstalten mithilfe von Satzungen weiter ausdifferenzieren.2013 Daf&#252;r m&#252;ssten ihnen neue fachliche
und auch rechtliche Kompetenzen zugewiesen werden: So sind ihnen fachlich nur allgemeine, aber keine
speziellen Befugnisse wie Schnittstellen zu den Daten zugewiesen worden. Rechtlich k&#246;nnen sie zwar das Vorlegen
von Unterlagen und Auskunft verlangen, eine Berichtspflicht der Medienintermedi&#228;re oder besondere
Kontrollbefugnisse in Bezug auf die Einhaltung der Vorschriften besteht aber nicht.2014 Ein Haupthindernis f&#252;r eine
sinnvolle Regulierung von Informationsintermedi&#228;ren ist nach wie vor der mangelnde Zugang zu Daten und
Dokumentationsmaterial &#252;ber die Funktionsweise der eingesetzten KI-Techniken und Algorithmen sowie die
Prinzipien der Auswahl und Priorisierung. W&#228;hrend Schutzrechte, etwa f&#252;r personenbezogene Daten oder
Gesch&#228;ftsgeheimnisse, gewahrt werden m&#252;ssen, darf der Datenzugang zu den Systemen der Informationsintermedi&#228;re nicht
mit einem allgemeinen Verweis auf solche Schutzrechte verwehrt werden. Wo allgemeine
Ver&#246;ffentlichungspflichten nicht in Betracht kommen, sind In-Camera-Verfahren denkbar, also die Er&#246;ffnung des Zugangs f&#252;r
bestimmte, legitimierte Personengruppen wie z. B. Mitarbeiterinnen und Mitarbeiter von Aufsichtsbeh&#246;rden.
Gewisse Sorgen bei der Erhaltung der Medienvielfalt bestehen bei Sprachassistenten, da diese regelm&#228;&#223;ig auf
Suchanfragen nur ein Ergebnis liefern2015 und die Auswahlentscheidung durch die weitere Ausgestaltung
zus&#228;tzlich beschr&#228;nkt wird.2016 Die Nutzerautonomie bei der Auswahl der Einstellungen, die Einfluss auf die
angezeigten Ergebnisse haben, sind dabei beschr&#228;nkt.
Auff&#228;llig ist die fehlende Modernisierung des Medienkonzentrationsrechts. Mit Einf&#252;hrung der Transparenz- und
Nichtdiskriminierungspflichten hat die Gesetzgebung erkannt, dass Intermedi&#228;re im Rahmen der Sicherung der
Vielfalt zu ber&#252;cksichtigen sind. Das Gesamtbild zur Betrachtung des Einflusses auf die Meinungsbildung soll
aber das Medienkonzentrationsrecht zeichnen. Hier wurde bislang vers&#228;umt, Intermedi&#228;re in die &#220;berlegungen
2007 Vgl. &#167; 93 Absatz 3 Medienstaatsvertrag-E.
2008 Zum Teil stellen einzelne Intermedi&#228;re &#228;hnliche Informationen schon zur Verf&#252;gung; vgl. Pr&#228;sentation von Dr. Anja Zimmer
(Medienanstalt Berlin-Brandenburg), Projektgruppendrucksache 19(27)PG 6-22 vom 7. Februar 2020, S. 8.
2009 Beispielsweise durch Men&#252;f&#252;hrung und Leitung der Nutzenden im Rahmen des User-Flows ohne weiteren Zwischenschritt abrufbar.
2010 Beispielsweise durch Anbringung eines entsprechenden Hinweises an jedem angezeigten Inhalt oder Beitrag.
2011 Vgl. Schwartmann et al. (2020): Transparenz bei Medienintermedi&#228;ren, S. 26 f.
2012 Dabei muss erkennbar sein, ob s&#228;mtliche Inhalte im Netz durch Indexierung abrufbar sind oder nur diejenigen, die
Medienintermedi&#228;re selbst festgelegt haben.
2013 Zur unterschiedlichen Ausgestaltung der Satzungsbefugnis vgl. &#167; 96 Medienstaatsvertrag-E mit &#167; 88 Medienstaatsvertrag-E.
2014 Pr&#228;sentation von Dr. Anja Zimmer (Medienanstalt Berlin-Brandenburg), Projektgruppendrucksache 19(27)PG 6-22 vom 7. Februar
2020, S. 12; ebenso Schwartmann, in: Klausa (2020): Gutachten: Neue Regeln f&#252;r Facebook &amp; Co. n&#246;tig.
2015 Darstellung Dr. Anja Zimmer (Medienanstalt Berlin-Brandenburg) in der Sitzung der Projektgruppe KI und Medien am 10. Februar
2020.
2016 Vgl. Zimmer (2019): Smart Regulation: Welche Antworten gibt der Medienstaatsvertrag auf die Regulierungsherausforderungen des
21. Jahrhunderts? &#8211; Ein Blick aus der Regulierungspraxis, S. 126.
zur zuk&#252;nftigen Ausgestaltung des Medienkonzentrationsrechts &#252;berhaupt einzubeziehen.2017 Es werden
Anbieter, die aufgrund ihres Einflusspotenzials vergleichbar sind, vom Rundfunkrecht ungleich bewertet. Hinzu tritt
der Umstand, dass sich der gesetzliche Ausgestaltungsauftrag im Bereich der Rundfunkordnung f&#252;r den
Gesetzgeber zu einer Pflicht verdichtet, wenn Hinweise vorliegen, dass die Freiheit der &#246;ffentlichen und individuellen
Meinungsbildung m&#246;glicherweise gef&#228;hrdet ist.2018 Es wird dringend mehr Forschung zu der Frage ben&#246;tigt, wer
im digitalen Raum als &#8222;meinungsm&#228;chtig&#8220; im Sinne eines beherrschenden oder besonders gro&#223;en Einflusses auf
die Meinungsbildung zu gelten hat. Dabei sollte insbesondere die Rolle automatisierter Empfehlungssysteme und
KI f&#252;r die Meinungsmacht von Informationsintermedi&#228;ren untersucht werden.
7.2.1.1 Handlungsempfehlungen
Da die Kompetenz im Medienbereich zwischen Bund und L&#228;ndern verteilt ist sowie regulatorische Ans&#228;tze
immer st&#228;rker auf EU-Ebene erfolgen, sollte einerseits dringend gemeinsam mit den L&#228;ndern grundlegend &#252;berpr&#252;ft
werden, ob die Bund-L&#228;nder-Kompetenzverteilung im Bereich der Plattform- und Telemedienregulierung (vor
allem Rundfunkstaatsvertrag, Jugendmedienschutz-Staatsvertrag, Jugendschutzgesetz,
Netzwerkdurchsetzungsgesetz) angesichts der fortschreitenden Entwicklungen im KI-Bereich noch sachgerecht und konsistent ist. Auf
dieser Grundlage sollten notwendige Ver&#228;nderungen aufgezeigt und angegangen werden. Andererseits sollte
Medienregulierung auf europ&#228;ischer und internationaler Ebene vorangetrieben werden. Dabei m&#252;ssen alle
Regulierungs- und Aufsichtsbeh&#246;rden im Medienbereich st&#228;rker aufeinander abgestimmt werden. Auf europ&#228;ischer
Ebene bedarf es einer St&#228;rkung der European Regulators Group for Audiovisual Media Services (ERGA), die
sich aus den Regulierungsbeh&#246;rden der 28 europ&#228;ischen Mitgliedstaaten zusammensetzt. Eine konsistente
Regulierung auf europ&#228;ischer Ebene erfordert eine ausreichend ausgestattete Beh&#246;rde, die Regulierung auch um- und 
durchsetzen kann.
Da Medienregulierung sich immer an den Grundrechten auf Meinungs- und Informationsfreiheit zu messen hat
und deshalb staatliche Regulierung immer eine Regulierung hin zu Vielfalt sein muss, sind Informations- und
Transparenzpflichten ein gro&#223;er Schritt in Richtung einer normativen Ausgestaltung der Distribution von
Inhalten im Internet:2019 Denn die Informationsasymmetrie und die Black-Box-Problematik2020 m&#252;ssen durchaus als
Transparenz- und Vielfaltsdefizit im Anwendungsbereich des Medienstaatsvertrags angesehen werden2021. Da 
den Medienanstalten die praktische Ausgestaltung der Normen zukommt, sollten die ersten Erfahrungen
abgewartet und evaluiert werden. Dringend anzuraten ist auch, an der weiteren Modernisierung von
Landesmedienanstalten zu arbeiten, etwa &#252;ber weitere Zusammenlegungen zu diskutieren und &#252;ber den weiteren Aufbau
fachlicher Expertise in den Anstalten sowie &#252;ber die Zusammensetzung der Gremien nachzudenken.2022 Die
Erweiterung des Anwendungsbereichs auf neue Angebotsformate wie Intermedi&#228;re macht die m&#246;gliche &#220;berlappung
der Medienregulierung mit Regelungsaspekten deutlich, f&#252;r die gegebenenfalls eine Bundeskompetenz besteht
(Telekommunikation, Wirtschaft, Kartellrecht, &#246;ffentliche F&#252;rsorge, Strafrecht). Eine Modernisierung b&#246;te hier
Gelegenheit, die &#220;bergabepunkte und &#8208;verfahren sowie die Koordination zwischen Bund und L&#228;ndern zu
definieren und entsprechende Prozesse zu etablieren. Wichtigster Schritt daf&#252;r bleibt aber interdisziplin&#228;re Forschung
(Kommunikation, &#214;konomie, Medienrecht, Technik), um das mit dem Design der Aufmerksamkeits&#246;konomie
einhergehende Problem im Bereich der &#246;ffentlichen Meinungsbildung anzugehen.2023 Damit Regulierung im
Medienbereich Wirkung entfalten kann, muss sie auch auf europ&#228;ischer und internationaler Ebene vorangetrieben
werden.
2017 Vgl. Gounalakis et al. (2019): KEK Kommission zur Ermittlung der Konzentration im Medienbereich &#8211; 21. Jahresbericht 2018/2019,
S. 29.
2018 Vgl. Schulz und Dreyer (2018): Stellungnahme zum Diskussionsentwurf eines Medienstaatsvertrags der L&#228;nder, S. 17.
2019 Vgl. Gounalakis et al. (2019): KEK Kommission zur Ermittlung der Konzentration im Medienbereich &#8211; 21. Jahresbericht 2018/2019,
S. 28: Die Einbeziehung von Benutzeroberfl&#228;chen sowie die Erweiterung von Diskriminierungsverboten und Transparenzpflichten 
sind vor dem Hintergrund der Vielfaltssicherung jedenfalls positiv zu bewerten.
2020 Zur Blackbox-Problematik siehe auch das Kapitel 7.3.2 dieses Projektgruppenberichts [Technische M&#246;glichkeiten der Governance
von ADM-Systemen].
2021 Vgl. Schwartmann et al. (2020): Transparenz bei Medienintermedi&#228;ren.
2022 Die Landesmedienanstalten haben bereits gemeinsame Gremien eingerichtet, z. B. die Kommission zur Ermittlung der Konzentration
im Medienbereich, weitere Informationen dazu unter: https://www.kek-online.de/ (zuletzt abgerufen am 9. September 2020), oder
die Kommission f&#252;r Jugendmedienschutz, weitere Informationen dazu unter: https://www.kjm-online.de (zuletzt abgerufen am
9. September 2020).
2023 Dies betrifft sowohl das mit dem Aufmerksamkeits&#246;konomiedesign einhergehende Problem der Kompetenzverteilung als auch das
mit dem Aufmerksamkeits&#246;konomiedesign einhergehende Problem der Informationsvermittlung abseits journalistisch-ethischer
Ma&#223;st&#228;be; vgl. zu den aktuellen Debatten diesbez&#252;glich z. B. Voss (2020): &#8222;Wir sind auf dem direkten Weg ins digitale Mittelalter&#8220;.
7.2.2 Wettbewerbsrecht
Die bereits im Kapitel 5.4 des Mantelberichts [Wettbewerbsrecht] angesprochenen &#220;berlegungen zur Reform
des Wettbewerbsrechts betreffen auch die Medienbranche. Dabei findet die Kontrolle von Konzentration,
Wettbewerb und Meinungsfreiheit im Medienbereich im &#8222;Dreieck&#8220; aus Kartellrecht, Telekommunikationsrecht und
Rundfunkrecht statt. Das Rundfunkrecht verfolgt mit der Sicherung der Meinungsvielfalt einen anderen Ansatz
als das Kartell- und Telekommunikationsrecht und ist daher parallel anzuwenden.2024 
Klassische Medienh&#228;user sind herausgefordert, da die Produktion von Inhalten und deren Verbreitung
zunehmend nicht mehr in einer Hand liegen. Denn die Distribution von Inhalten geschieht h&#228;ufig &#252;ber
Medienintermedi&#228;re wie soziale Netzwerke, w&#228;hrend die Produktion von Inhalten weiter von klassischen Medienh&#228;usern
dominiert wird,2025 insbesondere bei Medienintermedi&#228;ren wie sozialen Netzwerken. Gro&#223;e Plattformanbieter haben
aber zum Teil auch im Mediensektor die Funktion von Gatekeepern inne2026 und nutzen KI zur Distribution aller
Inhalte.2027 Auf ihnen vermischen sich dabei medienspezifische Dienstleistungen wie das Verbreiten von
Nachrichten und Informationen mit anderen Gesch&#228;ftsmodellen (z. B. betreibt die Suchmaschine Google auch Google
Shopping oder Google Jobs). Kartellrechtliche Untersuchungen weisen darauf hin, dass Plattformanbieter ihre
Position ausnutzen, indem Angebote bestimmter Unternehmen auf der eigenen Plattform gegen&#252;ber Angeboten
von Wettbewerbern bevorzugt behandelt werden.2028 Diese Medienintermedi&#228;re sind dabei von
Netzwerkeffekten gepr&#228;gt, die ihre Wettbewerbsposition st&#228;rken und daf&#252;r sorgen, dass nur wenige Anbieter den Markt
pr&#228;gen.2029 Insbesondere in Bezug auf die allgemeine wettbewerbsrechtliche Herausforderung einer
Datenmonopolisierung spielt hier im Verh&#228;ltnis Medienanbieter zu Plattformanbieter die sogenannte Intermediationsmacht
eine Rolle. Das bedeutet, dass Inhalte von Medienanbietern auch &#252;ber die Plattformen ausgespielt werden, ohne
dass eine (ausreichende) finanzielle R&#252;ckkoppelung erfolgt. Weiterhin k&#246;nnen die Medienunternehmen nur
schwerlich ein Gegengewicht zur Marktdominanz von Plattformanbietern aufbauen. Unter anderem liegt dies an
der Marktabgrenzung im Kartellrecht. Eine entsprechende &#196;nderung des Wettbewerbsrechts wird diskutiert.2030 
Auch bei der Konkurrenz um den Plattformmarkt im Medienbereich an sich spielen die Netzwerkeffekte eine
Rolle. Beispielhaft genannt sei die derzeitige kartellrechtliche Untersuchung der EU-Kommission gegen
Apple.2031 
Bisher gestaltet es sich anhand der bestehenden Regulierung als schwierig, Marktmacht von Plattformanbietern, 
die verschiedene Dienste integriert haben, festzustellen.
Dar&#252;ber hinaus ist ein Zugang von Wettbewerbern zu den Datenpools marktm&#228;chtiger Plattformen bisher im
Wettbewerbsrecht nicht vorgesehen. Unter anderem liegt dies vor allem an der Marktabgrenzung im Kartellrecht.
Andererseits wird die Machtposition von Intermedi&#228;ren dadurch beg&#252;nstigt, dass die Folgen von
Netzwerkeffekten sowie die Datenmacht von Unternehmen bisher bei der Bestimmung der Eingriffsschwellen des Kartell- und 
Wettbewerbsrechts nicht ber&#252;cksichtigt werden.2032
2024 Vgl. Beckmann und M&#252;ller (2014): Teil 10 Kartellrecht A Rn. 18. Siehe auch Kapitel 7.2.1 dieses Projektgruppenberichts [
Medienrecht (Medienstaatsvertrag)] zum Medienkonzentrationsrecht.
2025 Pr&#228;sentation von Prof. Dr. Podszun (Heinrich-Heine-Universit&#228;t D&#252;sseldorf), Projektgruppendrucksache 19(27)PG 6-20 vom 7.
Februar 2020.
2026 Siehe auch Kapitel 6.2.1 dieses Projektgruppenberichts [Algorithmisch personalisierte Nachrichtenkan&#228;le und politisches
Microtargeting].
2027 Siehe auch Kapitel 6 dieses Projektgruppenberichts [Distribution].
2028 Ein medienspezifisches Beispiel ist die Kartellstrafe, die die EU-Kommission gegen Google im Jahr 2017 verh&#228;ngt hat, da Google 
auf seiner Suchmaschine die Ergebnisse seines hauseigenen Preisvergleichsdienstes Google Shopping besser platziert hatte als die
Preisvergleichsdienste von Wettbewerbern, Weitere Informationen dazu unter: https://ec.europa.eu/germany/news/eu-kommission-
verh%C3%A4ngt-geldbu%C3%9Fe-von-242-milliarden-euro-gegen-google_de (zuletzt abgerufen am 5. August 2020).
2029 Siehe auch Kapitel 5.4 des Mantelberichts [Wettbewerbsrecht]. 
2030 Unternehmen sollen auch dann marktbeherrschend sein, wenn sie zwar nicht als Anbieter oder Nachfrage einer bestimmten Art von 
Waren oder gewerblichen Leistungen, wohl aber als Vermittler auf dem sachlich und r&#228;umlich relevanten Markt die
Marktbeherrschungskriterien des &#167; 18 Absatz 1 des Gesetzes gegen Wettbewerbsbeschr&#228;nkungen erf&#252;llen,vgl. Schweitzer et al. (2018):
Modernisierung der Missbrauchsaufsicht f&#252;r marktm&#228;chtige Unternehmen, S. 72.
2031 So legte der Musikstreaming-Anbieter Spotify im Jahr 2019 Beschwerde bei der EU-Kommission ein, da Apple f&#252;r das Abschlie&#223;en
eines Abos &#252;ber den App-Store Geb&#252;hren in H&#246;he von 30 Prozent des Umsatzes erhebe. Spotify sah darin eine Bevorteilung des
hauseigenen Musikstreaming-Dienstes (Apple Music), da bei diesem die Geb&#252;hr nicht anf&#228;llt. Das Ergebnis der Untersuchung steht
noch aus. Weitere Informationen dazu unter: https://www.golem.de/news/spotify-beschwerde-eu-will-kartellverfahren-gegen-apple-
einleiten-1905-141050.html (zuletzt abgerufen am 5. August 2020).
2032 Ein Beispiel daf&#252;r ist das vorl&#228;ufige Scheitern des Bundeskartellamtes mit einem Verfahren gegen Facebook. Das Kartellamt hatte
Facebook verboten, Daten von WhatsApp und Instagram mit den bestehenden Facebook-Konten der Nutzerinnen und Nutzer
zusammenzuf&#252;hren. Mit einem Eilantrag wehrte sich Facebook vor dem Oberlandesgericht D&#252;sseldorf und bekam vorerst recht, da die
7.2.2.1 Handlungsempfehlungen
Medienm&#228;rkte sollten eine gesonderte Betrachtung finden. Auf EU-Ebene sollte die Marktabgrenzung f&#252;r
Medienm&#228;rkte &#252;berarbeitet werden. Es ist daf&#252;r Sorge zu tragen, dass die Kriterien, nach denen Suchergebnisse bzw.
Produkte gefiltert oder gerankt werden, f&#252;r die Verbraucherin oder den Verbraucher transparent sind. Zu pr&#252;fen
ist, inwiefern ein Verhaltenskodex f&#252;r Unternehmen mit markt&#252;bergreifender Bedeutung zum Umgang mit
Medien und Nachrichten zur Sicherung der medialen Vielfalt beitragen kann oder ob allgemeine Rahmenvorgaben
zu Transparenz und Diskriminierungsfreiheit im Gesetz notwendig sind.
Technische M&#246;glichkeiten der Governance von KI-Systemen in der Produktion und 
Verteilung von Medien durch Software (Governance by algorithms)
Da die Kontrolle zumindest einiger generierender und verteilender KI-Systeme notwendig erscheint, werden in
diesem Abschnitt die technischen Grundlagen, die f&#252;r eine durch Software unterst&#252;tzte Kontrolle notwendig sind,
und die (heutigen) Grenzen solcher Kontrollm&#246;glichkeiten aufgezeigt.
In diesem Bericht wurde schon erw&#228;hnt, dass im Bereich Medien zwei Typen von KI angewendet werden, die
auch problematische Aspekte aufweisen, die der Governance bed&#252;rfen. Das eine sind generative KI-Systeme,
das andere algorithmische entscheidungstreffende oder -unterst&#252;tzende Systeme mit einer lernenden oder
gelernten Komponente; zu diesen geh&#246;ren insbesondere Empfehlungssysteme. In diesem Abschnitt geht es um die
Frage, inwieweit solche KI-Systeme bzw. ihre Ergebnisse automatisiert durch Software identifiziert oder
&#252;berwacht werden k&#246;nnen. 
7.3.1 Algorithmische Governance von generativen KI-Systemen
Im Bereich der generativen KI-Systeme k&#246;nnen beispielsweise Deep Fakes mithilfe von Algorithmen wenigstens
teilweise identifiziert werden. Es handelt sich hierbei aber um ein klassisches Hase-und-Igel-Spiel: Wird eine
M&#246;glichkeit zum Erkennen von Deep Fakes ver&#246;ffentlicht, nehmen die Entwicklerinnen und Entwickler der
generativen KI-Systeme diese M&#246;glichkeit so auf, dass sie nicht mehr zur Identifikation verwendet werden kann.
Ein &#228;hnliches Muster ist seit Jahrzehnten zwischen den Verfasserinnen und Verfassern von Spam-E-Mails sowie
den Entwicklerinnen und Entwicklern von Spamfiltern zu beobachten. 
Da KI-Systeme immer musterbasiert arbeiten, k&#246;nnen diese Muster f&#252;r die Identifikation prinzipiell verwendet
werden. Das gelingt aber nur, sofern die generierten Medien lang genug sind, um darin statistische Muster zu
entdecken. Sehr kurze Fakes sind daher schwerer zu entlarven als l&#228;ngere.
Zusammenfassend wird man im Bereich der generativen KI-Systeme langfristig und fortgesetzt
Identifikationssysteme entwickeln m&#252;ssen, um die jeweils vorherrschenden Muster identifizieren zu k&#246;nnen. 
7.3.2 Technische M&#246;glichkeiten der Governance von ADM-Systemen
Wie bereits in Kapitel 6.1 dieses Projektgruppenberichts [Problematische Aspekte von Empfehlungssystemen]
erl&#228;utert, gibt es verschiedene Aspekte, die bei Empfehlungssystemen, die digitale Inhalte selektieren und
anordnen, f&#252;r Probleme sorgen k&#246;nnen. Der erste problematische Aspekt ist gleichzeitig ihr gr&#246;&#223;ter Vorteil: In der
digitalen Welt k&#246;nnen Empfehlungssysteme einfach personalisiert werden. Was eine gro&#223;e Zeitersparnis sein 
kann, weil Nutzerinnen und Nutzer sich nicht durch Inhalte bewegen m&#252;ssen, die sie nicht interessieren, f&#252;hrt
bei anderen Gruppen zu Intransparenz:
1. Produzentinnen und Produzenten von digitalen Inhalten k&#246;nnen nur schwer Einblick darin gewinnen, ob
ihre Produkte den Markt erreichen &#8211; die Plattformen k&#246;nnen diesen Einblick jederzeit gew&#228;hren oder wieder
abstellen und gleichzeitig die Regeln von Auswahl und Anordnung von Inhalten ver&#228;ndern. Dies erzeugt a)
eine hohe Abh&#228;ngigkeit von den Plattformen und b) macht es f&#252;r die Schutzinstitutionen von selbst&#228;ndigen 
Anbietern und die Gesellschaft im Ganzen schwierig, die Lage zu &#252;berblicken.
2. Wenn es bei den digitalen Inhalten um Nachrichten oder politische Werbung geht, ist es f&#252;r die Gesellschaft
wichtig, Einblicke darin zu haben, welche Art von Nachrichten bestimmte Teilgruppen erhalten (Diversit&#228;t
bzw. Filterblasenph&#228;nomen) und ob diese inhaltlich korrekt sind. 
Richter kein wettbewerbssch&#228;dliches Verhalten erkennen konnten. Weitere Informationen dazu unter: https://www.sueddeut-
sche.de/wirtschaft/facebook-daten-whatsapp-instagram-1.4576484 (zuletzt abgerufen am 5. August 2020).
3. Wenn es bei den digitalen Inhalten um Werbung f&#252;r Produkte geht, ist es notwendig, dass Anbieter der
Produkte einen fairen und nachvollziehbaren Zugang zum digitalen Markt bekommen. Insbesondere dann,
wenn der digitale Inhalt Nutzerinnen und Nutzer als Arbeitnehmerin bzw. Arbeitnehmer beschreibt (auf
Karriereplattformen wie XING oder LinkedIn) und sie potenziellen Arbeitgeberinnen und Arbeitgebern
angeboten werden, m&#252;ssen die Rechte von Arbeitnehmerinnen und Arbeitnehmern durchsetzbar sein (z. B. 
Diskriminierungsfreiheit).
4. F&#252;r Verbrauchersch&#252;tzer, Wettbewerbsbeh&#246;rden, Konkurrenten und Jugendsch&#252;tzer ist es bei Werbungen
f&#252;r Produkte hingegen wichtig, nachvollziehen zu k&#246;nnen, ob die angepriesenen Eigenschaften von
Produkten der Wahrheit entsprechen (insbesondere bei Gesundheitsprodukten) und ob Kinder- und
Jugendschutzrechte eingehalten wurden.
Bei den meisten dieser Fragestellungen ist es weniger wichtig, zu verstehen, wieso wer welchen digitalen Inhalt
angeboten bekam; vielmehr ist es wichtig, zu wissen, ob die jeweiligen dabei notwendigen Aspekte eingehalten
wurden, z. B. Fairness, Zugang zum Markt, Diversit&#228;t, Korrektheit, rechtliche Bedingungen. In den meisten
F&#228;llen kann dies daher ohne Einsicht in das eigentliche Entscheidungssystem kontrolliert werden, sondern durch
eine gezielte Eingabe von Testdaten und Analyse der resultierenden Entscheidungen. Auch der
Personalisierungsgrad kann ohne Einsicht in den Code bestimmt werden.2033 Solche sogenannten Black-Box-Analysen &#8211; die 
den Code nicht ben&#246;tigen &#8211; k&#246;nnen damit zur algorithmischen Kontrolle von Empfehlungssystemen genutzt
werden, wenn die daf&#252;r notwendigen Datenzug&#228;nge vorhanden sind (Governance by algorithms).2034 
Auf der einen Seite k&#246;nnen die verwendeten Trainings- wie auch Inputdaten algorithmisch auf Vollst&#228;ndigkeit, 
Fehlerraten und Qualit&#228;t hin &#252;berpr&#252;ft werden. Algorithmen k&#246;nnen auch genutzt werden, um die verwendeten
Trainingsdaten auf ungerechtfertigte Diskriminierungen hin zu &#252;berpr&#252;fen &#8211; dazu wird beispielsweise eines von
&#252;ber zwei Dutzend Fairnessma&#223;en verwendet.2035 Da maschinelle Lernverfahren solche ungerechtfertigten
Diskriminierungen in ihre sp&#228;tere Entscheidungsregeln &#252;bernehmen k&#246;nnten, ist diese &#220;berpr&#252;fung sehr wichtig. 
Auf der anderen Seite gibt es eine Reihe von algorithmischen Methoden, um die Entscheidungslogik eines
Entscheidungssystems zu &#252;berpr&#252;fen. Die algorithmische &#220;berpr&#252;fung der Sinnhaftigkeit vom Programmcode ist
extrem schwierig bis unm&#246;glich &#8211; wurde ein zu l&#246;sendes Problem sehr detailliert modelliert, ist es manchmal
m&#246;glich, dessen Umsetzung im Programmcode direkt zu verifizieren. Das wird in den meisten F&#228;llen bei KI-
Systemen nicht m&#246;glich sein. Daher ist die wichtigste &#220;berpr&#252;fungsm&#246;glichkeit durch einen Algorithmus die
Durchf&#252;hrung oder Unterst&#252;tzung bei sogenannten Black-Box-Analysen. Hierbei wird das zu &#252;berpr&#252;fende
System als &#8222;Black Box&#8220; betrachtet, also als ein System, in das man keinen direkten Einblick erh&#228;lt. Insbesondere ist
dessen Code unbekannt. Dennoch kann man ein Verst&#228;ndnis der Entscheidungslogik bekommen, indem man 
Daten in das System eingibt, die jeweiligen Entscheidungen errechnen l&#228;sst und aus der Beziehung von Ein- und 
Ausgabe R&#252;ckschl&#252;sse auf die zugrunde liegende Entscheidungsmechanik sowie &#252;ber die G&#252;te des Systems
zieht.2036 Bei der Auditierung von ADM-Systemen &#252;ber solche Black-Box-Ans&#228;tze gibt es verschiedene
Verfahren; die Gesellschaft f&#252;r Informatik2037 folgt bei der Kategorisierung einer Unterteilung, die sich an der
Beteiligung der eigentlichen Nutzerinnen bzw. Nutzer des ADM-Systems orientiert: So werden beispielsweise
Verfahren, bei denen echte Menschen gebeten werden, die Ergebnisse eines ADM-Systems, das sie nutzen, zu spenden,
von solchen unterschieden, bei denen Fake-Accounts genutzt werden. 
Mit solchen Black-Box-Ans&#228;tzen k&#246;nnen dann manchmal andere Eigenschaften als die Entscheidungslogik
untersucht werden: Mithilfe eines partizipativen Ansatzes konnte z. B. zur Bundestagswahl 2017 gezeigt werden,
dass die Personalisierung der Suchergebnisse auf Google bei der Suche nach politischen Parteien oder deren
2033 Vgl. Krafft et al.: What did you see? A study to measure personalization in Google&#8217;s search engine.
2034 Aktuell werden diese im Projekt &#8222;GOAL &#8211; Governance von und durch Algorithmen&#8220; (weitere Informationen dazu unter: https://goal-
projekt.de/ (zuletzt abgerufen am 5. August 2020)) erforscht, das durch das Bundesminsterium f&#252;r Bildung und Forschung gef&#246;rdert
wird (F&#246;rderkennzeichen: 01|S19020).
2035 Fairnessma&#223;e sind Formeln, die f&#252;r einen Algorithmus, der Entscheidungen trifft, messen, wie fair die richtigen und m&#246;glicherweise
falschen Entscheidungen auf zwei oder mehr Bev&#246;lkerungsgruppen verteilt sind. Dazu gibt es verschiedene Ans&#228;tze und daher gibt 
es verschiedene Formeln daf&#252;r.
2036 Vgl. Diakopoulos (2014): Algorithmic Accountability: On the Investigation of Black Boxes.
2037 &#8222;Nicht-invasives Audit&#8220;, &#8222;Scraping Audit&#8220;, &#8222;Sock Puppet Audit&#8220; und &#8222;Crowdsourced Audit&#8220; nach Gesellschaft f&#252;r Informatik e. V.
(2018): Technische und rechtliche Betrachtungen algorithmischer Entscheidungsverfahren. Studien und Gutachten im Auftrag des
Sachverst&#228;ndigenrats f&#252;r Verbraucherfragen.
jeweiliger Kanzlerkandidatin oder deren jeweiligem Kanzlerkandidaten sehr gering ist.2038 Da eine hohe
Personalisierung die notwendige Grundlage f&#252;r die Bildung der oben schon erw&#228;hnten Filterblasen2039 im
Nachrichtenbereich ist und eine solche Black-Box-Analyse messen kann, wie hoch der Personalisierungsgrad f&#252;r
verschiedene Nachrichtenbereiche ist, k&#246;nnte eine Verstetigung solcher Analysen sinnvoll sein. Diese Analyse war
jedoch nur durchf&#252;hrbar, da Tausende B&#252;rgerinnen und B&#252;rgern an der Datensammlung beteiligt worden waren,
was bei einer Verstetigung der &#220;berpr&#252;fung zu bedenken ist. Die M&#246;glichkeiten solcher Analysen sind nicht f&#252;r
alle internetbasierten Dienste gleich: F&#252;r Suchmaschinen ist das Prozedere relativ einfach umzusetzen &#8211; k&#246;nnte
aber von daf&#252;r bereitgestellten Programmierschnittstellen stark profitieren. In anderen sozialen Medien wie
Twitter oder insbesondere Facebook ist dagegen eine automatisierte Black-Box-Analyse des Personalisierungsgrades
oder der individualisierten Werbeanzeigenauswahl bisher nahezu unm&#246;glich f&#252;r die Gesellschaft. 
Es ergibt sich daraus die Folgerung, dass die notwendigen maschinell nutzbaren Schnittstellen zu allen sozialen
Medien und sozialen Netzwerken geschaffen werden m&#252;ssen, deren Personalisierungsgrad zur
algorithmenbasierten Bildung oder Verh&#228;rtung von Filterblasen f&#252;hren k&#246;nnte. So k&#246;nnten Teile diese &#220;berpr&#252;fung
algorithmisch vorbereitet, unterst&#252;tzt oder sogar durchgef&#252;hrt werden.
7.3.2.1 Handlungsempfehlungen
Wie in Kapitel 3.2.4 dieses Projektgruppenberichts [Technische Grundlagen von Empfehlungssystemen]
dargestellt, ist bei Empfehlungssystemen f&#252;r Nachrichten aber auch f&#252;r soziale Medien meistens weder klar, was genau
sie optimieren (z. B. Nutzungsdauer, Einnahmen durch Werbung, Interaktion mit Inhalten) noch, nach welchen
Kriterien sie &#252;ber die Auswahl und Anordnung der selektierten Inhalten entscheiden. Zudem gibt es Hinweise
darauf, dass Empfehlungssysteme bei der Verbreitung von Falschnachrichten (Fake News),
Verschw&#246;rungstheorien und Hassbotschaften eine Rolle spielen. Empfehlungssysteme digitaler Inhalte bed&#252;rfen daher einer
Kritikalit&#228;tsbewertung, wie sie in Kapitel 4 des Mantelberichts [KI und Umgang mit Risiko] beschrieben ist. Im
Medienbereich w&#228;ren daf&#252;r Kriterien denkbar, die etwa eine h&#246;here Kritikalit&#228;t ab einer gewissen Nutzerzahl
und Reichweite oder ab einem gewissen Personalisierungsgrad vorsehen. Ebenso sollte die Kritikalit&#228;t auch
davon abh&#228;ngen, ob die Nutzerinnen und Nutzer wenigstens teilweise auch aus gesetzlich besonders gesch&#252;tzten
Personen bestehen (z. B. Kinder und Jugendliche, Arbeitnehmende etc.). 
Der Prozess der Kritikalit&#228;tsbewertung muss noch entwickelt werden. Die Mehrheit der Projektgruppe empfiehlt, 
daf&#252;r ausreichende Forschungsmittel und Mittel f&#252;r die Beratung bereitzustellen. Um Innovationen im digitalen 
Bereich nicht unn&#246;tig zu belasten, muss der Prozess so einfach wie m&#246;glich sein und sollte f&#252;r Systeme mit
geringer Kritikalit&#228;t von den Entwickelnden und den Anwendenden ohne zentrale Meldung durchgef&#252;hrt werden
k&#246;nnen.
Uploadfilter 
7.4.1 Filter bei der Umsetzung von Urheberrecht
Ein wichtiger und viel diskutierter Bereich, in dem KI-basierte Inhaltefilter zum Einsatz kommen, ist die
Erkennung urheberrechtlich gesch&#252;tzter Werke. Wie andere Filtertechniken betrifft dies vor allem Plattformen wie 
soziale Medien oder Videosharing-Dienste, auf denen Inhalte hochgeladen werden k&#246;nnen, das Volumen aber
eine manuelle Pr&#252;fung durch die Plattform unm&#246;glich macht.
Im Kontext der Frage nach urheberrechtlich gesch&#252;tzten Werken ist das Thema deutlich in den Fokus ger&#252;ckt.
Besondere &#246;ffentliche Aufmerksamkeit gibt es diesbez&#252;glich vor allem im Zusammenhang mit der EU-
Urheberrechtsrichtlinie 2019/790 (im Folgenden: DSM-Richtlinie), deren Artikel 17 Plattformen verpflichtet,
Ma&#223;nahmen gegen das Hochladen urheberrechtlich gesch&#252;tzter Werke zu ergreifen, f&#252;r die keine Nutzungserlaubnis
besteht. Explizit wird dort von einem bestm&#246;glichen Bem&#252;hen gesprochen. Nimmt man diese Vorgabe ernst, ist
die logische Schlussfolgerung, dass hier KI-basierte Technologien eingesetzt werden.
&#196;hnliche Verfahren werden allerdings in bestimmten Bereich schon seit einiger Zeit angewandt; bekannt ist vor
allem das von YouTube verwendete System &#8222;Content-ID&#8220;. Dieses wurde in einer ersten Form bereits 2007
eingef&#252;hrt.2040 Das System reagierte zun&#228;chst nur mit Verz&#246;gerung. Inzwischen reagiert das System unmittelbar
2038 Vgl. Krafft et al.: What did you see? A study to measure personalization in Google&#8217;s search engine; Die Aussage gilt f&#252;r den
Untersuchungszeitraum, die Menge der Teilnehmenden und die beschr&#228;nkte Menge an Suchanfragen, die in diesem Rahmen untersucht
wurden.
2039 Vgl. Pariser (2011): The filter bubble.
2040 Vgl. King (2007): Latest content ID tool for YouTube.
beim Upload entsprechender Inhalte. Rechteinhaber k&#246;nnen eine Referenzkopie ihrer Werke zur Verf&#252;gung
stellen, die in einer Datenbank gespeichert wird. Bei einem Upload eines Werkes wird dann automatisch nach
&#220;bereinstimmungen mit in dieser Datenbank verf&#252;gbaren Kopien gesucht, die zur Verf&#252;gung gestellt wurden.2041 
Auch andere gro&#223;e Plattformen verwenden solche Verfahren und mehrere Anbieter vertreiben entsprechende
Dienstleistungen bzw. Technologien.
Zu &#252;berpr&#252;fen, ob ein in digitaler Form vorliegendes Film- oder Tonwerk das Gleiche wie ein vorliegendes
Referenzwerk oder ein Ausschnitt davon ist &#8211; unabh&#228;ngig davon, ob es sich um die gleiche Datei handelt oder ob
oberfl&#228;chliche Modifikationen wie Spiegelung oder eine &#196;nderung durch Verrauschen vorgenommen wurden &#8211;
kann dabei als technisch weitgehend gel&#246;stes Problem angesehen werden. Es handelt sich um eine Aufgabe, f&#252;r
die heutige Methoden der Mustererkennung durch Maschinelles Lernen gut geeignet sind; von der Industrie
werden dementsprechend sehr geringe Fehlerraten hinsichtlich der Erkennung angegeben.
Allerdings ist die Erkennung nicht identisch mit der Aufgabe, zu erkennen, ob es sich bei der Ver&#246;ffentlichung
dieses Werks um eine Urheberrechtsverletzung handelt, denn es erfolgt keine juristische &#220;berpr&#252;fung. Zentral
ist, dass das Urheberrecht verschiedene gesetzliche Nutzungserlaubnisse kennt, von denen einige, beispielsweise
das Zitatrecht oder die Nutzung f&#252;r Parodien2042, nur durch eine Betrachtung des Kontexts und der Intention der
Ver&#246;ffentlichung beurteilt werden k&#246;nnen. Selbst eine semantische Betrachtung muss somit an Grenzen sto&#223;en.
Im Umkehrschluss gilt heute, dass eine solche Kontextbewertung mit automatisierten Verfahren, wie sie derzeit
angewendet und wahrscheinlich auch auf absehbare Zeit entwickelt werden, so wie gew&#252;nscht nicht leistbar ist
und auch gar nicht versucht wird. Dies best&#228;tigten auch die Anbieter entsprechender Software im
Konsultationsverfahren zur DSM-Richtlinie.2043 F&#252;r alle F&#228;lle, in denen Nutzungshandlungen von diesen Erlaubnissen
abgedeckt sind, muss daher von einer Fehlerrate bzgl. der Erkennung urheberrechtlich erlaubter Nutzungen nahe
100 Prozent ausgegangen werden.
Weitere Quellen f&#252;r falsche Positivmeldungen, dass es sich um eine urheberrechtlich nicht erlaubte Verwendung
handeln k&#246;nnte, entstehen dann, wenn gesch&#252;tzte Werke Ausschnitte aus anderen Werken enthalten oder auf
gemeinfreien Werken aufbauen, sodass die Originale oder andere Adaptionen der gemeinfreien Grundlage
f&#228;lschlicherweise als Urheberrechtsverletzung erkannt werden. Auch hierf&#252;r gibt es Praxisbeispiele.2044 
Eine Bewertung des Einsatzes derartiger Filter wird davon abh&#228;ngen, welche Konsequenzen aus der
vermeintlichen Erkennung einer Urheberrechtsverletzung gezogen werden. Eine automatisierte L&#246;schung (bzw.
Nichtver&#246;ffentlichung) k&#246;nnte bei fl&#228;chendeckendem Einsatz zur Folge haben, dass die kontextabh&#228;ngigen
Nutzungserlaubnisse des Urheberrechts in diesem Bereich faktisch ausgehebelt w&#252;rden, was in Anbetracht der Bedeutung
dieser Erlaubnisse f&#252;r die Meinungs-, Informations- und Pressefreiheit problematisch w&#228;re. In diesem Fall w&#252;rde 
man &#8222;im Zweifel gegen den Angeklagten&#8220; eine vorauseilende Zensur aus kommerziellem Interesse durchf&#252;hren.
Anders stellt sich die Situation dar, wenn die Erkennung im Zweifelsfall lediglich Ausl&#246;ser f&#252;r eine weitere,
sinnvollerweise menschliche &#220;berpr&#252;fung w&#228;re. Eine solche L&#246;sung f&#252;r die Umsetzung von Artikel 17 der DSM-
Richtlinie wird auch von der Bundesregierung in ihrer Protokollerkl&#228;rung als M&#246;glichkeit angef&#252;hrt2045 und ist
Teil der Empfehlungen einer Gruppe von europ&#228;ischen Urheberrechtsexpertinnen und -experten zur Umsetzung
f&#252;r F&#228;lle, in denen das erkannte Werk nicht &#8222;auf den ersten Blick&#8220; mit dem gesch&#252;tzten Werk identisch ist oder
ihm nicht &#8222;auf den ersten Blick&#8220; entspricht.2046 In den meisten F&#228;llen hat die Erkennung von urheberrechtlich
gesch&#252;tztem Material die Zahlung an Rechteinhaber auf Basis von Lizenz- oder Rahmenvereinbarungen zur
2041 Vgl. Google LLC (2020): Verwendung von Content ID.
2042 Derzeit werden Parodien im deutschen Urheberrecht nicht &#252;ber eine eigene Nutzungserlaubnis, sondern &#252;ber das Recht der freien
Benutzung nach &#167; 24 des Urhebergesetzes abgedeckt; mit dem Urteil des EuGH im Fall &#8222;Metall auf Metall&#8220; (Rechtssache
C-476/17) und Artikel 17 Absatz 7 der DSM-Richtlinie wird die Schaffung einer eigenen Nutzungserlaubnis f&#252;r Karikaturen,
Parodien und Pastiches aber unumg&#228;nglich werden.
2043 Vgl. den Stakeholder-Dialog der EU-Kommission zur Umsetzung von Artikel 17 der DSM-Richtlinie am 16. Dezember 2019,
zusammengefasst bei Keller (2020): Article 17 stakeholder dialogue: What we have learned so far &#8211; Part 1. Vgl. insbesondere Zitate
der Vertreter von Facebook und Audible Magic.
2044 Vgl. Schmiedel (2018): RTL hat uns mal kurz gekillt&#8288;; Kaiser (2018): Von einem, der auszog, das F&#252;rchten zu lernen.
2045 Vgl. Erkl&#228;rung der Bundesrepublik Deutschland zur Richtlinie &#252;ber das Urheberrecht und verwandte Schutzrechte im Digitalen 
Binnenmarkt; insbesondere zu Artikel 17 der Richtlinie, abrufbar unter: https://www.bmjv.de/SharedDocs/Down-
loads/DE/News/PM/041519_Protokollerklaerung_Richtlinie_Urheberrecht.pdf?__blob=publicationFile&amp;v=1 (zuletzt abgerufen am
1. September 2020).
2046 Vgl. Universiteit van Amsterdam, Instituut voor Informatierecht (2019): Safeguarding User Freedoms in Implementing Article 17 of
the Copyright in the Digital Single Market Directive: Recommendations from European Academics.
Folge. In diesem Fall hat eine Fehlerkennung eine unrechtm&#228;&#223;ige Zahlung zur Folge &#8211; entweder zum Nachteil
der Plattform oder zum Nachteil der hochladenden Person.
Wollte man eine n&#228;chste Generation von verbesserten Filtern entwickeln, die kontextuelle Zusammenh&#228;nge
erkennen und damit gegebenenfalls auch die Intention der Ver&#246;ffentlichung beurteilen k&#246;nnen, dann m&#252;sste man 
im gro&#223;en Stil entsprechende Daten vorher annotieren. Dies bedingt theoretisch, ein normatives und statisches
Annotationsschema zu entwerfen (z. B. Parodie, Gro&#223;zitat, Drittwerk, Plagiat, Kopie) und die Markierung von
Hunderttausenden von Verdachtsf&#228;llen und Nicht-Verdachtsf&#228;llen auszeichnen, damit dann mit Maschinellem
Lernen ein Modell entsprechend trainiert werden k&#246;nnte. Wie gut dieses am Ende funktionieren w&#252;rde, l&#228;sst sich
heute nicht absehen.
7.4.1.1 Handlungsempfehlungen
KI-basierte Uploadfilter2047 sind zum gegenw&#228;rtigen Zeitpunkt nicht dazu geeignet, Urheberechtsverletzungen
im juristischen Sinne sicher festzustellen. Solange kontextuelle Bez&#252;ge bzw. bestehende Lizenzierungen nicht
eindeutig erkennbar sind oder kenntlich gemacht werden k&#246;nnen, ist von einem routinierten Einsatz von KI-
Uploadfiltern ohne menschliche Kontrolle und Evaluation dringend abzuraten, um die Meinungs- und
Informationsfreiheit im Internet auch k&#252;nftig zu bewahren.2048 Der Umkehrschluss legt auch nahe, dass KI-basierte
Filterverfahren, solange sie nicht entsprechend leistungsstark sind, eben nicht unter die EU-Richtlinie fallen d&#252;rfen,
die die Definition &#8222;best effort&#8220;2049 mit sich bringt, da damit die Anzahl fehlerhafter Einstufungen deutlich &#252;ber
dem Nutzwert liegen und das freiheitlich-demokratische Grundprinzip der Meinungsfreiheit eingeschr&#228;nkt
w&#252;rde.
7.4.2 Hassrede2050 
7.4.2.1 Das Netzwerkdurchsetzungsgesetz gegen Hassrede
Gro&#223;e soziale Netzwerke sind nicht nur R&#228;ume der Diskussion und des Austausches politischer Meinungen,
sondern auch Orte sogenannter Hassrede und ihrer Verbreitung. 
Der Begriff der Hassrede (oder auch Hatespeech) ist juristisch nicht klar definiert, er beschreibt eine Grauzone
strafbarer und nicht-strafbarer &#196;u&#223;erungen. Darunter k&#246;nnen Beleidigungen fallen, Beschimpfungen,
abwertende &#196;u&#223;erungen und Aufrufe zur Gewalt.2051 Strafrechtlich relevant sind etwa die &#246;ffentliche Aufforderung zu
Straftaten (&#167; 111 des Strafgesetzbuchs (StGB)), Volksverhetzung (&#167; 130 StGB), Beleidigung (&#167; 185 StGB),
Verleumdung (&#167; 187 StGB), N&#246;tigung (&#167; 240 StGB) und Bedrohung (&#167; 241 StGB). Das Vorliegen einer Hassrede
l&#228;sst sich nicht immer an klar zu indexierenden W&#246;rtern und Redewendungen festmachen, diese m&#252;ssen auch in
einem konkreten Kontext stehen und eine Person unmissverst&#228;ndlich ansprechen. Durch Verwendung von Ironie, 
&#220;bertreibung, Auslassung oder Parodie k&#246;nnen einzelne Begriffe ambivalente Bedeutungen bekommen, die die
Zuordnung eines Tweets oder Kommentars als Hassrede erschweren.
Die gro&#223;en Plattformen haben sich hauseigene Richtlinien gegeben, um eine friedliche Kommunikation in ihrem
Bereich zu gew&#228;hrleisten. Au&#223;erdem sind sie gem&#228;&#223; dem Gesetz zur Verbesserung der Rechtsdurchsetzung in
sozialen Netzwerken (Netzwerkdurchsetzungsgesetz &#8211; NetzDG) dazu verpflichtet, offensichtlich rechtswidrige
Inhalte innerhalb von 24 Stunden nach Eingang der Beschwerde zu entfernen oder zu sperren.2052 Dar&#252;ber hinaus
verpflichtet sie das NetzDG, &#8222;&#252;ber Mechanismen zur &#220;bermittlung von Beschwerden &#252;ber rechtswidrige Inhalte
2047 Upload-Filter sind Software-Elemente, die hochzuladende Dateien inhaltlich &#252;berpr&#252;fen und unter bestimmten Umst&#228;nden
automatisiert das Hochladen verhindern.
2048 Da KI nach derzeitigem Stand keine Entscheidung &#252;ber die Urheberrechtsm&#228;&#223;igkeit eines Uploads treffen kann, versucht der DiskE 
II vom BMJV, den Menschen in den Entscheidungsprozess mit einzubeziehen. Wenn jemand Urheberrechte nutzen m&#246;chte und sich 
daf&#252;r auf nicht maschinell erkennbare Schranken st&#252;tzt, kann er im Vorfeld durch preflagging &#8222;mithelfen&#8220;. Das Verfahren &#252;berzeugt
nicht alle, zeigt aber zumindest, dass man den Grenzen von KI nicht allein durch nachtr&#228;gliche menschliche Kontrolle begegnen 
kann, sondern auch durch menschliche Aktion im Vorfeld in Kombination mit KI.
2049 Gem&#228;&#223; Artikel 17 Absatz 4 der Richtlinie &#252;ber das Urheberrecht und verwandte Schutzrechte im Digitalen Binnenmarkt m&#252;ssen 
Anbieter nach Ma&#223;gabe hoher branchen&#252;blicher Standards f&#252;r die berufliche Sorgfalt &#8222;alle Anstrengungen&#8220; (in der englischen
Textfassung &#8222;best efforts&#8220;) unternehmen, um sicherzustellen, dass Werke nicht verf&#252;gbar sind.
2050 Zu diesem Kapitel und dem folgenden Unterkapitel liegt ein Sondervotum aus der Fraktion der AfD vor [Sondervotum zu den
Kapiteln 7.4.2 und 7.4.2.1 des Berichts der Projektgruppe 6 &#8222;KI und Medien&#8220; (&#8222;Hassrede&#8220; und &#8222;Das Netzwerkdurchsetzungsgesetz gegen
Hassrede&#8220;) der Abgeordneten Joana Cotar sowie der Abgeordneten Peter Felser und Dr. Marc Jongen].
2051 Vgl. Bundeszentrale f&#252;r politische Bildung (2017): Was ist Hate Speech?
2052 &#167; 3 Absatz 2 Satz 2 NetzDG.
und [die] Entscheidungskriterien f&#252;r L&#246;schung und Sperrung von rechtswidrigen Inhalten&#8220; zu berichten.2053
Darunter fallen auch Beitr&#228;ge, die unter dem Begriff der Hassrede subsumiert werden.
Bei der Vielzahl an Diskussionsbeitr&#228;gen und Kommentaren, die es t&#228;glich zu beobachten gilt, setzen die gro&#223;en
Plattformen auch auf den Einsatz automatischer Filter, die zu beanstandende Beitr&#228;ge &#8211; von der Beleidigung bis
zum Mordaufruf &#8211; erkennen und l&#246;schen sollen. Der Ausschuss f&#252;r Recht und Verbraucherschutz des Deutschen
Bundestages hat sich im Mai 2019 und im Juni 2020 umfassend mit der rechtlichen und praktischen Einsch&#228;tzung
zur Umsetzung des NetzDG besch&#228;ftigt. Dabei haben Sachverst&#228;ndige sowohl Bedenken ausger&#228;umt als auch
Kritik ge&#228;u&#223;ert. So wird einerseits das NetzDG als wichtiger Schritt gewertet, um Hass und Beleidigungen im
Netz zu unterbinden, wie die hohe Anzahl der gel&#246;schten Beitr&#228;ge und das gestiegene Bewusstsein zeigen
w&#252;rden; da sich aber noch immer zu viele strafrechtlich relevante Inhalte auf den Plattformen finden w&#252;rden, wird 
gefordert, dass Plattformen ihrer herausgehobenen Verantwortung noch viel mehr gerecht werden. Dar&#252;ber
hinaus wird nach zwei Jahren NetzDG durchaus Nachbesserungsbedarf am Gesetz gesehen.2054 Die im April 2020
auf den Weg gebrachte Weiterentwicklung des NetzDG verfolgt vorrangig die Ziele, Transparenz und
Nutzerrechte zu st&#228;rken und die Rechtsdurchsetzung zu verbessern.2055 
Im Folgenden wird dargestellt, wie die drei in Deutschland gegenw&#228;rtig wichtigsten Plattformen auch auf KI-
L&#246;sungen zur&#252;ckgreifen, um mit dem Problem der Hassrede umzugehen.
7.4.2.2 Beispiel YouTube
Das Videoportal YouTube nimmt gem&#228;&#223; den Vorgaben des NetzDG halbj&#228;hrlich Stellung zu den gemeldeten
und gegebenenfalls gel&#246;schten Videos.2056 Nach Angaben der Plattform werden pro Minute etwa f&#252;nfhundert
Stunden Videomaterial hochgeladen. Um die eigenen Community-Richtlinien, die das Hochladen anst&#246;&#223;iger
Inhalte wie Pornografie, Spam, Hassrede, Bel&#228;stigung und Anstiftung zur Gewalt untersagen, zu gew&#228;hrleisten,
pr&#252;ft eine interne Abteilung aus Fachleuten (Juristinnen und Juristen, Datenanalysten und Ingenieurinnen und
Ingenieuren) die YouTube-Videos. Dar&#252;ber hinaus sind diejenigen, die die Plattform nutzen, dazu aufgerufen,
etwaige Verst&#246;&#223;e gegen die Community-Richtlinien zu melden.
Im fraglichen Berichtszeitraum (2. Halbjahr 2019) wurden der Plattform 188 671 Inhalte von Nutzerinnen und
Nutzern aus Deutschland gemeldet, weitere 88 807 von Beschwerdestellen. Von diesen beanstandeten Inhalten
wurden 80 824 als &#8222;Hassrede oder politischer Extremismus&#8220;, 42 099 als &#8222;pornografisch&#8220; und 11 281 als
&#8222;terroristisch oder verfassungswidrig&#8220; gemeldet. Von diesen beispielhaft genannten Inhalten wurden 24 692
(Hassrede), 10 959 (Pornografie) und 3 023 (terroristisch oder verfassungswidrig) entfernt, also jeweils rund ein
Viertel der gemeldeten Beitr&#228;ge. Von den als Hassrede eingestuften und entfernten Videos wurden 23 496 wegen des
Versto&#223;es gegen die internen Community-Richtlinien entfernt, lediglich 1 196 aufgrund des NetzDG.
YouTube spricht von einem &#8222;Mensch-Maschine-Ansatz&#8220; bei der Durchsetzung seiner Richtlinien. Seit Juni 2017
setzt die Plattform L&#246;sungen des Maschinellen Lernens ein, um m&#246;glicherweise extremistische oder gewaltt&#228;tige
Inhalte zu kennzeichnen und zu veranlassen, dass sie manuell gepr&#252;ft werden. Nach ersten Erfolgen im Training 
wurden die Algorithmen auch zum Aufsp&#252;ren schwierig zu beurteilender Inhalte, die Hass verbreiten und zu 
Hetze aufrufen, verwendet.2057 YouTube macht deutlich, dass automatisierte Systeme aber nur bei einer klar
definierten Verletzungshandlung eingesetzt werden k&#246;nnen und auch da an Grenzen sto&#223;en: &#8222;Eine menschliche
Beurteilung in all ihren feinen Nuancen kann eine Maschine nicht leisten.&#8220;2058 Daher setzt YouTube nach eigenen
Angaben Tausende von Mitarbeitenden weltweit ein, die rund um die Uhr beanstandete Inhalte redaktionell
&#252;berpr&#252;fen. Im Berichtszeitraum ist ein sogenanntes NetzDG-Team mit 65 Mitgliedern den Beschwerden gem&#228;&#223; dem
NetzDG nachgegangen.
2053 &#167; 2 Absatz 2 Satz 2 NetzDG.
2054 Vgl. Wortprotokoll der 52. Sitzung des Ausschusses f&#252;r Recht und Verbraucherschutz vom 15. Mai 2019 unter https://www.bundes-
tag.de/resource/blob/657216/bfcc934dee12f691775e6362971875d8/wortprotokoll-data.pdf. Vgl. auch Anh&#246;rung zu Novellierung 
des NetzDG unter: https://www.bundestag.de/presse/hib/701412-701412 (zuletzt abgerufen am 9. Oktober 2020).
2055 Vgl. Bundesministerium der Justiz und f&#252;r Verbraucherschutz (2020): Netzwerkdurchsetzungsgesetz wird weiterentwickelt.
2056 Vgl. Google LLC (2020): Google Transparenzbericht. Entfernungen von Inhalten nach dem Netzwerkdurchsetzungsgesetz.
2057 Im 1. Quartal 2020 wurde gut die H&#228;lfte aller von einem Algorithmus gemeldeten Videos, die gegen die YouTube-internen
Richtlinien verstie&#223;en, redaktionell gel&#246;scht, bevor sie angesehen werden konnten. Vgl. Google LLC (2020): Google Transparenzbericht.
YouTube-Community-Richtlinien und ihre Anwendung.
2058 Google LLC (2020): Google Transparenzbericht. Entfernungen von Inhalten nach dem Netzwerkdurchsetzungsgesetz.
7.4.2.3 Beispiel Facebook
Das soziale Netzwerk Facebook hat nach eigenen Angaben weltweit monatlich knapp 2,5 Milliarden aktive
Nutzerinnen und Nutzer. Die Zahl der t&#228;glich aktiven in Europa wird mit 286 Millionen angegeben; der Anteil der
20- bis 29-J&#228;hrigen, die Facebook nutzen, liegt im Jahr 2020 in Deutschland bei 73 Prozent.2059 Im 4. Quartal
2019 belief sich der Werbeumsatz des Netzwerks in Europa auf gut 5 Milliarden US-Dollar.2060 Facebook
Deutschland hat in sogenannten Gemeinschaftsstandards festgelegt, was auf seinen Seiten zul&#228;ssig ist und was
nicht. Diese Standards sollen sowohl die freie Meinungs&#228;u&#223;erung sch&#252;tzen als auch die pers&#246;nliche Sicherheit
der Nutzer garantieren. Verboten sind demnach unter anderem Inhalte, die gewaltt&#228;tiges und kriminelles
Verhalten f&#246;rdern, die Minderj&#228;hrigen schaden und als Hassrede gelten. Wer Facebook nutzt, kann &#8211; ob registriert oder
nicht &#8211; mittels eines speziellen Meldeformulars Inhalte melden, die seiner Ansicht nach gegen Bestimmungen
des NetzDG versto&#223;en.2061 
Im 2. Halbjahr 2019 wurden Facebook 3 087 Beschwerden gegen Inhalte wegen des mutma&#223;lichen Versto&#223;es
gegen das NetzDG &#252;bermittelt. Diese werden sowohl hinsichtlich ihrer Konformit&#228;t mit den
Gemeinschaftsrichtlinien als auch mit dem NetzDG gepr&#252;ft. Am h&#228;ufigsten bezogen sich die Beschwerden auf Beleidigung (1 373),
&#252;ble Nachrede (1 237) und Verleumdung (1 099).2062 Diese konkreten Beschwerden zogen in 270 F&#228;llen (bei
Beleidigung), in 174 F&#228;llen (bei &#252;bler Nachrede) und in 151 F&#228;llen (bei Verleumdung) eine L&#246;schung
beziehungsweise Sperrung der Inhalte nach sich; die Quoten liegen zwischen 13 und 19 Prozent. 
Zur Bearbeitung dieser Beschwerden in Deutschland hat Facebook gemeinsam mit externen Dienstleistern ein
Team aus 125 Personen gebildet, die speziell zu Fragen des NetzDG geschult sind. Ihnen stehen dabei
Orientierungshilfen zur Verf&#252;gung, die von internen Juristinnen und Juristen erarbeitet wurden. Dar&#252;ber hinaus setzt
Facebook, ohne dies n&#228;her auszuf&#252;hren, auf Technologien wie &#8222;Maschinelles Lernen, Computer Vision und KI,
[um] unangemessene Inhalte noch schneller und in einem weitaus gr&#246;&#223;eren Umfang zu finden als es Menschen
je k&#246;nnten&#8220;.2063 Im internationalen Kontext haben Algorithmen des Konzerns im 3. Quartal 2019 nach eigenen
Angaben in weit gr&#246;&#223;eren Dimensionen Posts mit Hassrede entdeckt: 7 Millionen Inhalte wurden automatisch 
gel&#246;scht, was einer Steigerung von 60 Prozent zum vorangegangenen Quartal entspricht; 80 Prozent davon, bevor
sie &#252;berhaupt jemand hat sehen oder lesen k&#246;nnen. Facebook f&#252;hrt diese Steigerung auf eine verbesserte Leistung 
der Algorithmen zur&#252;ck.2064 Diese automatisch gel&#246;schten Inhalte verstie&#223;en gegen die hauseigenen
Gemeinschaftsstandards; bei mutma&#223;lichen Verst&#246;&#223;en gegen das NetzDG in Deutschland reagiert der Konzern selbst. 
7.4.2.4 Beispiel Twitter
Der Kurznachrichtendienst Twitter will mit seinen Twitter-Regeln nach eigener Aussage daf&#252;r sorgen, dass sich
alle Nutzerinnen und Nutzer sicher f&#252;hlen, ihre Ansichten frei zu &#228;u&#223;ern. Die Plattform hat sich im Zuge des
NetzDG eine &#8222;Richtlinie zu Hass sch&#252;rendem Verhalten&#8220; gegeben. Diese untersagt es, &#8222;Gewalt gegen andere
Personen [zu] f&#246;rdern, sie direkt an[zu]greifen oder ihnen [zu] drohen, wenn diese &#196;u&#223;erungen aufgrund von
Abstammung, ethnischer Zugeh&#246;rigkeit, nationaler Herkunft, sexueller Orientierung, Geschlecht,
Geschlechtsidentit&#228;t, religi&#246;ser Zugeh&#246;rigkeit, Alter, Behinderung oder ernster Krankheit erfolgen&#8220;2065. Gelangt Twitter zur
&#220;berzeugung, dass konkrete Accounts Gewaltandrohungen teilen oder verbreiten, werden diese gesperrt. Wer
Twitter nutzt, wird aufgerufen, m&#246;gliche Verst&#246;&#223;e geben die genannte Richtlinie zu melden; Gleiches gilt f&#252;r
vermutete Verst&#246;&#223;e gegen das NetzDG.
Insgesamt gingen bei Twitter Deutschland im 2. Halbjahr 2019 gut 842 000 Beschwerden sowohl gegen die
Twitter-Regeln als auch gegen das NetzDG ein, was einem Plus von 69 Prozent im Vergleich zum 1. Halbjahr
2019 entspricht.2066 Die weitaus meisten Beschwerden gingen ein wegen mutma&#223;licher Volksverhetzung (&#167; 130
StGB, 273 549 Meldungen), Beleidigung (&#167; 185 StGB, 174 665 Meldungen) und &#246;ffentlicher Aufforderung zu
Straftaten (&#167; 111 StGB, 134 284 Meldungen). Die Anzahl der daraufhin getroffenen Ma&#223;nahmen lag bei 15 596 
2059 Weitere Informationen dazu unter: https://de.statista.com/themen/138/facebook/ (zuletzt abgerufen am 1. September 2020).
2060 Vgl. Statista (2020): Werbeums&#228;tze von Facebook nach Regionen vom 1. Quartal 2013 bis zum 2. Quartal 2020 (in Millionen 
US-Dollar).
2061 Hier und im Folgenden vgl. Facebook (2020): NetzDG Transparenzbericht.
2062 Da in einer NetzDG-Beschwerde gegebenenfalls mehrere Begr&#252;ndungen der Rechtswidrigkeit angegeben werden, &#252;bersteigt die
Summe der mutma&#223;lichen Straftatbest&#228;nde jene der Beschwerden.
2063 Facebook (2020): Facebook ver&#246;ffentlicht vierten NetzDG-Transparenzbericht.
2064 Vgl. heise.de (2019): Facebook l&#246;scht 1,7 Milliarden Fake-Accounts und erkennt Hassposts automatisch.
2065 Twitter Inc. (2020): Richtlinie zu hasssch&#252;rendem Verhalten.
2066 Hier und im Folgenden vgl. Twitter Inc. (2020): Twitter Netzwerkdurchsetzungsgesetzbericht: Juli &#8211; Dezember 2019.
(Volksverhetzung), 10 254 (Beleidigung) und 76 594 (&#246;ffentliche Aufforderung zu Straftaten). Bei Twitter sind
mehr als 70 Personen damit besch&#228;ftigt, NetzDG-Beschwerden zu bearbeiten, zum Teil bei Twitter direkt
angestellt, zum Teil bei einem Dienstleister. Dieses Team ist vielsprachig besetzt, da nicht alle Inhalte, die nach dem
NetzDG gemeldet werden, in deutscher Sprache verfasst sind. Eine Vorsortierung der Beschwerden durch einen
Algorithmus wird im Bericht nicht erw&#228;hnt, ebenso wenig ein m&#246;glicher Filter, der Hassreden bereits beim
Verfassen eines Tweets zuverl&#228;ssig erkennt und dementsprechend blockiert. 
Eine linguistische Analyse von rund 50 000 Tweets mit rechtsextremer Hassrede,2067 denen die gleiche Anzahl
&#8222;sicherer&#8220; Tweets zu Vergleichszwecken gegen&#252;bergestellt wurde, kommt zum Ergebnis, dass gut 90 Prozent
der besonders aggressiven Inhalte durch ein daf&#252;r entwickeltes KI-System korrekt als von Menschen vorab
definierte Hassrede identifiziert werden konnten und noch 76 Prozent der milderen Inhalte.2068 Als Kernmechanismen
der Hassrede wurden die Entmenschlichung und die Stereotypisierung einzelner Personen oder Gruppen mit den
Mitteln der Sprache bestimmt. Dies geschieht mittels Substantiven mit tendenzi&#246;sem Signalcharakter, mit
verbundenen Adjektiven und Verben sowie mit der Suggestion eines verbrecherischen Zusammenhangs. Auch
Emojis, Abk&#252;rzungen, Ziffern, Majuskeln und geh&#228;ufte Satzzeichen k&#246;nnen vom Algorithmus als Verst&#228;rkung
sowohl des Sinns als auch der Lautst&#228;rke einer Aussage bis hin zum Schreien interpretiert werden. Weitere
Elemente einer Hassrede k&#246;nnen der Analyse zufolge kreativ modifizierte Metaphern, Neologismen oder
Umformulierungen bekannter Zitate sein &#8211; diese Stilmittel &#252;bersteigen allerdings das Verm&#246;gen eines KI-Systems zum 
Aufsp&#252;ren entsprechender Inhalte.
7.4.2.5 Technische Perspektive auf das automatische Auffinden
Beleidigungen, Hassrede etc. lassen sich h&#228;ufig nicht am Vorkommen bestimmter und bekannter Signalw&#246;rter
oder -phrasen festmachen. Eine wesentliche Rolle spielt zudem der Kontext der &#196;u&#223;erung, etwa der Grad der
Herabsetzung oder die Tragweite der &#196;u&#223;erung. Hinzu kommt die zeitliche Dynamik, in der neue Begriffe
entstehen oder andere umgedeutet werden wie &#8222;Nafri&#8220;. Aus technischer Perspektive ist es daher kaum denkbar, zum
Auffinden von Hassrede ein &#8222;symbolisches Regelwerk&#8220; zu entwickeln. Damit bliebe als technische L&#246;sung nur
Maschinelles Lernen auf Basis von Daten.
Typische Mittel in der Entwicklung von Sprachtechnologie bei &#228;hnlichen Herausforderungen (z. B.
Dokumentklassifikation, Emotionserkennung etc.) sind Wettbewerbe (Challenges, Shared Tasks), die entweder von
&#246;ffentlichen Institutionen wie etwa der DARPA in den USA oder auch von Fachverb&#228;nden oder einzelnen Institutionen
ausgerichtet werden. Das Muster hierbei ist immer &#228;hnlich. Die Veranstalter stellen annotierte Trainingsdaten
zur Verf&#252;gung, auf deren Basis die Teilnehmenden dann in einem vorgegebenen Zeitrahmen ihre Systeme
entwickeln. An einem Stichtag werden dann Testdaten ver&#246;ffentlicht, die von den Teilnehmenden mit ihren
Systemen analysiert werden. Die Ergebnisse m&#252;ssen daraufhin innerhalb eines kurzen Zeitfensters (damit manuelle
Bearbeitung nicht m&#246;glich ist) an die Organisatoren in einem bestimmten Format geschickt werden. Daraufhin 
erfolgen dann Auswertungen, Rankings, Publikationen und h&#228;ufig ein Workshop oder &#196;hnliches.
Voraussetzungen f&#252;r solche Wettbewerbe sind:
1. ein Kategoriensystem (&#8222;Annotationsschema&#8220;) zum Labeln der Daten
2. hinreichende &#220;bereinstimmung der Annotatoren (Goldstandard, Ground Truth)
3. gen&#252;gend viele annotierte Daten
F&#252;r die englische Sprache gab es in der Vergangenheit verschiedene Wettbewerbe zur Erkennung von Hassrede.
F&#252;r die deutsche Sprache war die GermEval Shared Task on the Identification of Offensive Language&#8220; aus dem
Jahr 2018 der erste gr&#246;&#223;ere Wettbewerb.2069 Als Trainingsdaten wurden ca. 5 000 Tweets in zwei Stufen
annotiert. Die erste Stufe gibt bin&#228;r an, ob es sich um beleidigende Sprache handelt. Wenn ja, wurde der Typ der
Beleidigung annotiert (INSULT, ABUSE, PROFANITY und OTHER). Die Kategorien stammen von den
Ausrichtern und sind dokumentiert. Als Testset wurden weitere 3 000 Tweets herangezogen.
2067 Eine analoge Analyse zu linksextremer oder islamistischer Hassrede konnte nicht recherchiert werden.
2068 Vgl. Jaki und Smedt (2018): Right-wing German Hate Speech on Twitter: Analysis and Automatic Detection, Untersuchungszeitraum
August 2017 bis April 2018.
2069 Vgl. Ruppenhofer et al. (2018): Proceedings of the GermEval 2018 Workshop.
Der Wettbewerb ist ein erster Schritt, allerdings ist es schwer, die f&#252;r eine bestimmte Aufgabe n&#246;tige Datenmenge 
im Vorfeld zu bestimmen, so ist die hier annotierte Datenmenge (die Kategorie INSULT, also pers&#246;nliche
Beleidigung, kam in den Trainingsdaten beispielsweise nur 141-mal vor) in jedem Fall viel zu gering, als dass man
aus den Ergebnissen Einsichten &#252;ber die potenzielle G&#252;te von Hassrede-Filtern ableiten k&#246;nnte. Die Ground
Truth, also das verwendete Kategoriensystem mit den menschlichen Annotationen, stellt einen Ansatz dar, der
sicher noch ausgebaut werden muss. 
7.4.2.5.1 Handlungsempfehlungen 
Gegenw&#228;rtig sind automatische Filter zum Erkennen und Aussortieren von Hassrede noch nicht zuverl&#228;ssig
einsetzbar,2070 gerade wenn Grenzf&#228;lle (Ironie, Anspielung, &#220;bertreibung, Spott, Parodie, Zitat) betroffen sind, die
beurteilt werden m&#252;ssen.
Hingewiesen wird unter anderem auf Schw&#228;chen der KI-Systeme beim Verstehen und Auswerten von
Zusammenh&#228;ngen.2071 Daher sollte die Forschung in diesem Bereich forciert und es sollte bei einem potenziellen Einsatz
von Filtern darauf geachtet werden, dass dabei nicht die Meinungsfreiheit beschnitten wird, die Filter also
f&#228;lschlicherweise einwandfreie Kommentare indexieren oder gar automatisch blockieren. Eine Vorfilterung ist bereits
technisch machbar, die Trefferquote sollte nach und nach verbessert werden.
7.4.3 Weitere Anwendungen 
Neben den beiden hier im Detail beschriebenen Anwendungsbereichen werden KI-basierte Systeme zur
Erkennung zahlreicher anderer Kategorien unerw&#252;nschter Inhalte angewendet oder ihre Anwendung ist denkbar. Dabei
kann es sich etwa um verschiedene Formen strafbarer Inhalte, um pornografische oder anderweitig
jugendschutzrechtlich relevante Inhalte oder um Inhalte, deren Verbreitung eine Pers&#246;nlichkeitsrechtsverletzung darstellen
w&#252;rde, handeln. Derzeit wird insbesondere auf europ&#228;ischer Ebene im Rahmen der Verhandlungen &#252;ber die
Verordnung zur Verhinderung der Verbreitung terroristischer Online-Inhalte (&#8222;TERREG&#8220;) diskutiert, inwieweit
automatisierte Verfahren zur Erkennung solcher Inhalte darin vorgesehen sein sollen.
F&#252;r alle diese Einsatzm&#246;glichkeiten gelten vergleichbare Beschr&#228;nkungen wie in den oben n&#228;her untersuchten
Bereichen: Jede Klassifizierungsaufgabe, die ein Verst&#228;ndnis f&#252;r den Kontext von &#196;u&#223;erungen voraussetzt oder
nicht-triviale rechtliche Einordnungen beinhaltet, &#252;bersteigt die F&#228;higkeiten der daf&#252;r einsetzbaren Technologie.
Grunds&#228;tzlich denkbar sind der Einsatz zur Vorsortierung von Verdachtsf&#228;llen vor einer menschlichen Pr&#252;fung
in solchen F&#228;llen und der Einsatz als automatisierter Filter in F&#228;llen, in denen die Verbreitung eines spezifischen
Inhalts unabh&#228;ngig von jedem denkbaren Kontext unterbunden werden soll.
7.4.3.1 Handlungsempfehlungen
Der unkontrollierte Einsatz von Uploadfiltern sollte weitestm&#246;glich ausgeschlossen werden, wenn es um
kontextabh&#228;ngige oder rechtlich nicht-triviale Einsch&#228;tzungen geht. Das steht einer Verwendung von KI-basierten
Filtersystemen zur Vorsortierung im Vorfeld einer menschlichen Pr&#252;fung nicht entgegen. Eine Verbesserung
derzeit eingesetzter Systeme und eine regulatorische Begleitung ihres Einsatzes erscheinen vor diesem
Hintergrund w&#252;nschenswert, wobei eine Automatisierung der Rechtsdurchsetzung in jedem Fall zu vermeiden ist.
Eine automatisierte L&#246;schung bzw. Nichtver&#246;ffentlichung sollte beim derzeitigen und zu erwartenden Stand der
Technik auf F&#228;lle begrenzt sein, in denen die Verbreitung spezifischer Inhalte unabh&#228;ngig von jedem denkbaren
Kontext unterbunden werden soll, etwa im Fall dokumentierten Kindesmissbrauchs.
2070 Pr&#228;sentation von Dr. Aljoscha Burchardt (sachverst&#228;ndiges Mitglied der Enquete-Kommission KI), Projektgruppendrucksache
19(27)PG 6-14 vom 13. Dezember 2019.
2071 Algorithmen seien nicht geeignet f&#252;r das Aufsp&#252;ren von Hassreden, weil sie im Verstehen und Auswerten von Zusammenh&#228;ngen 
gravierende Schw&#228;chen h&#228;tten, so der UN-Sonderberichterstatter zur Meinungsfreiheit David Kaye, vgl. Hamich (2019): UN-Bericht
zu Hate Speech &#8211; Staaten sollten regulieren, nicht Unternehmen.
        
 
 
  
  
     
     
      
    
        
    
       
 
    
      
   
   
 
  
       
    
  
 
    
 
 
 
     
 
 
        
 
 
  
         
 
 
  
   
   
       
 
                                               
    
      
       
  
     
           
         
         
       
        
1
D. Sondervoten zum Gesamtbericht
Sondervoten der CDU/CSU-Fraktion
Sondervotum zu Kapitel 1 der Kurzfassung des Berichts (&#8222;Daten&#8220;) sowie Kapitel 5.7 
des Mantelberichts (&#8222;KI und Recht &#8211; Handlungsempfehlungen&#8220;) des
sachverst&#228;ndigen Mitglieds Dr. Sebastian Wieczorek und der Abgeordneten Marc Biadacz,
Hansj&#246;rg Durz, Ronja Kemmer, Jan Metzler, Stefan Sauer, Prof. Dr. Claudia
Schmidtke, Andreas Steier und Nadine Sch&#246;n sowie der sachverst&#228;ndigen Mitglieder
Susanne Dehmel, Prof. Dr. Wolfgang Ecker, Prof. Dr. Alexander Filipovi&#263;, 
Prof. Dr. Antonio Kr&#252;ger und Prof. Dr. J&#246;rg M&#252;ller-Lietzkow
Es ist eine zentrale Erkenntnis der Enquete-Kommission, dass sich die Datenverf&#252;gbarkeit f&#252;r Wirtschaft,
Wissenschaft und Gesellschaft verbessern muss. Dies ist insbesondere notwendig, um datengetriebene Innovationen
zu erm&#246;glichen. Das Wesen von Innovationen ist es generell, dass bestehende Faktoren auf eine urspr&#252;nglich
nicht vorgesehene Art und Weise kombiniert werden.2072 Experimente sind dabei die Grundlage f&#252;r einen
Lernvorgang, welcher letztendlich zu Innovationen f&#252;hrt.2073 Dies gilt insbesondere f&#252;r Innovationsprozesse in Bezug
auf KI-Systeme, die eine Vielzahl von Experimenten voraussetzen.2074 
Die Nutzung von personenbezogenen Daten f&#252;r datenbasierte Innovationen steht grunds&#228;tzlich nicht im
Widerspruch zu dem von der DSGVO f&#252;r jede nat&#252;rliche Person gew&#228;hrleisteten &#8222;Recht auf Schutz der sie betreffenden
personenbezogenen Daten&#8220;.2075 Die Durchsetzung dieses Rechts durch die DSGVO basiert dabei unter anderem
auf den Grundprinzipien der Datensparsamkeit und der Zweckgebundenheit. Diese schr&#228;nken allerdings sowohl
die Verf&#252;gbarkeit als auch Nutzung von personenbezogenen Daten f&#252;r datengetriebene Innovationen stark ein. 
Das in der Handlungsempfehlung geforderte Festhalten an der bisherigen &#8222;durch die DSGVO erreichten Balance
zwischen Datenschutz und Innovation&#8220;2076 ist deshalb problematisch, weil sie datengetriebene Innovationen
gerade in dem f&#252;r unsere Gesellschaft sensiblen aber wichtigen Bereich der personenbezogenen Daten
erschwert.2077 Es ist deshalb zu erwarten, dass diese Innovationen in Zukunft vordergr&#252;ndig durch nicht-
europ&#228;ische Akteure auf den Markt gebracht werden, bei denen nicht immer klar sein wird, ob sie den durch die DSGVO
intendierten Schutz gew&#228;hrleisten k&#246;nnen und wollen.
Im Weiteren wird dargelegt, warum und wie die DSGVO durch ein alternatives Prinzip der Datensorgfalt2078 
innovationsfreundlicher gestaltet werden k&#246;nnte, ohne dabei den Schutz personenbezogener Daten zu
vernachl&#228;ssigen.
Jeder Datensatz kann personenbezogen sein
&#8222;Ein Datensatz gilt [als] nicht-personenbezogen, wenn es kein bekanntes Verfahren gibt, aus diesem
personenbezogene Informationen zu gewinnen. Damit birgt jeder nicht-personenbezogene Datensatz das latente Risiko, 
durch neue technische Verfahren, innovative Nutzung bestehender Verfahren oder durch Kombination mit
weiteren Informationen personenbezogen zu werden.&#8220;2079 Dies wurde unter anderem eindrucksvoll durch die
Analyse von Meta-Daten durch David Kriesel (Anh&#246;rperson der Projektgruppe KI und Wirtschaft)2080 belegt. Als
Konsequenz sehen sich Unternehmen vielfach gezwungen, die anspruchsvollen und aufwandsintensiven Regeln
der DSGVO auch f&#252;r nicht-personenbezogene Daten umzusetzen oder entsprechende Datens&#228;tze gem&#228;&#223; des 
DSGVO-Prinzips der Datenminimierung zu l&#246;schen, auch wenn der Gesetzgeber dies explizit anders intendiert
hat. Dort hei&#223;t es: &#8222;Die Grunds&#228;tze des Datenschutzes sollten daher nicht f&#252;r anonyme Informationen gelten, d.h.
f&#252;r Informationen, die sich nicht auf eine identifizierte oder identifizierbare nat&#252;rliche Person beziehen, oder
personenbezogene Daten, die in einer Weise anonymisiert worden sind, dass die betroffene Person nicht oder
nicht mehr identifiziert werden kann.&#8220;
2072 Vgl. Schumpeter (2013): Theorie der wirtschaftlichen Entwicklung.
2073 Vgl. Meyerhoff (2016): Evolutions&#246;konomik.
2074 Siehe auch Kapitel 1.2 des Mantelberichts [Training von lernenden KI-Systemen].
2075 Vgl. Verordnung (EU) 2016/679, abrufbar unter: https://eur-lex.europa.eu/legal-content/de/TXT/?uri=CELEX%3A32016R0679 
(zuletzt abgerufen am 16. Oktober 2020).
2076 Siehe dazu Mantelbericht, KI und Recht, Kapitel 5.7, Handlungsempfehlungen, und Kurzfassung, Kapitel 2.
2077 Vgl. Kr&#246;smann und Wei&#223; (2020): Jedes 2. Unternehmen verzichtet aus Datenschutzgr&#252;nden auf Innovationen.
2078 Vgl. Positionspapier der CDU/CSU-Fraktion im Deutschen Bundestag (2020): Datenstrategie der Bundesregierung.
2079 Siehe auch Kapitel 2.5 des Mantelberichts [Personenbezogene Daten].
2080 Eine gute Zusammenfassung und weiterf&#252;hrende Links finden sich unter Stein (2017): Big Data: Gefahren f&#252;r Journalisten.
Innovationen basierend auf personenbezogenen Daten
In der Praxis ist es oft unerheblich, ob die f&#252;r datengetriebene Innovationen genutzten Daten einen Personenbezug
herstellen k&#246;nnen oder nicht, weil die personenbezogenen Informationen nicht verwendet werden, um in der
Anwendung einen konkreten Bezug herzustellen.
Folgendes Beispiel soll dies illustrieren: Ein Unternehmen m&#246;chte ein KI-System entwickeln, das in der Lage
ist, den Verschlei&#223; von Bauteilen in Produktionsanlagen vorherzusagen, um darauf basierend Wartungsarbeiten
zu koordinieren. Der daf&#252;r ben&#246;tigte Datensatz basiert auf mit Zeitstempeln versehenen Sensordaten der
Maschinen. Diese m&#252;ssen oft als personenbezogen angesehen werden, weil sich daraus auch Effizienzkennzahlen wie
beispielsweise die L&#228;nge von Arbeitspausen der an den Maschinen Arbeitenden ableiten lassen. F&#252;r das Training 
des KI-Systems sind diese personenbezogenen Informationen allerdings irrelevant. Das trainierte KI-System 
selbst wird keine R&#252;ckschl&#252;sse auf die im Trainingsdatensatz enthaltene personenbezogene Information zulassen. 
Auch w&#228;hrend des Betriebs der Produktionsanlagen wird das trainierte KI-System die beschriebenen Sensordaten
zwar weiterverarbeiten, die enthaltenen personenbezogenen Informationen dabei allerdings nicht nutzen. Ein
Risiko f&#252;r die Rechte und Freiheiten der Personen, mit denen die verwendeten Daten rein theoretisch verkn&#252;pft
werden k&#246;nnten, besteht im Rahmen der beschriebenen Verarbeitung nicht.
Datenminimierung und Zweckgebundenheit verhindern Innovationen
Wie aus dem Beispiel ersichtlich, ist es in vielen F&#228;llen notwendig, personenbezogene Daten zu verwenden, um
innovative Anwendungen zu entwickeln, ohne dass der Personenbezug f&#252;r die Anwendung eine Rolle spielt. Die
durch die DSGVO definierten Grunds&#228;tze der Datenminimierung und Zweckgebundenheit stehen der
Entwicklung von Innovationen und den daf&#252;r notwendigen Voraussetzungen teilweise entgegen. 
Die Datenminimierung zielt darauf ab, den Umfang der verarbeiteten Daten so weit wie m&#246;glich zu beschr&#228;nken.
Die Menge und Art der Daten soll die f&#252;r den Zweck notwendige Verarbeitung erm&#246;glichen, aber nicht dar&#252;ber
hinausgehen. Dazu muss genau &#252;berlegt werden, welche Daten wirklich gebraucht werden, um den formulierten
Zweck zu erf&#252;llen. Daten zu erheben, die direkt daf&#252;r nicht erforderlich sind, aber sp&#228;ter m&#246;glicherweise f&#252;r das
Unternehmen von Nutzen sein k&#246;nnen, ist somit nicht erlaubt.
F&#252;r eine Zweckbindung muss der Zweck offensichtlich bekannt sein, um die Verwendung der Daten an diesen 
zu binden. Werden Daten im Innovationsprozess eingesetzt, ist dieser jedoch gerade davon gekennzeichnet, dass
man nicht im Vorhinein wei&#223;, wozu die Daten verwendet werden. Kern von Trial-and-Error ist das Ausprobieren
von Ideen. Daten werden am Ende eines Innovationsprozesses m&#246;glicherweise in ganz anderer Weise verwendet,
als dies urspr&#252;nglich gedacht war. Es kann verhindern, sich grundlegend in Frage zu stellen und m&#246;glicherweise
seine urspr&#252;ngliche Idee zu verwerfen, da bereits die Datengrundlage darauf ausgerichtet ist. 
Datensorgfalt als alternatives Prinzip der DSGVO
Wie beschrieben, schr&#228;nkt die durch die DSGVO geforderte Datenminimierung und Zweckbindung den
kreativen Freiraum in Innovationsprozessen erheblich ein und verhindert damit auch solche Innovationen, die zwar auf
personenbezogenen Daten basieren, die enthaltenen personenbezogenen Informationen aber nicht nutzen. Dies
bedeutet nicht, dass diese Innovationen dadurch verhindert werden. Sie werden allerdings in der Mehrheit nicht
im Geltungsbereich der DSGVO gemacht werden. Da f&#252;r die Anwendung der innovativen L&#246;sungen der Zweck
wiederum bekannt ist, k&#246;nnen diese ohne gro&#223;e Einschr&#228;nkungen auch innerhalb der EU angeboten und genutzt
werden. Es ist allerdings sehr bedenklich, dass Europa gerade bei Innovationen, die in einem gesellschaftlich so
sensiblen Bereich erfolgen, lediglich ein Konsument ist, w&#228;hrend die Entwicklung in L&#228;ndern mit teils erheblich
anderen Rechtsvorschriften und Moralvorstellungen in Bezug auf informationelle Selbstbestimmung stattfindet.
Aus diesem Grund sollte die DSGVO auf europ&#228;ischer Ebene nachgesch&#228;rft werden, um auf der einen Seite den
Schutz personenbezogener Daten weiter zu gew&#228;hrleisten, gleichzeitig aber Innovationen, die nicht auf der
Nutzung dieser personenbezogenen Informationen beruhen, zu erm&#246;glichen. Dies kann erreicht werden, wenn das
Prinzip der Datensorgfalt, also ein gewissenhafter Umgang mit personenbezogenen Daten, an die Stelle von
Datenminimierung und eine zu engen Zweckbindung tritt. Somit w&#252;rde das Prinzip der Datensorgfalt den
notwendigen Freiraum f&#252;r Innovationen nach europ&#228;ischen DSGVO-Grunds&#228;tzen geben, indem es nicht mehr per se das
Erfassen potenziell personenbezogener Daten einschr&#228;nkt, sondern deren Nutzung in der Anwendung. Mit Blick
auf die F&#246;rderung von KI-Forschung und -Entwicklung sollte erwogen werden, eine Art Experimentierklausel
einzuf&#252;hren, so dass Daten zu Zwecken der Forschung und Entwicklung von Anwendungen in der Praxis erhoben
und weiter genutzt werden k&#246;nnen, wenn dies den &#252;berwiegenden Interessen der Betroffenen nicht entgegensteht.
Dies folgt der &#220;berzeugung, dass der durch die DSGVO intendierte Schutz personenbezogener Daten nicht
vordergr&#252;ndig dadurch erreicht werden sollte, dass deren Existenz verhindert wird, sondern dass die Nutzung
personenbezogener Informationen in Innovationsprozessen durch entsprechende Sorgfaltsma&#223;st&#228;be reguliert wird.
Die in der DSGVO verankerten Transparenz- und Sorgfaltspflichten f&#252;r personenbezogene Daten realisieren 
schon heute im Grundsatz die Nachvollziehbarkeit und somit die &#220;berpr&#252;fbarkeit von Innovationst&#228;tigkeiten mit
personenbezogenen Daten.
Sondervotum zu Kapitel 6 der Kurzfassung des Berichts (&#8222;Mensch und Gesellschaft&#8220;)
sowie Kapitel 4.2.6 des Berichts der Projektgruppe 6 &#8222;KI und Medien&#8220;
(&#8222;Medienm&#228;rkte und KI &#8211; Handlungsempfehlungen&#8220;) der Abgeordneten Ronja Kemmer und
der Abgeordneten Marc Biadacz, Hansj&#246;rg Durz, Jan Metzler, Stefan Sauer, Andreas 
Steier, Prof. Dr. Claudia Schmidtke und Nadine Sch&#246;n sowie der sachverst&#228;ndigen
Mitglieder Susanne Dehmel, Prof. Dr. Wolfgang Ecker, Prof. Dr. Antonio Kr&#252;ger und 
Dr. Sebastian Wieczorek 
Im Bericht wird gefordert: &#8222;Will man die Medienvielfalt erhalten, bleibt aus dieser Perspektive als sinnvolles
Instrument &#8211; neben der Anwendung des Kartellrechts &#8211; die Einf&#252;hrung einer Digitalsteuer auf die basierten
Dienste der Plattform- und Social-Media-Anbieter, die dadurch &#252;berproportional an den  Werbem&#228;rkten
teilhaben.&#8220;
Die CDU/CSU-Bundestagsfraktion spricht sich bez&#252;glich der Digitalsteuer, die vor allem US-amerikanische 
Technologie-Konzerne wie Amazon oder Google treffen soll, weil sie nach Ansicht von Kritikern zu wenig
Abgaben in einzelnen M&#228;rkten bezahlen, gegen einen nationalen Alleingang2081 oder einen einseitigen europ&#228;ischen 
Weg2082 aus, welche das Ziel und den Zweck einer globalen Einigung verfehlen w&#252;rden. Es ist zu bef&#252;rchten, 
dass eine Digitalsteuer auch deutsche Unternehmen treffen und ihre im internationalen Vergleich bereits hohe
Steuerlast zus&#228;tzlich erh&#246;hen w&#252;rde. Insoweit tr&#228;gt eine unilateral eingef&#252;hrte Digitalsteuer nicht zu mehr
Wettbewerbsgleichheit bei. 
Die CDU/CSU-Bundestagsfraktion setzt weiter auf eine Einigung auf Ebene der Organisation f&#252;r wirtschaftliche
Zusammenarbeit und Entwicklung (OECD), die im Rahmen ihres Mandats f&#252;r die &#8222;task force on digital
economy&#8220; (&#8222;TFDE&#8220;) bereits verschiedene L&#246;sungsans&#228;tze vorgelegt hat und einen Kompromiss unter den 137
L&#228;ndern inklusive der USA herbeif&#252;hren soll.2083 
Aktuelle Vorschl&#228;ge sehen vor, multinationale Konzerne auch in L&#228;ndern zu besteuern, in denen sie keine
physische Pr&#228;senz haben (Marktlandprinzip). Zudem ist ein globaler Mindeststeuersatz geplant. In diesem
Zusammenhang ist darauf hinzuweisen, dass es Mindeststeuern auf bestimmte Auslandsgewinne bereits in vielen
L&#228;ndern gibt, auch in Deutschland. Die Verlagerung der Besteuerungsrechte in Marktstaaten hingegen w&#252;rde v&#246;llig 
neue Spielregeln erfordern. Deutschland w&#252;rde als Export&#252;berschussland durch die Verlagerung der Besteuerung 
in die Marktl&#228;nder Steuereinnahmen verlieren. Ein international koordiniertes Vorgehen sowohl gegen
Nichtbesteuerung als auch gegen Doppelbesteuerung w&#228;re ein Fortschritt; bislang geschieht das aber meistens nur
unilateral, was zum Teil Nachteile wie Steuerchaos, Doppelbesteuerung und eine Diskriminierung von
grenz&#252;berschreitenden Investitionen bewirkt. Da die USA die Digitalsteuer derzeit als Importzoll interpretieren, sollte die
Einf&#252;hrung einer deutschen oder europ&#228;ischen Digitalsteuer vermieden werden, um weitere Eskalationen im
Handelskonflikt und daraus resultierende Verluste f&#252;r die Wirtschaft und den Fiskus zu vermeiden.2084 
Insofern schlie&#223;t sich die CDU/CSU-Bundestagsfraktion der pauschalen Forderung, die aus der Projektgruppe
&#8222;KI und Medien&#8220; eingebracht wurde, nicht an und empfiehlt stattdessen aus steuer- wie medienpolitischer Sicht
eine differenzierte Abw&#228;gung. Es wird u. a. empfohlen, der Entstehung von unerw&#252;nschter Marktmacht mit
wettbewerbspolitischen Eingriffen zu begegnen, wie sie bereits mit der aktuellen GWB-Novelle adressiert werden,
sowie das Angebot an Wirtschaftsinitiativen und F&#246;rderprogrammen zu nutzen, um Medienvielfalt zu f&#246;rdern. 
2081 Frankreich hat im Sommer 2019 die Einf&#252;hrung einer nationalen Digitalsteuer beschlossen. Auch Spanien, &#214;sterreich und Italien
haben nationale Vorst&#246;&#223;e vorgenommen. Diese neuen Steuern wirken allerdings &#228;hnlich wie Z&#246;lle, und die US-Regierung hat bereits
angek&#252;ndigt, Gegenma&#223;nahmen einzuleiten.
2082 Vgl. DPA (2020): Digitalsteuer: EU-Kommission will 2021 notfalls eigenen Plan vorlegen.
2083 Vgl. OECD (2020): Statement by the OECD/G20 Inclusive Framework on BEPS on the Two-Pillar Approach to Address the Tax
Challenges Arising from the Digitalisation of the Economy.
2084 Zu den &#246;konomischen und fiskalischen Auswirkungen der EU-Digitalsteuer; vgl. Fuest et al. (2018): Die Besteuerung der
Digitalwirtschaft.
Sondervotum zu Kapitel 9.4.1 des Mantelberichts (&#8222;Welche St&#228;rken hat die KI-
Forschung in Deutschland?&#8220;) des sachverst&#228;ndigen Mitglieds Dr. Sebastian
Wieczorek und der Abgeordneten Marc Biadacz, Hansj&#246;rg Durz und Prof. Dr. Claudia
Schmidtke sowie der sachverst&#228;ndigen Mitglieder Prof. Dr. Wolfgang Ecker und 
Prof. Dr. Alexander Filipovi&#263;
In der SWOT-Analyse zu KI-Forschung wird Deutschland attestiert, in der Breite gut aufgestellt zu sein.2085 
&#196;hnlich argumentiert auch die Strategie K&#252;nstliche Intelligenz der Bundesregierung2086, in der es hei&#223;t:
&#8222;Forschung und Innovation sind die Grundlagen f&#252;r die KI-Technologien der Zukunft. Hier hat Deutschland mit 
seiner breiten und exzellenten Forschungslandschaft eine sehr gute Ausgangslage.&#8220;
Basierend auf den Zahlen, die nachfolgend dargelegt werden, erscheint diese Analyse nicht haltbar. Vielmehr
wird ersichtlich, dass die Deutsche KI-Forschung im internationalen Vergleich &#8211; bezogen auf Menge und
Relevanz &#8211; keine Spitzenposition einnimmt. Aus diesem Grund muss Deutschland, auch in Relation zu seiner
Wirtschaftskraft, deutlich mehr Anstrengungen unternehmen, um die existierende KI-Forschung weiter auszubauen.
Dies gilt sowohl in der Breite als auch f&#252;r die F&#246;rderung von Spitzenforschung. Der Wissenstransfer in die
Wirtschaft kann hingegen als gro&#223;e St&#228;rke der deutschen KI-Forschung angesehen werden, so dass bei
entsprechenden Investitionen in die Forschung auch ein positiver Effekt f&#252;r die Wettbewerbsf&#228;higkeit der deutschen
Wirtschaft zu erwarten ist.
Breite der Deutschen KI-Forschung im Vergleich
Es ist mittlerweile vielfach belegt, dass China und die USA die KI-Forschung dominieren.2087 Dies l&#228;sst sich zum
Beispiel an der Zahl ver&#246;ffentlichter Beitr&#228;ge zum Thema KI in Forschungsjournalen ablesen. In absoluten
Zahlen belegt Deutschland hier den f&#252;nften Platz, ist aber weit entfernt davon, den beiden f&#252;hrenden Nationen
Konkurrenz zu machen, die jeweils sechsmal so viele Publikationen vorweisen k&#246;nnen.2088 Die verglichenen L&#228;nder
unterscheiden sich allerdings in Gr&#246;&#223;e und Wirtschaftskraft deutlich. Um die Breite der KI-Forschung besser
vergleichen zu k&#246;nnen, sollte die Zahl der Ver&#246;ffentlichungen in Relation zum Bruttoinlandsprodukt2089 gestellt
werden (Abbildung 20). Dabei wird klar, dass Deutschland in beiden Kategorien, gemessen an seiner
Wirtschaftsleistung, den meisten anderen Nationen deutlich hinterherhinkt. Dies gilt sowohl in Bezug auf aufstrebende
Industrienationen wie China und Indien, als auch bez&#252;glich europ&#228;ischer Staaten wie Gro&#223;britannien, Spanien,
Polen und Finnland, die in Relation zu ihrem Bruttoinlandsprodukt doppelt so erfolgreich publizieren. 
Aufgrund des gro&#223;en Abstands zu den f&#252;hrenden Nationen in der KI-Forschung &#8211; sowohl in absoluten als auch
in relativen Zahlen &#8211; l&#228;sst sich deshalb bez&#252;glich der Breite der Forschung eine &#8222;sehr gute Ausgangslage&#8220; nicht
feststellen.
2085 Siehe dazu Kapitel 9.4.1 des Mantelberichts [Welche St&#228;rken hat die KI-Forschung in Deutschland?].
2086 Vgl. Bundesregierung (2018): Strategie K&#252;nstliche Intelligenz der Bundesregierung.
2087 Vgl. Perrault et al. (2019): The AI Index 2019 Annual Report.
2088 Vgl. Perrault et al. (2019): The AI Index 2019 Annual Report; Microsoft Academic Graph Data set ist abrufbar unter:
https://www.microsoft.com/en-us/research/project/microsoft-academic-graph/, Dokumente abrufbar unter
https://drive.google.com/drive/folders/11xq2h6sk-vLuMODLbK_Fw90o7ZxrSIr4 (zuletzt abgerufen am 21. Oktober 2020).
2089 Vgl. Gross Domestic Product Data, weitere Informationen dazu unter World Bank Open Data: https://data.worldbank.org/ (zuletzt 
abgerufen am 16. Oktober 2020).
Abbildung 20
KI-Beitr&#228;ge zu Forschungsjournalen in den Jahren 2015 bis 2018 in Relation zum
Bruttoinlandsprodukt 2017
Relevanz der Deutschen KI-Forschung im Vergleich
Um die Relevanz einer Forschungspublikation zu beurteilen, betrachtet man &#252;blicherweise, wie oft andere
Wissenschaftlerinnen und Wissenschaftler in ihren Publikationen darauf Bezug nehmen. Allerdings variiert die
Anzahl von Zitierungen je nach Fachgebiet stark. Um den Publikationserfolg besser vergleichen zu k&#246;nnen, bietet
sich der Field-Weighted Citation Index (FWCI) an, der die Anzahl seiner Zitierungen einer Publikation in Bezug
zur durchschnittlichen Anzahl Zitierungen in diesem Fachgebiet ausgibt. Ein FWCI gr&#246;&#223;er 1 bedeutet
dementsprechend, dass eine Publikation &#252;berdurchschnittlich oft zitiert wurde. Wie in Abbildung212090, ersichtlich,
werden deutsche Forschungspublikationen &#252;berdurchschnittlich oft zitiert. Allerdings ist zu sehen, dass Deutschland
im europ&#228;ischen Vergleich keine Spitzenposition einnimmt. Dar&#252;ber hinaus erreichen mit den USA und
Gro&#223;britannien auch solche L&#228;nder eine h&#246;here Relevanz, die in absoluten Zahlen mehr KI-Publikationen haben als
Deutschland. 
Aufgrund dieser Zahlen l&#228;sst sich auch bez&#252;glich der Exzellenz der deutschen KI-Forschung eine &#8222;sehr gute
Ausgangslage&#8220; nicht feststellen.
2090 Vgl. Perrault et al. (2019): The AI Index 2019 Annual Report sowie Field-Weighted Citation Index Data, abrufbar unter:
https://drive.google.com/drive/folders/1_NTWwz81qHZEGbUJ_0Oks6C23Oy4UPoo (zuletzt abgerufen am 16. Oktober 2020).
Abbildung 21
Field-Weighted Citation Index der KI-Publikationen in den Jahren 2014 bis 2018
Wissenstransfer von KI-Forschung in die Wirtschaft
Ein guter Indikator f&#252;r die Effizienz des Wissenstransfers von KI-Forschung in die Wirtschaft ist die Anzahl
gemeinsamer KI-Forschungspublikationen von akademischen und industriellen Autorinnen und Autoren. Wie zu
erwarten, dominieren auch hier die USA und China in absoluten Zahlen2091, allerdings ist Deutschland hier relativ
zu seiner Wirtschaftsleistung2092 gut aufgestellt und belegt unter den zehn Nationen mit den meisten
Industriekollaborationen einem hervorragenden zweiten Platz hinter Gro&#223;britannien (siehe Abbildung 22). Auf dieser
Position sollte aufgebaut, Erkenntnis geschaffen und diese Erkenntnis in eine Anwendung gebracht werden.
2091 Vgl. Perrault et al. (2019): The AI Index 2019 Annual Report; Academic-Corporate Collaboration Data, Elsevier Scopus, abrufbar
unter: https://drive.google.com/drive/folders/1_NTWwz81qHZEGbUJ_0Oks6C23Oy4UPoo (zuletzt abgerufen am 16. Oktober
2020).
2092 Vgl. Gross Domestic Product Data, abrufbar unter World Bank Open Data: https://data.worldbank.org/ (zuletzt abgerufen am 16.
Oktober 2020).
Abbildung 22
Anzahl von KI-Forschungspublikationen mit Industriepartnern in den Jahren 2014 bis 2018,
absolut und relativ zum BIP
Sondervotum zu Kapitel 1 des Berichts der Projektgruppe 2 &#8222;KI und Staat&#8220;
(&#8222;Kurzfassung des Projektgruppenberichts&#8220;) der Abgeordneten Ronja Kemmer und der
Abgeordneten Marc Biadacz, Hansj&#246;rg Durz, Jan Metzler, Stefan Sauer, Prof. Dr. Claudia
Schmidtke, Andreas Steier und Nadine Sch&#246;n sowie der sachverst&#228;ndigen Mitglieder
Susanne Dehmel, Prof. Dr. Wolfgang Ecker, Prof. Dr. Antonio Kr&#252;ger, Prof. Dr. J&#246;rg 
M&#252;ller-Lietzkow und Dr. Sebastian Wieczorek
Die CDU/CSU-Bundestagsfraktion teilt die Forderung nach einer generellen und ex ante Einteilung von ADM-
Systemen und KI-gest&#252;tzten Systemen in Risikoklassen ausdr&#252;cklich nicht, die in den Beratungen der
Projektgruppe &#8222;KI und Staat&#8220; zun&#228;chst vorherrschte und an dieser und an anderen Stellen des Enquete-Berichtes
durchklingt. Eine horizontale (&#8222;one-size-fits-all&#8220;) KI-spezifische Regulierung lehnt die CDU/CSU-Bundestagsfraktion
schon aus Gr&#252;nden der Technologieneutralit&#228;t ab. Dar&#252;ber hinaus wurde durch interne wie externe
Sachverst&#228;ndige vielfach dargelegt, dass starre Risikomodelle, wie sie unter anderem durch die Datenethikkommission
vorgeschlagen werden2093, der Praxis nicht gerecht werden und Fehlgruppierungen ein hohes Risiko von
&#220;berregulierung bergen. Dies k&#246;nnte dazu f&#252;hren, dass Innovationen gerade in sensiblen Bereichen wie Gesundheit oder
Sicherheit gehemmt oder gar ausgeschlossen w&#252;rden. Dadurch w&#252;rden einerseits Menschen in Deutschland die
M&#246;glichkeiten entzogen, in diesem Bereich von KI-Anwendungen zu profitieren &#8211; ohne dass eine Risiko-Nutzen-
Abw&#228;gung f&#252;r den konkreten Anwendungsfall stattgefunden h&#228;tte; andererseits w&#252;rde das europ&#228;ische KI-
&#214;kosystem gest&#246;rt, da Aufwand und Kosten eines Entwicklungs- und Klassifizierungsprozesses insbesondere f&#252;r
KMU und Start-ups unverh&#228;ltnism&#228;&#223;ig w&#228;ren. 
So zeigten etwa die Praxisbeispiele und die Diskussion in der Sitzung der Enquete-Kommission vom 10.
Februar 2020 oder in den Workshops der Projektgruppe &#8222;KI und Wirtschaft&#8220; vom 8. April 2019, dass die
mannigfaltigen Entwicklungs- und Einsatzszenarien von KI-Systemen eine differenzierte Risikoeinordnung zwingend
2093 Vgl. Datenethikkommission der Bundesregierung (2019): Gutachten der Datenethikkommission der Bundesregierung.
        
 
 
 
 
   
 
 
    
 
  
  
    
     
  
  
  
 
 
 
 
     
               
      
 
       
    
 
  
    
    
      
    
    
 
  
 
    
 
 
   
  
                                               
           
         
        
    
 
2
notwendig machen. Es muss an konkreten Verarbeitungs- und Entscheidungsmechanismen und deren
Wirkweisen angekn&#252;pft werden. Auch branchenspezifische Einordnungen werden den differenzierten Einsatzarten nicht
gerecht. 2094 
Die CDU/CSU-Bundestagsfraktion hat sich daher in der Enquete-Kommission intensiv f&#252;r die schlie&#223;lich
mehrheitlich beschlossene Sichtweise zu KI und zum Umgang mit Risiko eingesetzt, die im Kapitel 4 des
Mantelberichts [KI und Umgang mit Risiko], ausf&#252;hrlich dargelegt ist: &#8222;Erst die Betrachtung des individuellen
Anwendungskontextes und der individuellen Einsatzumgebung erlauben eine umfassende Bewertung der mit dem
Gebrauch von Algorithmen und Systemen einhergehenden Kritikalit&#228;t.&#8220;2095 Zutreffend wird dort u. a. gefordert, 
kontextspezifische Referenzszenarien einzubeziehen, die Eintrittswahrscheinlichkeit von Risiken und den
jeweilige Nutzen des KI-Einsatzes gegen&#252;ber dem Schadenspotenzial eines Risikos abzuw&#228;gen sowie
prozessorientiert vorzugehen. Entsprechend haben die Koalitionsfraktionen auch in ihrem Antrag &#8222;Zukunftstechnologie
K&#252;nstliche Intelligenz als Erfolgsfaktor f&#252;r ein starkes und innovatives Europa &#8211; Eine Stellungnahme zum
Wei&#223;buch `Zur K&#252;nstlichen Intelligenz&#180; der EU-Kommission&#8220; auf Bundestagsdrucksache 19/22181 vom 8.
September 2020 argumentiert und Empfehlungen an die Bundesregierung sowie die EU-Kommission gegeben.
An den deutschen und europ&#228;ischen Gesetzgeber wird abschlie&#223;end die dringende Empfehlung gegeben, den
k&#252;nftigen Rechtsrahmen auf einen chancen- und risikobasierten Ansatz aufzusetzen, um die Verh&#228;ltnism&#228;&#223;igkeit
des regulatorischen Eingreifens zu gew&#228;hrleisten. Ein Klassifikationsschema muss neben den o. g. Aspekten
ber&#252;cksichtigen, dass es auch KI-Systeme ohne Sch&#228;digungspotenzial gibt, die keiner spezifischen Kontrolle
bed&#252;rfen, eine praktikable Zuordnung des KI-Systems durch Rechtsanwender m&#246;glich sein muss und auch
Ausnahmetatbest&#228;nde f&#252;r Forschung und Entwicklung notwendig werden k&#246;nnen.
Die CDU/CSU-Bundestagsfraktion distanziert sich in diesem Sondervotum ausdr&#252;cklich von Ambitionen eines
eigenen &#8222;KI-Gesetzes&#8220;, das ggf. jahrelange Verhandlungen auf europ&#228;ischer Ebene mit sich bringen oder gar an
der Komplexit&#228;t des Verfahrens und bzw. oder der Materie scheitern k&#246;nnte, und so f&#252;r die Wirtschaft wie die
Verwaltung zu Rechtsunsicherheit und fehlender Planungssicherheit beim Einsatz von KI f&#252;hren w&#252;rde.2096
Vielmehr sollten neue Regulierungen und neue Kontrollinstanzen dort gepr&#252;ft und ggf. nach klaren Kriterien
eingef&#252;hrt werden, wo Rechtsunsicherheit besteht. Dabei sollten &#196;nderungen ins existierende Regulierungsschema
eingepasst werden und insbesondere auch auf bew&#228;hrte Instrumentarien wie Standardisierung und Normierung 
sowie Ko-Regulierung gesetzt werden, die schnellere Wege erm&#246;glichen, um Regelungsl&#252;cken zu schlie&#223;en oder
Risiken praxisnah zu adressieren. 
Sondervoten der SPD-Fraktion
Sondervotum zu Kapitel 4 des Mantelberichts (&#8222;KI und Umgang mit Risiko&#8220;) der 
Abgeordneten Daniela Kolbe, Elvan Korkmaz-Emre, Falko Mohrs, Ren&#233; R&#246;spel und 
Jessica Tatti sowie der sachverst&#228;ndigen Mitglieder Dr. Florian Butollo, Prof. Dr.-Ing.
Sami Haddadin, Jan Kuhlen, Lena-Sophie M&#252;ller und Lothar Schr&#246;der
Die Regulierung und das Management des Risikos durch den Einsatz von KI-Systemen werden im
Mantelberichtsteil des Enquete-Berichtes aus unserer Sicht nicht angemessen ausgef&#252;hrt. Unsere Position m&#246;chten wir
daher hier beschreiben.
Orientierung am Menschen und gesamtgesellschaftliche Wirkung
Wir sind der Auffassung, dass sich die Bewertung von Risiko sowohl am Menschen als auch an der
gesamtgesellschaftlichen Wirkung orientieren sollte. Im Unterschied zu physischen Produkten (wie z. B. Chemikalien)
besteht beim Einsatz von algorithmischen Systemen und in besonderer Weise beim Einsatz von K&#252;nstlicher
Intelligenz die Schwierigkeit, Probleme und Gefahren aufzudecken und nachzuweisen. Insbesondere
gesamtgesellschaftliche Auswirkungen lassen sich kaum individuell beziffern. Ungewissheiten bez&#252;glich der Auswirkungen
neuer Technologien sind seit jeher kein pauschaler Ausschlussgrund f&#252;r vorbeugende Risikominimierung (dies
veranschaulicht bspw. die risikominimierende Regulierung der Gentechnik durch das Gentechnikgesetz von
2094 Siehe dazu das Protokoll der Sitzung der Enquete-Kommission vom 10. Februar 2020, das Protokoll der Projektgruppe &#8222;KI und 
Wirtschaft&#8220; vom 4. August 2019 und Kommissionsdrucksache 19(27)106 vom 10. Februar 2020.
2095 Siehe dazu Kapitel 4 des Mantelberichts [KI und Umgang mit Risiko].
2096 Vgl. Wirtschaftsrat der CDU e. V. (2020): Rahmenbedingungen f&#252;r K&#252;nstliche Intelligenz in der EU: Chancenorientierung vor
Risikobewertung.
1990). Zudem d&#252;rfen technische Gegebenheiten nicht den normativ gepr&#228;gten Gesetzgebungsprozess
bestimmen: Der Gesetzgeber sollte der Technik Vorgaben machen und nicht umgekehrt. 
Bei der Regulierung neuer Technologien sollte stets zuerst das Risiko ihrer Anwendung f&#252;r die Gesellschaft und
individuell Betroffene betrachtet werden und dann die Definition der gesellschaftlich erw&#252;nschten
Anforderungen folgen &#8211; unabh&#228;ngig von der Frage, wie schwer oder einfach diese technisch zu erreichen sind.
Normen als eine, aber nicht &#8222;die&#8220; L&#246;sung
Ein Risikomanagement kann dabei pr&#228;ventiv in Teilen auch auf Normen und Standards, die ethische Werte fest-
und durchsetzen, aufbauen. Der Vorteil von Normen und Standards, die in einem Verbund aus verschiedenen
Akteuren erarbeitet werden, liegt sicherlich darin, dass konkretere technische Vorgaben gemacht werden k&#246;nnen,
als dies im Gesetzgebungsverfahren m&#246;glich w&#228;re. Die Vorteile sind aber auch mit Nachteilen verbunden:
Insbesondere der hohe Druck durch (vor allem geringere) Standards anderer L&#228;nder, welche die europ&#228;ischen oder
deutschen Standards beeinflussen und der hohe Grad an Intransparenz, der so weit geht, dass zur Einhaltung der
Normen notwendige Dokumente nur zahlungspflichtig erworben werden k&#246;nnen, ist durchaus problematisch. 
Standards und Normen bilden einen wichtigen pr&#228;ventiven Ansatz, sind alleine jedoch nicht ausreichend, um das
Risiko algorithmischer Systeme angemessen zu regulieren.
Orientierung am konkreten Risiko, statt an einzelnen Sektoren
Der Regulierungsrahmen sollte nicht bereits grunds&#228;tzlich auf den Einsatz von KI in ausgew&#228;hlten Sektoren
begrenzt werden.
Ein auf KI beschr&#228;nkter Ansatz ist bereits im Ausgangspunkt zu eng und verstellt die eigentliche Debatte: Es gibt
derzeit keine allgemein anerkannte und ersch&#246;pfende Definition von KI, weshalb auch diese Enquete-
Kommission letztlich zu einer Begriffskl&#228;rung und nicht zu einer Definition kommt. 
Ein algorithmisches Entscheidungssystem kann in mehreren Sektoren zum Einsatz kommen. Zwar lassen sich 
unter Umst&#228;nden Sektoren ausmachen, in denen der Einsatz typischerweise besonders risikogeneigt ist. Diese
typisierte Betrachtung darf aber nicht den Blick darauf verstellen, dass algorithmische Entscheidungssysteme
auch jenseits dieser Sektoren im Einzelfall zu schwerwiegenden Grundrechtseingriffen f&#252;hren k&#246;nnen.
Umgekehrt existieren in jedem Sektor auch risikoarme Anwendungen, die keiner gehobenen Risikoregulierung
unterliegen sollten.
Der regulatorische Anwendungsbereich sollte daher algorithmische Systeme umfassen, die aufgrund ihrer
konkreten Verwendung &#252;ber Menschen entscheiden bzw. Entscheidungen beeinflussen und somit zu hohen Risiken
f&#252;r grundrechtlich gesch&#252;tzte G&#252;ter f&#252;hren.
&#8222;Tastende Regulierung&#8220; anstelle eines regulatorischen Schnellschusses
Wenn also anhand eines bestehenden Risikos  konkrete Anforderungen an eine Regulierung entwickelt werden
sollen, dann sollte im Sinne einer &#8222;tastenden Regulierung&#8220; auf der ersten Stufe damit begonnen werden,
Transparenz &#252;ber die Nutzung und den damit verbundenen Risiken von algorithmischen Entscheidungssystemen zu
schaffen. Dies soll zun&#228;chst dadurch erreicht werden, dass Akteure, die solche Systeme entwickeln oder
einsetzen, &#252;ber die spezifischen Risiken des Systems in einem einfachen Fragebogen gegen&#252;ber einer Aufsichtsbeh&#246;rde
Auskunft geben. Um dieses beh&#246;rdliche Wissen sodann in gesamtgesellschaftliches Wissen zu transferieren,
sollten die Beh&#246;rden Jahresberichte sowie die gesammelten statistischen Daten zur Verwendung von
algorithmischen Entscheidungssystemen und den dabei entstehenden Risiken ver&#246;ffentlichen. Diese Daten und
Erfahrungen m&#252;ssen ausgewertet und daraus evtl. entstehender Handlungsbedarf identifiziert werden. Dieser Prozess
erm&#246;glicht eine fundierte, evidenzbasierte Grundlage f&#252;r die tastende Ausgestaltung weitergehender
Anforderungen wie z. B. im Hinblick auf Nicht-Diskriminierung, menschliche Aufsicht, Genauigkeit und Robustheit.
&#8222;Gestufte Regulierung&#8220;
Wir halten eine &#8222;gestufte Regulierung&#8220;, die je nach konkretem Risiko mehrere Abstufungen vorsieht, f&#252;r einen
guten Ansatz, um spezifische Risiken auch spezifisch regulieren zu k&#246;nnen. Die Anzahl der Stufen muss unseres
Erachtens jetzt noch nicht festlegt werden. Deutlich ist jedoch, dass es darum gehen wird, unterschiedliche
Risikointensit&#228;ten unterschiedlich zu behandeln, weshalb eher mehr als weniger Risikostufen anzusetzen sind. Die
erste Stufe sollte aus unserer Sicht m&#246;glichst breit gestaltet werden. Denkbar beinhaltet sie eine
Transparenzpflicht dar&#252;ber, ob ein algorithmisches System eingesetzt wird. Auf einer n&#228;chsten Stufe w&#228;re dann zum Beispiel
transparent zu machen, wie und zu welchem Zweck ein solches System eingesetzt wird.
Sondervotum zu Kapitel 5.7 des Mantelberichts (&#8222;KI und Recht &#8211;
Handlungsempfehlungen&#8220;) der Abgeordneten Elvan Korkmaz-Emre und des sachverst&#228;ndigen
Mitglieds Jan Kuhlen, der Abgeordneten Arno Klare, Daniela Kolbe, Falko Mohrs und 
Ren&#233; R&#246;spel sowie der sachverst&#228;ndigen Mitglieder Prof. Dr.-Ing. Sami Haddadin, 
Lena-Sophie M&#252;ller und Lothar Schr&#246;der
Datenschutz ist Grundrechtsschutz. Die zu diesem Textteil existierende Argumentation f&#252;r eine weite Auslegung
der Zweck&#228;nderungsm&#246;glichkeit zum Beispiel in Richtung einer &#8222;alternativen Datensorgfalt&#8220; w&#252;rde unseres
Erachtens nicht nur zur Aush&#246;hlung der Datenschutz-Grundverordnung (DSGVO), sondern auch der Grundrechte
der Betroffenen auf Schutz der sie betreffenden personenbezogenen Daten aus Artikel 8 der EU-
Grundrechtecharta f&#252;hren.
Insbesondere ohne die Grunds&#228;tze der Zweckbindung und Datenminimierung kann ein Schutz der Grundrechte
nicht realisiert werden. Denn nur sie stellen sicher, dass personenbezogene Daten nicht grunds&#228;tzlich frei
verf&#252;gbar sind, da sie bereits an der Erhebung der Daten ansetzen und eben gerade nicht erst an deren Nutzung. Das
Bundesverfassungsgericht wie auch der Europ&#228;ische Gerichtshof haben dies immer wieder best&#228;tigt. Wenn Daten
als &#8222;Kommunikationsgegenstand&#8220; grunds&#228;tzlich allen zur Verf&#252;gung st&#252;nden, w&#228;re der Kern des Grundrechts
ausgeh&#246;hlt.
Die Definition personenbezogener Daten findet sich in Artikel 4 Nr. 1 DSGVO: &#8222;personenbezogene Daten&#8220;
[sind] alle Informationen, die sich auf eine identifizierte oder identifizierbare nat&#252;rliche Person [&#8230;] beziehen;
als identifizierbar wird eine nat&#252;rliche Person angesehen, die direkt oder indirekt, insbesondere mittels
Zuordnung zu einer Kennung [&#8230;] identifiziert werden kann. 
Die Grunds&#228;tze der Datenminimierung und der Zweckbindung betreffen personenbezogene Daten. Nicht
personenbezogene Daten zu erheben, die f&#252;r den Zweck der Verarbeitung nicht notwendig sind und sp&#228;ter f&#252;r ein 
Unternehmen von Nutzen sein k&#246;nnen, ist also sehr wohl erlaubt. Sind in einem Datensatz personenbezogene
Daten enthalten, in denen der Personenbezug f&#252;r das Innovationsvorhaben nicht erforderlich ist, besteht die
M&#246;glichkeit, den Datensatz um den Personenbezug zu bereinigen. Eine solche &#8222;Anonymisierung&#8220; ist zwar auch eine 
datenschutzrechtliche Verarbeitung, f&#252;r die es wiederum eine Rechtsgrundlage braucht &#8211; hier nimmt die
Datenschutzkonferenz jedoch meist den Rechtfertigungsgrund &#8222;berechtigtes Interesse&#8220; an. Das w&#228;re also nach
geltender Rechtslage m&#246;glich, eine &#196;nderung der datenschutzrechtlichen Grunds&#228;tze braucht es nicht. 
In Diskussionen wird immer wieder das unpassende Beispiel des Zeitstempels bei Maschinendaten verwendet,
um auf die Nachteile der Datenminimierung hinzuweisen. Anhand dieses Beispiels soll kurz erl&#228;utert werden,
dass die DSGVO weit weniger problematisch f&#252;r den unternehmerischen Alltag ist, als es der Anschein dieses
Beispiels zu vermitteln mag: Ein Unternehmen darf den beispielhaften Datensatz dann verwenden, wenn die
Zeitstempel nicht auf eine bestimmte Mitarbeiterin bzw. einen bestimmten Mitarbeiter zur&#252;ckzuf&#252;hren sind. Die
Kombination mit Daten eines anderen Datensatzes, um eine Identifikation der Person zu erreichen, ist ohne
Einwilligung oder ohne besonderes Interesse verboten. Wenn diese Daten allerdings f&#252;r das Training des KI-Systems
irrelevant sind und sie auch w&#228;hrend des Betriebs nicht genutzt werden, muss diese Information auch nicht
verwendet werden, und es gibt das beschriebene Problem nicht. 
Die SPD steht weiterhin zu den Grundprinzipien des europ&#228;ischen Datenschutzrechtes &#8211; und damit zum
Grundrechtsschutz. Wir wollen den hohen Datenschutz und innovative Datenverarbeitung in Einklang bringen. 
Sondervotum zu Kapitel C. III. &#8222;K&#252;nstliche Intelligenz und Staat (Projektgruppe 2)&#8220;
der Abgeordneten Daniela Kolbe, Elvan Korkmaz-Emre, Falko Mohrs, Ren&#233; R&#246;spel
und Jessica Tatti sowie der sachverst&#228;ndigen Mitglieder Prof. Dr.-Ing. Sami 
Haddadin, Jan Kuhlen, Lena-Sophie M&#252;ller und Lothar Schr&#246;der
Der Einsatz von Videokameras mit Gesichtserkennungssoftware wird im Projektgruppenbericht &#8222;KI und Staat&#8220;
des Enquete-Berichtes aus unserer Sicht nicht angemessen ausgef&#252;hrt. Unsere Position m&#246;chten wir daher hier
beschreiben.
Bei der Einf&#252;hrung von Video&#252;berwachungs- und Gesichtserkennungssystemen m&#252;ssen die Grundrechte der
Betroffenen gewahrt werden. Ein massenhafter Abgleich zwischen Datenbanken der Strafverfolgungsbeh&#246;rden und
Kameraaufnahmen mit Unterst&#252;tzung von Gesichtserkennungssoftware stellt ohne konkreten Anlass einen
groben Eingriff in die Grundrechte dar. So h&#228;ufen sich Erfahrungen &#252;ber die rassistische Diskriminierung von
Menschen nicht-wei&#223;er Hautfarbe durch Gesichtserkennungssysteme. Neben der damit verbundenen erheblichen
Anzahl von falschen Verd&#228;chtigungen gegen&#252;ber B&#252;rgerinnen und B&#252;rgern und Fragen nach der Einschr&#228;nkung
        
 
 
  
  
 
  
 
  
  
      
  
   
  
    
 
  
            
   
  
        
 
 
    
       
 
  
   
            
 
 
  
  
 
             
      
   
     
     
    
    
        
          
        
 
 
 
    
  
    
          
   
 
3
von Grundrechten sollte auch die Tatsache beachtet werden, dass die angestrebte Entlastung der
Sicherheitsbeh&#246;rden durch Technik mit dem teils falsch positiven Output des Systems konterkariert wird. Der Einsatz von
Videokameras mit Gesichtserkennungssoftware kann nur dann eine Chance darstellen, wenn rechtsstaatliche 
Grunds&#228;tze gewahrt werden k&#246;nnen. Der Gesetzesgeber sollte deshalb den Einsatz von
Gesichtserkennungssystemen im &#246;ffentlichen Raum nur in Ausnahmef&#228;llen zulassen. Zudem sollte sich der Gesetzesgeber auf EU-Ebene
f&#252;r entsprechende Regulierungen einsetzen.
Sondervoten der AfD-Fraktion
Sondervotum zu Kapitel 3 des Mantelberichts (&#8222;KI und Umgang mit Bias/
Diskriminierung&#8220;) des Abgeordneten Dr. Marc Jongen sowie der Abgeordneten Joana Cotar und 
Peter Felser
Aus Sicht der AfD-Fraktion sind die in diesem Kapitel beschriebenen Strategien zur Erkennung und Vermeidung
von Diskriminierung durch Bias nicht praxistauglich, sondern vielmehr geeignet, sich hemmend auf die
Entwicklung von KI-Systemen auszuwirken. Solange es keine normativen Vorgaben f&#252;r die &#8222;Fairnessma&#223;e&#8220; gibt, die aus
einem interdisziplin&#228;ren wissenschaftlichen Diskurs hervorgegangen sind, bleibt ein gro&#223;er interpretatorischer
Spielraum, was als diskriminierend zu gelten hat und was nicht. 
Im Folgenden wird der Begriff Bias als durch den Begriff Diskriminierung abgedeckt behandelt, da bereits die
Formulierung der Kapitel&#252;berschrift &#8222;Umgang mit Bias/Diskriminierung&#8220; im Mantelberichtsteil erkennen l&#228;sst,
dass es sich bei Bias um eine Voraussetzung von Diskriminierung handelt. Der Mantelberichtsteil beginnt mit
dem Pauschalurteil, dass Diskriminierung ein schon lange existierendes Ph&#228;nomen in unserer Gesellschaft und
weltweit sei. Diese Behauptung macht eine n&#228;here Betrachtung des Begriffs Diskriminierung erforderlich.
Diskriminieren bedeutet w&#246;rtlich: unterscheiden. Im Mantelberichtsteil wird der Begriff der Diskriminierung im
sozialwissenschaftlichen Sinne dahingehend verwendet, dass er die ungerechtfertigte Ungleichbehandlung von 
Gleichem und die ungerechtfertigte Gleichbehandlung von Ungleichem bezeichnet. Das ist deshalb sinnvoll, weil
die &#8211; eben nicht per se problematische &#8211; Praxis des Unterscheidens damit dort zur&#252;ckgewiesen wird, wo sie
Gruppen in Aspekten ihrer Identit&#228;t beschneiden und sie mit solchen Gruppen gleichsetzen oder ungleichsetzen
w&#252;rde, mit denen eine Gleichsetzung oder Ungleichsetzung jeweils empirisch unhaltbar und ungerecht w&#228;re.
Fragw&#252;rdige &#8222;Fairnessma&#223;e&#8220; zur Verhinderung von Diskriminierung
Als fragw&#252;rdig indes sind insbesondere die im Bericht angef&#252;hrten Strategien zur Erkennung und Vermeidung
von Diskriminierung zu klassifizieren. Diskriminierung durch Bias entstehe, so wird festgestellt, &#8222;wenn die
Datenauswahl ein systematisches Fehlverhalten des KI-Systems hervorruft, so dass Menschen aufgrund von &#228;u&#223;eren
und inneren Pers&#246;nlichkeitsmerkmalen ungerechtfertigt bevor- oder benachteiligt werden&#8220;. Es darf davon
ausgegangen werden, dass in diesem Fall, der eine Offenkundigkeit nahelegt, schon aufgrund bestehender rechtlicher
Regelungen korrigierend in das KI-System eingegriffen werden muss. 
Im Weiteren stellt der Bericht indes fest, dass &#8211; ungeachtet der Kategorien, die das Allgemeine
Gleichbehandlungsgesetz (AGG) in &#167; 1 nennt &#8211; Diskriminierung &#8222;nicht immer leicht zu erkennen&#8220; sei, &#8222;speziell wenn sie auf
einer Kombination verschiedener expliziter und impliziter Merkmale basiert&#8220;. Was hier unter &#8222;expliziten und
impliziten Merkmalen&#8220; zu verstehen ist, wird nicht n&#228;her erl&#228;utert. Stattdessen findet sich hierzu in einer Fu&#223;note
die Auskunft: &#8222;Beispielsweise w&#228;re ein System denkbar, das zwar weder in Bezug auf das Geschlecht, die
Hautfarbe und das Alter diskriminiert, aber dennoch afroamerikanische, junge Frauen benachteiligt.&#8220; Statt auf ein
konkretes Fallbeispiel verweist der Bericht nur auf eine Annahme, die &#252;berdies &#228;u&#223;erst schwer zu &#252;berpr&#252;fen ist.
Wie kann eine angebliche oder tats&#228;chliche Diskriminierung &#8222;afroamerikanischer, junger Frauen&#8220; einer KI
zugeschrieben werden, die nachweislich keine der im Einzelnen relevanten Diskriminierungsparameter aufweist?
Bei solchen indirekten Effekten handelt es sich um behauptete Diskriminierung, die weder bewiesen, noch
widerlegt werden kann. Sie &#246;ffnet willk&#252;rlichen und haltlosen Beschwerden seitens interessierter Gruppen T&#252;r und
Tor. 
Festzuhalten bleibt, dass der Bericht hier die Auskunft dar&#252;ber schuldig bleibt, wor&#252;ber eigentlich genau geredet
wird, wenn Diskriminierung &#8222;nicht immer leicht zu erkennen&#8220; sei. Dessen ungeachtet soll es aber m&#246;glich sein,
Diskriminierungen &#8222;&#252;ber die Berechnung von sogenannten Fairnessma&#223;en&#8220; zu entdecken. Oftmals indes st&#228;nden
deren Kriterien &#8222;miteinander im direkten Konflikt&#8220;. Daher sei &#8222;der wichtigste Schritt bei der Vermeidung von
Diskriminierung eine genaue Definition des &#8222;Fairnessma&#223;es, das zu ihrer Entdeckung verwendet werden soll&#8220;. 
Aus Sicht der AfD ist diese Mischung aus Spekulation, admonitio caritativa und Verdacht nicht praxistauglich.
Der Aufwand, den Programmierer von KI-Systemen hier betreiben m&#252;ssten, um &#252;ber die einschl&#228;gigen Vorgaben
hinaus alle m&#246;glichen Formen von Diskriminierung antizipierend zu erfassen, steht dann im keinem Verh&#228;ltnis
mehr. Das muss der Bericht auch selber einr&#228;umen, wenn er feststellt, dass die &#8222;Qualit&#228;t oder Fairness eines KI-
Systems&#8220; nicht &#8222;beliebig zu maximieren&#8220; sei.
Der Bericht bem&#228;ngelt weiter, dass in Deutschland &#8222;oft keine Informationen zu Religion, Hautfarbe, politischer
Orientierung oder anderen Merkmalen, aufgrund derer Diskriminierung stattfinden k&#246;nnte, erhoben&#8220; werden.
Wenn diese Daten nicht vorhanden seien, k&#246;nne &#8222;man sie zur Fairnesstestung von KI auch nicht benutzen,
obwohl eine Diskriminierung stattfindet&#8220;. Damit steht die Frage im Raum, aus welchen Gr&#252;nden derartige Daten &#8211;
wie z. B. die &#8222;politische Orientierung&#8220; &#8211; erhoben werden sollten, wenn es f&#252;r die Erhebung dieser Merkmale
keine zwingende Notwendigkeit gibt. Der Bericht legt nahe, dass nur dann Diskriminierung erkannt werden 
k&#246;nne. Diese Argumentation kommt einer petitio principii gleich: Es wird vorausgesetzt (was eigentlich erst
bewiesen werden m&#252;sste), n&#228;mlich dass es unerkannte Diskriminierungen geben k&#246;nnte, die nur deshalb nicht
erkannt werden, weil hierf&#252;r angeblich die Kriterien fehlten, die erhoben werden m&#252;ssten. Nur mit diesen
Merkmalen sei es m&#246;glich, &#8222;Fairnessma&#223;e&#8220; zu berechnen, deren Kriterien aber, siehe oben, oftmals &#8222;miteinander im
direkten Konflikt&#8220; st&#252;nden und mit Blick auf m&#246;gliche KI-Anwendungen zu fragw&#252;rdigen Ergebnissen f&#252;hren
k&#246;nnen.
Handlungsempfehlung
Es gibt aus Sicht der AfD keine Notwendigkeit, &#252;ber die einschl&#228;gigen gesetzlichen Regelungen hinaus anhand
von &#8222;Fairnessma&#223;en&#8220; Diskriminierung zu bek&#228;mpfen. Es besteht dann die Gefahr, dass sich die Diskussion um
die Eind&#228;mmung von Diskriminierung durch Bias mit Blick auf die Komplexit&#228;t derartiger &#8222;Fairnessma&#223;e&#8220;
hemmend auf die Entwicklung von KI-Systemen und damit auf die Wettbewerbsf&#228;higkeit Deutschlands auswirkt. 
Wenn &#8222;diskriminierungsfreie&#8220; KI-Systeme trotzdem entwickelt werden, so sollte f&#252;r die Nutzer transparent
dargestellt werden, welche &#8222;Fairnessma&#223;e&#8220; dabei zur Anwendung kommen, damit es ihnen ggf. freisteht, ein anderes
System zu benutzen.
Sondervotum zu Kapitel 6 des Mantelberichts (&#8222;Ethische Perspektiven auf KI&#8220;) des 
Abgeordneten Dr. Marc Jongen sowie der Abgeordneten Joana Cotar und 
Peter Felser
Im Mantelberichtsteil ,,Ethische Perspektiven auf KI&#8220; wird die fehlende technologische Souver&#228;nit&#228;t
Deutschlands nur sehr verhalten thematisiert und der Konnex zwischen dieser fehlenden technologischen Souver&#228;nit&#228;t
Deutschlands und der Er&#246;rterung von Voraussetzungen f&#252;r eine werteorientierte KI-Politik nur marginal
betrachtet. Das Sondervotum, das deshalb aus Sicht der AfD notwendig wurde, weist darauf hin, dass die &#220;berwindung
der gegenw&#228;rtigen Schw&#228;che des deutschen Bildungswesens eine notwendige Voraussetzung daf&#252;r bildet,
konkurrenzf&#228;hige und nach eigenen ethischen Ma&#223;st&#228;ben konzipierte KI-Technologien auf den Markt zu bringen.
Die &#220;berwindung der verloren gegangenen technologischen Souver&#228;nit&#228;t Deutschlands als Voraussetzung
f&#252;r eine werteorientierte KI-Entwicklung und -Wirtschaft
Der Mantelberichtsteil verweist auf die Bedeutung des gerechten Zugangs zu Bildung &#252;ber KI und der
zugrundeliegenden Technologien als Voraussetzung f&#252;r die Chancengerechtigkeit bei deren Nutzung und bei der
Teilhabe an gesellschaftlichen Debatten &#252;ber die KI. Der gerechte und allgemeine Zugang zur Bildung &#252;ber KI ist
aber nicht nur in dieser Hinsicht relevant, sondern auch hinsichtlich der M&#246;glichkeit, die moralischen Werte der
eigenen Gesellschaft und Kultur &#252;berhaupt in KI-Systeme einschreiben zu k&#246;nnen. 
Denn damit ethische Diskurse &#252;ber KI nicht nur stattfinden, sondern sich deren Ergebnisse auch in den
entwickelten KI-Systemen niederschlagen k&#246;nnen, muss die Software innerhalb einer Gesellschaft entwickelt und
produziert werden, in der diese Werte auch gelten. Dass es f&#252;r die ethische Praxis nicht gen&#252;gt, ethische Ma&#223;st&#228;be
theoretisch zu entwickeln und diesen vermeintlich entsprechende Produkte aus L&#228;ndern zu importieren, deren
geostrategische Interessen mit den eigenen teils betr&#228;chtlich differieren, zeigen u. a. die Beispiele von
importierter Spionagesoftware aus China oder den USA. So war etwa die im Jahr 2013 aufgedeckte fl&#228;chendeckende
&#220;berwachung deutscher B&#252;rger durch den US-Geheimdienst NSA u. a. dadurch m&#246;glich, dass in Deutschland
nachgefragte US-amerikanische KI-Anwendungen mit Spionagesoftware durchsetzt waren.2097 
2097 Cavelty und Egloff (2019): Cybersecurity: Rollen des Staates, S. 217.
Die im Mantelbericht vertretene Position, Technik- und Wertewandel br&#228;chen &#8222;nicht &#252;ber den Menschen herein&#8220;, 
sondern seien &#8222;Folgen des &#220;berlegens und Handelns der Menschen&#8220;2098, ist dann unzutreffend, wenn sie nicht
ber&#252;cksichtigt, dass es etwa im aufgezeigten Fall eben nicht die deutsche Gesellschaft ist, aus der heraus der
Technik- und Wertewandel ma&#223;geblich bestimmt wird. Deshalb befindet sich Deutschland gegenw&#228;rtig leider
oft in einer passiven oder gar erduldenden Rolle. 
Die fehlende technologische Souver&#228;nit&#228;t, die in diese Lage gef&#252;hrt hat, r&#252;hrt dabei u. a. daher, dass in
Deutschland noch immer ein Mangel an 55.000 IT-Fachkr&#228;ften besteht.2099 Dies h&#228;ngt auch mit dem Zustand des
deutschen Bildungssystems zusammen, das die entscheidende Rolle bei der Frage spielt, ob die heranwachsenden
B&#252;rger dazu bef&#228;higt werden, KI-Systeme einerseits hinreichend zu verstehen, um sich &#252;ber sie eine unabh&#228;ngige
Meinung bilden zu k&#246;nnen und ob andererseits in Deutschland sozialisierte KI-Forscher und -Entwickler die KI
geistig so weit zu durchdringen verm&#246;gen, dass sie in ihren Anwendungen Werte einschreiben k&#246;nnen, die den
ethischen Ma&#223;st&#228;ben unserer Kultur entsprechen. 
Entscheidend sind hierbei vor allem die Vermittlungen von Mathematikkenntnissen, denn &#8222;K&#252;nstliche Intelligenz
ist angewandte Mathematik&#8220;.2100 W&#228;hrend der Gesetzgeber sich nicht dazu versteigen sollte, zu bestimmen,
welchen Zielen die Gestaltung und der Einsatz von KI-Systemen folgen sollen, erlegt er sich insbesondere durch die
geltende Schulpflicht die Verantwortung auf, die Vermittlung von Mathematikkenntnissen auf einem f&#252;r die
ethische Beurteilung und Entwicklung von KI notwendigen Niveau zu gew&#228;hrleisten. Eben dieser Verantwortung
kommt der Staat nicht nach, wenn das Leistungsniveau an den Schulen stetig gesenkt wird und infolgedessen
auch das Leistungsniveau an den Hochschulen sinkt.2101 
Handlungsempfehlungen
Vor diesem dargelegten Hintergrund empfiehlt die AfD-Fraktion dem Gesetzgeber dringend, das Wissen und die
Bildung der B&#252;rger &#252;ber die KI und ihre mathematischen Grundlagen zu verbessern. Dies sollte in erster Linie
durch die Anhebung des Niveaus des Mathematikunterrichtes in allen Schulformen erreicht werden. Das ist
zun&#228;chst die entscheidende Voraussetzung daf&#252;r, um die Anzahl derjenigen B&#252;rger zu erh&#246;hen, die sich aus
eigenem Verst&#228;ndnis eine Meinung zur KI bilden k&#246;nnen. Denn nur so k&#246;nnen k&#252;nftig in pr&#228;genden
gesellschaftlichen Institutionen auch verschiedene gesellschaftliche Schichten und Milieus vertreten sein, die sich an einem
Diskurs &#252;ber ethische Perspektiven auf KI beteiligen k&#246;nnen. Ferner ist die Anhebung der (Aus-) Bildung &#252;ber
die KI nicht nur von unmittelbarer Relevanz f&#252;r die Entwicklung einer eigenen KI-Ethik, sondern auch f&#252;r deren
Durchsetzung am Markt. Denn nur durch eine bessere KI-Bildung kann auch sichergestellt werden, dass
zuk&#252;nftig in Deutschland sozialisierte und ausgebildete IT-Fachkr&#228;fte wie Software-Entwickler mit konkurrenzf&#228;higer
KI-Software auch f&#252;r Durchsetzung einer eigenen KI-Ethik sorgen. Die Durchsetzung von in Deutschland
entwickelten KI-Systemen am Markt ist dabei auch als Voraussetzung daf&#252;r zu sehen, dass das im Mantelbericht
genannte ethische Ziel der Gemeinwohlf&#246;rderung durch steigende Ertr&#228;ge der KI-Wirtschaft erreicht werden
kann. 
Sondervotum zu Kapitel 7 des Mantelberichts (&#8222;KI und Gesellschaft&#8220;) des
Abgeordneten Dr. Marc Jongen sowie der Abgeordneten Joana Cotar und Peter Felser
Aus Sicht der AfD-Fraktion ist die im Mantelbericht vorgenommene Formulierung &#252;bergeordneter
gesellschaftlicher Interessen, so z. B. im Hinblick auf die Herausforderungen Klimawandel und Demographie, schon deshalb
problematisch, weil deren Bestimmung durchaus strittig ist. Entsprechend fragw&#252;rdig ist die Indienstnahme der
KI f&#252;r die Bew&#228;ltigung dieser Herausforderungen. Die gezielte staatliche F&#246;rderung von KI-Technologien und
KI-Forschung darf sich aus Sicht der AfD-Fraktion nicht zugunsten politischer W&#252;nschbarkeiten von den
Mechanismen des Marktes entkoppeln.
2098 Siehe dazu Kapitel 6.1 des Mantelberichts [Ziele und Zwecke einer KI-Ethik].
2099 Vgl. Lindemann (2019): Digitale Vernetzung und (Cyber-)Sicherheit &#8211; unl&#246;sbarer Widerspruch oder zwei Seiten einer Medaille? F&#252;r
ein neues Zusammenspiel von Staat, Wirtschaft und Gesellschaft, S. 91.
2100 Vgl. Vortrag des sachverst&#228;ndigen Mitglieds Prof. Dr. Boris Hollas in der Sitzung der gesamten Enquete-Kommission am 2. M&#228;rz 
2020, abrufbar unter: https://www.bundestag.de/dokumente/textarchiv/2020/kw10-pa-enquete-ki-684058 (zuletzt abgerufen am
13. Oktober 2020).
2101 Vgl. das Sondervotum 3.11 zum Mathematikunterricht an deutschen Schulen [Sondervotum zu Kapitel 3.2.2, 5.2.4, 5.2.6 und 5.2.8.1 
des Berichts der Projektgruppe 4 &#8222;KI und Arbeit, Bildung, Forschung&#8220; (&#8222;Beispiele f&#252;r KI-Anwendungen in Schule und Hochschule&#8220;, 
&#8222;Anforderungen an den Schulunterricht&#8220;, &#8222;KI und Hochschule&#8220;  und &#8222;Lehrkr&#228;ftebildung&#8220;) des sachverst&#228;ndigen Mitglieds Prof.
Dr. Boris Hollas sowie der Abgeordneten Joana Cotar, Peter Felser und Dr. Marc Jongen].
Schwierigkeiten bei der Bestimmung &#252;bergeordneter gesellschaftlicher Interessen
Anders als im Mantelberichtsteil ,,Ethische Perspektiven auf KI&#8220; im Zusammenhang mit der Er&#246;rterung des
Gemeinwohl-Begriffs geschehen2102, wird die Existenz von &#252;bergeordneten gesellschaftlichen Interessen im
Berichtsteil ,,KI und Gesellschaft&#8220; in keiner Weise problematisiert, sondern vielmehr im Voraus konkret bestimmt. 
Der Mantelbericht spricht hier von der &#8222;Bek&#228;mpfung des Klimawandels&#8220; oder von &#8222;Herausforderungen des
demografischen Wandels&#8220;2103, zu deren Bew&#228;ltigung die KI einen wesentlichen Beitrag leisten k&#246;nne.
Demgegen&#252;ber h&#228;lt die AfD-Fraktion zun&#228;chst fest, dass es in pluralistischen Demokratien durchaus strittig ist, 
ob sich gesamtgesellschaftliche Interessen und die sie beg&#252;nstigenden Handlungen &#252;berhaupt ex ante bestimmen
lassen.2104 Setzt man eine fraglose Erkennbarkeit &#252;bergeordneter gesellschaftlicher Interessen aber gleichwohl
voraus, stellt sich die Frage, woran ein solches Interesse erkennbar wird. Dies gilt vor allem in Anbetracht der
im Text gegebenen Beispiele, darunter die Bek&#228;mpfung des Klimawandels. In den Handlungsempfehlungen des
Mantelberichtsteils wird angeregt, solche Technologien staatlich zu subventionieren, die potenziell n&#252;tzlich
seien, sich aber absehbar nicht am Markt durchsetzen k&#246;nnen.2105 Zum einen ist die Formulierung einer
potenziellen N&#252;tzlichkeit mehrdeutig und bietet viel Spielraum f&#252;r quasi experimentelle Fehlinvestitionen in
mangelhafte Technologie. Zum anderen stellt sich die Frage, wie es sich mit der Behauptung eines gegebenen und
korrekt erkannten &#252;bergeordneten gesellschaftlichen Interesses vertr&#228;gt, wenn sich Produkte, die dieses Interesse
bedienen sollen, nicht am Markt etablieren k&#246;nnen. Sollten sich bspw. Technologien f&#252;r weniger
versorgungssichere, aber als klimafreundlich geltende Energiequellen am Markt nicht durchsetzen k&#246;nnen, so w&#252;rde das den
berechtigten Zweifel an der Behauptung begr&#252;nden, dass ein h&#246;heres gesellschaftliches Interesse an sogenannten
Ma&#223;nahmen zur Bek&#228;mpfung des Klimawandels best&#252;nde, als an einer stabilen Energieversorgung. Nachfrage
sollte als Indikator f&#252;r gesellschaftliches Interesse folglich nicht ausgeblendet oder gar konterkariert werden.
Handlungsempfehlungen
Aus Sicht der AfD-Fraktion sollte ein entscheidendes Kriterium f&#252;r die gezielte staatliche F&#246;rderung von KI-
Anwendungen und der damit verbundenen KI-Forschung sein, ob sich diese absehbar am Markt behaupten
k&#246;nnen werden, nicht aber politische W&#252;nschbarkeiten, die sich an vermeintlichen gesamtgesellschaftlichen
Interessen ausrichten, tats&#228;chlich aber nur dem deutschen Steuerzahler weitere Lasten aufb&#252;rden werden.
Sondervotum zu Kapitel 8 des Mantelberichts (&#8222;KI und &#246;kologische Nachhaltigkeit&#8220;) 
des Abgeordneten Dr. Marc Jongen sowie der Abgeordneten Joana Cotar und 
Peter Felser
Das AfD-Sondervotum zu diesem Kapitel des Berichts begr&#252;ndet sich aus der Einseitigkeit, mit der der Begriff 
Nachhaltigkeit Verwendung findet. Nachhaltigkeit ist ein Begriff mit einem fragw&#252;rdigen Framing. Er
suggeriert, dass das, wof&#252;r er steht, f&#252;r die Allgemeinheit in jedem Fall ein w&#252;nschenswertes Ziel darstellt. In der Regel
wird unter Nachhaltigkeit eine Strategie verstanden, die die Erneuerung von Ressourcen gew&#228;hrleisten und deren
Raubbau entgegenwirken soll. Dieses Anliegen kann als &#246;kologische Nachhaltigkeit umrissen werden.
Tats&#228;chlich wurde der Begriff Nachhaltigkeit aber, wie ein Blick auf die Agenda 21 deutlich macht, auf drei Dimensionen
erweitert, n&#228;mlich a) eine soziale und wirtschaftliche Dimension, b) eine &#246;kologische Dimension, die auch die
Bereiche Klima-, Energie- und Landwirtschaftspolitik umfasst, und c) eine &#8222;emanzipatorische&#8220; Dimension, die
auf die St&#228;rkung der Rolle bestimmter gesellschaftlicher Gruppen (Frauen, ethnische Minderheiten etc.) f&#228;llt. Es
geht hier also auch um sozialtechnologische Ziele, die den B&#252;rger auf den vermeintlich richtigen Weg f&#252;hren
sollen.
Das problematische Framing des Begriffes Nachhaltigkeit
Der Begriff Nachhaltigkeit stammt aus der Forstwirtschaft und bezeichnet einen wirtschaftlichen Umgang mit 
Ressourcen, der darauf angelegt ist, die Lebensgrundlagen zuk&#252;nftiger Generationen dauerhaft zu erhalten.2106 
Gleich zu Beginn des Mantelberichtsteils wird die &#246;kologische Nachhaltigkeit stark mit der Beschr&#228;nkung von
2102 Siehe dazu Kapitel 6.2 des Mantelberichts [Ethische Perspektiven auf KI (Prinzipien, Werte)]. 
2103 Siehe dazu Kapitel 7.3 des Mantelberichts [Entwicklung und Einsatz von KI-Systemen im Sinne von Nachhaltigkeit und Wohlstand]. 
2104 Vgl. Schubert und Klein (2011): Das Politiklexikon, S. 141.
2105 Siehe dazu Kapitel 7.2 des Mantelberichts [Auswirkungen von KI-Systemen auf die Gesellschaft].
2106 Vgl. Schubert und Klein (2011): Das Politiklexikon, S. 230.
CO2-Emmissionen durch den Einsatz sogenannter erneuerbarer Energien assoziiert, was als Konsequenz der
Hypothese des treibhausgasinduzierten, anthropogenen Klimawandels erkennbar ist. Als Grundlage f&#252;r das
Verst&#228;ndnis von Nachhaltigkeit zieht der Mantelberichtsteil die 17 Ziele f&#252;r eine nachhaltige Entwicklung der
Vereinten Nationen heran, die sich im Aktionsprogramm Agenda 21 und in deren Nachfolgeagenda (Agenda 2030)
wiederfinden. Die hier genannten Ziele umfassen zahlreiche politische Themenfelder, darunter die Bek&#228;mpfung
von Armut und Hunger, Geschlechtergerechtigkeit, Schutz und F&#246;rderung der menschlichen Gesundheit, die
Sicherung von Wirtschaftswachstum und g&#252;nstiger, sauberer Energie sowie den Schutz von &#214;kosystemen und 
die Bek&#228;mpfung des Klimawandels und seiner Folgen.2107 
Diese Ziele finden auch im Leitbild des Rates f&#252;r nachhaltige Entwicklung, in dem es hei&#223;t: &#8222;Nachhaltige
Entwicklung hei&#223;t, Umweltgesichtspunkte gleichberechtigt mit sozialen und wirtschaftlichen Gesichtspunkten zu
ber&#252;cksichtigen. Zukunftsf&#228;hig wirtschaften bedeutet also: Wir m&#252;ssen unseren Kindern und Enkelkindern ein
intaktes &#246;kologisches, soziales und &#246;konomisches Gef&#252;ge hinterlassen. Das eine ist ohne das andere nicht zu
haben.&#8220;2108 
Dieses Framing, aber auch die 17 Ziele f&#252;r eine nachhaltige Entwicklung der Vereinten Nationen, deren
Umsetzung die Bundesregierung im M&#228;rz 2018 im Koalitionsvertrag festgeschrieben hat2109, fu&#223;t auf einer entgrenzten
Definition von Nachhaltigkeit, die nicht auf einer freien wissenschaftlichen Diskussion und damit auf
Falsifizierbarkeit beruht, sondern vor allem auf eine gesellschaftliche Transformation abzielt, die aus Sicht ihrer
Propagandisten als w&#252;nschenswert und damit normativ kommuniziert wird. Auch wenn die &#8222;hegemoniale
&#214;ffentlichkeit&#8220;2110 (Friedrich Krotz) einen gegenteiligen Eindruck zu erwecken versucht, gibt es weder einen hinreichend
offenen wissenschaftlichen Diskurs &#252;ber den Begriff Nachhaltigkeit noch dar&#252;ber, welches wissenschaftliche 
Niveau die Analysen haben, die Nachhaltigkeit als alternativlos zu kommunizieren versuchen, noch wie sinnvoll
die Konzepte sind, mit denen Nachhaltigkeit erreicht werden soll.
Die Bandbreite der Entw&#252;rfe, die mit Blick auf das Thema Nachhaltigkeit im Gespr&#228;ch sind, reicht deshalb vom
nachhaltigen Wachstum &#252;ber &#246;kosoziale Marktwirtschaft, &#8222;Green New Deal&#8220; bis hin zum &#214;kofeminismus und
&#246;kosozialistischen Ideen.2111 Einige dieser Ideen verlassen den Kontext einer marktwirtschaftlich verfassten
Gesellschaft und sind im Bereich sozialistischer Utopien zu verorten. Teile dieser Konzepte finden sich auch in den
17 Zielen f&#252;r nachhaltige Entwicklung wieder2112, so z. B. &#8222;Geschlechtergerechtigkeit&#8220;, &#8222;Keine Armut&#8220;,
&#8222;Menschenw&#252;rdige Arbeit und Wirtschaftswachstum&#8220; oder &#8222;Weniger Ungleichheiten&#8220;.
Vor diesem Hintergrund ist &#8211; mit Blick auf das hier zu verhandelnde Kapitel &#8222;KI und &#246;kologische
Nachhaltigkeit&#8220; aus dem Mantelberichtsteil &#8211; der Befund, dass die Hypothese des treibhausgasinduzierten, anthropogenen
Klimawandels, wie sie vom Weltklimarat verbreitet und von der Bundesregierung vertreten wird,
wissenschaftlich nicht gesichert ist, nicht &#252;berraschend. Er kann indes an dieser Stelle nicht tiefer er&#246;rtert werden, da dieser
Nachweis f&#252;r den Mantelberichtsteil nicht entscheidend ist.
Doppelengf&#252;hrung des Begriffs Nachhaltigkeit im Mantelbericht
Aus Sicht der AfD ist es angezeigt, auf die problematische Doppelengf&#252;hrung des Begriffs der Nachhaltigkeit in
diesem Kapitel des Mantelberichts hinzuweisen. Erstens wird Nachhaltigkeit stark auf die Klimapolitik und damit
auf die Reduktion von Treibhausgasemissionen fokussiert, auch auf Kosten des Schutzes von &#214;kosystemen und
weiterer Aspekte von Nachhaltigkeit. Zweitens wird nach dieser ersten Engf&#252;hrung noch zus&#228;tzlich eine Auswahl
an Energiequellen vorgenommen, die weder ber&#252;cksichtigt, ob eine hypothetisch unersch&#246;pfliche Energiequelle
2107 Weitere Informationen dazu unter: https://sdgs.un.org/goals (zuletzt abgerufen am 13. Oktober 2020); Bundesministerium f&#252;r
wirtschaftliche Zusammenarbeit und Entwicklung (2017): Der Zukunftsvertrag f&#252;r die Welt.
2108 Weitere Informationen dazu unter: https://www.nachhaltigkeitsrat.de/nachhaltige-entwicklung/ (zuletzt abgerufen am 13.
Oktober 2020).
2109 Koalitionsvertrag zwischen CDU, CSU und SPD, 19. Legislaturperiode.
2110 Vgl. hierzu auch das Sondervotum 3.13 zum Bericht der Projektgruppe 6 &#8222;KI und Medien&#8220;, Kapitel 5. 1, Analyse des Einsatzes von 
KI im klassischen Journalismus: Das Verh&#228;ltnis von &#8222;Massen-&#8220; und &#8222;Leitmedien&#8220; als Artikulationsinstanzen &#8222;hegemonialer
&#214;ffentlichkeit&#8220; und den sozialen Medien. [Sondervotum zu den Kapiteln 5.1.1 bis 5.1.3 des Berichts der Projektgruppe 6 &#8222;KI und Medien&#8220;
(&#8222;Funktionen des Journalismus &#8220;, &#8222;Qualit&#228;t und Ethik des Journalismus &#8220; und &#8222;Herausforderungen durch die Digitalisierung &#8220;) des
Abgeordneten Dr. Marc Jongen sowie der Abgeordneten Joana Cotar und Peter Felser]. 
2111 Weitere Informationen dazu unter: http://oekosozialismus.net/netzwerk/ (zuletzt abgerufen am 13. Oktober 2020). &#8222;Unser Ziel&#8220;, so 
kann hier u. a. nachgelesen werden, ist &#8222;eine solidarische und nachhaltige Gesellschaft&#8220;.
2112 Die Bundesregierung kommuniziert diese Ziele als &#8222;Die Glorreichen 17 Ziele nachhaltiger Entwicklung&#8220;, weitere Informationen 
dazu unter: https://www.dieglorreichen17.de/g17-de/ (zuletzt abgerufen am 13. Oktober 2020).
denn in ihrer praktischen Nutzbarkeit &#252;berhaupt anderen Energiequellen &#252;berlegen ist, noch die Kernkraft
einbezieht, welche als einzige relevante Energiequelle zugleich treibhausgasneutral und in vielf&#228;ltiger Hinsicht
nachhaltig ist. Dies ist selbst unter Annahme der Hypothese des treibhausgasinduzierten, anthropogenen
Klimawandels nicht nachvollziehbar.
Notwendige Besinnung auf die eigentliche Bedeutung von Nachhaltigkeit
Es ist daher geboten, sich auf die eigentliche Bedeutung von Nachhaltigkeit zu besinnen, die eingangs gegeben
worden ist: der wirtschaftliche Umgang mit Ressourcen, der darauf angelegt ist, die Lebensgrundlagen
zuk&#252;nftiger Generationen dauerhaft zu erhalten. Wie gezeigt worden ist, ist ein nachhaltiger Umgang mit Ressourcen
stark von der Technologie abh&#228;ngig, mittels derer die Ressourcen nutzbar gemacht werden. F&#252;r die Entwicklung
der KI bedeutet das, dass eine umweltvertr&#228;gliche und stabile Energieversorgung f&#252;r das Training und den
Einsatz der KI-Systeme, wie auch f&#252;r die effiziente Nutzung der KI-Hardware gew&#228;hrleistet sein muss. Denn die
Hardware von KI-Systemen ist auf relativ seltene Rohstoffe, u. a. Metalle der Seltenen Erden, angewiesen, deren
gr&#246;&#223;te Vorkommen sich weder auf deutschem noch auf europ&#228;ischem Boden befinden.2113 Dies gilt &#252;brigens
ebenso f&#252;r Windkraftanlagen und weitere Komponenten der Energiewende, die die seltenen Minerale Lithium,
Kobalt und Neodym ben&#246;tigen.2114 
Handlungsempfehlungen
Die Politik der Energiewende, im Sinne der Erreichung von Treibhausgasneutralit&#228;t durch die gezielte staatliche 
F&#246;rderung von vor allem Wind- und Solarkraftwerken unter gleichzeitigem Ausschluss der Kernkraft, muss als
gescheitert betrachtet werden.2115 &#220;berdies ist sie unter dem Gesichtspunkt tats&#228;chlicher Nachhaltigkeit nicht
w&#252;nschenswert. Daher kann es, im Gegensatz zur entsprechenden Zielbestimmung im Mantelberichtsteil, nicht
im Sinne einer nachhaltigkeitsorientierten Politik sein, anhand von KI-Anwendungen die Akzeptanz der B&#252;rger
f&#252;r eine verfehlte Politik der Energiewende st&#228;rken zu wollen. Die Bundesregierung ist deshalb aufgefordert, in 
ihrer Nachhaltigkeitspolitik eine grunds&#228;tzliche Kurskorrektur vorzunehmen und die Instrumentalisierung der KI
f&#252;r eine verfehlte Nachhaltigkeitspolitik einzustellen.
Sondervotum zu Kapitel 9 des Mantelberichts (&#8222;KI und Forschung&#8220;) des
Abgeordneten Dr. Marc Jongen sowie der Abgeordneten Joana Cotar und Peter Felser
Die im Mantelbericht normativ vorgetragene Forderung nach einer Erh&#246;hung des Frauenanteils und eines Mehr 
an &#8222;Diversit&#228;t&#8220; in der KI-Forschung ist aus Sicht der AfD nicht zielf&#252;hrend, sondern entspringt ideologischen
Motivationen. Im Vordergrund sollte das Ziel einer deutlichen Steigerung von gut ausgebildeten Hochschul-
Fachkr&#228;ften auch in der KI-Forschung stehen, und nicht die Frage, aufgrund welcher &#228;u&#223;eren Merkmale
Menschen zu privilegieren sind oder nicht.
Im Kapitel KI und Forschung des Mantelberichtes wird die &#220;berzeugung zum Ausdruck gebracht, dass es in es
in der Forschung zu K&#252;nstlicher Intelligenz mehr &#8222;Diversit&#228;t&#8220; bedarf. &#8222;Hochschulen sollten darin unterst&#252;tzt
werden, spezifische Programme zur Motivation von mehr Frauen sowie Menschen mit unterschiedlichem
sozialem Hintergrund zu entwickeln&#8220;, so z. B. durch Stipendien oder eine &#8222;besonders gestaltete Studien- oder
Promotionseingangsphase&#8220;. 
Weiter ist die Rede von einer &#8222;vorw&#228;rtsgewandten Forschungsstrategie&#8220;, die eine Zukunftsvision impliziert, &#8222;die 
erst einmal gar nicht die Technik in den Mittelpunkt stellt, sondern Anwendungsfelder mit hohem Potenzial 
identifiziert&#8220;. Dazu geh&#246;ren u. a. der Klimawandel, die Energieversorgung sowie die soziale Inklusion durch
Assistenz- und Kommunikationssysteme. Nach Auffassung der AfD sollte eine Forschungsstrategie nicht von
vornherein auf Themenfelder eingeengt werden, sondern ergebnisoffen angelegt sein. Alles andere l&#228;uft auf eine
Beschneidung der Wissenschaftsfreiheit hinaus und ist deshalb abzulehnen.
Mit der im Mantelbericht erhobenen Forderung, dass in Deutschland &#8222;die Anzahl von Frauen in der KI-
Forschung&#8220; &#8222;signifikant erh&#246;ht&#8220; werden und &#8222;Diversit&#228;t in einem so zukunftsgewandten Bereich &#8222;nicht nur normativ
w&#252;nschenswert&#8220; sein sollte, weil dies die &#8222;Wahrscheinlichkeit einer perspektivenreicheren Wissenschaft&#8220;
erh&#246;he, werden externe Ma&#223;st&#228;be an die Wissenschaft herangetragen, die, so die Philosophieprofessorin Dagmar
2113 Vgl. BR Wissen (2019): Gefragte Metalle f&#252;r moderne Technologien.
2114 Vgl. Umweltausschuss des Deutschen Bundestages, Nachhaltigkeitsstrategien, Ausschussdrucksache 19(16)216-A, S. 19.
2115 Vgl. Umweltausschuss des Deutschen Bundestages, Nachhaltigkeitsstrategien, Ausschussdrucksache 19(16)216-A, S. 9 f.
Borchers, &#8222;mit internen Qualit&#228;tsma&#223;st&#228;ben nichts zu tun haben&#8220;.2116 Die normative Forderung nach mehr
&#8222;Diversit&#228;t&#8220; und nach einer Erh&#246;hung des Frauenanteils f&#252;hrt dazu, dass aufgrund dieser sachfremden
Beurteilungskriterien nicht mehr die Qualit&#228;t wissenschaftlicher Arbeit Ma&#223;stab der Bewertung ist, sondern sekund&#228;re
Gesichtspunkte, die sogar mit der &#8222;Idee wissenschaftlicher Exzellenz konfligieren&#8220; k&#246;nnen.2117 
Die AfD ist deshalb der Auffassung, dass es in der Forschung mit Blick auf KI keineswegs mehr &#8222;Diversit&#228;t&#8220;
bedarf, sondern gut ausgebildeter Hochschul-Fachkr&#228;fte, denen entsprechende Perspektiven er&#246;ffnet werden
m&#252;ssen. Das Geschlecht oder der &#8222;soziale Hintergrund&#8220; d&#252;rfen hierbei keine Rolle spielen. Allein die fachliche
Qualifikation muss entscheidend sein. Die Steigerung ausgebildeter Hochschul-Fachkr&#228;fte im KI-Bereich ist 
dringlich, weil sich aufgrund dieses Engpasses KI-basierte Projekte verz&#246;gern oder nicht realisiert werden
k&#246;nnen.2118 
Bedenklich im Hinblick auf diese Forderungen ist der illiberale politische Impetus, der in dieser Frage
mitschwingt. Das angestrebte Ergebnis transportiert n&#228;mlich zwangsl&#228;ufig die nicht ausgesprochene Erwartung, dass
sich Menschen in einer Art und Weise zu verhalten haben, die eine baldige Realisierung der erhobenen Forderung
m&#246;glich macht. Borchers weist darauf hin, dass dies &#8222;schwer vereinbar sei mit der &#8222;Idee der Freiheit als
Handlungs- und Entscheidungsfreiheit derjenigen, die die &#8222;Institutionen und Beh&#246;rden durch ihre Arbeit&#8220; pr&#228;gten.2119 
Die normativen Forderungen nach einer Erh&#246;hung des Frauenanteils und nach &#8222;mehr Diversit&#228;t&#8220; birgt im
Weiteren ein hohes &#8222;Fragmentierungspotenzial&#8220;.2120 Die Angeh&#246;rigen der &#8222;Dominanzgruppe&#8220; sehen sich n&#228;mlich
mit der impliziten Forderung nach einer &#8222;positiven Diskriminierung&#8220; zugunsten &#8222;diverser&#8220; Gruppen oder Frauen
konfrontiert, deren Privilegierung ein Ausdruck von Gerechtigkeit sein soll. Tats&#228;chlich geht es hier aber nicht
um Gerechtigkeit, sondern um Gleichstellung im Sinne einer Ergebnisgleichheit. Gleichstellung indes l&#228;uft
Gerechtigkeitsprinzipien zuwider, wenn Personen aufgrund bestimmter wissenschaftsferner pers&#246;nlicher Merkmale
besonders gef&#246;rdert werden sollen. Eine derartige Gleichstellungspolitik lehnt die AfD als ungerecht ab. 
Handlungsempfehlungen
Normative Vorgaben in der KI-Forschung, die darauf abzielen, dass z. B. der Frauenanteil &#8222;signifikant erh&#246;ht&#8220;
werden m&#252;sse oder es eines Mehr an &#8222;Diversit&#228;t&#8220; bed&#252;rfe, das mit entsprechenden Ma&#223;nahmen durchzusetzen
ist, m&#252;ssen als wissenschaftsferne Ma&#223;nahmen, die geeignet sind, wissenschaftliche Qualit&#228;tsma&#223;st&#228;be zu
unterlaufen, abgewiesen werden.
Sondervotum zu den Kapiteln 4.1.3.1.1 und 5.2.1 des Berichts der Projektgruppe 1 
&#8222;KI und Wirtschaft&#8220; (&#8222;Themenfeld Start-ups&#8220; und &#8222;Innovation und Start-ups:
Startup-&#214;kosysteme, Start-up-F&#246;rderungen&#8220;) der Abgeordneten Joana Cotar sowie der 
Abgeordneten Peter Felser und Dr. Marc Jongen
Die erste Evaluierung der DSGVO zeigt, dass KMU durch die Datenschutzh&#252;rden in ihrer Gesch&#228;ftst&#228;tigkeit
ausgebremst werden. Eine umfassende Reform ist dringend geboten.
Vorbemerkung
Im Kapitel 4.1.3.1.1 des Berichtes der Projektgruppe &#8222;KI und Wirtschaft&#8220; [Themenfeld Start-ups] wird die
besondere Rolle von Start-ups beim Transfer technischer Innovationen in tragf&#228;hige Gesch&#228;ftsmodelle
hervorgehoben, besonders im Bereich der K&#252;nstlichen Intelligenz (KI). Damit agile Start-ups schnell wachsen und sich
am Markt durchsetzen k&#246;nnen, ist in der Phase geringer Ums&#228;tze der Zugang zu Kapital unabdingbar f&#252;r den
Erfolg. Die Finanzierung erfolgt in Deutschland teils &#252;ber sogenanntes Wagniskapital, teils &#252;ber &#246;ffentliche
F&#246;rderprogramme. International sind die USA im Bereich der KI-Start-ups f&#252;hrend, China holt diesbez&#252;glich auf,
w&#228;hrend Europa im Vergleich hinterherhinkt.
2116 Borchers (2019): Das identit&#228;tslinke Kultur- und Identit&#228;tsverst&#228;ndnis, S. 112.
2117 Vgl. Borchers (2019): Das identit&#228;tslinke Kultur- und Identit&#228;tsverst&#228;ndnis, S. 114.
2118 Vgl. Deutscher Bundestag, Parlamentsnachrichten (2020): Fachkr&#228;ftemangel im KI-Bereich.
2119 Vgl. Borchers (2019): Das identit&#228;tslinke Kultur- und Identit&#228;tsverst&#228;ndnis, S. 93.
2120 Kostner (2019): Identit&#228;tslinke L&#228;uterungsagenda. Welche Folgen hat sie f&#252;r Migrationsgesellschaften?, S. 30.
Die Projektgruppe ist mehrheitlich der Ansicht, dass die mit der europ&#228;ischen Datenschutz-Grundverordnung
(DSGVO)2121 gesetzten hohen Datenschutzstandards einen Wettbewerbsvorteil f&#252;r deutsche KI-Start-ups im
Gewinnen des Vertrauens der Nutzer darstellen k&#246;nnen. Diese Position kann sich die AfD-Fraktion nicht zu eigen
machen, ihre Kritik an der DSGVO und ihrer &#252;berbordenden B&#252;rokratie als Gesch&#228;ftshemmnis fand keinen
Eingang in den Berichtstext. Die DSGVO definiert den Schutz nat&#252;rlicher Personen bei der Verarbeitung
personenbezogener Daten als ein Grundrecht. Dieses Recht muss im Hinblick auf seine gesellschaftliche Funktion gesehen
und unter Wahrung des Prinzips der Verh&#228;ltnism&#228;&#223;igkeit gegen andere Grundrechte abgewogen werden. 
Die AfD-Fraktion ist der Ansicht, dass die Balance zwischen Freiheits- und Schutzrechten in der Praxis nur
mangelhaft funktioniert; sie ist konkret der Ansicht, dass die europ&#228;ische DSGVO im Gesch&#228;ftsalltag gerade
kleiner und junger Unternehmen praktisch schwer handhabbar ist und damit die Etablierung neuer
vielversprechender Gesch&#228;ftsmodelle behindert. Die DSGVO schafft zwar starke, jedoch nur schwer operationalisierbare
Betroffenenrechte2122, die obendrein mit den Interessen datenverarbeitender Unternehmen kollidieren. Hier
besteht akuter Reformbedarf.
Argumentation
Das urspr&#252;ngliche Ziel der DSGVO war es, die &#246;konomische und publizistische Macht monopolartiger
Plattformen aus den USA, die Millionen europ&#228;ischer Nutzer haben und &#252;ber deren Daten verf&#252;gen, zu beschr&#228;nken;
faktisch werden jedoch genau diese Anbieter durch die umst&#228;ndliche Praxis der Rechtfertigung von
Datenverarbeitung &#252;ber die Einwilligung im Wettbewerb mit kleinen Unternehmen beg&#252;nstigt und damit in ihrer
marktbeherrschenden Position gefestigt. Darunter leiden nicht zuletzt die Kunden, deren Auswahl an Dienstleistern in
unterschiedlichen Datenr&#228;umen von der Mobilit&#228;t &#252;ber die Websuche bis zur Kommunikation
datenschutzrechtlich &#252;ber Geb&#252;hr beschnitten wird.
Die mit der DSGVO einhergehenden Reglementierungen erschweren gerade den KI-Start-ups in Deutschland
ihre Gesch&#228;ftst&#228;tigkeit in administrativer Hinsicht. Die Komplexit&#228;t des Datenschutzes verz&#246;gert dessen
Umsetzung in den Unternehmen; seine Einhaltung absorbiert wichtige Kapazit&#228;ten, die an anderer Stelle fehlen. So hat
die DSGVO zu einer Einschr&#228;nkung der Reichweite kleinerer Unternehmen im Vergleich zu ihren bereits am
Markt pr&#228;senten, global agierenden Wettbewerbern gef&#252;hrt.2123 Zudem k&#246;nnen angesichts der hohen Strafen
datenschutzrechtliche Fehler das finanzielle Aus f&#252;r Jungunternehmer bedeuten.2124 Der geltende Datenschutz wirkt
somit in Deutschland und in der Europ&#228;ischen Union (EU) als Innovationsbremse in einer ausgesprochen
dynamischen Branche.
Gro&#223;e US-Plattformen werden in ihren Gesch&#228;ften nicht behindert
Diese skeptische Haltung gegen&#252;ber den Bestimmungen der DSGVO sowie den zust&#228;ndigen Aufsichtsbeh&#246;rden
der einzelnen L&#228;nder vertritt auch der Informatiker Martin Schallbruch bereits im ersten Jahr der Geltung der
DSGVO: &#8222;Europa hat sich in eine Datenschutz-Sackgasse begeben, aus der wir so schnell nicht wieder
herauskommen. Die gro&#223;en amerikanischen Internetplattformen werden in ihrem Gesch&#228;ft kaum behindert, die
europ&#228;ischen Unternehmen haben hohen Aufwand, um die komplizierten neuen Regeln einzuhalten. Die
Datenschutz-Aufsichtsbeh&#246;rden werden immer gr&#246;&#223;er, schwerf&#228;lliger und b&#252;rokratischer. Und die Betroffenen, die
Internetnutzerinnen und Internetnutzer in Europa &#8211; Sie haben weiterhin keine Ahnung, wer wann und f&#252;r was
ihre Daten nutzt.&#8220;2125 
Zwar sei es positiv zu sehen, dass die DSGVO das Recht vereinheitliche und damit ein scharfes Schwert f&#252;r eine 
europaweit bessere Durchsetzung des Datenschutzrechts schaffe, so Schallbruch. Allerdings basiere sie auf einer
alten (deutschen) Dogmatik, nach der Datenverarbeitung zun&#228;chst etwas Verbotenes sei.2126 F&#252;r die rechtm&#228;&#223;ige 
Verarbeitung der pers&#246;nlichen Daten einer Person durch ein Unternehmen ist gem&#228;&#223; DSGVO die Einwilligung 
2121 G&#252;ltig seit Mai 2018, im Volltext ver&#246;ffentlicht im Amtsblatt der Europ&#228;ischen Union, abrufbar unter: https://www.datenschutz-
grundverordnung.eu/wp-content/uploads/2016/05/CELEX_32016R0679_DE_TXT.pdf (zuletzt abgerufen am 13. Oktober 2020).
2122 Namentlich in den Artikeln 15 bis 20 DSGVO; etwa ein Auskunftsrecht, ein Recht auf L&#246;schung und ein Recht auf
Daten&#252;bertragbarkeit.
2123 Stellungnahme von Patrick Bunk (Ubermetrics Technologies) in der Sitzung der Projektgruppe KI und Wirtschaft am 8. April 2019.
Er beziffert den Reichweitenverlust der Werbenetzwerke von Facebook und Google zwischen 1 und 4 Prozent, den kleinerer
Unternehmen zwischen 10 und 25 Prozent.
2124 Artikel 83 der DSGVO sieht im Falle des Versto&#223;es gegen die in ihr festgelegten Bestimmungen eine Geldbu&#223;e von bis zu 20
Millionen Euro oder von bis zu 4 Prozent des weltweit erzielten Jahresumsatzes vor.
2125 Schallbruch (2018): Schwacher Staat im Netz, S. 67.
2126 Vgl. Schallbruch (2018): Schwacher Staat im Netz, S. 66.
der Person notwendig.2127 Als &#8222;Verarbeitung&#8220; personenbezogener Daten gelten hier &#8222;das Erheben, das Erfassen,
die Organisation, das Ordnen, die Speicherung, die Anpassung oder Ver&#228;nderung, das Auslesen, das Abfragen,
die Verwendung, die Offenlegung durch &#220;bermittlung, Verbreitung oder eine andere Form der Bereitstellung, 
den Abgleich oder die Verkn&#252;pfung, die Einschr&#228;nkung, das L&#246;schen oder die Vernichtung&#8220;.2128 
Schlussfolgerung
Die Projektgruppe empfiehlt im Kapitel 5.2.1 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220; [Innovation 
und Start-ups: Start-up-&#214;kosysteme, Start-up-F&#246;rderungen] vage, nach der Erstevaluation der DSGVO2129 zu 
entscheiden, welche Reformen gegebenenfalls notwendig sind, um Start-ups bei der rechtskonformen Umsetzung
der DSGVO zu unterst&#252;tzen. Hiervon abweichend vertritt die AfD-Fraktion die Position, dass die DSGVO mit
ihrem &#8222;One size fits all&#8220;-Ansatz prinzipiell ein zu grobes Verfahren ist, um den M&#246;glichkeiten und Bed&#252;rfnissen
sehr unterschiedlicher Unternehmen vom Start-up &#252;ber den Mittelst&#228;ndler bis zum Weltkonzern gerecht zu
werden.2130 Sie ist vielmehr ein trauriges Beispiel f&#252;r eine verfehlte Datenschutzpolitik, die B&#252;rgern und
Unternehmen, wie gerichtlich gekl&#228;rte Pr&#228;zedenzf&#228;lle zeigen, oftmals keine Rechtssicherheit gew&#228;hrt, vielmehr das Risiko
exorbitanter Bu&#223;geldzahlungen auferlegt. Die DSGVO hat die Rechtslage f&#252;r die meisten Start-ups und KMU in 
Deutschland vor allem komplizierter gemacht, &#252;berdies greift sie &#252;bertrieben in die Lebenswirklichkeit und den
zunehmend digitalen Alltag der B&#252;rger ein.
Ausweitung des &#8222;Medienprivilegs&#8220; auch auf Blogger, Influencer, Youtuber
So werden etwa &#252;ber Artikel 85 DSGVO die Mitgliedstaaten aufgefordert, das Recht auf freie Meinungs&#228;u&#223;erung
und Informationsfreiheit einschlie&#223;lich der Verarbeitung zu journalistischen, wissenschaftlichen, k&#252;nstlerischen
oder literarischen Zwecken mit dem Recht auf den Schutz personenbezogener Daten in Einklang zu bringen. Die
AfD-Fraktion hat einen Antrag f&#252;r die Erweiterung dieses &#8222;Medienprivilegs&#8220; auf Blogger, Influencer, Youtuber,
Fotografen und T&#228;tige im Bereich der &#214;ffentlichkeitsarbeit in den Deutschen Bundestag eingebracht, um die
Meinungsfreiheit insgesamt sicherzustellen.2131 Zwar seien auf Bundes- und Landesebene im Zusammenhang 
mit der DSGVO spezielle Vorschriften zum Schutz der Meinungsfreiheit erlassen worden, doch beschr&#228;nkten
diese sich auf die institutionalisierte Presse. Kritische Blogger oder Pressesprecher von Vereinen m&#252;ssten aber
in gleicher Weise in ihrem Grundrecht auf Meinungsfreiheit gesch&#252;tzt werden.2132 
Die AfD-Fraktion fordert den Gesetzgeber zu einer kritischen, durch Empirie gest&#252;tzten Bewertung der DSGVO
und einer entsprechenden Reform des Instruments mit Augenma&#223; auf europ&#228;ischer Ebene auf. Die DSGVO hat
sich allen guten Absichten zum Trotz zum B&#252;rokratiemonster entwickelt, das deutsche und europ&#228;ische
Startups und KMU im weltweiten Wettbewerb tendenziell behindert. Diese sind auf gro&#223;e Mengen
maschinenlesbarer, strukturierter, pseudonymisierter Daten zum Training ihrer KI-Algorithmen angewiesen &#8211; diese von ihren 
Nutzern zu erheben, zu erwerben und zu verarbeiten, erschwert ihnen die DSGVO, w&#228;hrend das Kapital der seit
Jahren dominanten Konzerne in Gestalt ihrer gewaltigen Datenvolumina unabl&#228;ssig Renditen abwirft. In dem
genannten Regelwerk wirkt das &#252;berholte Konzept einer individuellen Datensparsamkeit nach, an dessen Stelle
die Datensouver&#228;nit&#228;t m&#252;ndiger B&#252;rger und eigenverantwortlicher Konsumenten treten muss.
Ausblick
Am 24. Juni 2020 hat die Europ&#228;ische Kommission eine erste Evaluation der DSGVO dem Europ&#228;ischen
Parlament und dem Rat vorgelegt.2133 Die Kommission zieht ein grunds&#228;tzliches positives Fazit zu den ersten beiden
Jahren der Praxis der DSGVO; so sieht sie die Ziele der St&#228;rkung des Rechts des Einzelnen auf Schutz
personenbezogener Daten sowie die der Gew&#228;hrleistung des freien Verkehrs personenbezogener Daten innerhalb der EU
2127 Artikel 6 Absatz 1 DSGVO. Diese &#8222;Einwilligung&#8220; besteht zumeist im Setzen eines H&#228;kchens unter eine ellenlange, in einer f&#252;r viele
Menschen abschreckenden Sprache der Justiz formulierte Erkl&#228;rung, die angesichts ihres Volumens kaum jemand liest, geschweige
denn vollumf&#228;nglich versteht.
2128 Artikel 4 Absatz 2 DSGVO.
2129 Artikel 97 Absatz 1 der DSGVO schreibt f&#252;r den Mai 2020 einen ersten Evaluationsbericht der Europ&#228;ischen Kommission an das
Europ&#228;ische Parlament fest, danach weitere Evaluationen im Vierjahresrhythmus.
2130 Die in den Artikeln 40 und 42 der DSGVO benannten &#8222;besonderen Bed&#252;rfnisse von Kleinstunternehmen sowie kleinen und mittleren
Unternehmen&#8220; bez&#252;glich des zu erbringenden Datenschutzes mit den begrenzten Mitteln eines Start-ups werden von ihr gerade nicht
differenziert erfasst. Eine solche Differenzierung ist bei der erforderlichen Reform der DSGVO unbedingt zu garantieren.
2131 Bundestagsdrucksache 19/7430.
2132 Vgl. Fraktion der AfD im Deutschen Bundestag (2020): Cotar: Versch&#228;rfung des NetzDG ebnet Weg f&#252;r &#8222;DDR 2.0&#8220;.
2133 Vgl. Europ&#228;ische Kommission (2020): Mitteilung der Kommission an das Europ&#228;ische Parlament und den Rat.
erreicht. 2134 Sie ist weiter der Ansicht, dass in einer Wirtschaft, die zunehmend auf der Verarbeitung
personenbezogener Daten beruhe, die DSGVO ein Instrument darstelle, mit dem der Einzelne eine bessere Kontrolle &#252;ber
die eigenen Daten bekomme.2135 Nicht zuletzt sieht sie die EU in einer internationalen Vorreiterrolle im Bereich
des Datenschutzes; so h&#228;tten L&#228;nder in vielen Regionen der Welt sich ein legislatives Beispiel an der DSGVO
genommen.2136 Allerdings attestiert die Kommission auch, dass nach zwei Jahren noch nicht ausreichend
Erfahrungen aus der Praxis vorl&#228;gen, um eine umfassende Beurteilung des Regelwerkes abgeben zu k&#246;nnen.
Unterschiedlich gro&#223;e Unternehmen unterschiedlich behandeln
Ausdr&#252;cklich erkennt die Kommission nach R&#252;ckmeldungen aus der Wirtschaft an, dass die Anwendung der
DSGVO gerade f&#252;r kleine und mittlere Unternehmen (KMU) eine Herausforderung bedeute. So h&#228;tten die
Datenschutzbeh&#246;rden Muster f&#252;r Verarbeitungsvertr&#228;ge bereitgestellt, um die Anwendung der DSGVO f&#252;r KMU
k&#252;nftig zu erleichtern.2137 Das ist nach Ansicht der AfD-Fraktion nicht ausreichend, vielmehr gehen diese
Ma&#223;nahmen an der Realit&#228;t vieler KI-Start-ups in Deutschland vorbei. So zieht auch der Bundesverband
Informationswirtschaft, Telekommunikation und neue Medien, Bitkom e. V., eine durchwachsene Bilanz nach zwei Jahren
DSGVO: &#8222;Die DS-GVO reglementiert jeden einzelnen Datenverarbeitungsvorgang und jede Datenerhebung.
Vereine, Startups und Gro&#223;konzerne werden &#252;ber denselben Kamm geschoren und nicht differenziert behandelt. 
Die in der DS-GVO vorgesehenen Ausnahmen f&#252;r kleinere Unternehmen kommen in der Praxis so gut wie nie
zum Tragen. Dabei sollten Art und Umfang der Datenverarbeitungen ausschlaggebend f&#252;r die Verpflichtungen
sein, auch sollte man die Regeln grunds&#228;tzlich vereinfachen.&#8220;2138 Einer Umfrage des Bitkom zufolge sehen
derzeit acht von zehn Unternehmen in Deutschland Datenschutzanforderungen als die gr&#246;&#223;te H&#252;rde beim Einsatz
neuer Technologien. 
Raus aus der technischen Welt der 1970er-Jahre
Diese deprimierende Perspektive ist f&#252;r die AfD-Fraktion eine direkte Folge der &#220;berreglementierung der
personenbezogenen Datenverarbeitung durch Unternehmen im Namen der DSGVO. Der Gesetzgeber verfolgt das
hehre Ziel, die Pers&#246;nlichkeitsrechte der Menschen zu sch&#252;tzen, orientiert sich dabei aber defensiv an der
technischen Welt der 1970er Jahre.2139 Heute werden, dabei die Grenzen von L&#228;ndern, Kontinenten und Zeitzonen
&#252;berschreitend, &#252;ber mobile Endger&#228;te personenbezogene Daten auf Social-Media-Profilen, in Messenger-
Diensten, auf Auskunfts-Portalen und bei Streaming-Anbietern generiert, kombiniert, geteilt und interpretiert. Diesem
Paradigmenwechsel hin zu Allt&#228;glichkeit, Digitalit&#228;t und Komplexit&#228;t personenbezogener &#8222;Daten&#8220; wird die
DSGVO mit ihrer Schwerf&#228;lligkeit nicht gerecht, ihre Bestimmungen halten mit der rasanten technischen
Entwicklung (etwa Blockchain, KI, Smart Cities, biometrische Gesichtserkennung) nicht Schritt. Sie ist nach
Auffassung der AfD-Fraktion beileibe kein Werkzeug, das geeignet w&#228;re, die Position deutscher und europ&#228;ischer
KI-Start-ups im globalen Wettbewerb mit den Konzernen aus den USA und China zu st&#228;rken. Daher ist eine
grunds&#228;tzliche &#220;berarbeitung der DSGVO im genannten Sinne unabdingbar &#8211; zu einer solchen m&#246;ge, so die
Position der AfD-Fraktion, der Deutsche Bundestag die Bundesregierung in Kooperation mit den europ&#228;ischen
Partnern auffordern.
Sondervotum zu Kapitel 2 der AG-Berichte der Projektgruppe 2 &#8222;KI und Staat&#8220; (&#8222;AG
2: Smart City und Open Data&#8220;) des Abgeordneten Dr. Marc Jongen sowie der
Abgeordneten Joana Cotar und Peter Felser
Der AfD-Text zum Thema &#8222;Voraussetzungen und Auswirkungen staatlicher Einflussnahmen zur Verwirklichung
von Smart City/Smart Country/Smart Region&#8220; im Teilbericht der Projektgruppe &#8222;KI und Staat&#8220; der Enquete-
Kommission K&#252;nstliche Intelligenz wurde bis auf einige wenige Aspekte nicht &#252;bernommen, sondern von den
Vertretern der anderen Fraktionen im Abstimmungsverfahren aus dem Teilbericht herausreklamiert. In diesem
Beitrag wurde insbesondere auf den Kontext des Themas abgehoben, der hier zu adressieren w&#228;re. Es zeigt sich, 
dass es kritischer Anmerkungen zum Framing des Begriffes &#8222;smart&#8220; bedarf, um zu einer sachgem&#228;&#223;en Bewertung
2134 Ebd., S. 5.
2135 Ebd., S. 2.
2136 Ebd., S. 3.
2137 Ebd., S. 12.
2138 Bitkom e. V. (2020): Zwei Jahre DS-GVO: Bitkom zieht durchwachsene Bilanz.
2139 Vgl. Schallbruch (2018): Schwacher Staat im Netz, S. 181.
des Konzeptes zu kommen. Nur dann kommt auch eine entsprechende Validit&#228;t der Handlungsempfehlungen
zustande.
In der jetzigen Endfassung des Teilberichtes der Projektgruppe 2 zum Thema &#8222;Smart City&#8220; findet sich stattdessen
eine vorwiegend affirmativ-technizistische Betrachtung, der es an einer kritischen Gesamtw&#252;rdigung der Smart-
City-Konzepte mangelt. Aus diesem Grund hat sich die AfD-Fraktion entschlossen, f&#252;r diesen Teil des Berichts
der Projektgruppe 2 &#8222;KI und Staat&#8220; ein eigenes Sondervotum einzubringen.
&#8222;Smart City&#8220;-Konzepte: Motivation, Perspektiven und Interessenlagen unter besonderer
Ber&#252;cksichtigung der Rolle der K&#252;nstlichen Intelligenz
Die digitale Transformation (in) der Stadt zeigt Auswirkungen in mehreren Bereichen. So soll sie im st&#228;dtischen
Verwaltungsapparat Beh&#246;rdeng&#228;nge ersparen, st&#228;dteplanerische Entscheidungsprozesse transparenter machen
oder Mobilit&#228;t, den Energie- und Ressourceneinsatz und &#252;bergreifend Nachhaltigkeit optimieren. Daf&#252;r ist es
notwendig, den gesamten st&#228;dtischen Raum mit Kameras, Chips und Sensoren auszustatten, die alle erfassten 
Daten in einer Cloud abrufbar machen. Auf diese Weise kommt es zu einem st&#228;ndigen Austausch zwischen
Stadtbewohnern und der IT respektive deren Eignern und Betreibern. Der Algorithmus meldet, wenn die
Abfalltonne voll ist oder leitet den M&#252;ll durch unterirdische Rohre in die Deponien.2140 Beschleunigungssensoren im
Smartphone senden mittels App die GPS-Daten von Stra&#223;ensch&#228;den an die Stadtverwaltung, die dann
Reparaturdrohnen ausschw&#228;rmen l&#228;sst. Intelligente Algorithmen leiten den Verkehr so, dass Staus weitgehend
vermieden werden. Alles soll wie in einer gut ge&#246;lten Maschine ineinandergreifen. 
Die Zusammenarbeit von Stadtverwaltungen mit Hochschulen und Technologiezentren ist mitentscheidend f&#252;r
den Know-how-Aufbau. Letztere k&#246;nnen die St&#228;dte dabei unterst&#252;tzen, die Daten, die sie generieren, zu
interpretieren und ihren Wert f&#252;r neue Prozesse zu erkennen.
Anwendungen wie Deep Learning, Mustererkennung oder Maschinelles Lernen zeigen Korrelationen und Muster
auf, die f&#252;r Menschen auf den ersten Blick nicht erkennbar sind. Allerdings ist hierf&#252;r eine gro&#223;e Menge an
Datenpunkten notwendig, sodass k&#252;nstliche Intelligenz im &#246;ffentlichen Raum oder bei Projekten mit Beteiligung 
der &#246;ffentlichen Hand nur dann sinnvoll einzusetzen ist, wenn eine hinreichend gro&#223;e Menge an frei zug&#228;nglichen
Trainingsdaten (Open Data2141) vorhanden ist. Das ist bisher aber nur ansatzweise der Fall. KI hat deshalb in
vielen Smart-City-Projekten in Deutschland eine noch eher marginale Bedeutung.2142 Hierbei mag auch eine
Rolle spielen, dass die Smart-City-Idee bisher nicht differenziert genug zwischen den Problemen und Potenzialen 
unterschiedlich gro&#223;er R&#228;ume &#8211; vom Dorf &#252;ber das Mittelzentrum bis zur Metropole &#8211; unterscheidet.
Soll KI im h&#246;heren Ma&#223;e nutzbar gemacht werden k&#246;nnen, muss es deshalb das Ziel sein, &#8222;so viel als m&#246;glich
an Daten verf&#252;gbar zu machen&#8220;, wie auch der Teilbericht der Projektgruppe 2 &#8222;KI und Staat&#8220; hervorhebt.2143 
Eine Etappe dorthin k&#246;nnte der &#8222;Musterdatenkatalog&#8220; sein, den eine Reihe deutscher Kommunen im April 2020 
ver&#246;ffentlicht hat; hier finden sich unter anderem Echtzeitdaten zur Bev&#246;lkerungsentwicklung, Daten zu freien
Parkpl&#228;tzen oder auch zur Trinkwasserqualit&#228;t. Der Katalog kategorisiert die verf&#252;gbaren Open Data und
verweist auf ihre Quelle in den Kommunen.2144 
Wirtschaftliche Interessen hinter der Smart-City-Bewegung
Das suggestive Framing, dass sich das Leben der Bewohner der &#8222;Smart Cities&#8220; durch technische Innovationen,
die durch k&#252;nstliche Intelligenz weiter optimiert werden, einfacher und besser gestaltet, relativiert sich bei einem
Blick auf die wirtschaftlichen Interessen, die hinter der &#8222;Smart-City&#8220;-Bewegung stehen. Mit dieser Bewegung 
geht n&#228;mlich die Propagierung einer grenzenlosen Ausdehnung des Internets einher. H&#228;ufig werden in diesem
2140 Vgl. Mink (2015): In Helsinki ersetzt ein Mega-Sauger die M&#252;llabfuhr.
2141 Zur Definition Open Data vgl. Kapitel 2.1 des AG-Berichts 2 des Berichts der Projektgruppe &#8222;KI und Staat&#8220; [Einf&#252;hrung].
2142 Vgl. hierzu die Antwort der Bundesregierung auf die Kleine Anfrage der Fraktion der AfD auf Bundestagsdrucksache 19/12694:
&#8222;Potentiale des Einsatzes k&#252;nstlicher Intelligenz werden in einzelnen Anwendungsbereichen von Smart Cities gesehen, wie
beispielsweise im Mobilit&#228;tsbereich&#8220;. Wolfram Geier, Abteilungsleiter im Bundesamt f&#252;r Bev&#246;lkerungsschutz und Katastrophenhilfe (BBK),
urteilt: &#8222;Beim Einsatz sog. k&#252;nstlicher Intelligenz (KI) stehen wir jedoch noch ganz am Anfang.&#8220;, vgl. Geier (2020): Interview: Zu 
unserer Sicherheit und Resilienz m&#252;ssen wir alle beitragen, S. 702.
2143 Siehe Kapitel 2.1 des AG-Berichts 2 des Berichts der Projektgruppe &#8222;KI und Staat&#8220; [Einf&#252;hrung].
2144 Vgl. Piron (2020): Neue Open Data-Plattform soll den Weg zur Smart City ebnen.
Zusammenhang Zahlen kolportiert, die von einem US-Netzwerkausr&#252;ster stammen. Diese Zahlen sollen die
Notwendigkeit des Aus- oder Umbaus von St&#228;dten zu &#8222;Smart Cities&#8220;2145 unterstreichen. Das heute schon
milliardenschwere Marktvolumen, das sich mit &#8222;Smart Cities&#8220; und dem &#8222;Internet der Dinge&#8220; verbindet, steuert demnach,
so die Botschaft, auf exponentielle Wachstumsraten zu. Die IT-Konzerne im Telekommunikationsbereich haben
also handfeste Gr&#252;nde, das g&#228;ngige &#8222;Smartness&#8220;-Framing weiter zu befeuern. &#8222;Smart&#8220; soll daf&#252;r stehen, dass
immer mehr &#8222;Dinge&#8220; &#252;ber das Internet verbunden werden und auf Daten oder Ereignisse aus ihrer Umgebung
reagieren k&#246;nnen. Dazu wird Informations- und Kommunikationstechnologie in die verschiedenen Bereiche
st&#228;dtischen Lebens integriert.2146 
Das Verbinden von immer mehr Ger&#228;ten im &#8222;Internet der Dinge&#8220; bedeutet nach dem Informatiker Martin
Schallbruch, bis 2016 Abteilungsleiter f&#252;r Informationstechnik im Bundesministerium des Innern (BSI), eben auch das
Verbinden potenziell &#8222;schlechter Software mit wichtigen Anwendungen&#8220;.2147 Dass jeder Nutzer f&#252;r die
m&#246;glicherweise defizit&#228;re Software seines Ger&#228;tes verantwortlich gemacht wird, scheint indes keine sinnvolle L&#246;sung zu
sein. Gleiches gilt f&#252;r den Hersteller, bei dem im &#220;brigen die Frage im Raum steht, wie weit dessen
Verantwortung reichen soll. Der Staat sei hier gefordert, vern&#252;nftige und praxistaugliche Regeln der
Verantwortungszuweisung bereitzustellen.2148 
Smart-City-Konzepte als Sozialtechnologie im digitalen Gewand
&#8222;Smart City&#8220;-Konzepte k&#246;nnen nicht verbergen, eine Sozialtechnologie im digitalen Gewand zu sein. Die
Konzepte der Sozialtechnologie fu&#223;en auf dem Dogma der Machbarkeit. Hierf&#252;r werden auch Instrumente und
Modelle aus dem naturwissenschaftlich-technischen Bereich genutzt und zum Zwecke der Zielerreichung eingesetzt.
Sozialtechnologie weist im Weiteren ein Definitionsmerkmal auf, das man als &#8222;Instrumentalit&#228;t&#8220; bezeichnen
kann. Sie verfolgt ausdr&#252;cklich einen Zweck (bzw. eine Systemfunktion), der auf eine planm&#228;&#223;ige Weise
durchgef&#252;hrt und in der Praxis umgesetzt werden soll.2149 
Auch die f&#252;hrenden K&#246;pfe des Silicon Valley &#8211; die entweder (oder simultan) Finanziers oder (und) Ingenieure
sind, also daran gewohnt sind, menschliches Verhalten in Zahlen, Grafiken und Intervallen abzubilden, zu
analysieren, zu bewerten und vorherzusagen &#8211; sind der Auffassung, dass sich &#8222;soziale Interaktionen mit Big-Data-
Methoden berechnen und vorhersagen lassen. Die disruptiven IT-Unternehmer aus dem Silicon Valley werden
von der Ansicht angetrieben, dass der Staat mit seinem tradierten Tableau von Verwaltungsakten und Gesetzen
den Herausforderungen einer datengetriebenen Gesellschaft nicht mehr gewachsen sei. Er ist in ihren Augen eine
&#8222;&#252;berkommene Hardware&#8220;, die mit maschinellem Lernen, KI und Robotik zu aktualisieren sei.2150 
Dieses &#8222;mechanistische Weltbild&#8220;2151 steht in direktem Zusammenhang mit der zunehmenden Wertigkeit von
Rankings, Wettbewerben oder Vergleichswerten im Privaten, von denen auch der urbane Lebensraum erfasst
wird, der zunehmend &#8222;Smartness&#8220;-Kriterien unterworfen wird. Daraus leitet sich zunehmend auch die
Kreditw&#252;rdigkeit einer Stadt ab. Entsprechend gro&#223; ist der Zwang zur Offenheit gegen&#252;ber Smart-City-Konzepten, 
auch mit Blick auf die eigene Position auf den Anlagem&#228;rkten.2152 
2145 Evans (2011): Das Internet der Dinge, S. 3. Waren es im Jahre 2010 noch rund 12,5 Milliarden Ger&#228;te, die miteinander vernetzt
waren, sollen es im Jahre 2020 laut dem US-TI-Konzern Cisco bereits 50 Milliarden Ger&#228;te sein.
2146 Dass es sich bei dem Begriff &#8222;smart&#8220; um ein &#8222;Buzzword&#8220; handelt, verdeutlichen Magdalena Konieczek-Woger und Alexander Naeth
in ihrer Untersuchung, vgl. Konieczek-Woger und Naeth (2020): Achtung: Smart! - M&#246;glichkeiten und Grenzen der Idee der &#8222;Smart
City&#8220; f&#252;r deutsche Kommunen, S. 43 f.
2147 Schallbruch (2018): Schwacher Staat im Netz, S. 72.
2148 Vgl. Schallbruch (2018): Schwacher Staat im Netz, S. 193.
2149 Vgl. Knoblauch (2006): Sozialtechnologie, Soziologie und Rhetorik, S. 1-2.
2150 Vgl. Lobe (2019): Wie Technologiekonzerne die Stadt optimieren wollen. Sie stehen damit in der Tradition dessen, was Richard
Barbrook und Andy Cameron als &#8222;Kalifornische Ideologie&#8220; kennzeichneten; vgl. Barbrook und Cameron (1997): Die kalifornische
Ideologie.
2151 Lobe (2018): Computer sind nicht nur besser als Menschen. Sie wissen auch besser, was gut und was b&#246;se ist.
2152 Vgl. hierzu ausf&#252;hrlich Morozov und Bria (2017): Die smarte Stadt neu denken, S. 23.
Handlungsempfehlungen
&#8226; Die Digitalisierung stellt die Frage nach dem Versorgungsauftrag, ja, der Identit&#228;t des Staates in den meisten
Lebensbereichen neu.2153 Es haben sich neue Anforderungen an eine Grundversorgung entwickelt, wie z. B. 
im Hinblick auf ein leistungsf&#228;higes Internet. Ein zentrales Desiderat ist deshalb, dass der deutsche Staat
hier mit Blick auf die fortschreitende Digitalisierung mit aller Klarheit den Versorgungsauftrag definiert 
und digitale Infrastrukturplanung betreibt. Bleibt der Staat diese Definition schuldig (oder l&#228;sst er sie im 
Unklaren), werden die gro&#223;en IT-Konzerne sukzessive die Leistungen &#252;bernehmen, die vor der
Digitalisierung noch in der Verantwortung, Steuerung und Kontrolle des Gemeinwesens waren.2154 Das kann nicht im 
Sinne einer selbstbestimmt und individuell betriebenen Entwicklung von &#8222;Smart Cities&#8220; in Deutschland 
sein. Hier vor allem ergibt sich deshalb ein hoher Handlungsbedarf.
&#8226; Von zentraler Bedeutung mit Blick auf den weiteren Ausbau von Smart-City-Komponenten in Deutschland
ist die Planung einer effektiven Sicherheitsarchitektur gegen Cyber-Attacken.2155 Diese Architektur bedarf 
einer eindeutigen Adressierung im Hinblick auf deren Verantwortungsebenen. Eine solche Architektur muss
&#8222;aus einer ausgewogenen Mischung von Schutzmechanismen, fehler- und angriffserkennenden Sensoren
und effektiven Reaktionsmechanismen&#8220; bestehen, wie es unter anderem Dirk Loomans und Manuela Matz
anregen. Sollte es dennoch zu erfolgreichen Cyber-Angriffen kommen, muss pr&#228;ventiv Sorge getragen
werden, um &#8222;Domino- und Kaskadeneffekte&#8220;, die einen kompletten &#8222;Blackout&#8220; mit all seinen verheerenden
Konsequenzen nach sich ziehen, unterbinden zu k&#246;nnen. 
&#8226; Ein weiteres Handlungsfeld ist vor dem Hintergrund der Ausschreitungen in Stuttgart2156 oder in
Frankfurt/Main2157 die Sicherheit im &#246;ffentlichen Raum. Hier ist es angezeigt &#8211; im Rahmen des geltenden
Datenschutzes, &#252;ber deren &#220;berwachung z. B. ein Ombudsmann benannt werden k&#246;nnte &#8211;, auch diejenigen
M&#246;glichkeiten zu pr&#252;fen und voranzutreiben, die aus einer &#8222;Smart City&#8220; eine &#8222;Safe City&#8220; machen. Zu pr&#252;fen 
w&#228;re unter anderem die Videotechnik im st&#228;dtischen Raum zum Zwecke der Pr&#228;vention und Verfolgung
von Straftaten und Straft&#228;tern. Das Spektrum k&#246;nnte hier vom Schutz von Gro&#223;veranstaltungen bis hin zur
Pr&#228;vention gegen sich anbahnende Krawalle reichen. Mit Blick auf die Entwicklungsfortschritte im Hinblick
auf die Kameratechnik und den Einsatz von KI-gest&#252;tzten Analysetechniken2158 verspricht dieser Einsatz
ein Mehr an Sicherheit im st&#228;dtischen Raum. Fortschritte sind auch im Hinblick auf den Katastrophenschutz
zu erwarten, sei es nun bei Br&#228;nden oder &#220;berflutungen oder bei der Lenkung von Menschengruppen. In 
manchen Bereichen werde das Videobild gar nicht mehr ben&#246;tigt, sondern nur noch die Informationen. Die
M&#246;glichkeiten, die der Einsatz von Videotechnik hier aufzeigt, macht sie zu den Kernkomponenten der 
Smart-City-Infrastruktur.2159
&#8226; Verkehrslenkung, Cyber-Sicherheit, Kriminalit&#228;tspr&#228;vention sowie die Steigerung der Sicherheit im
&#246;ffentlichen Raum w&#228;ren demnach die erfolgversprechendsten Anwendungsfelder von Smart-City-Techniken,
gerade auch mit Blick auf die Einbindung K&#252;nstlicher Intelligenz. Entsprechend sollten hier vor allem die
Aktivit&#228;ten vorangetrieben werden. 
Alle anderen Anwendungsbereiche, die unter dem Schlagwort &#8222;Smart&#8220; auf eine grenzenlose Ausdehnung des
Internets hinauslaufen, sollten aufgrund der damit einhergehenden Gefahren, die sich unter anderem an dem
Stichwort &#8222;&#220;berwachungskapitalismus&#8220;2160 festmachen, vor dem Hintergrund der Bewahrung der
B&#252;rgerfreiheiten und der Gef&#228;hrdungen und Sicherheitsprobleme, die im Zusammenhang mit der Cybersicherheit zu erwarten
sind, nur sehr zur&#252;ckhaltend erschlossen werden.
2153 Vgl. hierzu Schallbruch (2018): Schwacher Staat im Netz, S. 207. Hier w&#228;re auch die Frage des steigenden Energieverbrauches durch 
Smart-City-Projekte zu thematisieren, der f&#252;r die Bundesregierung noch eine Blackbox darstellt, wie ihre Antwort auf eine Kleine
Anfrage der Fraktion der AfD auf Bundestagsdrucksache 19/12694 deutlich macht: &#8222;Der Bundesregierung liegen noch keine
Kenntnisse vor, ob in diesen oder den geplanten [Smart-City-]Modellprojekten die besondere Frage des Strombedarfs der IKT-
Infrastrukturen eine Rolle spielen wird.&#8220;, S. 9.
2154 Vgl. hierzu insbesondere Schallbruch (2018): Schwacher Staat im Netz, S. 204 ff.
2155 Siehe auch das Sondervotum 3.7 [Sondervotum zu Kapitel 2 der AG-Berichte der Projektgruppe 2 &#8222;KI und Staat&#8220; (&#8222;AG 2: Smart
City und Open Data &#8220;) des Abgeordneten Dr. Marc Jongen sowie der Abgeordneten Joana Cotar und Peter Felser].
2156 Vgl. z. B. Bilger (2020): Die Polizei ist erneut mit einem gro&#223;en Aufgebot im Einsatz.
2157 Vgl. z. B. Dicke et al. (2020): Feldmann bricht Urlaub ab - N&#228;chtlicher Besuch auf Opernplatz geplant.
2158 Vgl. Salder (2020): Kommunale Videosicherheitstechnik im Aufbruch: von der Verbrechensbek&#228;mpfung zum &#8222;Smart-City-Sensor&#8220;,
S. 718.
2159 Vgl. Salder (2020): Kommunale Videosicherheitstechnik im Aufbruch: von der Verbrechensbek&#228;mpfung zum &#8222;Smart-City-Sensor&#8220;,
S. 723 f.
2160 Zuboff (2018): Das Zeitalter des &#220;berwachungskapitalismus.
Sondervotum zu Kapitel 3.1 der AG-Berichte der Projektgruppe 2 &#8222;KI und Staat&#8220;
(&#8222;AG 3: Innere Sicherheit, &#196;u&#223;ere Sicherheit, IT-Sicherheit &#8211; Innere Sicherheit&#8220;) 
des Abgeordneten Peter Felser sowie der Abgeordneten Joana Cotar und Dr. Marc
Jongen 
Aus Sicht der AfD-Fraktion ist dieses Sondervotum notwendig geworden, weil sich die Projektgruppe 2 nur in 
sehr geringem Umfang mit der Verwendung von KI in der Administration von Einwanderungsbewegungen
befasst hat. Die AfD-Fraktion im Deutschen Bundestag h&#228;lt den Einsatz KI-basierter Technologien bei der
Bearbeitung von Visumantr&#228;gen, Aufenthaltsgenehmigungen, Asylantr&#228;gen und Einb&#252;rgerungsverfahren f&#252;r
nutzbringend. Dar&#252;ber hinaus sieht die AfD-Fraktion Chancen, die illegale Einwanderung nach Europa mit Hilfe von
KI effektiv zu unterbinden.
Insgesamt werden pro Jahr an den 173 Visastellen der deutschen Auslandsvertretungen etwa 2,5 Millionen
Visumantr&#228;ge bearbeitet.2161 Die Anzahl der gestellten Asylantr&#228;ge in Deutschland betr&#228;gt seit 2014 j&#228;hrlich etwa
zwischen 160 000 und 750 000.2162 Die Zuwanderung nach Deutschland betr&#228;gt seit 2012 zwischen 1 Million
und 2,2 Millionen Menschen.2163 Diese gro&#223;en Reise- und Wanderungsbewegungen stellen die deutsche
Verwaltung ebenso wie unsere Gesellschaft vor gro&#223;e Herausforderungen.2164 Immer mehr Menschen interagieren mit
verschiedenen Einwanderungsbeh&#246;rden. Es gibt weltweit verschiedenste Bestrebungen, die gro&#223;e Anzahl an
Entscheidungen zu automatisieren, die jeden Tag getroffen werden, wenn Menschen Grenzen &#252;berschreiten oder ein
neues Zuhause suchen. Eine effektive Verarbeitung aller erh&#228;ltlichen Daten und automatisierte
Entscheidungssysteme k&#246;nnen den Verwaltungsaufwand und die Fehlentscheidungen bei den jeweiligen Zulassungsverfahren
minimieren.
In Kanada, den USA, China, Russland und einigen anderen L&#228;ndern werden KI-basierte Analytik (z. B.
Mustererkennung, Vorhersagende Polizeiarbeit, Risikoanalyse, Biometrieverarbeitung) und automatisierte
Entscheidungssysteme bereits seit einiger Zeit verwendet, um die Zuwanderung und die Fl&#252;chtlingsaufnahme zu steuern.
Deutschland kann nach Auswertung der Erfahrungen dieser L&#228;nder und der Definition eigener Standards
Methoden der Zuwanderungs- oder Asylentscheidung etablieren, die sowohl den Zuwanderern und Asylsuchenden als
auch den Einheimischen zugutekommt. Das schlie&#223;t die Bek&#228;mpfung illegaler Migration ein.2165 
Der Begriff &#8222;automatisierte Entscheidungssysteme&#8220; soll sich hier auf eine bestimmte Klasse von Technologien
beziehen, die das Urteil menschlicher Entscheider unterst&#252;tzen. Regression, regelbasierte Systeme, pr&#228;diktive
Analysen, maschinelles Lernen, Deep Learning und neuronale Netze werden genutzt, um eine Entscheidung im
Visum-, Asyl- oder Einb&#252;rgerungsverfahren vorzuschlagen.
Die Einf&#252;hrung automatisierter KI-basierter Systeme wird sich auf die Prozesse und die Ergebnisse von
Entscheidungen auswirken. Das betrifft Entscheidungen, die bislang von Verwaltungsgerichten,
Einwanderungsbeh&#246;rden, Grenzbeamten, Juristen und Verwaltungsangestellten getroffen werden.
Das Bundesamt f&#252;r Migration und Fl&#252;chtlinge (BAMF) hat im Rahmen des Programms &#8222;Integriertes
Identit&#228;tsmanagement &#8211; Plausibilisierung, Datenqualit&#228;t und Sicherheitsaspekte (IDM-S)&#8220; bereits Assistenzsysteme
eingef&#252;hrt. Sie geben den Bearbeitern im Rahmen der Identit&#228;tsfeststellung unterst&#252;tzende Hinweise. Genutzt
werden Verfahren der Bildbiometrie, Namenstransliteration, Namensanalyse, Sprachbiometrie zur
Gro&#223;dialektanalyse und standardisierte Datentr&#228;gerauswertung (v. a. Mobiltelefon).2166 Die Nutzung dieser Assistenzsysteme
beschr&#228;nkt sich jedoch auf die Plausibilit&#228;tspr&#252;fung der vom Antragsteller gemachten Identit&#228;tsangaben. 
Die Zusammenarbeit mit dem Gemeinsamen Extremismus- und Terrorismusabwehrzentrum (GETZ), dem
Gemeinsamen Terrorismusabwehrzentrum (GTAZ) und anderen Sicherheitsbeh&#246;rden k&#246;nnte im Rahmen der
datenschutzrechtlichen M&#246;glichkeiten mittels KI-basierter Datenverarbeitungsmethoden stark ausgebaut werden.
Einige L&#228;nder (Australien, Neuseeland, China) experimentieren im Bereich Vorhersagende Polizeiarbeit mit KI-
basierten Systemen unter Mithilfe von Biometrie- und Gesichtserkennungstechnologien, um zuk&#252;nftige Straft&#228;ter
2161 Weitere Informationen dazu unter: https://www.auswaertiges-amt.de/de/service/visa-und-aufenthalt/-/2231558 (zuletzt abgerufen am
13. Oktober 2020).
2162 Vgl. Bundesamt f&#252;r Migration und Fl&#252;chtlinge (2020): Aktuelle Zahlen - Ausgabe: Juni 2020.
2163 Vgl. Statistisches Bundesamt (2020): Wanderungen zwischen Deutschland und dem Ausland 1991 bis 2019.
2164 Rund 1,6 Millionen der in Deutschland lebenden Menschen sind Zuwanderer. Keine andere gesellschaftliche Teilgruppe ist in der
Kriminalstatistik derart stark &#252;berrepr&#228;sentiert: 11 Prozent der Verd&#228;chtigen von K&#246;rperverletzungen, 15 Prozent der Verd&#228;chtigen
von T&#246;tungsdelikten, 12 Prozent bei den Verd&#228;chtigen von Vergewaltigungen und schweren sexuellen N&#246;tigungen. Vgl.
Bundeskriminalamt (2019): Kriminalit&#228;t im Kontext von Zuwanderung.
2165 Vgl. Azizi und Yektansani (2020): Artificial Intelligence and Predicting Illegal Immigration to the USA.
2166 Vgl. Bundesamt f&#252;r Migration und Fl&#252;chtlinge (2019): Ablauf des deutschen Asylverfahrens.
oder sogar Terroristen zu identifizieren. Die US-amerikanische Einwanderungs- und Zollbeh&#246;rde ICE testete
2018 einen Algorithmus, der gegebenenfalls die Inhaftierung von Migranten empfahl. Die Verwendung dieser
Technologie wurde von ICE jedoch mittlerweile eingestellt und durch die KI-Anwendung &#8222;Rekognition&#8220; von 
Amazon/AWS ersetzt.2167 
Entscheidungen in Einwanderungs- und Fl&#252;chtlingsfragen fallen unter die Rubrik des Verwaltungsrechts. Das
Verwaltungsrecht ist das Recht der Exekutive und der Staatsverwaltung. Das Verwaltungsrecht regelt die
Rechtsbeziehungen des Staates zu den mit dem Staat interagierenden Menschen und die Prozesse innerhalb des
Verwaltungsapparates. F&#252;r den einzelnen Antragsteller haben Entscheidungen in Einwanderungs- und
Fl&#252;chtlingsfragen teilweise drastische Konsequenzen. Die Verfahren innerhalb eines Verwaltungsapparates sind dazu meist
wenig transparent und M&#246;glichkeiten zum Widerspruch sind f&#252;r Zuwanderer oder Fl&#252;chtlinge oft besonders
gering. Daraus ergeben sich Erfordernisse f&#252;r die Entscheidungsprozesse, um die von Deutschland ratifizierten 
Vereinbarungen zum Schutz von Zuwanderern und Fl&#252;chtlingen einhalten zu k&#246;nnen.2168 
Ein wichtiges Ausschlusskriterium f&#252;r den Einsatz KI-basierter Technologien bei der Beurteilung von
Migrationsverfahren sind die rechtlichen und humanit&#228;ren Rahmenbedingungen. Die Rechte von Zuwanderern und
Fl&#252;chtlingen d&#252;rfen durch die Nutzung von Algorithmen nicht verletzt werden. Kanadische Wissenschaftler
haben die Grenzen maschinell gesteuerter Einwanderungs- und Aufenthaltsentscheidungen untersucht und kamen
zu dem Schluss, dass gerade Fl&#252;chtlinge besonders verletzliche und schutzbed&#252;rftige Akteure sind. Ihnen st&#252;nden
kaum Schutzma&#223;nahmen gegen Unrechtm&#228;&#223;igkeiten oder Fehler w&#228;hrend der Antragsverfahren zur Verf&#252;gung.
Die oft komplexe Natur vieler Fl&#252;chtlings- und Einwandererbiografien kann technologisch nicht immer
abgebildet werden. Jeder Zuwanderer oder Fl&#252;chtling muss vor Voreingenommenheit, Diskriminierung,
Datenschutzverletzungen und Verletzungen seiner Menschenrechte gesch&#252;tzt werden.2169 Eine endg&#252;ltige Entscheidung 
sollte durch einen menschlichen Bearbeiter erfolgen. Der maschinelle Bearbeiter darf nur unterst&#252;tzend zur
Beschleunigung und Vereinfachung des Verfahrens genutzt werden. Das Streben nach Effizienz und Sicherheit darf
nicht gegen die Fairness bei der Antragsgestaltung ausgespielt werden.
Auch in der Betrachtung der Migration im internationalen Ma&#223;stab kann die Nutzung von KI-Technologien einen
Beitrag zu mehr Transparenz und Verst&#228;ndnis liefern. Die globalen Migrationsbewegungen sind hochkomplexe
Systeme, deren Management oder Vorhersage sich &#228;u&#223;erst schwierig gestalten.2170 Gleichzeitig besteht ein hohes
Interesse, diese Prozesse zu begreifen oder sogar zu steuern. Effektive Grenzkontrollen, l&#228;nder&#252;bergreifende
Sicherheitsma&#223;nahmen, globales Migrationsmanagement und Verhinderung illegaler Migration sind
Herausforderungen, die in der globalisierten Welt des 21. Jahrhunderts oft die Komplexit&#228;tsgrenzen herk&#246;mmlicher
Entscheidungsprozesse &#252;bersteigen. Hinzu kommen St&#246;rfaktoren wie kriminelle Migration und steigende
Fremdenfeindlichkeit. Alle diese Faktoren und Ma&#223;nahmen stehen im Spannungsfeld von nationalem und internationalem
Recht und st&#252;tzen sich auf global g&#252;ltige Normen der Menschenrechte und der Rechtsstaatlichkeit.
Um die Abw&#228;gung bei automatisierten Entscheidungsfindungen in der Zuwanderungs- und Asylpolitik
transparent zu gestalten, sollte mit der Einf&#252;hrung KI-basierter Entscheidungssysteme auch organisatorisch auf diese
Technologie reagiert werden. Das BAMF k&#246;nnte ein unabh&#228;ngiges Gremium einrichten, das sich mit der
&#220;berpr&#252;fung aller vom BAMF verwendeten automatisierten Entscheidungssysteme befasst und Verwendung von KI-
Technologie &#246;ffentlich macht. Dar&#252;ber hinaus k&#246;nnte au&#223;erhalb des BAMF eine Task Force eingerichtet werden,
die neben Wissenschaft und Gesellschaft wichtige Akteure aus der Politik zusammenbringt, um die
Auswirkungen automatisierter Entscheidungssysteme abzusch&#228;tzen.
Sondervotum zu Kapitel 3.1 der AG-Berichte der Projektgruppe 2 &#8222;KI und Staat&#8220;
(&#8222;AG 3: Innere Sicherheit, &#196;u&#223;ere Sicherheit, IT-Sicherheit &#8211; Innere Sicherheit&#8220;) 
des Abgeordneten Peter Felser sowie der Abgeordneten Joana Cotar und Dr. Marc 
Jongen 
Die AfD-Fraktion im Deutschen Bundestag stellt fest, dass sich KI-basierte Technologien f&#252;r den Bereich des
polizeilichen Einsatztrainings sowie der Vor- und Nachbereitung von Eins&#228;tzen besonders eignen. Die konkrete
2167 Weitere Informationen dazu unter: https://docs.aws.amazon.com/rekognition/latest/dg/what-is.html (zuletzt abgerufen am 13.
Oktober 2020).
2168 Vgl. Engler und Schneider (2015): Fl&#252;chtlingsrecht: Der internationale Rahmen.
2169 Vgl. Molnar und Gill (2018): Bots at the Gate.
2170 Vgl. International Organization for Migration (2020): World migration report 2020.
Nutzung von KI im Polizeidienst ist aus unserer Sicht in der Projektgruppe 2 der Enquete-Kommission nicht 
ausreichend thematisiert worden, weshalb wir dieses Sondervotum dem Projektgruppenbericht hinzuf&#252;gen.
Das polizeiliche Einsatztraining steht seit jeher vor dem Problem der mangelnden Realit&#228;tsn&#228;he. Virtuelle
Trainingsumgebungen eignen sich hier besonders, um wirklichkeitsnahe Einsatzszenarien darzustellen. Die Rollen
der anderen Personen (z. B. Unbeteiligte, T&#228;ter) werden in diesen Szenarien von NPC2171 &#252;bernommen, deren 
Reaktionen und Handlungsweisen von einem KI-Algorithmus bestimmt werden. Derartige Lagesimulatoren
werden in einigen L&#228;ndern intensiv genutzt.2172 Die Anlagen sind sehr kostenintensiv und haben einen hohen
Wartungsaufwand. Dem gegen&#252;ber stehen der Zugewinn an Sicherheit und das hohe Ma&#223; an realer Lageabbildung.
Im polizeilichen Schie&#223;training mit scharfer Munition kann der Schwerpunkt auf die Handhabung der Waffe
gelegt werden. Dar&#252;ber hinaus ergibt sich eine Kostenersparnis durch die geringere Nutzungsintensit&#228;t
herk&#246;mmlicher polizeilicher Schie&#223;anlagen.
Bei der Planung, F&#252;hrung und Auswertung bestimmter polizeilicher Operationen kann der Einsatz KI-basierter
Systeme die Sicherheit aller Beteiligten erh&#246;hen und wesentlich zum Erfolg einer Operation beitragen. Im
milit&#228;rischen Bereich hat KI bereits vor einigen Jahren Einzug in die Operationsplanung gehalten. Der erzielte Nutzen
l&#228;sst sich auch f&#252;r Polizeibeh&#246;rden realisieren.2173 Algorithmen k&#246;nnen in zahlreichen Teilbereichen der
polizeilichen Operationsplanung und F&#252;hrung zum Einsatz kommen. Beispielhaft sind zu nennen:
&#8226; Infrastrukturmodellierung: unbekannte oder unsichtbare Gel&#228;ndeabschnitte oder Geb&#228;udeteile errechnen
und darstellen
&#8226; Tactical Prediction2174: Mit welcher Wahrscheinlichkeit werden sich Akteure (Unbeteiligte, Geiseln, T&#228;ter)
auf eine bestimmte Art und Weise verhalten?
&#8226; Simulationen m&#246;glicher Einsatzszenarien
&#8226; Post-operative Auswertung: Juristische und taktische Auswertung der Ereignisse, Lernergebnis f&#252;r sp&#228;tere
Eins&#228;tze
Ein Austausch mit den europ&#228;ischen Partnern ist zwingend erforderlich und w&#252;rde die Trainingsdatenmenge
vergr&#246;&#223;ern sowie Kosten minimieren.
Sondervotum zu den Kapiteln 3.1 und 3.2 der AG-Berichte der Projektgruppe 2 
&#8222;KI und Staat&#8220; (&#8222;AG 3: Innere Sicherheit, &#196;u&#223;ere Sicherheit, IT-Sicherheit &#8211; Innere 
Sicherheit&#8220; und &#8222;&#196;u&#223;ere Sicherheit&#8220;) des Abgeordneten Peter Felser sowie der 
Abgeordneten Joana Cotar und Dr. Marc Jongen
Die AfD-Fraktion im Deutschen Bundestag h&#228;lt den Einsatz KI-basierter Technologien in der der Objekt- und 
Raum&#252;berwachung f&#252;r gewinnbringend. Das vorliegende Sondervotum bildet eine thematische Erweiterung zum
Projektgruppenbericht, der die Absicherung und &#220;berwachung von R&#228;umen, z. B. Staatsgrenzen, nur marginal
und aus Sicht der AfD-Fraktion nicht ausreichend thematisiert.
Moderne &#220;berwachungssysteme, die KI-Algorithmen und maschinelles Lernen verwenden, sind in der Lage, 
Menschenmassen &#252;ber auf Drohnen oder fest installierte Optiken in Echtzeit autonom zu scannen und eine
Vielzahl m&#246;glicher Bedrohungen zu identifizieren. Die Daten&#252;bertragung erfolgt meist &#252;ber Live-Streaming-Video-
Feeds mit sehr geringer Latenz.
Die Systeme k&#246;nnen alles erkennen, was der Anwender in den Datensatz des Systems einspeist, einschlie&#223;lich 
vermisster oder gesuchter Personen, Gegenst&#228;nde (z. B. Waffen) oder Fahrzeuge. Dies geschieht durch schnelle 
Echtzeitanalysen verschiedener Parameter (Gesichtserkennung, Ganganalyse, Objekterkennung, Lippenlesen
usw.). Vorreiter bei der Anwendung dieser Technologien sind Indien und Kanada. In Gro&#223;britannien steht ein
&#228;hnliches System vor der Akkreditierung durch die Polizeibeh&#246;rden.2175 
Die im Text des Gesamtberichts der Kommission genannten Bedenken gegen&#252;ber der Erfassung, Speicherung
und Auswertung der Daten Unbeteiligter k&#246;nnen technisch ausger&#228;umt werden. Der Algorithmus verfremdet, 
2171 NPC: Abk&#252;rzung in online-Videospielen f&#252;r &#8222;Non Player Character&#8220; (Deutsch: Nicht-Spieler-Charakter). Dahinter verbirgt sich also
kein real am Spiel teilnehmender Mensch, sondern ein Algorithmus.
2172 Weitere Informationen dazu unter: https://survivr.com/virtual-reality-police-training/ (zuletzt abgerufen am 13. Oktober 2020) sowie
unter: https://www.apexofficer.com/ (zuletzt abgerufen am 13. Oktober 2020).
2173 Vgl. Branch (2018): Artificial Intelligence and Operational-Level Planning: An Emergent Convergence.
2174 Deutsch: Taktische Vorhersage.
2175 Vgl. Husseini (2019): AI in the sky: can drone surveillance technology replace CCTV?
wenn dies gew&#252;nscht ist, alle Personen, die nicht in ein vorgegebenes Muster fallen. Um falsche Alarme und
ungerechtfertigte Verhaftungen zu verhindern, ist auch hier ein menschlicher Bearbeiter zwingend erforderlich.
Mit dem Einsatz von Drohnen k&#246;nnen KI-basierte &#220;berwachungssysteme Objekte oder Gel&#228;ndeabschnitte (z. B. 
Sperrgebiete, Staatsgrenzen) analysieren.2176 Drohnen k&#246;nnen sehr gro&#223;e R&#228;ume mithilfe der mitgef&#252;hrten
Sensorik erfassen. Die Auswertung der gewonnenen und &#252;bertragenen Daten erfolgt durch KI-basierte Systeme.
Selbst umfassende &#220;berwachungskomplexe k&#246;nnen vollst&#228;ndig autonom oder, wenn gew&#252;nscht, teilautonom
operieren.2177 
Die europ&#228;ische Grenzschutzbeh&#246;rde FRONTEX2178 hat bereits ferngesteuerte Flugsysteme (RPAS2179) zur
Sicherung der weiten Grenzen der EU im Einsatz. Die Nutzung von autonomen und intelligenten, also KI-basierten,
Plattformen zur intelligenten technologischen Grenz&#252;berwachung sind von der Beh&#246;rde formuliert worden.2180 
Drohnen werden in absehbarer Zeit zur Normalit&#228;t an den europ&#228;ischen Staats- und Au&#223;engrenzen geh&#246;ren. Die
Bew&#228;ltigung der irregul&#228;ren Migration nach Europa ist ohne technische Unterst&#252;tzung durch milit&#228;rische
Technologie nicht denkbar. KI-Systeme k&#246;nnen die Effektivit&#228;t und die Resilienz der Grenz&#252;berwachung erh&#246;hen.
Eine Untersuchung mehrerer von der EU gebilligter Drohnenprojekte ergibt klare Ergebnisse und Empfehlungen
f&#252;r die europ&#228;ische Grenzsicherheit. Die Verschmelzung innerer und &#228;u&#223;erer Sicherheit durch die Verwendung
von KI- und Drohnen-unterst&#252;tzten Systeme ergibt rechtliche und ethische Unklarheiten, die vor einem
fl&#228;chendeckenden Einsatz zu kl&#228;ren sind.2181 
Sondervotum zu Kapitel 3.2.2, 5.2.4, 5.2.6 und 5.2.8.1 des Berichts der
Projektgruppe 4 &#8222;KI und Arbeit, Bildung, Forschung&#8220; (&#8222;Beispiele f&#252;r KI-Anwendungen in 
Schule und Hochschule&#8220;, &#8222;Anforderungen an den Schulunterricht&#8220;, &#8222;KI und
Hochschule&#8220; und &#8222;Lehrkr&#228;ftebildung&#8220;) des sachverst&#228;ndigen Mitglieds Prof. Dr. Boris
Hollas sowie der Abgeordneten Joana Cotar, Peter Felser und Dr. Marc Jongen 
Gr&#252;ndliche Kenntnisse der Mathematik und die F&#228;higkeit zu abstraktem Denken sind entscheidende
Voraussetzungen, um die KI zu beherrschen und weiter zu entwickeln. Die erheblichen Defizite der Sch&#252;ler und der
Studienanf&#228;nger im Fach Informatik und deren Auswirkungen sind im Projektgruppenbericht (siehe Kapitel 5.2.4 
des Berichts der Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220; [Anforderungen an den Schulunterricht])
nur im Ansatz dargestellt.
Aus der Sicht der AfD-Fraktion ergibt sich daher die Notwendigkeit eines Sondervotums, um die gro&#223;e Relevanz,
die diese Thematik f&#252;r jede KI-Politik der Bundesrepublik hat, f&#252;r den Abschlussbericht der Enquete-
Kommission zur Geltung zu bringen. Daher werden auch jene Faktoren, die den Mathematikunterricht an Schulen in
Deutschland mitbeeinflussen und in der Projektgruppenarbeit nur sehr rudiment&#228;r verhandelt wurden, in diesem
Sondervotum mitber&#252;cksichtigt. Gleiches gilt f&#252;r einzelne Felder der Bildungspolitik, die im
Projektgruppenbericht nicht oder aber in einer Weise er&#246;rtert werden, mit der die AfD-Fraktion nicht einverstanden ist.
Auswirkungen der Bildungspolitik
In einer Studie der Konrad-Adenauer-Stiftung ist zu lesen, dass unter Studienanf&#228;ngern in technischen F&#228;chern
&#8222;selbst einfache Fragen zur Analysis, die Gegenstand des G8-Lehrplansgewesen waren, von niemandem
beantwortet werden konnten&#8220;.2182 Eine Studie an Gymnasiasten am Ende der 13. Klasse zeigte, dass 69 Prozent die
Ziele voruniversit&#228;rer Mathematikausbildung nicht erf&#252;llten, 28 Prozent erreichten Leistungen, die deutlich unter
den Erwartungen der Sekundarstufe I liegen.2183 Im Eingangstest Mathematik an Fachhochschulen in NRW, der
&#252;ber viele Jahre die Kenntnisse der Studienanf&#228;nger pr&#252;fte, erreichten nur durchschnittlich 19 Prozent die
Anforderungen an die Studierf&#228;higkeit.2184 In einem Brandbrief beklagten Mathematikprofessoren 2017, dass die
2176 Vgl. B&#322;aszczok et al. (2013): Main Aims and Objectives of an IT System in the Implementation of the Project: Design and
Implementation of Innovative Unmanned Mobile Platforms for the Needs of Monitoring State Borders.
2177 Vgl. Freed et al. (2005): Intelligent Autonomous Surveillance of many Targets with few UAVs.
2178 Akronym: Fronti&#232;res ext&#233;rieures.
2179 RPAS: Abk&#252;rzung f&#252;r Remotely Piloted Aircraft Systems.
2180 Weitere Informationen dazu unter: https://cordis.europa.eu/project/id/663483 (zuletzt abgerufen am 13. Oktober 2020).
2181 Vgl. Csernatoni (2018): Constructing the EU&#8217;s high-tech borders: FRONTEX and dual-use drones for border management.
2182 Hoffmann und Henry-Huthmacher (2016): Ausbildungsreife &amp; Studierf&#228;higkeit, S. 12.
2183 Vgl. Kampa (2015): Mathematische Kompetenzen in Profiloberstufen in Schleswig-Holstein, S. 3.
2184 Vgl. Knospe (2011): Der Eingangstest Mathematik an Fachhochschulen in Nordrhein-Westfalen von 2002 bis 2010, S. 11.
Vorkenntnisse sehr vieler Studienanf&#228;nger nicht mehr f&#252;r ein technisches Studium ausreichen.2185 In den
Aufgaben des Landes Brandenburg f&#252;r die Pr&#252;fung Mathematik f&#252;r Gymnasien am Ende der Jahrgangsstufe 10 fand
sich im Jahr 2016 die Aufgabe &#8222;Geben Sie das arithmetische Mittel (Durchschnitt) der drei Werte an: 8; 40;
60&#8220;.2186 
Auch im internationalen Vergleich sind die Leistungen deutscher Sch&#252;ler in der Mathematik nur mittelm&#228;&#223;ig.
W&#228;hrend bei PISA 2018 die asiatischen L&#228;nder Spitzenpl&#228;tze belegen, liegt Deutschland mit deutlichem Abstand
auf Platz 20.2187 In der Studie TIMSS hatte sich Deutschland von Platz 12 im Jahr 20072188 auf Platz 20 im Jahr
20152189 verschlechtert.
Besonders gravierend sind die Unterschiede in der h&#246;chsten Kompetenzstufe. Erreichten diese in Singapur
50,1 Prozent der Sch&#252;ler, waren es in Deutschland nur 5,3 Prozent. Die absoluten Zahlen liegen in China bei
24,7 Millionen Sch&#252;lern, in Japan bei 1,8 Millionen, in S&#252;dkorea bei 0,9 Millionen und in Deutschland nur bei
0,2 Millionen.2190 Gerade die kl&#252;gsten K&#246;pfe werden aber gebraucht, um die Innovation voranzutreiben. Dies
zeigt sich in der Zahl der Patentanmeldungen:
China liegt hier vor allen anderen L&#228;ndern, Japan vor Deutschland, dem S&#252;dkorea sehr dicht folgt.2191 Auch in 
der wissenschaftlichen Forschung auf dem Gebiet der KI geh&#246;rt China l&#228;ngst zu den f&#252;hrenden Nationen. 
Gleichzeitig &#252;bt die Politik einen gro&#223;en Druck auf die Hochschulen aus, Studenten &#8211; wie bereits an den Schulen
&#252;blich &#8211; bis zum Abschluss &#8222;durchzuwinken&#8220;. Zielvereinbarungen enthalten Vorgaben f&#252;r Absolventenzahlen
und Abbrecherquoten, deren Verfehlung zu geringeren Mittelzuweisungen an die Hochschule f&#252;hrt. Die Weichen
f&#252;r eine weitere Erosion der Anforderungen an den Hochschulen sind damit gestellt.
Hochschulpolitik
Unter den beschriebenen Voraussetzungen kann auch eine Erh&#246;hung der Anzahl von KI-Professuren nicht zu
einer h&#246;heren Qualit&#228;t der Lehre f&#252;hren. Notwendig ist eine Anhebung der fachlichen Anforderungen an die
Studienanf&#228;nger, etwa durch eine Aufnahmepr&#252;fung, die Beseitigung von Fehlanreizen und ein
Paradigmenwechsel, der weg von quantitativen und hin zu qualitativen Zielen f&#252;hrt.
Die Initiative der Bundesregierung zur Einrichtung von 100 neuen KI-Professuren kann der KI langfristig
schaden. Einerseits gibt es wegen der hohen Nachfrage nach KI-Experten gegenw&#228;rtig nicht gen&#252;gend qualifizierte
Bewerber, um diese Stellen zu besetzen. Andererseits k&#246;nnen Professuren, die jetzt besetzt werden, in den
n&#228;chsten 30 Jahren nicht erneut besetzt werden. Dies kann dazu f&#252;hren, dass sich der wissenschaftliche Nachwuchs
aus Mangel an Perspektiven von der KI abwendet. Alle Ma&#223;nahmen, die eine St&#228;rkung der KI bewirken sollen,
m&#252;ssen langfristig ausgerichtet sein. Angesichts der durchschnittlichen Studiendauer von 4 Jahren bis zum
Bachelor-Abschluss in Informatik ist eine kurzfristige Steigerung der Absolventenzahlen durch h&#246;here
Studienkapazit&#228;ten kaum m&#246;glich.
Die Einrichtung eigener KI-Studieng&#228;nge, wie in Kapitel 5.2.6 (&#8222;KI und Hochschule&#8220;) gefordert, ist nicht
sinnvoll. Die KI ist ein Teil der Informatik und kann nicht losgel&#246;st von dieser gelehrt werden. Auch sollten die
beruflichen M&#246;glichkeiten der Absolventen durch eine Spezialisierung nicht zu sehr eingeschr&#228;nkt werden.
Sinnvoll sind allenfalls Aufbau- oder Master-Studieng&#228;nge mit einem Schwerpunkt in der KI.
Berufliche Bildung
Die Informatik-Studieng&#228;nge sollten durch einen Ausbau der beruflichen Bildung entlastet werden. Der
Fachinformatiker und der mathematisch-technische Softwareentwickler sind Ausbildungsberufe, die geringere
Anforderungen an die Mathematik-Kenntnisse stellen und gleichzeitig Wissen und F&#228;higkeiten vermitteln, mit denen 
zahlreiche Probleme, die sich in der t&#228;glichen Praxis stellen, gel&#246;st werden k&#246;nnen. Auch in der KI fallen bei der
2185 Vgl. Gesellschaft f&#252;r Bildung und Wissen e. V. Forum f&#252;r Schule, Ausbildung und Studium (2017): Mathematik: Brandbrief gegen 
Bildungsstandards.
2186 Land Brandenburg, Ministerium f&#252;r Bildung, Jugend und Sport (2015)/(2016): Pr&#252;fung am Ende der Jahrgangsstufe 10, S. 2.
2187 Weitere Informationen dazu unter: https://www.oecd.org/berlin/themen/pisa-studie/ (zuletzt abgerufen am 13. Oktober 2020).
2188 Vgl. Bos et al. (2008): TIMSS 2007 - Mathematische und naturwissenschaftliche Kompetenzen von Grundschulkindern in
Deutschland im internationalen Vergleich - Zusammenfassung, S. 17.
2189 Vgl. Wendt et al. (2016): TIMSS 2015, S. 164.
2190 Vgl. Heinsohn (2019): Wettkampf um die Klugen, S. 107 f.
2191 Weitere Informationen dazu unter: https://www.wipo.int/export/sites/www/pressroom/en/documents/pr_2020_848_annexes.pdf#an-
nex1, S.1 (zuletzt abgerufen am 13. Oktober 2020).
Gewinnung und Aufbereitung von Daten umfangreiche und zeitraubende Aufgaben an, f&#252;r die kein studierter
Informatiker ben&#246;tigt wird. Beruflich ausgebildete Informatiker k&#246;nnen studierte Informatiker unterst&#252;tzen,
deren Produktivit&#228;t steigern und dadurch den Bedarf an KI-Experten verringern.
Geschlechtergerechtigkeit
In einer freiheitlichen Gesellschaft m&#252;ssen wir akzeptieren, dass sich die Unterschiede zwischen den
Geschlechtern in einer unterschiedlichen Wahl der Schul- und Studienf&#228;cher manifestieren. Kenntnisse der KI, die zwischen
M&#228;nnern und Frauen verschieden sind, verstehen wir als Folge dieser Unterschiede. Nicht die Angleichung der
Geschlechter muss das Ziel der Bildungspolitik sein, sondern die optimale F&#246;rderung des Einzelnen.
Geschlechtergerechtigkeit bedeutet f&#252;r uns, dass jeder Sch&#252;ler und jeder Student unabh&#228;ngig von seinem Geschlecht ein
Bildungsangebot erh&#228;lt, das seinen Interessen und Begabungen entspricht. Die Abkehr von der Koedukation
durch getrennte Bildungsangebote f&#252;r M&#228;nner und Frauen, wie in Kapitel 5.2.8.1 des Berichts der Projektgruppe
&#8222;KI und Arbeit, Bildung, Forschung [Lehrkr&#228;ftebildung] gefordert, steht im Widerspruch zu den Zielen der
Gleichberechtigung und erschwert einen Vergleich der erbrachten Leistungen. Auch im Berufsleben m&#252;ssen 
Frauen mit M&#228;nnern zusammenarbeiten. Die Frauenstudieng&#228;nge Informatik an der Hochschule Bremen und der
HTW Berlin sollten daher abgeschafft werden.
Einwanderung
Eine wie bisher ungesteuerte Einwanderung f&#252;hrt zu einem weiter sinkenden Bildungsniveau. In Deutschland
liegen nach den Ergebnissen von TIMSS 2015 die Leistungen von Sch&#252;lern mit Migrationshintergrund deutlich 
unter denen ohne Migrationshintergrund.2192 In Australien, einem Land, das seine Einwanderung durch ein
Punktesystem steuert und illegale Immigranten abweist, wie auch in Singapur, das von Einwanderern eine hohe
berufliche Qualifikation fordert, zeigen Kinder von Migranten dagegen bessere Leistungen als die von
Einheimischen.2193 
In internationalen Schulleistungsuntersuchungen belegen arabische und afrikanische Staaten regelm&#228;&#223;ig die
hintersten Pl&#228;tze. Nach einer Untersuchung des Bildungs&#246;konomen W&#246;&#223;mann vom ifo Institut M&#252;nchen erreichen
65 Prozent der syrischen Sch&#252;ler nicht einmal die OECD-Grundkompetenzen, zwei Drittel sind funktionale
Analphabeten.2194 Einer Studie der TU Chemnitz zufolge besitzen selbst Asylbewerber mit Universit&#228;tsstudium
einen IQ, der 8 Punkte unter dem deutscher Realsch&#252;ler liegt.2195 
Erschwerend kommt dazu, dass Deutschland durch seine sehr hohe Steuer- und Abgabenlast, die weltweit nur 
noch von Belgien &#252;bertroffen wird, und die im Vergleich zu den USA oder der Schweiz zu deutlich geringeren
Nettol&#246;hnen f&#252;hrt, f&#252;r ausl&#228;ndische KI-Experten kaum attraktiv ist.
Mit einer Steuer- und Migrationspolitik, die Unqualifizierte anzieht und Hochqualifizierte fernh&#228;lt, wird
Deutschland nicht zu den in der KI f&#252;hrenden Nationen aufschlie&#223;en k&#246;nnen.
Einsatz von KI in der Lehre
Seit Jahrzehnten werden gro&#223;e Erwartungen an eine Verbesserung des Unterrichts durch technische Mittel
gehegt. Weder das Sprachlabor noch der Einsatz von Video und Multimedia konnten diese Erwartungen erf&#252;llen.
Die Digitalisierung des Unterrichts soll nun den erhofften Durchbruch bewirken. Die viel zitierte, umfangreiche
Metastudie des Bildungsforschers Hattie fand jedoch nur schwache, kaum wirksame Effekte bei der Nutzung von
webbasiertem Lernen im Unterricht.2196 Mehrere umfassende Studien an 52 Schulen in den USA konnten keine
positiven Auswirkungen des Einsatzes von Laptops in Schulen zeigen.2197 Auch Andreas Schleicher von der
OECD stellte fest: &#8222;Wo Computer in Klassenzimmern genutzt werden, sind ihre Auswirkungen auf die Leistung 
von Sch&#252;lern bestenfalls gemischt&#8220;.2198 Dagegen bringt der Technikeinsatz h&#228;ufig technische Probleme mit sich, 
die die Sch&#252;ler nicht beheben k&#246;nnen.
2192 Vgl. Wendt et al. (2016): TIMSS 2015, S. 324.
2193 Vgl. Wendt et al. (2016): TIMSS 2015, S. 321.
2194 Vgl. Wiarda (2015): Bildungs&#246;konom: Bildungsstand der Fl&#252;chtlinge niedriger als vermutet.
2195 Vgl. TU Chemnitz (2015): Ein Hintergrundgespr&#228;ch zum Migrations-Artikel im Focus, S. 5.
2196 Vgl. Hattie (2015): Lernen sichtbar machen, S. 268.
2197 Vgl. Texas Center for Educational Research (2009): Evaluation of the Texas Technology Immersion Pilot, S. 71.
2198 welt.de (2015): OECD: Keine besseren Leistungen durch Rechner an Schulen.
Die in Kapitel 3.2.2 des Berichts der Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung [Beispiele f&#252;r KI-
Anwendungen in Schule und Hochschule] dargestellten Anwendungen lassen sich unterteilen in
a) mit Sensoren ausgestattete digitale Lehrmittel und in
b) Anwendungen einer Datenanalyse auf Lerndaten (Learning Analytics).
Die Anwendungen in a) sind letztlich ein weiterer technischer Versuch zur Digitalisierung des Unterrichts.
Grundlegend andere Auswirkungen als in den schon genannten Untersuchungen sind durch diese nicht zu
erwarten. Selbst in KI-Vorlesungen findet die Lehre heute nicht wesentlich anders statt als vor 20 Jahren. Bei den
Anwendungen in b) wird versucht, in Daten, die Sch&#252;ler oder Studenten beim Arbeiten insbesondere mit digitalen 
Lehrmitteln erzeugen, Zusammenh&#228;nge zu finden und diese zur Verbesserung oder zur &#220;berwachung des
Lernprozesses zu nutzen. Da bereits der Nutzen der Digitalisierung des Unterrichts fraglich ist, ist auch hier das
Verbesserungspotential sehr gering.
Handlungsempfehlungen
Ohne eine grundlegende Kurs&#228;nderung in der Bildungspolitik wird Deutschland in der KI und in anderen
technischen Bereichen immer weiter ins Hintertreffen geraten, mit allen nachteiligen Folgen f&#252;r den
Wirtschaftsstandort. Angesichts der Konkurrenz aus Asien ist es notwendig, das Leistungsniveau in allen Schularten und an
den Hochschulen deutlich anzuheben und die berufliche Ausbildung als Alternative zum Studium zu st&#228;rken.
Besonderes Augenmerk muss auf die F&#246;rderung und die Erh&#246;hung der Anzahl der Sch&#252;ler mit der h&#246;chsten
Kompetenzstufe gelegt werden, weil diese die wichtigsten Beitr&#228;ge f&#252;r Wissenschaft und Innovation liefern. Die
Einwanderung von gering Qualifizierten, insbesondere aus L&#228;ndern mit niedrigem Bildungsniveau, muss beendet
werden. Die Steuer- und Abgabenlast muss deutlich sinken und die Geh&#228;lter f&#252;r Hochqualifizierte so stark
steigen, dass Deutschland im internationalen Wettbewerb um KI-Experten konkurrenzf&#228;hig wird.
Sondervotum zu den Kapiteln 1 und 4.3 des Berichts der Projektgruppe 6 &#8222;KI und 
Medien&#8220; (&#8222;Kurzfassung des Projektgruppenberichts&#8220; und &#8222;Ziele und Aufgaben von 
Medienpolitik&#8220;) der Abgeordneten Joana Cotar sowie der Abgeordneten Peter Felser
und Dr. Marc Jongen 
F&#252;r eine besondere Auffindbarkeit der Inhalte des &#214;RR im Internet gibt es keinen Grund. Entscheidend ist die
F&#246;rderung der Medienkompetenz der Menschen.
Vorbemerkung
In der Kurzfassung des Berichtes der Projektgruppe 6 &#8222;KI und Medien&#8220; wird die Ver&#228;nderung im Prozess der
Produktion, der Verteilung und der Rezeption von Medieninhalten in den vergangenen 30 Jahren skizziert.
Treiber dieser Entwicklung sind zum einen die Digitalisierung der Medien und ihrer M&#228;rkte, zum anderen zus&#228;tzlich
der Einsatz von KI-Systemen bei der Generierung und Distribution medialer Inhalte. An die Seite traditioneller
Medienh&#228;user, Sender und Verlage sind m&#228;chtige Plattformen getreten, die &#252;ber gro&#223;e Mengen
personenbezogener sowie Verhaltensdaten verf&#252;gen und ihren Nutzern KI-gest&#252;tzt Inhalte ausspielen, darunter auch politische
Nachrichten und Informationen. Die Projektgruppe geht davon aus, dass dieser Ver&#228;nderungsprozess sich
fortsetzen wird und sieht die Notwendigkeit, Medienpolitik und Regulierung im Medienbereich zu &#252;berdenken.
Die Projektgruppe konstatiert weiter, Medienpolitik m&#252;sse im Blick haben, &#8222;unabh&#228;ngigen Journalismus und
eine pluralistische &#214;ffentlichkeit zu gew&#228;hrleisten und zu f&#246;rdern&#8220;. Daher erscheine es wichtig, dass
&#8222;&#246;ffentlichrechtliche Medien auch k&#252;nftig relevant und akzeptiert bleiben &#8211; und zwar &#252;ber alle Altersgruppen und sozialen
Schichten hinweg&#8220;. Daf&#252;r m&#252;sse die Auffindbarkeit von Inhalten auch des &#246;ffentlich-rechtlichen Rundfunks &#8222;in 
allen Netzen durch geeignete Ma&#223;nahmen sichergestellt werden, um Netzneutralit&#228;t und
Diskriminierungsfreiheit zu gew&#228;hrleisten&#8220; (siehe Kapitel 1).
Die Projektgruppe folgt mit diesen Forderungen, die den Charakter von Handlungsempfehlungen haben, der
unausgesprochenen Pr&#228;misse, der &#246;ffentlich-rechtliche Rundfunk sei konstitutiv f&#252;r eine funktionierende
demokratische &#214;ffentlichkeit. Diese Annahme teilt die AfD-Fraktion nicht. In der Diskussion zur Abfassung dieser
Passage hatte die AfD-Fraktion wiederholt beantragt, die privilegierte Stellung des &#246;ffentlich-rechtlichen Rundfunks
und seiner Inhalte im Internet zu negieren, weil darin ein unzul&#228;ssiger Eingriff in den Medienmarkt zu sehen sei.
Da diese Position der AfD-Fraktion von der Mehrheit der Projektgruppe zur&#252;ckgewiesen wurde, wird sie nun an
dieser Stelle erneut erhoben und begr&#252;ndet.
Argumentation
Die Medienordnung der fr&#252;hen Bundesrepublik Deutschland l&#228;sst sich als duales System beschreiben: Auf der
einen Seite der &#246;ffentlich-rechtliche Rundfunk, auf der anderen Seite das privatwirtschaftlich organisierte
Zeitungs- und Verlagswesen. Die Einrichtung eines &#246;ffentlich-rechtlichen Rundfunks (&#214;RR) nach dem Vorbild der
britischen BBC2199 sollte zum einen der &#8222;Umerziehung&#8220; der deutschen Bev&#246;lkerung nach dem Ende des
Dritten Reiches dienen2200; zum anderen waren Sendefrequenzen in jenen Jahren knapp, so dass der Zugriff darauf
prim&#228;r &#252;ber &#246;ffentlich-rechtliche Rundfunkanstalten plausibel erschien. 
Ende der medialen Nachkriegsordnung
Dieses Nebeneinander von Funk und Fernsehen sowie Zeitungen und Zeitschriften erfuhr mit der Lizenzierung
privater TV-Kan&#228;le Anfang der 1980er Jahre eine Erweiterung. Mit der massenhaften Verbreitung des Internets
als Empfangs- und Sendemedium ab Ende der 1990er Jahre ist die mediale Nachkriegsordnung endg&#252;ltig pass&#233;.
Die Menschen sehen sich einem &#220;berangebot an TV-Sendern und Radiostationen, Streaminganbietern und
Videoportalen, gedruckten Zeitungen und aggregierten Nachrichtenservices, dazu Messengerdiensten, Blogs und
Datenbanken im Internet gegen&#252;ber (zur detaillierten Aufschl&#252;sselung der Mediennutzung in Deutschland siehe
Kapitel 4.1 des Berichts der Projektgruppe &#8222;KI und Medien&#8220; [Medienkonsum und Nutzungsverhalten]). Diese
verschiedenen Angebote finanzieren sich &#252;ber verpflichtende Beitr&#228;ge aller2201, &#252;ber Abonnementgeb&#252;hren, &#252;ber
Genossenschaftsmodelle, &#252;ber Werbung oder &#252;ber die Monetarisierung der Nutzerdaten. Dabei ist offenkundig,
dass die Nutzung des linearen TV-Programms vor allem bei Menschen jenseits der 55 Jahre verbreitet ist,
w&#228;hrend f&#252;r die unter 34-J&#228;hrigen das Internet die Hauptquelle der Nachrichten geworden ist (siehe Kapitel 4.1.3 des 
Berichts der Projektgruppe &#8222;KI und Medien&#8220; [Nachrichtennutzung]).
Dass &#246;ffentlich-rechtliche Medien und ihre Inhalte bevorzugt von &#196;lteren rezipiert werden, derweil sich j&#252;ngere
Alterskohorten anderer medialer Angebote bedienen, spiegelt nach Ansicht der AfD-Fraktion den
technologischen wie gesellschaftlichen Wandel der vergangenen 30 bis 40 Jahre. Eine &#8222;Akzeptanz&#8220; &#246;ffentlich-rechtlicher
Medien und deren Inhalte &#252;ber &#8222;alle Altersgruppen und sozialen Schichten hinweg&#8220; l&#228;sst sich nach Ansicht der
AfD-Fraktion medienpolitisch nicht verordnen oder gar einklagen; auf Medienm&#228;rkten entscheidet das Spiel
zwischen Angebot und Nachfrage &#252;ber die Annahme oder Ablehnung des Gelieferten. Vielmehr sollten sich die
Anstalten des &#214;RR fragen, was denn zu ihrem schleichenden Reichweitenverlust2202 und zu ihren
Imageproblemen2203 gef&#252;hrt hat.
Anfang 2019 geriet das ber&#252;chtigte &#8222;Framing-Manual&#8220; der Kognitionswissenschaftlerin Elisabeth Wehling2204 
versehentlich an die &#214;ffentlichkeit. Das Papier, als Grundlage ARD-interner Diskussionen gedacht, macht eine
ganze Reihe rhetorischer Vorschl&#228;ge f&#252;r den Umgang mit Kritikern des &#214;RR. So m&#252;sse die Kommunikation 
&#8222;immer in Form von moralischen Argumenten stattfinden&#8220;.2205 F&#252;r Wehling ist die &#8222;Rundfunkbeteiligung [&#8230;]
gelebte Eigenverantwortung f&#252;r die deutsche Kultur, Wirtschaft und Demokratie als Grundlage unseres
individuellen Wohlergehens&#8220;.2206 Ihre Darstellung gipfelt in der salbungsvollen Aussage: &#8222;Wir beteiligen uns am
gemeinsamen Rundfunk ARD um unserer selbst und unseres Landes willen.&#8220;2207 Eine individuelle Entscheidung
zu einer solchen &#8222;Beteiligung&#8220; ist nicht vorgesehen; Wehling geht so weit, eine stabile Infrastruktur des &#214;RR in
2199 Zur Rolle der BBC vgl. Plickert (2020): Die Briten und der Rundfunkwettbewerb.
2200 F&#252;r die unmittelbaren Nachkriegsjahre vgl. Kutsch (1999): Rundfunk unter alliierter Besatzung; f&#252;r die Zeit ab 1949 vgl. Diller
(1999): &#214;ffentlich-rechtlicher Rundfunk.
2201 Seit der Umstellung von der Ger&#228;te- auf die Haushaltsabgabe 2013 sprechen die Anstalten des &#246;ffentlich-rechtlichen Rundfunks
(&#214;RR) nicht l&#228;nger von einer &#8222;Rundfunkgeb&#252;hr&#8220;, sondern von einem &#8222;Rundfunkbeitrag&#8220;. Das Charakteristikum dieses
Finanzierungsmodells liegt in seiner lebenslangen Verpflichtung f&#252;r jeden Haushalt respektive Bewohner innerhalb Deutschlands. Die
fehlende M&#246;glichkeit, sich an diesem Arrangement nicht zu beteiligen (etwa, weil man bestimmte Sender nicht schaut oder gar kein TV
nutzt), l&#228;sst ihre Kritiker von einer &#8222;Zwangsabgabe&#8220; sprechen &#8211; sie bekommen ein Angebot, das sie nicht ablehnen k&#246;nnen.
2202 Das ZDF und die Anstalten der ARD erreichten 2015 kumuliert noch knapp 37 Prozent der TV-Zuschauer, vgl. Hasebrink et al.
(2017): Zur Entwicklung der Medien in Deutschland zwischen 2013 und 2016, S. 47.
2203 Eine prinzipielle Kritik am System des &#214;RR, vor allem der chronischen Misswirtschaft mit den Geb&#252;hren, kommt von Hans-Peter
Siebenhaar (Siebenhaar (2012): Die Nimmersatten). Der Autor hat seine Position in einem Interview zu Beginn des Jahres 2020 
aktualisiert, vgl. Hildebrandt (2020): &#8222;Unser Rundfunksystem krankt&#8220;.
2204 Vgl. Berkley International Framing Institute (2017): Framing-Manual.
2205 Ebd., S. 3.
2206 Ebd., S. 35.
2207 Ebd., S. 60.
den Rang eines Agenten der Daseinsversorgung zu erheben, analog der Gerichte, der Polizei, der Schulen und
der Stra&#223;en.2208 
Keine rhetorische Vereinnahmung des Publikums
Eine solch naiv-affirmative Haltung gegen&#252;ber den Medien des &#214;RR ist f&#252;r die AfD-Fraktion unakzeptabel. Die
Sendeanstalten2209 sind keine mildt&#228;tigen Stiftungen, sondern befinden sich in einem medialen Wettbewerb um
die Aufmerksamkeit der Nutzer und m&#252;ssen sich an der Qualit&#228;t ihres Programms messen lassen. Dabei sind
journalistische Standards wie Sorgfalt, Ausgewogenheit, Professionalit&#228;t und Objektivit&#228;t bei der Recherche und
bei der Berichterstattung zu beachten &#8211; und nicht eine &#8222;richtige Haltung&#8220;. Keinesfalls darf es, wie von Elisabeth
Wehling postuliert2210, zu einer rhetorischen und finanziellen Vereinnahmung zwischen den Anstalten des &#214;RR
und den Menschen kommen: Wir sind nicht Ihr! Es muss bei der journalistischen Arbeit immer eine klare
Trennung zwischen Redaktion, Publikum und Sachverhalt geben, als Norm und als Pr&#252;fstein. Wird diese Trennung
verwischt, beginnen PR und Propaganda.
Schlussfolgerung
Die AfD-Fraktion teilt die Position der Projektgruppe, dass ein unabh&#228;ngiger Journalismus f&#252;r das Herstellen
einer pluralistischen &#214;ffentlichkeit und dar&#252;ber hinaus f&#252;r eine funktionierende Demokratie unerl&#228;sslich ist. Dies
wird normativ &#252;ber die Sicherung des Zugangs zu Medien, Staatsferne, Vielfaltssicherung und Verhinderung von 
Meinungsmacht angestrebt (siehe Kapitel 4.3 des Berichts der Projektgruppe &#8222;KI und Medien&#8220; [Ziele und
Aufgaben von Medienpolitik]). Das hei&#223;t aber keineswegs, dass einzelne Medien gegen&#252;ber anderen zu bevorzugen
w&#228;ren. Die Forderung der Projektgruppe, die Auffindbarkeit der Angebote des &#214;RR m&#252;sste in allen Netzen
diskriminierungsfrei und chancengleich sichergestellt werden, kann die AfD-Fraktion nur ablehnen. Sie erkennt
darin eine Fortschreibung einer jahrzehntelangen Privilegierung der Sendeanstalten des &#214;RR: Diese k&#246;nnen
neben den Werbeeinnahmen auch &#252;ber die monatlichen Zwangsbeitr&#228;ge Gelder generieren, die den frei finanzierten
TV- und Radiosendern nicht zur Verf&#252;gung stehen. Wenn ihre Inhalte nun auch noch prominent im Internet
auffindbar sein sollen, was ohne eine Regulierung der KI-Systeme, die hinter der Ausspielung von Inhalten
stehen, kaum erreichbar ist, wirkt dies potenziell prohibitiv auf den Markteintritt neuer Medienanbieter. 
Die Sortierung von Inhalten im Internet erfolgt nach einem komplexen Empfehlungssystem (siehe die Kapitel 
3.2.3 [Personalisierte Empfehlungssysteme in den digitalen Medien] und 3.2.4 [Technische Grundlagen von
Empfehlungssystemen] des Berichts der Projektgruppe &#8222;KI und Medien&#8220;), das auf der Fragmentierung der
&#214;ffentlichkeit und der personalisierten Ansprache der einzelnen Nutzer aufbaut.2211 Wer sich Sendungen der
&#246;ffentlich-rechtlichen Anstalten ansehen oder anh&#246;ren m&#246;chte, kann das &#252;ber deren exklusive TV- und Radiokan&#228;le
tun. Wer sich im Internet zu politischen, kulturellen, wirtschaftlichen und gesellschaftlichen Themen informieren
oder unterhalten m&#246;chte, tut das gegebenenfalls auch deswegen, weil er gerade keine Angebote des &#214;RR sucht.
Es kommt f&#252;r die AfD-Fraktion einem Angriff auf die Meinungs- und Informationsfreiheit im Internet gleich,
wenn die Kr&#228;fte des Marktes regulativ gez&#252;gelt werden, indem die Reichweite des &#214;RR k&#252;nstlich auf das Internet
ausgedehnt wird. Auch auf Medienm&#228;rkten gilt: Was gut ist, setzt sich durch und findet Leser, Nutzer,
Konsumenten.
Der Staatsvertrag zur Modernisierung der Medienordnung in Deutschland (&#8222;Medienstaatsvertrag&#8220;)2212, der
voraussichtlich im Herbst 2020 von den Parlamenten der Bundesl&#228;nder ratifiziert werden wird, regelt nicht nur den
&#246;ffentlich-rechtlichen und den privaten Rundfunk, sondern auch sogenannte Medienintermedi&#228;re (siehe Kapitel 
7.2.1 des Berichts der Projektgruppe &#8222;KI und Medien&#8220; [Medienrecht (Medienstaatsvertrag)]). Diese werden in
&#167; 93 &#8222;Transparenz&#8220; und &#167; 94 &#8222;Diskriminierungsfreiheit&#8220; zur &#8222;Sicherung der Meinungsvielfalt&#8220; verpflichtet: Sie
2208 Ebd., S. 41.
2209 F&#252;r das Kalenderjahr 2019 lag die H&#246;he der Gesamtertr&#228;ge aus den Rundfunkbeitr&#228;gen bei gut 8 Milliarden Euro, vgl. ARD ZDF 
Deutschlandradio Beitragsservice, Kundenmanagement und Berichtswesen (2020): Jahresbericht 2019, S. 8. Diese Summe wird
durch die zu erwartende Erh&#246;hung des Rundfunkbeitrages im Jahr 2021 auf rund 10 Milliarden Euro j&#228;hrlich steigen.
2210 Vgl. Berkley International Framing Institute (2017): Framing-Manual, S. 56.
2211 In einer legend&#228;r gewordenen Anh&#246;rung vor dem US-Kongress im Dezember 2018 beantwortet Sundar Pichai, CEO von Google, die Frage
einer Abgeordneten, warum als Vorschlag auf die Suche nach einem &#8222;Idioten&#8220; auch ein Bild von Donald Trump angeboten werde. Hier
l&#228;sst sich von einer Weisheit der Algorithmen sprechen, die die Fragen, Erfahrungen und Erwartungen von Millionen Nutzern untersuchen 
und verdichten und ohne menschliche Redaktion auskommen. Abrufbar unter: https://www.youtube.com/watch?v=o6zfp6lRw2E (zuletzt
abgerufen am 13. Oktober 2020).
2212 Entwurf des Medienstaatsvertrags vom 5. Dezember 2019, abrufbar unter https://www.rlp.de/fileadmin/rlp-stk/pdf-Dateien/Medien-
politik/ModStV_MStV_und_JMStV_2019-12-05_MPK.pdf (zuletzt abgerufen am 13. Oktober 2020).
m&#252;ssen Informationen &#252;ber ihre Algorithmen, die hinter der Aggregation, Selektion und Pr&#228;sentation von
Inhalten stehen, in verst&#228;ndlicher Sprache verf&#252;gbar halten2213; sie d&#252;rfen weiterhin &#8222;journalistisch-redaktionell
gestaltete Angebote, auf deren Wahrnehmbarkeit sie besonders hohen Einfluss haben, nicht diskriminieren&#8220;.2214 
Welcher Natur die genannten journalistischen Angebote sind, wird im Medienstaatsvertrag nicht differenzierend
erw&#228;hnt; der bislang f&#252;r die Rolle des &#214;RR notorische Begriff der &#8222;Grundversorgung&#8220; taucht genau einmal auf
(&#167; 102, Absatz 4). Da die Medienpolitik in die Kompetenz der Bundesl&#228;nder f&#228;llt, stellt sich der AfD-Fraktion 
prinzipiell die Frage, ob der Bericht einer Projektgruppe der Enquete-Kommission KI an den Deutschen
Bundestag ein passendes Forum ist, Handlungsempfehlungen zugunsten der Wahrnehmbarkeit des &#214;RR im Internet zu 
geben.
Ausblick
Eine Reform des &#246;ffentlich-rechtlichen Rundfunks wird immer wieder angemahnt, ihre Notwendigkeit steht f&#252;r
die AfD-Fraktion au&#223;er Frage. Ein System, das au&#223;erhalb eines &#246;konomischen Modells steht und von einer
abgabenartigen Finanzierung lebt, wird keinen intrinsischen Antrieb entwickeln, einen digitalen, medialen
Versorgungsauftrag zu &#252;bernehmen, der geeignet w&#228;re, den gro&#223;en Medienintermedi&#228;ren, die zunehmend eine
infrastrukturelle Rolle spielen2215, im Wettbewerb um die Gunst der Nutzer die Stirn zu bieten.
Reform des &#214;RR ist &#252;berf&#228;llig und leicht umsetzbar
Bereits 2014 lieferte ein Gutachten des Wissenschaftlichen Beirats beim Bundesministerium der Finanzen2216 
wesentliche Punkte f&#252;r eine Reform des &#214;RR, die nach Ansicht der AfD-Fraktion nichts von ihrer Aktualit&#228;t
eingeb&#252;&#223;t haben und obendrein leicht umsetzbar sind. Die in Deutschland bestehende unterschiedliche
Regulierung von Presse und Rundfunk ist nur historisch zu erkl&#228;ren, an ihr muss nicht &#252;ber Geb&#252;hr festgehalten
werden.2217 Die nutzungsunabh&#228;ngige Zwangsabgabe zementiert die Sonderrolle des &#214;RR in Wirtschaft und
Gesellschaft, sie kann und soll abgeschafft und &#252;ber eine moderne Nutzungsgeb&#252;hr ersetzt werden.2218 Der &#214;RR sollte
sich auf die Bereitstellung von Inhalten in strukturschwachen Gebieten beschr&#228;nken, die den am Markt
orientierten Anbietern zu unattraktiv erscheinen. Nicht zuletzt ist die Publikation wirtschaftlicher Kenngr&#246;&#223;en dringend
notwendig, um eine Kosteneffizienz auch im &#214;RR zu f&#246;rdern.2219 
Nicht die Algorithmen entscheiden, sondern die Medienkompetenz der Menschen
Fragt man nach der Anzahl der Zuschauer, die pro Million Euro &#246;ffentlicher Ausgaben noch erreicht werden,
liegt der deutsche &#214;RR im internationalen Vergleich am unteren Ende der Skala.2220 W&#228;ren seine Produkte so
vielf&#228;ltig, gut recherchiert und qualitativ hochwertig, wie von den Redaktionen stets behauptet, k&#246;nnten diese
sich guten Gewissens dem Urteil des Publikums stellen und dieses freiwillig zahlen lassen f&#252;r einen
journalistischen Service &#8211; analog zu denen der Zeitungen, Verlage, verschl&#252;sselter TV-Sender und Streamingdienste. Dass
der &#214;RR ein Aufmerksamkeitsproblem hat, l&#228;sst sich nicht den KI-Algorithmen der Medienintermedi&#228;re
anlasten. Die verantwortlichen Redakteure in den Anstalten von ARD und ZDF m&#252;ssen sich fragen, ob der &#214;RR
seinem Auftrag weiterhin gerecht wird und noch neutral und ausgewogen berichtet.2221 Politisch interessierte und
m&#252;ndige B&#252;rger suchen sich ihre pr&#228;ferierten Informationskan&#228;le selbst, zur Vermittlung und Interpretation
politischer Positionen und Zusammenh&#228;nge braucht es keine staatstragenden Sendeanstalten mehr. Das Wissen um
das Funktionieren und die Wirkung der Algorithmen beim Auffinden und Sortieren politischer Inhalte ist nach
Ansicht der AfD-Fraktion ein zentraler Aspekt der Medienkompetenz. Darin solle unbedingt investiert werden &#8211;
dann werden die Menschen die ihnen angebotenen Inhalte schon selbst und eigenverantwortlich aufnehmen und
beurteilen.
2213 Vgl. &#167; 93 Absatz 2 Medienstaatsvertrag-E.
2214 &#167; 94 Absatz 1 Medienstaatsvertrag-E.
2215 Vgl. Schallbruch (2018): Schwacher Staat im Netz, S. 204.
2216 Vgl. Bundesministerium der Finanzen (2014): &#214;ffentlich-rechtliche Medien &#8211; Aufgabe und Finanzierung.
2217 Vgl. Bundesministerium der Finanzen (2014): &#214;ffentlich-rechtliche Medien &#8211; Aufgabe und Finanzierung, S. 13.
2218 Als Vorbild erscheinen die kostenpflichtigen Dienste wie Netflix oder Amazon, die sich vollst&#228;ndig &#252;ber ihre Zuschauer finanzieren.
2219 Vgl. Bundesministerium der Finanzen (2014): &#214;ffentlich-rechtliche Medien &#8211; Aufgabe und Finanzierung, S. 6.
2220 Vgl. Bundesministerium der Finanzen (2014): &#214;ffentlich-rechtliche Medien &#8211; Aufgabe und Finanzierung, S. 38.
2221 Diese elementaren journalistischen Prinzipien aus der angels&#228;chsischen Tradition standen Pate bei der Gr&#252;ndung der ARD 1950, vgl.
Diller (1999): &#214;ffentlich-rechtlicher Rundfunk, S. 149. Heute erinnert der &#167; 26 Absatz 2 Medienstaatsvertrag-E die Anstalten des
&#214;RR an die &#8222;Grunds&#228;tze der Objektivit&#228;t und Unparteilichkeit der Berichterstattung, die Meinungsvielfalt sowie die Ausgewogenheit
ihrer Angebote&#8220; zur Erf&#252;llung ihres Auftrages.
Sondervotum zu den Kapiteln 5.1.1 bis 5.1.3 des Berichts der Projektgruppe 6 &#8222;KI und 
Medien&#8220; (&#8222;Funktionen des Journalismus&#8220;, &#8222;Qualit&#228;t und Ethik des Journalismus&#8220;
und &#8222;Herausforderungen durch die Digitalisierung&#8220;) des Abgeordneten Dr. Marc 
Jongen sowie der Abgeordneten Joana Cotar und Peter Felser
Mittels &#196;nderungsantr&#228;gen wurden seitens der Vertreter der anderen Fraktionen wesentliche Aspekte dieses
Themenkreises, u. a. das spannungsreiche Verh&#228;ltnis von &#8222;hegemonialer &#214;ffentlichkeit&#8220; (Friedrich Krotz) und
sozialen Medien als Artikulationskan&#228;le der Gegen&#246;ffentlichkeitsbewegung, aus dem Teilbericht KI und Medien
getilgt. Als defizit&#228;r muss auch die Behandlung des Themas Fake News betrachtet werden, das einseitig
behandelt wurde und die Instrumentalisierung des Begriffs zur Bek&#228;mpfung politisch unliebsamer Positionen nicht
beleuchtet.
Aus diesen Gr&#252;nden hat sich die AfD-Fraktion entschlossen, f&#252;r diesen Teilbericht ein eigenes Sondervotum
einzubringen, um f&#252;r eine differenzierte Sichtweise der beiden Themenkomplexe &#8222;hegemoniale &#214;ffentlichkeit&#8220;
und soziale Medien sowie Fake News zu sorgen.
Das Verh&#228;ltnis von &#8222;Massen-&#8220; und &#8222;Leitmedien&#8220; als Artikulationsinstanzen &#8222;hegemonialer
&#214;ffentlichkeit&#8220; und den sozialen Medien
Die &#246;ffentliche Kommunikation war bislang vor allem durch die Massenmedien (Zeitungen, Radio, Fernsehen
und Film) gepr&#228;gt, die den Zugang zur &#214;ffentlichkeit bestimmten und f&#252;r die Themensetzung (&#8222;Agenda setting&#8220;) 
sorgten. Innerhalb dieser Massenmedien kam bestimmten Leitmedien eine meinungsbestimmende Bedeutung zu.
Thematisch dominierte vor allem das, was von den etablierten und einflussreichen Parteien, Verb&#228;nden oder
Interessengruppen2222 vorgebracht und verhandelt wurde. Die Leitmedien orientieren sich hierbei h&#228;ufig, wie der
Medienwissenschaftler Otfried Jarren feststellte, an den Argumentationsmustern der gesellschaftlichen Eliten2223, 
was in einem gewissen Spannungsverh&#228;ltnis mit ihrer &#8222;Kontrollfunktion&#8220; steht, die sich nicht nur auf den
&#8222;politisch-staatlichen Bereich&#8220;, sondern auch auf &#8222;wirtschaftliche Akteure&#8220; erstreckt.2224 Positionen, die von gering 
oder schwach organisierten Interessengruppen vertreten werden, oder Themen, die als politisch unkorrekt gelten, 
hatten es deshalb bisher schwer, Zugang zu Massenmedien und damit zur &#214;ffentlichkeit zu erhalten. 
Seit einigen Jahren ist eine deutliche Bedeutungsverschiebung weg von den traditionellen Leit- und
Massenmedien, allen voran dem &#246;ffentlich-rechtlichen Rundfunk, aber auch f&#252;hrenden Medien des Printjournalismus, hin 
zu den Social-Media-Plattformen2225 zu konstatieren. Diese Plattformen haben einen signifikanten Zuwachs an 
neuen Kommunikationsm&#246;glichkeiten f&#252;r Individuen, Gruppen oder Netzwerke gebracht2226, der die Reichweite
der bisherigen Themengeber reduziert, mit der Konsequenz, dass sich die Kommunikationsstrukturen zwischen
Leit- und Massenmedien und politischen Akteuren zunehmend wandeln.
Die sozialen Medien transportieren in gro&#223;er Zahl Standpunkte, Kritiken oder Bewertungen in die &#214;ffentlichkeit,
die diskursrelevant werden k&#246;nnen. Die bisherige journalistische &#8222;Gatekeeper&#8220;-Funktion nimmt damit
zunehmend ab. Damit verliere, so urteilt Otfried Jarren, auch der journalistische Darstellungsstil &#8211; &#8222;Sprache; bildliche
Darstellungsformen; Formen der Kritik etc.&#8220; &#8211; seine &#8222;pr&#228;gende Funktion&#8220;.2227 
Soziale Netzwerke geh&#246;ren damit zu den wichtigsten Artikulationskan&#228;len der Gegen&#246;ffentlichkeitsbewegung,
die Themen transportiert, die in der &#8222;hegemonialen &#214;ffentlichkeit&#8220; nicht oder nur marginal thematisiert werden. 
Unter &#8222;Gegen&#246;ffentlichkeit&#8220; ist &#8222;eine gegen eine hegemoniale &#214;ffentlichkeit gerichtete Teil&#246;ffentlichkeit&#8220; zu 
verstehen, &#8222;die um einen spezifischen gesellschaftlichen Diskurs oder Standpunkt herum strukturiert ist&#8220;.2228 
2222 Hierzu z&#228;hlen unter anderem Parteien, Medien, Nichtregierungsorganisationen (NGOs), Gewerkschaften und sonstige
Interessenverb&#228;nde.
2223 Vgl. hierzu Jarren (2019): Medien- und &#214;ffentlichkeitswandel durch Social Media als gesellschaftliche Herausforderung wie als
Forschungsfeld, S. 361.
2224 Siehe dazu Kapitel 5.1.1 des Berichts der Projektgruppe &#8222;KI und Medien&#8220; [Funktionen des Journalismus].
2225 Soziale Online-Netzwerke, Instant-Messenger, Suchmaschinen oder Videoportale gelten als sogenannte Intermedi&#228;re und sind zu 
wesentlichen Elementen des Kommunikations- und Informationsverhaltens herangewachsen, vgl. hierzu Kapitel 4.2.3 des Berichts
der Projektgruppe &#8222;KI und Medien&#8220; [Intermedi&#228;re: Plattformen und soziale Medien].
2226 Vgl. summarisch dazu Castells (2017): Der Aufstieg der Netzwerkgesellschaft.
2227 Jarren (2019): Medien- und &#214;ffentlichkeitswandel durch Social Media als gesellschaftliche Herausforderung wie als Forschungsfeld,
S. 353.
2228 Krotz (1998): Stichwort Gegen&#246;ffentlichkeit, S. 653.
Soziale Medien als wesentlicher Treiber des Wandels der &#246;ffentlichen Kommunikationskultur
Soziale Medien sind, dar&#252;ber d&#252;rfte Konsens herrschen, ein wesentlicher Treiber des Wandels der &#246;ffentlichen
Kommunikationskultur und damit auch im Hinblick auf das Verst&#228;ndnis von &#214;ffentlichkeit.2229 Journalistische
Standards, so z. B. die bisher obligatorische Norm, zwischen Bericht und Meinung zu trennen, gelten hier
nicht.2230 Es gibt deshalb Stimmen, die von einem &#8222;neuen Strukturwandel&#8216; der &#214;ffentlichkeit&#8220;2231 sprechen, um
&#8211; mit Anspielung auf eine einschl&#228;gige Arbeit von J&#252;rgen Habermas2232 &#8211; den ver&#228;nderten &#8222;Bedingungen und
Formen &#246;ffentlicher Kommunikation&#8220; Rechnung zu tragen. 
Dieser &#8222;Strukturwandel&#8220; d&#252;rfte durch die &#8222;algorithmengetriebenen Vermittlungslogiken sozialer Netzwerke&#8220;
weiter voranschreiten, weil sich die &#8222;algorithmenbasierte Aufmerksamkeitssteuerung&#8220;2233, die k&#252;nftig
zunehmend auch auf KI basieren wird, an den quantitativ gr&#246;&#223;ten Publikumsgruppen orientiert. Entsprechend m&#252;sse
sich auch das journalistische &#8222;Kuratieren in sozialen Netzwerken&#8220; &#8222;zwangsl&#228;ufig deren Logiken anpassen&#8220;2234, 
stellen Birgit Stark und Melanie Magin fest. Diese Entwicklungen d&#252;rften mit dem zunehmenden Einsatz von KI
zunehmend befeuert werden.
Wenn Klicks zu einer Art Ranking werden, liegt es nahe, dass Journalisten ihre Aktivit&#228;ten zunehmend ins
Internet verlagern und sich an Kriterien orientieren, die Aufmerksamkeit garantieren und Klickraten steigern. Die
Medienlogik passt sich damit zunehmend &#8222;den Intermedi&#228;rslogiken&#8220; an, n&#228;mlich der algorithmischen Filterung, 
Sortierung und Personalisierung.2235 
Die Gefahr der Ausgrenzung missliebiger Meinungen durch das Netzwerkdurchsetzungsgesetz
Die hiermit einhergehende Verwischung bisheriger Standards hat zu einer gesellschaftlichen Norm- wie
Regeldiskussion &#252;ber die Kommunikationskultur gef&#252;hrt, die sich unter anderem auch um Begriffe wie &#8222;fake news&#8220;, 
&#8222;shit storms&#8220; oder &#8222;hate speech&#8220; gruppiert2236, mit der Meinungsbilder verf&#228;lscht werden k&#246;nnen oder auch
Mobbing gegen missliebige Meinungen oder Personen ausge&#252;bt werden kann. Abhilfe soll hier unter anderem das
Gesetz zur Verbesserung der Rechtsdurchsetzung in sozialen Netzwerken (Netzwerkdurchsetzungsgesetz &#8211;
NetzDG) schaffen. Dieses Gesetz zwingt Plattformbetreiber in Form von Verfahrensvorschriften dazu,
rechtswidrige Inhalte innerhalb von 24 Stunden zu l&#246;schen.
Aus Sicht der AfD kann es nicht angehen, dass der Schutz der freien Meinungs&#228;u&#223;erung in den sozialen
Netzwerken mittels NetzDG auf private Akteure verlagert wird und der Rechtsstaat sich auf diese Weise aus der
Verantwortung stiehlt. Die AfD fordert deshalb die ersatzlose Streichung des NetzDG.2237 
Sondervotum zu den Kapiteln 5.1.1 bis 5.1.3 des Berichts der Projektgruppe 6 &#8222;KI und 
Medien (&#8222;Funktionen des Journalismus&#8220;, &#8222;Qualit&#228;t und Ethik des Journalismus&#8220; und 
&#8222;Herausforderungen durch die Digitalisierung&#8220;) des Abgeordneten Dr. Marc Jongen
sowie der Abgeordneten Joana Cotar und Peter Felser
Im 5. Kapitel des Teilberichts der Projektgruppe 6 &#8222;KI und Medien&#8220; wird es als eine Aufgabe der Journalisten 
beschrieben, Unwahrheiten, &#8222;Fake News&#8220;, Propaganda oder Verleumdungen zu identifizieren. Hierf&#252;r haben sich
mittlerweile sogenannte Faktenchecker etabliert, wie sie in Gestalt spezialisierter Redaktionen beim
&#246;ffentlichrechtlichen Rundfunk oder in Gestalt des journalistischen Recherchezentrums Correctiv existieren und die auch
2229 Vgl. hierzu z. B. Godulla (2017): &#214;ffentliche Kommunikation im digitalen Zeitalter, S. 31-38.
2230 Vgl. hierzu z. B. Bei&#223;wenger (2016): Praktiken in der internetbasierten Kommunikation.
2231 Imhof (2006): Politik im &#8222;neuen&#8220; Strukturwandel der &#214;ffentlichkeit.
2232 Vgl. Habermas (1990): Strukturwandel der &#214;ffentlichkeit.
2233 Stark und Magin (2019): Neuer Strukturwandel der &#214;ffentlichkeit durch Informationsintermedi&#228;re: Wie Facebook, Google &amp; Co. die
Medien und den Journalismus ver&#228;ndern, S. 398.
2234 Stark und Magin (2019): Neuer Strukturwandel der &#214;ffentlichkeit durch Informationsintermedi&#228;re: Wie Facebook, Google &amp; Co. die
Medien und den Journalismus ver&#228;ndern, S. 398.
2235 Vgl. Stark und Magin (2019): Neuer Strukturwandel der &#214;ffentlichkeit durch Informationsintermedi&#228;re: Wie Facebook, Google &amp;
Co. die Medien und den Journalismus ver&#228;ndern, S. 399.
2236 Vgl. Jarren (2019): Medien- und &#214;ffentlichkeitswandel durch Social Media als gesellschaftliche Herausforderung wie als
Forschungsfeld, S. 352. (Vgl. auch das Sondervotum 3.14 zu Fake News [Sondervotum zu den Kapiteln 5.1.1 bis 5.1.3 des Berichts der
Projektgruppe 6 &#8222;KI und Medien (&#8222;Funktionen des Journalismus &#8220;, &#8222;Qualit&#228;t und Ethik des Journalismus &#8220; und &#8222;Herausforderungen 
durch dieDigitalisierung &#8220;) des Abgeordneten Dr. Marc Jongen sowie der Abgeordneten Joana Cotar und Peter Felser]).
2237 Siehe hierzu ausf&#252;hrlich das Sondervotum 3.15 zum Netzwerkdurchsetzungsgesetz [Sondervotum zu den Kapiteln 7.4.2 und 7.4.2.1 
des Berichts der Projektgruppe 6 &#8222;KI und Medien&#8220; (&#8222;Hassrede&#8220; und &#8222;Das Netzwerkdurchsetzungsgesetz gegen Hassrede&#8220;) der
Abgeordneten Joana Cotar sowie der Abgeordneten Peter Felser und Dr. Marc Jongen].
auf spezialisierte Software zum Aufsp&#252;ren von Fake News zur&#252;ckgreifen. Nicht zum Ausdruck kommt im
Bericht, dass die verf&#228;nglichsten, weil herkunftsbedingt als besonders glaubw&#252;rdig geltenden Fake News auch von
Instanzen (wie z. B. Teile der Leitmedien)  verbreitet werden, die nach aktuellen Vorschl&#228;gen aus der
Medienwissenschaft sowie gem&#228;&#223; der Praxis des &#246;ffentlich-rechtlichen Rundfunks und des deutschen Ablegers von
Facebook als Vorbilder f&#252;r die Bek&#228;mpfung von Fake News dienen sollen.
Die Diskussion um Fake News ist einseitig und interessengesteuert
Der Begriff Fake News ist weder juristisch definiert, noch wird er in den vorliegenden Berichten der KI-Enquete
einheitlich verwendet. W&#228;hrend er an einer Stelle synonym mit &#8222;Falschnachrichten&#8220; und an anderer Stelle
synonym mit &#8222;Falsche[n] Informationen&#8220; verwendet wird, steht er im Bericht der Projektgruppe &#8222;KI und Medien&#8220;, 
Kapitel 5. 1 [Analyse des Einsatzes von KI im klassischen Journalismus], in einer Aufz&#228;hlung mit
&#8222;Unwahrheiten&#8220;, &#8222;Propaganda&#8220; und &#8222;Verleumdungen&#8220; &#8211; scheint mit diesen Begriffen also verwandt, jedoch mit keinem
davon identisch zu sein. Ein Blick auf medienwissenschaftliche Definitionsversuche best&#228;tigt dabei den Eindruck
grunds&#228;tzlicher Schwierigkeiten bei der Identifikation und etwaigen Bek&#228;mpfung von Fake News mittels KI.
Fake News sind demnach Beitr&#228;ge in journalistischer Form, deren Aussage oder Darstellung nicht mit der
Faktenlage &#252;bereinstimmt.2238 Es besteht dabei kein wissenschaftlicher Konsens, ob eine bewusste Erfindung oder
Verf&#228;lschung zur Erreichung politischer oder kommerzieller Ziele vorliegen muss.2239 Aber auch wenn man eines
dieser Motive voraussetzte, bliebe das Problem bestehen, dass einerseits das Motiv in jedem Fall nachzuweisen
w&#228;re und andererseits, dass von einer solchen Definition auch Satire erfasst w&#252;rde. 
Zu nennen ist in diesem Zusammenhang auch die steigende Bedeutung von Social Bots, also Programmen, die
in sozialen Netzwerken menschliche Verhaltensmuster nachahmen und als (falscher) Account auftauchen. Social
Bots, die im steigenden Ma&#223;e k&#252;nstliche Intelligenz einsetzen, k&#246;nnen auch f&#252;r politische Propaganda
missbraucht werden. Die gesteuerten Konten dienen dazu, ein hohes Interesse f&#252;r bestimmte Inhalte vorzut&#228;uschen.
Social Bots sind aufgrund ihrer hohen Verbreitungsgeschwindigkeit mutma&#223;lich geeignet, die freie Meinungs-
und Willensbildung durch manipulative Eingriffe in eine bestimmte Richtung zu beeinflussen. Diese Eingriffe
werden in erster Linie &#8222;migrationsfeindlichen, rechtspopulistischen Echokammern&#8220; zugeschrieben, die &#8222;ganze 
Informations- und Medien&#246;kosysteme herausgebildet&#8220; h&#228;tten und &#8222;die Diskussionen im Netz beeinflussen&#8220;2240, 
was zu Verunsicherung und Polarisierung f&#252;hre. 
Nicht thematisiert werden in der Regel hingegen Fake News, die von solchen Medien verbreitet werden, die ein
besonders hohes Vertrauen unter den B&#252;rgern genie&#223;en &#8211; allen voran also solche von Leitmedien, aber auch
staatlicher Stellen.2241 Die deutschen Leitmedien, einschlie&#223;lich der &#246;ffentlich-rechtlichen Rundfunkanstalten, 
geben Anlass, begr&#252;ndete Zweifel an ihrer Professionalit&#228;t und Objektivit&#228;t zu hegen.2242 
Fake News in den Leitmedien
So kam die von der Hamburg Media School durchgef&#252;hrte Studie &#8222;Die ,Fl&#252;chtlingskrise&#8216; in den Medien.
Tagesaktueller Journalismus zwischen Meinung und Information&#8220; beispielsweise zu dem Ergebnis, dass &#252;ber 80
Prozent der untersuchten Medienberichte von Leit-, Lokal- und Regionalmedien aus ganz Deutschland die
sogenannte Fl&#252;chtlingskrise und das Handeln der deutschen Bundesregierung im Jahr 2015 eindeutig positiv
darstellten, w&#228;hrend nur 6 Prozent m&#246;gliche Probleme massenhafter, illegaler Zuwanderung thematisierten.2243
Studienleiter Michael Haller urteilte, statt &#8222;kritisch zu berichten, habe der &#8222;Informationsjournalismus die Sicht, auch die
Losungen der politischen Elite&#8220; &#252;bernommen und sei selbst &#8222;mehr als politischer Akteur denn als neutraler
Beobachter aufgetreten&#8220;2244. Es handelte sich dabei nicht nur in informativer Hinsicht um nahezu fl&#228;chendeckendes
2238 Vgl. Appel und Doser (2020): Fake News, S. 10.
2239 Vgl. Appel und Doser (2020): Fake News, S. 11.
2240 Vgl. z. B. Die Beauftragte der Bundesregierung f&#252;r Migration, Fl&#252;chtlinge und Integration (2019): Deutschland kann Integration: 
Potenziale f&#246;rdern, Integration fordern, Zusammenhalt st&#228;rken, S. 50, 55.
2241 Vgl. Appel und Doser (2020): Fake News, S. 15.
2242 Vgl. Sondervotum 3.12 [Sondervotum zu den Kapiteln 1 und 4.3 des Berichts der Projektgruppe 6 &#8222;KI und Medien&#8220; (&#8222;Kurzfassung 
des Projektgruppenberichts &#8220; und &#8222;Ziele und Aufgaben von Medienpolitik &#8220;) der Abgeordneten Joana Cotar sowie der Abgeordneten
Peter Felser und Dr. Marc Jongen].
2243 Vgl. Scheer (2016): Alle sind willkommen; Hoffgaard (2016): Zu viel Willkommenskultur in den Medien.
2244 Scheer (2017): Wie Medien &#252;ber die Fl&#252;chtlingskrise berichteten.
Medienversagen, sondern um die affirmative Begleitung des, nach Einsch&#228;tzung des Staatsrechtlers Rupert
Scholz, gr&#246;&#223;ten Verfassungsbruches in der Geschichte der Bundesrepublik.2245 
Die Problematik der sogenannten Faktenchecker
Durch den Einsatz von KI zur Bek&#228;mpfung von Fake News k&#246;nnte deren Schadwirkung sogar noch verst&#228;rkt
werden. Denn bei KI-Anwendungen, die dazu eingesetzt werden k&#246;nnen, Nachrichten herauszufiltern, deren
Wahrheitsgehalt &#252;berpr&#252;ft werden soll2246, stellt sich notwendig die Frage nach deren Datengrundlage, also
woher diese ihren Ma&#223;stab von faktischer Korrektheit beziehen sollten. Verschiedene Medienwissenschaftler
schlagen hierf&#252;r Wikipedia, die Leitmedien und sogenannte Faktenchecker vor, wie sie in Gestalt spezialisierter
Redaktionen beim &#246;ffentlich-rechtlichen Rundfunk oder des journalistischen Recherchezentrums Correctiv
existieren.2247 Der Verweis auf Wikipedia muss verwundern. Wie anf&#228;llig gerade dieses Projekt f&#252;r die Produktion von 
Fake News ist, dokumentiert zum Beispiel das &#8222;Schwarzbuch Wikipedia&#8220;.2248 
Zur &#8222;Aufkl&#228;rung von Fake News&#8220;2249 wurde unter anderem das ARD-Onlineportal &#8222;faktenfinder&#8220; gegr&#252;ndet. Zur
Grenz&#246;ffnung im Jahre 2015 behaupteten dessen Projektleiter Patrick Gensing2250 und seine Kollegen 2018
beispielsweise, diese sei schon deshalb kein Rechtsbruch gewesen, weil sie gar nicht erst stattgefunden habe,
schlie&#223;lich h&#228;tte es bereits vor 2015 keine Grenzen innerhalb des Schengen-Raums gegeben.2251 Daher sei die 
Grenz&#246;ffnung lediglich eine Erfindung von AfD- und CSU-Politikern.2252 
Diese Behauptung irritiert schon deshalb, weil ein Gutachten des Wissenschaftlichen Dienstes des Bundestages
bereits 2017 zu dem Schluss kam, dass die Bundesregierung eben nicht rechtlich erkl&#228;rt habe, weshalb
Ma&#223;nahmen der Zur&#252;ckweisung an der Grenze mit Bezug auf um Schutz nachsuchende Drittstaatsangeh&#246;rige &#8222;derzeit
nicht zur Anwendung&#8220; k&#228;men und diese den Vorwurf, dass dies schlicht auf Anweisung aus dem
Innenministerium geschehe, eben nicht entkr&#228;ftete.2253 Auch der Verweis auf Abwesenheit von Grenzen im Schengen-Raum 
ist verfehlt, da die EU-Freiz&#252;gigkeit f&#252;r Personen mit Pass und Schengen-Visum gilt und nicht f&#252;r
Asylbewerber.2254 Insofern bestand und besteht nicht die Frage, ob es eine Grenz&#246;ffnung gab, sondern ob diese rechtm&#228;&#223;ig 
erfolgte. Entsprechend bietet eine Dokumentation des Wissenschaftlichen Dienstes des Bundestages von 2018
eine &#8222;Zusammenstellung der in der rechtswissenschaftlichen Literatur vertretenen Auffassungen zur rechtlichen
Beurteilung der sog. Grenz&#246;ffnung Anfang September 2015&#8220;, in der es seitens der Staatsrechtler Tabbert und
Wagenseil hei&#223;t: &#8222;Die zeitlich und quantitativ unbeschr&#228;nkte Aufrechterhaltung der Grenz&#246;ffnung durch den
Bundesinnenminister kann ohne Zweifel als wesentliche Entscheidung angesehen werden, die von der
Anordnungsbefugnis des &#167; 18 Absatz 4 Nummer 2 AsylG nicht mehr gedeckt ist.&#8220;2255 Hier zeigt sich beispielhaft, wie
zweifelhaft der Anspruch des Online-Portals &#8222;faktenfinder&#8220; im Hinblick auf die Aufkl&#228;rung von Fake News ist. 
Handlungsempfehlungen
Die hier angef&#252;hrten Beispiele veranschaulichen das Problem, dass die verf&#228;nglichsten, weil herkunftsbedingt
als besonders glaubw&#252;rdig geltenden Fake News nicht selten auch von eben den Stellen verbreitet werden, die
nach aktuellen Vorschl&#228;gen aus der Medienwissenschaft sowie gem&#228;&#223; der Praxis des &#246;ffentlich-rechtlichen
Rundfunks und des deutschen Ablegers von Facebook als Vorbilder f&#252;r die Bek&#228;mpfung von Fake News dienen
sollen. Auf KI-Anwendungen &#252;bertragen w&#252;rde die &#8222;hegemoniale &#214;ffentlichkeit&#8220; und der durch den im Be-
2245 Vgl. Steinwandter (2019): Rupert Scholz wirft Regierung andauernden Verfassungsbruch vor.
2246 Vgl. D&#246;rh&#246;fer (2020): K&#252;nstliche Intelligenz gegen Fake News.
2247 Vgl. Appel (2020): Wie l&#228;sst sich das Postfaktische eind&#228;mmen?, S. 205 ff.; Morawietz (2019): Alternative Fakten, Fake-News und
L&#252;gen mit dem Internet einfach enttarnen, S. 69 f., 74.
2248 Weitere Informationen dazu unter: https://www.schwarzbuch-wikipedia.de/ (zuletzt abgerufen am 13. Oktober 2020).
2249 Schick (2017): Fake News aufsp&#252;ren und aufkl&#228;ren.
2250 In einem Interview mit dem Medienmagazin &#8222;Vocer&#8220; erkl&#228;rte Gensing 2015, als Jugendlicher &#8222;Antifa m&#228;&#223;ig unterwegs&#8220; [sic]
gewesen zu sein, vgl. Reveland (2015): Patrick Gensing: &#8220;Medien d&#252;rfen keine &#196;ngste sch&#252;ren&#8220;.
2251 Vgl. Meyer (2018): Moderne Dolchsto&#223;legende.
2252 Vgl. Fischhaber (2018): Manipulation zugunsten von Angela Merkel? Das ist an Vorw&#252;rfen gegen die &#8222;Tagesschau&#8220; dran.
2253 Vgl. Die Wissenschaftlichen Dienste des Deutschen Bundestages (2017): Einreiseverweigerung und Einreisegestattung nach &#167; 18 
Asylgesetz, S. 11.
2254 Vgl. Vosgerau (2018): Hat sie, oder hat sie nicht?
2255 Die Wissenschaftlichen Dienste des Deutschen Bundestages (2018): Rechtsauffassungen zur Einreiseverweigerung und
Einreisegestattung im Zusammenhang mit der sog. Grenz&#246;ffnung, S. 9.
richtstext selbst kritisierte Mechanismus der Undurchsichtigkeit und vermeintlichen Objektivit&#228;t von KI-
Anwendungen damit noch verst&#228;rkt.2256 Die Verwendung von KI zur Bek&#228;mpfung von Fake News w&#228;re unter diesen
Bedingungen nicht zu leisten und w&#252;rde selbst die Reproduktion von Fake News, gerade solchen von
hegemonialer Herkunft und eine Verengung von Meinungskorridoren, bef&#246;rdern. Entsprechend lautet die
Handlungsempfehlung, den Radar f&#252;r die Ortung und Bek&#228;mpfung von Fake News deutlich auszuweiten und nicht nur auf
Str&#246;mungen zu richten, deren Bek&#228;mpfung gerade als politisch opportun gilt. &#220;berdies ist es aus Sicht der AfD
dringend notwendig, eine wissenschaftlich tragf&#228;hige und rechtlich bindende Definition von Fake News zu
erarbeiten, die den Geltungsbereich des Begriffs auf jene F&#228;lle einschr&#228;nkt, die eindeutig falsche
Tatsachenbehauptungen darstellen, sodass ein Missbrauch zur Bek&#228;mpfung missliebiger Meinungen oder Interpretation von
Tatsachen ausgeschlossen wird.
Sondervotum zu den Kapiteln 7.4.2 und 7.4.2.1 des Berichts der Projektgruppe 6 &#8222;KI
und Medien&#8220; (&#8222;Hassrede&#8220; und &#8222;Das Netzwerkdurchsetzungsgesetz gegen Hassrede&#8220;) 
der Abgeordneten Joana Cotar sowie der Abgeordneten Peter Felser und Dr. Marc 
Jongen 
Das NetzDG tr&#228;gt nicht dazu bei, politische Kommunikation im Internet zu zivilisieren. Es wird h&#246;chste Zeit, 
sich vom Konzept der &#8222;Hassrede&#8220; zu verabschieden.
Vorbemerkung
Im Berichtsteil 7.4.2 des Berichtes der Projektgruppe &#8222;KI und Medien&#8220; [Hassrede] wird am Beispiel
ausgew&#228;hlter gro&#223;er Plattformen dargestellt, welchen Anteil bereits heute automatisierte KI-L&#246;sungen am Finden und
L&#246;schen von Beitr&#228;gen haben, die gegen die Nutzungsbedingungen der Plattformen versto&#223;en. Der Geltungsbereich
dieser firmeneigenen Richtlinien wird durch das Gesetz zur Verbesserung der Rechtsdurchsetzung in sozialen
Netzwerken (Netzwerkdurchsetzungsgesetz &#8211; NetzDG)2257 erweitert. Damit soll einer zunehmenden Verrohung
der Kommunikation im Internet, speziell in den sozialen Medien, begegnet werden. Das seit Oktober 2017 in
Kraft befindliche NetzDG verpflichtet die Betreiber gro&#223;er Plattformen obendrein, so sie mehr als zwei Millionen
registrierte Nutzer in Deutschland haben, offensichtlich rechtswidrige Inhalte innerhalb von 24 Stunden nach
Eingang einer Beschwerde zu entfernen oder zu sperren und dar&#252;ber Bericht zu f&#252;hren (Kapitel 7.4.2.1 des
Berichts der Projektgruppe &#8222;KI und Medien [Das Netzwerkdurchsetzungsgesetz gegen Hassrede]).
Der von der AfD-Fraktion urspr&#252;nglich in diesem Textteil vorgebrachte Hinweis, dass mit der Pflicht zur
L&#246;schung offensichtlich rechtswidriger Beitr&#228;ge und deren Dokumentation gem&#228;&#223; NetzDG durch die Plattformen
eine unzul&#228;ssige Privatisierung der Rechtsprechung an den ordentlichen Gerichten vorbei stattfinde, wurde von
der Mehrheit der Projektgruppe verworfen und aus dem Projektbericht entfernt. Das kann aus Sicht der AfD-
Fraktion nicht unwidersprochen bleiben. Aus Sicht der AfD-Fraktion greift das NetzDG tief in die
grundgesetzlich verankerte Meinungsfreiheit2258 auch im Internet ein; die mit ihm einhergehende Privatisierung respektive
Entstaatlichung der Rechtsprechung und -durchsetzung ist dabei nur sein offenkundigster Fehler.2259 
Die AfD-Fraktion kritisiert das NetzDG und fordert dessen Abschaffung, weil es den Intermedi&#228;ren auferlegt,
sogenannte &#8222;Hassrede&#8220; zu detektieren und zu l&#246;schen und die Rechtsprechung damit privatisiert. Das NetzDG
greift tief in die Meinungsfreiheit im Internet ein, f&#252;hrt zu einem &#8222;Overblocking&#8220; zahlreicher Beitr&#228;ge und ist
formell und materiell verfassungswidrig. In den L&#246;schzentren der Intermedi&#228;re entscheiden juristisch sekund&#228;r
Qualifizierte &#252;ber die Einstufung einzelner Beitr&#228;ge als l&#246;schenswert. Dem Rechtsstaat wird dadurch die
Verantwortung entzogen. Noch sind es in Deutschland Gerichte, die Recht sprechen, das darf nicht an
privatwirtschaftlich orientierte Unternehmen delegiert werden.
2256 Vgl. das Sondervotum 3.1 [Sondervotum zu Kapitel 3 des Mantelberichts (&#8222;KI und Umgang mit Bias/Diskriminierung&#8220;) des
Abgeordneten Dr. Marc Jongen sowie der Abgeordneten Joana Cotar und Peter Felser].
2257 Vgl. Gesetz zur Verbesserung der Rechtsdurchsetzung in sozialen Netzwerken (Netzwerkdurchsetzungsgesetz &#8211; NetzDG):
https://www.gesetze-im-internet.de/netzdg/BJNR335210017.html (zuletzt abgerufen am 13. Oktober 2020).
2258 Artikel 5 Absatz 1 GG.
2259 En passant wird Artikel 103 Absatz 1 GG, nachdem vor Gericht jedermann Anspruch auf rechtliches Geh&#246;r habe, suspendiert.
Argumentation
Der Informatiker Martin Schallbruch, stellvertretender Direktor des Digital Society Institute der European School
of Management and Technology, Berlin, dokumentiert, dass gro&#223;e digitale Plattformen normativ Regeln des
Zusammenlebens setzen und bestimmen, wie Menschen im digitalen Raum miteinander umgehen: &#8222;Was auf
digitalen Plattformen passiert, ist dabei stets ein Produkt aus zwei Faktoren: den Algorithmen und Regeln der
Plattform sowie dem Verhalten der Nutzerinnen und Nutzer.&#8220;2260 Dieses Geschehen findet sich kodifiziert in den
internen Richtlinien, die sich die gro&#223;en Plattformen selbst geben; zum Teil aus wirtschaftlichen Motiven im
Sinne ungest&#246;rter Werbegesch&#228;fte, zum Teil aus einem Bewusstsein gesellschaftlicher Verantwortung.
Kein demokratisch legitimiertes Recht auf den Plattformen
Das Verabschieden des NetzDG kommentiert Schallbruch wie folgt: &#8222;Plattformen werden verpflichtet, eine Art 
Gerichtsbarkeit einzuf&#252;hren, die die widerstrebenden Interessen ihrer Nutzer abw&#228;gt. Damit setzt der Staat nicht
sein eigenes, demokratisch legitimiertes Recht auf den Plattformen durch, vielmehr akzeptiert er die normative 
Kraft der Plattformen. Er schiebt den Feudalherren der Technologiekonzerne, wie Morozov sie genannt hat, im
Grunde noch mehr Verantwortung und Macht zu. Der Staat betreibt seine Entmachtung selbst.&#8220;2261 Und, so lie&#223;e
sich erg&#228;nzen, er akzeptiert, dass die Plattformen im Zweifel eher einen Beitrag zu viel l&#246;schen, um sich nicht
der Gefahr einer hohen Bu&#223;geldzahlung auszusetzen.
Die prinzipielle wie detaillierte Kritik, die bereits im Vorfeld der Verabschiedung des NetzDG von verschiedenen
Seiten artikuliert wurde, kann anl&#228;sslich einer Anh&#246;rung im Ausschuss f&#252;r Recht und Verbraucherschutz des
Deutschen Bundestages im Mai 2019 nur wiederholt werden. Sabine Frank, Leiterin Regulierung, Verbraucher-
und Jugendschutz der Google Germany GmbH, h&#228;lt die bleibende Sorge vor einer vorauseilenden &#252;berm&#228;&#223;igen
Sperrung legitimer Inhalte f&#252;r berechtigt.2262 F&#252;r sie hat das NetzDG den absurden Effekt, dass es Symptome
(einer Hassrede) bei den sozialen Netzwerken, aber nicht deren Ursachen bei den T&#228;tern bek&#228;mpfe.2263 
Aufhebung des NetzDG w&#228;re ein Akt parlamentarischer Hygiene
Der Rechtsanwalt Joachim Nikolaus Steinh&#246;fel aus Hamburg sagt bei der zitierten Anh&#246;rung, dass die sozialen
Netzwerke im Vergleich zu traditionellen Medien einen freien und unmittelbaren Meinungsaustausch
erm&#246;glichten.2264 Er halte es f&#252;r &#8222;einen Akt demokratischer, parlamentarischer und gesetzgeberischer Hygiene, das NetzDG
aufzuheben&#8220;2265; erhaltenswerte Vorschriften des NetzDG (Beschwerdesystem, Berichts- und
Transparenzpflichten, Zustellungsbevollm&#228;chtigter) sollten in ein &#8222;neu zu formulierendes Gesetz, in dessen Mittelpunkt die
Freiheits- und B&#252;rgerrechte im Internet stehen&#8220;, aufgenommen werden.2266 
2260 Schallbruch (2018): Schwacher Staat im Netz, S. 98.
2261 Schallbruch (2018): Schwacher Staat im Netz, S. 105.
2262 Stellungnahme im Rahmen der &#246;ffentlichen Anh&#246;rung des Ausschusses f&#252;r Recht und Verbraucherschutz des Deutschen Bundestages
am 15. Mai 2019, S. 16, abrufbar unter: https://www.bundestag.de/resource/blob/642500/f7cbbae5c4c97e6c601049d4182e7eca/frank-
data.pdf (zuletzt abgerufen am 16. Oktober 2020).
2263 Stellungnahme im Rahmen der &#246;ffentlichen Anh&#246;rung des Ausschusses f&#252;r Recht und Verbraucherschutz des Deutschen Bundestages
am 15. Mai 2019, S. 18, abrufbar unter: https://www.bundestag.de/resource/blob/642500/f7cbbae5c4c97e6c601049d4182e7eca/frank-
data.pdf  (zuletzt abgerufen am 16. Oktober 2020).
2264 Stellungnahme zur &#246;ffentlichen Anh&#246;rung zum Thema Netzwerkdurchsetzungsgesetz vor dem Ausschuss f&#252;r Recht und
Verbraucherschutz des Deutschen Bundestages am 15. Mai 2019 in Berlin, insb. zu dem Gesetzentwurf der Fraktion der AfD,
Bundestagsdrucksache 19/81, zu dem Gesetzentwurf der Fraktion DIE LINKE., Bundestagsdrucksache 19/218, zu dem Antrag von B&#220;NDNIS
90/DIE GR&#220;NEN, BT-Dr. 19/5950 und zu dem Gesetzentwurf der Fraktion der FDP, Bundestagsdrucksache 19/204, S. 5, abrufbar
unter: https://www.bundestag.de/resource/blob/642460/8d38f23716a2ec6100809edb1c4d6c58/steinhoefel-data.pdf (zuletzt
abgerufen am 16. Oktober 2020).
2265 Stellungnahme zur &#246;ffentlichen Anh&#246;rung zum Thema Netzwerkdurchsetzungsgesetz vor dem Ausschuss f&#252;r Recht und
Verbraucherschutz des Deutschen Bundestages am 15. Mai 2019 in Berlin, insb. zu dem Gesetzentwurf der Fraktion der AfD,
Bundestagsdrucksache 19/81, zu dem Gesetzentwurf der Fraktion DIE LINKE., Bundestagsdrucksache 19/218, zu dem Antrag von B&#220;NDNIS
90/DIE GR&#220;NEN, Bundestagsdrucksache 19/5950 und zu dem Gesetzentwurf der Fraktion der FDP, Bundestagsdrucksache 19/204,
S. 4, abrufbar unter: https://www.bundestag.de/resource/blob/642460/8d38f23716a2ec6100809edb1c4d6c58/steinhoefel-data.pdf
(zuletzt abgerufen am 16. Oktober 2020).
2266 Stellungnahme zur &#246;ffentlichen Anh&#246;rung zum Thema Netzwerkdurchsetzungsgesetz vor dem Ausschuss f&#252;r Recht und
Verbraucherschutz des Deutschen Bundestages am 15. Mai 2019 in Berlin, insb. zu dem Gesetzentwurf der Fraktion der AfD,
Bundestagsdrucksache 19/81, zu dem Gesetzentwurf der Fraktion DIE LINKE., Bundestagsdrucksache 19/218, zu dem Antrag von B&#220;NDNIS
90/DIE GR&#220;NEN, Bundestagsdrucksache 19/5950 und zu dem Gesetzentwurf der Fraktion der FDP, Bundestagsdrucksache 19/204,
S. 4, abrufbar unter: https://www.bundestag.de/resource/blob/642460/8d38f23716a2ec6100809edb1c4d6c58/steinhoefel-data.pdf
(zuletzt abgerufen am 16. Oktober 2020).
Mag. Dr. Matthias C. Kettemann, LL.M. (Harvard), vom Leibniz-Institut f&#252;r Medienforschung, kommt bei der
genannten Anh&#246;rung vor dem Rechtsausschuss zu folgendem Ergebnis: &#8222;Eine privatisierte
Rechtsdurchsetzungsstruktur, wie sie das NetzDG vorsieht, spiegelt die Bedeutung der hybriden privaten R&#228;ume mit entscheidender
Relevanz f&#252;r die private wie &#246;ffentliche Kommunikation nicht wider.&#8220;2267 Seiner Ansicht nach stehen Staaten &#8211;
und nicht Unternehmen &#8211; in der Pflicht, das Recht auf freie Meinungs&#228;u&#223;erung im digitalen Umfeld nicht nur
nicht zu verletzen; sie h&#228;tten weiter die Verpflichtung, &#8222;ein regulatives Umfeld f&#252;r alle zu schaffen, diese Rechte
auch auszu&#252;ben&#8220;.2268 Dar&#252;ber hinaus moniert er mit explizitem KI-Bezug, dass die Regulierung jener
Algorithmen, &#8222;die in sozialen Medien sowohl die Vorschlagsselektion als auch die L&#246;schpraxis bestimmen&#8220;,
unzureichend sei.2269 
Schlussfolgerung
Die AfD-Fraktion ist der Ansicht, dass das NetzDG entgegen der erkl&#228;rten Absicht seiner Bef&#252;rworter nicht dazu
beigetragen hat, die politische Kommunikation im Internet ziviler, demokratischer und &#8222;erwachsener&#8220; zu
machen. Mit der Melde-, Berichts- und L&#246;schpflicht rechtswidriger Beitr&#228;ge (binnen 24 Stunden nach Eingang einer
Beschwerde) l&#228;dt der Staat hoheitliche Aufgaben bei privaten Unternehmen ab, anstatt sie bei den unabh&#228;ngigen
Gerichten zu belassen, wo sie aufgrund unserer Verfassung hingeh&#246;ren. Das NetzDG ist nicht nur ein drastischer
Angriff auf die Meinungsfreiheit auch im Internet, es ersch&#252;ttert zudem die legalen Fundamente unseres
Rechtsstaates. Nicht zuletzt ist es zur Regulierung des kommunikativen Miteinanders auf den sozialen Plattformen
&#252;berfl&#252;ssig: Die hauseigenen Verhaltensrichtlinien der Plattformen sind bewusst weiter und abstrakter gefasst als
die ans StGB angelehnten Meldetatbest&#228;nde des NetzDG. Die im halbj&#228;hrlichen Rhythmus vorgelegten
Transparenzberichte der Plattformen zeigen, dass weitaus mehr Inhalte entlang der eigenen Richtlinien detektiert und
entfernt wurden als nach dem NetzDG &#8211; die Selbstregulierung der Plattformen funktioniert (siehe explizit hierzu
Kapitel 7.4.2.2 des Berichts der Projektgruppe &#8222;KI und Medien&#8220; [Beispiel YouTube]).
Pluralismus nur im freien Austausch verschiedener und auch kontroverser Meinungen
Die Meinungs- und die damit zusammenh&#228;ngende Pressefreiheit sind f&#252;r die AfD-Fraktion nicht verhandelbare
G&#252;ter, nicht nur, weil sie im Katalog der Grundrechte des Grundgesetzes kodifiziert sind. Unter dem Titel
&#8222;Freiheit im Internet &#8211; B&#252;rgerrechte st&#228;rken&#8220; hat die AfD-Fraktion einen Antrag mit dem Ziel gestellt, der Deutsche
Bundestag m&#246;ge die Bundesregierung auffordern, das NetzDG &#8222;ersatzlos zu streichen und im Rahmen der
Meinungsfreiheit privaten Plattformanbietern keine Aufgaben der Strafverfolgungsbeh&#246;rden zu &#252;bertragen&#8220;.2270
Einen entsprechenden Gesetzentwurf hat die AfD-Fraktion bereits zu Beginn der 19. Legislatur vorgelegt.2271 Dabei
hat sie sich von der &#220;berzeugung leiten lassen, dass nur der Austausch verschiedener und damit auch
kontroverser Meinungen den Pluralismus einer demokratischen und liberalen Gesellschaft gew&#228;hrleistet. Es kann nicht
angehen, dass der Schutz der freien Meinungs&#228;u&#223;erung in den sozialen Netzwerken via NetzDG privaten
Akteuren &#252;bertragen wird, derweil der Rechtsstaat sich seiner Verantwortung entzieht.
Ausblick
Anders als im Kapitel 7.4.2.1 des Berichts der Projektgruppe &#8222;KI und Medien&#8220; [Das
Netzwerkdurchsetzungsgesetz gegen Hassrede] postuliert, ist die AfD-Fraktion keineswegs der Ansicht, dass die im April 2020 auf den
Weg gebrachte Weiterentwicklung des NetzDG Transparenz und Nutzerrechte st&#228;rken sowie die
Rechtsdurchsetzung verbessern werde. Die AfD-Fraktion vertritt vielmehr die Auffassung, dass &#8211; unbeschadet der
notwendigen Verfolgung von Straftaten im Internet &#8211; die Bundesregierung mit ihren Vorhaben im Gesetzentwurf2272 weit
2267 Stellungnahme als Sachverst&#228;ndiger f&#252;r die &#246;ffentliche Anh&#246;rung zum Netzwerkdurchsetzungsgesetz auf Einladung des
Ausschusses f&#252;r Recht und Verbraucherschutz des Deutschen Bundestags, 15. Mai 2019, S. 2, abrufbar unter: https://www.bundestag.de/re-
source/blob/642252/6dd66a4ca563336d3bd8ef432aa00bc8/kettemann-data.pdf (zuletzt abgerufen am 16. Oktober 2020).
2268 Stellungnahme als Sachverst&#228;ndiger f&#252;r die &#246;ffentliche Anh&#246;rung zum Netzwerkdurchsetzungsgesetz auf Einladung des
Ausschusses f&#252;r Recht und Verbraucherschutz des Deutschen Bundestags, 15. Mai 2019, S. 6, abrufbar unter: https://www.bundestag.de/re-
source/blob/642252/6dd66a4ca563336d3bd8ef432aa00bc8/kettemann-data.pdf (zuletzt abgerufen am 16. Oktober 2020).
2269 Stellungnahme als Sachverst&#228;ndiger f&#252;r die &#246;ffentliche Anh&#246;rung zum Netzwerkdurchsetzungsgesetz auf Einladung des
Ausschusses f&#252;r Recht und Verbraucherschutz des Deutschen Bundestags, 15. Mai 2019, S. 17, abrufbar unter: https://www.bundestag.de/re-
source/blob/642252/6dd66a4ca563336d3bd8ef432aa00bc8/kettemann-data.pdf (zuletzt abgerufen am 16. Oktober 2020).
2270 Bundestagsdrucksache 19/10172, S. 2.
2271 Bundestagsdrucksache 19/81.
2272 Der &#8222;Entwurf eines Gesetzes zur Bek&#228;mpfung des Rechtsextremismus und der Hasskriminalit&#228;t&#8220; der Fraktionen der CSD/CSU und 
der SPD (Bundestagsdrucksache 19/17741) sieht neben &#196;nderungen im Strafgesetzbuch, der Strafprozessordnung, des Bundesmel-
        
 
 
   
   
 
 
 
  
   
   
   
  
 
 
      
  
     
  
 
     
   
 
 
    
 
 
        
     
   
   
      
  
  
     
     
        
 
   
 
    
  
 
                 
  
  
 
                                               
     
  
 
            
      
4
&#252;ber das Ziel hinausschie&#223;t: &#8222;Die Herausgabe von Passw&#246;rtern und Nutzungsdaten, die verpflichtende Meldung
an das BKA, die damit verbundene Schaffung einer &#8218;Verdachtsdatenbank&#8216;, die Kriminalisierung von Meinungen
&#8211; all das kann nicht im Sinne eines Rechtsstaates sein. Dieses Vorhaben ist ein Angriff auf die
Pers&#246;nlichkeitsrechte der B&#252;rger und auf die Meinungsfreiheit im Netz. Statt die B&#252;rger zu sch&#252;tzen, werden sie auf Verdacht
kriminalisiert und eingesch&#252;chtert.&#8220;2273 
Keine Rede mehr von der &#8222;Hassrede&#8220;
Abschlie&#223;end noch ein wichtiger semantischer Hinweis. Im Kapitel 7.4.2.1 des Berichts der Projektgruppe &#8222;KI 
und Medien&#8220; [Das Netzwerkdurchsetzungsgesetz gegen Hassrede] wird richtig festgestellt, dass die sogenannte
&#8222;Hassrede&#8220; (auch &#8222;Hate Speech&#8220;) einer Legaldefinition entbehre; konsequenterweise enth&#228;lt das NetzDG in
seiner geltenden Fassung an keiner Stelle die Begriffe &#8222;Hass&#8220;, &#8222;Hassrede&#8220; oder &#8222;Hasskriminalit&#228;t&#8220;. Die AfD-
Fraktion beobachtet mit gro&#223;er Sorge, dass diese Termini mit ihrer empirischen Vagheit aus dem journalistischen
Diskurs peu &#224; peu in die Gesetzgebung Einzug halten, noch dazu mit einer unterstellten Kausalbeziehung
einseitig zum &#8222;Rechtsextremismus&#8220; (ohne &#8222;Linksextremismus&#8220;, &#8222;Islamismus&#8220; und &#8222;Terrorismus&#8220; auch nur erw&#228;hnt zu
finden). Die Grenzen der Meinungsfreiheit sind erst dann &#252;berschritten, wenn ein Straftatbestand vorliegt, nicht
aber durch Gef&#252;hle wie Wut oder Trauer, Euphorie oder Hass: &#8222;Durch Begriffe wie &#8218;Hassrede&#8216; und &#8218;
Hasskriminalit&#228;t&#8216; wird die Grenze der Meinungsfreiheit bewusst verwischt, denn &#8218;Hass&#8216; ist keine Straftat. Die Verwendung
dieser Begriffe durch staatliche Organe, zumal in einem Gesetz zur Kriminalit&#228;tsbek&#228;mpfung, ist strikt
abzulehnen.&#8220;2274 
Im Kapitel 7.4.2.5 des Berichtes der Projektgruppe &#8222;KI und Medien&#8220; [Technische Perspektive auf das
automatische Auffinden] wird zurecht darauf verwiesen, dass heutige KI-Algorithmen mit der Aufgabe, &#8222;Hassrede&#8220; zu
erkennen und gegebenenfalls automatisch zu l&#246;schen, &#252;berfordert sind. Dazu ist die menschliche Sprache zu
komplex; einzelne W&#246;rter k&#246;nnen je nach Kontext und Sprechermilieu verschiedene Bedeutungen haben;
einzelne W&#246;rter geraten au&#223;er Mode, neue kommen hinzu; elaborierte Sprachebenen der Parodie, der Ironie, der
&#220;bertreibung oder des Spottes k&#246;nnen das Verst&#228;ndnis des Gesagten respektive Geschriebenen erschweren; je
nach individueller Erfahrung reagieren manche Menschen auf bestimmte W&#246;rter sensibler oder affektiver als
andere. Entscheidend aber ist die &#8211; menschliche &#8211; Frage, welche W&#246;rter und Wendungen ein Algorithmus als
&#8222;Hassrede&#8220; decodieren soll? Diese Frage wird momentan an die Programmierer der KI-L&#246;sungen gerichtet wie
auch an die Strafverfolgungsbeh&#246;rden. Nach dem Verst&#228;ndnis der AfD-Fraktion f&#252;hrt diese Frage jedoch in die
Irre &#8211; das Strafgesetzbuch mit seinen einschl&#228;gigen Paragrafen listet ausreichend Tatbest&#228;nde auf, die es zu
unterbinden respektive zu verfolgen gilt. Ein bewusster Abschied vom Konzept der &#8222;Hassrede&#8220; und gleichzeitig
vom NetzDG, wie von der AfD-Fraktion gefordert, erleichterte diese Aufgabe ungemein.
Sondervoten der FDP-Fraktion
Sondervotum zu Kapitel 5.7 des Mantelberichts (&#8222;KI und Recht &#8211;
Handlungsempfehlungen&#8220;) der Abgeordneten Mario Brandenburg, Carl-Julius Cronenberg und Daniela
Kluckert sowie der sachverst&#228;ndigen Mitglieder Dr. Aljoscha Burchardt und Andrea
Martin
Die Freien Demokraten lehnen die Einsetzung einer Aufsichtsbeh&#246;rde f&#252;r den privatwirtschaftlichen Bereich ab.
Sie w&#252;rde einen massiven Eingriff in die freie Arbeitsaus&#252;bung von privaten Unternehmen bedeuten und
gleichzeitig den Staat bei Fehlern mitverantwortlich bis hin zu haftbar machen, falls z. B. ein Unternehmen auf Erlass
der Beh&#246;rde ein Produkt anpasst. Eine Aufsichtsbeh&#246;rde kann zudem den Wettbewerb verzerren, wenn z. B. von 
zwei Unternehmen mit &#228;hnlichen Produkten nur eines den Einschr&#228;nkungen der Aufsichtsbeh&#246;rde unterliegt, 
weil das andere Unternehmen kein KI-System einsetzt. Zudem ist es ein erkl&#228;rtes Ziel, das Vertrauen in KI zu
st&#228;rken. Vertrauen kann aber nicht geschaffen werden, wenn gleichzeitig auf der Notwendigkeit einer
Aufsichtsbeh&#246;rde beharrt wird.
Die Freien Demokraten stehen im &#220;brigen einer ex-ante Regulierung f&#252;r KI-Anwendungen, wie sie im Bericht
immer wieder auftaucht und teils gefordert wird, sehr kritisch gegen&#252;ber. Eine Regulierung sollte vorerst
innerdegesetzes, des Bundeskriminalamtsgesetzes und des Telemediengesetzes auch Versch&#228;rfungen des NetzDG vor. Speziell mit
Letzterem kommen auf die Plattformen das Sammeln, Auswerten und Profilieren von T&#228;ter- und Opfergruppen zu, also origin&#228;r staatliche 
Aufgaben.
2273 Fraktion der AfD im Deutschen Bundestag (2020): Cotar: Versch&#228;rfung des NetzDG ebnet Weg f&#252;r &#8222;DDR 2.0&#8220;.
2274 Bundestagsdrucksache 19/20169, S. 1.
halb bereits existierender Standards f&#252;r Nicht-KI-Systeme beginnen und nur im Bedarfsfall (nach-)reguliert
werden. Dabei ist eine bedarfsgerechte Regulierung sicherzustellen, die die Sektorenspezifika beachtet, nicht
innovationshemmend wirkt und wiederkehrend &#252;berpr&#252;ft wird. Wichtig ist hierbei, Risikobereiche nicht mit
Risikotechnologien zu vermischen. K&#252;nstliche Intelligenz an sich ist keine Risikotechnologie, jedoch gibt es Bereiche,
in denen es durchaus wichtig ist, eine konkrete Bedarfsanalyse f&#252;r Regulierung durchzuf&#252;hren.
Sondervotum zu den Kapiteln 3 und 6.2.1 des Mantelberichts (&#8222;KI und Umgang mit
Bias/Diskriminierung&#8220; und &#8222;Autonomie (Selbstbestimmung des Menschen als 
Handelnder, Entscheidungsfreiheit, Nicht-Manipulation)&#8220;) der Abgeordneten Mario 
Brandenburg, Carl-Julius Cronenberg, Daniela Kluckert und Jessica Tatti sowie der
sachverst&#228;ndigen Mitglieder Dr. Aljoscha Burchardt und Andrea Martin
Die Freien Demokraten m&#246;chten an dieser Stelle darauf hinweisen, dass KI-Anwendungen (vor allem sogenannte
algorithmische Entscheidungssysteme) keine Entscheidungen treffen. Entscheidungen treffen Subjekte wie
Menschen, die sich allen Wahlm&#246;glichkeiten bewusst sind und Konsequenzen ihrer Entscheidung verantwortlich
tragen. Die Grundlage von KI-Systemen sind Algorithmen, also vom Menschen programmierte
Handlungsanweisungen, die automatisch ablaufen. Weder der Algorithmus noch der technische &#8222;K&#246;rper&#8220; haben (aktuell) ein
Bewusstsein. Algorithmen l&#246;sen Probleme mit Hilfe der mathematischen Statistik. Sie liefern Ergebnisse von
Berechnungen, die als Basis von Wahlm&#246;glichkeiten verwendet werden k&#246;nnen. F&#252;r Entscheidungen und
Handlungen verantwortlich bleibt immer der Mensch!
Sondervotum zu Kapitel 6.2.4 des Mantelberichts (&#8222;Ethische Perspektive auf KI &#8211;
Gemeinwohl (Wohlstandsf&#246;rderung, Benefits, Interessen)&#8220;) der Abgeordneten Mario 
Brandenburg, Carl-Julius Cronenberg und Daniela Kluckert sowie der
sachverst&#228;ndigen Mitglieder Dr. Aljoscha Burchardt und Andrea Martin
F&#252;r Freie Demokraten stehen der Mensch und dessen individuelle Freiheit im Mittelpunkt. Die wiederholende
Betonung, dass KI den Menschen in den Mittelpunkt stellen muss, sehen wir als gegeben an. Dass jegliche KI
Forschung und -Entwicklung dem &#8222;Gemeinwohl&#8220; dienen muss, sehen wir aufgrund der schwammigen Definition 
von &#8222;Gemeinwohl&#8220; und einer begrenzenden Wirkung auf die Forschung jedoch als fragw&#252;rdig an. Es ist f&#252;r den
Gesetzgeber unm&#246;glich, jegliche Anwendungsf&#228;lle und deren, eventuell erst in der Zweitverwendung, positiven 
Auswirkungen f&#252;r ein sogenanntes &#8222;Gemeinwohl&#8220; abzusch&#228;tzen.
Sondervotum zu den Kapiteln 1 und 3.1 des Berichts der Projektgruppe 1 &#8222;KI und 
Wirtschaft&#8220; (&#8222;Kurzfassung des Projektgruppenberichts&#8220; und &#8222;Grundlagen und
Sachstandskl&#228;rung: KI hat gro&#223;es Potenzial, ist aber kein Selbstl&#228;ufer&#8220;) der Abgeordneten 
Mario Brandenburg, Carl-Julius Cronenberg und Daniela Kluckert sowie der
sachverst&#228;ndigen Mitglieder Dr. Aljoscha Burchardt und Andrea Martin
Die Freien Demokraten m&#246;chten an dieser Stelle explizit klarstellen, dass KI-Anwendungen &#8222;nur&#8220; (digitale)
technische Hilfsmittel sind. Sie sind in der Lage, zu einem gewissen Grade autonom, komplexe Probleme zu l&#246;sen. 
Technologien haben kein Werteger&#252;st und folgen keinen eigenen Zielen. Sie sind neutral, bis Menschen ihnen
eine entsprechende Wertung geben.
Sondervotum zu Kapitel 5.1.3.4 des Berichts der Projektgruppe 4 &#8222;KI und Arbeit,
Bildung, Forschung&#8220; (&#8222;Weiterentwicklung der sozialen Sicherungssysteme&#8220;) des
Abgeordneten Carl-Julius Cronenberg
Der exponentiell steigende Einsatz von KI-Systemen in der Arbeitswelt wird aufbauend auf die ohnehin weiter
fortschreitende Digitalisierung nicht nur den Inhalt von Arbeit, sondern auch die Organisation von
Arbeitsleistung sowie die Arbeitsteilung entlang kompletter Wertsch&#246;pfungsketten tiefgreifend ver&#228;ndern. Dieser Trend
er&#246;ffnet einerseits erhebliche Chancen auf volkswirtschaftliche Produktivit&#228;tssteigerungen und damit
verbundene Wohlstandszuw&#228;chse.2275 Andererseits stellt er auch neue Herausforderungen an die Organisation von
sozialer Sicherung f&#252;r Erwerbst&#228;tige und an die Besteuerung von Erwerbseinkommen.
2275 Vgl. pwc (2018): Auswirkungen der Nutzung von k&#252;nstlicher Intelligenz in Deutschland, S. 4.
Die sozialen Sicherungssysteme sind heute auf abh&#228;ngige Erwerbsarbeit mit den Merkmalen &#8222;arbeitsvertragliche,
langdauernde Besch&#228;ftigung f&#252;r einen Arbeitgeber in einem Betrieb&#8220; ausgerichtet: monatliche
Gehaltsabrechnung, Abf&#252;hrung der SV-Beitr&#228;ge, Einbehaltung der Arbeitnehmeranteile zu den Sozialversicherungen,
Abf&#252;hrung der Lohnsteuer &#8211; alles durch den Arbeitgeber. Davon abzugrenzen ist die selbst&#228;ndige Erwerbsarbeit, die
heute mittels des sogenannten Statusfeststellungsverfahrens erfolgt. Es erscheint fraglich, ob bzw. wie diese
aktuelle Organisation der sozialen Sicherungssysteme zielf&#252;hrend auf neue Erwerbsformen ausgedehnt werden
kann. Dabei m&#252;ssten folgende Anforderungen besondere Ber&#252;cksichtigung finden: Soziale Absicherung f&#252;r alle
Erwerbst&#228;tigen, Rechtssicherheit bei der Entwicklung neuer Gesch&#228;ftsmodelle, effektive Kontrollsysteme zur
Bek&#228;mpfung bzw. Vorbeugung von Missbrauch. 
Dar&#252;ber hinaus stellen neue Erwerbsformen und Einkommensquellen den Staat vor die Aufgabe, die Besteuerung
von Einkommen und Wertsch&#246;pfung (MWSt) sicherzustellen, sowie f&#252;r faire Wettbewerbsbedingungen
zwischen klassischer und neuer Arbeitsorganisation Sorge zu tragen. Auf mikro&#246;konomischer Ebene hat der Staat
die Aufgabe, dem Schutzbed&#252;rfnis der angestellten oder selbstst&#228;ndigen Erwerbst&#228;tigen genauso gerecht zu
werden, wie dem Anspruch auf die freie Entfaltung unternehmerischer Kreativit&#228;t und eines selbstbestimmten
Arbeitslebens.
Einige Auspr&#228;gungen neuer Erwerbsformen seien beispielhaft angef&#252;hrt:
&#8226; Neue Einkommensquellen entstehen: Sharing-Plattformen erm&#246;glichen etwa die Monetarisierung der
eigenen Wohnung oder des eigenen Autos. 
&#8226; Eine neue Gleichzeitigkeit von abh&#228;ngiger Besch&#228;ftigung und selbstst&#228;ndiger Arbeit oder der (mehrmalige)
Wechsel zwischen verschiedenen Erwerbsformen in einer Erwerbsbiografie.
&#8226; Ortsflexibles Arbeiten und mobile Arbeit nehmen zu: dezentrales Arbeiten bzw. der flexible Wechsel
zwischen verschiedenen Arbeitsorten stellen neue Herausforderungen dar.
&#8226; Plattformvermittelte Arbeit findet sich sowohl bei ortsgebundenen (Gig-Worker) als auch
ortsungebundenen (Crowd Worker) Dienstleistungen.
&#8226; Arbeit wird zunehmend grenz&#252;berschreitend organisiert: Besch&#228;ftigte arbeiten f&#252;r verschiedene
Auftraggeber oder Arbeitgeber innerhalb der EU und zunehmend auch im globalen Kontext.
Nach Auffassung des Autors ist die aktuelle Normsetzung durch Gesetzgebung und Rechtsprechung heute nicht
oder mindestens nur unzureichend in der Lage, die Verbreitung solcher Erwerbsformen schnell zu erkennen und
in Hinblick auf die beschriebenen Anforderungen regelkonform der jeweils anwendbaren
Sozialversicherungspflicht und Besteuerung zu unterwerfen.
Auch wenn aktuelle empirische Erhebungen noch keinen unmittelbaren Handlungsdruck nahelegen, wird aus
mehreren Gr&#252;nden empfohlen, die sozialen Sicherungssysteme proaktiv gestaltend weiterzuentwickeln.
Erstens ist fraglich, ob mit traditionellen Messmethoden solche Erscheinungsformen zurzeit &#252;berhaupt korrekt
erfasst werden. Zweitens verbreiten sich neue Erwerbsformen parallel zu den zugrundeliegenden Technologien
h&#228;ufig exponentiell schnell, was valide Trendprognosen erschwert. Schlie&#223;lich ist es w&#252;nschenswert, dass
Besch&#228;ftigte und Unternehmen die von ihnen pr&#228;ferierten Erwerbsformen und Gesch&#228;ftsmodelle umsetzen k&#246;nnen,
ohne die legitimen Interessen der Solidargemeinschaften der Sozialversicherten bzw. der Steuerzahler zu
beeintr&#228;chtigen. 
Sozial- und arbeitsrechtliche Regulierungen im Bereich neuer Erwerbsformen sollten passgenau auf
Anwendungen und Branchen ausgestaltet werden, zu Rechtssicherheit und Akzeptanz f&#252;hren sowie innovative, KI-basierte
Gesch&#228;ftsmodelle erm&#246;glichen.
Ein wichtiges Element der empfohlenen Weiterentwicklung stellt eine umfassende Reform des
Statusfeststellungsverfahrens samt klarer Positivkriterien dar. &#220;ber den Lebensverlauf hinweg, auch mit Blick auf die
bez&#252;glich Erwerbst&#228;tigkeit zunehmend diversen Lebensl&#228;ufe, sollte der Zugang zu sozialer Sicherung erm&#246;glicht
werden. Damit w&#252;rde Absicherung unabh&#228;ngig von den konkreten Erwerbsformen gew&#228;hrleistet. Mit einem
reformierten Statusfeststellungsverfahren lie&#223;e sich auch Klarheit &#252;ber die Erwerbsform schaffen und wo n&#246;tig,
soziale Sicherung effektiv organisieren, zum Beispiel wenn man gem&#228;&#223; dem Prinzip der Digitalen Sozialen
Sicherung (DSS) direkt beim digitalen zentralen Akteur ansetzt, n&#228;mlich der Plattform. Demnach k&#246;nnten immer dann
vollst&#228;ndig automatisiert Sozialversicherungsbeitr&#228;ge abgef&#252;hrt werden, wenn eine Leistungs- oder Zeiteinheit
aus einem plattformvermittelten Auftrag verg&#252;tet wird. DSS minimiert den b&#252;rokratischen Aufwand f&#252;r
Auftragnehmer und Auftraggeber und kann daher auch bei der Abrechnung kleiner Verg&#252;tungsbetr&#228;ge eingesetzt
werden. Das Risiko von Nachforderungen im Falle der Feststellung eines Arbeitgeber-Arbeitnehmer-Verh&#228;ltnisses
wird beseitigt. DSS ist zun&#228;chst f&#252;r die Plattformarbeit entwickelt. Wenn man (wie etwa in Chile) auch in
T&#228;tigkeiten au&#223;erhalb der Plattformen umfassend zu digitaler Rechnungsstellung &#252;bergeht, w&#228;re &#252;ber DSS aber auch
eine effektive und einfache Gestaltung der Sozialversicherung weiterer Selbst&#228;ndiger denkbar.2276 
Der Staat als Akteur
KI-Systeme sind grunds&#228;tzlich geeignet, den Wandel in der Arbeitswelt zu spiegeln und unterst&#252;tzend zu
begleiten. Insofern wird empfohlen, dass der Staat selbst (Sozialversicherungstr&#228;ger, Bundesbeh&#246;rden und
nachgelagerte Beh&#246;rden wie die BA, die FKS etc.) verst&#228;rkt KI-Systeme einsetzt und in diesem Bereich eine Vorreiterrolle 
einnimmt sowie staatliche Expertise im Umgang mit KI-Systemen aufbaut. Als potenziell gr&#246;&#223;ter Auftraggeber
kann der Staat die Entwicklung und Verbreitung menschenzentrierter KI-Systeme massiv f&#246;rdern und damit
indirekt einen wichtigen industriepolitischen Impuls setzen.
Es wird beispielhaft, aber nicht abschlie&#223;end die F&#246;rderung und der Einsatz von KI-Systemen empfohlen, die
&#8226; erg&#228;nzend zu traditionellen statistischen Methoden zus&#228;tzlich prospektive, langfristige Vorhersagen
(Szenarien-Technik) &#252;ber arbeitsmarktrelevante Entwicklungen treffen k&#246;nnen,
&#8226; repetitive Verwaltungst&#228;tigkeiten zugunsten von Beratungs- oder Coaching-T&#228;tigkeiten reduzieren
(B&#252;rokratie-R&#252;ckbau) und damit Verwaltungskosten senken k&#246;nnen,
&#8226; einen einfacheren, besseren und schnelleren Zugang von Informationen durch die Sozialversicherungen/
Beh&#246;rden f&#252;r B&#252;rgerinnen und B&#252;rger schaffen,
&#8226; die Ermittlung angemessener Kosten der Unterkunft im Leistungsbereich des SGB II oder XII unterst&#252;tzen,
&#8226; Fehlerquellen und Missbrauchsmuster besser und schneller identifizieren. 
Es wird erwartet, dass so Tr&#228;ger und Beh&#246;rden die Qualit&#228;t ihrer Arbeitsergebnisse bei geringeren Kosten
steigern k&#246;nnen. Beispielhaft sei die Finanzkontrolle Schwarzarbeit bei der Bek&#228;mpfung von Verst&#246;&#223;en gegen das
Mindestlohngesetz angef&#252;hrt. Der datenschutzrechtlich regelkonforme und diskriminierungsfreie Umgang mit
personenbezogenen Daten ist dabei immer sicherstellen.
Schlie&#223;lich werden die F&#246;rderung und der Einsatz von KI-Systemen empfohlen, die Entwicklungstrends in
ausgew&#228;hlten Wirtschaftssektoren unter besonderer Ber&#252;cksichtigung von neuen Erwerbsformen beobachten und
auswerten.
Fazit
Die Verbreitung von KI-Systemen in der Arbeitswelt beg&#252;nstigt die Verbreitung von neuen Erwerbsformen, die
ihrerseits die Weiterentwicklung der sozialen Sicherungssysteme erforderlich machen. Voraussetzung f&#252;r die
erfolgreiche Weiterentwicklung der sozialen Sicherungssysteme ist, dass der Staat als Akteur (Tr&#228;ger und
Beh&#246;rden) proaktiv selbst KI einsetzt.
Zur besseren Anschaulichkeit eine Analogie: Man stelle sich eine Enquete-Kommission um 1900 zur
Technologiefolgenabsch&#228;tzung &#8222;breite Nutzung des Automobils zum Personen- und G&#252;tertransport&#8220; vor. Die zentrale
These dieses Sondervotums lautete in etwa so: Wir wissen noch nicht, welche neuen Verkehrsregeln gebraucht
werden, welche obsolet sein werden und welche angepasst werden m&#252;ssen, aber zur Durchsetzung der zuk&#252;nftig
geltenden Verkehrsregeln wird empfohlen, dass die Verkehrspolizei fr&#252;hzeitig selbst Automobile einsetzt. Es ist
weder erwartbar, dass die Anforderungen an Verkehrsregeln aus der Perspektive von Kutschen oder
Transportkarren abgeleitet werden k&#246;nnen, noch dass Verkehrskontrollen in Zukunft von berittener Polizei sinnvoll
gew&#228;hrleistet werden k&#246;nnen. Da Autos damals Luxus waren und sich letztlich &#252;ber 100 Jahre verbreitet haben,
waren die anf&#228;nglichen Regulierungs-Vers&#228;umnisse verkraftbar.
Beide Voraussetzungen fehlen bei KI. Daher dr&#228;ngt sich proaktives gestaltendes Handeln beim Thema
&#8222;Weiterentwicklung der sozialen Sicherungssysteme&#8220; auf.
2276 Darstellung Prof. Dr. Enzo Weber (Institut f&#252;r Arbeitsmarkt- und Berufsforschung) in der Sitzung der Projektgruppe KI und Arbeit,
Bildung, Forschung am 25. November 2019.
        
 
 
    
     
 
      
    
  
 
 
         
     
 
  
 
  
 
    
  
    
  
  
     
       
 
      
  
     
  
   
  
  
   
 
 
  
    
 
  
 
    
   
   
     
  
5
Sondervotum zu Kapitel 4.1.3 des Berichts der Projektgruppe 5 &#8222;KI und Mobilit&#228;t&#8220;
(&#8222;Zukunft der Mobilit&#228;t &#8211; Handlungsempfehlungen&#8220;) der Abgeordneten Mario 
Brandenburg, Carl-Julius Cronenberg und Daniela Kluckert sowie der
sachverst&#228;ndigen Mitglieder Dr. Aljoscha Burchardt und Andrea Martin
Die Freien Demokraten sprechen sich klar f&#252;r ein modernes Personenbef&#246;rderungsgesetz aus. Neue
Gesch&#228;ftsmodelle und neue Anbieter dr&#228;ngen im Zuge der Digitalisierung auf den Markt f&#252;r Personenbef&#246;rderung. Um
diesem damit verbundenen ver&#228;nderten Mobilit&#228;tsverhalten der Menschen Rechnung zu tragen, ist eine
Anpassung des nicht mehr zeitgem&#228;&#223;en Personenbef&#246;rderungsgesetzes (PBefG) notwendig. Innovative
Mobilit&#228;tsdienste k&#246;nnen die Leistungsf&#228;higkeit und Effizienz des Personenverkehrs signifikant steigern und so zum Schutz
der Umwelt und der Entlastung der Infrastruktur beitragen. Um dieses Potenzial zu nutzen, ist der Gesamtmarkt
der Personenbef&#246;rderung durch die Schaffung eines Level Playing Fields f&#252;r alle Mobilit&#228;tsdienstleister zu
&#246;ffnen. Es braucht einen rechtlichen Rahmen, in dem f&#252;r alle Akteure dieselben Regeln gelten, alle die gleichen
Startvoraussetzungen haben und die Bed&#252;rfnisse der Nutzerinnen und Nutzer im Zentrum stehen. Gerade die
Mittel der Digitalisierung und algorithmischen Systeme erm&#246;glichen eine effiziente Auslastung von Fahrzeugen,
flexible und passgenaue Preisgestaltung und eine gleichm&#228;&#223;ige Verkehrsverteilung. Damit diese Potenziale
gehoben werden k&#246;nnen, m&#252;ssen faire Wettbewerbsbedingungen geschaffen werden &#8211; ohne steuerliche
Ungleichbehandlung, starre Preisregulierungen und &#246;konomisch und &#246;kologisch fragw&#252;rdige Leerfahren. Mit einem
innovationsfreundlichen Personenbef&#246;rderungsgesetz und den M&#246;glichkeiten von Digitalisierung und KI wird der
Verkehr effektiver, effizienter und nachhaltiger &#8211; zum Vorteil der Nutzerinnen und Nutzer.
Sondervoten der Fraktion DIE LINKE.
Sondervotum zu Kapitel 4 der Kurzfassung des Berichts (&#8222;Wirtschaft und Arbeit&#8220;) der 
Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds 
Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo weisen im Hinblick auf den Satz 
Die disruptive Natur von KI-Technologien erm&#246;glicht nicht nur komplett neue Produkte, sondern
auch neuartige Gesch&#228;ftsmodelle.
darauf hin, dass Technologien und damit auch KI-Systeme keine &#8222;Natur&#8220; besitzen, sondern von Menschen
geschaffen sind. Ob KI-Technologien disruptiv wirken oder nicht, h&#228;ngt im Wesentlichen davon ab, wie die
Systeme ausgestaltet sind und wie bzw. in welchem Umfang sie zum Einsatz kommen (k&#246;nnen). Die Politik hat die
Aufgabe, negative gesellschaftliche Folgen wirtschaftlicher Umbr&#252;che zu unterbinden und den Strukturwandel
sozialvertr&#228;glich zu gestalten. F&#252;r die Schaffung sinnvoller gesetzlicher Regelungen braucht es einen
demokratischen Prozess, der ausreichend Raum f&#252;r Diskussion und Verhandlungen erm&#246;glicht.
Sondervotum zu Kapitel 3.2 des Mantelberichts (&#8222;Diskriminierung durch Bias&#8220;) der 
Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds 
Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo erg&#228;nzen die im Haupttext genannte
Aufz&#228;hlung wie folgt:
a) Fehlende Diversit&#228;t kann auch bei Anwendungen der Bildersuche und bei Spracherkennungssystemen
diskriminieren.
b) Diskriminierung kann auch bei Anwendungen der Kreditvergabe, Jobportalen, Medienfiltern oder
Versicherungen reproduziert werden.
c) Fairnesskonflikte entstehen unter anderem bei Scorings aller Art, Jobportalen, Mietangeboten und bei
Predictive Policing.
Sondervotum zu Kapitel 3.5 des Mantelberichts (&#8222;Handlungsempfehlungen&#8220; zu &#8222;KI 
und Umgang mit Bias/Diskriminierung&#8220;) der Abgeordneten Dr. Petra Sitte und
Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo erg&#228;nzen die Handlungsempfehlungen
um folgende Punkte:
&#8226; Ein breiter gesellschaftlicher interdisziplin&#228;rer Diskurs sollte gef&#252;hrt werden, welche Fairness- und
Qualit&#228;tsma&#223;e bei KI-Systemen der &#246;ffentlichen Hand wichtig sind, damit Beh&#246;rden ermitteln k&#246;nnen, welche
Ungleichbehandlungen/Diskriminierungen gesellschaftlich akzeptiert sind.
&#8226; Bei der Modellierung, Entwicklung, sowie beim Test, Einsatz und Evaluation m&#252;ssen eventuell betroffene
vulnerable Gruppen einbezogen werden, um unerw&#252;nschte Diskriminierungen rechtzeitig zu entdecken und
verhindern zu k&#246;nnen.
Sondervotum zu Kapitel 4.4 des Mantelberichts (&#8222;KI-spezifisches
Risikomanagement&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des
sachverst&#228;ndigen Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo lehnen es ab, f&#252;r Unternehmen,
insbesondere auch KMU und Start-ups, besondere Ausnahmen bei der Kritikalit&#228;tsabsch&#228;tzung einzur&#228;umen. Unter
Wahrung der Verh&#228;ltnism&#228;&#223;igkeit muss im Zweifel stets der Schutz der Allgemeinheit den Vorrang haben.
Sondervotum zu Kapitel 4.5 des Mantelberichts (&#8222;Handlungsempfehlungen&#8220; zu &#8222;KI 
und Umgang mit Risiko&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie 
des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo lehnen die Handlungsempfehlung 
KI-Systeme sollten nicht unter Pauschalverdacht gestellt werden; durch Beschr&#228;nkung auf
Vorgaben f&#252;r Hochrisikoanwendungen sollte die Verh&#228;ltnism&#228;&#223;igkeit gewahrt bleiben. Dabei sollte ein
differenzierender Ansatz verfolgt werden, der m&#246;gliche Anforderungen an die Transparenz und
Nachvollziehbarkeit der Systeme mit der Kritikalit&#228;t des Systems im jeweiligen Anwendungsfall
begr&#252;ndet.
ab, da ohne Pr&#252;fung nicht festgestellt werden kann, ob eine Hochrisikoanwendung vorliegt. Wir lehnen eine
Unterscheidung nur in Hochrisikoanwendungen und alle anderen Anwendungen als unterkomplex ab.
Sondervotum zu Kapitel 5.2 des Mantelberichts (&#8222;Datenschutzrecht&#8220;) der
Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian 
Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo best&#228;rken die Forderung nach einer
Diskussion, ob Artikel 22 DSGVO auch f&#252;r teil-automatisierte Entscheidungssysteme gelten sollte, da die meisten
der im Einsatz befindlichen Systeme assistierend wirken und daher keine automatisierten Entscheidungen
stattfinden, sondern nur teilautomatisierte. Dies bedeutet, dass die Anspr&#252;che aus Artikel 22 DSGVO nicht gelten f&#252;r
teil-automatisierte Verfahren, wie sie mehrheitlich eingesetzt werden.
Sondervotum zu Kapitel 5.5 des Mantelberichts (&#8222;Haftungsrecht&#8220;) der Abgeordneten 
Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian 
Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo teilen den Handlungsvorschlag 
Die Einf&#252;hrung neuer Haftungstatbest&#228;nde der Gef&#228;hrdungshaftung sollte nur dort erwogen
werden, wo explizit durch KI-Systeme neue Gefahren f&#252;r besonders wichtige Rechtsg&#252;ter geschaffen
werden, die nicht bereits durch bestehende Haftungsvorschriften adressiert werden.
nur teilweise: Die Einf&#252;hrung neuer Haftungstatbest&#228;nde sollte &#252;berall dort erwogen werden, wo explizit durch
KI-Systeme neue Gefahren mit mittlerem oder hohem Risikopotenzial geschaffen werden, die nicht bereits durch
bestehende Haftungsvorschriften adressiert werden. Weitere &#220;berlegungen zu einer obligatorischen
Haftpflichtversicherung f&#252;r diese KI-Anwendungen (f&#252;r Hersteller, Besitzer, Betreiber) sollten angestellt werden.
Sondervotum zu Kapitel 5.6 des Mantelberichts (&#8222;Einsatz von KI in der &#246;ffentlichen 
Verwaltung&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des
sachverst&#228;ndigen Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo erg&#228;nzen die Fu&#223;note 225 des Berichts 
wie folgt: Eine Erlaubnisnorm befindet sich z. B. in &#167; 31a Satz 1 SGB II f&#252;r das Sozialrecht, n&#228;her dargestellt im
Bericht der Projektgruppe &#8222;KI und Staat&#8220;, andere Auffassung etwa Luthe (2017): Der vollst&#228;ndig automatisierte
Erlass eines Verwaltungsakts nach &#167; 31a SGB X (ebenso: Luthe (2017): &#167; 31a SGB X); Martini und Nink (2017):
Wenn Maschinen entscheiden &#8230; &#8211; vollautomatisierte Verwaltungsverfahren und der Pers&#246;nlichkeitsschutz;
Littmann (2017): &#167; 31a SGB X.
Sondervotum zu Kapitel 5.7 des Mantelberichts (&#8222;Handlungsempfehlungen&#8220; zu &#8222;KI 
und Recht&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des
sachverst&#228;ndigen Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo schlagen vor, die Rechtsunsicherheit bei
der Anwendung von Anonymisierungsverfahren zu reduzieren, indem der Vorgang der Anonymisierung
ausdr&#252;cklich unter die DSGVO f&#228;llt.
Im &#220;brigen lehnen sie die dort genannte Beschr&#228;nkung der Aufsicht
Von einer pauschalen Offenlegung von Algorithmen wird abgeraten. Eher denkbar ist die
Einsichtnahme durch die zust&#228;ndige Datenschutzaufsicht oder eine sonstige bereichsspezifische Aufsicht
sowie die Einrichtung von Schnittstellen, wenn ein begr&#252;ndeter Verdacht auf Datenmissbrauch
besteht, sodass nicht alle Algorithmen und KI-Anwendungen per se kontrolliert werden.
ab. Die formulierten Voraussetzungen sind so restriktiv (&#8222;begr&#252;ndeter Verdacht&#8220;), dass sie eine Aufsicht eher
ver- und behindern als bef&#246;rdern.
Sondervotum zu Kapitel 6 des Mantelberichts (&#8222;Ethische Perspektiven auf KI&#8220;) der 
Abgeordneten Dr. Petra Sitte und Jessica Tatti
Die Fraktion DIE LINKE. lehnt das Kapitel zu ethischen Perspektiven auf KI ab. Es ist grundlegend und auf
verschiedenen Ebenen misslungen, sodass eine &#8222;Rettung&#8220; durch einzelne Korrekturen nicht m&#246;glich erscheint.
Ohne das Kapitel in dieser Form w&#228;re der Bericht nicht schlechter. Weder beschreibt der vorliegende Text in der
ethischen Fachdiskussion befindliche Problemfelder des Themas KI, noch formuliert er in Grundz&#252;gen eine
ethische Theorie aus, anhand derer der Einsatz von KI moralisch bewertet werden k&#246;nnte.
Sondervotum zu Kapitel 7.1 des Mantelberichts (&#8222;Gesellschaftlicher Reflexionsbedarf
in Bezug auf die Wirkung von KI-Systemen&#8220;) der Abgeordneten Dr. Petra Sitte und
Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo weisen darauf hin, dass die im Satz
Ein Beispiel daf&#252;r ist der Konflikt zwischen der Anwenderfreundlichkeit von Dienstleistungen und
der Preisgabe der privaten Daten oder auch die Frage, wie hoch die Fehlertoleranz KI-basierter 
Ergebnisse sein darf, wenn sie erhebliche Nachteile f&#252;r B&#252;rgerinnen und B&#252;rger bedeuten k&#246;nnen.
beschriebene Anwenderfreundlichkeit sowie Daten- und Pers&#246;nlichkeitsschutz nicht zwingend in Widerspruch
stehen m&#252;ssen. Dass sie das in vielen der gegenw&#228;rtigen Gesch&#228;ftsmodelle tun, liegt weniger an ihrer
Unvereinbarkeit, sondern an dem Bestreben von Tech-Unternehmen die Daten von Nutzerinnen und Nutzern zu
monetarisieren.
Sondervotum zu Kapitel 7.4 des Mantelberichts (&#8222;Handlungsempfehlungen&#8220; zu &#8222;KI 
und Gesellschaft&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des 
sachverst&#228;ndigen Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo bedauern ausdr&#252;cklich, dass es nicht
m&#246;glich war, in den Enquete-Kommission &#252;ber m&#246;gliche gesellschaftliche Folgen eines vermehrten KI-Einsatzes
f&#252;r die Einkommens- und Verm&#246;gensverteilung zu diskutieren. Hier besteht noch ein erheblicher
gesellschaftlicher Reflexionsbedarf, welche KI wir wollen und brauchen. Wir brauchen einen gesellschaftlichen Diskurs, wie
eine nachhaltige und wohlstandsorientierte politische Gestaltung der Chancen und Auswirkungen von KI-
Systemen aussehen kann. So m&#252;ssen wir der Aussage in Handlungsempfehlung 6 entschieden widersprechen, dass in
den Projektgruppen Fragen der sozialen Nachhaltigkeit detailliert diskutiert und spezifisch unterf&#252;ttert worden 
seien. Das war nicht der Fall. Vor allem Fragen der sozialen Nachhaltigkeit und der gegenseitigen Beeinflussung
zwischen verschiedenen weiteren Aspekten von Nachhaltigkeit wurden marginalisiert.
Die Handlungsempfehlungen werden daher wie folgt erg&#228;nzt:
Die Gestaltung von KI-Systemen sollte sich an den Grunds&#228;tzen der &#8222;Agenda 2030 f&#252;r nachhaltige Entwicklung&#8220;
ausrichten. Das hei&#223;t: KI-Technologien d&#252;rfen nicht als Selbstzweck verstanden werden, sondern m&#252;ssen als
Mittel f&#252;r (sozial, &#246;kologisch und &#246;konomisch) nachhaltige Herausforderungen eingesetzt werden. Sie m&#252;ssen
mit ihren positiven und negativen Auswirkungen auf Umwelt, Gesellschaft und Wirtschaft abgewogen werden
und dabei zwingend bestehende rechtliche Vorgaben beachtet werden. Die individuelle, gleichberechtigte
Teilhabe aller Menschen am Nutzen von KI-Systemen ist ein zentraler Aspekt f&#252;r ihre Ausrichtung.
Sondervotum zu Kapitel 8.7 des Mantelberichts (&#8222;Handlungsempfehlungen&#8220; zu &#8222;KI 
und &#246;kologische Nachhaltigkeit&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti
sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo erg&#228;nzen die Handlungsempfehlungen
um zwei Punkte:
&#8226; Um nat&#252;rliche Ressourcen zu sch&#252;tzen, sind zirkul&#228;re, m&#246;glichst r&#252;ckstandsfreie Wertsch&#246;pfungsketten
notwendig. Hierf&#252;r ben&#246;tigen wir verbindliche Regelungen f&#252;r nachhaltige Produktionsweisen und
Gesch&#228;ftsmodelle zur Rohstoffr&#252;ckgewinnung. Es sollten gesetzlich verankerte Ziele und Anreize zur
nachhaltigen Ressourcenr&#252;ckgewinnung und Abfallvermeidung im digitalen Sektor geschaffen werden.
Besonderes Augenmerk muss hierbei die Bedeutung der Obsoleszenz und Wiederverwendbarkeit des eingesetzten 
Materials f&#252;r Endger&#228;te haben.
&#8226; Ein zentraler Ansatzpunkt f&#252;r die politische Steuerung sind die Datennutzungsrechte personen- und nicht
personenbezogener Daten, welche in gesamtgesellschaftlichen Debatten diskutiert und rechtlich geregelt
werden m&#252;ssen.
Sondervotum zu Kapitel 9.2.3 des Mantelberichts (&#8222;Leitlinie 3: F&#246;rderung der
Forschung in der Breite&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des 
sachverst&#228;ndigen Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo pr&#228;zisieren, dass die konkrete Abw&#228;gung
der relativen Priorisierung der Paradigmen 2 und 3 nicht auf Kosten der dezentralen Forschung gehen sollte, 
sondern die Vernetzung verschiedener Standorte und Disziplinen bef&#246;rdern. Dabei sind regional spezifische
Anwendungsfelder m&#246;glich und sinnvoll.
Sondervotum zu Kapitel 9.5 des Mantelberichts (&#8222;Zentrale Handlungsempfehlungen 
f&#252;r den Staat&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des
sachverst&#228;ndigen Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo betonen, dass sich die &#246;ffentliche
Forschungsf&#246;rderung sowohl f&#252;r die Schaffung von Zentren f&#252;r spezifische Anwendungsfelder von KI
(&#8222;Leuchtt&#252;rme&#8220;) einsetzen sollte als auch f&#252;r eine breite und international sehr gut vernetzte KI-Forschung. Beide
Strategien haben unterschiedliche Vor- und Nachteile: Leuchtturmprojekte k&#246;nnen u. a. durch ihre regional
spezifischen Anwendungungsfelder, Clusterbildung, kreative Interaktionen und informellen Austausch exzellent
werden. Zugleich kann die &#252;berm&#228;&#223;ige Konzentration von F&#246;rdermitteln in wenigen Zentren die Vorteile einer breit
angelegten, vielf&#228;ltigen Forschung in einem regional diversifizierten Netzwerk konterkarieren. Eine intelligente
Mischung zentralisierender und dezentralisierender, vernetzender Strategien erscheint daher vielversprechend.
Sondervotum zu Kapitel 10 des Mantelberichts (&#8222;KI und SARS-CoV-2&#8220;) der
Abgeordneten Dr. Petra Sitte und Jessica Tatti
Die Fraktion DIE LINKE. stellt klar, dass es sich bei der Erwartung, dass KI-gest&#252;tzte Systeme durch gr&#246;&#223;ere
Datens&#228;tze und &#8222;fortschrittliche&#8220; Technologie&#8220; ihren Vorsprung bei Vorhersagen ausbauen k&#246;nnten, um eine
nicht belegte Hoffnung der befragten Personen handelt. &#196;hnliche Hoffnungen in Big-Data-Analysen gab es
bereits fr&#252;her, etwa bez&#252;glich der Vorhersage von Grippe-Verbreitungen.2277 Diese Hoffnungen wurden bisher stets
entt&#228;uscht.
Sondervotum zu Kapitel 10.1 des Mantelberichts (&#8222;Potenziale und
Anwendungsbeispiele von KI zur Eind&#228;mmung und Beherrschung von Pandemien (insbesondere der
Covid-19-Pandemie)&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti
Die Fraktion DIE LINKE. legt Wert darauf festzustellen, dass alle Aussagen und Forderungen in diesem Kapitel
ausschlie&#223;lich auf den Aussagen der befragten Personen beruhen. Es handelt sich weder um allgemein anerkannte
wissenschaftliche Erkenntnisse noch um eine in der Enquete-Kommission entwickelte Haltung.
Sondervotum zu Kapitel 10.3 des Mantelberichts (&#8222;Chance in der Krise f&#252;r st&#228;rkere 
Translation und h&#246;here Akzeptanz von KI&#8220;) der Abgeordneten Dr. Petra Sitte und
Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo tragen die Aussage
&#8222;Es zeigte sich in den vergangenen Monaten, dass mit zielgerichteter Kommunikation eine hohe
Teilnehmerbereitschaft erreicht werden kann, beispielsweise hat die Datenspende-App des RKI, die
Daten von Fitnesstrackern auf freiwilliger Basis sammelt, bereits in sehr fr&#252;hen Stadien viel
Unterst&#252;tzung erfahren.&#8220;
so nicht mit. Von Anfang an bem&#228;ngelten Datensch&#252;tzerinnen und Datensch&#252;tzer sowie IT-Expertinnen und
-Experten fehlende Transparenz und gravierende Schwachstellen im Hinblick auf Datenschutz und IT-
Sicherheit.2278 Zuletzt stand die App auch wegen des mangelnden Nutzens in der Kritik. So w&#252;rden Daten nur
gelegentlich und zudem l&#252;ckenhaft erfasst.2279 Derzeit sei daher vorgesehen, das Projekt zum Jahresende zu
beenden.2280
Im Hinblick auf die Aussage
&#8222;Organisatorisch wird zudem empfohlen, Datenwissenschaftlerinnen und -wissenschaftlern, zum
Beispiel aus der &#8222;Deutschen COVID19 OMICS Initiative&#8220;, st&#228;rker in die Entwicklung von
Pandemie- und F&#246;rderma&#223;nahmen inkl. Mittelverteilung einzubeziehen.&#8220;
erg&#228;nzen sie, dass neben Datenwissenschaftlerinnen und -wissenschaftlern auch andere Disziplinen einbezogen
werden sollten, etwa Wirtschafts-, Rechts- und Sozialwissenschaftlerinnen und -wissenschaftler. Eine
interdisziplin&#228;re Zusammenarbeit in der Erforschung und Behandlung von Pandemien ist aus unserer Sicht notwenige
Voraussetzung f&#252;r erfolgreiche Ma&#223;nahmen.
Zu der Passage 
Entscheidend f&#252;r die Akzeptanz sind eine fr&#252;hzeitige Einbeziehung von Datenschutzinteressen und
die transparente Kommunikation der Notwendigkeit von Datenerhebungen.
f&#252;hren die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo erg&#228;nzend aus, dass immer die
datensparsamste Implementierung gew&#228;hlt werden sollte, die zum Erreichen der Ziele realistisch notwendig ist.
2277 Lazer und Kennedy (2015): What We Can Learn From the Epic Failure of Google Flu Trends.
2278 Vgl. Spiegel.de (2020): Chaos Computer Club findet Schwachstellen in &#8222;Corona-Datenspende&#8220; und Krupka (2020): Gesellschaft f&#252;r
Informatik kritisiert &#8222;Datenspende-App&#8220; des Robert-Koch-Instituts.
2279 Vgl. Zeit.de (2020): Datenspende-App soll erhebliche Messl&#252;cken haben.
2280 Vgl. Zeit.de (2020): Datenspende-App soll erhebliche Messl&#252;cken haben.
Zur Beurteilung und Kommunikation von Datenschutzaspekten empfiehlt sich der Kontakt zu NGOs mit
entsprechendem Auftrag, wie z. B. dem Chaos Computer Club, Digitalcourage e. V., etc.2281 
Dar&#252;ber hinaus teilen die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo die Aussagen des
Absatzes
In Anbetracht der konstanten Gefahr, dass in einer globalisierten Gesellschaft jederzeit Pandemien 
auftreten k&#246;nnen, erscheint es sinnvoll zur Wahrung des Vorsorgeprinzips eine Datenbasis auch
bzgl. gew&#246;hnlichen Erk&#228;ltungskrankheiten oder saisonaler Grippe zu erheben und mittels KI
auszuwerten. So lie&#223;en sich bereits auf Basis dieser Erkrankungen viele allgemeine Daten
beispielsweise &#252;ber die Rolle verschiedener Kontaktnetzwerke des &#246;ffentlichen Lebens f&#252;r die Verbreitung
von Erkrankungen in Abh&#228;ngigkeit von epidemiologischen und biologischen Eigenschaften ihres
Erregers erheben, die dann im Falle einer Pandemie die Datenbasis der Infektion erg&#228;nzen
k&#246;nnten.
nicht. Weder Nutzen noch Verh&#228;ltnism&#228;&#223;igkeit dieser Eingriffe sind belegt. Daher ist die Forderung zur
Datenerhebung und -verarbeitung zu allgemein und zu unbestimmt, um als Forderung der Kommission dienen zu
k&#246;nnen.
Sondervotum zu Kapitel 10.4 des Mantelberichts (&#8222;Fazit&#8220; zu &#8222;KI und SARS-CoV-2&#8220;) 
der Abgeordneten Dr. Petra Sitte und Jessica Tatti
Die Fraktion DIE LINKE. teilt die optimistische Aussage des Satzes
Die Corona-Pandemie hat aufgezeigt, wie KI konkret helfen kann, um zu einer L&#246;sung akuter
gesellschaftlicher Problemlagen beizutragen.
(noch) nicht, denn diese These ist bisher nicht belegt.
Sie erg&#228;nzt im &#220;brigen den gesamten Abschnitt wie folgt:
Die Rolle der Medien und die Gefahr von Desinformation sind in einer Pandemie nicht zu vernachl&#228;ssigen. Es
muss geregelt sein, unter welchen Umst&#228;nden und mit welchen Kontrollmechanismen Betreiber von
Intermedi&#228;ren Einfluss auf die Sortierung und Anzeige von Inhalten nehmen d&#252;rfen. Im Teilbericht KI und Medien wird
ausf&#252;hrlich erl&#228;utert, welche Regulierungsma&#223;nahmen die Kommission empfiehlt, um der algorithmisch
getriebenen Verbreitung von Desinformation zu begegnen und auch, welche Qualit&#228;t Inhaltefilter-Systeme haben und
warum sie zur Erkennung von sensiblen Inhalten nicht geeignet sind.
Neben den M&#246;glichkeiten und Chancen, die KI-Systeme unterst&#252;tzend bieten k&#246;nnen, um Pandemien zu
erkennen und einzud&#228;mmen, empfiehlt die Enquete-Kommission auch Grenzen zu ziehen, zu welchen Zwecken KI-
Systeme und Robotik auch im Falle gesundheitlicher Gefahren nicht eingesetzt werden darf. Vor dem
Hintergrund der Limitierungen von KI-Systemen m&#252;ssen insbesondere beim Einsatz bei lebensbedrohlichen
Situationen auch die hier genannten Vorschl&#228;ge einer Risikoklassifizierung unterzogen werden. M&#246;gliche
Risikofaktoren, die ein Verbot des Einsatzes von KI zu diesem Zweck nach sich ziehen k&#246;nnen, k&#246;nnten in diesem Kontext
sein:
&#8226; Die Erhebung, Speicherung und Verarbeitung von personenbezogenen Daten, deren Verarbeitung in einem
KI-System keinen erwiesenen Nutzen f&#252;r die Erkennung oder Eind&#228;mmung einer Pandemie haben.
&#8226; KI-Systeme f&#252;r Triage-Prozesse, in denen unmittelbar &#252;ber das Leben von Menschen entscheiden wird; zu
differenzieren sind das Stadium der Pandemie und die Folgen einer automatisierten oder halb-
automatisierten Entscheidung f&#252;r die individuelle Behandlung.
&#8226; KI-Systeme, die im Kontext einer Pandemie eingesetzt werden, bed&#252;rfen einer besonders hohen
Zuverl&#228;ssigkeit, eine zu definierende Fehlerquoten-Grenze darf nicht &#252;berschritten werden.
&#8226; KI-Systeme d&#252;rfen nicht f&#252;r die Einschr&#228;nkungs-Ma&#223;nahmenplanung und Ressourcenverteilung eingesetzt
werden.
2281 Vgl. Stellungnahme von Prof. Dr. Michael Meyer-Hermann und Dr. Sebastian Binder (Helmholtz-Zentrum f&#252;r Infektionsforschung 
Braunschweig), Kommissionsdrucksache 19(27)130 vom 6. Oktober 2020.
&#8226; Es bedarf der breiten Aufkl&#228;rung der Bev&#246;lkerung, dass Diagnosen per Sprachassistenzsystemen / Chatbots
fehlerhaft und widerspr&#252;chlich sein k&#246;nnen. Diese Systeme sollten so trainiert werden, dass sie
Informationsbedarfe nach lebensbedrohlichen Krankheiten erkennen und entsprechend keine Diagnosen vermitteln, 
sondern eine &#228;rztliche Untersuchung empfehlen.
&#8226; Kollektive und individuelle &#220;berwachungsma&#223;nahmen durch Roboter, Drohnen oder Gesichtserkennung
im &#246;ffentlichen Raum und in Einrichtungen der Infrastruktur des t&#228;glichen Lebens (Superm&#228;rkte, Gesch&#228;fte,
Bahnh&#246;fe, Flugh&#228;fen) mit dem Ziel der Kontrolle der Einhaltung von Einschr&#228;nkungs-Ma&#223;nahmen sind als
unverh&#228;ltnism&#228;&#223;ig abzulehnen.
Bereits in anderen Kontexten eingesetzte KI-Systeme d&#252;rfen im Fall einer pl&#246;tzlichen Pandemie nicht in neuen 
Kontexten eingesetzt werden, mindestens muss das KI-System einer erneuten Risikoklassifizierung unterzogen
und angepasst werden.
Sondervotum zu Kapitel 10.4 des Mantelberichts (&#8222;Fazit&#8220; zu &#8222;KI und SARS-CoV-2&#8220;)
der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen
Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo erg&#228;nzen, dass Apps allein keine
vertrauensbildende Ma&#223;nahme darstellen. Wenn sie eingesetzt werden, m&#252;ssen sie dar&#252;ber hinaus sicher und
datenschutzkonform sein. Eine Vorbereitung auf und eine Eind&#228;mmung von Epidemien und Pandemien setzen aber
immer auch Ressourcen, Kompetenzen, Pl&#228;ne und die politische Legitimation voraus.2282 
Sondervotum zu Kapitel 1 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220;
(&#8222;Kurzfassung des Projektgruppenberichts&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica 
Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo sprechen sich f&#252;r die
Gemeinwohlorientierung von KI-Forschung und Anwendung aus. Die pauschale Forderung nach einer Erh&#246;hung der
Geschwindigkeit belastet die notwendige Beratschlagung dar&#252;ber, wie der gemeinwohlorientierte Einsatz von KI-
Anwendungen umgesetzt werden sollte. Das erschwert es, Nachhaltigkeitsziele im Sinne einer digitalen Suffizienz zu
ber&#252;cksichtigen.2283 
Sie lehnen die Zielstellung einer zentralen und weisungsbefugten Steuerungsstruktur ab.
Sie lehnen auch eine enggef&#252;hrte nationale KI-Strategie unter dem Motto &#8222;Made in Germany&#8220; ab, da dies eine 
sch&#228;dliche Orientierung auf den Wettlauf nationaler Innovationssysteme widerspiegelt. Weitaus sinnvoller und
zielf&#252;hrend ist eine globale Kooperationsstrategie, um &#8222;Sustainable AI&#8220;, also eine nachhaltige KI, zum Nutzen
aller zu entwickeln und einzusetzen. Deutschland und Europa sollten hierbei eine Vorbildrolle einnehmen, dabei
allerdings Potenziale f&#252;r einer globalen Kooperation wahrnehmen, anstatt einen Wettlauf der geopolitischen
Bl&#246;cke zu forcieren.
Auch sehen sie den Ausbau der KI-F&#246;rderung gem&#228;&#223; dem Venture-Capital- / Start-up-Modell kritisch. Statt KI-
F&#246;rderung noch st&#228;rker an den Gewinnerwartungen von privaten Investoren auszurichten, sollten &#246;ffentliche
F&#246;rderinstrumente ausgebaut werden, um die gemeinwohlorientierte Entwicklung von &#8222;Sustainable AI&#8220; zu
unterst&#252;tzen.
Sondervotum zu Kapitel 3.1 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220;
(&#8222;Grundlagen und Sachstandskl&#228;rung: KI hat gro&#223;es Potenzial, ist aber kein
Selbstl&#228;ufer&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des
sachverst&#228;ndigen Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo teilen nicht die Auffassung, dass KI-
Systeme blo&#223; &#8222;leere H&#252;llen&#8220; seien und ersetzen insofern ihre Aussage in Fu&#223;note 441 dieses Berichts.
Programme, die KI nutzen, werden von Menschen programmiert, mit Daten trainiert, die vor ihrer Nutzung
ausgew&#228;hlt, extrahiert, ges&#228;ubert und veredelt wurden. KI-Systeme werden in Organisationen, in sozialen Kontexten
2282 Vgl. AlgorithmWatch (2020): Automatisierte Entscheidungssysteme und der Kampf gegen COVID-19 &#8211; unsere Position.
2283 Vgl. Lange und Santarius (2018): Smarte gr&#252;ne Welt? Digitalisierung zwischen &#220;berwachung, Konsum und Nachhaltigkeit, S. 143-
166; S. 199-203.
f&#252;r ganz bestimmte Zwecke mit konkreten Zielen eingesetzt. Die internationale Technik- wie Designforschung
belegen seit Jahrzehnten, dass Technologien keine (wert-) neutralen Artefakte sein k&#246;nnen.2284 
Sondervotum zu Kapitel 3.2 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220; (&#8222;KI 
in einf&#252;hrenden Szenarien&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie 
des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo lehnen die Darstellungen in Kapitel 3.2
als &#8222;einf&#252;hrende Szenarien&#8220; ab. Der Begriff Szenarien bzw. die Szenario-Technik wird in Wissenschaft, Politik
und Planung genutzt, wenn m&#246;gliche zuk&#252;nftige Entwicklungen analysiert, bewertet, interpretiert und
anschlie&#223;end anhand unterschiedlich belastbarer m&#246;glicher Entwicklungspfade beschrieben werden (z. B. als beste oder
schlechteste Extremvariante / &#8222;best case&#8220;, &#8222;worst case&#8220;, &#8222;Weiter-so&#8220;). Im Unterschied zu dieser anerkannten
Methodik handelt es sich im vorliegenden Teilkapitel um erfundene Beispiele in Fallform, bei denen v&#246;llig
ungekl&#228;rt bleibt, ob es sich um reale, aber anonymisierte, um typische, oder um extrem unwahrscheinliche Fiktionen 
handelt, aus denen keine belastbaren Entwicklungspfade abgeleitet werden k&#246;nnen. Vor allem im ersten Beispiel
bleiben der reale Erkenntnisgewinn und die daraus abgeleiteten Zielsetzungen aus dieser literarisch-
sentimentalen Sonderform zweifelhaft. Generell ist diese Darstellungsform an zentraler Stelle des Projektberichts &#8211;
zwischen Grundlagen und Zielen &#8211; unangemessen.
Sondervotum zu Kapitel 3.3 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220;
(&#8222;Zielstellungen: Deutschland im Jahr 2030 &#8211; eine Vision&#8220;) der Abgeordneten Dr. Petra
Sitte und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo halten die Grundausrichtung des Kapitels
&#8222;Zielstellungen&#8220; f&#252;r verfehlt und eine entsprechende Erg&#228;nzung f&#252;r zwingend erforderlich. Da es sich um eine
der Schl&#252;sselpassagen des Berichts handelt, werden zun&#228;chst die problematischsten Punkte aufgezeigt und im
Anschluss kursorisch f&#252;nf besonders wichtige Zielb&#252;ndel f&#252;r den Bereich K&#252;nstliche Intelligenz und Wirtschaft 
pr&#228;sentiert.
Ein Grundproblem des Berichtes ist, dass Fragen der K&#252;nstlichen Intelligenz und ihrer Auswirkungen analytisch 
aus organisatorischen, wirtschaftlichen und gesamtgesellschaftlichen Kontexten herausgel&#246;st und anschlie&#223;end
isoliert bewertet werden. Nahezu alle Formulierungen der Zielvorstellung des Berichts legen nahe, dass &#8222;die&#8220;
K&#252;nstliche Intelligenz implizit als &#8222;neutrales&#8220; Werkzeug gedeutet wird, als Technologie, die im Kern aus
Software besteht, die mittels automatisierter Verarbeitung massenhafter Daten funktionierende L&#246;sungen f&#252;r
komplexe Probleme findet. Ein solcher Reduktionismus ist angesichts der Technologiegeschichte bestenfalls als naiv
zu bezeichnen. Er kann aber weitreichende Folgen haben: KI und ihre Auswirkungen werden als technische, fast
schon naturwissenschaftliche Objekte und Ereignisse bewertet. Ihr wird damit ein &#8222;positiver&#8220; Zweck an sich
zugeschrieben, anstatt als ein weiteres Mittel zur Verfolgung bestimmter gesellschaftlicher, &#246;konomischer,
sozialer oder kultureller Zwecke wahrgenommen zu werden.2285 
Ein solcher Reduktionismus verhindert einen ernsthaften Blick darauf, welche wechselseitigen Irritationen
zwischen der Entwicklung, Einf&#252;hrung und Verstetigung von K&#252;nstlicher Intelligenz und wirtschaftlichen bzw.
gesellschaftlichen Prozessen vorliegen. Es wird insbesondere unterschlagen, dass die konkrete KI im Kontext der
gegebenen gesellschaftlichen Rahmenbedingungen prim&#228;r nach Ma&#223;gabe der privaten Verwertungsinteressen
und der Markt- und Wettbewerbslogik betrachtet wird. In diesem Sinne wird KI eben auch f&#252;r spezifische
Interessen und Zwecke eingesetzt, die dem Gemeinwohl schaden, die in eine soziale wie &#246;kologische Katastrophe
f&#252;hren k&#246;nnten.2286 
Wir weisen daher die im Bericht angelegte technikdeterministische Fehldeutung zur&#252;ck, nach der mit KI eine
technologische Revolution mit eindeutigen (kausalen) sozialen Folgen &#252;ber gesellschaftliche Akteure
hereinbricht. Sie verkennt die Bedeutung von Gestaltungs- und Aushandlungsprozessen verschiedener Akteure mit
2284 Vgl. etwa Weizenbaum (1986): Ohne uns geht&#8217;s nicht weiter. K&#252;nstliche Intelligenz und Verantwortung der Wissenschaft; Latour
(2006): &#220;ber technische Vermittlung: Philosophie, Soziologie und Genealogie [1994]; Rammert (2017): Technik und Innovation.
2285 Nach unserer Auffassung gibt es eine wechselseitige Beeinflussung von Technologie und gesellschaftlichen Rahmenbedingungen.
Als Technologie determiniert KI daher keine Zukunft. Sie kann aber die Eintrittswahrscheinlichkeit bestimmter Zuk&#252;nfte erh&#246;hen 
und beschleunigen bzw. verringern oder verz&#246;gern (vgl. Luhmann (1991): Soziologie des Risikos; Rammert (2017): Technik und 
Innovation) &#8211; und hat spezifische Kosten des (Nicht-) Einsatzes, etwa f&#252;r zu ber&#252;cksichtigende materielle und soziale Infrastrukturen.
2286 Vgl. D&#246;rre (2019): Risiko Kapitalismus. Landnahme, Zangenkrise, Nachhaltigkeitsrevolution; Wissenschaftlicher Beirat Globale
Umweltver&#228;nderungen (2019): Unsere gemeinsame digitale Zukunft - Zusammenfassung.
spezifischen Einzelinteressen, das Ringen um Macht, Einfluss und Deutungshoheit, die jede Form des Einsatzes
und der Anwendung neuer Technologien seit Jahrhunderten pr&#228;gen. F&#252;r uns gilt der sozialwissenschaftliche
Diskussionsstand, der einen komplexeren, durchaus in sich widerspr&#252;chlichen, KI-Begriff anwendet: Um m&#246;gliche
Auswirkungen, um Chancen und Potenziale von KI auf Wirtschaft und Gesellschaft beschreiben zu k&#246;nnen, muss
KI immer als Bestandteil sozio-technischer Systeme2287 in unterschiedlichen Kontexten spezifisch begriffen und 
bewertet werden.
Folglich sind die in weiten Teilen des Berichts formulierten Erwartung einer allgemeinen Disruption der
sozio&#246;konomischen Verh&#228;ltnisse sowie im Hinblick auf die Effekte f&#252;r die Produktivit&#228;t, das Wirtschaftswachstum
und die weitere volks- wie betriebswirtschaftliche Entwicklung nicht belastbar. Bestehende Unternehmen
befinden sich derzeit meist im Suchstadium, ob der Einsatz von KI &#252;berhaupt einen betriebswirtschaftlichen Sinn
ergeben kann.2288 Das begegnet uns derzeit vor allem
&#8226; im produzierenden Kontext als Teil einer inkrementellen (stufenweisen) Automatisierungsstrategie, die
z. B. mittels Robotik Arbeitspl&#228;tze substituieren soll;
&#8226; als Bestandteil einer systematischen Rationalisierungsstrategie, die Arbeits- und Produktionsprozesse
effizienter und kosteng&#252;nstiger gestalten soll, etwa durch das &#8222;Internet of Things&#8220; oder &#8222;Predictive Analytics&#8220;;
&#8226; im distributiven Kontext von (Unternehmens-) Verwaltung und Handel werden Automatisierungsstrategien 
erprobt, die menschliche Arbeit ersetzen sollen, etwa durch Software, die automatisiert Personen
bestimmten Kategorien zuordnet (&#8222;Scoring&#8220;, &#8222;Profiling&#8220;) und dadurch betriebswirtschaftlich optimieren soll, welche
Produkte und Dienstleistungen wem zu welchen Bedingungen angeboten werden und welche nicht;
&#8226; als Teil einer Rationalisierungsstrategie, wenn etwa KI als Bestandteil eines Cloud- oder Plattformservices
eingesetzt wird, um im virtuellen &#8222;Informationsraum&#8220;2289 Arbeit effizienter planen, steuern, organisieren,
kontrollieren und bewerten zu k&#246;nnen.
Weit umfassender als in den meisten l&#228;nger bestehenden Unternehmen werden KI-Verfahren im &#8222;digitalen
Kapitalismus&#8220;2290 eingesetzt, also dort, wo stetig Daten und Informationen als &#8222;Rohstoffe&#8220; wesentlich in Produkte
und Gesch&#228;ftsmodelle einflie&#223;en &#8211; sei es f&#252;r die personalisierte Werbung (z. B. Google), die Generierung von
Aufmerksamkeit (z. B. Facebook) oder als monetarisierbares Wissen &#252;ber Marktteilnehmer und Produkte (z. B. 
Apples App Store oder Alibaba). Diese Unternehmen neuen Typs sch&#246;pfen Gewinne nicht prim&#228;r aus dem
Verkauf knapper G&#252;ter auf allen offenen M&#228;rkten, sondern v. a. aus der Errichtung und Kontrolle &#8222;propriet&#228;rer&#8220;, 
d. h. privater M&#228;rkte. Gewinne entstehen weniger aus wertsch&#246;pfender Produktion oder Dienstleistungen als
durch die Absch&#246;pfung von Umsatzanteilen der Marktnutzer. Dieses Gesch&#228;ftsmodell von &#8222;Renten aus
Marktbesitz&#8220;2291 setzt eine Monopol- oder zumindest Quasi-Monopolstellung des Plattformbetreibers auf einem
bestimmten Teilmarkt voraus, um die notwendigen Skaleneffekte hervorzurufen. Um die Monopolstellung zu
etablieren, m&#252;ssen parallel die etablierten Gesch&#228;ftsmodelle, die die neuen Gesch&#228;fte beschr&#228;nken k&#246;nnten,
absichtsvoll zerst&#246;rt werden. So erzeugt etwa Uber massiven Wettbewerbsdruck auf Taxiunternehmen, Amazon auf den
station&#228;ren Einzelhandel, Airbnb auf die Hotellerie. Sie nutzen hierf&#252;r kurzfristige Vorteile bestehender
Regelungsl&#252;cken, u. a. bei Steuern, Lizenzen u.v.m.2292 KI-Systeme nehmen hier eine zunehmende und entscheidende
Rolle ein, indem sie massenhaft Daten sammeln, durch Verarbeitung veredeln &#8211; und zur individualisierten
Steuerung der Beteiligten einsetzen. KI hilft, den Zugang, das Verhalten und die Preise der Marktteilnehmenden zum
Nutzen der Marktbesitzer, also der Plattformkonzerne, zu optimieren.
K&#252;nstliche Intelligenz darf daher nicht nur als technologische Chance betrachtet werden. Mit KI starten weder
Wirtschaft noch Gesellschaft neu: Sie wird von profitorientierten Unternehmen eingesetzt. KI kann zum Teil des
2287 Sozio-technische Systeme zeichnen sich dadurch aus, dass technische, organisationale und personale Aspekte/Systeme eine
funktionale Einheit bilden und einander irritieren k&#246;nnen (vgl. Hirsch-Kreinsen und ten Hompel (2015): Digitalisierung industrieller Arbeit.
Entwicklungsperspektiven und Gestaltungsans&#228;tze; Trist: Sozio-technische Systeme). Sie sind zudem in ihre spezifischen sozialen 
Umwelten eingebettet.
2288 Vgl. Butollo (2019): Vernetzungstechnologie und Reproduktionsnetzwerke. Digitalisierung und die Reorganisation globaler
Wertsch&#246;pfung; Pfeiffer (2019): Digitale Transformation: Great, greater, tilt &#8230;? Von der Produktivkraft- zur Distributivkraftentwicklung;
Gordon (2015): Secular Stagnation: A Supply-Side View; Gordon (2018): Why has economic growth slowed when innovation
appears to be accelerating?
2289 Boes et al. (2015): Landnahme im Informationsraum. Neukonstituierung gesellschaftlicher Arbeit in der &#8222;digitalen Gesellschaft&#8220;.
2290 Vgl. Staab (2019): Digitaler Kapitalismus. Markt und Herrschaft in der &#214;konomie der Unknappheit.
2291 Staab (2019): Digitaler Kapitalismus. Markt und Herrschaft in der &#214;konomie der Unknappheit.
2292 Trotz dieser erheblichen Wettbewerbs- und Steuervorteile ist es vor allem bei den Sharing-Diensten noch v&#246;llig offen, ob diese
Gesch&#228;ftsmodelle &#252;berhaupt einen Gewinn abwerfen k&#246;nnen, oder ob es schlicht darum geht, mit gehypten Ideen
Spekulationserwartungen zu erwecken, mit denen die Gesch&#228;ftsgr&#252;nder und fr&#252;he Finanzinvestoren spektakul&#228;re Gewinne (durch Aktieng&#228;nge oder
Verkauf des Start-ups) erzielen k&#246;nnen.
Problems werden, etwa durch ihren rapide steigenden Strom- und Ressourcenverbrauch, und damit die bereits
bestehenden Umweltprobleme versch&#228;rfen. Die inh&#228;rente Tendenz zur Monopolbildung KI-getriebener
Gesch&#228;ftsmodelle beschleunigt die Polarisierung bei Einkommen und Verm&#246;gen. Wir sollten uns als Gesellschaft
fragen, was unsere W&#252;nsche f&#252;r die Zukunft sind: Wie und wozu k&#246;nnte KI gemeinwohlorientiert genutzt werden
und welche gemeinsamen Ziele sollten verfolgt werden?
F&#252;r uns k&#246;nnen Antworten auf diese zentralen Fragen nicht aus einer privatwirtschaftlichen Motivation oder
individuellen Positionen herausgefunden werden. KI kann ihre positiven Potenziale vielmehr nur unter der
Pr&#228;misse eines radikalen sozial-&#246;kologischen Umbaus hin zu mehr Nachhaltigkeit und sozialer Gerechtigkeit
entfalten. Dabei ist eine ethisch verantwortliche und menschenzentrierte Ausrichtung zu beachten. Das hei&#223;t, wir
brauchen und wollen K&#252;nstliche Intelligenz nicht um jeden Preis, &#252;berall, f&#252;r alles und so viel wie m&#246;glich. Das
hei&#223;t weiterhin, dass eine ethische und menschenzentrierte KI kein Selbstl&#228;ufer ist. Priorit&#228;t hat deshalb eine
gemeinwohlorientierte Zielsetzung und eine &#8222;sanfte Digitalisierung&#8220;2293, die das Wohlergehen von Menschen
und Natur bef&#246;rdert. Es ist Aufgabe der Politik und Gegenstand sozialer Auseinandersetzung, genau diese
Priorit&#228;ten zu verankern und in die Anwendung zu &#252;berf&#252;hren
Vor diesem Hintergrund schlagen wir folgend f&#252;nf generelle Zielb&#252;ndel vor, die bis 2030 die KI-Leitlinie bilden
sollten, anhand derer Politik und &#246;ffentliche Verwaltung ihre Instrumente sch&#228;rfen sollte.2294 Die fett gedruckten
Ziele werden dabei in der Gegenwartsform formuliert. So soll ein positives Bild der erstrebten, aber nur durch
gemeinsame Anstrengung erreichbaren Zukunft erzeugt werden. 
Zentrale Elemente unseres Ansatzes sind die gezielte F&#246;rderung w&#252;nschenswerter Innovationen mit hohem
Wohlfahrtsgewinn und gesellschaftlichem Nutzen, eine konsequente Regulierung gef&#228;hrdender Anwendungen
sowie eine breite gesellschaftliche Diskussion und partizipative Aushandlung, in welcher Gesellschaft wir leben
wollen.
Die Weichen f&#252;r einen europ&#228;ischen Weg zur &#8222;digitalisierten Nachhaltigkeitsgesellschaft&#8220;2295 werden bis
2030 erfolgreich gestellt und beschritten
Deutschland und Europa m&#252;ssen bis 2030 durch klare Rahmensetzungen verhindern, dass Prozesse der
Digitalisierung und des Einsatzes von KI als Brandbeschleuniger des Klimawandels sowie des steigenden Energie- und
Ressourcenbedarfs wirken. Die KI-F&#246;rderung der &#246;ffentlichen Hand richtet sich vorrangig am Nutzen der
Bev&#246;lkerung sowie der Weltgesellschaft aus, wie etwa an den Zielen f&#252;r nachhaltige Entwicklung der Vereinten
Nationen (kurz: SDG, &#8222;Sustainable Development Goals&#8220;). Bei &#246;ffentlichen Investitionen ist demnach die
&#246;ffentliche Hand aktiv mitbestimmend und muss von den Ertr&#228;gen profitieren. Wir wollen keine F&#246;rderung, die rein
technikbezogen &#246;ffentliche Mittel vergibt &#8211; unabh&#228;ngig von der Frage, welcher Nutzen und welcher Schaden f&#252;r
die Gesellschaft damit verbunden sein k&#246;nnte. Der aktive Staat hat seine genuine Rolle als markschaffende und
-gestaltende Instanz wieder bewusst auszuf&#252;llen.2296 Welche gesellschaftlichen Ziele besonders gef&#246;rdert
werden, ist in einem breiten und offenen gesellschaftlichen Diskurs festzulegen. Demokratisch transparent und mit
klarer Verantwortlichkeit und nicht in den Hinterzimmern von Politik, Wirtschaft und Forschungseinrichtungen.
KI-Infrastrukturen m&#252;ssen bis 2030 l&#228;ngst auf Gemeinwohl, Inklusion und Nachhaltigkeit ausgerichtet und
optimiert sein.
Das Wohlbefinden und die Lebensqualit&#228;t der Bev&#246;lkerung haben sich in Zeiten des verst&#228;rkten Einsatzes
von KI-Systemen in der Wirtschaft 2030 im Vergleich zu 2020 sp&#252;r- und messbar erh&#246;ht
Deutschland und Europa haben den Weg einer &#8222;sanften Digitalisierung&#8220; gew&#228;hlt. Die Nutzung von Systemen
mit K&#252;nstlicher Intelligenz ist im Jahr 2030 im Alltag einer digitalisierten Gesellschaft selbstverst&#228;ndlich
geworden. Die Maxime der Innovations- und Wirtschaftspolitik orientiert sich an einer qualitativen, inklusiven
Erh&#246;hung gesamtwirtschaftlicher Produktivit&#228;t, die insbesondere eine steigende Lebensqualit&#228;t, umfassende soziale
2293 Lange und Santarius (2018): Smarte gr&#252;ne Welt? Digitalisierung zwischen &#220;berwachung, Konsum und Nachhaltigkeit.
2294 Siehe auch Kapitel 5.33 der Sondervoten [Sondervotum zu Kapitel 5 des Berichts der Projektgruppe &#8222;KI und Wirtschaft &#8220;
(&#8222;Handlungsempfehlungen und Perspektiven &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds
Dr. Florian Butollo].
2295 Wissenschaftlicher Beirat Globale Umweltver&#228;nderungen (2019): Unsere gemeinsame digitale Zukunft &#8211; Zusammenfassung;
Wissenschaftlicher Beirat Globale Umweltver&#228;nderungen (2019): Unsere gemeinsame digitale Zukunft &#8211; Empfehlungen.
2296 Vgl. Mazzucato (2019): Der unternehmerische Staat. Risiken und Gewinne vergesellschaften.
Sicherheit, &#246;kologische Nachhaltigkeit sowie den Abbau von Diskriminierungen beinhaltet und f&#246;rdert. Die
Verf&#252;gbarkeit und Qualit&#228;t grundlegender G&#252;ter und Dienstleistungen des Alltagslebens2297 werden dank KI nicht
nur &#252;ber den Preis, sondern zugleich &#252;ber passendere gemeinwohlorientierte Indikatoren gesteuert. In den
Unternehmen tr&#228;gt der KI-Einsatz zum Erhalt und Ausbau guter Besch&#228;ftigung bei und hilft, die
Transformationslasten nicht einseitig auf den Faktor Arbeit abzuladen. Das sozial gerechte und inklusive qualitative Wachstum
beruht auf einer breiten gesellschaftlichen Allianz, u. a. von Umwelt- und Gewerkschaftsbewegungen.
Weder die weitere Digitalisierung noch der Einsatz von KI-Systemen haben 2030 dazu gef&#252;hrt, dass sich
die Verteilung zwischen Unternehmens- und Verm&#246;genseinkommen sowie Arbeitnehmerentgelten
zuungunsten der Arbeitnehmerentgelte entwickelten. Auch die Ungleichheit zwischen den
Arbeitnehmerentgelten hat bis 2030 stetig abgenommen:
Studien zur bisherigen Entwicklung von Digitalisierung und ihrer Folgen auf die Einkommens- und
Verm&#246;gensverteilung lassen bef&#252;rchten, dass sich die soziale Ungleichheit in Deutschland durch den Einsatz von KI weiter
erh&#246;hen k&#246;nnte.2298 Diese Entwicklung zeigt sich in zwei Dimensionen:
&#8226; Dauth u. a.2299 legen dar, dass der Einsatz von Robotern in der Industrie zwar zu einem Anstieg der
Arbeitsproduktivit&#228;t f&#252;hrt, aber nicht zu einem Anstieg der L&#246;hne. Damit tragen Roboter zum R&#252;ckgang der
Lohnquote bei, zugleich steigt die Gewinnquote der Unternehmen.2300 Die Verm&#246;gensertr&#228;ge steigen st&#228;rker
als die Arbeitseinkommen und bef&#246;rdern damit den ohnehin seit den 1980er Jahren in den Industrienationen
beobachtbaren Trend der wachsenden Ungleichheit.2301 Sp&#228;testens mit der Jahrtausendwende polarisierte 
sich die Situation zwischen den Unternehmen im Hinblick auf Umsatz, Gewinn und Marktmacht.
Mittlerweile pr&#228;gen in zahlreichen Branchen wenige &#8222;Superstar-Firmen&#8220; die M&#228;rkte &#8211; oft zulasten klassisch
produzierender Unternehmen und Dienstleister.2302 
&#8226; Zahlreiche Studien2303 zeigen auf, dass weitentwickelte Formen der Digitalisierung nicht zwingend zu mehr
Arbeitslosigkeit f&#252;hren m&#252;ssen. Es besteht jedoch die Gefahr, dass nunmehr auch Arbeitspl&#228;tze im h&#246;her
entlohnten Produktionsbereich abgebaut werden und in teils prek&#228;ren Dienstleistungsbranchen neu
entstehen. Ohne eine aktive arbeits- und besch&#228;ftigungspolitische Intervention wird dies die Erwerbseinkommen 
weiter polarisieren, die soziale Stabilit&#228;t gef&#228;hrden und die betriebliche wie gesamtwirtschaftliche
Produktivit&#228;t negativ beeinflussen. Das stellt letztlich die Leistungsf&#228;higkeit der &#252;ber Erwerbsarbeit finanzierten
Sozialversicherungssysteme in Frage.
KI-Unternehmen aus den USA, China und anderswo sind 2030 Partner wie Wettbewerber. Innovation
und Wertsch&#246;pfung sind durch &#8222;Coopetition&#8220;2304 gepr&#228;gt
Deutschland und Europa gehen in der Entwicklung und Nutzung einer gemeinwohlorientierten K&#252;nstlichen
Intelligenz mit gutem Beispiel global voran. Im Jahr 2030 spielen &#252;berzogene und unhaltbare Wachstums- und 
Produktivit&#228;tserwartungen durch KI keine Rolle f&#252;r die Entscheidungsfindung in Politik und Wirtschaft. Die
Vorstellung, Europa m&#252;sse KI haupts&#228;chlich schnell und m&#246;glichst schrankenlos entwickeln, um gegen &#8222;die 
2297 Vgl. Foundational Economy Collective (2019): Die &#214;konomie des Alltagslebens. F&#252;r eine neue Infrastrukturpolitik [2018].
2298 Vgl. dazu &#220;berblicksstudie von Staab und Prediger (2019): Digitalisierung und Polarisierung - Eine Literaturstudie zu den
Auswirkungen des digitalen Wandels auf Sozialstruktur und Betriebe.
2299 Vgl. Dauth et al. (2017): German Robots &#8211; The Impact of Industrial Robots on Workers.
2300 Vgl. S&#252;dekum (2018): Digitalisierung und die Zukunft der Arbeit.
2301 Vgl. Piketty (2014): Das Kapital im 21. Jahrhundert [2013]; Schr&#246;der et al. (2020): Million&#228;rInnen unter dem Mikroskop: Datenl&#252;cke
bei sehr hohen Verm&#246;gen geschlossen &#8211; Konzentration h&#246;her als bisher ausgewiesen.
2302 Vgl. Ponattu et al. (2018): Unternehmenskonzentration und Lohnquote in Deutschland. Eine Analyse auf Branchenebene zwischen
2008 und 2016; Autor et al. (2020): The Fall of the Labor Share and the Rise of Superstar Firms; S&#252;dekum et al. (2020): Roboter und
der Aufstieg europ&#228;ischer Superstar-Firmen.
2303 Vgl. Arntz et al. (2018): Digitalisierung und die Zukunft der Arbeit: Makro&#246;konomische Auswirkungen auf Besch&#228;ftigung,
Arbeitslosigkeit und L&#246;hne von morgen; Staab und Nachtwey (2016): Digitalisierung der Dienstleistungsarbeit; S&#252;dekum (2018):
Digitalisierung und die Zukunft der Arbeit; Horn et al. (2017): Was tun gegen die Ungleichheit?
2304 &#8222;Coopetition&#8220; ist ein Kofferwort, das Kooperation und Konkurrenz verbindet. Coopetition bezeichnet Ph&#228;nomene, die Aspekte von
Kooperation und Wettbewerb komplex miteinander verbinden. Coopetitive Systeme sind Nicht-Nullsummenspiele: Ein Gewinn
bedeutet nicht zwingend f&#252;r andere ein spiegelbildlicher Verlust. Vielmehr ist es wahrscheinlich, dass alle Spielerinnen und Spieler
(und Nicht-Spielerinnen und -Spieler!) gewinnen &#8211; oder verlieren. Beispielhaft zeigt sich dies u. a. in der zunehmenden Open Source-
Strategie einiger gro&#223;er Tech-Konzerne.
Chinesen&#8220; und &#8222;die Amerikaner&#8220; bestehen zu k&#246;nnen, ist mittlerweile &#252;berwunden.2305 Denn wenn auch in
einigen Bereichen ein Wettlauf stattfindet, so ist damit die &#252;bergeordnete Frage nicht gekl&#228;rt, zu welchem Zweck
und mit welchen Inhalten die deutsche bzw. europ&#228;ische Politik agieren sollte. Es sollte nur einen Wettlauf darum
geben, zukunftsf&#228;hige wirtschaftliche, soziale und &#246;kologische Strategien zum Wohl der gesamten Gesellschaft
zu entwickeln und umzusetzen. Unter dieser Handlungsmaxime relativiert sich die Bedeutung, wer den Wettlauf
gewinnt und wer nicht. Das 21. Jahrhundert muss ein Jahrhundert qualitativer Transformation sein.
Jeder KI-Einsatz findet 2030 unter datenschutzrechtlichen Bedingungen statt, die sowohl staatliche
&#220;berwachung als auch privatwirtschaftlichen Missbrauch personenbezogener Daten effektiv unterbinden.
Daten werden f&#252;r das Wirtschaften immer wichtiger, sie sind zugleich Produktionsmittel und Produktivkraft.2306 
Durch Regulierung soll sichergestellt werden, dass Daten nicht von privaten Unternehmen oder staatlichen
Stellen ungerechtfertigt angeeignet und missbr&#228;uchlich verwendet werden. Die Urheber von Daten bzw. die
beobachteten Menschen, &#252;ber die Daten erhoben werden, m&#252;ssen die tats&#228;chliche Kontrolle &#252;ber ihre Daten besitzen.
Personenbezogene Daten zu erheben, nutzen und weiterzuverarbeiten ist daher klar gesetzlich geregelt f&#252;r private 
und staatliche Stellen. In allen Bereichen werden weitgehend KI-Anwendungen genutzt, die die Datenhoheit
beim Anwender belassen. KI-basierte Automatisierung erh&#246;ht die Souver&#228;nit&#228;t der Nutzerinnen und Nutzer im
Sinne einer &#8222;augmented human intelligence&#8220;, einer mit KI-Hilfe erweiterten menschlichen Intelligenz.2307 
Sondervotum zu Kapitel 3.3.1 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220;
(&#8222;Angestrebte Gesellschafts- und Politikziele: Die Wirtschaft setzt KI unter Einhaltung
ethisch vereinbarter Normen ein&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti
sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo tragen den Absatz
Weiterhin erm&#246;glicht der Einsatz von KI auch eine effizientere Organisation von M&#228;rkten und hilft, 
irrationale Marktentscheidungen zu verhindern, die auf einem Mangel an Informationen beruhen
bzw. auf der Unf&#228;higkeit, Informationen zielgerichtet auszuwerten. Dadurch wird das Risiko von
Marktversagen reduziert und externe Kosten wie Risiken k&#246;nnen bei Marktentscheidungen besser
ber&#252;cksichtigt werden.
nicht mit. Irrationale Marktentscheidungen werden darin ausschlie&#223;lich als Folge eines Informationsdefizits
gesehen, was jedoch unterschl&#228;gt, dass a) irrationale Marktentscheidungen nicht zwangsl&#228;ufig durch
Informationsdefizite bedingt sind, und b) KI die Komplexit&#228;t des Verhaltens wirtschaftlicher Akteure nicht vollst&#228;ndig
abbilden kann.2308 Auch mittels KI wird die Anpassung der Wirklichkeit an das vorherrschende orthodoxe
Marktmodell2309 weder wahrscheinlicher noch gesellschaftlich erstrebenswerter. Im schlimmsten Fall kann KI sogar
systemische Risiken erh&#246;hen, wie das Beispiel avancierter digitaler Berechnungsmodelle w&#228;hrend der Finanzkrise 
2008/09 illustriert.2310 
2305 Vgl. Lee (2019): AI Superpowers. China, Silicon Valley und die neue Weltordnung [2017]; Zhao (2020): Alles unter dem Himmel.
Vergangenheit und Zukunft der Weltordnung [2016], S. 185-189.
2306 Vgl. Beitr&#228;ge in Butollo und Nuss (2019): Marx und die Roboter. Vernetzte Produktion, K&#252;nstliche Intelligenz und lebendige Arbeit.
2307 KI-Systeme dieser Art spielen den NutzerInnen Zusatzinformationen zu, auf deren Grundlage sie ein umfassenderes Bild ihres
Handelns gewinnen k&#246;nnen. Im Arbeitsprozess wird die menschliche Intuition und Auffassungsgabe z. B. durch Analysen gro&#223;er
Datens&#228;tze oder zu Vergleichssituationen unterst&#252;tzt, die au&#223;erhalb der sensorischen Auffassungsgabe der Subjekte liegen. Im Kontext
von betrieblichen Aushandlungsprozessen und der gezielten F&#246;rderung von Forschung in diesem Bereich setzen sich solche Systeme 
durch, welche die Autonomie der AnwenderInnen f&#246;rdern und zugleich dabei helfen, Ihre Kompetenz im Verh&#228;ltnis zum
Arbeitsgegenstand und der Interaktion mit KI-basierten Systemen zu entwickeln.
2308 Vgl. etwa March (1990): Beschr&#228;nkte Rationalit&#228;t, Ungewi&#223;heit und die Technik der Auswahl [1978]; Simon (1994): Die
Wissenschaft vom K&#252;nstlichen [1969, 1981].
2309 Einf&#252;hrend Hirte und Thieme (2013): Mainstream, Orthodoxie und Heterodoxie.
2310 Vgl. Nesvetailova (2010): Financial Alchemy in Crises &#8211; The Great Liquidity Illusion; grds. Mandelbrot und Hudson (2005): Fraktale 
und Finanzen - M&#228;rkte zwischen Risiko, Rendite und Ruin; Bookstaber (2008): Teufelskreis der Finanzm&#228;rkte - M&#228;rkte, Hedgefonds
und die Risiken von Finanzinnovationen; Triana (2009): Lecturing Birds on Flying &#8211; Can Mathematical Theories Destroy the
Financial Markets.
Sie sehen auch die Verengung des (vertieften) Studiums der KI auf &#8222;IT-Studieng&#228;nge&#8220; im Satz
Daneben werden in fast allen Studieng&#228;ngen KI-Grundlagen vermittelt, w&#228;hrend in IT-
Studieng&#228;ngen auch die gesellschaftlichen Implikationen des Technologieeinsatzes gelehrt werden.
kritisch. Der Gegenstand KI sollte als sozio-technisches System verstanden2311 und daher in interdisziplin&#228;ren
Ausbildungs- und Studieng&#228;ngen sowie Weiterbildungen vermittelt werden.
Im &#220;brigen vertreten die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo die Auffassung,
dass neben dem Gini-Koeffizienten2312 auch die negative Entwicklung der Lohnquote verhindert werden muss.
Die Lohnquote beschreibt das Verh&#228;ltnis von Einkommen aus nicht-selbst&#228;ndiger Arbeit zum Volkseinkommen,
das neben den L&#246;hnen auch Gewinne umfasst. Die Gewinnquote beschreibt den Anteil der Eink&#252;nfte aus
unternehmerischer und selbstst&#228;ndiger T&#228;tigkeit sowie Eink&#252;nfte aus Kapital und Verm&#246;gen. Die &#220;berwachung der
Lohnquote ist beispielsweise als Fr&#252;hwarnsystem f&#252;r die Zukunft der Finanzierung unserer sozialen
Sicherungssysteme wie z. B. der Rente unabdingbar.
Sondervotum zu Kapitel 3.3.3 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220;
(&#8222;Angestrebte Wirtschaftsziele: &#8222;KI made in Germany&#8220; als internationales
G&#252;tesiegel&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen 
Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo vertreten nicht die Auffassung, dass
Deutschland eine &#8222;F&#252;hrerschaft&#8220; als KI-Standort anstreben soll. Das ist weder realistisch noch erstrebenswert.
Vielmehr gilt es einen gemeinsamen europ&#228;ischen Weg zu gehen, der sich am Grundsatz der &#8222;Coopetition&#8220; sowie 
an weltweit abgestimmten Zielsetzungen ausrichtet. KI-Unternehmen in den USA, in China und anderswo sind
ebenso sehr Partner wie auch Konkurrenten. Die bedrohliche Tendenz hin zum Protektionismus darf sich nicht
in der Technologiepolitik wiederholen.
Sie tragen auch den Absatz 
Die &#246;ffentliche Verwaltung hat einen Transformationsprozess bew&#228;ltigt, der der innovativen
Wirtschaft in vielerlei Hinsicht zugutekommt: So wurden zum einen Zutrittsh&#252;rden im Vergabeprozess
f&#252;r jungen Unternehmen abgebaut, sodass der Zutritt f&#252;r die Gruppe der Start-ups als potenzielle
Bieter vereinfacht ist. Zum anderen nutzt die Verwaltung den Ideenreichtum der Start-ups f&#252;r sich
selbst, indem sie Digitalisierungs- und KI-Projekte, welche Verfahren vereinfachen und
Transparenz st&#228;rken, mit Start-ups realisiert sowie digitale Experimentierr&#228;ume innerhalb der Verwaltung
eingerichtet hat, in denen neue Prozesse mit KI initiiert und implementiert werden. Der Staat geht
damit als Enabler f&#252;r KI-Anwendungen voran.
nicht mit. Die &#246;ffentliche Verwaltung sollte vor allem solchen Start-ups offenstehen, die mithilfe von KI die
Qualit&#228;t und Rechtssicherheit von Prozessen und Entscheidungswegen erh&#246;hen. Sie sollte nach klaren
Bedingungen handeln, insbesondere im Hinblick auf den Datenschutz und die Verwertung der Ergebnisse.
Sondervotum zu Kapitel 4.1.3 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220;
(&#8222;Stand des Marktes&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des 
sachverst&#228;ndigen Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo tragen die Zahlen zur &#8222;Marktgr&#246;&#223;e f&#252;r
KI&#8220; nicht mit. Die Zahlen wurden von Unternehmen ver&#246;ffentlicht, die in diesen Bereich
Beratungsdienstleistungen anbieten. Wir lehnen die unkritische &#220;bernahme von solch wenig belastbaren Zukunftsprognosen f&#252;r
2311 Vgl. etwa Hirsch-Kreinsen und ten Hompel (2015): Digitalisierung industrieller Arbeit. Entwicklungsperspektiven und
Gestaltungsans&#228;tze; Lischka und Klingel (2017): Wenn Maschinen Menschen bewerten. Internationale Fallbeispiele f&#252;r Prozesse algorithmischer
Entscheidungsfindung. Impuls Algorithmenethik #1, Kapitel 2; AI Ethics Impact Group (2020): From Principles to Practice &#8211; An 
interdisciplinary framework to operationalise AI ethics, S. 10 f.
2312 Die Konzentration der Ungleichheitsmessung auf den Gini-Koeffizienten wird teils als unterkomplex kritisiert (z. B. Piketty (2014):
Das Kapital im 21. Jahrhundert [2013], S. 350-356 mit Verweis auf Stiglitz et al. (2009): The Measurement of Economic Performance
and Social Progress Revisited). Die Verwendung mehrerer oder besserer Ma&#223;e ist daher ergebnisoffen zu pr&#252;fen.
k&#252;nftiges Wachstum, Ums&#228;tze und Gewinne ab, die von Beratungsunternehmen mit unklarer Methodik und
Datenlage ver&#246;ffentlicht werden. Zu oft haben sich solche Prognosen nach einigen Jahren als falsch und blo&#223;es
&#8222;Verkaufsargument&#8220; f&#252;r die angebotenen Dienstleistungen erwiesen.2313 
Sondervotum zu Kapitel 4.1.3.1.2 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220;
(&#8222;Themenfeld Mittelstand&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie 
des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo lehnen die Aussage, dass die
Innovationsbereitschaft im Bereich KI nicht ausreichend ausgepr&#228;gt sei, als zu negativ ab. Korrekt ist, dass in KMU die
Innovationst&#228;tigkeit und -bereitschaft derzeit verh&#228;ltnism&#228;&#223;ig gering ausgepr&#228;gt ist. Das kann jedoch auf
rationale betriebswirtschaftliche Gr&#252;nde zur&#252;ckzuf&#252;hren sein, da KI-Anwendungen im Kontrast zu &#252;berh&#246;hten
Erwartungen nach pl&#246;tzlichen Effizienzgewinnen mitunter keine ausreichenden Ertr&#228;ge generieren, um den
Investitionsaufwand f&#252;r KMU zu rechtfertigen.
Sondervotum zu Kapitel 4.1.3.2.1 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220; 
(&#8222;Themenfeld Industrie und Produktion: Daten als Produktkomponente in der
produzierenden Industrie&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des 
sachverst&#228;ndigen Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo tragen die Aussage
Die meisten der heute hergestellten Maschinen sind meist nur teilautomatisiert oder mit
Assistenzfunktionen ausgestattet, dabei aber noch nicht selbstlernend. Gerade in Produktionsbereichen, die
sich heute durch einen hohen manuellen Aufwand, eine hohe Komplexit&#228;t und Varianz auszeichnen,
er&#246;ffnet der Einsatz von KI-basierter Technik neue M&#246;glichkeiten.
nicht mit. Dass in Produktionsbereichen mit hoher Komplexit&#228;t und Varianz durch den Einsatz von KI-basierten
Techniken neue M&#246;glichkeiten entstehen, ist nicht nachvollziehbar und oftmals gar falsch. Richtig w&#228;ren der
Verweis und die Einschr&#228;nkung auf Produktionsbereiche mit hohem manuellem, vor allem repetitivem Aufwand.
Sie tragen auch die Aussage
Auch k&#246;nnen hochkomplexe und heute verkettete Fertigungen (z. B. Fahrzeugmontage) zuk&#252;nftig
in dezentralen, autonomen und intelligent gesteuerten Produktionszellen erfolgen. Somit k&#246;nnen
selbst komplexe Produkte in geringen Losgr&#246;&#223;en wirtschaftlicher hergestellt werden, als dies heute 
m&#246;glich ist.
nicht mit. Dies sind bisher ausschlie&#223;lich Experimente und Modellversuche, deren Nutzen und Kosten sich erst
noch erweisen m&#252;ssen.
Sondervotum zu Kapitel 4.1.3.2.4 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220;
(&#8222;Themenfeld Agrar&#246;konomie und Landwirtschaft&#8220;) der Abgeordneten Dr. Petra Sitte
und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo weisen darauf hin, dass das Vertical
Indoor Farming eine Kreislaufwirtschaft mit geschlossenem N&#228;hrstoffkreislauf ist. Das hei&#223;t, es m&#252;ssen
zus&#228;tzliche N&#228;hrstoffe in den Boden eingetragen werden. Diese N&#228;hrstoffe sind in der Regel Kunstd&#252;nger, die enorm
energieaufw&#228;ndig produziert werden.
Sie merken im Hinblick auf die Aussage
Die Digitalisierung der Landwirtschaft birgt aber auch die Gefahr einer weiteren
Marktkonzentration und eines zunehmenden Kontrollverlusts sowie einer steigenden Abh&#228;ngigkeit der
Landwirtinnen und Landwirte von Agrarunternehmen.
2313 Vgl. etwa Moody: Schnelle Technologie, langsames Wachstum. Roboter und die Zukunft der Arbeit [2018].
an, dass sich durch den hohen Investitions- und Kapitalbedarf die Entwicklung in Richtung einer Investoren-
Landwirtschaft beschleunigen kann, in der kleinere, weniger kapitalintensive Akteure verdr&#228;ngt werden.
Sondervotum zu Kapitel 4.1.5 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220; 
(&#8222;&#214;kologie&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des
sachverst&#228;ndigen Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo weisen darauf hin, dass bei der
Bewertung der Prognosen zur Steigerung der Energieeffizienz ber&#252;cksichtigt werden muss, dass der Bedarf an
Rechenkapazit&#228;ten in den n&#228;chsten Jahren deutlich steigen wird (&#8222;Rebound-Effekt&#8220;). Das Gesamtvolumen des
Energieverbrauchs wird also trotz dieser Einsparungen insgesamt betr&#228;chtlich steigen.2314 Ob KI wirklich die
Energieeffizienz steigern kann, ist bis heute unklar und unbewiesen.
Sie lehnen im &#220;brigen den Absatz
Bei der Digitalisierung f&#228;llt zum einen viel Elektronikschrott an, zum anderen werden selten
vorkommende Elemente bei der Fertigung von Halbleitern verwendet. Vergleicht man man die Zahlen
und Prognosen des Hardware-KI-Markts mit denen des gesamten Halbleiter-Markts, so wird klar,
dass der KI-Halbleiter-Markt derzeit lediglich 5 Prozent des Gesamtmarkts ausmacht. Damit ist 
der Ressourcenverbrauch durch KI-Hardware relativ gesehen noch gering
als unzureichend ab: Bei der Digitalisierung f&#228;llt zum einen viel Elektronikschrott an, zum anderen werden selten 
vorkommende Elemente bei der Fertigung von Halbleitern verwendet.2315 Zwar macht der Ressourcenverbrauch
durch KI-Hardware derzeit lediglich f&#252;nf Prozent des Gesamtvolumens der IT-Hardware aus, doch stellt auch
das bei einem wachsenden Marktvolumen eine Herausforderung f&#252;r den Ressourcenverbrauch dar.2316 Diese 
Problematik intensiviert sich zus&#228;tzlich, da KI-Technologien als Querschnittstechnologien viele gesellschaftliche
Bereiche durchdringen werden. Entsprechend wird ein Anstieg des Anteils von KI-Hardware am gesamten IT-
Hardwarevolumen auf 15 Prozent im Jahr 2025 prognostiziert2317, wobei in dieser Zahl das ben&#246;tigte
Hardwarevolumen in Rechenzentren nur teilweise erfasst ist. Die Entwicklung ressourcenschonender KI ist somit dringend
geboten. Entsprechende L&#246;sungen k&#246;nnten ein erhebliches Marktpotential besitzen.
Sondervotum zu Kapitel 4.1.6 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220; 
(&#8222;Stand der Administration/Politik &#8211; rechtliche Fragen&#8220;) der Abgeordneten Dr. Petra
Sitte und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo bedauern, dass hier &#8211; im ansonsten um
Realismus bem&#252;hten Bericht &#8211; eine &#8222;starke&#8220; KI im Sinne der Science Fiction bzw. der kalifornischen Technik-
2314 Vgl. Villani (2018): For a Meaningful Artificial Intelligence &#8211; Towards a French and European Strategy; Deutsche Energie Agentur
(2017): Analyse der mit erh&#246;htem IT- Einsatz verbundenen Energieverbr&#228;uche infolge der zunehmenden Digitalisierung. Status Quo
und Prognosen.
2315 Wissenschaftlicher Beirat Globale Umweltver&#228;nderungen (2019): Unsere gemeinsame digitale Zukunft - Hauptgutachten; Deutsche
Rohstoffagentur (2016): Rohstoffe f&#252;r Zukunftstechnologien 2016; The Shift Project (2019): Lean ICT: Towards digital sobriety,
S. 30 ff.
2316 Digitalisierung ist, wie auch der Wissenschaftliche Beirat der Bundesregierung Globale Umweltver&#228;nderungen feststellt, &#8222;ein Treiber
f&#252;r Ressourcenextraktion und schnell wachsende Mengen von Elektroschrott und toxischem Abfall.&#8220; (Wissenschaftlicher Beirat
Globale Umweltver&#228;nderungen (2019): Unsere gemeinsame digitale Zukunft - Hauptgutachten). Hardware ist auf wertvolle Rohstoffe
wie Edelmetalle, Sondermetalle und seltene Erden angewiesen. Metalle wie Gallium, Indium, Tantal, Kupfer, Cobalt oder Palladium
spielen f&#252;r IT-Hardware eine besonders gro&#223;e Rolle, einige dieser Rohstoffe sind sehr knapp. So ist damit zu rechnen, dass die derzeit
bekannten Vorr&#228;te von Indium nur noch f&#252;r ca. 15 Jahre ausreichen. Rohstoffe wie Tantal und Cobalt stammen derzeit zu gro&#223;en
Teilen aus Hochrisikol&#228;ndern in Bezug auf die Verletzung von menschenrechtlichen, sozialen und &#246;kologischen Standards. Die
Wiedergewinnung wertvoller Rohstoffe aus ausgemusterten IT-Komponenten ist derzeit sowohl technisch als auch wirtschaftlich eine 
gro&#223;e Herausforderung. So liegt die Recyclingquote f&#252;r Indium, Gallium und Tantal derzeit bei unter 1 Prozent. Vgl. Villani (2018):
For a Meaningful Artificial Intelligence &#8211; Towards a French and European Strategy; Bundesanstalt f&#252;r Geowissenschaften und
Rohstoffe (2018): Tantal; The Shift Project (2019): Lean ICT: Towards digital sobriety; Deutsche Rohstoffagentur (2016): Rohstoffe f&#252;r
Zukunftstechnologien 2016; Deutsche Rohstoffagentur (2018): Zur Verf&#252;gbarkeit von Kobalt f&#252;r den Industriestandort Deutschland.
2317 Vgl. Kapitel 4.1.4 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220; [Hardware/Infrastruktur] sowie Batra et al.: Artificial-
intelligence hardware (2018): New opportunities for semiconductor companies.
Utopisten in Aussicht gestellt wird.2318 Diese Ideenwelt h&#228;lt die Fraktion DIE LINKE. f&#252;r illusion&#228;r und politisch
gef&#228;hrlich.
Sie betrachten die Auffassung
Zu ber&#252;cksichtigen ist, dass eine KI-spezifische Erg&#228;nzung bei der Haftung und bei
Pflichtversicherungen einerseits bei Unternehmen wie bei Nutzerinnen und Nutzern zu mehr Vertrauen f&#252;hren
kann, sich auf die KI-Technologie einzulassen, andererseits aber auch unn&#246;tig Skepsis hervorrufen
kann.
als abwegig, dass eine Pflichtversicherung eine &#8222;unn&#246;tige&#8220; Skepsis bef&#246;rdern k&#246;nnte: Erh&#246;ht die Haftpflicht f&#252;r
PKW die Skepsis der Verkehrsteilnehmer am Kraftfahrzeug?
Sondervotum zu Kapitel 5 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220;
(&#8222;Handlungsempfehlungen und Perspektiven&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica 
Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo halten die Grundausrichtung des Kapitels
&#8222;Handlungsempfehlungen und Perspektiven&#8220; f&#252;r verfehlt und eine entsprechende Erg&#228;nzung daher f&#252;r zwingend
erforderlich.
Handlungsempfehlungen konkretisieren, wie von der Wahrnehmung des Status Quo zu den gew&#252;nschten Zielen
gekommen werden soll. Da die oben vorgeschlagenen Ziele2319 andere sind als die Visionen des Berichts der
Projektgruppe, weichen die Empfehlungen in einigen (d. h. nicht allen) Punkten ab. Dies betrifft vor allem die
Empfehlungen zu Wachstum, Produktivit&#228;t und Wertsch&#246;pfung (Kapitel 5.1 des Berichts der Projektgruppe &#8222;KI
und Wirtschaft&#8220; [Wachstum, Wertsch&#246;pfung und Nachhaltigkeit mit und durch KI])2320, zur
Wirtschaftsf&#246;rderung mit &#246;ffentlichen Mitteln ohne Vorgabe gesellschaftlicher Zielstellungen (Kapitel 5.2 des Berichts der
Projektgruppe &#8222;KI und Wirtschaft&#8220; [Unterst&#252;tzung der KI-Akteure])2321 sowie zu Innovationen und Start-ups
(Kapitel 5.2.1 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220; [Innovation und Start-ups: Start-up-&#214;kosysteme, 
Start-up-F&#246;rderungen])2322. 
2318 Vgl. Kurzweil (2014): Menschheit 2.0. Die Singularit&#228;t naht [2005]; kritisch: Nachtwey und Seidl (2017): Die Ethik der Solution 
und der Geist des Digitalen Kapitalismus.
2319 Siehe auch Kapitel 5.24 der Sondervoten [Sondervotum zu Kapitel 3.3 des Berichts der Projektgruppe &#8222;KI und Wirtschaft&#8220;
(&#8222;Zielstellungen: Deutschland im Jahr 2030 &#8211; eine Vision &#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen 
Mitglieds Dr. Florian Butollo].
2320 Die Empfehlungen negieren, dass wir aufgrund der sozial-&#246;kologischen Herausforderungen ein anderes Wachstum und eine andere 
Wertsch&#246;pfung brauchen. Die M&#246;glichkeit, mittels KI neben Preisen auch andere soziale und &#246;kologische Werte zu bilanzieren &#8211; auf 
Unternehmens- wie auf gesellschaftlicher Ebene - und somit in eine langfristige Planung jenseits der kurzfristigen Profitmaximierung
einzubringen, wird leichtfertig verschenkt. Zudem basieren die Handlungsempfehlungen stark auf unseri&#246;sen Prognosen bez&#252;glich
zuk&#252;nftigen BIP- und Produktivit&#228;tswachstums (vgl. etwa Brynjolfsson et al. (2017): Artificial Intelligence and the Modern
Productivity Paradox: A Clash of Expectations and Statistcs; Moody: Schnelle Technologie, langsames Wachstum. Roboter und die Zukunft
der Arbeit [2018]), die st&#228;ndig von interessierter Seite (u. a. Beratungsfirmen, Finanzdienstleistern und Lobbyverb&#228;nden) erstellt und 
popularisiert werden.
2321 Die alleinigen Ziele &#8222;neue Gesch&#228;ftsmodelle&#8220; und &#8222;schnelles Wachstum&#8220; f&#252;hren nicht automatisch zu einer verantwortungsvollen 
oder gar wirtschaftlich sinnvollen Technologieentwicklung, sondern k&#246;nnen diametrale Ergebnisse haben. Das zerst&#246;rt das Vertrauen 
der B&#252;rgerinnen und B&#252;rger in eine w&#252;nschenswerte Zukunft. &#214;ffentliche Betriebe als Pioniere und gezielte &#246;ffentliche Investitionen 
sehen wir als eine sinnvolle Alternative zur &#252;berm&#228;&#223;igen F&#246;rderung und Regulierung zu Gunsten privaten Wagniskapitals. Hier
werden in der Regel Risiken und Chancen ungleich verteilt &#8211; zu Lasten der Allgemeinheit &#8211; und falsche, einseitige Anreize f&#252;r schnell
skalierbare Gesch&#228;ftsmodelle gesetzt (&#8222;moral hazard&#8220;). Nachhaltige KI-Projekte f&#252;r einen gemeinwohlorientierten digitalen Wandel
sind notwendig, nicht schnelle Profite f&#252;r kapitalstarke Anleger, die sich auch noch das Risiko des Scheiterns durch die &#246;ffentliche
Hand &#8222;vergolden&#8220; lassen wollen.
2322 Eine technik- und Start-up-fixierte Wirtschaftsf&#246;rderung, die nicht die Gesch&#228;ftsmodelle, Produkte und deren gesellschaftliche
Auswirkungen qualitativ klassifiziert, lehnen wir ab. Start-ups spielen aufgrund ihrer F&#228;higkeit, sich ohne R&#252;cksicht auf bestehende 
Gesch&#228;ftsprozesse auf innovative Anwendungen fokussieren zu k&#246;nnen, eine wichtige Rolle im KI-Innovationssystem. Um in
unserem Sinne f&#246;rderw&#252;rdige bahnbrechende Innovationen zu erzielen, m&#252;ssen jedoch Gesch&#228;ftsinteressen mit gesellschaftlichen
Zielsetzungen verbunden werden. Kontraproduktiv w&#228;ren daher z. B. die Aufweichung oder Aussetzung sozialer oder
datenschutzrechtlicher Rahmenvorschriften (&#8222;B&#252;rokratieabbau&#8220;), da dies nicht zur Nachhaltigkeit von Gesch&#228;ftsmodellen beitr&#228;gt, sondern vielmehr
neue Gesch&#228;ftsmodelle bef&#246;rdert, die allein auf der Ausnutzung von Regulierungsausnahmen beruhen. Gef&#246;rdert werden kann
vielmehr durch eine qualifizierte Beratung und Unterst&#252;tzung von Unternehmen, wie sie gesetzliche Regen effizient umsetzen und
einhalten k&#246;nnen. Der Einsatz &#246;ffentlicher Mittel sollte der Beteiligung an und der Mitsprache bei der Gesch&#228;ftsentwicklung dienen und 
eben nicht einfach der Absicherung von Wagniskapitalgebern (vgl. Mazzucato (2019): Der unternehmerische Staat. Risiken und
Gewinne vergesellschaften).
Im Folgenden benennen wir in Abgrenzung zu den genannten Passagen einige Eckpunkte f&#252;r unsere
Handlungsempfehlungen. Der Schwerpunkt liegt hierbei auf staatlichen Ma&#223;nahmen (F&#246;rderung und Regulierung), denn
nur diese kann Politik gezielt einsetzen. Eine gute Regulierung ist unabdingbar. Sie blockiert nicht etwa
wirtschaftliche und gesellschaftliche Dynamik, sondern r&#228;umt dem Richtigen Raum, Zeit und Ressourcen f&#252;r
Entwicklungsprozesse ein, indem sie das Falsche verhindert.
Gemeinwohlorientierte KI f&#246;rdern &#8211; &#8222;Sustainable&#8220; bzw. nachhaltige KI als Praxisstandard
Eine gemeinwohlorientierte und menschenzentrierte KI auch und gerade in der Wirtschaft darf nicht blo&#223;es
Aush&#228;ngeschild oder Werbe-Slogan sein. Das zeigt sich unter anderem in der konsequenten Ausrichtung der
F&#246;rdermittelvergabe an der Gemeinwohlorientierung.2323 
K&#252;nstliche Intelligenz ist laut Stand der Forschung ein hervorragendes Instrument zur &#220;berwachung und
Kontrolle von Prozessen auf organisationaler, wirtschaftlicher und gesellschaftlicher Ebene.2324 Dies gilt es f&#252;r
gemeinwohlorientierte Ziele zu nutzen: Auf organisationaler Ebene werden zeitnahe und komplexere
Bilanzierungen m&#246;glich, die nicht nur in Geldwerten (Kosten, Preise) messen, sondern auch soziale und &#246;kologische
Wertsch&#246;pfung bzw. Wertvernichtung sicht- und vergleichbar machen.2325 Auf wirtschaftlicher Ebene wird eine
Verteilung knapper (und unknapper2326) Ressourcen, G&#252;ter und Dienstleistungen m&#246;glich, die sich nicht nur &#252;ber
Zahlungsf&#228;higkeit, Preis und das Prinzip der individuellen Gewinnmaximierung regelt. Auf gesellschaftlicher
Ebene k&#246;nnte eine KI-unterst&#252;tzte dezentrale Steuerung langfristig helfen, Bed&#252;rfnisse und Lebenschancen
besser mit der G&#252;terproduktion zu koppeln und die planetaren Grenzen zu beachten.2327 
Wirtschaft wie Gesellschaft stehen in den kommenden Jahrzehnten vor der Aufgabe, Klima- und andere
Umweltkatastrophen zu verhindern und zugleich Armut und Ungleichheit zu bek&#228;mpfen.2328 K&#252;nstliche Intelligenz
muss als ein Mittel eingesetzt werden, diese soziale, &#246;kologische und wirtschaftliche
Nachhaltigkeitstransformation zu bef&#246;rdern. M&#246;gliche negative Auswirkungen, die sich u. a. in der beschleunigten Polarisierung von
Einkommen, Verm&#246;gen und Kompetenzen manifestiert, sind aktiv zu verhindern. Es liegt daher auf der Hand, KI
nicht einfach als Technologie- und spezifische Wirtschaftsf&#246;rderung zu verstehen und politisch zu betreiben, 
sondern als wichtigen Teilbereich einer missionsorientierten2329 F&#246;rderpolitik zu begreifen.
2323 Hierzu ein kleines, ganz praktisches Beispiel: Gender-Budgeting. KI-F&#246;rderung sollte nicht nur auf eine diskriminierungsfreie KI-
Anwendung zielen, sondern darauf, Gleichstellung aktiv zu bef&#246;rdern. Werden &#246;ffentliche F&#246;rdermittel so eingesetzt, dass sie eher
M&#228;nner oder Frauen f&#246;rdern? Wer profitiert (Ressourcen, Besch&#228;ftigung, Einkommen, Reputation/Mentalit&#228;t)? Wie genau &#8211; Bsp.: 
F&#246;rderung intelligente Robotik: Pflegerobotik (Frauen) vs. Exoskelett (Industrie/Logistik &#8211; M&#228;nner)? Hier k&#246;nnten KI-Auswertungen
auch in der Forschung und Evaluation weiterhelfen &#8211; als Objekt wie als methodisches Mittel (vgl. Pimminger und Bergmann (2020):
Gleichstellungsrelevante Aspekte der Digitalisierung der Arbeitswelt in Deutschland, S. 34-39).
2324 F&#252;r viele, vgl. Mau (2017): Das metrische Wir. &#220;ber die Quantifizierung des Sozialen; Baecker (2018): 4.0 oder Die L&#252;cke die der
Rechner l&#228;sst; Nassehi (2019): Muster. Theorie der digitalen Gesellschaft. Wichtig ist, die M&#246;glichkeiten und Grenzen von Kontrolle 
und Steuerung (&#8222;control&#8220; in umfassender Bedeutung) komplexer Prozesse wissenschaftlich aufzuarbeiten und entsprechende Ans&#228;tze
kritisch wiederzubeleben, wie etwa Kybernetik, System- und Komplexit&#228;tstheorien.
2325 Zum Wert vgl. Mazzucato (2019): Wie kommt der Wert in die Welt? Von Sch&#246;pfern und Absch&#246;pfern [2018]. Ausbauf&#228;hige Ans&#228;tze
gibt es z. B. in der Gemeinwohl-Bilanzierung oder der Nachhaltigkeitsberichterstattung. Davon unbenommen bleibt, dass es sinnvoll
sein kann, vorerst soziale und &#246;kologische Ressourcenverbrauche bzw. Folgewirkungen in Geldwert zu beziffern und zur Steuerung 
zu nutzen.
2326 Wirtschaft in traditionellem Sinne versteht sich als der gesellschaftliche Bereich, in dem es um eine effiziente Verteilung knapper
G&#252;ter und Dienstleistungen geht. &#8222;Knappheit bedeutet, auf Dinge zuzugreifen,  auf die andere auch zugreifen k&#246;nnen und wollen &#8211;
und zwar so, dass ein erfolgter Zugriff weitere Zugriffe auf das Gut ausschlie&#223;t&#8220; (Sahr (2018): Ungleichheit auf Knopfdruck. Die
Spielregeln des Keystroke-Kapitalismus [2017], S. 61., unter Bezug auf Luhmann (1996): Die Wirtschaft der Gesellschaft [1994],
S. 177-229). Im digitalen Kapitalismus haben wir es dagegen h&#228;ufig mit G&#252;tern und Dienstleistungen zu tun, die mit geringen Kosten
hoch skalierbar sind. D. h., Kosten f&#252;r sehr wenige und f&#252;r sehr viele Produkte liegen sehr nahe beisammen. Um mit diesen
&#8222;unknappen&#8220; G&#252;tern und Dienstleistungen Geld verdienen zu k&#246;nnen, werden sie k&#252;nstlich verknappt bzw. der Zugang zu diesen G&#252;tern 
wird mit einer Geb&#252;hr belegt (vgl. Staab (2019): Digitaler Kapitalismus. Markt und Herrschaft in der &#214;konomie der Unknappheit).
2327 Diese Hoffnung st&#252;tzt sich auf die reale Entwicklung im Zeitalter von Big Data und des &#8222;&#220;berwachungskapitalsismus&#8220; (Zuboff
(2018): Das Zeitalter des &#220;berwachungskapitalismus) durch private Unternehmen. Diese Instrumente m&#252;ssten jedoch
gemeinwohlorientiert gewendet, weiterentwickelt und eingesetzt werden (vgl. etwa Schaupp und Jochum (2019): Die Steuerungswende. Zur
M&#246;glichkeit einer nachhaltigen und demokratischen Wirtschaftsplanung im digitalen Zeitalter).
2328 Vgl. D&#246;rre (2019): Risiko Kapitalismus. Landnahme, Zangenkrise, Nachhaltigkeitsrevolution.
2329 Missionsorientiert meint, dass gesetzte ambitionierte Leitbilder (etwa: Wirtschaften ohne CO2-Emissionen) zun&#228;chst nicht KI-
spezifisch sind. Wenn KI direkt (z. B. als Teil eines sozio-technischen Produktions-/Distributionssystems) oder indirekt (z. B. als
Forschungswerkzeug) der Zielerreichung dienen kann, dann wird eine F&#246;rderung m&#246;glich. &#214;ffentliche Innovationspolitik sollte also
insbesondere diejenige interdisziplin&#228;re KI-Forschung besonders f&#246;rdern, die gesellschaftlichen Zielsetzungen verpflichtet ist (siehe
auch Kapitel 9 des Mantelberichts [KI und Forschung]).
Wir m&#252;ssen M&#246;glichkeiten finden, denjenigen, die sich mit Hilfe des Einsatzes von KI-Technologien Gewinne
aneignen, ohne selbst wirklich produktiv zu sein (&#8222;Taker&#8220; vs. &#8222;Maker&#8220;2330), das Gesch&#228;ftsmodell zu entziehen 
(vgl. unten, Datenpolitik) &#8211; oder zumindest daf&#252;r zu sorgen, dass die extrahierten Gewinne wieder an die
wirklichen Produzenten zur&#252;ckflie&#223;en. Die &#8222;Taker&#8220; &#8211; derzeit vor allem digitale Plattformkonzerne, die zugleich
Pioniere und f&#252;hrende Anwender der KI-Entwicklungen sind &#8211; sollten einen Teil der erhaltenen Renten2331 in Form 
von h&#246;heren Steuern zum gesamtgesellschaftlichen Nutzen abf&#252;hren m&#252;ssen.2332 
Die Bek&#228;mpfung der wachsenden sozialen Ungleichheit im Kontext der digitalen Transformation bedarf zudem
einer weit gerechteren Prim&#228;r- und Sekund&#228;rverteilung der Einkommen. Hierzu sind neue, geeignete Instrumente
einzuf&#252;hren2333 bzw. bestehende Instrumente anzupassen, etwa durch eine effektive Unternehmensbesteuerung
und h&#246;here Spitzensteuers&#228;tze.2334 Es gilt in der digitalen Transformation die Lohnquote zu erh&#246;hen, die
Ungleichverteilung von Einkommen und Verm&#246;gen sp&#252;rbar zur&#252;ckzuf&#252;hren und besonders betroffene Gruppen zu
unterst&#252;tzen.2335 Neu entstehende Arbeitspl&#228;tze im Dienstleistungsbereich d&#252;rfen nicht l&#228;nger prek&#228;r und zu
immer schlechteren Bedingungen entstehen. Dies betrifft insbesondere auch (teils schein-) selbst&#228;ndige Arbeit, die
&#252;ber digitale Plattformen vermittelt wird.
KI-Innovationen sollten f&#252;r den Bereich Dekarbonisierung und Klimaschutz im Energiebereich besonders
gef&#246;rdert werden. Dazu geh&#246;rt, dass
&#8226; Potenziale digitaler Technologien f&#252;r das Umweltmonitoring, die Steuerung von Energieverteilung und den
Umstieg auf erneuerbare Energiesysteme genutzt werden,
&#8226; Energie- und Ressourceneffizienz als explizites Innovationsziel f&#252;r alle digitale Technologien und
Anwendungen gefordert wird sowie CO2-Produktion, Ressourcenverbr&#228;uche und Umweltfolgen angemessen
eingepreist werden,
im Sinne einer Kreislaufwirtschaft ein vorausschauendes Produktdesign die Langlebigkeit und
Reparaturfreundlichkeit von Beginn an beinhaltet sowie umwelt- und gesundheitssch&#228;digende Ressourcennutzung vermieden 
wird. Elektroschrott ist effektiv mit hohen Quoten zu recyceln und der illegale Export ist zu unterbinden.2336 
Verantwortungsvolle Datenpolitik: dezentral vor zentral &#8211; KI-basierte Monopolbildungen verhindern &#8211;
Neues digitales (Markt-) Prinzip: Kooperation vor Wettbewerb
Basis f&#252;r lernende KI-Anwendungen sind massenhaft verf&#252;gbare, vielf&#228;ltige und qualitativ gute (Trainings-)
Daten. Zurzeit werden allumfassend Daten generiert und gespeichert, aber oft fehlt die Fantasie, wie diese in
Geldwert umgewandelt werden k&#246;nnen. Andere sind da weiter: Etwa Gesch&#228;ftsmodelle, die kostenfreie
Dienstleistungen anbieten und im Gegenzug die Nutzerinnen und Nutzer beobachten (&#252;berwachen), wie dies Google bei
Suchanfragen oder soziale Netzwerke wie Facebook praktizieren. Die Beobachtungsdaten werden anschlie&#223;end
privatwirtschaftlich verwertet, etwa f&#252;r personalisierte Werbung oder zur Kundenbindung. Das muss sich &#228;ndern.
Personenbezogene bzw. -beziehbare Daten m&#252;ssen soweit als m&#246;glich dezentral, auf den Ger&#228;ten und in den
Speichern der Betroffen verbleiben. Bereits heute sind Apps und Dienste m&#246;glich, die Daten nicht an eine zentrale
Stelle &#252;bersenden, wie etwa die offizielle Corona-App beweist. Dort, wo es sich nicht vermeiden l&#228;sst,
personenbezogene Daten zu &#252;bergeben, muss eine klare und strafbewehrte Zweckbindung mit Kopplungsverboten, 
2330 Vgl. Mazzucato (2019): Wie kommt der Wert in die Welt? Von Sch&#246;pfern und Absch&#246;pfern [2018]; Staab (2019): Digitaler
Kapitalismus. Markt und Herrschaft in der &#214;konomie der Unknappheit.
2331 Rente wird hier im Sinne des englischen Wortes &#8222;rent&#8220; verstanden und steht f&#252;r die Entrichtung einer Geb&#252;hr als ein
au&#223;er&#246;konomisches Einkommen aufgrund einer Vormachtstellung, nicht aufgrund einer Leistung (vgl. Sahr (2018): Ungleichheit auf Knopfdruck.
Die Spielregeln des Keystroke-Kapitalismus [2017], S. 124 f.).
2332 Vgl. etwa S&#252;dekum (2018): Digitalisierung und die Zukunft der Arbeit und nachfolgende Abschnitte zur Verhinderung von
Monopolbildungen.
2333 Diverse Vorschl&#228;ge liegen vor beispielsweise f&#252;r Digitalsteuern, Verm&#246;genssteuern, Quellensteuern auf Finanzfl&#252;sse zur
Gewinnverlagerung in Steueroasen und/oder Finanztransaktionssteuern. Diese sollten in Bezug auf KI-getriebene Gesch&#228;ftsmodelle evaluiert
und spezifiziert werden. (Legale) Steuervermeidungstricks, etwa durch konzerninterne Verrechnungspreise f&#252;r Patente und Lizenzen,
m&#252;ssen verhindert werden.
2334 F&#252;r konkrete Vorschl&#228;ge und Wege vgl. beispielsweise Horn et al. (2017): Was tun gegen die Ungleichheit?, S. 10-18.
2335 Dies kann zum Beispiel durch k&#252;rzere Vollzeit, eine St&#228;rkung der Sozialversicherungssysteme, besser gef&#246;rderte Ausbildungen und 
hinreichend finanzierte lebensbegleitende Weiterbildungen erreicht werden. Ein weiterer Baustein ist ein armutsfester Mindestlohn
in H&#246;he von mindestens 12 Euro (Stand 2020).
2336 Vgl. Wissenschaftlicher Beirat Globale Umweltver&#228;nderungen (2019): Unsere gemeinsame digitale Zukunft - Zusammenfassung,
S. 19; Wissenschaftlicher Beirat Globale Umweltver&#228;nderungen (2019): Unsere gemeinsame digitale Zukunft - Empfehlungen
Kapitel 9.1.1; Lange und Santarius (2018): Smarte gr&#252;ne Welt? Digitalisierung zwischen &#220;berwachung, Konsum und Nachhaltigkeit.
Datensparsamkeit und L&#246;schregeln nicht nur gelten, sondern auch konsequent auf Einhaltung &#252;berwacht,
durchgesetzt und sanktioniert werden. Die daf&#252;r verantwortlichen Stellen sind mit ausreichenden (Personal-)
Ressourcen auszustatten. An Stelle der massenhaften privatwirtschaftlichen Aneignung und Weitergabe
personenbeziehbarer Daten gilt es, KI (-Modelle) unter Wahrung von Datenschutz und Datensouver&#228;nit&#228;t der Nutzerinnen und
Nutzer zu trainieren. Hierzu ist weitere &#246;ffentliche Forschung an dezentraler KI und im Hinblick auf
Treuhandmodelle f&#252;r die selbstbestimmte Datenfreigabe (z. B. &#8222;Trust Center&#8220;) notwendig.2337 
Enorm wichtig f&#252;r einen europ&#228;ischen KI-Ansatz ist die F&#246;rderung wertsch&#246;pfender Modelle und dass dabei
Datenbedarfe nicht grenzenlos ausgeweitet werden. Das betrifft vor allem nicht-personenbezogene Daten wie
etwa Maschinen-, Geo- und Strukturdaten, z. B. Verkehrsdaten. Diese Daten sind vorhanden und werden
zunehmend erhoben, sind aber oft in privaten und &#246;ffentlichen &#8222;Silos&#8220; gespeichert, die f&#252;r sich genommen zu klein 
sind, um KI hinreichend zu trainieren. Hier sind neue Wege des Austauschs und der Kooperation anzusto&#223;en und
zu unterst&#252;tzen. Die Vernetzung ist z. B. durch neutrale Intermedi&#228;re m&#246;glich, die nicht prim&#228;r der eigenen
Renditemaximierung verpflichtet sind (Genossenschaftsmodelle etc.). Staatliche und andere &#246;ffentliche Stellen
k&#246;nnen hierbei durch eine koordinierte Datenpolitik unterst&#252;tzen, die &#246;ffentliche Daten in hoher Qualit&#228;t bereitstellt.
Die bereits sichtbare Tendenz, dass die Realisierung des vollen Nutzens von KI mit einer St&#228;rkung bzw. der
Bildung von technologischen wie unternehmerischen Monopolen/Oligopolen (Stichwort: GAFAM) einhergeht,
ist durch politische Ma&#223;nahmen und entsprechende klare nationale wie internationale Gesetze, Verordnungen
und Vereinbarungen strikt zu bek&#228;mpfen. Die Abh&#228;ngigkeit von wenigen, meist privatwirtschaftlichen
Unternehmen bedeutet neben hohen Gewinnen f&#252;r diese Mono- bzw. Oligopole auch eine zunehmende Macht &#252;ber
gesellschaftliche Entwicklungen und Teilhabechancen von Menschen (&#8222;Winner-takes-it-all&#8220;-M&#228;rkte durch
gezielte Lock-In-Effekte). Daher sollte auf europ&#228;ischer wie nationaler Ebene die Weiterentwicklung des Kartell-
und Wettbewerbsrechts forciert werden, um die Bildung und Aufrechterhaltung digitaler Mono- bzw. Oligopole
verhindern zu k&#246;nnen. Das dient der Wahrung von Verbraucherrechten und kann zugleich der sinkenden
Lohnquote entgegenwirken.2338 Zus&#228;tzlich sind weiter gefasste Rechte auf Datenportabilit&#228;t und Interoperabilit&#228;t 
bei Nutzung von Plattformen zu implementieren sowie die Einrichtung einer Digitalagentur (&#8222;Digital Markets
Unit&#8220;) zur Marktbeobachtung und Rechtsdurchsetzung zu pr&#252;fen.2339 Neben einer Regulierung, die auf die
Verhinderung sch&#228;dlicher Monopole fokussiert ist, sollte verst&#228;rkt diskutiert werden, wie transformatorische
Potenziale digitaler und KI-Technologien2340 f&#252;r eine gerechtere Verteilung der KI-Wertsch&#246;pfung genutzt werden
k&#246;nnten.
Die Herausforderungen der sozial-&#246;kologischen Zangenkrise erfordern einen ergebnissoffen gesellschaftlichen
Diskurs, welches Wachstum und welches Wirtschaften wir zuk&#252;nftig betreiben k&#246;nnen und wollen, ohne soziale
Gerechtigkeit und planetare Grenzen als Ziele aus den Augen zu verlieren. KI- und andere digitale
Gesch&#228;ftsmodelle funktionieren hervorragend in einem entfesselten finanzmarktgetriebenen Wirtschaftssystem, zerst&#246;ren
paradoxerweise im Erfolgsfall jedoch freie M&#228;rkte, da sie auf dem Prinzip von propriet&#228;ren, privaten M&#228;rkten, des
2337 Um berechtigte Bef&#252;rchtungen von B&#252;rgerinnen und B&#252;rgern, Verbraucherinnen und Verbrauchern sowie Besch&#228;ftigten vor
nachteiligen Effekten des Datenpoolings (vgl. Pasquale (2015): The Black Box Society. The Secret Algorithms that Control Money and
Information; Zuboff (2018): Das Zeitalter des &#220;berwachungskapitalismus) auszur&#228;umen, wird auf globaler Ebene &#252;ber eine &#8222;United 
Nations Privacy Convention&#8220; nachgedacht. Diese soll das weltweite Menschenrecht auf Privatsph&#228;re verwirklichen (Artikel 12 der
Allgemeinen Erkl&#228;rung der Menschenrechte; Artikel 17 des Internationalen Pakts &#252;ber b&#252;rgerliche und politische Rechte). Das ist 
sinnvoll und sollte ausgehandelt werden. Die Grunds&#228;tze k&#246;nnen bereits vorab in deutsches und europ&#228;isches Recht umgesetzt
werden, um ein Vorbild und Anreize zu setzen.
2338 Unternehmenskonzentrationen auf Brancheneben, sogenannte Superstar-Firmen (Autor et al. (2017): Concentrating on the Fall of the
Labor Share; Autor et al. (2020): The Fall of the Labor Share and the Rise of Superstar Firms; Ponattu et al. (2018):
Unternehmenskonzentration und Lohnquote in Deutschland. Eine Analyse auf Branchenebene zwischen 2008 und 2016), sind nach derzeitigem
Erkenntnisstand nachteilig f&#252;r die Entwicklung der Lohnquote.
2339 Vgl. Busch (2018): Algorithmic Accountability. Gutachten, S. 17.
2340 Aktuelle Vorschl&#228;ge besch&#228;ftigen sich u. a. damit, wie mehr Menschen aktiv an der Wertsch&#246;pfung teilhaben k&#246;nnten. Dazu geh&#246;rt
z. B. die F&#246;rderung freier Zug&#228;nge und von freier Software, um insbesondere Bottom-up-Innovationen zu st&#228;rken. Beispiele daf&#252;r
sind etwa niedrigschwellige und lokale Maker-Spaces, Coding Communities, gemeinn&#252;tzige Sharing-Genossenschaften und
&#228;hnliches mehr (vgl. etwa Mason (2016): Postkapitalismus. Grundrisse einer kommenden &#214;konomie [2015]; Dickel (2019): Prototyping 
Society. Zur vorauseilenden Technisierung der Zukunft; Schrape (2018): Open-Source-Communities: Die soziotechnische
Verstetigung kollektiver Inventionen). Voraussetzung w&#228;re auch hier, digitale und KI-basierte Wertabsch&#246;pfung angemessen zu teilen &#8211; in 
Geld und in Daten (vgl. z. B. Pr&#252;fer (2020): Die Datenteilungspflicht. Innovation und fairer Wettbewerb auf datengetriebenen
M&#228;rkten). Diese Ans&#228;tze sollten diskutiert werden.
&#8222;Winner-takes-it-all&#8220; beruhen.2341 Anstatt Konkurrenz und Wettbewerb um jeden Preis &#8211; auch der
Selbstzerst&#246;rung &#8211; sollten wir uns &#252;ber neue Wege der Kooperation, Kollaboration und Partizipation verst&#228;ndigen, die allen
ein gutes Leben und Wirtschaften erm&#246;glichen.2342 KI k&#246;nnte bei der Umsetzung als Werkzeug helfen.
Am Schadenspotential orientierte gesetzliche KI-Regulierung
Der europ&#228;ische KI-Weg muss sich durch eine differenzierte gesetzliche Regulation2343 auszeichnen, die sich am
gesellschaftlichen Schadenspotential eines KI-Systems orientiert. Besonders geeignet und praktikabel scheint die
Definition und Etablierung von pr&#252;fbaren Risikoklassen f&#252;r KI-Systeme, die abgestufte Einsatzbereiche
zulassen2344 und eine wirksame Kontrolle der Einhaltung von Verbraucher- und Besch&#228;ftigtenrechten erlauben.2345 
Wir empfehlen, auf Grundlage des Risikoklassen-Modells2346 von Krafft/Zweig2347 &#8211; Basis f&#252;r die Empfehlung 
der Datenethikkommission2348 &#8211; und dessen Erweiterung durch die AI Ethics Impact Group2349 einen
Beteiligungsprozess zu initiieren, der innerhalb von vier Jahren zu einer verbindlichen gesetzlichen Regulierung f&#252;hrt.
So sollen Nutzerinnen und Nutzer von KI-Systemen und die von KI-Auswirkungen Betroffen wirksam vor
intransparenten und/oder unausweichbaren Schadensrisiken gesch&#252;tzt werden. Dieses Bewertungs-, Monitoring-
und Kontrollsystem ist mit Verbraucherverb&#228;nden, Gewerkschaften und Unternehmensvertretern sowie
Vertreterinnen und Vertretern der Wissenschaft gemeinsam zu entwickeln und etablieren.2350 
Nutzerinnen und Nutzer haben die legitime Erwartung, dass Rankings, Ratings und Reputationssysteme2351 von
Plattformen auf einem &#8222;neutralen&#8220; Suchalgorithmus beruhen und nicht hinsichtlich m&#246;glichst hoher
Renditevorhersagen personalisiert werden.2352 Diese Erwartung ist regulatorisch umzusetzen, deren Einhaltung wirksam und
2341 Beispielhaft steht daf&#252;r die Aussage des Investors Peter Thiel (vgl. Thiel (2014): Competition Is for Losers. If you want to create and
capture lasting value, look to build a monopoly), der als Philosophie des Silicon Valley ausgegeben hat: &#8222;Competition is for losers&#8220;
- Wettbewerb sei was f&#252;r Verlierer. Dieser Satz verdeutlicht die fundamentale Abkehr digitalen Wirtschaftens vom
Wettbewerbsprinzip als Treiber der Marktwirtschaft.
2342 Zweischneidig sind daher die Forderungen nach einer nationalen &#8222;digitalen Souver&#228;nit&#228;t&#8220; (Pohle (2020): Digitale Souver&#228;nit&#228;t). Eine 
Souver&#228;nit&#228;t, die auf nationaler Abschottung und Protektionismus beruht, ist weder politisch noch wirtschaftlich w&#252;nschenswert. 
Eine Souver&#228;nit&#228;t hingegen, die darin besteht, &#252;ber umsetzungsf&#228;higes technisches K&#246;nnen und wissenschaftliches Wissen zu
verf&#252;gen, ist unbedingt zu begr&#252;&#223;en (so auch Piketty (2014): Das Kapital im 21. Jahrhundert [2013], S. 103 f.).
2343 Gesetzlich meint nicht, dass alles positiv reguliert werden sollte. Gerade f&#252;r das globale Wirtschaftssystem ist wichtig, dass vieles
soweit als m&#246;glich &#252;ber internationale Normierung und zugeh&#246;rige Gremien erfolgt, Gesetze jedoch zur Umsetzung der Normen und 
Standards verpflichten.
2344 Es wird nachdr&#252;cklich darauf hingewiesen und bef&#252;rwortet, dass durch die Einf&#252;hrung und Durchsetzung eines solchen
Kontrollsystems &#8222;rote Linien&#8220; des Inverkehrbringens und Einsatzes von KI- und ADM-Systemen gesetzt werden, nicht aber die Forschung an
solchen Systemen generell verboten wird. Einige KI-Anwendungen werden durch das Kontrollsystem mit hoher Wahrscheinlichkeit
untersagt, etwa t&#246;dliche autonome Waffensysteme oder eine KI-gest&#252;tzte Bewertung von B&#252;rgerinnen und B&#252;rgern durch Staat
(&#8222;Social Scoring&#8220;, Gesichtserkennung). Diese Anwendungsformen stehen offensichtlich im Widerspruch zu ethischen Grunds&#228;tzen
der Europ&#228;ischen Union, nationalen Gesetzen und den Menschenrechten.
2345 Hierzu geh&#246;rt auch, die zust&#228;ndigen Aufsichtsbeh&#246;rden mit ausrechend qualifiziertem Personal sowie den erforderlichen
Einsichtnahme- und Kontrollbefugnissen auszustatten (z. B. Auskunfts-, Einsichts- und Zugangsrechte) sowie rechtliche Grundlagen f&#252;r die 
Kontrollelemente zu schaffen (u. a. Normierung, Zertifizierung, Transparenz, Testing, Auditing, Einsatz von Kontrollalgorithmen,
In-Camera-Verfahren etc.).
2346 Hiermit ist kein Urteil &#252;ber andere Vorschl&#228;ge verbunden, die teilweise ebenfalls positive Aspekte aufzeigen. Ausdr&#252;cklich
herausgehoben werden sollen Sachverst&#228;ndigen Rat f&#252;r Verbraucherfragen (2018): Technische und rechtliche Betrachtungen
algorithmischer Entscheidungsverfahren; Sachverst&#228;ndigen Rat f&#252;r Verbraucherfragen (2018): Verbrauchergerechtes Scoring; Martini (2019):
Blackbox Algorithmus &#8211; Grundfragen einer Regulierung K&#252;nstlicher Intelligenz; Martini (2019): Grundlinien eines Kontrollsystems
f&#252;r algorithmenbasierte Entscheidungsprozesse sowie Verbraucherzentrale Bundesverband (2019): Positionspapier des
Verbraucherzentrale Bundesverbands.
2347 Vgl. Krafft und Zweig (2019): Transparenz und Nachvollziehbarkeit algorithmenbasierter Entscheidungsprozesse. Ein
Regulierungsvorschlag aus sozioinformatischer Perspektive.
2348 Vgl. Datenethikkommission der Bundesregierung (2019): Gutachten der Datenethikkommission der Bundesregierung.
2349 Vgl. AI Ethics Impact Group (2020): From Principles to Practice - An interdisciplinary framework to operationalise AI ethics.
2350 Dabei geht es nicht nur um die Herstellung von Vertrauen, sondern ebenso um die Erhaltung eines grunds&#228;tzlichen Misstrauens in 
KI-Entscheidungen: KI birgt stets das Risiko, dass durch die mathematisch-naturwissenschaftliche Anmutung einer &#8222;neutralen&#8220;
Entscheidung unsichtbar gemacht wird, dass zugleich auf der Hinterb&#252;hne interessengleitete Aushandlungen und Machtspiele
stattfinden. Chinas Entwicklung eines &#8222;Social Credit Systems&#8220; sollte von Europa auch als L&#246;sungsversuch verstanden werden, der auf das
Problem des Misstrauens gegen&#252;ber bisherigen Entscheidungstr&#228;gern und -verfahren in Beh&#246;rden und Unternehmen reagiert (vgl.
Block und Dickel (2020): Jenseits der Autonomie, S. 113 f.). Die europ&#228;ische Alternative sollte daher ausdr&#252;cklich auch Misstrauen 
wertsch&#228;tzen.
2351 Letzteres im Sinne von: Kundenbewertungen, vgl. auch Heintz (2010): Numerische Differenz. &#220;berlegungen zu einer Soziologie des
(quantitativen) Vergleichs; Heintz (2019): Vom Komparativ zum Superlativ. Eine kleine Soziologie der Rangliste.
2352 Vgl. Sachverst&#228;ndigen Rat f&#252;r Verbraucherfragen (2018): Technische und rechtliche Betrachtungen algorithmischer
Entscheidungsverfahren.
sanktionsbew&#228;hrt zu kontrollieren. Da eine Verpflichtung der Plattformbetreiber auf eine volle Transparenz der
Bewertungssysteme gegen&#252;ber den Nutzenden wenig zielf&#252;hrend ist, sind beh&#246;rdliche Befugnisse zur
Durchf&#252;hrung eines &#8222;Algorithmen-Audits&#8220; f&#252;r Ranking-, Rating- und Reputations-Algorithmen einzuf&#252;hren.2353
Ein weiterer Baustein f&#252;r die Etablierung einer verantwortungsvollen und gemeinwohlorientierten KI-Nutzung
ist eine verschuldensunabh&#228;ngige Gef&#228;hrdungshaftung f&#252;r das Inverkehrbringen von KI-Systemen.2354 Eine
Gef&#228;hrdungshaftung ist f&#252;r Technologien mit hohem Risikopotential nichts Ungew&#246;hnliches2355 und erh&#246;ht den
Anreiz f&#252;r Hersteller, die maximal m&#246;gliche Sicherheit ihrer Produkte zu gew&#228;hrleisten und sorgt daf&#252;r, nicht im
Schadensfall die Verantwortung auf den Gesetzgeber bzw. die &#246;ffentliche Hand abw&#228;lzen zu k&#246;nnen.2356
Riskantes Handeln ist an klare Verantwortlichkeit mit personaler und finanzieller Risikohaftung zu binden, um die
grassierende Problematiken von &#8222;moral hazard&#8220; (d. h. Risikoverhaltens durch Fehlanreize), Trittbrettfahrer-
Verhalten und der Abw&#228;lzung/Externalisierung von Kosten in Wirtschaft, Politik und Gesellschaft strikt zu unterbinden.
Folglich wird die Einf&#252;hrung einer Pflichtversicherung f&#252;r Hersteller und Betreiber von KI-Systemen empfohlen, 
um im Falle von Zahlungs- oder Zuordnungsschwierigkeiten die Gesch&#228;digten zu entlasten2357 und die
&#246;ffentliche Hand nicht als &#8222;Risk Taker&#8220; der letzten Instanz zu missbrauchen. Das bef&#246;rdert Rechtssicherheit und
Vertrauen auf allen Seiten.
Voraussetzung f&#252;r eine wirksame &#220;berwachung und Kontrolle der Wirkungen von KI-getriebenen Systemen ist,
dass &#246;ffentliche Stellen in der Lage sind, Folgen und unbeabsichtigte Nebenfolgen von Ma&#223;nahmen zeitnah und
schnell zu quantifizieren und qualifizieren. Wir ben&#246;tigen Daten und bessere Modelle zur Beobachtung und
Bewertung, ob durch den Einsatz von KI eine Ann&#228;herung an die gew&#252;nschten Ziele stattfindet und wenn ja, welche
Qualit&#228;t dabei sichtbar wird. Wir ben&#246;tigen eine Weiterentwicklung der &#246;ffentlichen Statistik in Deutschland und
Europa, ggfs. auch auf globaler Ebene und unter Zuhilfenahme von Big Data und KI-Methoden: f&#252;r ein
Monitoring von Wohlbefinden und Lebensqualit&#228;t der Bev&#246;lkerung jenseits der BIP-Messung2358, ein Monitoring von
KI- und anderen digitalen Auswirkungen auf Besch&#228;ftigte2359, die Erfassung von Emissions- und
Ressourcenfu&#223;abdr&#252;cken in traditionellen Wirtschaftszweigen wie auch der Digitalwirtschaft &#252;ber die gesamte
Wertsch&#246;pfungskette hinweg sowie die Ermittlung &#246;kologischer Kenngr&#246;&#223;en und Zusammenh&#228;nge als Informationsbasis
f&#252;r eine effektivere Regulierung des Verbrauchs von Ressourcen.
Infrastrukturen als &#246;ffentliche Daseinsvorsorge &#8211; Infrastrukturen der Marktlogik entziehen
F&#252;r einen diskriminierungsfreien Zugang zu gemeinwohlf&#246;rderlichen KI-Systemen ist die Bereitstellung einer
geeigneten Infrastruktur zentral. Das ist mittlerweile fundamentaler Bestandteil &#246;ffentlicher Daseinsvorsorge im
21. Jahrhundert. Jede Art K&#252;nstlicher Intelligenz ist sowohl auf materielle wie auf immaterielle Infrastrukturen
angewiesen: Je nach Anwendung werden fl&#228;chendeckende Glasfaserkabel oder ein l&#252;ckenloses schnelles
Mobilfunknetz ben&#246;tigt (z. B. IoT, (teil-)autonomes Fahren). Server- und Cloudservices ben&#246;tigen zentrale und
dezentrale Rechenzentren etc. F&#252;r all das sind Energie, Rohstoffe und auszuweisende Fl&#228;chen die unmittelbaren Vo-
2353 Ob die Kompetenzen und Befugnisse zur Durchf&#252;hrung regelm&#228;&#223;iger oder anlassbezogener Audits den im Bereich von
Telekommunikations- und Finanzdienstleistungen den in diesen Bereichen bereits zust&#228;ndigen Beh&#246;rden &#252;bertragen werden (BNetzA, BaFin)
und f&#252;r andere Branchen dem Bundeskartellamt, wie z. B. Busch (vgl. Busch (2018): Algorithmic Accountability. Gutachten, S. 11)
r&#228;t, oder eine eigene Beh&#246;rde gegr&#252;ndet wird, wird an dieser Stelle explizit offen gelassen.
2354 Darstellung Dr. Axel Metzger (Humboldt-Universit&#228;t zu Berlin) in der Sitzung der Projektgruppe &#8222;KI und Wirtschaft&#8220; vom
6. Mai 2019.
2355 Beispiele aus dem deutschen Recht sind u. a. die Teilnahme am Stra&#223;enverkehr mit einem Kraftfahrzeug, der Betrieb von
Atomkraftwerken, einer Flug- oder Eisenbahngesellschaft sowie die Produkthaftung.
2356 Ggfs. kann bei Einf&#252;hrung einer Risikoklassifizierung f&#252;r KI-Systeme eine Gef&#228;hrdungshaftung je nach Risikoklasse stufenweise 
beschr&#228;nkt werden. Erg&#228;nzend wird darauf hingewiesen, dass die Gef&#228;hrdungshaftung den Betreiber des KI-Systems nicht aus seiner
Haftung entl&#228;sst, beispielsweise bei fahrl&#228;ssigem Einsatz.
2357 Vgl. Spindler (2015): Roboter, Automation, k&#252;nstliche Intelligenz, selbst-steuernde Kfz &#8211; Braucht das Recht neue
Haftungskategorien?, S. 775 f.
2358 Ans&#228;tze f&#252;r die Indikatorenentwicklung finden sich z. B. bei Stiglitz et al. (2009): The Measurement of Economic Performance and
Social Progress Revisited, in der Berechnung eines Nationalen bzw. Regionalen Wohlfahrtsindex (vgl. Diefenbacher et al. (2016):
Aktualisierung und methodische &#220;berarbeitung des Nationalen Wohlfahrtsindex 2.0 f&#252;r Deutschland 1991 bis 2012; Held (2019):
Leben in Schleswig-Holstein &#8211; subjektive Einsch&#228;tzungen als Teil der Wohlfahrtsmessung), im &#8222;neuen magischen Viereck der
Wirtschaftspolitik&#8220; (vgl. Linder (2019): Das neue magische Viereck der Wirtschaftspolitik. Update, 2014 &#8211; 2018) sowie dem &#8222;Better Life
Index&#8220;, weitere Informationen dazu unter: http://www.oecdbetterlifeindex.org/de/#/11111111111 (zuletzt abgerufen am 14. Oktober
2020).
2359 Z. B. durch eine Weiterentwicklung DGB-Index &#8222;Gute Arbeit&#8220;, weitere Informationen dazu unter: https://index-gute-arbeit.dgb.de/
(zuletzt abgerufen am 14. Oktober 2020).
raussetzungen, die eben nicht privatwirtschaftlich beliebig bereitgestellt, umgewidmet und erzeugt werden
k&#246;nnen. Zu immateriellen Infrastrukturen z&#228;hlen u. a. Rechts- und Cybersicherheit (inkl. der Verfolgung von
Rechtsverletzungen) und auch technische Standards und Normen (z. B. TCP/IP, RAMI 4.0, ISO/IEC JTC 1/SC 42,
DIN SPEC 3105).
Aufgrund dieser Komplexit&#228;t, der R&#252;ck- und Folgewirkungen und des Umfangs der digitalen Transformation
kann sich die &#246;ffentliche Hand nicht weiter passiv auf die blo&#223;e Vergabe von Lizenzen und F&#246;rderbescheiden
(z. B. f&#252;r Mobilfunk, Stromtrassen, Kraftwerke) beschr&#228;nken &#8211; sie muss zudem letztlich garantieren k&#246;nnen, dass
die Infrastruktur bundesweit l&#252;ckenlos KI-Anwendungen erm&#246;glicht. Konkurrierende Unternehmen m&#252;ssen zu
strategischen Kooperationen angehalten werden, um Schl&#252;sselanwendungen zu f&#246;rdern und gemeinsame
Plattformen aufzubauen. In diesem Sinne wird die Entwicklung von Open Access, Open Source und offenen
Standards als wesentliche Infrastrukturelemente vorangetrieben. Der Staat muss und soll nicht alles selbst tun, hat
aber die Erbringung, Qualit&#228;t und Zugang der notwendigen Infrastruktur aktiv zu sichern.
KI ist nicht nur auf Infrastruktur angewiesen, sondern wird als Bestandteil sozio-technischer Systeme selbst zu
Infrastruktur2360: KI funktioniert meist im Hintergrund und ist f&#252;r die Nutzerinnen und Nutzer oftmals unsichtbar. 
Daher ist es elementar, dass KI-Infrastrukturen von Beginn an auf Gemeinwohl, Inklusion und Nachhaltigkeit
hin optimiert werden2361, die eine effektivere Allokation von Alltagsg&#252;tern und -dienstleistung erm&#246;glichen. Eine
Landnahme gemeinsamer Infrastrukturen durch das neoliberale Projekt2362 ist strikt abzulehnen, zumal Risiko
und Nutzen dort v&#246;llig ungleich verteilt werden. Soziale Ungleichheit darf nicht nur auf individueller Ebene
bek&#228;mpft werden, sondern auch und gerade durch die Bereitstellung guter Infrastrukturen f&#252;r alle.
Gesellschaftliche Aushandlungsprozesse: KI, Wohlergehen und Wirtschaften
Digitale Technologien inklusive K&#252;nstlicher Intelligenz tragen zum Wandel von Wirtschaft und Gesellschaft bei,
indem sie weitere Formen der Kommunikation und des Zusammenlebens er&#246;ffnen. Wie dies geschieht und wie
es zu deuten ist, wird seit Jahren kontrovers diskutiert, u. a. als umfassendere Individualisierung
(&#8222;Singularisierung&#8220;)2363 oder als Beschleunigung von Polarisierungsprozessen zwischen Personengruppen. Das k&#246;nnte die
Basis f&#252;r den Zusammenhalt des Gemeinwesens zerst&#246;ren.2364 
Wir sollten daher nicht nur &#252;ber die Chancen (und Gefahren) von K&#252;nstlicher Intelligenz als Technik sprechen,
wir m&#252;ssen auf allen Ebenen und mit verschiedensten partizipativen Verfahren aushandeln, in welcher
Gesellschaft wir leben wollen: Zu welchen G&#252;tern und Dienstleistungen sollte Zugang bestehen, damit es allen wohl
ergeht? Und kann &#8222;der&#8220; Markt das regeln, oder sollten in bestimmten Sektoren auch andere
Steuerungsmechanismen als Geld greifen, z. B. Gesundheit im medizinischen Bereich, Bildung im schulischen Bereich oder
Wissen in der Forschung? Welches Wirtschaften wollen wir f&#246;rdern, welches verhindern? Welche Rolle haben
Besch&#228;ftigte im sozio-technischen Wandel und wie k&#246;nnen wir Besch&#228;ftigte st&#228;rken? Wie funktioniert eine
partizipative Technikgestaltung mit einer starken betrieblichen Mitbestimmung? Wie k&#246;nnen wir
gemeinwohlorientierte und kooperative Plattformmodelle unter Einbeziehung und Kontrolle der Nutzerinnen und Nutzer f&#246;rdern,
etwa durch Genossenschaften oder die F&#246;rderung von Open Source? Wie k&#246;nnen wir die Entwicklung von Apps
2360 Infrastrukturen werden hier in einem breiten Sinn verstanden als fundamentale G&#252;ter und Dienstleistungen, die nicht nur materielle,
sondern auch die sozialen G&#252;ter und Dienstleistungen umfassen, die die Versorgung mit Alltagsg&#252;tern garantieren, die alle Menschen 
gleicherma&#223;en ben&#246;tigen (vgl. Foundational Economy Collective (2019): Die &#214;konomie des Alltagslebens. F&#252;r eine neue
Infrastrukturpolitik [2018]). Dazu geh&#246;ren als materielle Infrastrukturen etwa Rohre, Kabel, Transport- und Filialnetze zur Versorgung mit
Strom, Wasser, Daten oder Stra&#223;e und Schienen. Zur sozialen Infrastruktur z&#228;hlen v. a. Wohlfahrtsdienste des &#246;ffentlichen Sektors,
etwa medizinische und pflegerische Versorgung, Bildung, M&#252;llabfuhr, Banken, Justiz und der Schutz vor weiteren existentiellen
Risiken wie Arbeitslosigkeit und Armut. Infrastrukturen sind zudem durch relationale Praktiken und Standards gekennzeichnet, die
eine qualifizierte Nutzung erst erm&#246;glichen (vgl. Star und Ruhleder: Schritte zu einer &#214;kologie von Infrastruktur. Design und Zugang 
f&#252;r gro&#223;angelegte Informationsr&#228;ume [1995/1996]).
2361 Damit ist die Verabschiedung einer verabsolutierten Marktlogik verbunden. Diese optimiert an Gesichtspunkten der Effizienz. Das 
ist in sehr vielen Bereichen angemessen und sinnvoll. In anderen Bereichen sind (auch) andere Kriterien elementar, wie etwa
Zielerreichung (Effektivit&#228;t) oder die Robustheit gegen&#252;ber Fehlern und pl&#246;tzlichen Krisen. Beispielsweise darf ein Gesundheitssystem 
nicht so sehr auf Effizienz getrimmt sein, dass es bei unvorhergesehenen Ereignissen umgehend &#252;berfordert ist oder gar
zusammenbricht.
2362 Vgl. Morozov (2020): Digitale &#246;ffentliche Infrastruktur. Das sozialdemokratische Projekt des 21. Jahrhunderts.
2363 Reckwitz (2018): Die Gesellschaft der Singularit&#228;ten. Zum Strukturwandel der Moderne [2017].
2364 Vgl. Boltanski und Chiapello (2013): Der neue Geist des Kapitalismus [2003]; Nachtwey (2017): Die Abstiegsgesellschaft. &#220;ber das 
Aufbegehren in der regressiven Moderne [2016]; Misik (2019): Die falschen Freunde der einfachen Leute; Reckwitz (2020): Das
Ende der Illusionen. Politik, &#214;konomie und Kultur in der Sp&#228;tmoderne [2019] u. v. m.
f&#246;rdern, die nachhaltigen Konsum erleichtern, wie die &#246;ffentliche Auftragsvergabe an Datensuffizienz und
Nachhaltigkeit koppeln?
Ganz pragmatisch schlagen wir vor, mit den Ma&#223;nahmen zu beginnen, die nicht nur auf die oben formulierten 
Ziele hinf&#252;hren, sondern die auch mit den Zielvorstellungen anderer Interessenvertreterinnen und -vertreter
vereinbar sind &#8211; denn beginnen sollten wir jetzt, aber weder beliebig noch &#252;berhastet. Vielmehr sollte Politik zuerst
versuchen, die Entwicklungen sinnvoll zu entschleunigen, damit sich alle gesellschaftlichen Gruppen
ausreichend auf die gemeinsam zu vereinbarenden Ver&#228;nderungsprozesse einstellen k&#246;nnen.2365 
Sondervotum zu Kapitel C. III. &#8222;K&#252;nstliche Intelligenz und Staat (Projektgruppe 2)&#8220;
der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen
Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. unterst&#252;tzt im Wesentlichen den im vorliegenden Bericht der Projektgruppe &#8216;KI und 
Staat&#8217; vorgestellten Sachstand und die darin enthaltenen Handlungsempfehlungen. In einigen Bereichen ergaben
sich jedoch substanziellere Differenzen, die in diesem Sondervotum dargestellt werden. Sie betreffen
insbesondere die Bereiche innere und &#228;u&#223;ere Sicherheit, wo sich die Positionen der Linksfraktion von denen des
mehrheitlich beschlossenen Berichts erheblich in der Bewertung der bereits eingesetzten KI- bzw. ADM-Systeme und 
ihrer k&#252;nftigen Anwendungen unterscheiden.
Allgemeine Chancen und Risiken des Einsatzes von ADM-Systemen in der &#246;ffentlichen Verwaltung gelten
grunds&#228;tzlich auch f&#252;r das Milit&#228;r sowie f&#252;r Beh&#246;rden und Ministerien, die mit Sicherheitsfragen zu tun haben.
Jedoch haben diese Bereiche h&#228;ufiger einen besonderen Grundrechtsbezug, woraus sich h&#246;here Anforderungen
an den Einsatz von KI ergeben.
Da das Schadenspotenzial f&#252;r Individuen und die Gesellschaft beim fehlerhaftem Einsatz derartiger Systeme 
erheblich sein kann &#8211; von Grundrechtsverletzungen bis hin zum Tod von Zivilistinnen und Zivilisten beim
Einsatz t&#246;dlicher autonomer Waffensysteme &#8211; sollten sie in manchen Bereichen gar nicht und in anderen nur dann
eingesetzt werden, wenn ADM-Systeme ausgereift sind, zuverl&#228;ssig arbeiten, nicht unverh&#228;ltnism&#228;&#223;ig in
Grundrechte eingreifen und wenn das transparent und nachvollziehbar &#252;berpr&#252;ft wird. Diesen Entwicklungsgrad haben
heutige, im Bereich Milit&#228;r und innere Sicherheit eingesetzte Systeme nicht, sie bergen daher ein reales und nicht
vertretbares Schadenspotenzial, das von Diskriminierung in der Identifikation potenzieller Verd&#228;chtiger bis zur
T&#246;tung Unschuldiger reichen kann.
Bei allen Anwendungen von KI in Fragen der inneren und &#228;u&#223;eren Sicherheit ist eine sorgf&#228;ltige Abw&#228;gung
zwischen dem Interesse nach mehr Sicherheit und potenziellen und unverh&#228;ltnism&#228;&#223;igen Grundrechtseingriffen
zu treffen. Eine besonders sorgf&#228;ltige Abw&#228;gung ergibt sich auch aufgrund des staatlichen Gewaltmonopols und
der Machtasymmetrie zwischen B&#252;rgerinnen und B&#252;rgern sowie staatlichen Sicherheits- und Milit&#228;rorganen.
Verantwortung und Bewertungsmodelle
Die Fraktion DIE LINKE. fordert deutlich strengere Vorgaben f&#252;r die Bewertung und Risikoklassifizierung von 
KI-Systemen und bef&#252;rwortet ein Bewertungsverfahren anhand eines standardisierten Risikoklassenmodells, das
sowohl die Frage kl&#228;rt, ob ein KI-System &#252;berhaupt eingesetzt werden darf, als auch, welche Bedingungen es bei
einem zul&#228;ssigen Einsatz erf&#252;llen muss. Um die Frage nach dem generellen Einsatz eines KI-Systems zu
beantworten, muss vor der Einf&#252;hrung jedes KI-Systems f&#252;r nicht-triviale Aufgaben des Staates dessen Vereinbarkeit
mit den Grundrechten sowie das Verh&#228;ltnis von erwartetem Nutzen und m&#246;glichen Sch&#228;den f&#252;r Individuen und
die Gesellschaft &#252;berpr&#252;ft werden. Dies sollte auf Basis eines standardisierten Risikoklassenmodells erfolgen. 
Die Fraktion DIE LINKE. bef&#252;rwortet ein Verbot bzw. Nicht-Einsatz-Gebot von KI-Systemen, die nach
Anwendung eines solchen Risikoklassenmodells in eine nicht mehr vertretbare Risikoklasse fallen. Dies steht im
Widerspruch zur Projektgruppe, die sich nicht f&#252;r ein Verbot gef&#228;hrlicher KI-Systeme aussprechen wollte.2366 
2365 Vgl. Pfeiffer (2019): Digitale Transformation: Great, greater, tilt &#8230; ? Von der Produktivkraft- zur Distributivkraftentwicklung,
S. 398; &#228;hnlich das Pl&#228;doyer f&#252;r eine &#8222;sanfte Digitalisierung&#8220; von Lange und Santarius (2018): Smarte gr&#252;ne Welt? Digitalisierung
zwischen &#220;berwachung, Konsum und Nachhaltigkeit.
2366 Siehe auch Kapitel 1 [Kurzfassung des Projektgruppenberichts] des Berichts der Projektgruppe &#8222;KI und Staat&#8220; sowie Kapitel 1.1.
[Einf&#252;hrung] und Kapitel 1.2. [Thematischer Scherpunkt] des AG-Berichts 1 des Berichts der Projektgruppe &#8222;KI und Staat&#8220;.
KI-Systeme, die eingesetzt werden d&#252;rfen, werden nach dem im &#246;ffentlichen Sektor einheitlich anzuwendenden
Risikoklassenmodell, in eine bestimmte Risikoklasse eingeordnet.2367 Die zur jeweiligen Risikoklasse geh&#246;rigen
Vorgaben (z. B. hinsichtlich Nachvollziehbarkeit, Transparenz, Erfolgsparameter etc.) sind einzuhalten. Die
Risikoklasseneinstufung sowie die vorgeschaltete Bewertung eines KI-Systems sollten in einem transparenten und
nachvollziehbaren Prozess erfolgen. Damit gehen die Forderungen der Fraktion DIE LINKE. &#252;ber die
Handlungsempfehlungen des Projektgruppenberichts hinaus, KI-Systeme etwa f&#252;r den Einsatz im Sicherheitsbereich
&#8222;m&#246;glichst&#8221; einer Risikoklasse zuzuordnen.2368 Sowohl eine Bewertung der Grundrechtsvereinbarkeit der KI-
Systeme als auch eine Risikoklassifizierung m&#252;ssen vor jeder (nicht-trivialen) staatlichen Anwendung eines KI-
Systems durchgef&#252;hrt werden.
Je Risikoklasse sind angemessene Ver&#246;ffentlichungspflichten festzulegen, einzuhalten sowie j&#228;hrlich
Evaluationen vorzunehmen, um Klarheit &#252;ber den tats&#228;chlichen Nutzen herzustellen. Sollte anhand der Evaluationen ein
Verfehlen der Nutzenparameter festgestellt werden, muss umgehend gepr&#252;ft werden, ob das System weiterhin
eingesetzt werden soll. So ist bei diesen Evaluationen z. B. stets auf unzul&#228;ssige Diskriminierung zu achten und
darauf, dass das eingesetzte System vollst&#228;ndig nachvollziehbar ist. Eine einmalige &#220;berpr&#252;fung reicht bei
lernenden Systemen nicht, da sie sich kontinuierlich ver&#228;ndern. Diese Forderungen werden auch von den
Informationsfreiheitsbeauftragten aus Bund und L&#228;ndern bei allen Anwendungen selbstlernender Systeme in der
&#214;ffentlichen Verwaltung unterst&#252;tzt.2369 
Der Einsatz von ADM-Systemen durch &#246;ffentliche Stellen muss stets transparent erfolgen, es muss f&#252;r davon
direkt Betroffene und Verb&#228;nde einen einfachen Zugang zu Rechtsmitteln geben, um bei Bedarf, wie z. B. auch
in Art. 22 Absatz 3 DSGVO vorgesehen, Widerspruch gegen eine automatisierte Entscheidung einzulegen.
Grunds&#228;tzlich fordert die Fraktion DIE LINKE. ein Widerspruchsrecht bzw. ein Recht auf &#220;berpr&#252;fung des
jeweiligen Vorgangs durch einen Mensch f&#252;r jede Verwaltungsentscheidung, die durch einen KI-Einsatz zustande 
kam. Ausnahmen sollte es f&#252;r den Bagatell-Einsatz ohne Auswirkung auf Teilhabe und Grundrechtsbezug geben
(z. B. KI-basierte Postkorbsortierung in Beh&#246;rden). Entscheidungen, die nicht vollst&#228;ndig durch ein KI-System
getroffen wurden, sondern bei denen es einen sogenannten menschlichen Letztentscheid gab, sind gesondert zu
betrachten, denn es ist weitere Forschung zu der Frage notwendig, inwieweit menschliche Entscheidungen, die
mit Hilfe von fast-autonomen Systemen getroffen werden, tats&#228;chlich trotzdem unabh&#228;ngig vom KI-System
gef&#228;llt wurden &#8211; also ob der Letztentscheid einen tats&#228;chlichen Unterschied zur vollautomatisierten Entscheidung
darstellt.2370 
ADM-Systeme sind au&#223;erdem grunds&#228;tzlich nur f&#252;r den Zweck einzusetzen, f&#252;r den sie urspr&#252;nglich entwickelt, 
trainiert sowie bewertet wurden. Dieser wesentlichen Forderung konnte sich leider keine Mehrheit der Enquete
anschlie&#223;en, obwohl es bereits wissenschaftliche Erkenntnisse dazu gibt, welche groben M&#228;ngel
zweckentfremdet eingesetzte KI-Systeme haben. 
Zu jedem Zeitpunkt muss weiterhin die rechtliche Verantwortung f&#252;r eine ADM-basierte Entscheidung eindeutig
gekl&#228;rt sein. Bei Entscheidungsprozessen, die Grundrechte einschr&#228;nken k&#246;nnen, d&#252;rfen ADM-Systeme nur
Input f&#252;r Entscheidungen von Menschen liefern, niemals jedoch eine Entscheidung allein treffen. Eine
nachtr&#228;gliche Kontrolle durch Menschen ist dabei nicht ausreichend. Personal, das mit KI-Systemen arbeitet, ist regelm&#228;&#223;ig
darin zu schulen.
Da es sich bei KI-Systemen um eine Art immaterieller Infrastruktur handelt, sollte neben einer
Einzelfallbetrachtung analog zu anderen Infrastrukturprojekten eine gesamtarchitektonische Betrachtung zur Ermittlung der
Gesamtwirkung mit Blick auf potenzielle &#8222;Nebenwirkungen&#8221; und den zu erwartenden Nutzen f&#252;r Mensch und
Gesellschaft erfolgen.2371 Denn KI-Systeme haben grunds&#228;tzlich das Potenzial, gesellschaftliche Strukturen
nachhaltig zu ver&#228;ndern und dadurch eine Vielzahl von Lebensbereichen zu betreffen. Es ist daher erforderlich, nicht
nur die tempor&#228;ren Auswirkungen eines einzelnen KI-Systems auf einzelne Menschen zu betrachten, sondern
auch l&#228;ngerfristige und wechselwirkende Effekte sowie den Kontext des Einsatzes in eine ganzheitlichere
Evaluation mit einzubeziehen. Zu den zu entwickelnden Bewertungsma&#223;st&#228;ben k&#246;nnten folgende Punkte geh&#246;ren:
F&#246;rderung der Vielfalt, Schaffung ausgeglichener sozialer, infrastruktureller, wirtschaftlicher, &#246;kologischer und
2367 Das Risikoklassenmodell sollte dabei an das Modell angelehnt sein, welches die Datenethikkommission in ihrem Gutachten
beschreibt (vgl. Datenethikkommission der Bundesregierung (2019): Gutachten der Datenethikkommission der Bundesregierung).
2368 Siehe auch Kapitel 1 [Kurzfassung des Projektgruppenberichts] des Berichts der Projektgruppe &#8222;KI und Staat&#8220; sowie Kapitel 3.3 des
AG-Berichts 3 des Berichts der Projektgruppe &#8222;KI und Staat&#8220; [IT-Sicherheit].
2369 Vgl. Matthes (2018): K&#252;nstliche Intelligenz in der Verwaltung: IFG Beauftragte von Bund und L&#228;ndern fordern Transparenz.
2370 Siehe auch Kapitel 3.2 des AG-Berichts 3 des Berichts der Projektgruppe &#8222;KI und Staat&#8220; [&#196;u&#223;ere Sicherheit].
2371 Darstellung Lorena Jaume-Palasi (The Ethical Tech Society) in der Sitzung der Projektgruppe &#8222;KI und Staat&#8220; am 6. Mai 2019.
kultureller Verh&#228;ltnisse, die F&#246;rderung des sozialen Zusammenhalts, die Gew&#228;hrleistung einer umfassenden
stabilen Daseinsvorsorge, die F&#246;rderung der Kultur, der Sicherheit und der Nachhaltigkeit. Eine solche
Gesamtbetrachtung sollte bei m&#246;glichen Einschr&#228;nkungen mit Grundrechtsbezug analog zur
&#220;berwachungsgesamtrechnung erfolgen.
Verwaltung
Die Fraktion DIE LINKE. bem&#228;ngelt die einseitige Darstellung der potenziellen Vorteile eines Einsatzes von KI-
Systemen in der Verwaltung, denn potenzielle negative Effekte werden nicht aufgef&#252;hrt (Personalabbau, h&#246;here
Zahl von fehlerhaften Bescheiden).2372 
F&#252;r den Bereich der Grundsicherung f&#252;r Arbeitsuchende (&#8222;Hartz IV&#8221;, Sozialgeld) und Sozialhilfe weist die
Fraktion DIE LINKE. die im Projektgruppenbericht genannten Beispiele zur&#252;ck.2373 Bei der Leistungsgew&#228;hrung zur
Existenzsicherung handelt es sich gerade nicht um routinem&#228;&#223;ige Prozesse, die sich zu einer Automatisierung
eignen, sondern um hochindividualisierte Einzelfallentscheidungen. Bescheide im Bereich SGB II sind, so die
herrschende Meinung der Sozialgerichtsbarkeit, kein Massengesch&#228;ft: Antr&#228;ge m&#252;ssen individuell bearbeitet und
entschieden werden. Dass die Bearbeitung und Bescheidung eben nicht routiniert und problemlos erfolgt, zeigen
die anhaltend hohen Fallzahlen bei Widerspr&#252;chen und Gerichtsprozessen, die zudem sehr h&#228;ufig positiv f&#252;r die
B&#252;rgerinnen und B&#252;rger enden.2374 
Dementsprechend teilt die Fraktion DIE LINKE. die Auffassung aus Abbildung 1, S. 207 nicht, dass die
Bearbeitung von Antr&#228;gen auf staatliche Leistungen grunds&#228;tzlich als einfache, nicht-komplexe Bearbeitung
einzustufen sei. Das Beispiel der oben angef&#252;hrten Leistungen nach dem SGB II (&#8222;Hartz IV&#8220; und Sozialgeld) zeigt,
dass diese teils hochkomplex und stets im Einzelfall zu entscheiden sind, also keinesfalls ein Massengesch&#228;ft
darstellen k&#246;nnen oder rechtlich d&#252;rften. Eine automatisierte Bescheidung etwa bez&#252;glich existenzsichernder
Leistungen, w&#252;rde zun&#228;chst einen grunds&#228;tzlichen Umbau des Existenzsicherungssystems hin zu einer
automatisierbaren Leistung voraussetzen. So m&#252;ssten unbestimmte Rechtsbegriffe wie &#8222;Kosten der Unterkunft und
Heizung&#8220; (&#167; 22 SGB II) vollst&#228;ndig eliminiert und ersetzt werden, um die Leistung ohne menschlichen Eingriff
berechnen zu k&#246;nnen.
In anderen Bereichen staatlichen Handelns bedarf es differenzierten Betrachtungen, die danach unterscheiden,
ob es nur um die Einreichung eines Antrags geht &#8211; also etwa das KI-gest&#252;tzte Ausf&#252;llen eines Antragsformulars
(hier kann ein KI-System wie beispielsweise ein Chatbot durchaus routinem&#228;&#223;ig und im Massengesch&#228;ft
einsetzbar sein) &#8211; oder um die Bearbeitung eines Antrags innerhalb der Verwaltung, die eben nur dann &#252;berhaupt mit
einem KI-System erfolgen darf, wenn es keinerlei Ermessenspielr&#228;ume gibt.
Innere Sicherheit
Die Fraktion DIE LINKE. teilt die positive Positionierung des Projektgruppenberichts zur automatischen
Gesichtserkennung nicht. Beim Gesichtserkennungstestprojekt am Berliner Bahnhof S&#252;dkreuz wurde ein
Hauptproblem von ADM-Systemen offensichtlich, die zur Fahndung nach Rechtsbr&#252;chigen und Gef&#228;hrdern eingesetzt
werden, n&#228;mlich ihre sehr hohen Falsch-Positiv-Raten.2375 Die durch die Mehrheitsposition in der Enquete
getragene Beschreibung fokussiert auf einseitige, euphemistische Beschreibungen des Projekterfolgs, der durch die
Datenlage nicht hinreichend belegt ist und in einem realen Praxiseinsatz nicht nachbildbar w&#228;re (wie z. B. der
gleichzeitige Einsatz drei verschiedener Gesichtserkennungssysteme).
Nach Auswertung der vorhandenen Datenlage ist f&#252;r die Fraktion DIE LINKE. erwiesen, dass ein solcher Einsatz
schlecht funktionierender Gesichtserkennungssysteme dazu f&#252;hren w&#252;rde, dass t&#228;glich hunderte von Menschen
an einem Bahnhof &#8211; oder Tausende bundesweit &#8211; falsch verd&#228;chtigt w&#252;rden, mit all den negativen Folgen, die
das f&#252;r die zu Unrecht Verd&#228;chtigten und ihr Umfeld hat. 
Es ist au&#223;erdem nicht nachvollziehbar, woher die erheblichen polizeilichen Ressourcen kommen sollen, um die
zahlreichen (f&#228;lschlich) Verd&#228;chtigten hinreichend gr&#252;ndlich aber zeitnah zu kontrollieren. Es liegt der Schluss
nahe, dass die Wahrscheinlichkeit, tats&#228;chliche T&#228;ter zu ergreifen eher sinkt, weil zu viele Polizistinnen und
2372 Siehe auch Kapitel 1 [Kurzfassung des Projektgruppenberichts] und AG-Berichts 1 [AG 1: KI in der Verwaltung und internationale
Vorbilder] des Berichts der Projektgruppe &#8222;KI und Staat&#8220;.
2373 Siehe auch Kapitel 1.2 des AG-Berichts 1 des Berichts der Projektgruppe &#8222;KI und Staat&#8220; [Thematischer Scherpunkt].
2374 Vgl. Becher (2019): Hartz IV: Hohe Erfolgsquoten bei Widerspr&#252;chen und Klagen mit weiterf&#252;hrenden Links zu amtlichen
Statistiken.
2375 Vgl. Krempl (2018): CCC: Bundespolizei hat Bericht zur Gesichtserkennung absichtlich gesch&#246;nt.
Polizisten damit besch&#228;ftigt sein w&#252;rden, mit viel Aufwand Unschuldige zu &#252;berpr&#252;fen. Der
Bundesdatenschutzbeauftragte Ulrich Kelber sowie Datensch&#252;tzer aus Bund und L&#228;ndern stellten bereits fest, dass biometrische
Gesichtserkennung aufgrund ihrer hohen Fehlerquote erheblich in das Grundrecht auf informationelle
Selbstbestimmung eingreift.2376 Trotzdem plant die Bundesregierung zusammen mit der Europ&#228;ischen Union, die
Nutzung von Gesichtserkennungssystemen in polizeilichen Datenbanken weiter auszubauen2377 und diese au&#223;erdem
zusammenzuf&#252;hren.2378 
Risiken des Einsatzes K&#252;nstlicher Intelligenz ergeben sich vor allem dann, wenn sie Menschen in Gruppen
einteilt und es anhand dieser Gruppenzuordnung zu unterschiedlicher Behandlung kommt. Eine solche
Gruppeneinteilung muss nicht einmal beabsichtigt sein, sondern ergibt sich h&#228;ufig aus den Daten, die f&#252;r das Training der
ADM-Systeme eingesetzt wurden. Diese Trainingsdatens&#228;tze bilden bestehende Benachteiligungen ab (z. B. 
&#220;berrepr&#228;sentation von Schwarzen in den US-Kriminalstatistiken) und repr&#228;sentieren verschiedene
demographische Gruppen unterschiedlich gut. Dies zeigt sich an von Geschlecht und Ethnie abh&#228;ngigen Fehlerquoten, z. B. 
bei h&#228;ufigerer Einstufung Unschuldiger als Verd&#228;chtige, wenn sie dunkelh&#228;utig sind.2379
Aufgrund dessen hat die Stadt San Francisco aus Sorge vor Racial Profiling und Missbrauchsgefahr den Einsatz
von Gesichtserkennungssoftware durch Beh&#246;rden generell verboten. Die Gefahr, dass der Einsatz solcher
Technologien die B&#252;rgerrechte verletzen k&#246;nne, &#252;berwiege die behaupteten Vorteile bei Weitem, entschied der
Stadtrat der kalifornischen Metropole. Der Einsatz von Gesichtserkennung drohe rassistische Ungerechtigkeit zu
versch&#228;rfen und bedrohe die M&#246;glichkeit, frei von st&#228;ndiger Beobachtung durch die Regierung zu leben.2380 Auch 
f&#252;r sonstige &#220;berwachungstechnologie, von Kennzeichenerfassung &#252;ber Predictive Policing bis IMSI Catcher
gelten nun starke Einschr&#228;nkungen in San Francisco. &#220;berwachungstechnologie darf durch Beh&#246;rden nur noch
nach strengsten Auflagen und einem &#246;ffentlichen Hearing genehmigt werden und nur dann, wenn ihre
Diskriminierungsfreiheit nachgewiesen wurde. Bei Genehmigung ist fortan j&#228;hrlich ein umfangreicher Bericht zu
ver&#246;ffentlichen. Das Ziel ist, staatliche &#220;berwachung darauf zu beschr&#228;nken, wo sie unabdingbar ist, einen
nachweisbaren Nutzen stiftet, Freiheitsrechte nicht unverh&#228;ltnism&#228;&#223;ig einschr&#228;nkt und keine diskriminierenden Effekte
aufweist, um durch maximale Transparenz das Vertrauen in staatliche Institutionen wieder zu st&#228;rken. Dieser
Position schlie&#223;t sich die Fraktion DIE LINKE. vollst&#228;ndig an, leider war sie nicht mehrheitsf&#228;hig in der Enquete-
Kommission. Auch Tech-Konzerne wie Google nehmen Abstand von automatischer Gesichtserkennung aus
Sorge vor Missbrauch.2381 
Au&#223;erdem weist die Fraktion DIE LINKE. die Behauptungen des Projektgruppenberichtes zur&#252;ck, dass durch
eine &#8222;intelligente Videoauswertung&#8221; von Verhaltenserkennung wie sie in Mannheim getestet wird2382 im
Gegensatz zur biometrischen Gesichtserkennung, die Reaktionszeiten der Ermittlungsbeh&#246;rden gesenkt werden
k&#246;nnten und damit ein sachgerechter Einsatz erfolge.2383 Diese Art der Auswertung ist deutlich kritischer zu
betrachten, als es der Bericht vermuten l&#228;sst, und grunds&#228;tzlich abzulehnen. Eine nicht anlassbezogene
&#220;berwachungsma&#223;nahme mit hohen Grundrechtseingriffen, die immer, &#252;berall und gegen alle gerichtet ist, ist nach dem EuGH-
Urteil zur Vorratsdatenspeicherung schlicht nicht zul&#228;ssig. Zudem kann eine solche Ma&#223;nahme nicht isoliert
betrachtet werden, sondern muss in einer &#220;berwachungsgesamtrechnung bewertet werden, die andere
&#220;berwachungsma&#223;nahmen, sowie deren Effekte und Synergien untereinander mitbedenkt.
2376 Vgl. DPA (2019): Kelber warnt vor automatischer Gesichtserkennung.
2377 Vgl. Antwort der Bundesregierung auf die Kleine Anfrage der Fraktion DIE LINKE. auf Bundestagsdrucksache 19/4889.
2378 Vgl. Antwort der Bundesregierung auf die Kleine Anfrage der Fraktion DIE LINKE. auf Bundestagsdrucksache 19/4889; Mertens 
(2018): EU und Berlin planen mehr Gesichtserkennung in polizeilich genutzten Datenbanken, Monroy (2018): &#8222;Gemeinsamer
Identit&#228;tsspeicher&#8220;: Biometrische Daten landen in europ&#228;ischem Datentopf; Fanta (2018): EU-Projekt entwickelt smarten L&#252;gendetektor
f&#252;r Grenzkontrollen.
2379 Vgl. Raji und Buolamwini (2019): Actionable Auditing: Investigating the Impact of Publicly Naming Biased Performance Results
of Commercial AI Products.
2380 Vgl. Zeit.de (2019): San Francisco verbietet Gesichtserkennung durch Beh&#246;rden.
2381 Vgl. Bosker (2011): Facial Recognition: The One Technology Google Is Holding Back.
2382 Vgl. Fraunhofer-Institut f&#252;r Optronik, Systemtechnik und Bildauswertung: Intelligente Video&#252;berwachung f&#252;r mehr Sicherheit und 
Datenschutz; Ministerium f&#252;r Inneres, Digitalisierung und Migration Baden-W&#252;rttemberg: Startschuss f&#252;r die algorithmenbasierte
Video&#252;berwachung beim Polizeipr&#228;sidium Mannheim (zuletzt abgerufen am 23. Oktober 2020.
2383 Siehe auch Kapitel 3.1.2 des AG-Berichts 3 [Thematischer Schwerpunkt] unter &#8222;Gesichtserkennung und Video&#252;berwachung&#8220; und
Kapitel 3.1.3 des AG-Berichts 3 [Handlungsempfehlungen und Perspektiven] des Berichts der Projektgruppe &#8222;KI und Staat&#8220;.
Zu den unerw&#252;nschten Nebenwirkungen derartiger &#220;berwachungsma&#223;nahmen geh&#246;rt der sogenannte &#8222;Chilling
Effect&#8221;: nach dem Menschen ihr Verhalten bei st&#228;ndiger &#220;berwachung selbst bei legalen Aktivit&#228;ten
einschr&#228;nken, um m&#246;glichst konform zu handeln. B&#252;rgerinnen und B&#252;rger k&#246;nnten beispielsweise ihre politische
Partizipation zur&#252;ckfahren &#8212; wie aus anderen F&#228;llen bekannt ist.2384 Eine derartige Beeinflussung ist in einer
Demokratie jedoch inakzeptabel. Zudem ist die generelle Verh&#228;ltnism&#228;&#223;igkeit einer solchen
&#220;berwachungsinfrastruktur in Frage zu stellen. Eine dauerhafte und nicht anlassbezogene &#220;berwachungsma&#223;nahme wie automatisierte
Gesichtserkennung oder Verhaltens&#252;berwachung steht in keinem zurechtfertigendem Verh&#228;ltnis zum
postulierten Nutzen. Auch pr&#228;ventiv f&#252;hrt eine automatisierte &#220;berwachungsinfrastruktur nicht zu einer Abnahme der
Kriminalit&#228;t. Der Einsatz derartiger Technologien mit hohen Grundrechtseingriffen ohne tats&#228;chlich
nachgewiesenen, erheblichen Nutzen, der zus&#228;tzlich nicht durch andere Praktiken ohne vergleichbare Grundrechtseingriffe
erreichbar sein darf, verbietet sich nach Auffassung der Fraktion DIE LINKE.
B&#252;rgerrechte werden in unvertretbarer Weise verletzt, wenn Gesichts- und Verhaltenserkennung zur
Identifikation von Straft&#228;terinnen und Straft&#228;tern eingesetzt wird, obwohl die Falsch-Positiv-Raten insbesondere bei
spezifischen demographischen Gruppen wie People of Color hoch sind. Ein tats&#228;chlicher Mehrwert biometrischer
&#220;berwachung im Vergleich zu klassischer Polizeiarbeit konnte bisher ebenso wenig erbracht werden, wie bei der
Vorratsdatenspeicherung. Tats&#228;chlich waren beispielsweise fast alle terroristischen Attent&#228;ter der letzten Jahre
in Europa polizeilich bekannt und bei vielen gab es Hinweise auf ihrve Gef&#228;hrlichkeit. Anis Amri ist ein
besonders eklatantes Beispiel daf&#252;r, dass gute Polizeiarbeit das furchtbare Attentat auf den Berliner Weihnachtsmarkt
h&#228;tte verhindern k&#246;nnen, mehr biometrische &#220;berwachung jedoch nicht. Die LINKE. lehnt den Einsatz von
automatisierter Gesichts- und Verhaltenserkennung in diesem Kontext daher grunds&#228;tzlich ab. 
Im Abschnitt des Projektgruppenberichtes zum Thema &#8222;Predictive Policing&#8221; kritisiert die Fraktion DIE LINKE.
die Streichung des Erfahrungsberichtes des heutigen Referatsleiters f&#252;r Kriminalangelegenheiten im
nordrheinwestf&#228;lischen Innenministerium, der unmittelbar am Betrieb des Predictive-Policing-Systems SKALA in
Nordrhein-Westfalen beteiligt war. Zwar ist ein Teil seiner Kritikpunkte im finalen Projektgruppenbericht enthalten,
trotzdem hat sich die Projektgruppe dagegen entschieden, die genannten Kritikpunkte auf die Erfahrungswerte
eines Beamten zur&#252;ckzuf&#252;hren, der praktische Kenntnisse im Umgang mit einem Predictive-Policing-Systems
hat.2385 So fehlt in der Darstellung des Projektgruppenberichts seine Einsch&#228;tzung, dass der Einsatz von
Predicitive-Policing-Systemen bei personenbezogenen Taten, z. B. Raub&#252;berf&#228;llen oder K&#246;rperverletzung, nicht
sinnvoll ist. &#8222;Heatlists&#8220; f&#252;r potenzielle Gef&#228;hrderinnen und Gef&#228;hrder h&#228;lt er f&#252;r riskant den sie k&#246;nnten auch zur
selbsterf&#252;llenden Prophezeiung werden (Menschen werden solange verfolgt, bis sie tats&#228;chlich eine Straftat
begehen) und w&#228;ren im Polizeialltag nicht hilfreich, denn Grundrechtseingriffe sind ohnehin nur anlassbezogen
erlaubt und nicht aufgrund von Prognosen.
F&#252;r die Fraktion DIE LINKE. besteht dar&#252;ber hinaus die Gefahr der Umkehr der Unschuldsvermutung beim
Einsatz von Predictive-Policing-Systemen, sowie das Potenzial von Diskriminierung von Angeh&#246;rigen
spezifischer demographischer Gruppen.
&#196;u&#223;ere Sicherheit
Nach Auffassung der Fraktion DIE LINKE. bleibt die im Bericht vorgeschlagene Regulierung und &#196;chtung von
KI-Systemen f&#252;r den milit&#228;rischen Einsatz deutlich hinter humanistischen Anspr&#252;chen zur&#252;ck. 
Bef&#252;rworterinnen und Bef&#252;rworter vollautonomer t&#246;dlicher Waffensysteme (LAWS) betonen, dass diese den
Krieg &#8222;humanisieren&#8220; w&#252;rden, weil dadurch das Opferrisiko f&#252;r die eigenen Streitkr&#228;fte s&#228;nke, Kollateralsch&#228;den
minimiert sowie Pr&#228;zision und Tempo von kriegerischen Handlungen erh&#246;ht w&#252;rden. DIE LINKE. findet diese
Darstellung euphemistisch und nicht der Realit&#228;t entsprechend und sieht im Einsatz von LAWS abweichend zur
Darstellung im Abschlussbericht die Gefahr einer Dehumanisierung des Krieges, weil der Mensch und seine
Moralvorstellungen bei LAWS keine Rolle mehr spielen und Maschinen gegen Menschen eingesetzt werden.
Der behaupteten Pr&#228;zision stehen au&#223;erdem viele Berichte zu zahlreichen zivilen Opfern im Drohnenkrieg
gegen&#252;ber, die besch&#246;nigend als &#8222;Kollateralsch&#228;den&#8221; bezeichnet werden.2386 
Eine vollst&#228;ndige und sofortige &#196;chtung von LAWS ist f&#252;r DIE LINKE. daher unumg&#228;nglich. Eine &#196;chtung von
LAWS schlie&#223;t dabei ein, dass auf deutschem Boden kein Einsatz von LAWS erfolgen darf und auch nicht direkt
2384 Vgl. Roos (2016): Studie belegt Selbstzensur von Internetnutzern nach Snowden-Enth&#252;llungen; Karig (2015): Befallen vom
&#220;berwachungsvirus.
2385 Vgl. Stiftung Neue Verantwortung (2018): Transkript zum Hintergrundgespr&#228;ch &#8222;Predictive Policing in Deutschland&#8220;.
2386 Weitere Informationen dazu unter: https://www.thebureauinvestigates.com/projects/drone-war/ (zuletzt abgerufen am 18. Juni 2019).
oder indirekt unterst&#252;tzt wird. Konsequenterweise muss daher auch dem US-Milit&#228;rst&#252;tzpunkt Ramstein die
Unterst&#252;tzung derartiger Drohneneins&#228;tzen untersagt werden. Daf&#252;r hat sich in der Enquete Kommission keine
Mehrheit gefunden. Im Bericht der Projektgruppe wird au&#223;erdem die Position vertreten, dass eine &#196;chtung erst
dann erfolgen k&#246;nne, wenn es eine hinreichende Anzahl L&#228;nder g&#228;be, die sich dieser Entscheidung anschlie&#223;en
(eine konkrete Zahl wurde dabei nicht genannt).2387 Allerdings haben 28 L&#228;nder bereits eine solche &#196;chtung
ausgesprochen, bedauerlicherweise geh&#246;rt Deutschland aber nach wie vor nicht dazu und es fand sich leider auch
keine Mehrheit in der Enquete-Kommission, um eine zeitnahe &#196;chtung explizit zu empfehlen, obwohl die
&#196;chtung im Koalitionsvertrag zwischen CDU/CSU und SPD als Ziel benannt ist.
ADM-Systeme, deren Einsatz aus ethischen oder juristischen Gr&#252;nden nicht zul&#228;ssig sind, sollten au&#223;erdem
einem Herstellungs-, Handels- und Exportverbot unterliegen. Deutschland muss bei besonders gef&#228;hrlichen KI-
Systemen den Einsatz &#228;chten und sich f&#252;r die internationale &#196;chtung solcher Systeme stark machen. Gerade
LAWS sind ethisch nicht vertretbar, da ihre potenzielle Schadenswirkung schon im Normalbetrieb und
insbesondere bei Fehlern des Systems irreparabel und gravierend ist &#8211; sowohl f&#252;r get&#246;tete Zivilistinnen und Zivilisten und
ihre Familien, als auch f&#252;r die Gesellschaft als Ganzes. Der zu erwartende Nutzen f&#252;r Individuen und Gesellschaft
rechtfertigt diese nicht wieder gut zu machenden Menschenrechtsverletzungen nicht.
Immer wieder und auch im vorliegenden Bericht der Enquete wird darauf hingewiesen, dass es nur darauf
ank&#228;me, einen menschlichen Letztentscheid sicherzustellen, dass also der Einsatz von fast-autonomen
Waffensystemen v&#246;llig in Ordnung w&#228;re, so lange irgendwo ein Mensch vor einem Bildschirm sitzt und die Aufforderung
des Computerprogramms &#8222;Die Zielperson ist zu 84 Prozent ein Terrorist, der Einsatz letaler Waffen wird
empfohlen. Bitte best&#228;tigen Sie den Einsatz letaler Waffen&#8221; mit einem Klick auf die Enter-Taste best&#228;tigt.
Allerdings gibt es kaum belastbare Forschung zu der Frage, inwieweit fast-autonome letale Waffensysteme sich
im tats&#228;chlichen Einsatz von LAWS hinreichend unterscheiden, oder ob sie nicht &#228;hnlich behandelt werden
m&#252;ssen. So lange die Annahme unbest&#228;tigt ist, dass ein menschlicher Letztentscheid tats&#228;chlich eine unabh&#228;ngige
Entscheidung eines Menschen und damit eine zus&#228;tzliche moralische Instanz darstellt und es glaubhafte Zweifel
von Fachleuten dazu gibt, sollten diese Systeme den LAWS gleichgesetzt werden. Stresssituationen, die
Un&#252;bersichtlichkeit in milit&#228;rischen Konflikten, die Notwendigkeit blitzschneller Reaktionen und blindes Vertrauen in
Vorschl&#228;ge fast-autonomer Systeme k&#246;nnen dazu f&#252;hren, dass ADM-gest&#252;tzte Entscheidungsvorgaben kaum
korrigiert werden. Die Unabh&#228;ngigkeit menschlicher Entscheiderinnen und Entscheider kann sich auch im Laufe
l&#228;ngerer Nutzung solcher fast-autonomen Systeme ver&#228;ndern. Es ist dabei zu bef&#252;rchten, dass Menschen mit
zunehmender Nutzung von fast-autonomen Systemen immer mehr geneigt sind, den Empfehlungen des Systems
zu folgen. Dabei d&#252;rften auch soziale Faktoren wie die pers&#246;nliche Verantwortung bei Fehlentscheidungen eine
Rolle spielen. Alle diese Aspekte m&#252;ssen eingehender erforscht werden, bevor ein Einsatz auch von KI-
gest&#252;tzten Waffensystemen mit menschlichem Letztentscheid &#252;berhaupt erwogen werden darf.
Milit&#228;rische KI-Systeme k&#246;nnen auch zum Einsatz kommen, wenn sich deren Zweck nicht gegen Leib und Leben 
von Menschen richtet. Solche Systeme k&#246;nnen insbesondere bei der Gel&#228;ndesondierung, Aufkl&#228;rung, Warnung
und bei Minensuchrobotern von Nutzen sein. Jedoch muss auch dieser Einsatz unter klaren gesetzlichen
Rahmenbedingungen stattfinden. Ob KI-Systeme dar&#252;ber hinaus auch in Anwendungen f&#252;r Verteidigungszwecke
integriert werden d&#252;rfen, muss in einer gesamtgesellschaftlichen Diskussion er&#246;rtert und ggf. streng reguliert
werden, denn auch solche Systeme k&#246;nnen durch Auf- oder Umr&#252;stung als offensive Systeme eingesetzt werden. 
Es sind zudem Prozesse und Kriterien zu entwickeln, nach denen Dual Use KI-Systeme und ihre Bausteine
identifizierbar sind. Sie sind ebenfalls einer ethischen Bewertung zu unterziehen und einer Risikoklasse zuzuordnen
und zu behandeln wie milit&#228;rische KI-Systeme. Auf jeden Fall muss der Export fast autonomer letaler
Waffensysteme, die zu ganz autonomen Systemen umger&#252;stet werden k&#246;nnen, verboten sein.
Die Position der Fraktion DIE LINKE. unterscheidet sich auch in der Betrachtung ziviler und milit&#228;rischer
Forschung. Nach &#220;berzeugung der Linksfraktion sollte zivile und milit&#228;rische Forschung getrennt erfolgen.
Forschung im milit&#228;rischen Bereich sollte transparent dokumentiert werden, ethischen Richtlinien folgen und von
einem gesellschaftlichen Diskurs begleitet werden. Wenn Forschungseinrichtungen sich selbst Zivilklauseln
gegeben haben, sind diese zu respektieren. Auf keinen Fall darf in die Wissenschaftsfreiheit eingegriffen werden, 
indem F&#246;rderungen davon abh&#228;ngig gemacht werden, ob eine milit&#228;rische Nutzung von Forschungsergebnissen
gestattet wird oder nicht. Die Ver&#246;ffentlichung von Software durch Forschungseinrichtungen mit Zivilklauseln
unter Non-Military-Lizenzen muss auch dann m&#246;glich sein, wenn eine Verpflichtung zur Ver&#246;ffentlichung von
2387 Siehe auch Kapitel 3.2.3 des AG-Berichts 3 des Berichts der Projektgruppe &#8222;KI und Staat&#8220; [Handlungsempfehlungen und
Operationalisierung].
Forschungsergebnissen im Sinne von Open Access besteht. Zudem warnen viele Wissenschaftlerinnen und
Wissenschaftler sowie Entscheiderinnen und Entscheider gro&#223;er Technologieunternehmen vor der
Weiterentwicklung K&#252;nstlicher Intelligenz vor allem im milit&#228;rischen Bereich, so lange es keine ausgereifte und wirksame
Regulierung K&#252;nstlicher Intelligenz gibt.2388 
Die Fraktion DIE LINKE. teilt au&#223;erdem nicht das im Bericht genannte Argument, dass Deutschland und Europa
eine technologische Aufr&#252;stung durch den Einsatz von KI in milit&#228;rischen Feldern braucht, um eine gestaltende
Rolle bei der Weiterentwicklung des V&#246;lkerrechts zu spielen.2389 Dazu gibt es viele andere Optionen, die weniger
Gefahrenpotenzial bieten.
Sondervotum zu Kapitel 3.2.1.3 des Berichts der Projektgruppe &#8222;KI und Arbeit,
Bildung, Forschung&#8220; (&#8222;Prozessoptimierung durch Predictive Analysis&#8220;) der
Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen Mitglieds Dr. Florian 
Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo verweisen auf die Erfahrungen mit bereits
im Einsatz befindlicher Software in Betrieben. Auf Optimierung ausgelegte KI-Systeme beinhalten das Risiko
der Leistungs&#252;berwachung, Arbeitsverdichtung, &#220;berforderung und Entwertung von Arbeit.2390 Systeme, die die
Arbeit von Besch&#228;ftigten steuern, erfassen zum Teil jeden Arbeitsschritt.2391 So ist beispielsweise der Fall des
gro&#223;en Versandh&#228;ndlers Amazon bekannt, in dessen Logistikzentrum minuti&#246;s aufgezeichnet und ausgewertet
wird, wie produktiv einzelne Besch&#228;ftigte sind. F&#252;r die Mitarbeiterinnen und Mitarbeiter bedeutet das
permanenten &#220;berwachungsdruck und Leistungsdrill. In einem System, das jeden Arbeitsschritt sowie den Arbeitstakt
vorgibt, k&#246;nnen Besch&#228;ftigte nicht mehr selbst&#228;ndig agieren, sondern nur noch reagieren, was letztendlich auch
zu einer Entwertung ihrer Arbeit f&#252;hrt. Einen Einsatz solcher Systeme lehnt die Fraktion DIE LINKE. strikt ab.
Sondervotum zu Kapitel 5.1.1.2 des Berichts der Projektgruppe &#8222;KI und Arbeit,
Bildung, Forschung&#8220; (&#8222;Bislang wenig Forschung zu den Besch&#228;ftigungseffekten von 
KI&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti sowie des sachverst&#228;ndigen
Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo teilen die grundlegende Einsch&#228;tzung der
Projektgruppe, dass der Einsatz von KI mit Umbr&#252;chen auf dem Arbeitsmarkt einhergehen wird, in deren Folge
sich T&#228;tigkeitsprofile ver&#228;ndern, Berufsfelder an Bedeutung verlieren und neue Berufsfelder entstehen. Dieser
Prozess wird Gewinnerinnen bzw. Gewinner und Verliererinnen bzw. Verlierer hervorbringen und stellt Politik,
Tarifpartner und Gewerkschaften vor gro&#223;e Herausforderungen. Ein Effekt, der seit Jahren zu beobachten ist, ist
eine st&#228;rkere Ungleichheit der Lohn- und Einkommensverteilung, mit stagnierenden Reall&#246;hnen in der Mitte des
Lohnspektrums. 
Nach Einsch&#228;tzung von Experten tr&#228;gt die Automatisierung zur steigenden Einkommensungleichheit bei.
Besch&#228;ftigte in Produktionsberufen mit mittlerem Qualifikationsniveau seien am st&#228;rksten von Automatisierung
bedroht. Zwar sind auch in dieser Gruppe keine negativen Besch&#228;ftigungseffekte festzustellen, doch gehe der
vermehrte Robotereinsatz mit Lohneinbu&#223;en einher: &#8222;Das Problem der steigenden Roboterisierung zeigte sich
also nicht in Form h&#246;herer Arbeitslosigkeit, sondern in Form geringerer L&#246;hne&#8220;.2392 Nach Einsch&#228;tzung des
&#214;konomen Jens S&#252;dekum stehen diese Lohneinbu&#223;en einer Konzentration von Verm&#246;gen, Marktmacht und
Marktanteilen in sogenannten Superstar-Firmen gegen&#252;ber. Die Gewinner der Digitalisierung und von KI-
Technologien sind vor allem die Hochqualifizierten sowie die Bezieher von Kapital- und Gewinneinkommen. 
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo schlie&#223;en sich dieser Einsch&#228;tzung an
und weisen darauf hin, dass auch der Einsatz von KI zu einem Treiber der Ungleichheit werden kann, wenn er
nicht durch tarifliche und sozialpolitische Ma&#223;nahmen flankiert wird. Daher sollte die Politik die Lohn- und 
Einkommensverteilung im Blick behalten, um einem Abw&#228;rtstrend rechtzeitig entgegenwirken zu k&#246;nnen. M&#246;g-
2388 Vgl. Smith (2018): Facial recognition: It&#8217;s time for action.
2389 Siehe auch Kapitel 3.2.3 des AG-Berichts 3 des Berichts der Projektgruppe &#8222;KI und Staat&#8220; [Handlungsempfehlungen und
Operationalisierung].
2390 Vgl. Baars (2017): Wie Amazon Mitarbeiter in Niedersachsen &#252;berwacht.
2391 Vgl. Kooroshy (2017): Amazon: Verst&#246;&#223;e gegen Mitarbeiterrechte.
2392 Vgl. S&#252;dekum (2018): Digitalisierung und die Zukunft der Arbeit: Was ist am Arbeitsmarkt passiert und wie soll die
Wirtschaftspolitik reagieren?
lichen negativen Effekten muss zudem auf betrieblicher Ebene begegnet werden, um zu erreichen, dass die
Besch&#228;ftigten gleicherma&#223;en von Produktivit&#228;tsfortschritten und neuen M&#246;glichkeiten zur Entlastung von physisch 
und psychisch belastenden T&#228;tigkeiten profitieren.
Sondervotum zu Kapitel 5.2 des Berichts der Projektgruppe &#8222;KI und Arbeit, Bildung, 
Forschung&#8220; (&#8222;KI in der Bildung&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti
sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo verstehen Bildung als sozialen Prozess.
KI in der Bildung muss daher stets dem Zweck dienen, Lernen als sozialen Prozess mit dem Ziel der
Pers&#246;nlichkeitsbildung, Selbstbestimmung und M&#252;ndigkeit zu unterst&#252;tzen. Eine KI kann unter keinen Umst&#228;nden eine
Lehrperson ersetzen. 
Kinder und Jugendliche haben ebenfalls einen Anspruch auf den Schutz ihrer Grundrechte und m&#252;ssen gerade
im Schulbetrieb besonders gesch&#252;tzt werden &#8211; da Schulpflicht besteht, haben sie keine M&#246;glichkeiten, den hier
angelegten Ma&#223;nahmen, Technologien und Leitlinien auszuweichen.
DIE LINKE. teilt den Ansatz der Projektgruppe, dass KI in der Bildung zu verschiedenen Zwecken sinnvoll und
im Sinne der Lehrenden und Lernenden eingesetzt werden kann. Wir gehen jedoch davon aus, dass hierbei nicht
zwangsl&#228;ufig personenbezogene Daten von Lernenden verarbeitet werden m&#252;ssen, sondern dass KI nur
eingesetzt werden sollte, um Lernmittel und -verfahren zu analysieren. KI-Systeme ben&#246;tigen daf&#252;r nur nicht-
personenbezogene Daten oder h&#246;chstens anonymisierte und aggregierte personenbezogene Daten. So kann KI
beispielsweise Lehrkr&#228;ften helfen, zu erkennen, bei welchen Aufgaben eine Mehrheit der Sch&#252;lerinnen und Sch&#252;ler
Schwierigkeiten hat oder welche Lehrinhalte bevorzugt von der Mehrheit einer Lerngruppe genutzt werden oder 
auch dabei unterst&#252;tzen, Stundenpl&#228;ne zu organisieren. Lernende wiederum k&#246;nnen KI-Systeme nutzen, um
gro&#223;e Textmengen zu analysieren und so ihren eigenen Lernprozess erleichtern. Die weitere Erforschung und
Entwicklung von KI-Systemen zu Lern- und Unterrichtszwecken sollten sich auf solche Anwendungen
beschr&#228;nken. 
Alle Anwendungen m&#252;ssen in ein p&#228;dagogisches Konzept eingebunden sein und bed&#252;rfen vor der Einf&#252;hrung
der Kontrolle durch eine Datenschutzbeauftragte oder einen Datenschutzbeauftragten. Daten werden
idealerweise nur lokal in der Schule oder in gepr&#252;ften und anerkannten Schul-Clouds gespeichert. Durch den Einsatz
von KI gewonnene Erkenntnisse, die auf nicht-personenbezogenen oder aggregierten Daten basieren, k&#246;nnen und
sollten als offene Daten (Open Education Data, OED) bereitgestellt werden.
Eine Entwicklung von im Bericht genannten KI-Systemen zur personenbezogenen Analyse und Bewertung von
Lernenden lehnen wir ab. KI-Anwendungen k&#246;nnen durchaus lernunterst&#252;tzend wirken, z. B. als AR-Brillen.
Dieses Lernen mit KI-Anwendungen ist zu unterst&#252;tzen. Jedoch m&#252;ssten die Elemente des Lernens, die deutlich
&#252;ber die Vermittlung von Wissensinhalten hinaus gehen, auf die Produktion von Daten ausgerichtet werden, um
alle Schritte des Lernprozesses gleicherma&#223;en in die Analyse einflie&#223;en lassen zu k&#246;nnen. Dies w&#252;rde eine
vollst&#228;ndige Quantifizierung der Lernenden nach sich ziehen und unbeobachtete Freir&#228;ume minimieren. Dies lehnen
wir ab. Denn lernende Menschen d&#252;rfen nicht als informationsverarbeitende Systeme betrachtet werden: Rein
datenbasierte Mess-Verfahren und auf Vergleichbarkeit optimierte Aufgabenstellungen w&#252;rden keine kognitiven 
Zwischenschritte und Teilkonzepte sowie alternative L&#246;sungswege erfassen k&#246;nnen. Dies entspr&#228;che einer
Abkehr von grundlegenden Didaktik-Formen. Zudem wurde die Wirksamkeit personalisierten Lernens mit digitalen 
Medien im Unterricht noch nicht ausreichend systematisch evaluiert.
Daten, die der willentlichen Steuerung der Betroffenen entzogen sind und einer hohen Wahrscheinlichkeit der
Fehlinterpretation unterliegen, wie es beispielsweise bei Sprach-, Stimm- und Mimikanalysen m&#246;glich ist, d&#252;rfen
nicht erhoben, verarbeitet oder gespeichert werden. Es darf nicht zul&#228;ssig sein, dass Emotionen und
Pers&#246;nlichkeiten auf diese Weise zu Zwecken der Vereinfachung reduziert werden, da Daten und Modelle nie neutral sind.
Die Verfahren der Systeme, diese Daten auszuwerten, und die dahinter liegenden Wahrnehmungs- und
Realit&#228;tsmodellierung bleiben f&#252;r Lehrkr&#228;fte intransparent.2393 
Der Ermessensspielraum der Lehrkr&#228;fte kann sich dadurch eher reduzieren als erweitern &#8211; wie auch andere in
Arbeitsverh&#228;ltnissen abh&#228;ngige Nutzer von KI-Systemen wird es auch f&#252;r Lehrkr&#228;fte enorm schwierig sein, sich
gegen einen systembasierten Vorschlag zu stellen. Datendashboards, die Daten zusammenfassen und
visualisieren (z. B. mittels Einsatz von Ampelsystemen) t&#228;uschen also nur eine entlastende Wirkung vor. 
2393 Vgl. Hartong (2019): Learning Analytics und Big Data in der Bildung.
Auch KI-basierte Prognosesysteme, die Lernerfolge von Studierenden voraussagen, lehnen wir ab. 
Sondervotum zu Kapitel 5.5 des Berichts der Projektgruppe &#8222;KI und Arbeit, Bildung, 
Forschung&#8220; (&#8222;SWOT-Analyse&#8220;) der Abgeordneten Dr. Petra Sitte und Jessica Tatti
sowie des sachverst&#228;ndigen Mitglieds Dr. Florian Butollo
Die Fraktion DIE LINKE. und der Sachverst&#228;ndige Dr. Florian Butollo verweisen darauf, dass der Begriff des
&#8222;Social Scoring&#8220; in den Kapiteln 3.1.2 [Thematischer Schwerpunkt] und 3.1.3 [Handlungsempfehlungen und
Perspektiven] des AG-Berichts 3 im Bericht der Projektgruppe &#8222;KI und Staat&#8220; in Bezug auf staatliche
&#220;berwachung erl&#228;utert wird und nicht in Bezug auf Softwaresysteme in Betrieben. Der Hinweis, dass &#8222;Social Scoring&#8220;
den rechtsstaatlichen Grunds&#228;tzen in Deutschland widerspricht und deshalb in Deutschland nicht eingef&#252;hrt
werden darf, ist zwar richtig, aber an dieser Stelle irref&#252;hrend.
Softwaresysteme zur &#220;berwachung und Evaluation der Leistung von Besch&#228;ftigten werden hierzulande bereits
in privaten Unternehmen eingesetzt.2394 Ein Beispiel hierf&#252;r ist das Personalsystem &#8222;Zonar&#8220; des Berliner Online-
Versandh&#228;ndlers Zalando. Die umstrittene Software dient dazu, Leistung und soziales Verhalten der
Besch&#228;ftigten zu beurteilen und bewerten. 
Die Berliner Beauftragte f&#252;r Datenschutz und Informationsfreiheit pr&#252;ft derzeit, ob &#8222;Zonar&#8220; mit den bestehenden
Datenschutzregelungen vereinbar ist oder verboten werden muss.2395 Sie geht auch davon aus, dass sogenannte
360-Grad-Feedback-Verfahren zur Leistungsbeurteilung von Mitarbeitern, wie sie auch von Zalando eingesetzt
werden, k&#252;nftig verst&#228;rkt in Unternehmen zum Einsatz kommen werden. Derartige Systeme seien zwar nicht per
se unzul&#228;ssig; es m&#252;sse jedoch gew&#228;hrleistet sein, dass Eingriffe in die Pers&#246;nlichkeitsrechte der Betroffenen
verh&#228;ltnism&#228;&#223;ig blieben und kein dauerhafter &#220;berwachungsdruck herrsche.2396 
Die Gewerkschaft Verdi kritisiert Zonar als &#8222;arbeitnehmerfeindlich&#8220; und datenschutzrechtlich problematisch. 
Die permanente &#220;berwachung durch die Software belaste das Betriebsklima und f&#252;hre dazu, dass L&#246;hne
willk&#252;rlich festgelegt w&#252;rden.2397 Eine laufende &#220;berwachung und Verdatung aller Handlungen wirkt sich
nachweislich auf das Verhalten und das Wohlbefinden von Besch&#228;ftigten aus. Eine Studie2398 zu &#8222;digitalem Stress&#8220; aus 
dem Jahr 2018 zeigt, dass Erwerbst&#228;tige entscheidungsunterst&#252;tzende Software mit am h&#228;ufigsten mit negativen 
Auswirkungen auf den Arbeitsalltag verbinden. 
Sondervotum zu Kapitel C. VI. &#8222;K&#252;nstliche Intelligenz und Mobilit&#228;t (Projektgruppe 5)&#8220;
der Abgeordneten Dr. Petra Sitte und Jessica Tatti
Die Fraktion DIE LINKE. unterst&#252;tzt den vorliegenden Bericht der Projektgruppe &#8216;K&#252;nstliche Intelligenz und
Mobilit&#228;t&#8217; in gro&#223;en Teilen. DIE LINKE. erkennt an und teilt damit die Auffassung der Projektgruppe, dass im
Rahmen eines Projektgruppenberichts zum Thema K&#252;nstliche Intelligenz und Mobilit&#228;t die vielf&#228;ltigen
Problemstellungen der aktuellen Verkehrspolitik nicht vollst&#228;ndig er&#246;rtert oder befriedigend gel&#246;st werden k&#246;nnen. Auch
sollte KI nicht als alleinige L&#246;sung f&#252;r die zahlreichen Probleme im Verkehrsbereich propagiert werden.
K&#252;nstliche Intelligenz ersetzt weder eine politische Richtungsvorgabe noch einen regulatorischen Rahmen, die beide
f&#252;r eine soziale und nachhaltige Verkehrswende notwendig sind.
Allerdings bedauert die Fraktion DIE LINKE., dass im Laufe der gesamten Projektgruppenarbeit innerhalb der
Enquete-Kommission K&#252;nstliche Intelligenz verschiedene Themenbereiche keinen Raum gefunden haben. So
sollten Fragen zu Energie und &#214;kologie in Bezug auf K&#252;nstliche Intelligenz urspr&#252;nglich im Bericht der
Projektgruppe &#8222;KI und Wirtschaft&#8220; bearbeitet werden. Diese Themen hat man allerdings mit Verweis auf die
Projektgruppe &#8222;KI und Mobilit&#228;t&#8220; dort nicht behandelt, da urspr&#252;nglich Umwelt- und Energiethemen der Projektgruppe
&#8222;KI und Mobilit&#228;t&#8220; zugeordnet worden waren. Innerhalb der Projektgruppe &#8222;KI und Mobilit&#228;t&#8220; entschied sich
eine Mehrheit gegen die Stimmen der Fraktion DIE LINKE. leider daf&#252;r, sich ausschlie&#223;lich mit dem Thema
Mobilit&#228;t zu befassen. Dadurch fielen alle Themen aus den Bereichen Umwelt und Energie g&#228;nzlich durch das
Raster der Enquete Kommission. In einer Zeit, die nicht nur die Digitalisierung als gro&#223;e, weltweite und gesell-
2394 Vgl. Kaleta (2019): Experte &#252;ber Zalandos Evaluationssystem Zonar: &#8222;Unternehmen nutzen diese Tools immer st&#228;rker&#8220;.
2395 Vgl. Hagel&#252;ken und Kl&#228;sgen (2019): Datensch&#252;tzer: Zalando soll Kontrollsoftware aussetzen; Hagel&#252;ken und Kl&#228;sgen (2019): So
&#252;berwacht Zalando seine Mitarbeiter sowie Bath (2020): Beh&#246;rde nennt Zalando Kriterien f&#252;r Feedback-App.
2396 Vgl. Bath (2020): Beh&#246;rde nennt Zalando Kriterien f&#252;r Feedback-App.
2397 Vgl. ver.di (2019): ver.di kritisiert System permanenter digitaler Leistungskontrollen und Ratings bei Zalando.
2398 Vgl. Gimpel et al. (2018): Digitaler Stress in Deutschland.
        
 
 
 
  
  
     
 
  
  
  
    
  
   
     
 
 
      
 
  
   
   
  
 
   
  
    
 
  
   
      
    
      
    
   
    
 
          
 
    
    
  
 
 
   
 
  
                                               
       
     
6
schaftsver&#228;ndernde Herausforderung sieht, sondern insbesondere auch den Klimawandel, findet die
Linksfraktion diese Leerstelle der Enquete unverzeihlich und schwer vermittelbar. So haben wir keine Landwirtschaft 4.0 
debattiert und weder &#252;ber Potentiale von KI, den Ressourceneinsatz zu senken oder das Tierwohl zu verbessern, 
noch &#252;ber die Problematiken, die sich rund um die Frage der damit verbundenen Datenhaltung,
Monopolisierungstendenzen und neuen Abh&#228;ngigkeiten ergeben, diskutiert.
Wir haben uns nicht, wie es notwendig gewesen w&#228;re, mit Smart-Meter-Anwendungen oder den
Ressourcenverbrauch von KI-Anwendungen oder die Chancen von KI, den Energieverbrauch in der IT oder durch andere
Gro&#223;verbraucher zu senken, besch&#228;ftigt. Wir haben nicht dar&#252;ber gesprochen, welche M&#246;glichkeiten KI im Bereich 
der Klimamodellierung und der Beurteilung von Handlungsoptionen zur Begrenzung der Erderhitzung bieten
k&#246;nnte. Das bedauern wir au&#223;erordentlich, denn sowohl Chancen als auch Risiken, die im Zusammenhang von
KI und Umwelt- sowie Energiethemen stehen, w&#228;ren dringend gesellschaftlich zu diskutieren.2399 
Dar&#252;ber hinaus bem&#228;ngelt die Fraktion DIE LINKE., dass sich die Themenfelder Verkehrsplanung, -prognosen
und -steuerung kaum und nur sehr unkritisch im Projektgruppenbericht wiederfinden. Gro&#223;e
Mobilit&#228;tsplattformanbieter k&#246;nnen bereits heute dank K&#252;nstlicher Intelligenz genauere Verkehrsprognosen erstellen, die ihnen
aufgrund ihrer Flottenst&#228;rke einen zielgerichteten Eingriff in die Verkehrsleitung erlauben k&#246;nnen. Solchen
Eingriffen muss regulatorisch entgegengewirkt werden. Eine solche Forderung haben wir jedoch nicht durchsetzen
k&#246;nnen.
Um Monopolbildungen im Mobilit&#228;tsbereich generell zu verhindern, will die Fraktion DIE LINKE. deutlich 
strengere Vorgaben, als dies der Projektgruppenbericht fordert.2400 Die Marktmacht von Plattformen aller Art 
besteht nicht nur in ihrem zur Verf&#252;gung stehenden Kapital und dem Stab an Mitarbeiterinnen und Mitarbeitern,
sondern vor allem in den Datenmengen des Unternehmens. Neben Verhaltensregeln f&#252;r marktbeherrschende
Plattformen (die ggf. auch noch anzupassen sind) m&#252;ssen daher offene Programmierschnittstellen (API) und
Open-Data-Konzeptionen f&#252;r gro&#223;e Plattformanbieter verpflichtend werden &#8211; idealerweise auf europ&#228;ischer
Ebene, wo auch sinnvolle Standards gemeinsam entwickelt und anschlie&#223;end als Vorgabe etabliert werden
sollten. 
Die Vergesellschaftung von Daten sollte f&#252;r Ausnahmef&#228;lle &#8211; etwa bei besonderer Marktdominanz einzelner
datengetriebener Unternehmen rechtlich erm&#246;glicht werden und dann Anwendung finden, wenn das erforderlich
ist, um einen fairen Wettbewerb wieder herzustellen, in dem aber auch gemeinwohlorientierte Alternativen
entstehen k&#246;nnen. Dazu k&#246;nnen sich gerade nicht personenbezogene Mobilit&#228;tsdaten besonders gut eignen, z. B. 
Stauinformationen in der Hand von Konzernen wie Google.
Sondervoten der Fraktion B&#220;NDNIS 90/DIE GR&#220;NEN
Sondervotum zu Kapitel 5.3 des Berichtsteils &#8222;Allgemeiner Teil: Auftrag und 
Arbeitsweise&#8220; (&#8222;Einbeziehung der &#214;ffentlichkeit und Pressearbeit&#8220;) der
Abgeordneten Dr. Anna Christmann, Dieter Janecek, Dr. Petra Sitte und Jessica Tatti
sowie der sachverst&#228;ndigen Mitglieder Prof. Dr. Hannah Bast, Dr. Florian Butollo
und Dr. Stefan Heumann
Ein Grund f&#252;r die Einsetzung der Enquete-Kommission zu K&#252;nstlicher Intelligenz war die grundlegende
Bedeutung des Themas f&#252;r die gesamte Gesellschaft. Wir alle sind t&#228;glich &#8211; wissentlich oder unwissentlich &#8211; mit der
Technologie konfrontiert. Aus diesem Grund hat aus unserer Sicht auch die &#246;ffentliche Debatte der
Auswirkungen von KI auf die unterschiedlichen Lebensbereiche unserer Gesellschaft eine hohe Bedeutung. Es gab in der
Kommission gro&#223;e Einigkeit, dass es nicht sinnvoll ist, Terminator-Horrorszenarien einerseits und &#252;berzogene
Heilsversprechen andererseits plakativ gegeneinanderzustellen. Ziel der Kommission war es viel mehr, diese
holzschnittartigen Vorstellungen zu &#252;berwinden und zu einer differenzierten Bewertung der Technologie, ihrer
Auswirkungen und den daraus folgenden Handlungsauftr&#228;gen an Politik, Wirtschaft, Wissenschaft und
Gesellschaft zu gelangen.
Um dieses Ziel zu erreichen, ist die Enquete-Kommission aus unserer Sicht bei ihrer Arbeitsweise allerdings
deutlich hinter ihren M&#246;glichkeiten zur&#252;ckgeblieben. Wir halten nicht nur den Bericht der Enquete-Kommission
mitsamt seinen Handlungsempfehlungen f&#252;r relevant, um zu einer m&#252;ndigen und aufgekl&#228;rten Gesellschaft im
Umgang mit KI zu gelangen. Wir h&#228;tten die zwei Jahre, in denen die Enquete-Kommission gearbeitet hat, aktiv
2399 Vgl. Deutschlandfunk.de: K&#252;nstliche Intelligenz gegen den Klimawandel.
2400 Siehe auch Kapitel C. VI. des Berichts der Projektgruppe &#8222;KI und Mobilit&#228;t&#8221; [K&#252;nstliche Intelligenz und Mobilit&#228;t (Projektgruppe 5)].
f&#252;r eine &#246;ffentliche Debatte nutzen m&#252;ssen. Stattdessen hat sich die Enquete sehr stark auf die interne
Gremienarbeit fokussiert. Es wurden zwar G&#228;ste geladen und die Vortr&#228;ge im Plenum der Gesamtenquete &#246;ffentlich per
Video zur Verf&#252;gung gestellt. Es h&#228;tte aber dar&#252;ber hinaus deutlich mehr bedurft, um die Chancen, die so eine
besondere parlamentarische Kommission f&#252;r die gesellschaftliche Positionierung zu einem Thema bietet,
tats&#228;chlich zu nutzen.
&#214;ffentlichkeit der Sitzungen
Wir begr&#252;&#223;en es zwar, dass alle Vortr&#228;ge von internen und externen Sachverst&#228;ndigen im Rahmen der gro&#223;en
Enquete-Kommissionssitzungen online abrufbar sind, h&#228;tten uns aber die vollst&#228;ndige &#214;ffentlichkeit der
Sitzungen gew&#252;nscht. Gerade Nachfragen und Diskussion mit und unter den Expertinnen und Experten k&#246;nnen zu
einem h&#246;heren Verst&#228;ndnis der Technologie f&#252;hren und helfen, die Konfliktlinien beim Umgang mit einer neuen 
Technologie zu erkennen. Nicht &#246;ffentlich waren die Expertinnen- und Expertenanh&#246;rungen, die in den
thematisch aufgegliederten Projektgruppen stattgefunden haben. 
Ver&#246;ffentlichung der Zwischenberichte
KI ist eine Technologie, die sich sehr schnell entwickelt. Daher ist die Sinnhaftigkeit der
Handlungsempfehlungen in vielen Punkten eng an den Zeitpunkt ihrer Formulierung gebunden. Bereits im Herbst 2019 lagen die
Projektgruppenberichte der ersten Arbeitsgruppenphase vor. Wir haben uns vehement daf&#252;r eingesetzt, dass diese
umgehend als Arbeitsstand ver&#246;ffentlicht werden und nicht erst alle zusammen mit dem Endbericht. Dies h&#228;tte
eine umgehende Debatte &#252;ber die Handlungsempfehlungen erm&#246;glicht und auch Feedback an die Kommission 
zur&#252;ckgespiegelt. Es war zwar begr&#252;&#223;enswert, dass wenigstens eine Zusammenfassung der
Projektgruppenberichte ver&#246;ffentlicht wurde. Dies war aus unserer Sicht jedoch nicht ausreichend.
Echte B&#252;rgerbeteiligung
Die Enquete-Kommission hat sich leider f&#252;r eine sehr minimale Form der B&#252;rgerbeteiligung entschieden. Es hat
lediglich einige Wochen im Fr&#252;hjahr 2020 eine Online-Beteiligung zu vorgegebenen Fragestellungen gegeben.
Urspr&#252;nglich war noch die Einbeziehung von Fokusgruppen geplant, was leider wegen Corona ausfallen musste.
Die einzige Gelegenheit, bei der die Ergebnisse der Online-Beteiligung minimal aufgegriffen wurden, war ein 
&#246;ffentliches Symposium im September 2020. Ansonsten sind die Ergebnisse der Online-Beteiligung &#8211; auch weil
diese zu einem so sp&#228;ten Zeitpunkt durchgef&#252;hrt wurden &#8211; nicht in den Enquete-Bericht eingeflossen. Aus
unserer Sicht h&#228;tte die Enquete-Kommission von Beginn an mit einem umfangreichen Beteiligungskonzept arbeiten
m&#252;ssen, das weiter &#252;ber diese minimalen Beteiligungsformate hinausgegangen w&#228;re.
Wir h&#228;tten uns zuf&#228;llig zusammengesetzte Diskussionen mit B&#252;rgerinnen und B&#252;rgern gew&#252;nscht, die bereits
fr&#252;h einen detaillierten Einblick in die Kenntnisse und die Haltung zu KI in der Gesellschaft geboten h&#228;tten.
Bestehende Umfragen verm&#246;gen nur sehr begrenzt, aussagekr&#228;ftige Positionen zu KI abzufragen. Auch h&#228;tte die
Enquete dezentral bei &#246;ffentlichen Ereignissen dabei sein k&#246;nnen, um in der Breite &#252;ber ihre Arbeit zu
informieren und mit verschiedenen Gruppen in direkten Austausch zu kommen. Angedacht waren zwischendurch etwa
der Evangelische Kirchentag, Buchmessen oder vergleichbare Gelegenheiten, die einen Austausch mit der
&#214;ffentlichkeit erm&#246;glichen. 
Die Online-Beteiligung h&#228;tte sehr viel fr&#252;her und umfassender stattfinden m&#252;ssen. Aufgrund des sp&#228;ten
Zeitpunkts waren die M&#246;glichkeiten sehr limitiert, und die Ergebnisse sind nicht relevant in den Abschlussbericht
der Kommission eingeflossen. So steht der Beteiligungsbericht separat zur Arbeit der Kommission, ohne dass
die Ergebnisse in der Kommission &#252;berhaupt diskutiert wurden (abgesehen von den wenigen Ausschnitten beim
Symposium). 
Zuk&#252;nftige Enquete-Kommissionen sollten aus unserer Sicht immer von Beginn an mit einem umfassenden
Beteiligungskonzept arbeiten, f&#252;r das auch finanzielle Mittel bereitstehen sollten. Dies kann je nach Thema
unterschiedlich ausfallen, sollte aber grunds&#228;tzlich Standard sein.
Sondervotum zu Kapitel 9 des Mantelberichts (&#8222;KI und Forschung&#8220;) die Abgeordneten
Dr. Anna Christmann und der Abgeordnete Dieter Janecek sowie der
sachverst&#228;ndigen Mitglieder Prof. Dr. Hannah Bast und Dr. Stefan Heumann
Die Grundausrichtung des Kapitels 9 des Mantelberichts [KI und Forschung] und die genannten strategischen
Ziele werden von uns unterst&#252;tzt. In Anbetracht der gravierenden Bedeutung einer exzellenten Forschung f&#252;r die
Gestaltung einer so wichtigen Zukunftstechnologie hat das Handlungsfeld in der Gesamtschau allerdings zu
wenig Raum bekommen.
Gerade weil wir eine wertegeleitete Technologieentwicklung zum Wohl von Mensch und Umwelt anstreben, ist
es f&#252;r uns zentral, dass wir dazu auch in der Lage sind. KI ver&#228;ndert die Welt gravierend und wir d&#252;rfen nicht
am Rand stehen und zuschauen, wie andere die Richtung der Ver&#228;nderung vorgeben. Wir m&#252;ssen mit am
Steuerrad dabei sein. Eine starke Forschungslandschaft ist Voraussetzung daf&#252;r, dass wir KI-Entwicklung und -
Einsatz aktiv gestalten k&#246;nnen &#8211; das geht aus dem vorliegenden Abschnitt zu Forschung nicht ausreichend hervor. 
Auf folgende Punkte m&#246;chten wir daher an dieser Stelle hinweisen:
&#8226; Um der Bedeutung der Forschung f&#252;r die Gestaltung von KI gerecht zu werden, w&#228;re aus unserer Sicht eine
eigenst&#228;ndige Projektgruppe zum Thema Forschung angemessen gewesen. Der Teil Forschung ist nun in
einer gesonderten Task Force erarbeitet worden. Diese hatte &#8211; verglichen mit den ordentlichen
Projektgruppen &#8211; weder gleich viel Zeit, noch die die M&#246;glichkeit zur Vorladung von externen G&#228;sten.  Zudem ist
dadurch auch ein vergleichsweise kurzer Abschnitt zu einem so bedeutenden Thema entstanden. Wir
bedauern, dass unserem Vorschlag einer eigenst&#228;ndigen Projektgruppe zu Beginn der Enquete-Kommission
nicht gefolgt wurde. 
&#8226; Eine detaillierte St&#228;rken- und Schw&#228;chen-Analyse unseres Forschungsstandorts w&#228;re eine wichtige
Voraussetzung f&#252;r gezielte F&#246;rderma&#223;nahmen und einen fokussierten Aufbau von Strukturen. Im vorliegenden
Bericht wird eine sehr grobe Einordnung vorgenommen. Es werden viele Standorte erw&#228;hnt und
europ&#228;ische Publikationen als Gesamtheit mit denen in den USA und China verglichen. Ein konkreter Einblick,
welche Standorte welche besondere Expertise und St&#228;rke mitbringen, erfolgt nicht. Dieser w&#252;rde aber eine
sehr viel gezieltere Empfehlung erm&#246;glichen, wie die Standorte in Zukunft weiterentwickelt werden
k&#246;nnen. Eine fehlende strategische Priorit&#228;tensetzung ist aus unserer Sicht problematisch f&#252;r den Aufbau einer
starken KI-Forschungslandschaft.
&#8226; Die M&#246;glichkeiten, Rahmenbedingungen f&#252;r KI-Forschung in Deutschland zu verbessern, werden zu
oberfl&#228;chlich beleuchtet. Es ist nicht gelungen, internationale Vorbilder oder Beispiele aus anderen
Forschungsbereichen zu er&#246;rtern und insbesondere nicht, wie eine Umgebung geschaffen werden kann, die Talente
besonders anzieht und einen fruchtbaren Boden f&#252;r wachsende Expertise auf h&#246;chstem Niveau bietet.
Gehaltsstrukturen, flexiblere Governance von Forschungsinstitutionen, M&#246;glichkeiten der Kooperation mit der
Wirtschaft und notwendige Infrastruktur werden nicht im Detail beschrieben. Dabei ist es eine wichtige
Debatte, wie sich Institutionen in dem zum Teil engen Rahmen unseres Hochschul- und
Wissenschaftssystems erfolgreich zu einem KI-Leuchtturm entwickeln k&#246;nnen. 
&#8226; Europ&#228;ische und internationale Kooperationen im Bereich der KI-Forschung sind entscheidend, denn
Forschung lebt immer von dem Austausch von Expertise. Es ist gut, dass europ&#228;ische Forschungsnetzwerke im
Bericht der Enquete nun auch genannt werden. Es w&#228;re zielf&#252;hrend gewesen, eine globale Landkarte zu
erstellen, welche die Partnerschaften, die Deutschland anstreben sollte und wie diese schnell angegangen
werden k&#246;nnen, darstellt. Gerade f&#252;r Europa w&#228;re aus unserer Sicht eine KI-Landkarte &#252;berf&#228;llig, um klarer
zu sehen, welche Kooperationen einen echten Mehrwert generieren w&#252;rden. Aber auch die aktive Suche
von Zusammenarbeit mit weiteren L&#228;ndern, die unsere Werte teilen, um gemeinsam eine zivile, nachhaltige
und soziale KI-Entwicklung und -Anwendung zu sichern, sollte ein zentrales Vorhaben sein. 
&#8226; Die Verzahnung der Forschung mit der gesellschaftlichen Debatte wird angerissen, das unterst&#252;tzen wir.
Interessent w&#228;re eine Konkretisierung, wie dies erfolgen kann. M&#246;glichkeiten sind gesellschaftliche Beir&#228;te 
oder Reallabore, welche Forschung und Gesellschaft strukturiert in Austausch und in Zusammenarbeit
bringen. Diese sind bisher Einzelf&#228;lle und noch nicht in der Fl&#228;che verankert, was aus unserer Sicht ein wichtiges
forschungspolitisches Ziel ist.
Sondervotum zu Kapitel C. VII. &#8222;K&#252;nstliche Intelligenz und Medien (Projektgruppe 6)&#8220;
der Abgeordneten Tabea R&#246;&#223;ner, Dr. Petra Sitte und Jessica Tatti und der
sachverst&#228;ndigen Mitglieder Dr. Florian Butollo und Dr. Stefan Heumann
Wie im Mantelbericht dargelegt, ber&#252;hrt KI so gut wie alle Lebensbereiche der B&#252;rgerinnen und B&#252;rger. Neben
pers&#246;nlichen Auswirkungen, etwa f&#252;r den Berufsalltag oder die eigene Mobilit&#228;t, ergeben sich auch
gesellschaftliche Effekte, insbesondere mit Blick auf demokratische Prozesse und die politische Willensbildung. Dieser
Aspekt kommt aus unserer Sicht im Enquetebericht, gerade im Bericht der Projektgruppe 6 &#8222;KI und Medien (Social
Media, Meinungsbildung, Demokratie)&#8220;, zu kurz, weshalb wir einige erg&#228;nzende und klarstellende Punkte f&#252;r
n&#246;tig halten.
KI spielt bei der politischen Meinungsbildung eine immer gr&#246;&#223;ere Rolle. Das liegt vor allem an der wachsenden
Bedeutung sozialer Medien und Internetplattformen im allt&#228;glichen Nachrichten- und Medienkonsum. Daraus 
ergeben sich f&#252;r unsere Demokratie gewaltige Herausforderungen.2401 Der Projektbericht schweift allerdings von
diesem Kernproblem immer wieder ab und setzt sich mit der Rolle von KI in Medien generell auseinander. Es
ist unbestritten, dass KI auch bei Games und Unterhaltungsmedien sowie im redaktionellen Produktionsalltag
relevant ist. Allerdings geht durch diese breite Befassung mit KI und Medien an vielen Stellen die Fokussierung
auf die politische Meinungsbildung und die damit verbundenen Auswirkungen auf unsere Demokratie verloren,
die laut Untertitel der Projektgruppe (&#8222;Social Media, Meinungsbildung, Demokratie&#8220;) aber im Fokus stehen
sollten.
Anstatt dieser breiten Befassung mit KI und Medien h&#228;tte insbesondere die Rolle von KI bei der Distribution von
politisch relevanten Inhalten und Nachrichten sehr viel st&#228;rker in den Blick genommen und ausf&#252;hrlicher
untersucht werden m&#252;ssen. Hierbei ist es ratsam, der dieser Distribution zugrundeliegende Datenerfassung und -
verarbeitung mehr Aufmerksamkeit zuzuwenden, denn das umfassende Tracking der Nutzenden und das Erfassen
und Aggregieren pers&#246;nlicher Verhaltensdaten haben &#252;berhaupt erst die Voraussetzungen f&#252;r die Nutzung von
KI im Medienbereich geschaffen. Vor allem f&#252;r gro&#223;e Plattform-Unternehmen sind dadurch spannende neue
Gesch&#228;ftsmodelle und die Optimierung einer Aufmerksamkeits&#246;konomie m&#246;glich geworden. Die
gesellschaftspolitischen Kollateralsch&#228;den dieser KI-getriebenen sozialen Netzwerke und Medienplattformen stehen im
Mittelpunkt einer weit gefassten und kontroversen Debatte, von der fast t&#228;glich in den Nachrichten zu lesen und zu
h&#246;ren ist. Im Bericht fehlt allerdings eine entsprechend starke Gewichtung dieses Themenfelds &#8211; gerade
bez&#252;glich einer tieferen Auseinandersetzung mit den technischen M&#246;glichkeiten und &#246;konomischen Logiken, die den
Einsatz von KI in sozialen Medien und Internetplattformen gepr&#228;gt haben. Aufgrund des detaillierten und
umfassenden Trackings der Nutzerinnen und Nutzer ist der Datenschutz ein zentraler Hebel zur Regulierung des
Einsatzes von KI im Kontext politischer Meinungsbildung. Diese wichtige Perspektive fehlt im
Projektgruppenbericht allerdings. Auch die bislang nicht sehr effektiven Versuche, den sich daraus ergebenden Problemen, vor
allem bez&#252;glich der Verbreitung von &#8222;Hate Speech&#8220; und Desinformation zu begegnen (wiederum mit KI-
getriebenen L&#246;sungen), sind im Bericht unterbelichtet.
Datenzug&#228;nge und Forschung
Kapitel 5.4 des Berichts der Projektgruppe &#8222;KI und Medien&#8220; [Datenzugang als Voraussetzung f&#252;r Datenanalyse]
Verbesserter Datenzugang bei gro&#223;en Plattformen ist, wie im Projektgruppenbericht dargelegt, von essenzieller
Bedeutung. Allerdings sollten grunds&#228;tzlich die M&#246;glichkeiten f&#252;r Forschung, Medien und Zivilgesellschaft
verbessert werden, potenzielle Auswirkungen von KI-Systemen auf die Meinungsbildung zu untersuchen. Dazu
geh&#246;ren als Ausgangspunkt offene Datenschnittstellen, doch dies allein ist nicht ausreichend: Es muss auch
Menschen und Organisationen geben, die mit den dann verf&#252;gbaren riesigen Datensets arbeiten k&#246;nnen. Dies erfordert
Fachleute, Ressourcen wie etwa Rechenkapazit&#228;ten sowie unabh&#228;ngige Institutionen zur Verbreitung der
Untersuchungsergebnisse. Daher sollte der Gesetzgeber in Deutschland und in der EU n&#228;her ausdifferenzieren, was
genau mit &#8222;mehr Datenzugang&#8220; gemeint ist und wer letztendlich mit den Daten arbeiten kann und soll.
Da dies unweigerlich Fragen zur Finanzierung aufwirft, ist zu &#252;berlegen, ob ein unabh&#228;ngiger Fonds aufgesetzt
werden k&#246;nnte, der Forschende, Fachleute aus der Zivilgesellschaft sowie Journalistinnen und Journalisten dabei
unterst&#252;tzt, Auswirkungen von KI auf demokratische Willensbildungs- und Wahlprozesse zu untersuchen. Ein
solch weit gefasstes Verst&#228;ndnis des Fonds w&#252;rde etwa Forschung zu Desinformation, Diskriminierung,
Wahlbeeinflussung, Plattformdesign und digitaler Nachrichtenkompetenz in sozialen Medien und anderen KI-
gest&#252;tzten Informations- und Nachrichtenr&#228;umen erm&#246;glichen. Der Fonds k&#246;nnte mit einem Bruchteil der Einnahmen
gro&#223;er Plattformen und/oder staatlichen Zusch&#252;ssen finanziert werden und w&#252;rde so die Erforschung der
genannten Ph&#228;nome nicht allein Privatunternehmen &#252;berlassen, sondern Untersuchungen im &#246;ffentlichen Interesse
erm&#246;glichen.2402 Er k&#246;nnte zudem gleichzeitig zu einem diversifizierten, gest&#228;rkten Medienumfeld beitragen.
2401 Vgl. Jaursch (2020): Regeln f&#252;r faire digitale Wahlk&#228;mpfe: Welche Risiken mit politischer Onlinewerbung verbunden sind und
welche Reformen in Deutschland n&#246;tig sind.
2402 Vgl. Bell (2015): Media should use tech for &#8216;good&#8217; journalism; Zuckerman (2020): The Case for Digital Public Infrastructure;
Macpherson (2020): The Pandemic Proves We Need A &#8218;Superfund&#8216; to Clean Up Misinformation on the Internet.
Verbesserte Aufsichtsmechanismen f&#252;r KI-getriebene Medienintermedi&#228;re auf deutscher und
europ&#228;ischer Ebene 
Kapitel 7.1 [Internationale Regulierung] und 7.2 [Nationale Regulierung] des Berichts der Projektgruppe &#8222;KI 
und Medien&#8220;
Vor dem Hintergrund der eingangs geschilderten Risiken betonen wir die dringende Notwendigkeit f&#252;r einen
regulatorischen Rahmen f&#252;r soziale Medien und andere Anbieter KI-getriebener Informations- und
Medienr&#228;ume. Dieser sollte sich nicht allein auf die Moderation von Inhalten und die L&#246;schung strafrechtlich relevanter
Inhalte konzentrieren, wie es bislang insbesondere auf deutscher Ebene (etwa im Netzwerkdurchsetzungsgesetz
[NetzDG]), aber auch auf europ&#228;ischer Ebene (etwa zu Urheberrecht und Gesetzesvorhaben zu terroristischen
Inhalten), meist der Fall war. W&#228;hrend rechtswidrige Inhalte, egal ob online oder offline, beseitigt werden
m&#252;ssen, wird der Fokus auf das Strafrecht den Herausforderungen, die KI-gest&#252;tzte Plattformen offenbaren, nicht
gerecht, denn es gibt auch Inhalte, die nicht eindeutig als rechtswidrig einzustufen sind, weil sie unter den Schutz
der Meinungsfreiheit fallen. Der Projektgruppenbericht betont in diesem Zusammenhang richtigerweise die
Ablehnung gegen&#252;ber Uploadfiltern und die Gefahr von &#8222;Overblocking&#8220;.
Alternative Regulierungsvorschl&#228;ge bleiben im Bericht allerdings vage. F&#252;r alternative regulatorische Ans&#228;tze
ist es erforderlich, &#220;berlegungen aus diversen Politik- und Rechtsbereichen, insbesondere Datenschutz,
Wettbewerb und Medienaufsicht, zu verkn&#252;pfen.2403 Dies wird im Bericht nicht detailliert genug ausgef&#252;hrt.
Datenschutzrechtliche Vorgaben m&#252;ssen teils besser durchgesetzt werden (beispielsweise sind viele
Datenschutzbeh&#246;rden in Deutschland und Europa unterfinanziert, was eine konsequente Umsetzung der Datenschutz-
Grundverordnung [DSGVO] erschwert) und teils ausdifferenziert werden (so etwa im Bereich Profiling/Tracking, zu
dem weiterhin passende Regeln fehlen). Zu Wettbewerbsfragen gilt es etwa, zu &#252;berlegen, inwiefern klare,
konsistente Regeln f&#252;r Interoperabilit&#228;t dabei helfen k&#246;nnten, der monopolartigen Konzentration digitaler
Informationsr&#228;ume auf einige wenige Anbieter entgegenzutreten.
Zudem sollten insbesondere die Vorz&#252;ge eines EU-weiten Regulierungsansatzes st&#228;rker in den Vordergrund
r&#252;cken. Eine klare Handlungsempfehlung ist es, dass der deutsche Gesetzgeber sich auf europ&#228;ischer Ebene f&#252;r ein
differenziertes, progressives und unabh&#228;ngiges Aufsichtsregime f&#252;r KI-getriebene Plattformen wie soziale
Netzwerke, Videoportale und Suchmaschinen einsetzen sollte. Das Vorhaben der Europ&#228;ischen Kommission f&#252;r ein
Digitale-Dienste-Gesetz (Digital Services Act, DSA), das w&#228;hrend der Arbeit der Enquete-Kommission
angesto&#223;en wurde, sollte Deutschland intensiv begleiten und gestalten, um sicherzustellen, dass die dargelegten Risiken
f&#252;r demokratische Prozesse adressiert werden. Deutschland sollte sich daf&#252;r einsetzen, dass der DSA umfassende
Transparenzregeln f&#252;r Algorithmic-Decision-Making-Systeme (ADM-Systeme) und (politisches)
Microtargeting enth&#228;lt und klare Rechenschaftspflichten vorgibt, etwa in Form von Transparenzberichten,
Zustellungsbevollm&#228;chtigten in allen L&#228;ndern und einer gest&#228;rkten Aufsicht. Insbesondere zu letzterem Punkt sollte
Deutschland Erfahrungen mit dem NetzDG, dem Medienstaatsvertag (MStV) und der DSGVO-Umsetzung einbringen.
Diese Gesetze verfolgen unterschiedliche Ans&#228;tze, welche Art von Beh&#246;rde auf welcher politischen Ebene mit
welchen Befugnissen soziale Netzwerke und Suchmaschinen beaufsichtigt. Eine bessere Koordinierung und
Ressourcenausstattung sowie eine klare Kompetenzabgrenzung sollte f&#252;r den DSA das Minimalziel f&#252;r m&#246;gliche
Aufsichtsformate sein.
Kapitel 7.3.2 des Berichts der Projektgruppe &#8222;KI und Meiden [Technische M&#246;glichkeiten der Governance von
ADM-Systemen]
Die Handlungsempfehlungen in diesem Bereich sind zu unterst&#252;tzen, lassen aber wichtige Herausforderungen
f&#252;r die Meinungsbildung durch ADM-Systeme unbeachtet. ADM-Systeme werden schon lange, etwa bei sozialen
Netzwerken, Videoportalen und Suchmaschinen, eingesetzt und bestimmen unter anderem mit, welche
(politischen) Inhalte Nutzerinnen und Nutzer sehen. Diese Systeme werden von Einzelpersonen in privaten
Unternehmen mit Blick auf Gewinnmaximierung entwickelt und unterstehen kaum einer institutionalisierten,
unabh&#228;ngigen Kontrolle im &#246;ffentlichen Interesse. Eine solche Kontrolle im &#246;ffentlichen Interesse ist dringend zu
empfehlen. Verpflichtende Register und Audits von ADM-Systemen, eingebettet in das oben geschilderte EU-weite
Transparenz- und Aufsichtsregime, sind erstrebenswert. Die Register sollten als eine Art Dokumentationspflicht
f&#252;r Plattformen/Informationsintermedi&#228;re verstanden werden, die ADM-Systeme nutzen. Der MStV macht
bereits Schritte in diese Richtung, indem erstmals in der deutschen Medienregulierung spezielle Transparenzregeln
f&#252;r die Algorithmen, die gro&#223;e soziale Netzwerke und Suchmaschinen einsetzen, eingef&#252;hrt werden. Basierend 
2403 Vgl. Jaursch (2019): Regulatorische Reaktionen auf Desinformation.
auf den Erfahrungen mit diesen Regelungen und den zahlreichen Ans&#228;tzen, die in Forschung und
Zivilgesellschaft entwickelt werden, sollte Deutschland sich auf EU-Ebene einbringen, um ein gemeinsames Konzept f&#252;r
die Ausgestaltung solcher Register und Audits zu erarbeiten.
Aktuell ist noch unklar, wie genau Register und Audits ausgestaltet sein sollten, um Aufsichtsstellen, Forschung,
Zivilgesellschaft und in einigen F&#228;llen auch B&#252;rgerinnen und B&#252;rgern geeignete Einblicke in die ADM-Systeme 
zu gew&#228;hren. Hier sollte angesetzt werden mit der Forderung, dass nicht nur Forschung in diesem Bereich
verstetigt und vertieft wird, sondern dass Deutschland sich aktiv f&#252;r einen europ&#228;ischen Kooperationsprozess
einsetzt, der offene Fragen kl&#228;rt (zum Beispiel, f&#252;r welche Unternehmen ADM-Register sinnvoll sind, f&#252;r welche
KI-Systeme Audits verpflichtend sein sollen und welche Informationen &#252;berhaupt f&#252;r Audits n&#246;tig sind)2404.
Dieser Prozess sollte diverse Stakeholder einbeziehen, etwa die Europ&#228;ische Kommission, europ&#228;ische
Aufsichtsbeh&#246;rden, Zivilgesellschaft, Forschung, Wirtschaft und betroffene Gruppen. Hierf&#252;r sind auf europ&#228;ischer und
deutscher Ebene staatliche F&#246;rderungen n&#246;tig.
Solche Auditregelungen sind eine vielversprechende M&#246;glichkeit f&#252;r den Gesetzgeber in Deutschland und in der
EU, sich nicht ausschlie&#223;lich auf Regeln zur Inhaltemoderation und -l&#246;schung zu konzentrieren. Sie k&#246;nnen f&#252;r
ein Mindestma&#223; an Transparenz und &#246;ffentlicher Kontrolle sorgen und vermeiden dabei eine Debatte um
m&#246;gliche Eingriffe in die Meinungsfreiheit, die bei Regeln zur Inhaltel&#246;schung unweigerlich und berechtigterweise
aufkommen: Bei Transparenz- und Auditregeln geht es darum, f&#252;r KI-gest&#252;tzte Plattformen sinnvolle
Compliance-Prozesse zu etablieren, und nicht darum, Vorschriften f&#252;r die L&#246;schung einzelner Inhalte, die potenziell
strafrechtlich relevant sein k&#246;nnten, aufzustellen.
2404 Vgl. AlgorithmWatch (2020): Our Response to the European Commission&#8217;s Planned Digital Services Act.
        
 
 
  
   
     
         
    
      
         
   
   
 
     
      
      
        
  
     
     
  
 
  
   
 
  
   
 
   
      
   
  
    
    
  
   
  
   
 
  
                                               
     
 
              
      
    
  
   
        
   
    
          
    
     
 
       
1
E. Repliken
Repliken der CDU/CSU-Fraktion
Replik der Abgeordneten Ronja Kemmer und der Abgeordneten Marc Biadacz,
Hansj&#246;rg Durz, Jan Metzler, Stefan Sauer, Prof. Dr. Claudia Schmidtke, Nadine Sch&#246;n,
Andreas Steier sowie der sachverst&#228;ndigen Mitglieder Susanne Dehmel, 
Prof. Dr. Wolfgang Ecker, Prof. Dr. Alexander Filipovic, Dr. Tina Kl&#252;wer, 
Prof. Dr. Antonio Kr&#252;ger, Prof. Dr. J&#246;rg M&#252;ller-Lietzkow und Dr. Sebastian Wieczorek 
zu den Sondervoten 3.3 und 3.4 des Abgeordneten Dr. Marc Jongen und anderer zu 
den Kapiteln 7 und 8 des Mantelberichts (&#8222;KI und Gesellschaft&#8220; und &#8222;KI und
&#246;kologische Nachhaltigkeit&#8220;)
Der Abgeordnete Dr. Marc Jongen und andere erheben in einem Sondervotum den Vorwurf einer &#8222;entgrenzten
Definition von Nachhaltigkeit, und negiern mit ihren Aussagen im Folgenden nicht nur die wissenschaftlichen 
Erkenntnisse, die Grundlage von internationalen wie nationalen Konzepten und Strategien f&#252;r Nachhaltigkeit und
Klimapolitik &#8211; etwa den 17 Zielen f&#252;r eine nachhaltige Entwicklung &#8211; sind, sondern behaupten &#252;berdies, dass
&#8222;die Hypothese des treibhausgasinduzierten, anthropogenen Klimawandels, wie sie vom Weltklimarat verbreitet
und von der Bundesregierung vertreten wird, wissenschaftlich nicht gesichert&#8220; sei und leiten daraus den Vorwurf
einer &#8222;Instrumentalisierung der KI f&#252;r eine verfehlten Nachhaltigkeitspolitik&#8220; durch die Bundesregierung ab.
Infrage gestellt wird zudem, dass die Bek&#228;mpfung des Klimawandels ein &#252;bergeordnetes gesellschaftliches
Interesse sei.
Dies weist die CDU/CSU-Bundestagsfraktion als sachlich falsch zur&#252;ck und erkl&#228;rt:
Die dort ge&#228;u&#223;erte Negation des treibhausgasinduzierten, anthropogenen Klimawandels steht im Widerspruch zu
grundlegenden Erkenntnissen zu Klima und Klimawandel, &#252;ber die in der Wissenschaft seit l&#228;ngerer Zeit ein
nahezu vollst&#228;ndiger Konsens herrscht. Denn Beobachtungen und Untersuchungen auf der ganzen Welt zeigen
deutlich, dass Klimawandel stattfindet und dass die durch menschliche Aktivit&#228;ten freigesetzten Treibhausgase
ein Hauptantrieb daf&#252;r sind. Die CDU/CSU-Bundestagsfraktion sieht diesen Konsens sowohl durch die
Metastudien von James Powell2405 und John Cook2406 als auch durch die fundierten Aussagen der IPCC-Berichte2407
gest&#252;tzt. Es wurde darin wissenschaftlich gesichert und gut belegt, dass der Mensch Haupt der bereits laufenden
globalen Erw&#228;rmung ist. 2408 Diesem Konsens stimmen Wissenschafts-Akademien aus 80 L&#228;ndern zu, au&#223;erdem
viele weitere wissenschaftliche Organisationen und &#8211; laut mehrerer Studien &#8211; rund 97 Prozent der
Klimawissenschaftlerinnen und Klimawissenschaftler.2409 Auf diesen Erkenntnissen setzt auch die Nachhaltigkeitspolitik der
Bundesregierung auf.2410
In der Enquete-Kommission K&#252;nstliche Intelligenz wurde das Thema &#8222;Nachhaltigkeit und KI&#8220; am 5.
Dezember 2019 sowie in verschiedenen Projektengruppen beraten und mehrheitlich zeigte sich die Erwartung, dass
positive Beitr&#228;ge von KI-basierten Systemen im Zusammenhang mit Nachhaltigkeitszielen erzielt werden
k&#246;nnen, dazu z&#228;hlen beispielsweise die Chancen vernetzter Energie- und Verkehrsinfrastrukturen, eine genauere
Erdbeobachtung f&#252;r Klimaver&#228;nderungen oder verbesserte L&#246;sungen f&#252;r Ressourcenmanagement. Dabei wurde
die Forderung erhoben, dass neue Technologien nie zum Selbstzweck, sondern stets in Bezug zu gesellschaftlich
erw&#252;nschten Entwicklungen gesetzt werden, dazu geh&#246;rt die Erhaltung der nat&#252;rlichen Lebensgrundlagen.
Umfragen und Studien belegen, dass dies als &#252;bergeordnetes gesellschaftliches Interesse anzusehen ist.2411 
2405 Vgl. Powell (2016): The Consensus on Anthropogenic Global Warming Matters; Powell (2015): Climate Scientists Virtually
Unanimous.
2406 Vgl. Cook et al. (2016): Consensus on consensus: a synthesis of consensus estimates on human-caused global warming.
2407 Weitere Informationen dazu unter: https://www.de-ipcc.de/128.php (zuletzt abgerufen am 20. Oktober 2020).
2408 Die Berichte des IPCC beruhen auf tausenden von Ver&#246;ffentlichungen aus aller Welt und zehntausenden von Gutachterkommentaren.
Die Ausgewogenheit, Verl&#228;sslichkeit und Vollst&#228;ndigkeit seiner Aussagen wird durch detaillierte Verfahrensregeln mit einem
mehrstufigen, transparenten Begutachtungsverfahren sowie weltweite Expertenbeteiligung gew&#228;hrleistet.
2409 Vgl. Cook (2010): Gibt es wirklich einen Klimawandel?
2410 Weitere Informationen dazu unter: https://www.bundesregierung.de/breg-de/themen/nachhaltigkeitspolitik/eine-strategie-begleitet-
uns (zuletzt abgerufen am 20. Oktober 2020).
2411 Das gesellschaftliche Interesse und Bewusstsein bzgl. an Nachhaltigkeit zeigt sich nicht nur im Rahmen von weltweiten
Demonstrationen von vielen jungen Menschen, weitere Informationen dazu unter: https://fridaysforfuture.de/ (zuletzt abgerufen am 20. Oktober
2020), sondern ist durch diverse Studien und Umfragen belegt, vgl. u. a. Umweltbundesamt (2020): Umweltbewusstsein in
Deutschland. Vgl. auch die mehrheitlich beschlossenen Handlungsempfehlungen der Enquete-Kommission im Kapitel KI und Gesellschaft
des Mantelberichts [Handlungsempfehlungen] und im Kapitel KI und &#246;kologische Nachhaltigkeit [Handlungsempfehlungen].
Replik der Abgeordneten Ronja Kemmer und der Abgeordneten Marc Biadacz,
Hansj&#246;rg Durz, Jan Metzler, Stefan Sauer, Prof. Dr. Claudia Schmidtke, Nadine Sch&#246;n,
Andreas Steier sowie der sachverst&#228;ndigen Mitglieder Susanne Dehmel, Prof. 
Dr. Wolfgang Ecker, Prof. Dr. Alexander Filipovic, Dr. Tina Kl&#252;wer, Prof. Dr. Antonio 
Kr&#252;ger, Prof. Dr. J&#246;rg M&#252;ller-Lietzkow und Dr. Sebastian Wieczorek zum
Sondervotum 3.5 des Abgeordneten Dr. Marc Jongen und anderer zu Kapitel 9 des
Mantelberichts (&#8222;KI und Forschung&#8220;)
In ihren Sondervotum widersprechen der Abgeordnete Dr. Marc Jongen und andere der Notwendigkeit von
Diversit&#228;t und Erh&#246;hung des Frauenanteils und unterstellen aktuellen Ma&#223;nahmen Wirtschaftsferne oder gar,
dass sie wissenschaftliche Qualit&#228;tsma&#223;st&#228;ben entgegenlaufen.
Dies weist die CDU/CSU- Bundestagsfraktion als sachlich falsch zur&#252;ck und erkl&#228;rt:
Chancengerechtigkeit und Vielfalt im Wissenschaftssystem sind Voraussetzungen f&#252;r seine Zukunftsf&#228;higkeit
und daher zentrale Ziele unserer Bildungs- und Wissenschaftspolitik. Sie ist auf eine nachhaltige, strukturelle
Ver&#228;nderung angelegt, denn die nachhaltige Einbindung der Talente und Potenziale von Frauen ist nicht nur eine
Frage der Gerechtigkeit, sondern f&#252;r die Organisationen mit gro&#223;en Vorteilen verbunden: Erfahrungen zeigen,
dass gemischte Teams kreativer, erfolgreicher und kommunikativer arbeiteten, was zu besseren Forschungs- und
Entwicklungsergebnissen beitr&#228;gt. Talente k&#246;nnen aus einer gr&#246;&#223;eren Grundgesamtheit gesch&#246;pft und andere
Akzente gesetzt werden. Die gr&#246;&#223;ere Vielfalt kann zu einer Erweiterung der Forschungsperspektive f&#252;hren. 
Dies wurde mit Blick auf KI und Frauen in Forschung und Wirtschaft in der Sitzung der Enquete-Kommission
am 2. M&#228;rz 2020 &#252;berzeugend dargelegt.2412 Die Ber&#252;cksichtigung von Geschlechterfragestellungen ist zudem
intensiver Forschungsgegenstand.2413 Viele Instrumente &#8211; wie das Professorinnenprogramm, die
Exzellenzstrategie oder der Zukunftsvertrag Studium und Lehre &#8211; und spezielle Initiativen wie die F&#246;rderung von
Nachwuchswissenschaftlerinnen im Bereich der KI-Forschung &#8211; haben bereits eine positive gleichstellungspolitische
Dynamik entfaltet.2414 Dabei erfolgt die F&#246;rderung nicht nach &#8222;normativen Vorgaben&#8220; oder &#8222;sachfremden&#8220;
Beurteilungskriterien, wie das Sondervotum unterstellt, sondern nach hohen Ma&#223;st&#228;ben bei der Personalentwicklung
und -gewinnung, die auf Kompetenz und akademische Standards ausgerichtet sind.2415 Da das Potenzial von
Wissenschaftlerinnen in Deutschland noch nicht in ausreichendem Ma&#223;e genutzt wird, fordert die Enquete-
Kommission berechtigterweise, Frauen im Wissenschaftsbetrieb auch mit besonderem Blick auf KI-Bereiche weiter zu
fordern und zu f&#246;rdern.2416
Replik der Abgeordneten Ronja Kemmer und der Abgeordneten Marc Biadacz,
Hansj&#246;rg Durz, Jan Metzler, Stefan Sauer, Prof. Dr. Claudia Schmidtke, Nadine Sch&#246;n,
Andreas Steier sowie der sachverst&#228;ndigen Mitglieder Susanne Dehmel, 
Prof. Dr. Wolfgang Ecker, Prof. Dr. Alexander Filipovic, Dr. Tina Kl&#252;wer, 
Prof. Dr. Antonio Kr&#252;ger, Prof. Dr. J&#246;rg M&#252;ller-Lietzkow und Dr. Sebastian Wieczorek 
zum Sondervotum 3.11 des sachverst&#228;ndigen Mitglieds Prof. Dr. Boris Hollas und 
anderer zu den Kapiteln 3.2.2, 5.2.4, 5.2.6 und 5.2.8.1 des Berichts der Projektgruppe 
&#8222;KI und Arbeit, Bildung, Forschung&#8220; (&#8222;Beispiele f&#252;r KI-Anwendungen in Schule und 
Hochschule&#8220;, &#8222;Anforderungen an den Schulunterricht&#8220;, &#8222;KI und Hochschule&#8220; und 
&#8222;Lehrkr&#228;ftebildung&#8220;)
Unter der &#220;berschrift &#8222;Einwanderung&#8220; behaupten das sachverst&#228;ndige Mitglied Prof. Dr. Boris Hollas und
andere: &#8222;Eine wie bisher ungesteuerte Einwanderung f&#252;hrt zu einem weiter sinkenden Bildungsniveau&#8220; und f&#252;hrt
2412 Die Enquete-Kommission hat sich am 2. M&#228;rz 2020 mit dem Thema &#8222;KI und Frauen/Fachkr&#228;ftegewinnung&#8220; befasst und dabei diverse 
Studien und Erfahrungen in den Blick genommen.
2413 Weitere Informationen dazu unter: https://www.bmbf.de/de/genderforschung-222.html und zu aktuellen Projekten z. B. unter:
http://heike-kahlert.de/gender-governance (jeweils zuletzt abgerufen am 20. Oktober 2020).
2414 Weitere Informationen dazu unter: https://www.bmbf.de/de/chancengerechtigkeit-und-vielfalt-im-wissenschaftssystem-204.html
(zuletzt abgerufen am 20. Oktober 2020).
2415 Zum Stand der Gleichstellung, Ma&#223;nahmen und Auswahlkriterien vgl. Antwort der Bundesregierung auf die Kleine Anfrage der
Abgeordneten Kai Gehring, Ulle Schauws, Dr. Anna Christmann, weiterer Abgeordneter und der Fraktion B&#220;NDNIS 90/DIE GR&#220;-
NEN auf Bundestagsdrucksache 19/12248 oder zahlreiche Evaluationen, wie z. B. zum Professorinnenprogramm, vgl. GESIS &#8211;
Leibniz-Institut f&#252;r Sozialwissenschaften Kompetenzzentrum Frauen in Wissenschaft und Forschung CEWS (2017): Evaluation des
Professorinnenprogramms des Bundes und der L&#228;nder: Zweite Programmphase und Gesamtevaluation.
2416 33,4 Prozent der Forschenden aller Disziplinen in der EU sind Frauen. Deutschland liegt mit einem Frauenanteil von 28,0 Prozent
unter dem EU-Durchschnitt (an Hochschulen, in Unternehmen, im Regierungs- sowie im privaten Non-Profit-Sektor).
        
 
 
 
   
 
    
  
  
 
   
       
   
 
 
   
    
 
 
    
   
        
 
 
 
 
   
   
   
   
      
   
 
     
   
  
 
         
   
   
   
    
     
 
                                               
    
2
Belege daf&#252;r an, dass &#8222;Leistungen von Sch&#252;lern mit Migrationshintergrund deutlich unter den ohne
Migrationshintergrund&#8220; l&#228;gen. In der weiteren Argumentation wird an dem IQ von Migranten gezweifelt und in der Folge
gefordert, dass die Einwanderung von gering Qualifizierten beendet werden m&#252;sse&#8220;, um Deutschland im
&#8222;internationalen Wettbewerb um KI-Experten konkurrenzf&#228;hig&#8220; zu halten bzw. zu machen.
Dies weist die CDU/CSU-Bundestagsfraktion als sachlich falsch zur&#252;ck und erkl&#228;rt:
Die Behauptung, welche die AfD anf&#252;hrt, dass Migranten und Menschen von au&#223;erhalb des europ&#228;ischen
Kulturraums durchschnittlich geringere Ergebnisse bei IQ-Tests erzielen und dadurch weniger intelligent und
qualifiziert seien, ist in der Sache nicht richtig. Denn dabei wird au&#223;er Acht gelassen, dass die meisten verwendeten
Intelligenztests nicht kulturunabh&#228;ngig sind. Wenn ein IQ-Test in einer bestimmten Sprache erfolgreich
absolviert werden m&#246;chte, muss man die betreffende Sprache gut beherrschen, um ein &#228;hnliches Ergebnis erzielen zu
k&#246;nnen, wie ein Muttersprachler. 
Die Frage nach den Wirkungszusammenh&#228;ngen, die Bildungsdisparit&#228;ten hervorbringen, wurde ebenfalls nicht
zutreffend beantwortet. Der gemeinsam von Bund und L&#228;ndern gef&#246;rderten Bericht &#8222;Bildung in Deutschland
2020&#8220;2417 hat eine umfassende empirische Bestandsaufnahme f&#252;r das deutsche Bildungswesen vorgelegt. Er zeigt
differenziert auf, dass es nicht einen einzigen urs&#228;chlichen Mechanismus gibt, sondern viele Faktoren auf
unterschiedlichen Ebenen von Bedeutung sind. Im Schulbereich zeigt sich beispielsweise oftmals, dass bereits unter
Ber&#252;cksichtigung weniger Personenmerkmale wie der sozio&#246;konomischen Herkunft der Kinder und
Jugendlichen (Bildungsstand der Eltern oder Betroffenheit von Risikolagen) oder des Geschlechts nur noch ein geringer
&#8222;Migrationseffekt&#8220; in Bezug auf den Bildungserfolg feststellbar ist. Wir weisen auf Basis der empirischen
Befunde dieses Bildungsberichts, der &#252;ber Jahrzehnte hinweg den Bildungsstand in der deutschen Bev&#246;lkerung
analysiert hat, jegliche Verallgemeinerung des Bildungsstands von Menschen mit Migrationshintergrund zur&#252;ck
und verweisen auf die vielen unterschiedlichen Faktoren, die zu einem unterschiedlichen Bildungsniveau f&#252;hren,
wie etwa das Zuzugsalter oder die Herkunftsregion.
Repliken der SPD-Fraktion
Replik des Abgeordneten Ren&#233; R&#246;spel und der Abgeordneten Arno Klare,
Daniela Kolbe, Elvan Korkmaz-Emre und Falko Mohrs sowie der sachverst&#228;ndigen
Mitglieder Prof. Dr.-Ing. Sami Haddadin, Jan Kuhlen, Lena-Sophie M&#252;ller und 
Lothar Schr&#246;der zum Sondervotum 4.5 des Abgeordneten Carl-Julius
Cronenberg zu Kapitel 5.1.3.4 des Berichts der Projektgruppe 4 &#8222;KI und Arbeit,
Bildung, Forschung&#8220; (&#8222;Weiterentwicklung der Sozialen Sicherungssysteme&#8220;)
Der Text des Sondervotums suggeriert, dass in der Enquete-Kommission und insbesondere in der Projektgruppe
Arbeit das Thema &#8222;Soziale Sicherungssysteme&#8220; nicht er&#246;rtert worden sei. Dem ist nicht so. 
Richtig ist: Die FDP konnte sich mit den anderen Fraktionen der Projektgruppe zun&#228;chst aus inhaltlichen und am
Ende aus zeitlichen Gr&#252;nden nicht auf einen gemeinsamen Textentwurf verst&#228;ndigen. 
Die Spannweite der inhaltlichen Auseinandersetzung innerhalb der Projektgruppe &#8222;Arbeit&#8220; war sehr gro&#223;: Auf 
der einen Seite gab es einige Mitglieder, die das besagte Thema als &#8222;nicht KI-spezifisch&#8220; deklarierten und deshalb
gar nicht diskutieren wollten. Auf der anderen Seite beschrieben weitere Mitglieder sehr kreative L&#246;sungsans&#228;tze,
wie beispielsweise die Versteuerung von Digitalisierungsertr&#228;gen. Auch ein Kompromiss-Vorschlag des
Vorsitzenden der Projektgruppe f&#252;hrte nicht zu einem von allen getragenen Konsens in der Projektgruppe. 
Deshalb verst&#228;ndigten sich die Mitglieder der Projektgruppe darauf, es bei der Forderung nach der Einsetzung
einer Expertengruppe zu belassen, die das Thema &#8222;Soziale Sicherungssysteme&#8220; mit ausreichend Zeit in der
n&#228;chsten Legislaturperiode umfassend er&#246;rtern soll.
2417 Autorengruppe Bildungsberichterstattung (2020): Bildung in Deutschland 2020.
        
 
 
      
    
    
     
    
     
  
   
    
    
    
       
   
  
  
         
 
      
  
   
    
            
  
 
   
  
   
 
 
  
  
  
        
      
   
  
  
       
     
 
 
 
3
Replik des Abgeordneten Ren&#233; R&#246;spel und der Abgeordneten Dr. Danyal Bayaz,
Dr. Anna Christmann, Anke Domscheit-Berg, Arno Klare, Daniela Kolbe, Elvan
Korkmaz-Emre, Falko Mohrs, Tabea R&#246;&#223;ner, Dr. Petra Sitte und Jessica Tatti sowie 
der sachverst&#228;ndigen Mitglieder Dr. Florian Butollo, Prof. Dr.-Ing. Sami Haddadin, 
Dr. Stefan Heumann, Jan Kuhlen, Lena-Sophie M&#252;ller, Lothar Schr&#246;der und Prof.
Dr. Katharina Zweig zum Sondervotum 3.11 des sachverst&#228;ndigen Mitglieds Prof.
Dr. Boris Hollas und anderer zu den Kapiteln 3.2.2, 5.2.4, 5.2.6 und 5.2.8.1 des 
Berichts der Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220; (&#8222;Beispiele f&#252;r KI-
Anwendungen in Schule und Hochschule&#8220;, &#8222;Anforderungen an den Schulunterricht&#8220;, 
&#8222;KI und Hochschule&#8220; und &#8222;Lehrkr&#228;ftebildung&#8220;)
Die Unterzeichnerinnen und Unterzeichner weisen Teile des Sondervotums als sachlich falsch zur&#252;ck und
erkl&#228;ren dazu:
Unter der &#220;berschrift &#8222;Einwanderung&#8220; behaupten das sachverst&#228;ndige Mitglied Prof. Dr. Boris Hollas und
andere unter anderem, dass die &#8222;bisher ungesteuerte Einwanderung&#8220; zu einem geringeren Bildungsniveau f&#252;hre.
Die anschlie&#223;end aufgef&#252;hrten Belege und Begr&#252;ndungsketten unterscheiden konsequent zwischen
&#8222;Einheimischen&#8220; und &#8222;Migranten&#8220;. 
Weiterhin wird behauptet &#8222;Asylbewerbern mit Universit&#228;tsstudium&#8220; h&#228;tten einen niedrigeren IQ als &#8222;der
deutsche Realsch&#252;ler&#8220;. 
Unter der &#220;berschrift &#8222;Handlungsempfehlungen&#8220; fordert Prof. Dr. Boris Hollas, dass die Einwanderung aus
&#8222;L&#228;ndern mit geringem Bildungsniveau&#8220; beendet werden m&#252;sse.
Dazu beziehen wir wie folgt Stellung:
&#8226; Die AfD-Fraktion beziehungsweise das sachverst&#228;ndige Mitglied Prof. Dr. Boris Hollas und andere haben
es unterlassen, die besagten Punkte des Sondervotum in der fast zweij&#228;hrigen Laufzeit der Enquete-
Kommission in die Projektgruppenarbeit einzubringen. Damit hat die AfD diese Punkte einer inhaltlichen
Auseinandersetzung und einer seri&#246;sen wissenschaftlichen Diskussion entzogen. 
&#8226; Die Punkte sind l&#228;ngst wissenschaftlich widerlegt und haben unseres Erachtens in einem Enquetebericht zu
&#8222;K&#252;nstlicher Intelligenz&#8220; nichts verloren. 
&#8226; Denn die genannten Punkte haben zwar viel mit Rassismus und Polemik gegen Migration zu tun, jedoch
nichts mit dem Thema &#8222;K&#252;nstliche Intelligenz&#8220;.
&#8226; Die Unterzeichnerinnen und Unterzeichner distanzieren sich ausdr&#252;cklich von dem im Sondervotum
enthaltenen Rassismus und der Stereotypisierung.
Replik der FDP-Fraktion
Replik der Abgeordneten Mario Brandenburg, Daniela Kluckert und Carl-Julius
Cronenberg sowie der sachverst&#228;ndigen Mitglieder Dr. Aljoscha Burchardt und Andrea
Martin zum Sondervotum 3.11 des sachverst&#228;ndigen Mitglieds Prof. Dr. Boris Hollas
und anderer zu den Kapiteln 3.2.2, 5.2.4, 5.2.6 und 5.2.8.1 des Berichts der
Projektgruppe &#8222;KI und Arbeit, Bildung, Forschung&#8220; (&#8222;Beispiele f&#252;r KI-Anwendungen in 
Schule und Hochschule&#8220;, &#8222;Anforderungen an den Schulunterricht&#8220;, &#8222;KI und
Hochschule&#8220; und &#8222;Lehrkr&#228;ftebildung&#8220;)
Unter der &#220;berschrift &#8222;Einwanderung&#8220; behaupten das sachverst&#228;ndige Mitglied Prof. Dr. Boris Hollas und
andere: &#8222;Einer Studie der TU Chemnitz zufolge besitzen selbst Asylbewerber mit Universit&#228;tsstudium einen IQ,
der 8 Punkte unter dem deutschen Realsch&#252;ler liegt.&#8220;
Wir distanzieren uns von dieser Aussage. Weder wurde selbige im Rahmen der Enquete-Kommission diskutiert,
noch l&#228;sst sich ein thematischer Bezug zu K&#252;nstlicher Intelligenz erkennen.
        
 
 
     
    
 
 
 
   
  
 
   
 
 
    
   
   
 
  
 
    
   
 
 
 
  
  
  
   
 
  
  
 
  
  
 
 
 
 
  
   
 
 
 
 
  
   
 
4
Literaturverzeichnis zu den Sondervoten und Repliken
AI Ethics Impact Group (2020): From Principles to Practice &#8211; An interdisciplinary framework to operationalise
AI ethics. Hg. v. Bertelsmann Stiftung. G&#252;tersloh. Online verf&#252;gbar unter https://www.bertelsmann-
stiftung.de/fileadmin/files/BSt/Publikationen/GrauePublikationen/WKIO_2020_final.pdf, zuletzt
abgerufen am 13.10.2020.
AlgorithmWatch (2020): Automatisierte Entscheidungssysteme und der Kampf gegen COVID-19 &#8211; unsere
Position. Online verf&#252;gbar unter https://algorithmwatch.org/positionspapier-adms-und-covid19/, zuletzt
abgerufen am 13.10.2020.
AlgorithmWatch (2020): Our Response to the European Commission&#8217;s Planned Digital Services Act. Online
verf&#252;gbar unter https://algorithmwatch.org/en/submission-digital-services-act-dsa/, zuletzt abgerufen am
13.10.2020.
Appel, Markus (2020): Wie l&#228;sst sich das Postfaktische eind&#228;mmen? In: Markus Appel (Hg.): Die Psychologie
des Postfaktischen. &#220;ber Fake News, &#8222;L&#252;genpresse&#8220;, Clickbait &amp; Co (Sachbuch).
Appel, Markus; Doser, Nicole (2020): Fake News. In: Markus Appel (Hg.): Die Psychologie des
Postfaktischen. &#220;ber Fake News, &#8222;L&#252;genpresse&#8220;, Clickbait &amp; Co (Sachbuch), S. 9&#8211;20.
ARD ZDF Deutschlandradio Beitragsservice, Kundenmanagement und Berichtswesen (2020): Jahresbericht
2019. Online verf&#252;gbar unter https://www.rundfunkbeitrag.de/e175/e6373/Jahresbericht_2019.pdf, 
zuletzt abgerufen am 13.10.2020.
Arntz, Melanie; Gregory, Terry; Zierhan, Ulrich (2018): Digitalisierung und die Zukunft der Arbeit:
Makro&#246;konomische Auswirkungen auf Besch&#228;ftigung, Arbeitslosigkeit und L&#246;hne von morgen. Hg. v. 
ZEW &#8211; Zentrum f&#252;r europ&#228;ische Wirtschaftsforschung. Mannheim. Online verf&#252;gbar unter
http://ftp.zew.de/pub/zew-docs/gutachten/DigitalisierungundZukunftderArbeit2018.pdf, zuletzt
abgerufen am 13.10.2020.
Autor, David; Dorn, David; Katz, Lawrence F.; Patterson, Christina; Van Reenen, John (2017): Concentrating 
on the Fall of the Labor Share. In: American Economic Review: Papers &amp; Proceedings (107(5)), S. 180&#8211; 
185. Online verf&#252;gbar unter https://doi.org/10.1257/aer.p20171102, zuletzt abgerufen am 14.10.2020.
Autor, David; Dorn, David; Katz, Lawrence F.; Patterson, Christina; Van Reenen, John (2020): The Fall of the
Labor Share and the Rise of Superstar Firms. In: Quarterly Journal of Economics (135(2)), S. 645&#8211;709, 
zuletzt abgerufen am 13.10.2020.
Autorengruppe Bildungsberichterstattung (2020): Bildung in Deutschland 2020. Ein indikatorengest&#252;tzter
Bericht mit einer Analyse zu Bildung in einer digitalisierten Welt. 1. Auflage. Bielefeld: wbv Media.
Online verf&#252;gbar unter https://www.bildungsbericht.de/de/bildungsberichte-seit-2006/bildungsbericht-
2020/pdf-dateien-2020/bildungsbericht-2020.pdf, zuletzt abgerufen am 20.10.2020.
Azizi, SeyedSoroosh; Yektansani, Kiana (2020): Artificial Intelligence and Predicting Illegal Immigration to
the USA. In: Int. Migr. 58 (5), S. 183&#8211;193.
Baars, Meike (2017): Wie Amazon Mitarbeiter in Niedersachsen &#252;berwacht. In: noz.de, 13. Dezember 2017. 
Online verf&#252;gbar unter https://www.noz.de/deutschland-welt/niedersachsen/artikel/992503/wie-amazon-
mitarbeiter-in-niedersachsen-ueberwacht, zuletzt abgerufen am 13.10.2020.
Baecker, Dirk (2018): 4.0 oder Die L&#252;cke die der Rechner l&#228;sst. Berlin: Merve.
Barbrook, Richard; Cameron, Andy (1997): Die kalifornische Ideologie. Wiedergeburt der Moderne? Online
verf&#252;gbar unter https://www.heise.de/tp/features/Die-kalifornische-Ideologie-3229213.html, zuletzt 
abgerufen am 13.10.2020.
Bath, Dominik (2020): Beh&#246;rde nennt Zalando Kriterien f&#252;r Feedback-App. In: morgenpost.de, 27. Juli 2020. 
Online verf&#252;gbar unter https://www.morgenpost.de/berlin/article229602786/Behoerde-nennt-Zalando-
Kriterien-fuer-Feedback-App.html, zuletzt abgerufen am 13.10.2020.
Batra, Gaurav; Jacobson, Zach; Madhav, Siddarth; Queirolo, Andrea; Santhanam, Nick: Artificial-intelligence
hardware (2018): New opportunities for semiconductor companies. Hg. v. Mc Kinsey &amp; Company. 
Online verf&#252;gbar unter
https://www.mckinsey.com/~/media/McKinsey/Industries/Semiconductors/Our%20Insights/Artificial%2 
0intelligence%20hardware%20New%20opportunities%20for%20semiconductor%20companies/Artificia 
l-intelligence-hardware.pdf, zuletzt abgerufen am 13.10.2020.
Becher, Lena (2019): Hartz IV: Hohe Erfolgsquoten bei Widerspr&#252;chen und Klagen. Hg. v. o-ton-
arbeitsmarkt.de. Online verf&#252;gbar unter https://www.o-ton-arbeitsmarkt.de/o-ton-news/hartz-iv-hohe-
erfolgsquoten-bei-widerspruechen-und-klagen-2, zuletzt abgerufen am 14.10.2020.
Bei&#223;wenger, Michael (2016): Praktiken in der internetbasierten Kommunikation. In: Arnulf Deppermann, 
Angelika Linke und Helmuth Feilke (Hg.): Sprachliche und kommunikative Praktiken. Berlin, Boston:
De Gruyter Mouton (Jahrbuch des Instituts f&#252;r Deutsche Sprache), S. 279&#8211;309.
Bell, Emily (2015): Media should use tech for &#8216;good&#8217; journalism. In: journalism.co.uk, 16. Juli 2015. Online
verf&#252;gbar unter https://www.journalism.co.uk/news/emily-bell-news-groups-should-harness-tech-in-the-
service-of-good-journalism/s2/a565812/, zuletzt abgerufen am 13.10.2020.
Berkley International Framing Institute (2017): Framing-Manual. Unser gemeinsamer, freier Rundfunk ARD.
Online verf&#252;gbar unter https://cdn.netzpolitik.org/wp-upload/2019/02/framing_gutachten_ard.pdf, 
zuletzt abgerufen am 13.10.2020.
Bilger, Christine (2020): Die Polizei ist erneut mit einem gro&#223;en Aufgebot im Einsatz. In: stuttgarter-
zeitung.de, 03. Juli 2020. Online verf&#252;gbar unter https://www.stuttgarter-zeitung.de/inhalt.randale-in-
stuttgart-erneut-grosser-polizeieinsatz.e87e7b58-b275-4767-87c6-70401ad87d4b.html, zuletzt abgerufen 
am 13.10.2020.
Bitkom e. V. (2020): Zwei Jahre DS-GVO: Bitkom zieht durchwachsene Bilanz. Online verf&#252;gbar unter
https://www.bitkom.org/Presse/Presseinformation/Zwei-Jahre-DS-GVO-Bitkom-zieht-durchwachsene-
Bilanz, zuletzt abgerufen am 13.10.2020.
B&#322;aszczok, Marcin; Gw&#243;&#378;d&#378;, Arkadiusz; Hoppe, &#321;ukasz; Sk&#243;rka, Krzysztof (2013): Main Aims and Objectives
of an IT System in the Implementation of the Project: Design and Implementation of Innovative
Unmanned Mobile Platforms for the Needs of Monitoring State Borders. In: Aleksander Nawrat, 
Krzysztof Simek und Andrzej &#346;wierniak (Hg.): Advanced Technologies for Intelligent Systems of
National Border Security. Berlin, Heidelberg: Springer (Studies in Computational Intelligence, 440), 
S. 175&#8211;183.
Block, Katharina; Dickel, Sascha (2020): Jenseits der Autonomie. In: Behemoth (13 (1)), S. 109&#8211;131, zuletzt
abgerufen am 14.10.2020.
Boes, Andreas; K&#228;mpf, Tobias; Langes, Barbara; L&#252;hr, Thomas (2015): Landnahme im Informationsraum. 
Neukonstituierung gesellschaftlicher Arbeit in der &#8222;digitalen Gesellschaft&#8220;. In: WSI Mitteilungen (2), 
S. 77&#8211;85, zuletzt abgerufen am 13.10.2020.
Boltanski, Luc; Chiapello, &#200;ve (2013): Der neue Geist des Kapitalismus [2003]. Aus dem Franz&#246;sischen von 
Michael Tillmann. Mit einem Vorwort von Franz Schultheis. Konstanz: UVK.
Bookstaber, Richard (2008): Teufelskreis der Finanzm&#228;rkte &#8211; M&#228;rkte, Hedgefonds und die Risiken von 
Finanzinnovationen. Kulmbach: B&#246;rsenmedien AG.
Borchers, Dagmar (2019): Das identit&#228;tslinke Kultur- und Identit&#228;tsverst&#228;ndnis. In: Sandra Kostner, Stefan Luft
und Elham Manea (Hg.): Identit&#228;tslinke L&#228;uterungsagenda. Eine Debatte zu ihren Folgen f&#252;r
Migrationsgesellschaften. Stuttgart: ibidem Verlag (Impulse, 1), S. 89&#8211;123.
Bos, Wilfried; Bonsen, Martin; Baumert, J&#252;rgen; Prenzel, Manfred; Selter, Christoph; Walther, Gerd (2008):
TIMSS 2007 &#8211; Mathematische und naturwissenschaftliche Kompetenzen von Grundschulkindern in 
Deutschland im internationalen Vergleich &#8211; Zusammenfassung. Handreichung zur Pressekonferenz in 
Berlin. Online verf&#252;gbar unter https://www.phil-fak.uni-
duesseldorf.de/fileadmin/Redaktion/Institute/Sozialwissenschaften/BF/Lehre/WiSe0809/VL/TIMSS_20 
07_Pressemappe.pdf, zuletzt abgerufen am 13.10.2020.
Bosker, Bianca (2011): Facial Recognition: The One Technology Google Is Holding Back. Hg. v. Huffpost. 
Online verf&#252;gbar unter
https://webcache.googleusercontent.com/search?q=cache:MwDlXjKEg2oJ:https://www.huffpost.com/en 
try/facial-recognition-google_n_869583+&amp;cd=3&amp;hl=en&amp;ct=clnk&amp;gl=us, zuletzt aktualisiert am
06.12.2017, zuletzt abgerufen am 14.10.2020.
BR Wissen (2019): Gefragte Metalle f&#252;r moderne Technologien. Online verf&#252;gbar unter
https://www.br.de/wissen/seltene-erden-metalle-smartphones-china-100.html, zuletzt abgerufen am
13.10.2020.
Branch, William A. (2018): Artificial Intelligence and Operational-Level Planning: An Emergent Convergence. 
Hg. v. School of Advanced Military Studies, US Army Command and General Staff College, Fort
Leavenworth, KS. Online verf&#252;gbar unter https://apps.dtic.mil/dtic/tr/fulltext/u2/1070958.pdf, zuletzt
abgerufen am 13.10.2020.
Brynjolfsson, Erik; Rock, Daniel; Syverson, Chad (2017): Artificial Intelligence and the Modern Productivity
Paradox: A Clash of Expectations and Statistcs. Hg. v. National Bureau of Economic Research.
Cambridge (NBER WORKING PAPER SERIES, 24001). Online verf&#252;gbar unter
https://www.nber.org/papers/w24001.pdf, zuletzt abgerufen am 13.10.2020.
Bundesamt f&#252;r Migration und Fl&#252;chtlinge (2019): Ablauf des deutschen Asylverfahrens. Ein &#220;berblick &#252;ber die
einzelnen Verfahrensschritte und rechtlichen Grundlagen. Online verf&#252;gbar unter
https://www.bamf.de/SharedDocs/Anlagen/DE/AsylFluechtlingsschutz/Asylverfahren/das-deutsche-
asylverfahren.html, zuletzt abgerufen am 13.10.2020.
Bundesamt f&#252;r Migration und Fl&#252;chtlinge (2020): Aktuelle Zahlen &#8211; Ausgabe: Juni 2020. Tabellen Diagramme
Erl&#228;uterungen. Online verf&#252;gbar unter
https://www.bamf.de/SharedDocs/Anlagen/DE/Statistik/AsylinZahlen/aktuelle-zahlen-juni-
2020.pdf?__blob=publicationFile&amp;v=5, zuletzt abgerufen am 13.10.2020.
Bundesanstalt f&#252;r Geowissenschaften und Rohstoffe (2018): Tantal. Rohstoffwirtschaftliche Steckbriefe. 
Online verf&#252;gbar unter
https://www.bgr.bund.de/DE/Themen/Min_rohstoffe/Downloads/rohstoffsteckbrief_ta.pdf?__blob=publi 
cationFile&amp;v=3, zuletzt abgerufen am 13.10.2020.
Bundeskriminalamt (2019): Kriminalit&#228;t im Kontext von Zuwanderung. Bundeslagebild 2019. Online
verf&#252;gbar unter
https://www.bka.de/SharedDocs/Downloads/DE/Publikationen/JahresberichteUndLagebilder/Kriminalit 
aetImKontextVonZuwanderung/KriminalitaetImKontextVonZuwanderung_2019.html?nn=62336, 
zuletzt abgerufen am 13.10.2020.
Bundesministerium der Finanzen (2014): &#214;ffentlich-rechtliche Medien &#8211; Aufgabe und Finanzierung. Gutachten 
des Wissenschaftlichen Beirats beim Bundesministerium der Finanzen. Online verf&#252;gbar unter
https://www.bundesfinanzministerium.de/Content/DE/Downloads/Broschueren_Bestellservice/2014-12-
15-gutachten-medien.pdf?__blob=publicationFile&amp;v=7, zuletzt abgerufen am 13.10.2020.
Bundesministerium f&#252;r wirtschaftliche Zusammenarbeit und Entwicklung (2017): Der Zukunftsvertrag f&#252;r die
Welt. Die Agenda 2030 f&#252;r nachhaltige Entwicklung. Infobrosch&#252;re. Online verf&#252;gbar unter
http://www.bmz.de/de/mediathek/publikationen/reihen/infobroschueren_flyer/infobroschueren/Materiali 
e270_zukunftsvertrag.pdf, zuletzt abgerufen am 13.10.2020.
Bundesregierung (2018): Strategie K&#252;nstliche Intelligenz der Bundesregierung. Online verf&#252;gbar unter
https://www.ki-strategie-deutschland.de/home.html, zuletzt abgerufen am 20.07.2020.
Busch, Christoph (2018): Algorithmic Accountability. Gutachten. Hg. v. ABIDA. Osnabr&#252;ck. Online verf&#252;gbar
unter
https://www.abida.de/sites/default/files/ABIDA%20Gutachten%20Algorithmic%20Accountability.pdf, 
zuletzt abgerufen am 14.10.2020.
Butollo, Florian (2019): Vernetzungstechnologie und Reproduktionsnetzwerke. Digitalisierung und die
Reorganisation globaler Wertsch&#246;pfung. In: Florian Butollo und Sabine Nuss (Hg.): Marx und die
Roboter. Vernetzte Produktion, K&#252;nstliche Intelligenz und lebendige Arbeit. Berlin: Dietz, S. 198&#8211;215.
Butollo, Florian; Nuss, Sabine (2019): Marx und die Roboter. Vernetzte Produktion, K&#252;nstliche Intelligenz und 
lebendige Arbeit. Berlin: Dietz.
Castells, Manuel (2017): Der Aufstieg der Netzwerkgesellschaft. Das Informationszeitalter. Wirtschaft.
Gesellschaft. Kultur. Band 1. 2nd ed. Wiesbaden: Springer Fachmedien Wiesbaden (Neue Bibliothek der
Sozialwissenschaften).
Cavelty, Myriam Dunn; Egloff, Florian J. (2019): Cybersecurity: Rollen des Staates. In: Isabelle Borucki und 
Wolf J. Sch&#252;nemann (Hg.): Internet und Staat. Perspektiven auf eine komplizierte Beziehung. 1. Auflage
(Staatsverst&#228;ndnisse), S. 209&#8211;230. Online verf&#252;gbar unter https://www.nomos-
elibrary.de/10.5771/9783845290195-209.pdf, zuletzt abgerufen am 13.10.2020.
Cook, John (2010): Gibt es wirklich einen Klimawandel? Hg. v. klimafakten.de (Fakten statt Behauptungen, 
#Fakt001). Online verf&#252;gbar unter https://www.klimafakten.de/behauptungen/behauptung-es-gibt-noch-
keinen-wissenschaftlichen-konsens-zum-klimawandel, zuletzt aktualisiert am September 2019, zuletzt
abgerufen am 20.10.2020.
Cook, John; Oreskes, Naomi; Doran, Peter T.; Anderegg, William R. L.; Verheggen, Bart; Maibach, Ed W. et
al. (2016): Consensus on consensus: a synthesis of consensus estimates on human-caused global
warming. In: Environ. Res. Lett. 11 (4), S. 48002.
Csernatoni, Raluca (2018): Constructing the EU&#8217;s high-tech borders: FRONTEX and dual-use drones for 
border management. In: European Security 27 (2), S. 175&#8211;200. Online verf&#252;gbar unter
https://www.tandfonline.com/doi/full/10.1080/09662839.2018.1481396#aHR0cHM6Ly93d3cudGFuZG 
ZvbmxpbmUuY29tL2RvaS9wZGYvMTAuMTA4MC8wOTY2MjgzOS4yMDE4LjE0ODEzOTY/bmVl 
ZEFjY2Vzcz10cnVlQEBAMA==, zuletzt abgerufen am 13.10.2020.
Datenethikkommission der Bundesregierung (2019): Gutachten der Datenethikkommission der
Bundesregierung. Online verf&#252;gbar unter
http://www.bmi.bund.de/SharedDocs/downloads/DE/publikationen/themen/it-digitalpolitik/gutachten-
datenethikkommission.pdf?__blob=publicationFile&amp;v=6, zuletzt abgerufen am 14.10.2020.
Dauth, Wolfgang; Findeisen, Sebastian; S&#252;dekum, Jens; W&#246;&#223;ner, Nicole (2017): German Robots &#8211; The Impact
of Industrial Robots on Workers (IAB Discussion Paper, 30). Online verf&#252;gbar unter
http://doku.iab.de/discussionpapers/2017/dp3017.pdf, zuletzt abgerufen am 13.10.2020.
Deutsche Energie Agentur (2017): Analyse der mit erh&#246;htem IT- Einsatz verbundenen Energieverbr&#228;uche
infolge der zunehmenden Digitalisierung. Status Quo und Prognosen. Online verf&#252;gbar unter
https://www.dena.de/fileadmin/dena/Dokumente/Pdf/9232_dena-Metastudie_Analyse_IT-
Einsatz_Energieverbraeuche_Digitalisierung.pdf, zuletzt abgerufen am 13.10.2020.
Deutsche Rohstoffagentur (2016): Rohstoffe f&#252;r Zukunftstechnologien 2016. Auftragsstudie. Online verf&#252;gbar
unter https://www.deutsche-rohstoffagentur.de/DERA/DE/Downloads/Studie_Zukunftstechnologien-
2016.pdf?__blob=publicationFile&amp;v=5, zuletzt abgerufen am 13.10.2020.
Deutsche Rohstoffagentur (2018): Zur Verf&#252;gbarkeit von Kobalt f&#252;r den Industriestandort Deutschland. Online
verf&#252;gbar unter https://www.bgr.bund.de/DERA/DE/Downloads/vortrag-kobalt-
albarazi.pdf?__blob=publicationFile&amp;v=3, zuletzt abgerufen am 13.10.2020.
Deutscher Bundestag, Parlamentsnachrichten (2020): Fachkr&#228;ftemangel im KI-Bereich. K&#252;nstliche 
Intelligenz &#8211; Gesellschaftliche Verantwortung und wirtschaftliche Potenziale/Anh&#246;rung (hib 233/2020). 
Online verf&#252;gbar unter https://www.bundestag.de/presse/hib/684806-684806, zuletzt abgerufen am
13.10.2020.
Deutschlandfunk.de: K&#252;nstliche Intelligenz gegen den Klimawandel. Carina Fron im Gespr&#228;ch mit Manfred 
Kloiber. Online verf&#252;gbar unter https://www.deutschlandfunk.de/umwelt-kuenstliche-intelligenz-gegen-
den-klimawandel.684.de.html?dram:article_id=477738, zuletzt abgerufen am 14.10.2020.
Dicke, Tim Vincent; Gottschalk, Alexander; Lother, Sophia (2020): Feldmann bricht Urlaub ab &#8211; N&#228;chtlicher
Besuch auf Opernplatz geplant. In: fnp.de, 23. Juli 2020. Online verf&#252;gbar unter
https://www.fnp.de/frankfurt/frankfurt-opernplatz-randale-polizei-schlaegerei-corona-party-muell-
seehofer-feldmann-zr-90010754.html, zuletzt abgerufen am 13.10.2020.
Dickel, Sascha (2019): Prototyping Society. Zur vorauseilenden Technisierung der Zukunft. Bielefeld:
transcript.
Die Beauftragte der Bundesregierung f&#252;r Migration, Fl&#252;chtlinge und Integration (2019): Deutschland kann 
Integration: Potenziale f&#246;rdern, Integration fordern, Zusammenhalt st&#228;rken. 12. Bericht der Beauftragten 
der Bundesregierung f&#252;r Migration, Fl&#252;chtlinge und Integration. Online verf&#252;gbar unter
https://www.integrationsbeauftragte.de/resource/blob/89600/1699390/478a6d7d9cd3fc2c18131ebfcfef3d 
ac/lagebericht-12-data.pdf, zuletzt abgerufen am 13.10.2020.
Die Wissenschaftlichen Dienste des Bundestages (2017): Einreiseverweigerung und Einreisegestattung nach 
&#167; 18 Asylgesetz. Ausarbeitung. WD 3: Verfassung und Verwaltung. Online verf&#252;gbar unter
https://www.bundestag.de/resource/blob/514854/0bdb98e0e61680672e965faad3498e93/wd-3-109-17-
pdf-data.pdf, zuletzt abgerufen am 13.10.2020.
Die Wissenschaftlichen Dienste des Bundestages (2018): Rechtsauffassungen zur Einreiseverweigerung und 
Einreisegestattung im Zusammenhang mit der sog. Grenz&#246;ffnung. WD 3: Verfassung und Verwaltung. 
Online verf&#252;gbar unter
https://www.bundestag.de/resource/blob/563758/8285a2b6cfa0bc2538314d3a6f8b44c8/wd-3-139-18-
pdf-data.pdf, zuletzt abgerufen am 13.10.2020.
Diefenbacher, Hans; Held, Benjamin; Rodenh&#228;user, Dorothee; Zieschank, Roland (2016): Aktualisierung und 
methodische &#220;berarbeitung des Nationalen Wohlfahrtsindex 2.0 f&#252;r Deutschland 1991 bis 2012.
Hg. v. Umweltbundesamt. Online verf&#252;gbar unter
https://www.umweltbundesamt.de/sites/default/files/medien/378/publikationen/texte_29_2016_aktualisi 
erung_und_methodische_ueberarbeitung_des_nationalen_wohlfahrtsind.pdf, zuletzt abgerufen am
14.10.2020.
Diller, Ansgar (1999): &#214;ffentlich-rechtlicher Rundfunk. In: J&#252;rgen Wilke (Hg.): Mediengeschichte der
Bundesrepublik Deutschland. K&#246;ln: B&#246;hlau Verlag, S. 146&#8211;166.
D&#246;rh&#246;fer, Pamela (2020): K&#252;nstliche Intelligenz gegen Fake News. Max-Planck-Wissenschaftler entwickeln
einen Algorithmus, der Nachrichten mit gro&#223;em Schadenspotenzial herausfiltert. In: fr.de, 29. Januar
2020. Online verf&#252;gbar unter https://www.fr.de/wissen/kuenstliche-intelligenz-gegen-fake-news-
11002369.html, zuletzt abgerufen am 13.10.2020.
D&#246;rre, Klaus (2019): Risiko Kapitalismus. Landnahme, Zangenkrise, Nachhaltigkeitsrevolution. In: Klaus
D&#246;rre, Hartmut Rosa, Karina Becker, Sophie Bose und Benjamin Seyd (Hg.): Gro&#223;e Transformation?
Zur Zukunft moderner Gesellschaften. Sonderband des Berliner Journals f&#252;r Soziologie. Wiesbaden:
Springer VS, S. 3&#8211;33.
DPA (2019): Kelber warnt vor automatischer Gesichtserkennung. In: Zeit.de, 12. Januar 2019. Online
verf&#252;gbar unter https://www.zeit.de/news/2019-01/12/kelber-warnt-vor-
automatischergesichtserkennung-190112-99-531900, zuletzt abgerufen am 14.10.2020.
DPA (2020): Digitalsteuer: EU-Kommission will 2021 notfalls eigenen Plan vorlegen. In: heise online, 2020. 
Online verf&#252;gbar unter https://www.heise.de/news/Digitalsteuer-EU-Kommission-will-2021-notfalls-
eigenen-Plan-vorlegen-4892432.html, zuletzt abgerufen am 13.10.2020.
Engler, Marcus; Schneider, Jan (2015): Fl&#252;chtlingsrecht: Der internationale Rahmen. Online verf&#252;gbar unter
https://www.bpb.de/gesellschaft/migration/kurzdossiers/207695/fluechtlingsrecht, zuletzt abgerufen am
13.10.2020.
Europ&#228;ische Kommission (2020): Mitteilung der Kommission an das Europ&#228;ische Parlament und den Rat. 
Datenschutz als Grundpfeiler der Teilhabe der B&#252;rgerinnen und B&#252;rger und des Ansatzes der EU f&#252;r den 
digitalen Wandel &#8211; zwei Jahre Anwendung der Datenschutz-Grundverordnung. Online verf&#252;gbar unter
https://ec.europa.eu/transparency/regdoc/rep/1/2020/DE/COM-2020-264-F1-DE-MAIN-PART-1.PDF, 
zuletzt abgerufen am 13.10.2020.
Evans, Dave (2011): Das Internet der Dinge. So ver&#228;ndert die n&#228;chste Dimension des Internet die Welt. 
Hg. v. Cisco Internet Business Solutions Group. Online verf&#252;gbar unter
https://www.cisco.com/c/dam/global/de_de/assets/executives/pdf/Internet_of_Things_IoT_IBSG_0411F 
INAL.pdf, zuletzt abgerufen am 13.10.2020.
Fanta, Alexander (2018): EU-Projekt entwickelt smarten L&#252;gendetektor f&#252;r Grenzkontrollen. 
Hg. v. Netzpolitik.org. Online verf&#252;gbar unter https://netzpolitik.org/2018/eu-projekt-entwickelt-
smarten-luegendetektor-fuer-grenzkontrollen/, zuletzt abgerufen am 14.10.2020.
Fischhaber, Thomas (2018): Manipulation zugunsten von Angela Merkel? Das ist an Vorw&#252;rfen gegen die
&#8222;Tagesschau&#8220; dran. In: merkur.de, 26. Juni 2018. Online verf&#252;gbar unter
https://www.merkur.de/politik/manipulation-zugunsten-von-angela-merkel-ist-an-vorwuerfen-gegen-
tagesschau-dran-zr-9983219.html, zuletzt abgerufen am 13.10.2020.
Foundational Economy Collective (2019): Die &#214;konomie des Alltagslebens. F&#252;r eine neue Infrastrukturpolitik 
[2018]. Aus dem Englischen von Stephan Gebauer. Berlin: Suhrkamp.
Fraktion der AfD im Deutschen Bundestag (2020): Cotar: Versch&#228;rfung des NetzDG ebnet Weg f&#252;r &#8222;DDR
2.0&#8220;. Online verf&#252;gbar unter https://www.afdbundestag.de/cotar-verschaerfung-des-netzdg-ebnet-weg-
fuer-ddr-2-0/, zuletzt abgerufen am 13.10.2020.
Fraunhofer-Institut f&#252;r Optronik, Systemtechnik und Bildauswertung: Intelligente Video&#252;berwachung f&#252;r mehr
Sicherheit und Datenschutz. Start f&#252;r Pilotprojekt in Mannheim. Online verf&#252;gbar unter
https://www.iosb.fraunhofer.de/servlet/is/93474/, zuletzt abgerufen am 14.10.2020.
Freed, Michael; Fitzgerald, Will; Harris, Robert (2005): Intelligent Autonomous Surveillance of many Targets
with few UAVs.
Fuest, Clemens; Clemens, Meier; Neumeier, Florian; St&#246;hlker, Daniel (2018): Die Besteuerung der
Digitalwirtschaft. Hg. v. IHK f&#252;r M&#252;nchen und Oberbayern. ifo. Online verf&#252;gbar unter
https://www.ifo.de/DocDL/Studie-Digitalsteuer-2018.pdf.
Geier, Wolfram (2020): Interview: Zu unserer Sicherheit und Resilienz m&#252;ssen wir alle beitragen. In: Chirine
Etezadzadeh (Hg.): Smart City &#8211; Made in Germany. Die Smart-City-Bewegung als Treiber einer
gesellschaftlichen Transformation. 1st ed. 2020, S. 697&#8211;707.
Gesellschaft f&#252;r Bildung und Wissen e. V. Forum f&#252;r Schule, Ausbildung und Studium (2017): Mathematik:
Brandbrief gegen Bildungsstandards. Online verf&#252;gbar unter https://bildung-
wissen.eu/fachbeitraege/schule-und-unterricht/mathematik-brandbrief-gegen-bildungsstandards.html, 
zuletzt abgerufen am 13.10.2020.
GESIS &#8211; Leibniz-Institut f&#252;r Sozialwissenschaften Kompetenzzentrum Frauen in Wissenschaft und Forschung 
CEWS (2017): Evaluation des Professorinnenprogramms des Bundes und der L&#228;nder: Zweite
Programmphase und Gesamtevaluation. Online verf&#252;gbar unter https://www.gwk-
bonn.de/fileadmin/Redaktion/Dokumente/Papers/Evaluation_des_Professorinnenprogramms-
Bericht_Januar_2017.pdf, zuletzt abgerufen am 20.10.2020.
Gimpel, Henner; Lanzl, Julia; Manner-Romberg, Tobias; N&#252;ske, Niklas (2018): Digitaler Stress in 
Deutschland. Eine Befragung von Erwerbst&#228;tigen zu Belastung und Beanspruchung durch Arbeit mit
digitalen Technologien. Hg. v. Hans B&#246;ckler Stiftung. Online verf&#252;gbar unter
https://www.boeckler.de/pdf/p_fofoe_WP_101_2018.pdf, zuletzt abgerufen am 13.10.2020.
Godulla, Alexander (2017): &#214;ffentliche Kommunikation im digitalen Zeitalter. Grundlagen und Perspektiven 
einer integrativen Modellbildung. Wiesbaden: Springer VS.
Gordon, Robert J. (2015): Secular Stagnation: A Supply-Side View. In: American Economic Review: Papers &amp;
Proceedings (105(5)), S. 54&#8211;59. Online verf&#252;gbar unter
https://pubs.aeaweb.org/doi/pdfplus/10.1257/aer.p20151102, zuletzt abgerufen am 13.10.2020.
Gordon, Robert J. (2018): Why has economic growth slowed when innovation appears to be accelerating?
Hg. v. National Bureau of Economic Research. Cambridge (NBER WORKING PAPER SERIES, 
24554). Online verf&#252;gbar unter https://www.nber.org/papers/w24554.pdf, zuletzt abgerufen am
13.10.2020.
Habermas, J&#252;rgen (1990): Strukturwandel der &#214;ffentlichkeit. Untersuchungen zu einer Kategorie der
b&#252;rgerlichen Gesellschaft ; mit einem Vorwort zur Neuauflage 1990. Zugl.: Marburg, Univ., Habil.-
Schr., 1961. Frankfurt am Main: Suhrkamp (Suhrkamp-Taschenbuch Wissenschaft, 891).
Hagel&#252;ken, Alexander; Kl&#228;sgen, Michael (2019): So &#252;berwacht Zalando seine Mitarbeiter. In: sueddeutsche.de, 
19. November 2019. Online verf&#252;gbar unter https://www.sueddeutsche.de/wirtschaft/zalando-
ueberwachung-zonar-1.4688431, zuletzt abgerufen am 15.10.2020.
Hagel&#252;ken, Alexander; Kl&#228;sgen, Michael (2019): Datensch&#252;tzer: Zalando soll Kontrollsoftware aussetzen. 
In: sueddeutsche.de, 26. November 2019. Online verf&#252;gbar unter
https://www.sueddeutsche.de/wirtschaft/zalando-zonar-1.4698105, zuletzt abgerufen am 13.10.2020.
Hartong, Sigrid (2019): Learning Analytics und Big Data in der Bildung. Zur notwendigen Entwicklung eines
datenpolitischen Alternativprogramms. Hg. v. Gewerkschaft Erziehung und Wissenschaft. Online
verf&#252;gbar unter
https://www.gew.de/index.php?eID=dumpFile&amp;t=f&amp;f=91791&amp;token=702ec8d5f9770206a4aa8a107975 
0ec9021b90bf&amp;sdownload=&amp;n=Learninganalytics-2019-web-IVZ.pdf, zuletzt abgerufen am
13.10.2020.
Hasebrink, Uwe; Schulz, Wolfgang; Dreyer, Stephan; Kirsch, Anna-Katharina; Loosen, Wiebke; Puschmann, 
Cornelius et al. (2017): Zur Entwicklung der Medien in Deutschland zwischen 2013 und 2016. 
Wissenschaftliches Gutachten zum Medien- und Kommunikationsbericht der Bundesregierung. 
Hg. v. Hans-Bredow-Institut f&#252;r Medienforschung an der Universit&#228;t Hamburg. Hamburg. Online
verf&#252;gbar unter
https://www.bundesregierung.de/resource/blob/975226/752272/cfbcb2bc28dd2a6fc33eb5f5c2a437b0/20 
17-06-27-medienbericht-data.pdf?download=1, zuletzt abgerufen am 13.10.2020.
Hattie, John (2015): Lernen sichtbar machen. 3. erweiterte Auflage mit Index und Glossar. Hg. v. Wolfgang 
Beywl und Klaus Zierer. Baltmannsweiler: Schneider Verlag Hohengehren.
Heinsohn, Gunnar (2019): Wettkampf um die Klugen. Kompetenz, Bildung und die Wohlfahrt der Nationen.
Heintz, Bettina (2010): Numerische Differenz. &#220;berlegungen zu einer Soziologie des (quantitativen)
Vergleichs. In: Zeitschrift f&#252;r Soziologie 39 (3), S. 162&#8211;181, zuletzt abgerufen am 14.10.2020.
Heintz, Bettina (2019): Vom Komparativ zum Superlativ. Eine kleine Soziologie der Rangliste. In: Stefan 
Nicolae, Martin Endre&#223;, Oliver Berli und Daniel Bischur (Hg.): (Be)Werten. Beitr&#228;ge zur sozialen 
Konstruktion von Wertigkeit. Wiesbaden: Springer VS, S. 45&#8211;80.
Held, Benjamin (2019): Leben in Schleswig-Holstein &#8211; subjektive Einsch&#228;tzungen als Teil der
Wohlfahrtsmessung (SOEPpapers on Multidisciplinary Panel Data Research, 1044). Online verf&#252;gbar
unter https://www.diw.de/documents/publikationen/73/diw_01.c.678978.de/diw_sp1044.pdf, zuletzt
abgerufen am 14.10.2020.
Hildebrandt, Antje (2020): &#8222;Unser Rundfunksystem krankt&#8220;. Interview mit Hans-Peter Siebenhaar.
In: cicero.de, 30. Januar 2020. Online verf&#252;gbar unter
https://www.cicero.de/wirtschaft/gebuehrenverschwendung-oeffentlich-rechtlicher-rundfunk-Haseloff-
tom-buhrow-umweltsau-afd, zuletzt abgerufen am 13.10.2020.
Hirsch-Kreinsen, Hartmut; ten Hompel, Michael (2015): Digitalisierung industrieller Arbeit.
Entwicklungsperspektiven und Gestaltungsans&#228;tze. In: Thomas Bauernhansl, Michael ten Hompel und 
Birgit Vogel-Heuser (Hg.): Handbuch Industrie 4.0. Produktion. Automatisierung und Logistik. Berlin, 
Heidelberg: Springer, S. 1&#8211;20.
Hirte, Katrin; Thieme, Sebastian (2013): Mainstream, Orthodoxie und Heterodoxie. Zur Klassifizierung der
Wirtschaftswissenschaften. Hg. v. Zentrum f&#252;r &#214;konomische und Soziologische Studien Universit&#228;t
Hamburg. Online verf&#252;gbar unter https://www.econstor.eu/bitstream/10419/77079/1/751902152.pdf, 
zuletzt abgerufen am 15.10.2020.
Hoffgaard, Henning (2016): Zu viel Willkommenskultur in den Medien. Studie beweist: Viele Journalisten
lie&#223;en kritische Distanz vermissen und machten sich Merkels &#8222;Wir schaffen das&#8220; zu eigen. In: Junge
Freiheit, 19. August 2016 (34/16), S. 17. Online verf&#252;gbar unter https://jf-
archiv.de/archiv16/201634081954.htm, zuletzt abgerufen am 13.10.2020.
Hoffmann, Elisabeth; Henry-Huthmacher, Christine (2016): Ausbildungsreife &amp; Studierf&#228;higkeit. 
Hg. v. Konrad-Adenauer-Stiftung e. V. Online verf&#252;gbar unter
https://www.kas.de/documents/252038/253252/7_dokument_dok_1.pdf/ec1762cf-4191-596a-5163-
3357c553d3ff?version=1.0&amp;t=1539650980320, zuletzt abgerufen am 13.10.2020.
Horn, Gustav A.; Behringer, Jan; Gechert, Sebastian; Rietzler, Katja; Stein, Ulrike (2017): Was tun gegen die
Ungleichheit? Wirtschaftspolitische Vorschl&#228;ge f&#252;r eine reduzierte Ungleichheit. IMK-Report 129. 
Online verf&#252;gbar unter https://www.boeckler.de/pdf/p_imk_report_129_2017.pdf, zuletzt abgerufen am
13.10.2020.
Husseini, Talal (2019): AI in the sky: can drone surveillance technology replace CCTV? Online verf&#252;gbar
unter https://www.army-technology.com/features/ai-drone-surveillance-cctv/, zuletzt abgerufen am
13.10.2020.
Imhof, Kurt (2006): Politik im &#8222;neuen&#8220; Strukturwandel der &#214;ffentlichkeit (f&#246;g discussion paper, GL-2006-
0010). Online verf&#252;gbar unter https://www.foeg.uzh.ch/dam/jcr:00000000-13a2-35bc-0000-
00004655ac23/Politik_und_Medien.pdf, zuletzt abgerufen am 13.10.2020.
International Organization for Migration (2020): World migration report 2020. Geneva (World Migration 
Report). Online verf&#252;gbar unter https://www.un.org/sites/un2.un.org/files/wmr_2020.pdf, zuletzt
abgerufen am 13.10.2020.
Jarren, Otfried (2019): Medien- und &#214;ffentlichkeitswandel durch Social Media als gesellschaftliche 
Herausforderung wie als Forschungsfeld. In: Mark Eisenegger, Linards Udris und Patrik Ettinger (Hg.):
Wandel der &#214;ffentlichkeit und der Gesellschaft. Gedenkschrift f&#252;r Kurt Imhof. 1st ed. 2019, S. 349&#8211;376.
Jaursch, Julian (2019): Regulatorische Reaktionen auf Desinformation. Wie Deutschland und die EU
versuchen, gegen manipulative Meinungsmache auf digitalen Plattformen vorzugehen. Hg. v. Stiftung 
Neue Verantwortung. Berlin. Online verf&#252;gbar unter https://www.stiftung-
nv.de/sites/default/files/regulatorische_reaktionen_auf_desinformation.pdf, zuletzt abgerufen am
13.10.2020.
Jaursch, Julian (2020): Regeln f&#252;r faire digitale Wahlk&#228;mpfe: Welche Risiken mit politischer Onlinewerbung 
verbunden sind und welche Reformen in Deutschland n&#246;tig sind. Hg. v. Stiftung Neue Verantwortung. 
Berlin. Online verf&#252;gbar unter https://www.stiftung-nv.de/de/publikation/regeln-fuer-faire-digitale-
wahlkaempfe, zuletzt abgerufen am 13.10.2020.
Kaleta, Philip (2019): Experte &#252;ber Zalandos Evaluationssystem Zonar: &#8222;Unternehmen nutzen diese Tools
immer st&#228;rker&#8220;. Hg. v. businessinsider.de, zuletzt aktualisiert am
https://www.businessinsider.de/wirtschaft/zalando-and-zonar-mehr-unternehmen-nutzen-
evaluationstools-2019-11/, zuletzt abgerufen am 13.10.2020.
Kampa, Nele (2015): Mathematische Kompetenzen in Profiloberstufen in Schleswig-Holstein. In: IPN Bl&#228;tter
Informationen aus dem Leibniz-Institut f&#252;r die P&#228;dagogik der Naturwissenschaften und Mathematik 32, 
2015 (2/2015). Online verf&#252;gbar unter https://www.ipn.uni-kiel.de/de/das-ipn/archiv/ipnbl152s13.pdf, 
zuletzt abgerufen am 07.08.2020.
Karig, Friedemann (2015): Befallen vom &#220;berwachungsvirus. Hg. v. Deutschlandfunk.de. Online verf&#252;gbar
unter https://www.deutschlandfunk.de/staatliche-ueberwachung-befallen-vom-
ueberwachungsvirus.1184.de.html?dram:article_id=307639, zuletzt abgerufen am 14.10.2020.
Knoblauch, Hubert (2006): Sozialtechnologie, Soziologie und Rhetorik.
Knospe, Heiko (2011): Der Eingangstest Mathematik an Fachhochschulen in Nordrhein-Westfalen von 2002 
bis 2010. Online verf&#252;gbar unter https://docplayer.org/11992046-Der-mathematik-eingangstest-an-
fachhochschulen-in-nordrhein-westfalen.html, zuletzt abgerufen am 13.10.2020.
Konieczek-Woger, Magdalena; Naeth, Alexander (2020): Achtung: Smart! &#8211; M&#246;glichkeiten und Grenzen der
Idee der &#8222;Smart City&#8220; f&#252;r deutsche Kommunen. [Aktualisierte Version]. Berlin: Universit&#228;tsverlag der
TU Berlin (ISR Impulse Online, 66).
Kooroshy, Kaveh (2017): Amazon: Verst&#246;&#223;e gegen Mitarbeiterrechte. Hg. v. ndr.de. Online verf&#252;gbar unter
https://www.ndr.de/fernsehen/sendungen/panorama3/Amazon-Verstoesse-gegen-
Mitarbeiterrechte,amazon278.html, zuletzt abgerufen am 13.10.2020.
Kostner, Sandra (2019): Identit&#228;tslinke L&#228;uterungsagenda. Welche Folgen hat sie f&#252;r Migrationsgesellschaften?
In: Sandra Kostner, Stefan Luft und Elham Manea (Hg.): Identit&#228;tslinke L&#228;uterungsagenda. Eine Debatte
zu ihren Folgen f&#252;r Migrationsgesellschaften. Stuttgart: ibidem Verlag (Impulse, 1), S. 17&#8211;73.
Krafft, Tobias D.; Zweig, Katharina A. (2019): Transparenz und Nachvollziehbarkeit algorithmenbasierter
Entscheidungsprozesse. Ein Regulierungsvorschlag aus sozioinformatischer Perspektive. 
Hg. v. Verbraucherzentrale Bundesverband (vzbv). Online verf&#252;gbar unter
https://www.vzbv.de/sites/default/files/downloads/2019/05/02/19-01-22_zweig_krafft_transparenz_adm-
neu.pdf, zuletzt abgerufen am 13.10.2020.
Krempl, Stefan (2018): CCC: Bundespolizei hat Bericht zur Gesichtserkennung absichtlich gesch&#246;nt. 
Hg. v. heise.de. Online verf&#252;gbar unter https://www.heise.de/newsticker/meldung/CCC-Bundespolizei-
hat-Bericht-zur-Gesichtserkennung-absichtlich-geschoent-4191216.html, zuletzt abgerufen am
14.10.2020.
Kr&#246;smann, Christoph; Wei&#223;, Rebekka (2020): Jedes 2. Unternehmen verzichtet aus Datenschutzgr&#252;nden auf
Innovationen. Hg. v. bitkom. Online verf&#252;gbar unter
https://www.bitkom.org/Presse/Presseinformation/Jedes-2-Unternehmen-verzichtet-aus-
Datenschutzgruenden-auf-Innovationen, zuletzt abgerufen am 13.10.2020.
Krotz, Friedrich (1998): Stichwort Gegen&#246;ffentlichkeit. In: Otfried Jarren, Ulrich Sarcinelli und Ulrich Saxer
(Hg.): Politische Kommunikation in der demokratischen Gesellschaft. Ein Handbuch mit Lexikonteil. 
Wiesbaden: VS Verlag f&#252;r Sozialwissenschaften.
Krupka, Daniel (2020): Gesellschaft f&#252;r Informatik kritisiert &#8222;Datenspende-App&#8220; des Robert-Koch-Instituts. 
Online verf&#252;gbar unter https://www.wissenschaftsregion-bonn.de/news-termine/news/news-
details/pm7282-gesellschaft-fuer-informatik-kritisiert-datenspende-app-des-robert-koch-instituts/, zuletzt 
abgerufen am 13.10.2020.
Kurzweil, Ray (2014): Menschheit 2.0. Die Singularit&#228;t naht [2005]. Aus dem Englischen von Martin 
R&#246;tzschke. 2. Aufl. Berlin: Lola Books.
Kutsch, Arnulf (1999): Rundfunk unter alliierter Besatzung. In: J&#252;rgen Wilke (Hg.): Mediengeschichte der
Bundesrepublik Deutschland. K&#246;ln: B&#246;hlau Verlag, S. 59&#8211;90.
Land Brandenburg, Ministerium f&#252;r Bildung, Jugend und Sport (2015/2016): Pr&#252;fung am Ende der
Jahrgangsstufe 10. Mathematik. Online verf&#252;gbar unter https://bildungsserver.berlin-
brandenburg.de/fileadmin/bbb/unterricht/pruefungen/pruefungen_am_ende_der_jahrgangsstufe_10/16_P 
10_Gym_Ma_A.pdf, zuletzt abgerufen am 13.10.2020.
Lange, Steffen; Santarius, Tilmann (2018): Smarte gr&#252;ne Welt? Digitalisierung zwischen &#220;berwachung, 
Konsum und Nachhaltigkeit. M&#252;nchen: oekom.
Latour, Bruno (2006): &#220;ber technische Vermittlung: Philosophie, Soziologie und Genealogie [1994]. 
In: Andr&#233;a Belliger und David Krieger (Hg.): ANThology. Ein einf&#252;hrendes Handbuch zur Akteur-
Netzwerk-Theorie. transcript: Bielefeld, S. 483&#8211;528.
Lazer, David; Kennedy, Ryan (2015): What We Can Learn From the Epic Failure of Google Flu Trends. 
Hg. v. wired.com. Online verf&#252;gbar unter https://www.wired.com/2015/10/can-learn-epic-failure-
google-flu-trends/, zuletzt abgerufen am 13.10.2020.
Lee, Kai-Fu (2019): AI Superpowers. China, Silicon Valley und die neue Weltordnung [2017]. Aus dem
Englischen von Jan W. Haas. Frankfurt am Main, New York: Campus.
Lindemann, Florian (2019): Digitale Vernetzung und (Cyber-)Sicherheit &#8211; unl&#246;sbarer Widerspruch oder zwei
Seiten einer Medaille? F&#252;r ein neues Zusammenspiel von Staat, Wirtschaft und Gesellschaft. In:
Christian Vogt, Christian Endre&#223; und Patrick Peters (Hg.): Wirtschaftsschutz in der Praxis. Positionen 
zur Unternehmenssicherheit und Kriminalpr&#228;vention in der Wirtschaft. 1st ed. 2019 (Sicherheit &#8211;
interdisziplin&#228;re Perspektiven), S. 87&#8211;113.
Linder, Fabian (2019): Das neue magische Viereck der Wirtschaftspolitik. Update, 2014 &#8211; 2018. Hg. v. Hans
B&#246;ckler Stiftung. D&#252;sseldorf (IMK Reprt, 153). Online verf&#252;gbar unter
https://www.boeckler.de/pdf/p_imk_report_153_2019.pdf, zuletzt abgerufen am 14.10.2020.
Lischka, Konrad; Klingel, Anita (2017): Wenn Maschinen Menschen bewerten. Internationale Fallbeispiele f&#252;r
Prozesse algorithmischer Entscheidungsfindung. Impuls Algorithmenethik #1. Hg. v. Bertelsmann 
Stiftung. G&#252;tersloh. Online verf&#252;gbar unter https://algorithmenethik.de/wp-
content/uploads/sites/10/2018/02/ADM-Fallstudien-1.pdf, zuletzt abgerufen am 13.10.2020.
Littmann, J&#246;rg (2017): &#167; 31a SGB X. In: Karl Hauck, Wolfgang Noftz und Peter Becker (Hg.): Hauck/Noftz
Modul SGB X: Verwaltungsverfahren, Schutz der Sozialdaten, Zusammenarbeit der Leistungstr&#228;ger und 
ihre Beziehungen zu Dritten &#8211; Jahresabonnement. SGBdigital &#8211; Fachwissen Sozialrecht. Berlin: Erich
Schmidt.
Lobe, Adrian (2018): Computer sind nicht nur besser als Menschen. Sie wissen auch besser, was gut und was 
b&#246;se ist. In: nzz.ch, 16. Juni 2018. Online verf&#252;gbar unter https://www.nzz.ch/feuilleton/computer-sind-
nicht-nur-besser-als-menschen-sie-wissen-auch-besser-was-gut-und-was-boese-ist-ld.1394510, zuletzt 
abgerufen am 13.10.2020.
Lobe, Adrian (2019): Wie Technologiekonzerne die Stadt optimieren wollen. In: sz.de, 12. Januar 2019. Online
verf&#252;gbar unter https://www.sueddeutsche.de/digital/smart-cities-algorithmen-daten-stadtplanung-
1.4277905, zuletzt abgerufen am 13.10.2020.
Luhmann, Niklas (1991): Soziologie des Risikos. Berlin, New York: de Gruyter.
Luhmann, Niklas (1996): Die Wirtschaft der Gesellschaft [1994]. 2. Aufl. Frankfurt am Main: Suhrkamp.
Luthe, Ernst-Wilhelm (2017): &#167; 31a SGB X. In: Rainer Schlegel und Thomas Voelzke (Hg.): Juris
Praxiskommentar SGB X. 2. Aufl.
Luthe, Ernst-Wilhelm (2017): Der vollst&#228;ndig automatisierte Erlass eines Verwaltungsakts nach &#167; 31a SGB X. 
In: Die Sozialgerichtsbarkeit Zeitschrift f&#252;r das aktuelle Sozialrecht 05, S. 250&#8211;258.
Macpherson, Lisa (2020): The Pandemic Proves We Need A &#8218;Superfund&#8216; to Clean Up Misinformation on the
Internet. Hg. v. Public Knowledge. Online verf&#252;gbar unter https://www.publicknowledge.org/blog/the-
pandemic-proves-we-need-a-superfund-to-clean-up-misinformation-on-the-internet/, zuletzt abgerufen
am 13.10.2020.
Mandelbrot, Benoit B.; Hudson, Richard L. (2005): Fraktale und Finanzen &#8211; M&#228;rkte zwischen Risiko, Rendite
und Ruin. M&#252;nchen: Piper.
March, James G. (1990): Beschr&#228;nkte Rationalit&#228;t, Ungewi&#223;heit und die Technik der Auswahl [1978]. In:
James G. March (Hg.): Entscheidung und Organisation. Kritische und konstruktive Beitr&#228;ge, 
Entwicklungen und Perspektiven. Wiesbaden: Gabler, S. 297&#8211;328.
Martini, Mario (2019): Blackbox Algorithmus &#8211; Grundfragen einer Regulierung K&#252;nstlicher Intelligenz. Unter
Mitarbeit von Michael Kolain und Jan Mysegades. Berlin: Springer.
Martini, Mario (2019): Grundlinien eines Kontrollsystems f&#252;r algorithmenbasierte Entscheidungsprozesse. 
Gutachten im Auftrag des Verbraucherzentrale Bundesverbands. Online verf&#252;gbar unter
https://www.vzbv.de/sites/default/files/downloads/2019/07/17/martini_-_adm-kontrollsystem_2.pdf, 
zuletzt abgerufen am 14.10.2020.
Martini, Mario; Nink, David (2017): Wenn Maschinen entscheiden&#8230; &#8211; vollautomatisierte
Verwaltungsverfahren und der Pers&#246;nlichkeitsschutz. In: NVwZ 2017 (10), S. 1&#8211;14.
Mason, Paul (2016): Postkapitalismus. Grundrisse einer kommenden &#214;konomie [2015]. Aus dem Englischen 
von Stephan Gebauer. Berlin: Suhrkamp.
Matthes, Marie-Charlotte (2018): K&#252;nstliche Intelligenz in der Verwaltung: IFG Beauftragte von Bund und 
L&#228;ndern fordern Transparenz. Hg. v. Netzpolitik.org. Online verf&#252;gbar unter
https://netzpolitik.org/2018/kuenstliche-intelligenz-in-der-verwaltung-ifg-beauftragte-von-bund-und-
laendern-fordern-transparenz/, zuletzt abgerufen am 14.10.2020.
Mau, Steffen (2017): Das metrische Wir. &#220;ber die Quantifizierung des Sozialen. Berlin: Suhrkamp.
Mazzucato, Mariana (2019): Der unternehmerische Staat. Risiken und Gewinne vergesellschaften.
In: Leviathan (47,2), S. 123&#8211;143.
Mazzucato, Mariana (2019): Wie kommt der Wert in die Welt? Von Sch&#246;pfern und Absch&#246;pfern [2018]. 
Aus dem Englischen von Bernhard Schmid. Frankfurt, New York: Campus.
Mertens, Jannik (2018): EU und Berlin planen mehr Gesichtserkennung in polizeilich genutzten Datenbanken.
Hg. v. Netzpolitik.org. Online verf&#252;gbar unter https://netzpolitik.org/2018/eu-und-berlin-planen-mehr-
gesichtserkennung-in-polizeilich-genutzten-datenbanken/, zuletzt abgerufen am 14.10.2020.
Meyer, Robert D. (2018): Moderne Dolchsto&#223;legende. Warum Angela Merkel im Sommer 2015 nicht die
Grenzen &#246;ffnete, und Bild-Chef Julian Reichelt besser nicht an diese Zeit erinnert werden will. In: 
neues-deutschland.de, 21. Juni 2018. Online verf&#252;gbar unter https://www.neues-
deutschland.de/artikel/1091926.mythos-von-der-grenzoeffnung-moderne-dolchstosslegende.html, 
zuletzt abgerufen am 13.10.2020.
Meyerhoff, Jan (2016): Evolutions&#246;konomik. Hg. v. exploring-economics.org. Online verf&#252;gbar unter
https://www.exploring-economics.org/de/orientieren/evolutionsoekonomik/, zuletzt abgerufen am
13.10.2020.
Mink, Marion (2015): In Helsinki ersetzt ein Mega-Sauger die M&#252;llabfuhr. In: welt.de, 17. Juli 2015. Online
verf&#252;gbar unter https://www.welt.de/wissenschaft/article144138817/In-Helsinki-ersetzt-ein-Mega-
Sauger-die-, zuletzt abgerufen am 13.10.2020.
Misik, Robert (2019): Die falschen Freunde der einfachen Leute. Berlin: Suhrkamp.
Molnar, Petra; Gill, Lex (2018): Bots at the Gate. A Human Rights Analysis of Automated Decision Making in
Canada&#8217;s Immigration and Refugee System. Online verf&#252;gbar unter https://citizenlab.ca/wp-
content/uploads/2018/09/IHRP-Automated-Systems-Report-Web-V2.pdf, zuletzt abgerufen am
13.10.2020.
Monroy, Matthias (2018): &#8222;Gemeinsamer Identit&#228;tsspeicher&#8220;: Biometrische Daten landen in europ&#228;ischem
Datentopf. Hg. v. Netzpolitik.org. Online verf&#252;gbar unter https://netzpolitik.org/2018/gemeinsamer-
identitaetsspeicher-biometrische-daten-landen-in-europaeischem-datentopf/, zuletzt abgerufen am
14.10.2020.
Moody, Kim: Schnelle Technologie, langsames Wachstum. Roboter und die Zukunft der Arbeit [2018]. 
In: Florian Butollo und Sabine Nuss (Hg):  Marx und die Roboter. Vernetzte Produktion, K&#252;nstliche
Intelligenz und lebendige Arbeit. Berlin: Dietz, S. 132-155.
Morawietz, Holger (2019): Alternative Fakten, Fake-News und L&#252;gen mit dem Internet einfach enttarnen.
In: Wilfried K&#252;rschner (Hg.): Alternative Fakten, Fake News und Verwandtes. Wissenschaft und 
&#214;ffentlichkeit (Vechtaer Universit&#228;tsschriften).
Morozov, Evgeny (2020): Digitale &#246;ffentliche Infrastruktur. Das sozialdemokratische Projekt des
21. Jahrhunderts (WISO Direkt, 4/2020). Online verf&#252;gbar unter http://library.fes.de/pdf-
files/wiso/16163.pdf, zuletzt abgerufen am 14.10.2020.
Morozov, Evgeny; Bria, Francesca (2017): Die smarte Stadt neu denken. Wie urbane Technologien 
demokratisiert werden k&#246;nnen. Berlin: Rosa-Luxemburg-Stiftung.
Nachtwey, Oliver (2017): Die Abstiegsgesellschaft. &#220;ber das Aufbegehren in der regressiven Moderne [2016].
7. Aufl. Berlin: Suhrkamp.
Nachtwey, Oliver; Seidl, Timo (2017): Die Ethik der Solution und der Geist des Digitalen Kapitalismus. IfS
Working Paper #11. Hg. v. Institut f&#252;r Sozialforschung. Frankfurt am Main. Online verf&#252;gbar unter
http://www.ifs.uni-frankfurt.de/wp-content/uploads/IfS-WP-11.pdf, zuletzt abgerufen am 13.10.2020.
Nassehi, Armin (2019): Muster. Theorie der digitalen Gesellschaft. M&#252;nchen: C. H. Beck.
Nesvetailova, Anastasia (2010): Financial Alchemy in Crises &#8211; The Great Liquidity Illusion. New York: Pluto 
Press.
OECD (2020): Statement by the OECD/G20 Inclusive Framework on BEPS on the Two-Pillar Approach to 
Address the Tax Challenges Arising from the Digitalisation of the Economy. &#8211; January 2020, 
OECD/G20 Inclusive Framework on BEPS, OECD. Paris. Online verf&#252;gbar unter
http://www.oecd.org/tax/beps/statement-by-the-oecd-g20-inclusive-framework-on-beps-january-
2020.pdf, zuletzt abgerufen am 16.10.2020.
Pasquale, Frank (2015): The Black Box Society. The Secret Algorithms that Control Money and Information. 
Cambridge, London: Harvard University Press.
Perrault, Raymond; Shoham, Yoav; Brynjolfsson, Erik; Clark, Jack; Etchemendy, John; Grosz, Barbara et al. 
(2019): The AI Index 2019 Annual Report. Hg. v. Stanford University. Online verf&#252;gbar unter
https://hai.stanford.edu/sites/default/files/ai_index_2019_report.pdf, zuletzt abgerufen am 07.08.2020.
Pfeiffer, Sabine (2019): Digitale Transformation: Great, greater, tilt &#8230;? Von der Produktivkraft- zur
Distributivkraftentwicklung. In: Klaus D&#246;rre, Hartmut Rosa, Karina Becker, Sophie Bose und Benjamin 
Seyd (Hg.): Gro&#223;e Transformation? Zur Zukunft moderner Gesellschaften. Sonderband des Berliner
Journals f&#252;r Soziologie. Wiesbaden: Springer VS, S. 383&#8211;399.
Piketty, Thomas (2014): Das Kapital im 21. Jahrhundert [2013]. Aus dem Franz&#246;sischen von Ilse Utz und 
Stefan Lorenzer. 2. Aufl. M&#252;nchen: C. H. Beck.
Pimminger, Irene; Bergmann, Nadja (2020): Gleichstellungsrelevante Aspekte der Digitalisierung der
Arbeitswelt in Deutschland. Expertise f&#252;r den Dritten Gleichstellungsbericht der Bundesregierung. 
Online verf&#252;gbar unter https://www.dritter-
gleichstellungsbericht.de/kontext/controllers/document.php/104.2/1/822c6a.pdf, zuletzt abgerufen am
13.10.2020.
Piron, Rebecca (2020): Neue Open Data-Plattform soll den Weg zur Smart City ebnen. Online verf&#252;gbar unter
https://kommunal.de/neue-open-data-plattform-soll-den-weg-zur-smart-city-ebnen, zuletzt abgerufen am
13.10.2020.
Plickert, Philip (2020): Die Briten und der Rundfunkwettbewerb. In: FAZ, 29. Juli 2020, S. 15.
Pohle, Julia (2020): Digitale Souver&#228;nit&#228;t. In: Tanja Klenk, Frank Nullmeier und G&#246;ttrik Wever (Hg.):
Handbuch Digitalisierung in Staat und Verwaltung. Wiesbaden: Springer VS.
Ponattu, Dominic; Sachs, Andreas; Weinelt, Heidrun; Sieling, Alexander (2018): Unternehmenskonzentration 
und Lohnquote in Deutschland. Eine Analyse auf Branchenebene zwischen 2008 und 2016. 
Hg. v. Bertelsmann Stiftung. Online verf&#252;gbar unter https://www.bertelsmann-
stiftung.de/fileadmin/files/BSt/Publikationen/GrauePublikationen/Studie_BST_PIW01_07lay_RB.pdf,
zuletzt abgerufen am 13.10.2020.
Positionspapier der CDU/CSU-Fraktion im Deutschen Bundestag (2020): Datenstrategie der Bundesregierung. 
Online verf&#252;gbar unter https://www.cducsu.de/sites/default/files/2020-
05/Positionspapier_zur_Datenstrategie.pdf.
Powell, James Lawrence (2015): Climate Scientists Virtually Unanimous. In: Bulletin of Science, Technology
&amp; Society 35 (5-6), S. 121&#8211;124. 
Powell, James Lawrence (2016): The Consensus on Anthropogenic Global Warming Matters. In: Bulletin of
Science, Technology &amp; Society 36 (3), S. 157&#8211;163.
Pr&#252;fer, Jens (2020): Die Datenteilungspflicht. Innovation und fairer Wettbewerb auf datengetriebenen M&#228;rkten. 
Hg. v. Friedrich Ebert Stiftung. Bonn. Online verf&#252;gbar unter http://library.fes.de/pdf-
files/fes/15990.pdf, zuletzt abgerufen am 14.10.2020.
pwc (2018): Auswirkungen der Nutzung von k&#252;nstlicher Intelligenz in Deutschland. Online verf&#252;gbar unter
https://www.pwc.de/de/business-analytics/sizing-the-price-final-juni-2018.pdf.
Raji, Inioluwa Deborah; Buolamwini, Joy (2019): Actionable Auditing: Investigating the Impact of Publicly
Naming Biased Performance Results of Commercial AI Products. Hg. v. Association for the
Advancement of Artificial Intelligence. Online verf&#252;gbar unter https://www.aies-
conference.com/2019/wp-content/uploads/2019/01/AIES-19_paper_223.pdf, zuletzt abgerufen am
14.10.2020.
Rammert, Werner (2017): Technik und Innovation. In: Andrea Maurer (Hg.): Handbuch der
Wirtschaftssoziologie. Wiesbaden: Springer VS, S. 415&#8211;441.
Reckwitz, Andreas (2018): Die Gesellschaft der Singularit&#228;ten. Zum Strukturwandel der Moderne [2017].
5. Aufl. Berlin: Suhrkamp.
Reckwitz, Andreas (2020): Das Ende der Illusionen. Politik, &#214;konomie und Kultur in der Sp&#228;tmoderne [2019]. 
5. Aufl. Berlin: Suhrkamp.
Reveland, Carla (2015): Patrick Gensing: &#8220;Medien d&#252;rfen keine &#196;ngste sch&#252;ren&#8220;. Hg. v. vocer.org. Online
verf&#252;gbar unter https://www.vocer.org/patrick-gensing-medien-duerfen-keine-aengste-schueren/, zuletzt
abgerufen am 13.10.2020.
Roos, Ute (2016): Studie belegt Selbstzensur von Internetnutzern nach Snowden-Enth&#252;llungen. Hg. v. heise.de. 
Online verf&#252;gbar unter https://www.heise.de/ix/meldung/Studie-belegt-Selbstzensur-von-
Internetnutzern-nach-Snowden-Enthuellungen-3194816.html, zuletzt abgerufen am 14.10.2020.
Sachverst&#228;ndigen Rat f&#252;r Verbraucherfragen (2018): Technische und rechtliche Betrachtungen algorithmischer
Entscheidungsverfahren. Gutachten der Fachgruppe Rechtsinformatik der Gesellschaft f&#252;r
Informatik e. V. im Auftrag des Sachverst&#228;ndigenrats f&#252;r Verbraucherfragen. Online verf&#252;gbar unter
https://www.svr-verbraucherfragen.de/wp-content/uploads/GI_Studie_Algorithmenregulierung.pdf, 
zuletzt abgerufen am 14.10.2020.
Sachverst&#228;ndigen Rat f&#252;r Verbraucherfragen (2018): Verbrauchergerechtes Scoring. Gutachten des
Sachverst&#228;ndigenrats f&#252;r Verbraucherfragen. Online verf&#252;gbar unter http://www.svr-
verbraucherfragen.de/wp-content/uploads/SVRV_, zuletzt abgerufen am 14.10.2020.
Sahr, Aaron (2018): Ungleichheit auf Knopfdruck. Die Spielregeln des Keystroke-Kapitalismus [2017]. Bonn:
Sonderausgabe f&#252;r die Bundeszentrale f&#252;r politische Bildung.
Salder, Frank (2020): Kommunale Videosicherheitstechnik im Aufbruch: von der Verbrechensbek&#228;mpfung 
zum &#8222;Smart-City-Sensor&#8220;. In: Chirine Etezadzadeh (Hg.): Smart City &#8211; Made in Germany. Die Smart-
City-Bewegung als Treiber einer gesellschaftlichen Transformation. 1st ed. 2020, S. 717&#8211;726.
Schallbruch, Martin (2018): Schwacher Staat im Netz. Wie die Digitalisierung den Staat in Frage stellt.
Wiesbaden: Springer.
Schaupp, Simon; Jochum, Georg (2019): Die Steuerungswende. Zur M&#246;glichkeit einer nachhaltigen und 
demokratischen Wirtschaftsplanung im digitalen Zeitalter. In: Florian Butollo und Sabine Nuss (Hg.):
Marx und die Roboter. Vernetzte Produktion, K&#252;nstliche Intelligenz und lebendige Arbeit. Berlin: Dietz, 
S. 327&#8211;344.
Scheer, Ursula (2016): Alle sind willkommen. Studie stellt dar, wie &#252;ber Fl&#252;chtlinge berichtet wird. In: FAZ, 
August 2016 (184), S. 17.
Scheer, Ursula (2017): Wie Medien &#252;ber die Fl&#252;chtlingskrise berichteten. In: faz.net, 12. Juli 2017. Online
verf&#252;gbar unter https://www.faz.net/aktuell/feuilleton/debatten/fluechtlingskrise-so-berichteten-die-
medien-15115172.html, zuletzt abgerufen am 13.10.2020.
Schick, Catharina (2017): Fake News aufsp&#252;ren und aufkl&#228;ren. Gezielte Falschmeldungen eind&#228;mmen: Die
ARD gr&#252;ndet das Online-Portal &#8222;faktenfinder&#8220; zur Aufkl&#228;rung von Fake News. In: tagesspiegel.de, 
03. April 2017. Online verf&#252;gbar unter https://www.tagesspiegel.de/gesellschaft/medien/ard-gruendet-
faktenfinder-fake-news-aufspueren-und-aufklaeren/19608588.html, zuletzt abgerufen am 13.10.2020.
Schrape, Jan-Felix (2018): Open-Source-Communities: Die soziotechnische Verstetigung kollektiver
Inventionen. In: Ulrich Dolata und Jan-Felix Schrape (Hg.): Kollektivit&#228;t und Macht im Internet. Soziale
Bewegungen &#8211; Open Source Communities &#8211; Internetkonzerne. Wiesbaden: Springer VS, S. 71&#8211;100.
Schr&#246;der, Carsten; Bartels, Charlotte; G&#246;bler, Konstantin; Grabka, Markus M.; K&#246;nig, Johannes (2020):
Million&#228;rInnen unter dem Mikroskop: Datenl&#252;cke bei sehr hohen Verm&#246;gen geschlossen &#8211;
Konzentration h&#246;her als bisher ausgewiesen (DIW Wochenbericht, 29). Online verf&#252;gbar unter
https://www.bpb.de/system/files/dokument_pdf/Schubert,%20Klein%20-%20Das%20Politiklexikon.pdf, 
zuletzt abgerufen am 13.10.2020.
Schubert, Klaus; Klein, Martina (2011): Das Politiklexikon. Begriffe, Fakten, Zusammenh&#228;nge. Bonn:
BpB (Schriftenreihe / Bundeszentrale f&#252;r Politische Bildung, Bd. 1174). Online verf&#252;gbar unter
https://www.bpb.de/system/files/dokument_pdf/Schubert,%20Klein%20-%20Das%20Politiklexikon.pdf, 
zuletzt abgerufen am 13.10.2020.
Schumpeter, Joseph A. (2013): Theorie der wirtschaftlichen Entwicklung. Eine Untersuchung &#252;ber
Unternehmergewinn, Kapital, Kredit, Zins und den Konjunkturzyklus. 9. Aufl. Berlin: Duncker &amp;
Humblot.
Siebenhaar, Hans-Peter (2012): Die Nimmersatten. Die Wahrheit &#252;ber das System ARD und ZDF. [1.,teilw., 
geschw&#228;rzte Aufl.]. K&#246;ln: Eichborn.
Simon, Herbert A. (1994): Die Wissenschaft vom K&#252;nstlichen [1969, 1981]. 2. Aufl. Wien, New York:
Springer.
Smith, Brad (2018): Facial recognition: It&#8217;s time for action. Hg. v. blogs.microsoft.com. Online verf&#252;gbar unter
https://blogs.microsoft.com/on-the-issues/2018/12/06/facial-recognition-its-time-for-action/, zuletzt 
abgerufen am 14.10.2020.
Spiegel.de (2020): Chaos Computer Club findet Schwachstellen in &#8222;Corona-Datenspende&#8220;, 21. April 2020. 
Online verf&#252;gbar unter https://www.spiegel.de/netzwelt/apps/corona-datenspende-chaos-computer-club-
findet-schwachstellen-in-app-a-8d19fc6d-7138-4283-a62d-420c93f5743b, zuletzt abgerufen am
13.10.2020.
Spindler, Gerald (2015): Roboter, Automation, k&#252;nstliche Intelligenz, selbst-steuernde Kfz &#8211; Braucht das Recht
neue Haftungskategorien? In: CR, S. 766&#8211;776, zuletzt abgerufen am 14.10.2020.
Staab, Philipp (2019): Digitaler Kapitalismus. Markt und Herrschaft in der &#214;konomie der Unknappheit. Berlin:
Suhrkamp.
Staab, Philipp; Nachtwey, Oliver (2016): Digitalisierung der Dienstleistungsarbeit. In: Aus Politik und 
Zeitgeschichte 66 (18-19). Online verf&#252;gbar unter
https://www.bpb.de/system/files/dokument_pdf/APuZ_2016-18-19_online.pdf, S. 24&#8211;31, zuletzt
abgerufen am 13.10.2020.
Staab, Philipp; Prediger, Lena J. (2019): Digitalisierung und Polarisierung &#8211; Eine Literaturstudie zu den 
Auswirkungen des digitalen Wandels auf Sozialstruktur und Betriebe. FGW-Studie Digitalisierung von 
Arbeit 19. Hg. v. Hartmut Hirsch-Kreinsen und Anemari Kara&#269;i&#263;. D&#252;sseldorf. Online verf&#252;gbar unter
http://www.fgw-nrw.de/fileadmin/user_upload/FGW-Studie-I40-19-Staab-2019_07_16-komplett-
web.pdf, zuletzt abgerufen am 13.10.2020.
Star, Susan; Ruhleder, Karin: Schritte zu einer &#214;kologie von Infrastruktur. Design und Zugang f&#252;r
gro&#223;angelegte Informationsr&#228;ume [1995/1996]. In: Star, Susan Leigh: Grenzobjekte und 
Medienforschung. Hg. v. Sebastian Grie&#223;mann und Nadine Taha. Bielefeld: transcript, S. 359&#8211;402.
Stark, Birgit; Magin, Melanie (2019): Neuer Strukturwandel der &#214;ffentlichkeit durch 
Informationsintermedi&#228;re: Wie Facebook, Google &amp; Co. die Medien und den Journalismus ver&#228;ndern. 
In: Mark Eisenegger, Linards Udris und Patrik Ettinger (Hg.): Wandel der &#214;ffentlichkeit und der
Gesellschaft. Gedenkschrift f&#252;r Kurt Imhof. 1st ed. 2019.
Statistisches Bundesamt (2020): Wanderungen zwischen Deutschland und dem Ausland 1991 bis 2019. Online
verf&#252;gbar unter https://www.destatis.de/DE/Themen/Gesellschaft-
Umwelt/Bevoelkerung/Wanderungen/Tabellen/wanderungen-alle.html, zuletzt abgerufen am
13.10.2020.
Stein, Melanie (2017): Big Data: Gefahren f&#252;r Journalisten. In: ndr.de, 2017. Online verf&#252;gbar unter
https://www.ndr.de/nachrichten/netzwelt/Big-Data-Gefahren-fuer-Journalisten,spiegelmining104.html, 
zuletzt abgerufen am 13.10.2020.
Steinwandter, Lukas (2019): Rupert Scholz wirft Regierung andauernden Verfassungsbruch vor. 
In: jungefreiheit.de, 20. Juni 2019 (26/19). Online verf&#252;gbar unter
https://jungefreiheit.de/politik/deutschland/2019/rupert-scholz-wirft-regierung-andauernden-
verfassungsbruch-vor/, zuletzt abgerufen am 13.10.2020.
Stiftung Neue Verantwortung (2018): Transkript zum Hintergrundgespr&#228;ch &#8222;Predictive Policing in
Deutschland&#8220;. Online verf&#252;gbar unter https://www.stiftung-nv.de/de/publikation/transkript-zum-
hintergrundgespraech-predictive-policing-deutschland#collapse-newsletter_banner_bottom, zuletzt
abgerufen am 14.10.2020.
Stiglitz, Joseph; Sen, Amartya; Fitoussi, Jean Paul (2009): The Measurement of Economic Performance and
Social Progress Revisited. Hg. v. OFCE &#8211; Centre de recherche en &#233;conomie de Sciences Po. Paris.
Online verf&#252;gbar unter
https://www.researchgate.net/publication/239807212_The_Measurement_of_Economic_Performance_a 
nd_Social_Progress_Revisited_The_Measurement_of_Economic_Performance_and_Social_Progress_R 
evisited_Commission_on_the_Measurement_of_Economic_Performance_and_So, zuletzt abgerufen am
13.10.2020.
S&#252;dekum, Jens (2018): Digitalisierung und die Zukunft der Arbeit. WPZ-Analyse Nr. 19. Online verf&#252;gbar
unter http://www.wpz-fgn.com/wp-content/uploads/PA19DigitalisierungZukunftArbeit20180726.pdf, 
zuletzt abgerufen am 13.10.2020.
S&#252;dekum, Jens (2018): Digitalisierung und die Zukunft der Arbeit: Was ist am Arbeitsmarkt passiert und wie
soll die Wirtschaftspolitik reagieren? IZA Standpunkte Nr. 90. Hg. v. IZA &#8211; Institute of Labor
Economics. Online verf&#252;gbar unter http://ftp.iza.org/sp90.pdf, zuletzt abgerufen am 13.10.2020.
S&#252;dekum, Jens; Stiebale, Joel; W&#246;ssner, Nicole (2020): Roboter und der Aufstieg europ&#228;ischer Superstar-
Firmen. Hg. v. inclusive productivity. Online verf&#252;gbar unter https://inclusive-productivity.de/roboter-
und-der-aufstieg-europaeischer-superstar-firmen/, zuletzt abgerufen am 13.10.2020.
Texas Center for Educational Research (2009): Evaluation of the Texas Technology Immersion Pilot. Final
Outcomes for a Four-Year Study (2004-05 to 2007-08). Online verf&#252;gbar unter
https://files.eric.ed.gov./fulltext/ED536296.pdf, zuletzt abgerufen am 13.10.2020.
The Shift Project (2019): Lean ICT: Towards digital sobriety. Online verf&#252;gbar unter
https://theshiftproject.org/wp-content/uploads/2019/03/Lean-ICT-Report_The-Shift-Project_2019.pdf, 
zuletzt abgerufen am 13.10.2020.
Thiel, Peter (2014): Competition Is for Losers. If you want to create and capture lasting value, look to build a
monopoly. In: Wall Street Journal, 12. September 2014. Online verf&#252;gbar unter
https://www.wsj.com/articles/peter-thiel-competition-is-for-losers-1410535536, zuletzt abgerufen am
14.10.2020.
Triana, Pablo (2009): Lecturing Birds on Flying &#8211; Can Mathematical Theories Destroy the Financial Markets.
New Jersey: John Wiley &amp; Sons.
Trist, Eric L.: Sozio-technische Systeme. In: Bennis, Warren G.; Benne, Kenneth D; Chin, Robert (Hg.):
&#196;nderung des Sozialverhaltens. Stuttgart: Ernst Klett, S. 201&#8211;218.
TU Chemnitz (2015): Ein Hintergrundgespr&#228;ch zum Migrations-Artikel im Focus. Online verf&#252;gbar unter
https://www.tu-
chemnitz.de/hsw/psychologie/professuren/entwpsy/team/rindermann/pdfs/HintergrundFocusRindermann 
.pdf, zuletzt abgerufen am 13.10.2020.
Umweltbundesamt (2020): Umweltbewusstsein in Deutschland. Online verf&#252;gbar unter
https://www.umweltbundesamt.de/themen/nachhaltigkeit-strategien-internationales/gesellschaft-
erfolgreich-veraendern/umweltbewusstsein-in-deutschland, zuletzt abgerufen am 20.10.2020.
ver.di (20.11.2019): ver.di kritisiert System permanenter digitaler Leistungskontrollen und Ratings bei Zalando. 
Online verf&#252;gbar unter https://www.verdi.de/presse/pressemitteilungen/++co++8777f162-0b79-11ea-
a0a2-525400940f89, zuletzt abgerufen am 13.10.2020.
Verbraucherzentrale Bundesverband (2019): Algorithmenkontrolle. Positionspapier des Verbraucherzentrale
Bundesverbands. Online verf&#252;gbar unter https://www.vzbv.de/sites/default/files/downloads/2019/05/02/19-
05-02_vzbv_positionspapier_algorithmenkontrolle.pdf zuletzt abgerufen am 14.10.2020.
Villani, C&#233;dric (2018): For a Meaningful Artificial Intelligence &#8211; Towards a French and European Strategy. 
Online verf&#252;gbar unter https://www.aiforhumanity.fr/pdfs/MissionVillani_Report_ENG-VF.pdf, zuletzt
abgerufen am 13.10.2020.
Vosgerau, Ulrich (2018): Hat sie, oder hat sie nicht? In: jungefreiheit.de, 22. Juni 2018. Online verf&#252;gbar unter
https://jungefreiheit.de/debatte/kommentar/2018/hat-sie-oder-hat-sie-nicht/, zuletzt abgerufen am
13.10.2020.
Weizenbaum, Joseph (1986): Ohne uns geht&#8217;s nicht weiter. K&#252;nstliche Intelligenz und Verantwortung der
Wissenschaft. In: Bl&#228;tter f&#252;r deutsche und internationale Politik Sonderdruck Nr. 332 (9).
welt.de (2015): OECD: Keine besseren Leistungen durch Rechner an Schulen. In: welt.de, 15. September 2015. 
Online verf&#252;gbar unter https://www.welt.de/newsticker/news1/article146423435/OECD-Keine-besseren-
Leistungen-durch-Rechner-an-Schulen.html, zuletzt abgerufen am 13.10.2020.
Wendt, Heike; Bos, Wilfried; Selter, Christoph; K&#246;ller, Olaf; Schwippert, Knut; Kasper, Daniel (2016): TIMSS
2015. Mathematische und naturwissenschaftliche Kompetenzen von Grundschulkindern in Deutschland 
im internationalen Vergleich. M&#252;nster, New York: Waxmann Verlag. Online verf&#252;gbar unter
http://www.content-select.com/index.php?id=bib_view&amp;ean=9783830985662.
Wiarda, Jan-Martin (2015): Bildungs&#246;konom: Bildungsstand der Fl&#252;chtlinge niedriger als vermutet. Online
verf&#252;gbar unter https://www.jmwiarda.de/2015/11/19/bildungs%C3%B6konom-bildungsstand-der-
fl%C3%BCchtlinge-niedriger-als-vermutet/, zuletzt abgerufen am 13.10.2020.
Wirtschaftsrat der CDU e.V (2020): Rahmenbedingungen f&#252;r K&#252;nstliche Intelligenz in der EU:
Chancenorientierung vor Risikobewertung. Online verf&#252;gbar unter
https://www.wirtschaftsrat.de/wirtschaftsrat.nsf/id/positionspapier-weissbuch-ki-regulierungsrahmen-
de/$file/Positionspapier%20Wei%C3%9Fbuch%20KI-Regulierungsrahmen.pdf.
Wissenschaftlicher Beirat Globale Umweltver&#228;nderungen (2019): Unsere gemeinsame digitale Zukunft &#8211;
Empfehlungen. Online verf&#252;gbar unter
https://www.wbgu.de/fileadmin/user_upload/wbgu/publikationen/hauptgutachten/hg2019/pdf/WBGU_H 
GD2019_Empfehlungen.pdf, zuletzt abgerufen am 13.10.2020.
Wissenschaftlicher Beirat Globale Umweltver&#228;nderungen (2019): Unsere gemeinsame digitale
Zukunft &#8211; Hauptgutachten. Online verf&#252;gbar unter
https://www.wbgu.de/fileadmin/user_upload/wbgu/publikationen/hauptgutachten/hg2019/pdf/wbgu_hg2 
019.pdf, zuletzt abgerufen am 13.10.2020.
Wissenschaftlicher Beirat Globale Umweltver&#228;nderungen (2019): Unsere gemeinsame digitale 
Zukunft &#8211; Zusammenfassung. Online verf&#252;gbar unter
https://www.wbgu.de/fileadmin/user_upload/wbgu/publikationen/hauptgutachten/hg2019/pdf/WBGU_H 
GD2019_Z.pdf, zuletzt abgerufen am 13.10.2020.
Zeit.de (2019): San Francisco verbietet Gesichtserkennung durch Beh&#246;rden, 15. Mai 2019. Online verf&#252;gbar
unter https://www.zeit.de/politik/ausland/2019-05/ueberwachung-gesichtserkennung-san-francisco-usa-
verbot, zuletzt abgerufen am 14.10.2020.
Zeit.de (2020): Datenspende-App soll erhebliche Messl&#252;cken haben, 01. Oktober 2020. Online verf&#252;gbar unter
https://www.zeit.de/wissen/gesundheit/2020-10/robert-koch-institut-coronavirus-datenspende-app-
messluecken-kosten, zuletzt abgerufen am 13.10.2020.
Zhao, Tingyang (2020): Alles unter dem Himmel. Vergangenheit und Zukunft der Weltordnung [2016]. 
Aus dem Chinesischen von Michael Kahn-Ackermann. 2. Aufl. Berlin: Suhrkamp.
Zuboff, Shoshana (2018): Das Zeitalter des &#220;berwachungskapitalismus. Frankfurt, New York: Campus.
Zuckerman, Ethan (2020): The Case for Digital Public Infrastructure. Hg. v. Knight First Amendment Institute. 
Online verf&#252;gbar unter https://s3.amazonaws.com/kfai-documents/documents/7f5fdaa8d0/Zuckerman-
1.17.19-FINAL-.pdf, zuletzt abgerufen am 13.10.2020.
        
 
 
  
  
  
    
 
  
   
 
  
  
   
 
   
 
 
  
 
  
   
  
   
   
 
  
  
  
 
 
  
   
 
 
   
   
 
 
    
  
 
   
 
 
  
 
1
F. Anhang
Glossar
Begriff Erl&#228;uterung
ADM-Systeme Engl., ADM = algorithmic decision making; algorithmische
Entscheidungssysteme.
Aggregation Anh&#228;ufung, Zusammenfassung.
agil wendig, anpassungsf&#228;hig; Unternehmen, die schnell und
gewinnbringend auf sich &#228;ndernde Gegebenheiten reagieren k&#246;nnen, 
werden auch als agile Unternehmen bezeichnet.
AI Engl., Abk&#252;rzung f&#252;r Artificial Intelligence, K&#252;nstliche Intelligenz.
annotieren Anmerken, kennzeichnen; Daten annotieren bedeutet Daten mit
weiteren Informationen zu kennzeichnen bzw. vor zu strukturieren 
oder vorher zu verarbeiten.
Anonymisierung Anonymisierung umfasst verschiedene Methoden der
Datenverarbeitung, die zum Ziel haben, personenbezogene
Informationen in Datens&#228;tzen unzug&#228;nglich zu machen.
auditieren Etwas als externer Pr&#252;fer auf die Erf&#252;llung bestimmter (Qualit&#228;ts-
)Standards hin zu bewerten und anschlie&#223;end zu zertifizieren.
Augmented Reality Engl., erweiterte Realit&#228;t; Augmented Reality bezeichnet die 
Erg&#228;nzung der Darstellung der realen Welt um virtuelle Aspekte mit
dem Ziel, die menschliche Wahrnehmung zu erweitern.
Avatar Grafische Darstellung, Animation, Karikatur oder &#196;hnliches als
Verk&#246;rperung der Benutzerinnen oder des Benutzers im virtuellen
Raum.
B2B Engl., Abk&#252;rzung f&#252;r Business-to-Business; B2B beschreibt
Gesch&#228;ftsbeziehungen zwischen zwei Unternehmen.
B2C Engl., Abk&#252;rzung f&#252;r Business-to-Consumer; B2C beschreibt
Gesch&#228;ftsbeziehungen zwischen einem Unternehmen und einer
Privatperson (Konsumenten, Kunden).
Benchmarking Benchmarking ist die Analyse von Ergebnissen oder Prozessen 
anhand eines festgelegten Vergleichsma&#223;stabs (Benchmark). Ziel
einer solchen Analyse ist es, Unterschiede und 
Verbesserungsm&#246;glichkeiten zu erkennen.
Best Practices Engl.; bew&#228;hrte Vorgehensweisen, Praktiken oder  Methoden.
Bias Engl., Verzerrung, Voreingenommenheit; In der Informatik 
bezeichnet man mit Bias ein Fehlverhalten, das auf einer
systematischen Verzerrung beruht.
Big Data Engl., gro&#223;e Datenmengen; Big Data bezeichnet Datenmengen, 
welche beispielsweise zu gro&#223;, zu komplex, zu schnelllebig oder zu 
schwach strukturiert sind, um sie mit manuellen und herk&#246;mmlichen 
Methoden der Datenverarbeitung auszuwerten.
Black Box Engl., &#8222;schwarzer Kasten&#8220;; Eine Black Box besagt, dass man zwar
die Bedingungen bzw. Eingabewerte und die Resultate bzw. 
Ausgabewerte eines Systems messen kann, aber die 
dazwischenliegenden Vorg&#228;nge der Entscheidungsfindung nicht
nachvollzogen werden k&#246;nnen.
Begriff Erl&#228;uterung
Blockchain Engl., &#8222;Blockkette&#8220;; Blockchain ist eine dezentrale 
Datenbankstruktur, die eine kryptografische (verschl&#252;sselte)
Verkettung und Dokumentation der Datens&#228;tze aufweist (z. B. als
Basis digitaler W&#228;hrungen).
Chatbot Elektronisches Dialogsystem, das einen nat&#252;rlichen Chatteilnehmer
imitiert.
Citizen Science Engl., B&#252;rgerforschung/-wissenschaft; Citizen Science ist eine Form
der Offenen Wissenschaft, bei der Projekte unter Mithilfe von oder
komplett durch interessierte B&#252;rgerinnen und B&#252;rger durchgef&#252;hrt
werden.
Cloud Eine IT-Infrastruktur, die beispielsweise &#252;ber das Internet verf&#252;gbar
gemacht wird. Sie beinhaltet in der Regel Speicherplatz,
Rechenleistung oder Anwendungssoftware als Dienstleistung.
Cluster Engl., B&#252;ndel, Ansammlung; In der Wirtschaft wird die r&#228;umliche
Konzentration miteinander verbundener Unternehmen und 
Institutionen innerhalb eines bestimmten Wirtschaftszweiges als
Cluster bezeichnet.
Code of Conduct Engl., auf freiwilliger Basis, selbst verordneter Verhaltenskodex, 
Verhaltensregeln.
Cyber-physisches System (CPS) Bezeichnet den Verbund informatischer bzw. softwaretechnischer
Komponenten mit mechanischen und elektronischen Teilen, die &#252;ber
eine Dateninfrastruktur, wie beispielsweise das Internet,
kommunizieren.
Data Analytics Engl., Datenanalyse; Data Analytics bezeichnet die Analyse von
Daten mit dem Ziel, aus diesen Daten Muster und Zusammenh&#228;nge
zu erkennen und somit Informationen zu gewinnen.
Data-Governance Engl.; bezeichnet ein Regelwerk f&#252;r das Management der Daten, die 
in einem Unternehmen, einer Organisation oder der &#246;ffentlichen 
Verwaltung verwendet werden (etwa die Modalit&#228;ten der Erhebung, 
Aufbereitung, Pflege, Nutzung, ggf. Ver&#246;ffentlichung).
Datenpool Engl., Datenb&#252;ndel, Datensammlung; Ein Datenpool beschreibt eine
Einrichtung, &#252;ber die verschiedene Partner ihre Daten zentral oder
dezentral verwalten und deren Ziel es ist, diese Daten gemeinsam zu 
nutzen und zu verwerten.
Deep Learning Engl., tiefes Lernen; Deep Learning beschreibt eine besondere Art
des Maschinellen Lernens mittels sog. neuronaler Netze. Der Begriff
der Tiefe bezieht sich hier auf die gro&#223;e Anzahl Schichten dieser
Rechennetze.
Deep Fake Engl.; beschreibt das Resultat der Erstellung oder Manipulation von 
Foto- , Audio- und Videoinhalten durch Methoden des maschinellen
Lernens, die &#196;u&#223;erungen oder Handlungen real existierender
Personen wiedergeben, die diese in Wahrheit nicht get&#228;tigt haben. 
Disruption Disruption ist ein Prozess, bei dem ein bestehendes
Gesch&#228;ftsmodell, Produkt, Dienstleistung oder eine bestehende
Technologie durch neue Innovation ersetzt und vollst&#228;ndig vom
Markt verdr&#228;ngt wird.
Distribution Verteilung, Verbreitung.
Diversit&#228;t Vielfalt, Vielf&#228;ltigkeit.
Begriff Erl&#228;uterung
E-Government Engl., Abk&#252;rzung f&#252;r Electronic Government, elektronische
Regierung; E-Government bezeichnet den verst&#228;rkten Einsatz von
modernen IT-Techniken und elektronischen Medien f&#252;r Regierungs-
und Verwaltungsprozesse.
empirisch Durch systematische Beobachtung.
evaluieren Sach- und fachgerecht beurteilen, auswerten, einem
Bewertungsprozess unterziehen, &#252;berpr&#252;fen.
evidenzbasiert Auf Grundlage empirisch zusammengetragener und bewerteter
wissenschaftlicher Erkenntnisse erfolgend.
Exoskelett Bezeichnet ein mechanisches Ger&#252;st, welches am Au&#223;enk&#246;rper des
Menschen angebracht wird, um den K&#246;rper mit einem St&#252;tzkorsett 
zu unterst&#252;tzen.
Explainable AI Engl., erkl&#228;rbare KI; Explainable AI beschreibt das systematische 
Erkl&#228;ren und &#220;berpr&#252;fen des Maschinellen Lernens. Explainable AI
soll nachvollziehbar machen, auf welche Weise ein KI-System zu
Ergebnissen kommt.
Eye-Tracking Engl., Blickerfassung; Eye Tracking beschreibt die Messung 
des Blickverhaltens bzw. der visuellen Informationsaufnahme durch 
Aufzeichnung der Augenbewegung.
Fairnessma&#223; Formeln, die f&#252;r einen Algorithmus, der Entscheidungen trifft, 
messen, wie fair die richtigen und m&#246;glicherweise falschen 
Entscheidungen auf zwei oder mehr Bev&#246;lkerungsgruppen verteilt
sind.
Fake News Engl., Falsch- und Fehlinformationen; Fake News werden h&#228;ufig 
durch elektronische Kan&#228;le (vor allem soziale Medien) verbreitet.
Sie gehen von Einzelnen oder Gruppen aus, die in eigenem oder
fremdem Auftrag handeln. Es gibt pers&#246;nliche, politische und 
wirtschaftliche Motive f&#252;r die Erstellung.
Falsch-Positiv-Rate Der Anteil, der f&#228;lschlich als positiv eingestuften Objekte, die in
Wirklichkeit negativ sind.
fragmentiert Aufgespalten, zerteilt, zergliedert.
Freiheitsgrad Unabh&#228;ngige, ver&#228;nderliche, innere oder &#228;u&#223;ere Parameter eines
Systems.
Governance Der Begriff &#8222;Governance&#8220; umfasst die Art und Weise, wie 
Entscheidungen getroffen und Inhalte formuliert und umgesetzt
werden.
G2G Engl., Abk&#252;rzung f&#252;r Government-to-Government; G2G bezeichnet
die Interaktion und die Prozesse, die innerhalb des &#246;ffentlichen 
Sektors ablaufen. Dies schlie&#223;t die Interaktion zwischen zwei
Beh&#246;rden ebenso ein wie die Daten&#252;bermittlung innerhalb einer
Verwaltung.
G2C Engl., Abk&#252;rzung f&#252;r Government to Citizen; G2C bzw. C2G
bezeichnet die Interaktion zwischen B&#252;rgerinnen und B&#252;rgern und 
der &#246;ffentlichen Verwaltung.
Hidden Champions Engl., &#8222;heimliche Gewinner&#8220;; Hidden Champions sind oftmals
weitgehend unbekannte Unternehmen, die in ihren Branchen mit
meist hochspezialisierten Produkten und Dienstleistungen 
Weltmarktf&#252;hrer sind.
Begriff Erl&#228;uterung
holistisch Ganzheitlich.
Hype Engl., Welle oberfl&#228;chlicher Begeisterung, &#246;ffentlicher
Aufmerksamkeit.
Hyperscaler Engl.; Hyperscaler sind Systeme, die durch Cloud-Computing 
entstehen, indem sie durch Tausende bis Millionen von Servern in 
einem Netzwerk verbunden und erweiterbar sind. Unter
Hyperscalern versteht man im Allgemeinen auch die drei gro&#223;en 
Cloud-Anbieter Amazon, Microsoft und Google.
IKT Abk&#252;rzung f&#252;r Informations- und Kommunikationstechnologie.
immanent Innewohnend, in etwas enthalten.
inh&#228;rent Einer Sache innewohnend.
Inklusion In eine Gruppe einschlie&#223;ende, gleichberechtigte Teilhabe einer
anderen Gruppe.
inkrementell Schrittweise erfolgend, aufeinander aufbauend.
Internet of Things (IoT) Engl., Internet der Dinge; Internet of Things bezeichnet die
Vernetzung zwischen &#8222;intelligenten&#8221; Gegenst&#228;nden sowohl
untereinander als auch nach au&#223;en hin mit dem Internet. 
Verschiedene Objekte, Alltagsgegenst&#228;nde oder Maschinen werden
dabei mit Prozessoren und eingebetteten Sensoren ausgestattet, 
sodass sie in der Lage sind, via IP-Netz miteinander zu
kommunizieren.
Interoperabilit&#228;t F&#228;higkeit unterschiedlicher Systeme, m&#246;glichst nahtlos
zusammenzuarbeiten.
Iteration Beschreibt allgemein einen Prozess mehrfachen Wiederholens
gleicher oder &#228;hnlicher Handlungen zur schrittweisen Ann&#228;herung
an eine L&#246;sung oder ein bestimmtes Ziel.
kausal urs&#228;chlich, auf dem Verh&#228;ltnis zwischen Ursache und Wirkung 
beruhend.
KMU Abk&#252;rzung f&#252;r &#8222;kleine und mittlere Unternehmen&#8220;.
Knowledge Sharing Engl., Wissensaustausch.
kognitiv Das Wahrnehmen, Denken, Erkennen betreffend.
Kollaboration Zusammenarbeit.
kollaborativ Gemeinsam, zusammen arbeitend, entwickelnd.
Korrelation Eine Korrelation beschreibt den statistischen, mithilfe der
Wahrscheinlichkeitsrechnung zu erfassenden Zusammenhang
zwischen bestimmten Erscheinungen. Dieser Zusammenhang kann 
zuf&#228;llig sein oder auf einer indirekten Kausalbeziehung (siehe 
kausal) wie einer gemeinsamen Ursache basieren.
Kritikalit&#228;t Engl., critical = gef&#228;hrlich, kritisch; Die Bewertung der Kritikalit&#228;t 
von KI-Systemen adressiert die potenziellen Gef&#228;hrdungen durch 
den Einsatz dieser Systeme mit dem Ziel des Risikomanagements.
Kryptow&#228;hrung Kryptow&#228;hrungen sind digitale (Quasi-)W&#228;hrungen mit einem meist
dezentralen, stets verteilten und kryptografisch abgesicherten 
Zahlungssystem. Zu ihnen geh&#246;ren etwa Bitcoin und Litecoin.
K&#252;nstliche Intelligenz Siehe hierzu das Kapitel B. I. 7 Begriffserkl&#228;rung K&#252;nstliche
Intelligenz
Begriff Erl&#228;uterung
Langfristdaten Daten, die &#252;ber einen langen Zeitraum gesammelt wurden.
LAWS
(Lethal Autonomous Weapon
Systems)
Engl., t&#246;dliche autonome Waffensysteme.
Leuchtturmprojekt Herausragendes, wegweisendes Projekt.
Level Playing Field Engl.; eine Situation mit  gleichen und fairen 
Wettbewerbsbedingungen f&#252;r alle Teilnehmer. 
Living Lab Engl., Reallabor.
Location Engl., Standort.
Lock-in-Effekt Lock-in-Effekte beschreiben eine enge Bindung des Verbrauchers
an ein Produkt, welche ihm das Wechseln zu einem
Konkurrenzanbieter erschwert. 
(Medien-/Multi-)Konvergenz Prozess des Zusammenwachsens bisher getrennt betrachteter
Kommunikations- oder Medienbereiche mit der Tendenz zur
Vereinheitlichung (z. B. einheitliche Datenbankbasis), Vernetzung 
(z. B. Printmailing mit personalisierter URL) oder Verschmelzung
(z. B. Internet-TV).
Messenger Engl., Bote; Programme zur digitalen Sofortkommunikation.
Microtargeting Engl.; bezeichnet verschiedene datenbasierte Marketingstrategien,
welche Zielgruppen identifizieren, um diese mit passgenauen 
Werbe- und Image-Botschaften anzusprechen.
Mismatch Engl., Diskrepanz, Ungleichgewicht, Nicht&#252;bereinstimmung
Mobility Engl., Beweglichkeit; Mobility ist ein Schlagwort der
Informationstechnologie zur Umschreibung von Trends, welche
Mobilger&#228;te und mobiles Internet behandeln. Der Begriff wird 
ebenfalls f&#252;r KI-gest&#252;tzte Mobilit&#228;tsangebote verwendet.
Monitoring Engl., (Dauer)beobachtung; Monitoring bezeichnet eine fortlaufende
&#220;berwachung von Prozessen und Vorg&#228;ngen.
Moonshot-Projekt Engl.; Besonders ehrgeizige, vision&#228;re und bahnbrechende Projekte, 
angelehnt an die Vision von John F. Kennedy, den ersten Menschen 
zum Mond zu schicken.
Narrativ (Verbindende) sinnstiftende Erz&#228;hlung.
Natural Language Processing Engl., nat&#252;rliche Sprachverarbeitung; Natural Language Processing 
beschreibt die Erfassung nat&#252;rlicher Sprache und ihrer
computerbasierten Verarbeitung durch Algorithmen.
Neurointerface Zusammengesetztes Wort aus den Begriffen Neuro und Interface (=
engl., Schnittstelle). Ein Neurointerface liest Gehirnstr&#246;me aus.
Newsfeed Abonnierbare elektronische Nachrichten, die &#252;ber Aktualisierungen 
und neu generierte Meldungen informieren.
NGO Engl., Abk&#252;rzung f&#252;r Non-Governmental Organisation; Der Begriff
bezeichnet eine Nichtregierungsorganisation, also eine private,
unabh&#228;ngige, nicht gewinnorientierte Organisation, die einen
sozialen oder gesellschaftspolitischen Zweck verfolgt und nicht
durch ein &#246;ffentliches Mandat legitimiert ist.
OECD Abk&#252;rzung: Organisation f&#252;r wirtschaftliche Zusammenarbeit und 
Entwicklung.
Begriff Erl&#228;uterung
On-Demand Engl., auf Anforderung/Bestellung; je nach Nachfrage.
Open Access Engl., offener Zugang; Open Access bezeichnet den freien Zugang 
zu Wissen, beispielsweise zu wissenschaftlicher Literatur oder
anderen Materialien im Internet.
Open Data Engl., offene Daten; Open Data sind f&#252;r jede Person einsehbare, 
nutzbare und weiterverbreitbare Daten.
Open Source Engl., offene Quelle; Als Open Source wird Software bezeichnet, 
deren Quelltext &#246;ffentlich und von Dritten eingesehen, ge&#228;ndert und 
genutzt werden kann. Open-Source-Software kann meistens
kostenlos genutzt werden.
Opt-Out-Regelung Die M&#246;glichkeit, sich gegen eine Anwendung zu entscheiden und 
z. B. ein anderes Verfahren ohne KI zu w&#228;hlen.
Output Engl., Ausgabe; Unter Output versteht man in der Informatik das, 
was ein Programm nach interner Berechnung auf einem
Ausgabeger&#228;t (beispielsweise Bildschirm oder Drucker), einer 
Schnittstelle oder einem Datenspeicher (Datei) ausgibt. Bezeichnet
im allgemeineren Sinne auch den Ertrag.
Overhead Engl.; zus&#228;tzlich ben&#246;tigte Daten, Verwaltungsdaten, auch 
zus&#228;tzlich anfallende Kosten, bezeichnet im allgemeineren Sinne
auch den Mehraufwand.
Partizipation Partizipation bezeichnet allgemein die Teilhabe und Beteiligung von 
B&#252;rgerinnen und B&#252;rgern an Willensbildungs- und 
Entscheidungsprozessen.
Plattform Eine Plattform im Internet ist eine Webseite, die dem Austausch und 
der Verbreitung von Informationen, Inhalten oder Produkten dient.
Portfolio Gesamtes, aufeinander abgestimmtes Angebot.
Predicitive Maintenance Engl., vorausschauende Wartung/Instandhaltung; Predictive
Maintenance verfolgt einen vorausschauenden Ansatz und wartet
Maschinen und Anlagen proaktiv, um Ausfallzeiten niedrig zu 
halten.
Predictive Policing Engl., vorausschauende Polizeiarbeit; KI-Systeme sollen dabei 
unterst&#252;tzen, Polizeiarbeit gezielt zu steuern, um Gesetzesverst&#246;&#223;e 
zu verhindern.
Prim&#228;rdaten Auch als Rohdaten (Raw Data) oder Urdaten bezeichnet, beschreibt
der Begriff diejenigen Daten, die bei einer Beobachtung, einer
Messung oder einer Datenerhebung unmittelbar gewonnen werden 
und noch unbearbeitet vorliegen.
Privacy by default Engl.; Privacy by default bedeutet &#252;bersetzt &#8222;Datenschutz durch 
datenschutzfreundliche Voreinstellungen&#8220;. Gemeint ist damit, dass
die Werkseinstellungen datenschutzfreundlich auszugestalten sind. 
Auf diese Weise sollen insbesondere die Nutzer gesch&#252;tzt werden,
die weniger technikaffin sind.
Privacy by design Engl.; Privacy by design bedeutet &#8222;Datenschutz durch 
Technikgestaltung&#8220; und greift den Gedanken auf, dass der
Datenschutz bei Datenverarbeitungsvorg&#228;ngen am besten
eingehalten wird, wenn er bei deren Erarbeitung bereits technisch 
integriert ist.
Begriff Erl&#228;uterung
Pseudonymisierung Pseudonymisierung umfasst, &#228;hnlich der Anonymisierung, 
verschiedene Methoden der Datenverarbeitung, um
personenbezogene Informationen in Datens&#228;tzen unzug&#228;nglich zu 
machen. Bei der Pseudonymisierung wird das
Identifikationsmerkmal durch ein Pseudonym, beispielsweise eine
Ziffernfolge ersetzt. Ohne die Information dar&#252;ber, welches
Pseudonym zu welchem Identifikationsmerkmal geh&#246;rt, ist der
Personenbezug bei erfolgreicher Pseudonymisierung nicht
herstellbar. Anders als bei der Anonymisierung kann der
Personenbezug jedoch bei Bedarf wieder hergestellt werden.
Quanten-Computing Quantencomputer interpretieren und verarbeiten Informationen 
anders als herk&#246;mmliche Computer. Der klassische PC arbeitet mit
einem bin&#228;ren System &#8211; die Daten werden in Bits gespeichert. Diese 
Bits k&#246;nnen lediglich zwei Zust&#228;nde annehmen: Eins (an) und Null
(aus). Im Quanten-Computing wird dagegen mit Quantenbits
(Qubits) gearbeitet.  Diese sollen dann nicht nur einen Zustand, 
sondern auch zwei zugleich &#8211; 1 und 0 &#8211; annehmen k&#246;nnen. Dadurch 
sollen Quantencomputer bestimmte Arten von Problemen erheblich
schneller l&#246;sen k&#246;nnen als herk&#246;mmliche Computer.
Quantified Self Engl., bezeichnet Methoden zur Vermessung des Menschen mit
Apps, Fitnesstrackern und anderen Ger&#228;ten.
Racial Profiling Engl., Profilerstellung aufgrund ethnischer Stereotype oder &#228;u&#223;erer
Merkmale; &#8222;Racial Profiling&#8220; bezeichnet polizeiliche Ma&#223;nahmen,
die nicht auf einer konkreten Verdachtsgrundlage oder Gefahr (etwa
dem Verhalten einer Person oder Gruppe) erfolgen, sondern allein
aufgrund von &#228;u&#223;eren Merkmalen, wie z. B. der Hautfarbe oder
(vermuteter) Religionszugeh&#246;rigkeit.
Reallabor Reallabore sind eine neue Form der Kooperation 
zwischen Wissenschaft und Zivilgesellschaft, bei der das
gegenseitige Lernen in einem experimentellen Umfeld im
Vordergrund steht. Akteure aus Wissenschaft und Praxis kommen 
dort zusammen, um auf Basis eines gemeinsamen
Problemverst&#228;ndnisses wissenschaftlich und sozial robuste
L&#246;sungen zu erarbeiten und auszuprobieren, meist noch bevor eine
gesetzliche Grundlage f&#252;r diese L&#246;sungen vorliegt.
Rebound-Effekt Der Rebound-Effekt bezeichnet die vermehrte Nachfrage nach
Ressourcen, die durch eine Steigerung der Produktivit&#228;t verursacht
oder erm&#246;glicht wird. Die urspr&#252;nglich beabsichtigten Einsparungen 
k&#246;nnen durch den Rebound-Effekt teilweise wieder aufgehoben
werden, beispielsweise wenn erh&#246;hte Energieeffizienz zu erh&#246;htem
Verbrauch f&#252;hrt.
Recruiting Engl., Suche nach bzw. Vermittlung von Arbeitskr&#228;ften.
Resilienz Systemische Widerstandsf&#228;higkeit gegen&#252;ber St&#246;rungen und 
anderen Beeintr&#228;chtigungen mit dem Ziel, nicht vollst&#228;ndig zu 
versagen, sowie die F&#228;higkeit, nach einer St&#246;rung zum
Ausgangszustand zur&#252;ckzukehren.
Roadmap Engl.; eine Roadmap ist ein Strategie- oder Projektplan. Auf einer
Roadmap wird ein Projekt in Schritte unterteilt, sodass erkennbar
wird, in welcher Weise das Projektziel erreicht werden soll.
Rohdaten siehe Prim&#228;rdaten.
Begriff Erl&#228;uterung
Sample Engl., Muster, Beispiel, Stichprobe.
Sandboxes/Sandk&#228;sten Engl., digitale Experimentierr&#228;ume. In der Informatik k&#246;nnen damit
z. B. Webseiten bezeichnet werden, die unter Ausschluss der
&#214;ffentlichkeit getestet werden.
Scoring/ Social Scoring Engl.; Scoring bezeichnet die Klassifizierung oder Bewertung 
anhand einer numerischen Skala, z. B. durch die Vergabe von 
Punkten. Social Scoring bezeichnet die Beurteilung von Menschen 
anhand bestimmter Eigenschaften oder Verhaltensweisen.
Screening Engl.; Unter Screening versteht man ein systematisches
Testverfahren, das eingesetzt wird, um innerhalb eines definierten 
Pr&#252;fbereichs Elemente herauszufiltern, die bestimmte Eigenschaften
aufweisen.
Security by design Engl.; der Begriff meint das Ber&#252;cksichtigen von 
Sicherheitsanforderungen an Soft- und Hardware schon w&#228;hrend der
Entwicklungsphase eines Produktes, um sp&#228;tere Sicherheitsl&#252;cken 
zu vermeiden.
Skaleneffekt Der Skaleneffekt oder &#8222;Gr&#246;&#223;envorteil&#8220; beschreibt die Abh&#228;ngigkeit
der produzierten Menge von der Menge der Produktionsfaktoren. 
Typischerweise treten Skaleneffekte bei Softwarel&#246;sungen auf, da
f&#252;r diese zwar hohe Fix- und Entwicklungskosten, jedoch im Betrieb 
nur sehr geringe, variable Kosten anfallen.
Smart City Engl., intelligente Stadt; Smart City bezeichnet Lebensr&#228;ume der
Menschen (Stadt, Gemeinde, l&#228;ndliches Leben), die im Kontext der
Digitalisierung anders oder neu gestaltet werden. Entgegen dieser
weit umfassenden Beschreibung sind Smart Cities im engeren Sinne
St&#228;dte oder Metropolregionen (z. B. Berlin oder Hamburg), die als
konzentrierte, urbane Lebensr&#228;ume das Handlungsfeld f&#252;r
Digitalisierung darstellen.
Smart Country Engl., intelligentes Land; Smart Country ist eine Initiative, die sich
der Weiterentwicklung l&#228;ndlicher R&#228;ume, also &#8222;country&#8221; im Sinne
von &#8222;countryside&#8221;, verschrieben hat, und sich bewusst parallel zu 
&#8222;Smart City&#8221; definiert.
Smart Health/E-Health Engl., intelligente Gesundheit; Ein Sammelbegriff f&#252;r den Einsatz
digitaler Technologien im Gesundheitswesen. Er bezeichnet alle 
Hilfsmittel und Dienstleistungen, bei denen Informations- und 
Kommunikationstechnologien (IKT) zum Einsatz kommen, und die
der Vorbeugung, Diagnose, Behandlung, &#220;berwachung und 
Verwaltung im Gesundheitswesen dienen.
Smart Home Engl., intelligentes Zuhause; Smart Home zielt auf das informations-
und sensortechnisch aufger&#252;stete, in sich selbst und nach au&#223;en 
vernetzte Zuhause. Verwandte Begriffe sind &#8222;Smart Living&#8220; und 
&#8222;Intelligent Home&#8220;.
Smart Service
Engl., intelligente Dienstleistung; ein Smart Service ist eine digitale
Dienstleistung, die auf der Basis vernetzter, intelligenter technischer
Systeme und Plattformen Daten sammelt und analysiert. Die dabei
entstehenden Informationen und Wertangebote werden im Rahmen 
dienstleistungsbasierter Gesch&#228;ftsmodelle &#252;ber digitale Marktpl&#228;tze 
und Schnittstellen vermarktet.
Begriff Erl&#228;uterung
Smart Region Engl., intelligente Region; eine Smart Region ist ein regionaler
Verbund unterschiedlicher Gebietsk&#246;rperschaften, der digitalisierte
Bereiche aus Kommunen, der (lokalen) Wirtschaft und der
Zivilgesellschaft umfasst.
Smartwatch Engl., intelligente Armbanduhr; eine Smartwatch ist eine digitale
Armbanduhr, die &#228;hnlich wie ein modernes Handy bedient und mit
diesem verbunden werden kann. Sie zeigt Zeit und Datum an, misst
den Puls, z&#228;hlt die Schritte und vermittelt Informationen.
Social Innovation Engl., soziale Innovation; &#8222;Social Innovation&#8220; bezeichnet Konzepte 
und Innovationen, die gezielt auf das L&#246;sen sozialer Probleme und 
auf das Handeln im Sinne des Gemeinwohls setzen. Bei Social-
Innovation-Fonds handelt es sich um eine neuartige Finanzierung 
solcher Projekte.
Soft Skill Engl.; methodische, pers&#246;nliche und soziale Kompetenzen, die sich 
fach&#252;bergreifend in der Pers&#246;nlichkeit und im Verhalten eines
Menschen spiegeln.
Stakeholder Engl., Anspruchsgruppen; Mit dem Begriff Stakeholder sind alle
Personen, Gruppen oder Institutionen gemeint, die von den 
Unternehmensaktivit&#228;ten eines Unternehmens direkt oder indirekt
betroffen sind oder die generell ein Interesse an den Aktivit&#228;ten 
bekunden (z. B. Aktion&#228;re, Mitarbeiter, Kunden, Lieferanten etc.).
Start-up Engl.; neu gegr&#252;ndetes Wirtschaftsunternehmen, dem &#252;blicherweise
eine innovative Gesch&#228;ftsidee und ein hohes Wachstumspotenzial
zugeschrieben wird.
SWOT-Analyse Engl., Abk&#252;rzung f&#252;r &#8222;Analysis of strengths, weakness, 
opportunities and threats&#8220;, St&#228;rken-Schw&#228;chen-Chancen-Risiken-
Analyse.
Tracking Engl.; das Verfolgen umfasst alle Bearbeitungsschritte, die der
Verfolgung von (bewegten) Objekten dienen.
Transformation Umwandlung, Umformung, Umgestaltung.
Translation &#220;bertragung, &#220;bersetzung.
Trust Engl., Vertrauen.
valide g&#252;ltig, gesichert.
Virtual Reality Engl., virtuelle Realit&#228;t. Als virtuelle Realit&#228;t wird die Darstellung
und gleichzeitige Wahrnehmung der Wirklichkeit und ihrer
physikalischen Eigenschaften in einer in Echtzeit 
computergenerierten, interaktiven virtuellen Umgebung bezeichnet.
Fonds Geldreserve f&#252;r einen bestimmten Zweck.
Wertsch&#246;pfungskette Gesamtheit der Prozesse (wie Produktion, Auslieferung u. a.), die zu 
einer Wertsch&#246;pfung f&#252;hren.
        
 
 
   
   
 
  
  
   
 
 
 
 
   
   
 
 
 
 
 
   
 
   
 
 
    
 
 
 
   
 
   
    
    
 
 
   
 
  
  
 
2
Literaturverzeichnis zum Bericht
Abadi, Martin; Chu, Andy; Goodfellow, Ian; McMahan, H. Brendan; Mironov, Ilya; Talwar, Kunal; Zhang, Li
(2016): Deep Learning with Differential Privacy. In: Edgar Weippl, Stefan Katzenbeisser, Christopher
Kruegel, Andrew Myers und Shai Halevi (Hg.): Proceedings of the 2016 ACM SIGSAC Conference on 
Computer and Communications Security. Conference on Computer and Communications Security. 
Vienna Austria, 24.-28. Oktober 2016. New York, NY, USA: ACM, S. 308&#8211;318.
Accenture (2018): Weg ohne Ziel? Wie Deutschland ein Spitzenstandort f&#252;r K&#252;nstliche Intelligenz werden 
kann. Online verf&#252;gbar unter https://www.accenture.com/_acnmedia/pdf-90/accenture-weg-ohne-ziel-
studie.pdf, zuletzt abgerufen am 03.08.2020.
Achleitner, Ann-Kristin; Braun, Reiner; Behrens, Jan Henning; Lange, Thomas (2019): Innovationskraft in 
Deutschland verbessern: &#214;kosystem f&#252;r Wachstumsfinanzierung st&#228;rken (acatech STUDIE). Online 
verf&#252;gbar unter https://www.acatech.de/publikation/innovationskraft-in-deutschland-verbessern/, zuletzt
abgerufen am 21.07.2020.
Adam, Martin (2020): Die BVG k&#246;nnte beim Berlk&#246;nig zu hoch gepokert haben. Berliner Pilotprojekt vor dem
Aus. In: rbb24.de, 05. Februar 2020. Online verf&#252;gbar unter
https://www.rbb24.de/wirtschaft/beitrag/2020/02/berlin-berlkoenig-droht-das-aus-koalitionsausschuss-
bvg-kosten.html, zuletzt abgerufen am 27.07.2020.
adesso SE: Betrugserkennung f&#252;r Versicherer. Effektive Bek&#228;mpfung von Versicherungsbetrug und 
-missbrauch. Online verf&#252;gbar unter
https://www.adesso.de/de/branchen/versicherungen/sonderthemen/betrugserkennung.jsp, zuletzt
abgerufen am 15.07.2020.
Ah-Fat, Patrick; Huth, Michael (2019): Optimal Accuracy-Privacy Trade-Off for Secure Computations. 
In: IEEE Trans. Inform. Theory 65 (5), S. 3165&#8211;3182. 
Ahlers, Elke (2015): Leistungsdruck, Arbeitsverdichtung und die (ungenutzte) Rolle von 
Gef&#228;hrdungsbeurteilungen. In: Wirtschafts- und Sozialwissenschaftliches Institut (WSI-Mitteilungen)
(03/2015), S. 194&#8211;201. Online verf&#252;gbar unter https://www.wsi.de/data/wsimit_2015_03_ahlers.pdf, 
zuletzt abgerufen am 17.07.2020.
Ahlers, Elke (2020): Arbeitsintensivierung in den Betrieben. Problemdeutungen und Handlungsfelder von 
Betriebsr&#228;ten. In: Wirtschafts- und Sozialwissenschaftliches Institut (WSI-Mitteilungen) 73 (1), S. 29&#8211;37. 
Ajder, Henry; Patrini, Giorgio; Cavalli, Francesco; Cullen, Laurence (2019): The State of Deepfakes:
Landscape, Threats, and Impact. Hg. v. Deeptrace. Online verf&#252;gbar unter
https://regmedia.co.uk/2019/10/08/deepfake_report.pdf, zuletzt abgerufen am 30.07.2020.
Albers, Erik (2018): Wie Barcelona eine offene &#8222;Smart City&#8220; im Dienste des Gemeinwohls plant. Interview. 
Hg. v. Netzpolitik.org. Online verf&#252;gbar unter https://netzpolitik.org/2018/freie-software-als-
oeffentliches-gut-und-was-rathaeuser-dafuer-tun-koennen/, zuletzt abgerufen am 16.07.2020.
Albert, Cecilia; Garc&#237;a-Serrano, Carlos; Hernanz, Virginia (2010): On-the-job training in Europe: Determinants
and wage returns. In: International Labour Review 149 (3), S. 315&#8211;341. 
Allianz SE (2017): The Future of Work &#8211; Harry und Allie. Sie suchen Ihren Traumjob? Lernen Sie unseren 
quirligen und umg&#228;nglichen Chatbot kennen, der unheimlich gern mit Bewerbern &#252;ber die Chancen 
spricht, die die Allianz zu bieten hat. Online verf&#252;gbar unter
https://www.allianz.com/de/presse/news/unternehmen/personalthemen/171016-future-of-work-allie-the-
chatbot.html, zuletzt abgerufen am 15.07.2020.
Alter, Adam (2017): Irresistible. The rise of addictive technology and the business of keeping us hooked. New 
York: Penguin Press.
Altmeier, Peter (2018): Wirtschaftsminister Altmaier sieht k&#252;nstliche Intelligenz als &#8222;Schl&#252;sselfrage f&#252;r
Deutschland und Europa&#8220;. In: Handelsblatt.com, 17. Juli 2018. Online verf&#252;gbar unter
https://www.handelsblatt.com/meinung/gastbeitraege/gastbeitrag-wirtschaftsminister-altmaier-sieht-
kuenstliche-intelligenz-als-schluesselfrage-fuer-deutschland-und-europa/22806976.html?ticket=ST-
14242794-QBVmiwmOCAg340pKfHbd-ap5, zuletzt abgerufen am 27.07.2020.
&#193;lvarez, Sonja (2020): Kreative KI &#8211; Wenn Computer Kunst schaffen. In: tagesspiegel.de, 09. M&#228;rz 2020. 
Online verf&#252;gbar unter https://www.tagesspiegel.de/kultur/kreative-ki-wenn-computer-kunst-
schaffen/25625630.html, zuletzt abgerufen am 13.07.2020.
Anderton, Kevin (2019): The Business Of Video Games: Market Share For Gaming Platforms in 2019. 
In: forbes.com. Online verf&#252;gbar unter https://www.forbes.com/sites/kevinanderton/2019/06/26/the-
business-of-video-games-market-share-for-gaming-platforms-in-2019-infographic/#3ca1fab7b254, 
zuletzt abgerufen am 27.07.2020.
Angrist, Joshua David; Pischke, J&#246;rn-Steffen (2009): Mostly harmless econometrics. An empiricist's
companion. Princeton, NJ: Princeton Univ. Press.
Angwin, Julia; Larson, Jeff; Mattu, Surya; Kirchner, Lauren (2016): Machine Bias. There&#8217;s software used
across the country to predict future criminals. And it&#8217;s biased against blacks. In: ProPublica.org, 23. Mai
2016. Online verf&#252;gbar unter https://www.propublica.org/article/machine-bias-risk-assessments-in-
criminal-sentencing, zuletzt abgerufen am 17.07.2020.
Angwin, Julia; Varner, Madeleine; Tobin, Ariana (2020): Facebook Enabled Advertisers to Reach &#8216;Jew
Haters&#8217;. Hg. v. Pro Publica Inc. Online verf&#252;gbar unter https://www.propublica.org/article/facebook-
enabled-advertisers-to-reach-jew-haters, zuletzt aktualisiert am 14.09.2017, zuletzt abgerufen am
03.08.2020.
Anke Domscheit-Berg (2019): Schriftliche Frage in der Woche vom 8. Juli 2019. Online verf&#252;gbar unter
https://mdb.anke.domscheit-berg.de/2019/07/schriftliche-frage-in-der-woche-vom-8-juli-2019/, zuletzt
aktualisiert am 23.07.2019, zuletzt abgerufen am 17.07.2020.
Aral Aktiengesellschaft (2019): Trends beim Autokauf 2019. Aral Studie. Online verf&#252;gbar unter
https://www.aral.de/content/dam/aral/business-sites/de/global/retail/presse/broschueren/aral-studie-
trends-beim-autokauf-2019.pdf, zuletzt abgerufen am 28.07.2020.
Arbeitsgemeinschaft Deutscher Verkehrsflugh&#228;fen (ADV) (2020): ADV-Monatsstatistik. ADV Monthly 
Traffic Report 12/2019. Online verf&#252;gbar unter https://www.adv.aero/wp-
content/uploads/2016/02/12.2019-ADV-Monatsstatistik.pdf, zuletzt abgerufen am 03.08.2020.
ard.de (2019): Rundfunkstaatsvertrag. Online verf&#252;gbar unter
https://www.ard.de/home/Rundfunkstaatsvertrag/538802/index.html, zuletzt abgerufen am 29.07.2020.
Ardila, Diego; Kiraly, Atilla P.; Bharadwaj, Sujeeth; Choi, Bokyung; Reicher, Joshua J.; Peng, Lily et al. 
(2019): End-to-end lung cancer screening with three-dimensional deep learning on low-dose chest
computed tomography. In: Nature medicine 25 (6), S. 954&#8211;961. 
Arntz, Melanie; Gregory, Terry; Zierahn, Ulrich (2016): The Risk of Automation for Jobs in OECD Countries:
A Comparative Analysis. Hg. v. OECD Publishing. Paris (OECD Social, Employment and Migration 
Working Papers, No. 189). Online verf&#252;gbar unter https://www.oecd-
ilibrary.org/docserver/5jlz9h56dvq7-
en.pdf?expires=1596716127&amp;id=id&amp;accname=guest&amp;checksum=50E9892303C8B3F7A06CDB3529A 
A916F, zuletzt abgerufen am 06.08.2020.
Aschermann, Tim (2018): Was ist RAW? Einfach und verst&#228;ndlich erkl&#228;rt. Hg. v. CHIP Digital GmbH. Online
verf&#252;gbar unter https://praxistipps.chip.de/was-ist-raw-einfach-und-verstaendlich-erklaert_44540, zuletzt
aktualisiert am 07.09.2018, zuletzt abgerufen am 30.07.2020.
Asendorf, Dirk (13. Feburar 2020): Intelligenz, die keinem hilft. Digitale Stromz&#228;hler. In: Die Zeit, 13. Feburar
2020 (8). Online verf&#252;gbar unter https://www.zeit.de/2020/08/digitale-stromzaehler-smart-meter-
effizienz-stromverbrauch, zuletzt abgerufen am 07.08.2020.
Asiri, Sidath (2018): Machine Learning Classifiers. Hg. v. towardsdatascience.com. Online verf&#252;gbar unter
https://towardsdatascience.com/machine-learning-classifiers-a5cc4e1b0623, zuletzt abgerufen am
20.07.2020.
assono GmbH: Chatbot f&#252;r Recruiting, Personalmanagement und HR. Online verf&#252;gbar unter
https://www.assono.de/chatbot/chatbots-im-recruiting, zuletzt abgerufen am 16.07.2020.
Athalye, Anish; Carlini, Nicholas; Wagner, David: Obfuscated Gradients Give a False Sense of Security: 
Circumventing Defenses to Adversarial Examples. Online verf&#252;gbar unter
https://arxiv.org/pdf/1802.00420.pdf, zuletzt abgerufen am 23.07.2020.
Auer, Christoph (et al.) (2019): K&#252;nstliche Intelligenz im Gesundheitswesen. In: Robin Haring (Hg.):
Gesundheit digital. Perspektiven zur Digitalisierung im Gesundheitswesen. Berlin, Heidelberg: Springer
Berlin Heidelberg.
Australian Competition and Consumer Commission (2019): Digital Platforms Inquiry. Final Report. Online
verf&#252;gbar unter https://www.accc.gov.au/system/files/Digital%20platforms%20inquiry%20-
%20final%20report.pdf, zuletzt abgerufen am 04.08.2020.
Ausw&#228;rtiges Amt (2018): T&#246;dliche Roboter-Waffen weltweit &#228;chten. Artikel. Online verf&#252;gbar unter
https://www.auswaertiges-amt.de/de/aussenpolitik/themen/abruestung-ruestungskontrolle/autonome-
waffen/2131346, zuletzt abgerufen am 20.07.2020.
Autorengruppe Bildungsberichterstattung (2020): Bildung in Deutschland 2020. Ein indikatorengest&#252;tzter
Bericht mit einer Analyse zu Bildung in einer digitalisierten Welt. Online verf&#252;gbar unter 
https://www.bildungsbericht.de/static_pdfs/bildungsbericht-2020.pdf, zuletzt abgerufen am 09.09.2020.
AW AlgorithmWatch gGmbH (2020): Positionen zum Einsatz von KI im Personalmanagement. Rechte und 
Autonomie von Besch&#228;ftigten st&#228;rken &#8211; Warum Gesetzgeber, Unternehmen und Betriebsr&#228;te handeln 
m&#252;ssen. Berlin. Online verf&#252;gbar unter https://algorithmwatch.org/wp-
content/uploads/2020/03/AlgorithmWatch_AutoHR_Positionspapier_2020.pdf, zuletzt abgerufen am
06.08.2020.
Backhaus, Nils (2019): Kontextsensitive Assistenzsysteme und &#220;berwachung am Arbeitsplatz: Ein
metaanalytisches Review zur Auswirkung elektronischer &#220;berwachung auf Besch&#228;ftigte. In: Z. Arb. Wiss. 73 
(1), S. 2&#8211;22. 
Backovic, Lazar (2018): Robo-Recruiting &#8211; 5 wichtige Fragen verst&#228;ndlich beantwortet. Immer mehr
Unternehmen setzen bei der Personalauswahl auf k&#252;nstliche Intelligenz. Was Bewerber und 
Unternehmen wissen m&#252;ssen. In: Handelsblatt, 27. Mai 2018. Online verf&#252;gbar unter
https://www.handelsblatt.com/unternehmen/beruf-und-buero/the_shift/kuenstliche-intelligenz-robo-
recruiting-5-wichtige-fragen-verstaendlich-beantwortet/22597666.html?ticket=ST-6150545-
9xZJLx7ceQgGxgOX7bFz-ap5, zuletzt abgerufen am 16.07.2020.
Bailey, Brian (2018): The Impact Of Moore&#8217;s Law Ending. Hg. v. Semiconductor Engineering. Online
verf&#252;gbar unter https://semiengineering.com/the-impact-of-moores-law-ending/, zuletzt abgerufen am
27.07.2020.
Baker, Toby; Smith, Laurie (2019): Educ-AI-tion Rebooted? Exploring the future of artificial intelligence in
schools and colleges. Unter Mitarbeit von Nandra Anissa. Hg. v. Nesta. Online verf&#252;gbar unter
https://media.nesta.org.uk/documents/Future_of_AI_and_education_v5_WEB.pdf, zuletzt abgerufen am
06.08.2020.
Balasubramania, Ramnath; Libarikian, Ari; McElhaney, Doug (2018): Insurance 2030&#8212;The impact of AI on 
the future of insurance. Hg. v. McKinsey &amp; Company, zuletzt aktualisiert am
https://www.mckinsey.com/industries/financial-services/our-insights/insurance-2030-the-impact-of-ai-
on-the-future-of-insurance#, zuletzt abgerufen am 23.07.2020.
Balkow, Corinna; Eckardt, Irina (2019): Denkimpuls Digitale Ethik. Transparenz und Nachvollziehbarkeit
algorithmischer Systeme. Unter Mitarbeit von Aljoscha Burchardt, Lena-Sophie M&#252;ller, Nora Schultz
und Barbara Schwarze. Hg. v. Initiative D21 e. V. Online verf&#252;gbar unter
https://initiatived21.de/app/uploads/2019/06/algomon_denkimpuls_transparenz_190620.pdf, zuletzt
abgerufen am 06.08.2020.
Bandura, Albert (1977): Self-efficacy: Toward a unifying theory of behavioral change. In: Psychological 
Review 84 (2), S. 191&#8211;215.
Bange, Axel (2017): Big Data Analytics &#8211; Tagesgesch&#228;ft in der NBA. Sensordaten, Bildanalyse und 
Rechenspiele pr&#228;gen den US-Profibasketball auf und neben dem Platz. Hg. v. BI Scout Business
Intelligence, Analytics &amp; Big Data. Online verf&#252;gbar unter https://www.bi-scout.com/big-data-analytics-
tagesgeschaeft-in-der-nba, zuletzt aktualisiert am 27.03.2017, zuletzt abgerufen am 10.07.2020.
Bank of America; Merrill Lynch (2016): Global Semiconductors Deep Learning and the processor chips
fueling the AI revolution &#8211; a primer. Online verf&#252;gbar unter
https://olui2.fs.ml.com/publish/content/application/pdf/GWMOL/Deep-Learning-AI-Primer.pdf, zuletzt
abgerufen am 23.07.2020.
Barocas, Solon; Hardt, Moritz; Narayanan, Arvind (2019): Fairness and Machine Learning: fairmlbook.org. 
Online verf&#252;gbar unter https://fairmlbook.org, zuletzt abgerufen am 04.08.2020.
Bartl, Marc (2019): Studie: Nicht einmal jeder Zweite erkennt einen Text von einer KI. Online verf&#252;gbar unter
https://kress.de/news/detail/beitrag/143344-studie-nicht-einmal-jeder-zweite-erkennt-einen-text-von-
einer-ki.html, zuletzt aktualisiert am 14.08.2019, zuletzt abgerufen am 30.07.2020.
Bath, Dominik (2020): Beh&#246;rde nennt Zalando Kriterien f&#252;r Feedback-App. Mit der Feedback-App Zonar
beurteilt der Modeh&#228;ndler Zalando seine Mitarbeiter. Die Datenschutzbeh&#246;rde hat erste Kriterien
formuliert. In: morgenpost.de, 27. Juli 2020. Online verf&#252;gbar unter
https://www.morgenpost.de/berlin/article229602786/Behoerde-nennt-Zalando-Kriterien-fuer-Feedback-
App.html, zuletzt abgerufen am 09.09.2020.
Batra, Gaurav; Jacobson, Zach; Madhav, Siddarth; Queirolo, Andrea; Santhanam, Nick (2018):
Artificialintelligence hardware: Artificial-intelligence hardware: New opportunities for semiconductor companies. 
Hg. v. McKinsey &amp; Company. Online verf&#252;gbar unter
https://www.mckinsey.com/~/media/McKinsey/Industries/Semiconductors/Our%20Insights/Artificial%2 
0intelligence%20hardware%20New%20opportunities%20for%20semiconductor%20companies/Artificia 
l-intelligence-hardware.pdf, zuletzt abgerufen am 23.07.2020.
Bauer, Felix; Buchberger, Stefan; Dewes, Andreas; Friedrichs, J&#246;rg; Motzek, Alexander; Sartor, Nicolas et al. 
(2018): Machine Learning und die Transparenzanforderungen der DS-GVO. Leitfaden. Hg. v. Bitkom. 
Online verf&#252;gbar unter https://www.bitkom.org/sites/default/files/file/import/180926-Machine-Learning-
und-DSGVO.pdf, zuletzt abgerufen am 05.08.2020.
Bauer, Vera (2018): Sound Search: Google verwendet seine KI-Song-Erkennung des Pixels 2. 
Hg. v. mobilegeeks.de. Online verf&#252;gbar unter https://www.mobilegeeks.de/news/sound-search-google-
verwendet-seine-ki-song-erkennung-des-pixels-2/, zuletzt aktualisiert am 16.09.2018, zuletzt abgerufen 
am 14.07.2020.
Baum, Katharina; Mei&#223;ner, Stefan; Abramova, Olga; Krasnova, Hanna (2019): Do they really care about
targeted political ads? Investigation of user privacy concerns and preferences. In: Association for
Information Systems (Hg.): Proceedings of the 27th European Conference on Information Systems
(ECIS),. 27th European Conference on Information Systems. Stockholm &amp; Uppsala, 8.-14. Juni 2019 
(Research Papers). Online verf&#252;gbar unter
https://aisel.aisnet.org/cgi/viewcontent.cgi?article=1076&amp;context=ecis2019_rp, zuletzt abgerufen am
01.09.2020.
Beauchamp, Tom L.; Childress, James F. (2013): Principles of biomedical ethics. Seventh edition. New York, 
Oxford: Oxford University Press.
Beckmann, Kirsten; M&#252;ller, Ulf (2014): Teil 10 Kartellrecht. In: Karsten Altenhain: Handbuch Multimedia-
Recht. Rechtsfragen des elektronischen Gesch&#228;ftsverkehrs. Stand: Dez. 2014 (40. Erg.-Lfg.). 
Hg. v. Bernd Holznagel, Thomas Hoeren und Ulrich Sieber: Beck.
Beermann, Beate; Backhaus, Nils; Tisch, Anita; Bretschneider, M. (2019): Arbeitswissenschaftliche 
Erkenntnisse zu Arbeitszeit und gesundheitlichen Auswirkungen. 1. Auflage. Hg. v. Bundesanstalt f&#252;r
Arbeitsschutz und Arbeitsmedizin (baua: fokus). Dortmund. Online verf&#252;gbar unter
https://www.baua.de/DE/Angebote/Publikationen/Fokus/Arbeitszeiten.pdf?__blob=publicationFile&amp;v=3 
, zuletzt abgerufen am 16.07.2020.
Begleitforschung Mittelstand-Digital (2019): K&#252;nstliche Intelligenz im Mittelstand. Relevanz, Anwendungen, 
Transfer. Online verf&#252;gbar unter https://www.mittelstand-
digital.de/MD/Redaktion/DE/Publikationen/kuenstliche-intelligenz-im-mittelstand.html, zuletzt 
abgerufen am 21.07.2020.
Begleitforschung PAiCE; iit-Institut f&#252;r Innovation und Technik in der VDI / VDE Innovation + Technik 
GmbH (2018): Potenziale der K&#252;nstlichen Intelligenz im produzierendem Gewerbe in Deutschland. 
Studie im Auftrag des Bundesministeriums f&#252;r Wirtschaft und Energie (BMWi) im Rahmen der 
Begleitforschung zum Technologieprogramm PAiCE &#8211; Platforms | Additive Manufacturing | Imaging |
Communication | Engineering. Online verf&#252;gbar unter
https://www.bmwi.de/Redaktion/DE/Publikationen/Studien/potenziale-kuenstlichen-intelligenz-im-
produzierenden-gewerbe-in-deutschland.pdf?__blob=publicationFile&amp;v=8, zuletzt abgerufen am
22.07.2020.
Beicht, Ursula (2017): Ausbildungschancen von Ausbildungsstellenbewerbern und -bewerberinnen mit
Migrationshintergrund. Aktuelle Situation 2016 und Entwicklung seit 2004. Hg. v. Bundesinstitut f&#252;r
Berufsbildung. Bonn. Online verf&#252;gbar unter
https://www.bibb.de/veroeffentlichungen/de/publication/download/8331, zuletzt abgerufen am
05.08.2020.
Bejing Academy of Artificial Intelligence (2019): Beijing AI Principles. Online verf&#252;gbar unter
https://www.baai.ac.cn/blog/beijing-ai-principles, zuletzt abgerufen am 06.08.2020.
Bellovin, Steven M.; Dutta, Preetam K.; Reitinger, Nathan (2019): Privacy and Synthetic Datasets. In: Stanford 
Technology Law Review 22 (1). Online verf&#252;gbar unter https://law.stanford.edu/wp-
content/uploads/2019/01/Bellovin_20190129.pdf, zuletzt abgerufen am 05.08.2020.
Bendel, Oliver (2018): Definition: Was ist &#8222;Chatbot&#8220;? Online verf&#252;gbar unter
https://wirtschaftslexikon.gabler.de/definition/chatbot-54248, zuletzt aktualisiert am 19.02.2018, zuletzt
abgerufen am 13.07.2020.
Berens, Philipp; Ayhan, Murat Seckin (2019): Proprietary data formats block health research. In: Nature 565
(7740), S. 429.
Berg, Achim (2020): K&#252;nstliche Intelligenz Einsatz und Forschung in Deutschland. Hg. v. Bitkom e. V. Online
verf&#252;gbar unter https://www.bitkom.org/sites/default/files/2020-06/bitkom-charts-kunstliche-intelligenz-
08-06-2020_final_0.pdf, zuletzt abgerufen am 05.08.2020.
Berger, Daniel (2019): IBM nutzte Flickr-Fotos f&#252;r Gesichtserkennung, ohne Nutzer zu informieren. 
Hg. v. heise.de. Online verf&#252;gbar unter https://www.heise.de/newsticker/meldung/IBM-nutzte-Flickr-
Fotos-fuer-Gesichtserkennung-ohne-Nutzer-zu-informieren-4334805.html, zuletzt abgerufen am
05.08.2020.
Bertelsmann Stiftung: Stadtplanung der Zukunft in der Smart City Wien. Recherchereise. Online verf&#252;gbar
unter https://www.bertelsmann-stiftung.de/de/unsere-projekte/smart-
country/projektnachrichten/stadtplanung-der-zukunft-in-der-smart-city-wien/, zuletzt abgerufen am
16.07.2020.
Best, Jo (2016): Scientists are using cloud computing and AI to track these mysterious, beautiful whale sharks. 
A unique project is using some very old, and very cutting edge, IT to track the biggest fish in the sea. 
Hg. v. zdnet.com. Online verf&#252;gbar unter https://www.zdnet.com/article/scientists-are-using-cloud-
computing-and-ai-to-track-these-mysterious-beautiful-whale-sharks/, zuletzt abgerufen am 07.08.2020.
Bieker, Felix; Bremert, Benjamin; Hagendorff, Thilo (2018): Die &#220;berwachungs-Gesamtrechnung, oder:
Es kann nicht sein, was nicht sein darf. In: Alexander Ro&#223;nagel, Michael Friedewald und Marit Hansen 
(Hg.): Die Fortentwicklung des Datenschutzes. Wiesbaden: Springer Fachmedien Wiesbaden (DuD-
Fachbeitr&#228;ge), S. 139&#8211;150.
Big Brother Watch (2019): Big Brother Watch Briefing for the Westminster Hall debate in Facial recognition
and the biometrics strategy on 1st May 2019. Online verf&#252;gbar unter https://bigbrotherwatch.org.uk/wp-
content/uploads/2019/05/Big-Brother-Watch-briefing-on-Facial-recognition-and-the-biometric-strategy-
for-Westminster-Hall-debate-1-May-2019.pdf, zuletzt aktualisiert am April 2019, zuletzt abgerufen am
17.07.2020.
Birkholz, Claudia (2019): Warum es f&#252;r Musik mehr braucht als K&#252;nstliche Intelligenz. 
Hg. v. Bundesministerium f&#252;r Bildung und Forschung. Online verf&#252;gbar unter
https://www.wissenschaftsjahr.de/2019/neues-aus-der-wissenschaft/das-sagt-die-wissenschaft/kann-ki-
das-kreative-schaffen-des-kunstschaffenden-bereichern/, zuletzt aktualisiert am 29.11.2019, zuletzt
abgerufen am 14.07.2020.
Birkner, Guido: Unilever rekrutiert mit menschlicherem Gesicht &#8211; durch k&#252;nstliche Intelligenz. Nur Marketing 
oder eine feste &#220;berzeugung? Der niederl&#228;ndisch-britische Konsumg&#252;terkonzern Unilever setzt
k&#252;nstliche Intelligenz ein, um den Recruitingprozess menschlicher zu gestalten. In: Frankfurter 
Allgemeine Personaljournal 2018 (04/2018). Online verf&#252;gbar unter https://www.faz-
personaljournal.de/ausgabe/04-2018/unilever-rekrutiert-mit-menschlicherem-gesicht-durch-
kuenstlicheintelligenz-914/, zuletzt abgerufen am 16.07.2020.
Bitkom e. V.: Zwei Drittel der Unternehmen haben DS-GVO gr&#246;&#223;tenteils umgesetzt. Online verf&#252;gbar unter
https://www.bitkom.org/Presse/Presseinformation/Zwei-Drittel-der-Unternehmen-haben-DS-GVO-
groesstenteils-umgesetzt, zuletzt abgerufen am 05.08.2020.
Bitkom e. V. (2017): Bundesb&#252;rger geben K&#252;nstlicher Intelligenz gro&#223;e Chancen. Online verf&#252;gbar unter
https://www.bitkom.org/Presse/Presseinformation/Bundesbuerger-geben-Kuenstlicher-Intelligenz-
grosse-Chancen.html, zuletzt abgerufen am 16.07.2020.
Bitkom e. V. (2018): K&#252;nstliche Intelligenz &#8211; Von der Strategie zum Handeln, 2018. Online verf&#252;gbar unter
https://www.bitkom.org/sites/default/files/2018-
12/Bitkom%20Charts%20K%C3%BCnstliche%20Intelligenz%2005%2012%202018_final.pdf, zuletzt
abgerufen am 20.07.2020.
Bitkom e. V. (03.06.2019): Logistik muss Digitalisierung weiter beschleunigen. Berlin. Online verf&#252;gbar unter
https://www.bitkom.org/Presse/Presseinformation/Logistik-muss-Digitalisierung-weiter-beschleunigen, 
zuletzt abgerufen am 22.07.2020.
Bitkom e. V. (21.07.2019): K&#252;nstliche Intelligenz ist die Top-Technologie f&#252;r Startups. Online verf&#252;gbar unter
https://www.bitkom.org/Presse/Presseinformation/Kuenstliche-Intelligenz-ist-die-Top-Technologie-fuer-
Startups, zuletzt abgerufen am 21.07.2020.
Bitkom e. V. (2019): Erstmals mehr als 100.000 unbesetzte Stellen f&#252;r IT-Experten. Online verf&#252;gbar unter
https://www.bitkom.org/Presse/Presseinformation/Erstmals-mehr-als-100000-unbesetzte-Stellen-fuer-
IT-Experten, zuletzt abgerufen am 05.08.2020.
Bitkom e. V. (2020): Unternehmen tun sich noch schwer mit K&#252;nstlicher Intelligenz. Online verf&#252;gbar unter
https://www.bitkom.org/Presse/Presseinformation/Unternehmen-tun-sich-noch-schwer-mit-
Kuenstlicher-Intelligenz, zuletzt abgerufen am 14.07.2020.
Bleisch, Natalie; Koch, Wolfgang; Sch&#228;fer, Carmen (2019): Aktuelle Aspekte der Internetnutzung in 
Deutschland &#8211; ARD/ZDF-Onlinestudie 2019: Mediale Internetnutzung und Video-on Demand gewinnen
weiter an Bedeutung. In: Media Perspektiven (9/2019), S. 374&#8211;388. Online verf&#252;gbar unter
http://www.ard-zdf-onlinestudie.de/files/2019/0919_Beisch_Koch_Schaefer.pdf, zuletzt abgerufen am
15.07.2020.
Boes, Andreas; Langes, Barbara; L&#252;hr, Thomas; K&#228;mpf, Tobias (2018): Lean und agil im B&#252;ro &#8211; Neue
Organisationskonzepte in der digitalen Transformation und ihre Folgen f&#252;r die Angestellten. Bielefeld:
transcript Verlag. Online verf&#252;gbar unter
https://library.oapen.org/bitstream/handle/20.500.12657/30735/643153.pdf?sequence=1&amp;isAllowed=y, 
zuletzt abgerufen am 07.08.2020.
B&#246;hm, Markus (2017): Aus dem Go-Olymp direkt in den Ruhestand. K&#252;nstliche Intelligenz AlphaGo. 
In: spiegel.de, 29. Mai 2017. Online verf&#252;gbar unter https://www.spiegel.de/netzwelt/games/alphago-
von-deepmind-kuenstliche-intelligenz-geht-in-den-go-ruhestand-a-1149639.html, zuletzt abgerufen am
07.08.2020.
Bojarin, Jan (2014): K&#252;nstliche Intelligenz in Spielen &#8211; Die KI ist so intelligent wie ihre Entwickler.
Hg. v. Golem.de. Online verf&#252;gbar unter https://www.golem.de/news/kuenstliche-intelligenz-in-spielen-
die-ki-ist-so-intelligent-wie-ihre-entwickler-1412-110758.html, zuletzt aktualisiert am 02.12.2014, 
zuletzt abgerufen am 15.07.2020.
Bol&#237;var, Manuel Pedro Rodr&#237;guez (2016): Characterizing the Role of Governments in Smart Cities:
A Literature Review. In: J. Ramon Gil-Garcia, Theresa A. Pardo und Taewoo Nam (Hg.): Smarter as the 
New Urban Agenda, Bd. 11. Cham: Springer International Publishing (Public Administration and 
Information Technology), S. 49&#8211;71.
Bolz, Adrian; Remacly, Christian; Gottschlich, Reiner (2019): Smart City Cologne. Hg. v. Stadt K&#246;ln. Online
verf&#252;gbar unter https://www.smartcity-cologne.de/, zuletzt abgerufen am 17.07.2020.
Bonin, Holger; Gregory, Terry; Zierahn, Ulrich (2015): &#220;bertragung der Studie von Frey/Osborne (2013) auf
Deutschland. Hg. v. Zentrum f&#252;r Europ&#228;ische Wirtschaftsforschung (ZEW). Mannheim (ZEW
Kurzexpertise, No. 57). Online verf&#252;gbar unter
https://www.econstor.eu/bitstream/10419/123310/1/82873271X.pdf, zuletzt abgerufen am 06.08.2020.
Boorsma, Bas (2017): A new digital deal. Beyond smart cities. How best leverage digitalization for the benefit
of our communities. First Edition. Netherlands: Rainmaking Publications.
Borstel, Stefan von; Wisdorff, Flora (2014): Mangelnde Reife bei Azubis. Firmen klagen &#252;ber schlechte
Bewerber, locken aber gleichzeitig mit Dienstwagen. In: welt.de, 22. August 2014. Online verf&#252;gbar
unter https://www.welt.de/print/welt_kompakt/print_wirtschaft/article131474994/Mangelnde-Reife-bei-
Azubis.html, zuletzt abgerufen am 06.08.2020.
Bort, Julie (2019): Bericht: Amazon nutzt ein System, das automatisch K&#252;ndigungen f&#252;r unproduktive
Mitarbeiter schreibt. In: Business Insider, 29. April 2019. Online verf&#252;gbar unter
https://www.businessinsider.de/tech/amazon-system-schreibt-automatisch-kuendigungen-fuer-
mitarbeiter-2019-4/, zuletzt abgerufen am 15.07.2020.
Boulamwini, Joy; Gebru, Timnit (2018): Gender Shades: Intersectional Accuracy Disparities in Commercial
Gender Classification. In: Neil Lawrence und Mark Reid (Hg.): Proceedings of the 1st Conference on 
Fairness, Accountability and Transparency, Bd. 81. Unter Mitarbeit von Sorelle A. Friedler und Christo 
Wilson. Conference on Fairness, Accountability and Transparency. New York, NY, USA, 23 - 24 
Februar 2018. Proceedings of Machine Learning Research (Proceedings of Machine Learning Research, 
81), S. 77&#8211;91. Online verf&#252;gbar unter
http://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf, zuletzt abgerufen am 17.07.2020.
Boutin, Paul (2011): Your Results May Vary. Will the information superhighway turn into a cul-de-sac because 
of automated filters? In: The Wall Street Journal, 20. Mai 2011. Online verf&#252;gbar unter
https://www.wsj.com/articles/SB10001424052748703421204576327414266287254, zuletzt abgerufen 
am 04.08.2020.
Bovenschulte, Marc (2019): Deepfakes. Manipulation von Filmsequenzen. Hg. v. B&#252;ro f&#252;r Technikfolgen-
Absch&#228;tzung beim Deutschen Bundestag (Themenkurzprofil, Nr. 25). Online verf&#252;gbar unter
http://www.tab-beim-bundestag.de/de/pdf/publikationen/themenprofile/Themenkurzprofil-025.pdf, 
zuletzt abgerufen am 08.08.2020.
Boyd, Ashley (2020): Facebook's New Transparency Updates: Helpful, But Not Exhaustive. Hg. v. Mozilla
Foundation. Online verf&#252;gbar unter https://foundation.mozilla.org/en/blog/facebooks-new-transparency-
updates-helpful-not-exhaustive/, zuletzt aktualisiert am 09.01.2020, zuletzt abgerufen am 03.08.2020.
Brandt, Mathias (2019): K&#252;nstliche Intelligenz rechnet sich. Statista. Online verf&#252;gbar unter
https://de.statista.com/infografik/16992/umsatz-der-in-deutschland-durch-ki-anwendungen-beeinflusst-
wird/, zuletzt abgerufen am 20.07.2020.
Brandt, Mathias (2020): Glasfaserausbau kommt in Deutschland kaum voran. Hg. v. Statista GmbH. Online
verf&#252;gbar unter https://de.statista.com/infografik/3553/anteil-von-glasfaseranschluessen-in-
ausgewaehlten-laendern/?utm_campaign=61450e766a-
All_InfographTicker_daily_DE_PM_KW20_2020_Di&amp;utm_medium=email&amp;utm_source=Statista+Glo 
bal&amp;utm_term=0_afecd219f5-61450e766a-305673833&amp;fbclid=IwAR0QuSBHeGpoIFNlzV8VjA-
ytvSl0cOUpT63Ee_pepSntScyxFE-s9RJuRA, zuletzt abgerufen am 14.07.2020.
Br&#228;utigam, Christoph; Enste, Peter; Evans, Michaela; Hilbert, Josef; Merkel, Sebastian; &#214;z, Fikret (2017):
Digitalisierung im Krankenhaus. Mehr Technik &#8211; bessere Arbeit? D&#252;sseldorf: Hans-B&#246;ckler-Stiftung
(FF Forschungsf&#246;rderung, Nr. 364). Online verf&#252;gbar unter http://hdl.handle.net/10419/173275.
Bretschneider, M.; Dr&#246;ssler, S.; Magister, S.; Seidler, A.; Engel, T.; Schmidt, S. et al. (2018): Digitalisierung, 
Industrie 4.0 und Gesundheit &#8211; ein Literaturreview zur empirischen Befundlage. In: Das
Gesundheistwesen. Pr&#228;vention in Lebenswelten &#8211; 54. Jahrestagung der Deutschen Gesellschaft f&#252;r 
Sozialmedizin und Pr&#228;vention (DGSMP) &#8211; Die DGSMP Jahrestagung in Dresden findet statt unter
Beteiligung des MDK Sachsen. Dresden, 12.09.2018 - 14.09.2018: Georg Thieme Verlag KG (Das
Gesundheitswesen), S. 69. Online verf&#252;gbar unter https://www.thieme-
connect.com/products/ejournals/abstract/10.1055/s-0038-1667810, zuletzt abgerufen am 17.07.2020.
Bridle, James (2017): Something is wrong on the internet. Hg. v. medium.com. Online verf&#252;gbar unter
https://medium.com/@jamesbridle/something-is-wrong-on-the-internet-c39c471271d2, zuletzt
aktualisiert am 06.11.2017, zuletzt abgerufen am 31.07.2020.
Brien, J&#246;rn (2018): KI schl&#228;gt 20 Anw&#228;lte bei der Analyse von Vertr&#228;gen klar. Eine k&#252;nstliche Intelligenz (KI)
der Plattform Lawgeex hat in einem Test 20 US-Anw&#228;lte bei der Analyse von Vertr&#228;gen klar hinter sich
gelassen &#8211; sowohl in puncto Genauigkeit als auch bei der Dauer. In: t3n.de, 26. Februar 2018. Online
verf&#252;gbar unter https://t3n.de/news/ki-schlaegt-anwaelte-analyse-963741/, zuletzt abgerufen am
15.07.2020.
Brin, Sergey; Page, Lawrence: The anatomy of a large-scale hypertextual Web search engine. In: Computer
Networks and ISDN Systems 30 (1998), 30 (1998), S. 107&#8211;117. Online verf&#252;gbar unter
https://snap.stanford.edu/class/cs224w-readings/Brin98Anatomy.pdf, zuletzt abgerufen am 16.07.2020.
Brundage, Miles; Avin, Shahar; Clark Jack; Toner, Helen; Eckersley, Peter; Garfinkel, Ben et al. (2018): The
Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation. Hg. v. Future of
Humanity Institute, University of Oxford, Centre for the Study of Existential Risk, University of
Cambridge, Center for a New American Security, Electronic Frontier Foundation und OpenAI. Online
verf&#252;gbar unter https://arxiv.org/ftp/arxiv/papers/1802/1802.07228.pdf, zuletzt abgerufen am
23.07.2020.
Brynjolfsson, Erik; McAfee, Andrew (2016): The second machine age. Work, progress, and prosperity in a
time of brilliant technologies. New York, London: W.W. Norton &amp; Company.
Brynjolfsson, Erik; McAfee, Andrew; Henzler, Herbert A. (2018): The Second Machine Age. Wie die n&#228;chste 
digitale Revolution unser aller Leben ver&#228;ndern wird. Kulmbach: Plassen Verlag.
Brzeski, Carsten; Burk, Inga (2015): Die Roboter kommen. Folgen der Automatisierung f&#252;r den deutschen 
Arbeitsmarkt. Hg. v. ING DiBa Economic Research. Online verf&#252;gbar unter
https://ingwb.de/media/1398074/ing-diba-economic-research-die-roboter-kommen.pdf, zuletzt abgerufen 
am 16.07.2020.
Buchmann, Erik: Datenschutz und Privatheit in vernetzten Informationssystemen. Kapitel 3: Anonymit&#228;t und 
Anonymit&#228;tsma&#223;e. Hg. v. Karlsruher Institut f&#252;r Technologie. Online verf&#252;gbar unter
https://www.ipd.kit.edu/mitarbeiter/buchmann/11SS-Datenschutz/03-Anonymitaet.pdf, zuletzt abgerufen 
am 05.08.2020.
B&#252;hler, Joachim; Rohleder, Bernhard (2018): Autonomes Fahren und vernetzte Mobilit&#228;t. Hg. v. Bitkom e. V. 
und Verband der Technischen &#220;berwachungs-Vereine. Online verf&#252;gbar unter
https://www.bitkom.org/sites/default/files/file/import/Bitkom-Charts-Autonomes-Fahren-und-vernetzte-
Mobilitat-18-04-2018-final.pdf, zuletzt abgerufen am 03.08.2020.
Bundesanstalt f&#252;r Arbeitsschutz und Arbeitsmedizin (2014): Arbeit in der Pflege &#8211; Arbeit am Limit?
Arbeitsbedingungen in der Pflegebranche. 1. Auflage. Dortmund (BIBB/BAuA-Faktenblatt, 10). Online
verf&#252;gbar unter https://www.baua.de/DE/Angebote/Publikationen/Fakten/BIBB-BAuA-
10.pdf?__blob=publicationFile&amp;v=4, zuletzt abgerufen am 15.07.2020.
Bundesanstalt f&#252;r Arbeitsschutz und Arbeitsmedizin (2018): Liefern, lagern und 
bef&#246;rdern &#8211; Arbeitsbedingungen in Verkehrs- und Logistikberufen. 1. Auflage. Dortmund 
(BIBB/BAuA-Faktenblatt, 23). Online verf&#252;gbar unter
https://www.baua.de/DE/Angebote/Publikationen/Fakten/BIBB-BAuA-
23.pdf?__blob=publicationFile&amp;v=8, zuletzt abgerufen am 15.07.2020.
Bundesanstalt f&#252;r Arbeitsschutz und Arbeitsmedizin  (2018): 100 Jahre Achtstundentag. Historische
Meilensteine und aktuelle Zahlen. 1. Auflage. Hg. v. Bundesanstalt f&#252;r Arbeitsschutz und 
Arbeitsmedizin. Dortmund (baua:fokus). Online verf&#252;gbar unter
https://www.baua.de/DE/Angebote/Publikationen/Fakten/100-Jahre-
Achtstundentag.pdf?__blob=publicationFile&amp;v=3, zuletzt abgerufen am 17.07.2020.
Bundesanstalt f&#252;r Finanzdienstleistungsaufsicht (2018): Big Data trifft auf K&#252;nstliche Intelligenz &#8211;-
Herausforderungen und Implikationen f&#252;r Aufsicht und Regulierung von Finanzdienstleistungen. Online
verf&#252;gbar unter https://www.bafin.de/SharedDocs/Downloads/DE/dl_bdai_studie.html, zuletzt abgerufen 
am 23.07.2020.
Bundesinstitut f&#252;r Bau-, Stadt- und Raumforschung (BBSR) im Bundesamt f&#252;r Bauwesen und Raumordnung 
(BBR): Smart City Charta. Digitale Transformation in den Kommunen nachhaltig gestalten = Smart City
Charter ; making digital transformation at the local level sustainable. Stand: Mai 2017. Unter Mitarbeit 
von Eva Schweitzer, Peter Jakubowski und Stephan G&#252;nthner. Bundesinstitut f&#252;r Bau-, Stadt- und 
Raumforschung; Deutschland. Online verf&#252;gbar unter
https://www.bmi.bund.de/SharedDocs/downloads/DE/veroeffentlichungen/themen/bauen/wohnen/smart-
city-charta-kurzfassung-de-und-
en.pdf;jsessionid=62D16CC13D698FDE03739B24BEF3B2E2.2_cid364?__blob=publicationFile&amp;v=4, 
zuletzt abgerufen am 03.08.2020.
Bundesinteressenvertretung f&#252;r alte und pflegebetroffene Menschen e. V. (BIVA-Pflegeschutzbund) (2018):
Digitalisierung in der Altenhilfe. Online verf&#252;gbar unter https://www.biva.de/digitalisierung-in-der-
altenhilfe/, zuletzt aktualisiert am 06.07.2018, zuletzt abgerufen am 10.07.2020.
Bundeskartellamt (28.02.2018): Kl&#246;ckner darf digitale Plattform f&#252;r Stahlprodukte starten. Online verf&#252;gbar
unter
https://www.bundeskartellamt.de/SharedDocs/Meldung/DE/Meldungen%20News%20Karussell/2018/28 
_02_2018_Kloeckner.html, zuletzt abgerufen am 22.07.2020.
Bundesministerium der Justiz und f&#252;r Verbraucherschutz (2020): Entwurf eines Ersten Gesetzes zur Anpassung 
des Urheberrechts an die Erfordernisse des digitalen Binnenmarkts. Diskussionsentwurf. Online
verf&#252;gbar unter
https://www.bmjv.de/SharedDocs/Gesetzgebungsverfahren/Dokumente/DiskE_Anpassung%20Urheberr 
echt_digitaler_Binnenmarkt.pdf;jsessionid=5F1CCAA51B04755785D099B4423C50B4.2_cid289?__blo 
b=publicationFile&amp;v=1, zuletzt abgerufen am 05.08.2020.
Bundesministerium der Justiz und f&#252;r Verbraucherschutz (2020): Netzwerkdurchsetzungsgesetz wird 
weiterentwickelt. Online verf&#252;gbar unter
https://www.bmjv.de/SharedDocs/Pressemitteilungen/DE/2020/040120_NetzDG.html, zuletzt abgerufen 
am 06.08.2020.
Bundesministerium des Innern, f&#252;r Bau und Heimat: Smart Cities: Stadtentwicklung im digitalen Zeitalter.
Online verf&#252;gbar unter https://www.bmi.bund.de/DE/themen/bauen-wohnen/stadt-
wohnen/stadtentwicklung/smart-cities/smart-cities-node.html, zuletzt abgerufen am 03.08.2020.
Bundesministerium des Innern, f&#252;r Bau und Heimat (2019): Binnenwanderung. In: Bundesministerium des
Innern, f&#252;r Bau und Heimat (Hg.): Deutschlandatlas 2019. Bundesamt f&#252;r Bauwesen und Raumordnung, 
S. 16&#8211;17. Online verf&#252;gbar unter https://online.flippingpages.de/live/deutschlandatlas-2019/16/, zuletzt
abgerufen am 23.07.2020.
Bundesministerium des Innern, f&#252;r Bau und Heimat (2019): 13 Modellprojekte Smart Cities ausgew&#228;hlt.
Wissenstransfer soll in die Breite wirken. Online verf&#252;gbar unter
https://www.bmi.bund.de/SharedDocs/pressemitteilungen/DE/2019/07/20190709-smartcities.html,
zuletzt abgerufen am 03.08.2020.
Bundesministerium des Innern, f&#252;r Bau und Heimat: E-Government-Gesetz. E-Government schafft die 
Voraussetzungen f&#252;r zeit- und ortsunabh&#228;ngige Verwaltungsdienste. Die elektronische Verwaltung wird 
auch durch gesetzliche Regelungen gef&#246;rdert. (Moderne Verwaltung). Online verf&#252;gbar unter
https://www.bmi.bund.de/DE/themen/moderne-verwaltung/e-government/e-government-gesetz/e-
government-gesetz-node.html, zuletzt abgerufen am 17.07.2020.
Bundesministerium des Innern, f&#252;r Bau und Heimat: Open Data (Moderne Verwaltung). Online verf&#252;gbar unter
https://www.bmi.bund.de/DE/themen/moderne-verwaltung/open-government/open-data/open-data-
node.html, zuletzt abgerufen am 17.07.2020.
Bundesministerium des Innern, f&#252;r Bau und Heimat (03.09.2019): Auftakt f&#252;r erste Staffel Modellprojekte
Smart Cities. Wissenstransfer soll in die Breite wirken. Berlin. Online verf&#252;gbar unter
https://www.bmi.bund.de/SharedDocs/pressemitteilungen/DE/2019/09/smart-cities-modellprojekte.html, 
zuletzt abgerufen am 17.07.2020.
Bundesministerium f&#252;r Arbeit und Soziales (2019): Qualifizierungsoffensive am Arbeitsmarkt. Online
verf&#252;gbar unter https://www.bmas.de/DE/Schwerpunkte/Nationale-
Weiterbildungsstrategie/qualifizierungsoffensive.html;jsessionid=84AA1130EAF7F7E1B3F9B0D24F22 
785B, zuletzt abgerufen am 06.08.2020.
Bundesministerium f&#252;r Arbeit und Soziales, Abteilung Grundsatzfragen des Sozialstaats, der Arbeitswelt und 
der sozialen Marktwirtschaft (2016): Weissbuch Arbeiten 4.0. Arbeit weiter denken. Berlin. Online
verf&#252;gbar unter
https://issuu.com/support.bmaspublicispixelpark.de/docs/161121_wei__buch_final?e=26749784/430704 
04, zuletzt abgerufen am 15.07.2020.
Bundesministerium f&#252;r Bildung und Forschung: Be-greifen. Begreifbare, interaktive Experimente: Praxis und 
Theorie im MINT-Studium verbinden. Online verf&#252;gbar unter https://www.technik-zum-menschen-
bringen.de/projekte/be-greifen, zuletzt abgerufen am 16.07.2020.
Bundesministerium f&#252;r Bildung und Forschung: Das Tenure-Track-Programm. Online verf&#252;gbar unter
https://www.bmbf.de/de/wissenschaftlicher-nachwuchs-144.html, zuletzt abgerufen am 07.08.2020.
Bundesministerium f&#252;r Bildung und Forschung (2018): Forschung und Innovation f&#252;r die Menschen. Die
Hightech-Strategie 2025. Online verf&#252;gbar unter https://www.hightech-strategie.de/de/hightech-
strategie-2025-1726.html, zuletzt abgerufen am 23.07.2020.
Bundesministerium f&#252;r Bildung und Forschung (2018): Bekanntmachung. Richtlinie zur F&#246;rderung von 
Forschung und Entwicklung auf dem Gebiet &#8222;Robotische Systeme f&#252;r die Pflege&#8220;, Bundesanzeiger vom
14.11.2018. Online verf&#252;gbar unter https://www.bmbf.de/foerderungen/bekanntmachung-2088.html, 
zuletzt abgerufen am 09.09.2020.
Bundesministerium f&#252;r Bildung und Forschung (2019): Bekanntmachung. Richtlinie zur F&#246;rderung von 
Forschungsinitiativen auf dem Gebiet der &#8222;Mikroelektronik f&#252;r Industrie 4.0 (Elektronik I4.0)&#8220;, 
Bundesanzeiger vom 28.02.2019. Online verf&#252;gbar unter
https://www.bmbf.de/foerderungen/bekanntmachung-2349.html, zuletzt abgerufen am 09.09.2020.
Bundesministerium f&#252;r Bildung und Forschung (2020): Bekanntmachung. Richtlinie zur F&#246;rderung von 
Zuwendungen f&#252;r die Forschung zur digitalen Hochschulbildung &#8211; Innovationen in der
Hochschulbildung durch K&#252;nstliche Intelligenz und Big Data, Bundesanzeiger vom 04.03.2020. Online
verf&#252;gbar unter https://www.bmbf.de/foerderungen/bekanntmachung-2873.html, zuletzt abgerufen am
09.09.2020.
Bundesministerium f&#252;r Bildung und Forschung (2020): SmICS: Smarte Software gegen SARS-CoV-2. Online
verf&#252;gbar unter https://www.gesundheitsforschung-bmbf.de/de/smics-smarte-software-gegen-sars-cov-2-
11471.php, zuletzt abgerufen am 18.09.2020.
Bundesministerium f&#252;r Bildung und Forschung; Bundesministerium f&#252;r Wirtschaft und Energie;
Bundesministerium f&#252;r Verkehr und digitale Infrastruktur (2019): Forschung f&#252;r autonomes Fahren. Ein 
&#252;bergreifender Forschungsrahmen von BMBF, BMWi und BMVI. Aktionsplan. Bundesregierung. 
Online verf&#252;gbar unter
https://www.bmbf.de/upload_filestore/pub/Aktionsplan_Forschung_fuer_autonomes_Fahren.pdf, zuletzt
abgerufen am 23.07.2020.
Bundesministerium f&#252;r Umwelt, Naturschutz und nukleare Sicherheit (21.08.2019): K&#252;nstliche Intelligenz f&#252;r
den Umweltschutz nutzen. Bundesregierung sucht KI-Leuchtturmprojekte. Pressemitteilung Nr. 141/19. 
Online verf&#252;gbar unter https://www.bmu.de/pressemitteilung/kuenstliche-intelligenz-fuer-den-
umweltschutz-nutzen/, zuletzt abgerufen am 07.08.2020.
Bundesministerium f&#252;r Verkehr und digitale Infrastruktur: Aktionsplan Schiene: Investieren, modernisieren, 
digitalisieren. Online verf&#252;gbar unter https://www.bmvi.de/SharedDocs/DE/Artikel/E/finanzierung-
schiene.html, zuletzt abgerufen am 29.07.2020.
Bundesministerium f&#252;r Verkehr und digitale Infrastruktur: Bundesverkehrswegeplan 2030. Online verf&#252;gbar
unter https://www.bmvi.de/SharedDocs/DE/Anlage/G/BVWP/bvwp-2030-
kabinettsplan.pdf?__blob=publicationFile, zuletzt abgerufen am 03.08.2020.
Bundesministerium f&#252;r Verkehr und digitale Infrastruktur: Der Schienenpakt steht! Die Schiene ist f&#252;r uns der
Verkehrstr&#228;ger Nummer Eins. Online verf&#252;gbar unter
https://www.bmvi.de/SharedDocs/DE/Artikel/E/zukunftsbuendnis-schiene-uebersicht.html, zuletzt 
abgerufen am 29.07.2020.
Bundesministerium f&#252;r Verkehr und digitale Infrastruktur: Digitale Testfelder. Online verf&#252;gbar unter
https://www.bmvi.de/DE/Themen/Digitales/Digitale-Testfelder/Digitale-Testfelder.html, zuletzt 
abgerufen am 28.07.2020.
Bundesministerium f&#252;r Verkehr und digitale Infrastruktur (2017): Ma&#223;nahmenplan der Bundesregierung zum
Bericht der Ethik-Kommission Automatisiertes und Vernetztes Fahren. (Ethik-Regeln f&#252;r
Fahrcomputer). Online verf&#252;gbar unter
https://www.bmvi.de/SharedDocs/DE/Publikationen/DG/massnahmenplan-zum-bericht-der-
ethikkommission-avf.pdf?__blob=publicationFile, zuletzt abgerufen am 28.07.2020.
Bundesministerium f&#252;r Verkehr und digitale Infrastruktur (2018): Machbarkeitsstudie zum Projekt Zukunft
Bahn (ETCS/NeuPro). Kernergebnisse der Studie von McKinsey &amp; Company f&#252;r das
Bundesministerium f&#252;r Verkehr und digitale Infrastruktur. Online verf&#252;gbar unter
https://www.bmvi.de/SharedDocs/DE/Anlage/E/machbarkeitsstudie-zukunft-
bahn.pdf?__blob=publicationFile, zuletzt abgerufen am 03.08.2020.
Bundesministerium f&#252;r Verkehr und digitale Infrastruktur (2018): Digitalisierung und K&#252;nstliche Intelligenz in 
der Mobilit&#228;t. Aktionsplan. Online verf&#252;gbar unter
https://www.bmvi.de/SharedDocs/DE/Anlage/DG/aktionsplan-ki.pdf?__blob=publicationFile, zuletzt
abgerufen am 24.07.2020.
Bundesministerium f&#252;r Verkehr und digitale Infrastruktur (2020): Mobilit&#228;t in Deutschland. Online verf&#252;gbar
unter https://www.bmvi.de/SharedDocs/DE/Artikel/G/mobilitaet-in-deutschland.html, zuletzt aktualisiert 
am Februar 2020, zuletzt abgerufen am 23.07.2020.
Bundesministerium f&#252;r Wirtschaft und Energie: Die Reallabore-Strategie des BMWi. Online verf&#252;gbar unter
https://www.bmwi.de/Redaktion/DE/Dossier/reallabore-testraeume-fuer-innovation-und-
regulierung.html, zuletzt abgerufen am 28.07.2020.
Bundesministerium f&#252;r Wirtschaft und Energie: Kommission Wettbewerbsrecht 4.0. Online verf&#252;gbar unter
https://www.bmwi.de/Redaktion/DE/Artikel/Wirtschaft/kommission-wettbewerbsrecht-4-0.html, zuletzt
abgerufen am 03.08.2020.
Bundesministerium f&#252;r Wirtschaft und Energie (2018): Monitoring-Report Wirtschaft DIGITAL 2018. Online
verf&#252;gbar unter https://www.bmwi.de/Redaktion/DE/Publikationen/Digitale-Welt/monitoring-report-
wirtschaft-digital-2018-langfassung.pdf?__blob=publicationFile&amp;v=12, zuletzt abgerufen am
13.07.2020.
Bundesministerium f&#252;r Wirtschaft und Energie (2019): Industriestrategie 2030. Online verf&#252;gbar unter
https://www.bmwi.de/Redaktion/DE/Publikationen/Industrie/industriestrategie-
2030.pdf?__blob=publicationFile&amp;v=20, zuletzt abgerufen am 18.08.2020.
Bundesministerium f&#252;r Wirtschaft und Energie (2019): Von der Idee zum Markterfolg. Programme f&#252;r einen 
innovativen Mittelstand. Online verf&#252;gbar unter
https://www.bmwi.de/Redaktion/DE/Publikationen/Technologie/von-der-idee-zum-markterfolg-
innovationsprogramme-fuer-den-mittelstand.pdf?__blob=publicationFile&amp;v=42, zuletzt abgerufen am
21.07.2020.
Bundesministerium f&#252;r Wirtschaft und Energie (2019): Wirtschaftsmotor Mittelstand &#8211; Zahlen und Fakten zu 
den deutschen KMU. Online verf&#252;gbar unter
https://www.bmwi.de/Redaktion/DE/Publikationen/Mittelstand/wirtschaftsmotor-mittelstand-zahlen-
und-fakten-zu-den-deutschen-kmu.html, zuletzt abgerufen am 21.07.2020.
Bundesministerium f&#252;r Wirtschaft und Energie (18.04.2019): Innovationswettbewerb &#8222;K&#252;nstliche Intelligenz 
als Treiber f&#252;r volkswirtschaftlich relevante &#214;kosysteme&#8220;. Online verf&#252;gbar unter https://www.digitale-
technologien.de/DT/Redaktion/DE/Kurzmeldungen/Aktuelles/2019/DT/2019_01_25_DT_Kuenstliche_I 
ntelligenz.html, zuletzt abgerufen am 21.07.2020.
Bundesministerium f&#252;r Wirtschaft und Energie (2019): Das Projekt GAIA-X. Eine vernetzte Dateninfrastruktur
als Wiege eines vitalen, europ&#228;ischen &#214;kosystems. Unter Mitarbeit von Bundesministerium f&#252;r Bildung 
und Forschung. Online verf&#252;gbar unter https://www.bmwi.de/Redaktion/DE/Publikationen/Digitale-
Welt/das-projekt-gaia-x.pdf?__blob=publicationFile&amp;v=22, zuletzt abgerufen am 03.08.2020.
Bundesministerium f&#252;r Wirtschaft und Energie (2019): Gesundheitswirtschaft &#8211; Fakten &amp; Zahlen. Ergebnisse
der Gesundheitswirtschaftlichen Gesamtrechnung, Ausgabe 2018. Online verf&#252;gbar unter
https://www.bmwi.de/Redaktion/DE/Publikationen/Wirtschaft/gesundheitswirtschaft.pdf?__blob=public 
ationFile&amp;v=3-fakten-zahlen-2018.pdf?__blob=publicationFile&amp;v=3, zuletzt abgerufen am 10.07.2020.
Bundesministerium f&#252;r Wirtschaft und Energie (2020): Einsatz von K&#252;nstlicher Intelligenz in der Deutschen 
Wirtschaft. Stand der KI-Nutzung im Jahr 2019. Online verf&#252;gbar unter
https://www.bmwi.de/Redaktion/DE/Publikationen/Wirtschaft/einsatz-von-ki-deutsche-
wirtschaft.pdf?__blob=publicationFile&amp;v=8, zuletzt abgerufen am 16.07.2020.
Bundesnetzagentur: Frequenzaktion 2019. Az: BK1-17/001. Online verf&#252;gbar unter
https://www.bundesnetzagentur.de/DE/Sachgebiete/Telekommunikation/Unternehmen_Institutionen/Bre 
itband/MobilesBreitband/Frequenzauktion/2019/Auktion2019.html?nn=268128, zuletzt abgerufen am
28.07.2020.
Bundesnetzagentur (2018): Jahresbericht 2018. 20 Jahre Verantwortung f&#252;r Netze. Online verf&#252;gbar unter
https://www.bundesnetzagentur.de/SharedDocs/Downloads/DE/Allgemeines/Bundesnetzagentur/Publika 
tionen/Berichte/2019/JB2018.pdf?__blob=publicationFile&amp;v=5, zuletzt abgerufen am 28.07.2020.
Bundesnetzagentur (2020): Mobiles Breitband. Versorgung der Bev&#246;lkerung mit funkgest&#252;tzten 
Breitbandanschl&#252;ssen. Online verf&#252;gbar unter
https://www.bundesnetzagentur.de/DE/Sachgebiete/Telekommunikation/Unternehmen_Institutionen/Fre 
quenzen/OeffentlicheNetze/Mobilfunknetze/mobilfunknetze-node.html, zuletzt abgerufen am
23.07.2020.
Bundespolizei (2019): Test intelligenter Videoanalyse-Technik. Online verf&#252;gbar unter
https://www.bundespolizei.de/Web/DE/04Aktuelles/01Meldungen/2019/06/190607_videoanalyse.html, 
zuletzt aktualisiert am 07.06.2019, zuletzt abgerufen am 17.07.2020.
Bundespolizeipr&#228;sidium (2018): Abschlussbericht des Bundespolizeipr&#228;sidiums zur biometrischen 
Gesichtserkennung. Erprobung von Systemen zur intelligenten Videoanalyse. Abschlussbericht. 
Potsdam. Online verf&#252;gbar unter
https://www.bundespolizei.de/Web/DE/04Aktuelles/01Meldungen/2018/10/181011_abschlussbericht_ge 
sichtserkennung_down.pdf;jsessionid=0A54A284F5BA134602B7B17D783E1D26.2_cid324?__blob=p 
ublicationFile&amp;v=1, zuletzt abgerufen am 17.07.2020.
Bundesregierung (2016): Rechtssicherheit f&#252;r automatisiertes Fahren. Strassenverkehr 4.0. Online verf&#252;gbar
unter https://www.bundesregierung.de/breg-de/aktuelles/rechtssicherheit-fuer-automatisiertes-fahren-
349048, zuletzt aktualisiert am 04.11.2016, zuletzt abgerufen am 28.07.2020.
Bundesregierung (2018): Strategie K&#252;nstliche Intelligenz der Bundesregierung. Online verf&#252;gbar unter
https://www.bmbf.de/files/Nationale_KI-Strategie.pdf, zuletzt abgerufen am 27.07.2020.
Bundesregierung (2020): KI spielt die Musik. Online verf&#252;gbar unter https://www.bundesregierung.de/breg-
de/aktuelles/ki-in-der-kultur-1720970.
Bundesregierung (2020): Digitale Stadtentwicklung und F&#246;rderung von Smart Cities. Online verf&#252;gbar unter
https://www.bundesregierung.de/breg-de/themen/digital-made-in-de/digitale-stadtentwicklung-und-
foerderung-von-smart-cities-1546630, zuletzt abgerufen am 03.08.2020.
Bundesregierung (2020): Gestaltung einer digitalen Ordnungspolitik. Online verf&#252;gbar unter
https://www.bundesregierung.de/breg-de/themen/digital-made-in-de/gestaltung-einer-digitalen-
ordnungspolitik-1547010, zuletzt abgerufen am 05.08.2020.
Bundesverband der Deutschen Fluggesellschaften (2017): Single European Sky &#8211; Europas gr&#246;&#223;tes CO2-
Senkungsprojekt. Flugsicherung. Online verf&#252;gbar unter
http://www.bdf.aero/files/6014/9606/7996/15._Umsetzungspotentiale_SES.pdf, zuletzt abgerufen am
03.08.2020.
Bundesverband der Deutschen Industrie e. V. (2018): Innovationsindikator 2018. Online verf&#252;gbar unter
http://www.innovationsindikator.de/fileadmin/content/2018/pdf/Innovationsindikator__2018.pdf, zuletzt
abgerufen am 21.07.2020.
Bundesverband der Deutschen Industrie e. V. (2019): K&#252;nstliche Intelligenz in Sicherheit und Verteidigung. 
Handlungsempfehlungen der deutschen Industrie. Positionspapier (BDI-Publikation, 0083). Online
verf&#252;gbar unter https://e.issuu.com/embed.html#2902526/66182763, zuletzt abgerufen am 20.07.2020.
Bundesverband der Deutschen Industrie e. V.; Deutsche Bank AG (2018): Die gr&#246;&#223;ten Familienunternehmen in 
Deutschland. Unternehmensbefragung 2018 &#8211; Kooperation mit Start-ups. Online verf&#252;gbar unter
https://e.issuu.com/embed.html#2902526/63072616, zuletzt abgerufen am 21.07.2020.
Bundesverband der Deutschen Luftverkehrswirtschaft: Luftfahrt sichert mehr als 800.000 Arbeitspl&#228;tze in 
Deutschland. Online verf&#252;gbar unter https://www.bdl.aero/de/themen-positionen/bedeutung-des-
luftverkehrs/luftfahrt-sichert-mehr-als-800-000-arbeitsplaetze-in-deutschland/, zuletzt abgerufen am
03.08.2020.
Bundesverband der Deutschen Luftverkehrswirtschaft (2018): Was bedeutet Luftfracht f&#252;r Deutschland? Eine
Analyse der volkswirtschaftlichen Bedeutung, der Funktionsweise, der Prozesse sowie des Wettbewerbs
im Luftfrachtverkehr. Online verf&#252;gbar unter https://www.bdl.aero/wp-content/uploads/2018/10/was-
bedeutet-luftfracht-fur-deutschland.pdf, zuletzt abgerufen am 03.08.2020.
Bundesverband Deutscher Kapitalbeteiligungsgesellschaften e.V; Internet Economy Foundation; Roland 
Berger GmbH (2018): Treibstoff Venture Capital. Wie wir Innovation und Wachstum befeuern. Online
verf&#252;gbar unter
https://www.bvkap.de/sites/default/files/news/vc_studie_von_ief_bvk_roland_berger_treibstoff_venture 
_capital.pdf, zuletzt abgerufen am 30.07.2020.
Bundesverband Digitale Wirtschaft e. V (2018): K&#252;nstliche Intelligenz im Handel &#8211; Vom Professional Butler 
zur DSGVO. Online verf&#252;gbar unter
https://www.bvdw.org/themen/publikationen/detail/artikel/whitepaper-kuenstliche-intelligenz-im-
handel-vom-professional-butler-zur-dsgvo/, zuletzt abgerufen am 23.07.2020.
Bundesverband Musikindustrie e. V.; GfK Entertainment GmbH (2019): Umsatz. Online verf&#252;gbar unter
https://www.musikindustrie.de/markt-bestseller/musikindustrie-in-zahlen/umsatz, zuletzt abgerufen am
16.09.2020.
Bundeszentrale f&#252;r politische Bildung (2017): Was ist Hate Speech? Online verf&#252;gbar unter
https://www.bpb.de/252396/was-ist-hate-speech, zuletzt aktualisiert am 12.07.2017, zuletzt abgerufen 
am 05.08.2020.
Bundeszentrale f&#252;r politische Bildung (2018): Ranking &#8211; Die 50 gr&#246;&#223;ten Medienkonzerne 2018. Institut f&#252;r
Medien- und Kommunikationspolitik gGmbH. Online verf&#252;gbar unter
https://www.mediadb.eu/datenbanken/internationale-medienkonzerne.html, zuletzt aktualisiert am
10.03.2020, zuletzt abgerufen am 09.09.2020.
Bundeszentrale f&#252;r politische Bildung (2019): US-Dominanz an der Spitze: Neues Ranking der gr&#246;&#223;ten 
Medien- und Wissenskonzerne der Welt 2018. Institut f&#252;r Medien- und Kommunikationspolitik. Online
verf&#252;gbar unter https://www.mediadb.eu/dossiers/dossiers/newsdetail/article/us-dominanz-an-der-spitze-
neues-ranking-der-groessten-medien-und-wissenskonzerne-der-welt.html, zuletzt aktualisiert am
10.03.2020, zuletzt abgerufen am 09.09.2020.
B&#252;nte, Oliver (2019): Wahlbeeinflussung durch Social Media: Facebook liefert Daten f&#252;r Studie. Hg. 
v.heise.de. Online verf&#252;gbar unter https://www.heise.de/newsticker/meldung/Wahlbeeinflussung-durch-
Social-Media-Facebook-liefert-Daten-fuer-Studie-4410132.html, zuletzt aktualisiert am 30.04.2019,
zuletzt abgerufen am 31.07.2020.
Burchardt, Aljoscha; Uszkoreit, Hans (2018): IT f&#252;r soziale Inklusion. Digitalisierung &#8211; K&#252;nstliche Intelligenz
&#8211; Zukunft f&#252;r alle. M&#252;nchen, Wien: De Gruyter Oldenbourg.
B&#252;rgerschaft der Freien und Hansestadt Hamburg (2018): Bericht der Enquete-Kommission Kinderschutz und 
Kinderrechte weiter st&#228;rken: &#220;berpr&#252;fung, Weiterentwicklung, Umsetzung und Einhaltung gesetzlicher
Grundlagen, fachlicher Standards und Regeln in der Kinder- und Jugendhilfe &#8211; Verbesserung der 
Interaktion der verschiedenen Systeme und Akteurinnen und Akteure&#8220;. Hamburg (Drucksache
21/16000). Online verf&#252;gbar unter https://www.buergerschaft-
hh.de/parldok/dokument/65251/bericht_der_enquete_kommission_kinderschutz_und_kinderrechte_weit 
er_staerken_ueberpruefung_weiterentwicklung_umsetzung_und_einhaltung_gesetzlicher_gru.pdf, 
zuletzt abgerufen am 28.08.2020.
Butollo, Florian; Ehrlich, Martin; Engel, Thomas (2017): Amazonisierung der Industriearbeit? Industrie 4.0, 
Intralogistik und die Ver&#228;nderung der Arbeitsverh&#228;ltnisse in einem Montageunternehmen der
Automobilindustrie. In: Arbeit Zeitschrift f&#252;r Arbeitsforschung, Arbeitsgestaltung und Arbeitspolitik 26 
(1), S. 33&#8211;59.
Butollo, Florian; J&#252;rgens, Ulrich; Krzywdzinski, Martin (2018): Von Lean Production zur Industrie 4.0. Mehr
Autonomie f&#252;r die Besch&#228;ftigten? In: Arbeits- und Industriesoziologische Studien 11, Oktober 2018 
(Heft-Nr. 2), S. 75&#8211;90. Online verf&#252;gbar unter https://www.arbsoz.de/ais-studien-leser/56-von-lean-
production-zur-industrie, zuletzt abgerufen am 17.07.2020.
B&#252;ttgen, Patrick (2019): Smart City Index: Hamburg ist die smarteste Stadt Deutschlands. Online verf&#252;gbar
unter https://t3n.de/news/smart-city-index-hamburg-stadt-1209069/?, zuletzt aktualisiert am 19.10.2019,
zuletzt abgerufen am 16.07.2020.
B&#252;ttner, Nico (2018): KI in Computerspielen und was sie uns &#252;ber KI in der Gesch&#228;ftswelt lehren kann. 
Hg. v. SAS Institute Inc. Online verf&#252;gbar unter https://blogs.sas.com/content/sasdach/2018/12/03/ki-in-
computerspielen-was-sie-uns-uber-ki-in-der-geschaftswelt-lehrt/, zuletzt aktualisiert am 03.12.2018,
zuletzt abgerufen am 15.07.2020.
Buytendijk, Frank; Vashisth, Shubhangi; Duncan, Alan D.; Moran, Michael P. (2016): Kick-Start the
Conversation on Digital Ethics, 2016. Hg. v. Gartner.
Case, Steve (2016): The third wave. An entrepreneur's vision of the future. First Simon &amp; Schuster trade
paperback edition, New expanded edition. New York: Simon &amp; Schuster Paperbacks.
Castle, Jarrod; Fornaro, Celine; Genovesi, Darryl; Lin, Eric; Strauss, David E.; Wadewitz, Thomas; Edridge, 
Dominic (2017): Flying solo &#8211; how far are we down the path towards pilotless planes? Hg. v. UBS
Limited (Q-Series). Online verf&#252;gbar unter https://neo.ubs.com/shared/d1ssGmLAVeEB/ues81939.pdf, 
zuletzt abgerufen am 24.07.2020.
CDU, CSU, SPD (2018): Ein neuer Aufbruch f&#252;r Europa Eine neue Dynamik f&#252;r Deutschland Ein neuer
Zusammenhalt f&#252;r unser Land. Koalitionsvertrag zwischen CDU, CSU und SPD. 19. Legislaturperiode. 
Online verf&#252;gbar unter
https://www.bundesregierung.de/resource/blob/975226/847984/5b8bc23590d4cb2892b31c987ad672b7/ 
2018-03-14-koalitionsvertrag-data.pdf?download=1, zuletzt aktualisiert am 14.03.2018, zuletzt
abgerufen am 17.07.2020.
Center for Financial Studies (2018): CFS-Umfrage: K&#252;nstliche Intelligenz wird zuk&#252;nftig zu den Kernthemen 
der Finanzindustrie z&#228;hlen &#8211; Mehr Initiative zur Information und Aufkl&#228;rung der Bev&#246;lkerung sinnvoll. 
Online verf&#252;gbar unter https://www.ifk-cfs.de/de/media-lounge/news-newsletter/artikel/article/cfs-
survey-artificial-intelligence-will-be-one-of-the-core-topics-of-the-financial-industry-in-the.html, zuletzt 
abgerufen am 30.07.2020.
Centre for Data Ethics and Innovation (2020): Review of online targeting: Final report and recommendations. 
Online verf&#252;gbar unter
https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/86416 
7/CDEJ7836-Review-of-Online-Targeting-05022020.pdf, zuletzt abgerufen am 04.08.2020.
Chanler, Mike; Dye, Colleen; Coppinger, Catherine; Nieh, Gina; Maris, Tudor (2019): Global Talent Trends
2019. The 4 trends transforming your workplace. Hg. v. LinkedIn. Online verf&#252;gbar unter
https://app.box.com/s/c5scskbsz9q6lb0hqb7euqeb4fr8m0bl/file/388525098383, zuletzt abgerufen am
07.08.2020.
Chen, Angela; Hao, Karen (2020): Emotion AI researchers say overblown claims give their work a bad name. 
A lack of government regulation isn&#8217;t just bad for consumers. It&#8217;s bad for the field, too. In:
technologyreview.com, 14. Februar 2020. Online verf&#252;gbar unter
https://www.technologyreview.com/2020/02/14/844765/ai-emotion-recognition-affective-computing-
hirevue-regulation-ethics/, zuletzt abgerufen am 05.08.2020.
Chen, Chaona; Crivelli, Carlos; Garrod, Oliver G. B.; Schyns, Philippe G.; Fern&#225;ndez-Dols, Jos&#233;-Miguel; Jack,
Rachael E. (2018): Distinct facial expressions represent pain and pleasure across cultures. In:
Proceedings of the National Academy of Sciences of the United States of America 115 (43), E10013-
E10021. 
Chesney, Robert; Citron, Danielle (2019): Deepfakes and the New Disinformation War &#8211; The Coming Age of
Post-Truth Geopolitics. In: Foreign Affairs, S. 147. Online verf&#252;gbar unter
https://www.foreignaffairs.com/articles/world/2018-12-11/deepfakes-and-new-disinformation-
war?cid=otr-authors-january_february_2019-121118, zuletzt abgerufen am 30.07.2020.
Choi, Youn I.; Chung, Jun-Won; Kim, Kyoung Oh; Kwon, Kwang An; Kim, Yoon Jae; Park, Dong Kyun et al. 
(2019): Concordance Rate between Clinicians and Watson for Oncology among Patients with Advanced 
Gastric Cancer: Early, Real-World Experience in Korea. In: Canadian journal of gastroenterology &amp;
hepatology 2019, S. 8072928. 
Choudhury, Olivia; Gkoulalas-Divanis, Aris; Salonidis, Theodoros; Sylla, Issa; Park, Yoonyoung; Hsu, Grace;
Das, Amar (2020): Anonymizing Data for Privacy-Preserving Federated Learning. Online verf&#252;gbar
unter https://arxiv.org/pdf/2002.09096.pdf, zuletzt abgerufen am 05.08.2020.
Christian-Albrechts-Universit&#228;t zu Kiel Philosophische Fakult&#228;t: Sch&#246;nheit im &#8222;Auge&#8220; der Algorithmen. 
Online verf&#252;gbar unter https://digitalekultur.medienpaedagogik.uni-kiel.de/archiv/impuls/23, zuletzt 
abgerufen am 06.08.2020.
Christian-Albrechts-Universit&#228;t zu Kiel Philosophische Fakult&#228;t Institut f&#252;r P&#228;dagogik: Student Crowd 
Research (SCoRe). Online verf&#252;gbar unter https://www.medienpaedagogik.uni-kiel.de/de/profil/student-
crowd-research-score, zuletzt abgerufen am 06.08.2020.
Christl, Wolfie (2019): Microtargeting, Pers&#246;nliche Daten als politische W&#228;hrung. Daten&#246;konomie. In: Aus
Politik und Zeitgeschichte (APuZ) 69 (24-26), S. 42&#8211;48. Online verf&#252;gbar unter
https://www.bpb.de/system/files/dokument_pdf/APuZ_2019-24-26_online.pdf, zuletzt abgerufen am
03.08.2020.
Chuvpilo, Gleb (2019): AI Research Rankings 2019: Insights from NeurIPS and ICML, Leading AI
Conferences. Hg. v. medium.com. Online verf&#252;gbar unter https://medium.com/@chuvpilo/ai-research-
rankings-2019-insights-from-neurips-and-icml-leading-ai-conferences-ee6953152c1a, zuletzt abgerufen 
am 07.08.2020.
Cire&#351;an, Dan C.; Giusti, Alessandro; Gambardella, Luca M.; Schmidhuber, J&#252;rgen (2013): Mitosis detection in 
breast cancer histology images with deep neural networks. In: Medical image computing and
computerassisted intervention : MICCAI International Conference on Medical Image Computing and Computer-
Assisted Intervention 16 (Pt 2), S. 411&#8211;418. 
Conradi, Malte (2019): Uber stemmt Mega-B&#246;rsengang &#8211; und entt&#228;uscht trotzdem. In: s&#252;ddeutsche.de, 10. Mai
2019. Online verf&#252;gbar unter https://www.sueddeutsche.de/wirtschaft/uber-boersengang-1.4440657, 
zuletzt abgerufen am 21.08.2020.
contentmanager.de (2018): Drei Use Cases f&#252;r K&#252;nstliche Intelligenz im Digital Publishing &#8211; Was wir von
gro&#223;en Medienh&#228;usern lernen k&#246;nnen. Online verf&#252;gbar unter
https://www.contentmanager.de/cms/contentpepper/drei-use-cases-fuer-kuenstliche-intelligenz-im-
digital-publishing-was-wir-von-grossen-medienhaeusern-lernen-koennen/, zuletzt aktualisiert am
15.05.2018, zuletzt abgerufen am 15.07.2020.
Corbett-Davies, Sam; Goel, Sharad (2018): The Measure and Mismeasure of Fairness: A Critical Review of
Fair Machine Learning. Online verf&#252;gbar unter https://arxiv.org/pdf/1808.00023.pdf, zuletzt abgerufen 
am 04.08.2020.
D64 - Zentrum f&#252;r Digitalen Fortschritt (2018): Der Einfluss K&#252;nstlicher Intelligenz auf Freiheit, Gerechtigkeit 
und Solidarit&#228;t. Online verf&#252;gbar unter https://d-64.org/wp-content/uploads/2018/11/D64-Grundwerte-
KI.pdf, zuletzt abgerufen am 20.07.2020.
Dahlmann, Anja; Dickow, Marcel (2019): Pr&#228;ventive Regulierung autonomer Waffensysteme. 
Handlungsbedarf f&#252;r Deutschland auf verschiedenen Ebenen. Hg. v. Stiftung Wissenschaft und Politik. 
Berlin (SWP-Studie, 1). Online verf&#252;gbar unter https://www.swp-
berlin.org/fileadmin/contents/products/studien/2019S01_dkw_dnn.pdf, zuletzt abgerufen am 20.07.2020.
Dahlmann, Don (2019): Deutsche Carsharing-Anbieter stehen vor einem Dilemma. Hg. v. gr&#252;nderszene.de
(Drehmoment). Online verf&#252;gbar unter https://www.gruenderszene.de/automotive-mobility/deutsche-
carsharing-anbieter-stehen-vor-einem-riesigen-dilemma, zuletzt abgerufen am 27.07.2020.
Daley, Sam (2019): Surgical Robots, new Medicines and Better Care: 32 Examples of AI in Healthcare. 
Hg. v. BuiltIn. Online verf&#252;gbar unter https://builtin.com/artificial-intelligence/artificial-intelligence-
healthcare, zuletzt aktualisiert am 25.03.2020, zuletzt abgerufen am 10.07.2020.
Daly, Angela; Hagendorff, Thilo; Hui, Li; Mann, Monique; Marda, Vidushi; Wagner, Ben et al. (2019):
Artificial Intelligence Governance and Ethics: Global Perspectives. Online verf&#252;gbar unter
https://arxiv.org/ftp/arxiv/papers/1907/1907.03848.pdf, zuletzt abgerufen am 06.08.2020.
Danish Maritime Authority (2017): Analysis of regulatory barriers to the use of autonomous ships. Final 
Report. Ramboll; CORE Advokatfirma. Online verf&#252;gbar unter
https://www.dma.dk/Documents/Publikationer/Analysis%20of%20Regulatory%20Barriers%20to%20the 
%20Use%20of%20Autonomous%20Ships.pdf, zuletzt abgerufen am 24.07.2020.
Datenaufsichtsbeh&#246;rden des Bundes und der L&#228;nder (2019): Hambacher Erkl&#228;rung zur K&#252;nstlichen Intelligenz. 
Sieben datenschutzrechtliche Anforderungen. Entschlie&#223;ung der 97. Konferenz der unabh&#228;ngigen 
Datenaufsichtsbeh&#246;rden des Bundes und der L&#228;nder. Hambacher Schloss. Online verf&#252;gbar unter
https://www.datenschutzkonferenz-online.de/media/en/20190405_hambacher_erklaerung.pdf, zuletzt
abgerufen am 05.08.2020.
Datenethikkommission der Bundesregierung (2019): Gutachten der Datenethikkommission der
Bundesregierung. Online verf&#252;gbar unter
http://www.bmi.bund.de/SharedDocs/downloads/DE/publikationen/themen/it-digitalpolitik/gutachten-
datenethikkommission.pdf?__blob=publicationFile&amp;v=6, zuletzt abgerufen am 04.08.2020.
Datenschutzbeauftragten des Bundes und der L&#228;nder (1992): Entschlie&#223;ung der 43. Konferenz der
Datenschutzbeauftragten des Bundes und der L&#228;nder. Baden-W&#252;rttemberg. Online verf&#252;gbar unter
https://datenschutz.sachsen-anhalt.de/konferenzen/nationale-
datenschutzkonferenz/entschliessungen/entschliessung-der-43-konferenz-am-2324-maerz-1992-
inbaden-wuerttemberg/arbeitnehmerdatenschutz/, zuletzt abgerufen am 05.08.2020.
Daum, Mario (2018): Digitaler Wandel in Call- und Service-Centern: Aktuelle Trends und ihre Folgen f&#252;r
Arbeitsorganisation und Besch&#228;ftigte. Hg. v. Hans B&#246;ckler Stiftung (Working Paper
Forschungsf&#246;rderung, 102). Online verf&#252;gbar unter
https://www.econstor.eu/bitstream/10419/216027/1/hbs-fofoe-wp-102-2018.pdf, zuletzt abgerufen am
04.08.2020.
Davis, Fred D. (1989): Perceived Usefulness, Perceived Ease of Use, and User Acceptance of Information 
Technology. In: MIS Quarterly 13 (3), S. 319&#8211;340. 
DB Netz AG (2014): European Train Control System (ETCS) bei der DB Netz AG. Online verf&#252;gbar unter
https://www.deutschebahn.com/resource/blob/1303328/d9556ec0c860abb53cf07bfcb693f79d/Anhang_T 
hemendienst_ETCS-data.pdf, zuletzt abgerufen am 24.07.2020.
DB Vertrieb (2020): Digitale Weichendiagnose mit DIANA. Infografik: Mithilfe von DIANA und Sensoren 
St&#246;rungen fr&#252;hzeitig erkennen. Online verf&#252;gbar unter https://inside.bahn.de/digitale-weichendiagnose-
diana/, zuletzt aktualisiert am 17.06.2020, zuletzt abgerufen am 03.08.2020.
Deeney, Chris (2019): Six in Ten (61%) Respondents Across 26 Countries Oppose the Use of Lethal
Autonomous Weapons Systems. Opposition to Fully Autonomous Weapons Has Increased Since 2017, 
Up From 56%. Hg. v. Ipsos. Online verf&#252;gbar unter https://www.ipsos.com/en-us/news-polls/human-
rights-watch-six-in-ten-oppose-autonomous-weapons, zuletzt abgerufen am 20.07.2020.
Deloitte (2017): Hitting the accelerator: the next generation ofmachine-learning chips. Online verf&#252;gbar unter
https://www2.deloitte.com/content/dam/Deloitte/global/Images/infographics/technologymediatelecomm 
unications/gx-deloitte-tmt-2018-nextgen-machine-learning-report.pdf, zuletzt abgerufen am 23.07.2020.
Deloitte (07.03.2019): Deutsche Unternehmen setzen bei K&#252;nstlicher Intelligenz auf clevere L&#246;sungen &#8222;von 
der Stange&#8220;. State of AI in the Enterprise Survey. D&#252;sseldorf. 05.08.2020, zuletzt abgerufen am
https://www2.deloitte.com/de/de/pages/presse/contents/AI-in-the-Enterprise.html.
Deming, William Edwards (2000): The new economics. For industry, government, education. 2nd ed. 
Cambridge, Mass: MIT Press.
Dengler, Katharina; Matthes, Britta (2018): Substituierbarkeitspotenziale von Berufen &#8211; Wenige Berufsbilder
halten mit der Digitalisierung Schritt. Hg. v. IAB &#8211; Institut f&#252;r Arbeitsmarkt- und Berufsforschung (IAB
Kurzbericht &#8211; Aktuelle Analysen aus dem Institut f&#252;r Arbeitsmarkt- und Berufsforschung, 4/2018). 
Online verf&#252;gbar unter http://doku.iab.de/kurzber/2018/kb0418.pdf, zuletzt abgerufen am 16.07.2020.
Der Bundesbeauftragte f&#252;r den Datenschutz und die Informationsfreiheit (2020): Positionspapier zur
Anonymisierung unter der DSGVO unter besonderer Ber&#252;cksichtigung der TK-Branche. Online
verf&#252;gbar unter https://www.bfdi.bund.de/DE/Infothek/Transparenz/_functions/Konsultation_table.html, 
zuletzt abgerufen am 05.08.2020.
Der Bundesbeauftragte f&#252;r den Datenschutz und die Informationsfreiheit (10.02.2020): BfDI nutzt erstmals
Konsultationsverfahren. Online verf&#252;gbar unter
https://www.bfdi.bund.de/DE/Infothek/Pressemitteilungen/2020/03_Konsultationsverfahren.html,
zuletzt abgerufen am 04.08.2020.
Der Standard (2019): K&#252;nstliche Intelligenz l&#228;sst alte Videospiele fast wie neu aussehen. In: derstandard.de
2019, 26. April 2019. Online verf&#252;gbar unter
https://www.derstandard.de/story/2000101746486/kuenstliche-intelligenz-laesst-alte-videospiele-fast-
wie-neu-aussehen, zuletzt abgerufen am 15.07.2020.
Destatis (2020): Seeverkehr 2019. G&#252;terumschlag in deutschen Seeh&#228;fen um 0,3 % gesunken. Online verf&#252;gbar
unter
https://www.destatis.de/DE/Presse/Pressemitteilungen/2020/03/PD20_107_463.html;jsessionid=8C53D2 
FEEA8357060779E157D1E65052.internet8721, zuletzt abgerufen am 05.08.2020.
Dettmers, Sebastian; Jochmann, Walter; Hermann, Anastasia; Zimmermann, Tobias; Knappstein, Michael;
Fastenroth, Lukas M.; Pela, Patricia (2020): Agile Unternehmen. Zukunftstrend oder Mythos der
digitalen Arbeistwelt. Hg. v. StepStone GmbH und Kienbaum Institut @ ISM f&#252;r Leadership &amp;
Transformation GmbH (Kienbaum &amp; Stepstone Studie 2020).
Dettmers, Tim (2016): A Full Hardware Guide to Deep Learning. Online verf&#252;gbar unter
https://timdettmers.com/2018/12/16/deep-learning-hardware-guide/, zuletzt abgerufen am 23.07.2020.
Deutsche Bahn AG: Ferndiagnose per Flugger&#228;t. Online verf&#252;gbar unter
https://www.deutschebahn.com/de/Digitalisierung/technologie/digitaler_alltag/drohnen-3232264, zuletzt
abgerufen am 03.08.2020.
Deutsche Bahn AG (2019): Integrierter Zwischenbericht Januar-Juni 2019. Deutschland braucht eine starke 
Schiene. Online verf&#252;gbar unter
https://www.deutschebahn.com/resource/blob/4322384/86e13e4d279d89f3ed24c575f5d1297e/Integierte 
r-Zwischenbericht-data.pdf, zuletzt abgerufen am 28.07.2020.
Deutsche Energie Agentur (2017): Analyse der mit erh&#246;htem IT-Einsatz verbundenen Energieverbr&#228;uche
infolge der zunehmenden Digitalisierung. Status Quo und Prognosen. Online verf&#252;gbar unter
https://www.dena.de/fileadmin/dena/Dokumente/Pdf/9232_dena-Metastudie_Analyse_IT-
Einsatz_Energieverbraeuche_Digitalisierung.pdf, zuletzt abgerufen am 23.07.2020.
Deutsche Flugsicherung: Single European Sky. Online verf&#252;gbar unter
https://www.dfs.de/dfs_homepage/de/Europa/Single%20European%20Sky/, zuletzt abgerufen am
03.08.2020.
Deutsche Flugsicherung (2019): Luftverkehr in Deutschland. Mobilit&#228;tsbericht 2018. Online verf&#252;gbar unter
https://www.dfs.de/dfs_homepage/de/Presse/Publikationen/Mobilitaetsbericht_2018_Web_k.pdf, zuletzt
abgerufen am 03.08.2020.
Deutsche Forschungsgemeinschaft (2019): Leitlinien zur Sicherung guter wissenschaftlicher Praxis. Kodex. 
Bonn. Online verf&#252;gbar unter
https://www.dfg.de/download/pdf/foerderung/rechtliche_rahmenbedingungen/gute_wissenschaftliche_pr 
axis/kodex_gwp.pdf, zuletzt abgerufen am 06.08.2020.
Deutsche Hochschulmedizin e. V. (2014): Medizinischer Fortschritt braucht leistungsstarke IT-L&#246;sungen. 
Road-Map Deutsche Hochschulmedizin e. V. f&#252;r die Weiterentwicklung der IT-Infrastruktur. Deutsche
Hochschulmedizin e. V. Online verf&#252;gbar unter
https://www.uniklinika.de/fileadmin/user_upload/pdf/2014-07-
09_Deutsche_Hochschulmedizin_ e. V._IT-Positionspapier_Final.pdf, zuletzt abgerufen am 09.07.2020.
Deutsche Vereinigung f&#252;r gewerblichen Rechtschutz und Urheberrecht e. V. (2019): Stellungnahme des GRUR
Fachausschusses f&#252;r Urheber- und Verlagsrecht zur Umsetzung der EU-RLn im Urheberrecht (DSM-RL 
(EU) 2019/790 und Online-SatCab-RL (EU) 2019/789). Online verf&#252;gbar unter
https://www.bmjv.de/SharedDocs/Gesetzgebungsverfahren/Stellungnahmen/2019/Downloads/090519_S 
tellungnahme_GRUR_EU-Richtlinien_Urheberrecht.pdf?__blob=publicationFile&amp;v=2, zuletzt
abgerufen am 05.08.2020.
Deutscher Ethikrat (2017): Big Data und Gesundheit. Datensouver&#228;nit&#228;t als informationelle Freiheitsgestaltung 
: Stellungnahme. Berlin. Online verf&#252;gbar unter
https://www.ethikrat.org/fileadmin/Publikationen/Stellungnahmen/deutsch/stellungnahme-big-data-und-
gesundheit.pdf, zuletzt abgerufen am 09.07.2020.
Deutscher Gewerkschaftsbund (2018): Stellungnahme zu den Eckpunkten der Bundesregierung f&#252;r eine
Strategie K&#252;nstliche Intelligenz vom 18. Juli 2018. Online verf&#252;gbar unter
https://www.dgb.de/downloadcenter/++co++f5babc7e-cb9f-11e8-b533-52540088cada, zuletzt abgerufen 
am 20.07.2020.
Deutscher Gewerkschaftsbund (2019): K&#252;nstliche Intelligenz und die Arbeit von morgen. Ein Impulspapier des 
Deutschen Gewerkschaftsbundes zur Debatte um K&#252;nstliche Intelligenz (KI) in der Arbeitswelt. Online
verf&#252;gbar unter https://www.dgb.de/uber-uns/dgb-heute/arbeit-der-zukunft/++co++3efc0928-cd76-11e9-
81dd-52540088cada, zuletzt abgerufen am 30.07.2020.
Deutscher Gewerkschaftsbund (2020): K&#252;nstliche Intelligenz (KI) f&#252;r Gute Arbeit. Ein Konzeptpapier des
DGB zum Einsatz von K&#252;nstlicher Intelligenz (KI) in der Arbeitswelt. Online verf&#252;gbar unter
https://www.dgb.de/++co++c6d62716-8473-11ea-9ada-52540088cada, zuletzt abgerufen am
16.07.2020.
Deutscher Presserat (2020): Aufgaben des Presserats. Online verf&#252;gbar unter
https://www.presserat.de/kontakt.html, zuletzt aktualisiert am 2020, zuletzt abgerufen am 29.07.2020.
Deutscher Verkehrssicherheitsrat: Vision Zero. Online verf&#252;gbar unter https://www.dvr.de/dvr/vision-zero/,
zuletzt abgerufen am 23.07.2020.
Deutscher Wetterdienst: Entwicklung des Integrierten Vorhersagesystems SINFONY. Online verf&#252;gbar unter
https://www.dwd.de/DE/forschung/forschungsprogramme/sinfony_iafe/sinfony_node.html, zuletzt
abgerufen am 03.08.2020.
Deutsches Forschungszentrum f&#252;r K&#252;nstliche Intelligenz (20.04.2017): Wenn die Bilder l&#252;gen &#8211; KI-System
entlarvt Fake News im Internet. Kaiserslautern. Heyer, Christian. Online verf&#252;gbar unter
https://www.dfki.de/web/news/detail/News/wenn-die-bilder-luegen-ki-system-entlarvt-fake-news-im-
internet/, zuletzt abgerufen am 23.07.2020.
Deutsches Forschungszentrum f&#252;r K&#252;nstliche Intelligenz GmbH (DFKI) Robotics Innovation Center (2020):
Exoskeleton active (Capio). Capio Upper Body Exoskeleton for Teleoperation. Online verf&#252;gbar unter
https://robotik.dfki-bremen.de/en/research/robot-systems/exoskelett-aktiv-ca.html, zuletzt aktualisiert am
13.07.2020, zuletzt abgerufen am 15.07.2020.
Deutsches Institut f&#252;r Normung e. V. (2019): K&#252;nstliche Intelligenz &#8211; Mit Normung und Standardisierung 
innovationsfreundliche Rahmenbedingungen f&#252;r die Technologie der Zukunft schaffen. Online verf&#252;gbar
unter https://www.din.de/blob/300540/ee6c35719f2172d1cc000552b1a6bcf2/19-01-din-positionspapier-
kuenstliche-intelligenz-data.pdf, zuletzt abgerufen am 27.07.2020.
Deutsches Zentrum f&#252;r Luft- und Raumfahrt (2019): Globale TanDEM-X-Waldkarte verf&#252;gbar. Online
verf&#252;gbar unter https://www.dlr.de/content/de/artikel/news/2019/02/20190506_globale-tandem-x-
waldkarte-verfuegbar.html, zuletzt abgerufen am 07.08.2020.
Deutsches Zentrum f&#252;r Luft- und Raumfahrt e. V.: Der urbane Luftverkehr. Online verf&#252;gbar unter
https://www.dlr.de/content/de/artikel/luftfahrt/leitkonzepte/urbaner-luftverkehr.html, zuletzt abgerufen 
am 24.07.2020.
Deutschlandradio (2019): Das digitale Bandmitglied (Kompressor), 05. September 2019. Online verf&#252;gbar
unter https://www.deutschlandfunkkultur.de/wettbewerb-zur-ki-musik-das-digitale-
bandmitglied.2156.de.html?dram:article_id=458126, zuletzt abgerufen am 14.07.2020.
DFC Intelligence (2015): DFC Inteligence Forecasts Global Video Game Software Industry to reach $100B in 
2019. Online verf&#252;gbar unter https://www.dfcint.com/news-posts/dfc-intelligence-forecasts-global-
video-game-software-industry-to-reach-100b-in-2019/, zuletzt abgerufen am 27.07.2020.
DFC Intelligence (2019): Online console video game sales expected to pass packaged sales in 2019. Online
verf&#252;gbar unter https://www.dfcint.com/dossier/online-console-video-game-sales-expected-to-pass-
packaged-sales-in-2019/#, zuletzt aktualisiert am 08.03.2019, zuletzt abgerufen am 28.07.2020.
Diakopoulos, Nicholas (2014): Algorithmic Accountability: On the Investigation of Black Boxes. In: Columbia 
Journalism Review. Online verf&#252;gbar unter
https://www.cjr.org/tow_center_reports/algorithmic_accountability_on_the_investigation_of_black_box 
es.php, zuletzt abgerufen am 05.08.2020.
Dickow, Marcel (2015): Robotik &#8211; ein Game-Changer f&#252;r Milit&#228;r und Sicherheitspolitik? Hg. v. Stiftung 
Wissenschaft und Politik. Berlin. Online verf&#252;gbar unter https://www.swp-
berlin.org/fileadmin/contents/products/studien/2015_S14_dkw.pdf, zuletzt abgerufen am 17.07.2020.
die medienanstalten &#8211; ALM GbR (2020): Medienvielfaltsmonitor 2019-II. Anteile der Medienangebote und 
Medienkonzerne am Meinungsmarkt der Medien in Deutschland. Online verf&#252;gbar unter
https://www.die-
medienanstalten.de/fileadmin/user_upload/die_medienanstalten/Themen/Forschung/Medienvielfaltsmon 
itor/Medienanstalten_MedienVielfaltsMonitor.pdf, zuletzt abgerufen am 31.08.2020.
Die Wissenschaftlichen Dienste des Deutschen Bundestags (2018): Autonomes und automatisiertes Fahren auf
der Stra&#223;e &#8211; rechtlicher Rahmen. Ausarbeitung. WD 7: Zivil-, Straf- und Verfahrensrecht, 
Umweltschutzrecht, Bau. Online verf&#252;gbar unter
https://www.bundestag.de/resource/blob/562790/c12af1873384bcd1f8604334f97ee4b9/wd-7-111-18-
pdf-data.pdf, zuletzt abgerufen am 24.07.2020.
Die Wissenschaftlichen Dienste des Deutschen Bundestags (2018): Regulierung von Intermedi&#228;ren. 
M&#246;glichkeiten und Auswirkungen der Regulierung im Hinblick auf Medienvielfalt. WD 10: Medien,
Kultur und Sport. Online verf&#252;gbar unter
https://www.bundestag.de/resource/blob/591830/c58874d515f02deecdc34ff18727ce12/WD-10-062-18-
pdf-data.pdf, zuletzt abgerufen am 15.07.2020.
Digital-Gipfel Plattform &#8222;Digitale Netze und Mobilit&#228;t&#8220; (2019): Thesenpapier der Fokusgruppe &#8222;Intelligente
Mobilit&#228;t&#8220;. Plattform &#8222;Digitale Netze und Mobilit&#228;t&#8220;. Online verf&#252;gbar unter https://plattform-digitale-
netze.de/app/uploads/2019/10/Digitale-Mobilita%CC%88tsplattformen.pdf, zuletzt abgerufen am
27.07.2020.
Dinerstein, Eric; Bethke, Anna: How do we use Artificial Intelligence (AI) cameras to save wildlife?: 
Weltbank. Online verf&#252;gbar unter https://olc.worldbank.org/content/how-do-we-use-artificial-
intelligence-ai-cameras-save-wildlife, zuletzt abgerufen am 07.08.2020.
Dinklage, Fabian; Meier, Sebastian; Seibel, Benjamin (2018): KI-Szenarien: Potenziale und
Herausforderungen. Online verf&#252;gbar unter https://lab.technologiestiftung-berlin.de/projects/ki-ai-
intro/de/potentials-challenges.html, zuletzt abgerufen am 20.07.2020.
DKE.de (2019): Normungs-Roadmap zu Ethik und KI geplant. Online verf&#252;gbar unter
https://www.dke.de/de/news/2019/normungs-roadmap-zu-ethik-und-ki-geplant, zuletzt abgerufen am
27.07.2020.
Doerr, John (2018): OKR. Objectives &amp; Key Results : wie Sie Ziele, auf die es wirklich ankommt, entwickeln, 
messen und umsetzen. M&#252;nchen: Verlag Franz Vahlen GmbH. Online verf&#252;gbar unter
https://elibrary.vahlen.de/extern/vahlen/live/cover/10.15358/9783800657742.gif.
Dolata, Ulrich (2011): Wandel durch Technik. Eine Theorie soziotechnischer Transformation. Frankfurt am
Main: Campus-Verl. (Schriften aus dem Max-Planck-Institut f&#252;r Gesellschaftsforschung K&#246;ln, 73). 
Online verf&#252;gbar unter http://www.mpi-fg-koeln.mpg.de/pu/books_wz/2011/wz_dol_2011-2.asp.
Dolling, Cornelia (2020): Pr&#228;zise Diagnostik und Behandlung von akutem Lungenversagen. Einsatz der ASIC
App wird auf Intensivstationen ausgeweitet. Hg. v. Smart Medical Information Technology for
Healthcare. Online verf&#252;gbar unter https://www.smith.care/prazise-diagnostik-und-behandlung-von-
akutem-lungenversagen-einsatz-der-asic-app-wird-auf-intensivstationen-ausgeweitet/, zuletzt aktualisiert 
am 01.07.2020, zuletzt abgerufen am 18.09.2020.
Dorloff, Axel (2019): China &#8211; K&#252;nstliche Intelligenz als Staatsziel. Bis 2030 m&#246;chte China zur Supermacht im
Bereich der K&#252;nstlichen Intelligenz werden. Die chinesische Regierung hat dazu milliardenschwere 
F&#246;rderprogramme aufgelegt. KI gilt als Allheilmittel, um die Wirtschaft zukunftsf&#228;hig zu machen &#8211; und 
um die autorit&#228;re Herrschaft effizienter zu gestalten. Hg. v. Deutschlandfunk. Online verf&#252;gbar unter
https://www.deutschlandfunk.de/china-kuenstliche-intelligenz-als-
staatsziel.724.de.html?dram:article_id=440743&amp;utm_source=D64+Ticker&amp;utm_campaign=68344e5dd8 
-EMAIL_CAMPAIGN_4_22_2018_COPY_01&amp;utm_medium=email&amp;utm_term=0_aa5ef144ff-
68344e5dd8-64702577, zuletzt abgerufen am 06.08.2020.
D&#246;rnemann, Martina; Gertz, Carsten (2016): Wirkungen des autonomen/fahrerlosen Fahrens in der Stadt. 
Zusammenfassung. Hg. v. Senator f&#252;r Umwelt, Bau und Verkehr. Online verf&#252;gbar unter
https://docplayer.org/63599514-Wirkungen-des-autonomen-fahrerlosen-fahrens-in-der-stadt-
zusammenfassung.html, zuletzt abgerufen am 28.07.2020.
Douek, Evelyn (2020): What Kind of Oversight Board Have You Given Us? Online verf&#252;gbar unter
https://lawreviewblog.uchicago.edu/2020/05/11/fb-oversight-board-edouek/, zuletzt aktualisiert am
11.05.2020, zuletzt abgerufen am 04.08.2020.
dpa (2019): Jede Fahrt eine planerische Herausforderung. DB-G&#252;terbahn. In: wiwo.de, 30. Mai 2019. Online
verf&#252;gbar unter https://www.wiwo.de/unternehmen/dienstleister/db-gueterbahn-jede-fahrt-eine-
planerische-herausforderung/24386892.html, zuletzt abgerufen am 29.07.2020.
Dr&#228;ger, J&#246;rg; M&#252;ller-Eiselt, Ralph (2019): Wir und die intelligenten Maschinen. Wie Algorithmen unser Leben 
bestimmen und wir sie f&#252;r uns nutzen k&#246;nnen. M&#252;nchen: DVA.
Drechsler, J&#246;rg; Jentzsch, Nicola (2018): Synthetische Daten. Innovationspotential und gesellschaftliche
Herausforderungen. Hg. v. Stiftung Neue Verantwortung e. V. Online verf&#252;gbar unter
https://www.stiftung-nv.de/sites/default/files/synthetische_daten.pdf, zuletzt abgerufen am 04.08.2020.
Dredge, Stuart (2017): AI and music: will we be slaves to the algorithm? In: theguardian.com, 06. August
2017. Online verf&#252;gbar unter https://www.theguardian.com/technology/2017/aug/06/artificial-
intelligence-and-will-we-be-slaves-to-the-algorithm, zuletzt abgerufen am 14.07.2020.
Dreier, Thomas; Schulze, Gernot (2008): Urheberrechtsgesetz. Urheberrechtswahrnehmungsgesetz, 
Kunsturhebergesetz ; Kommentar. 3. Aufl.: Beck (Beck-online). Online verf&#252;gbar unter http://beck-
online.beck.de/Default.aspx?vpath=bibdata/komm/DreierSchulzeKoUrhG_3/Buch/cont/DreierSchulzeK 
oUrhG.htm.
Dreyer, Stephan; Schulz, Wolfgang (2018): Was bringt die Datenschutz-Grundverordnung f&#252;r automatisierte
Entscheidungssysteme? Potenziale und Grenzen der Absicherung individueller, gruppenbezogener und 
gesellschaftlicher Interessen. Hg. v. Bertelsmann Stiftung.
Duden: Daten. Rechtschreibung, Bedeutung, Definition, Herkunft. Hg. v. Bibliographisches Institut GmbH. 
Online verf&#252;gbar unter https://www.duden.de/node/30506/revision/30535, zuletzt abgerufen am
04.08.2020.
Duden: Risiko. Rechtschreibung, Bedeutung, Definition, Herkunft. Hg. v. Bibliographisches Institut GmbH. 
Online verf&#252;gbar unter https://www.duden.de/rechtschreibung/Risiko, zuletzt abgerufen am 04.08.2020.
dvz.de (2019): Behala und Partner schicken den Schwarm aufs Wasser. In: dvz.de, 23. September 2019. Online
verf&#252;gbar unter https://www.dvz.de/rubriken/test-technik/alternative-antriebe/detail/news/behala-und-
partner-schicken-den-schwarm-aufs-wasser.html, zuletzt abgerufen am 03.08.2020.
Ebers, Martin (2018): Beeinflussung und Manipulation von Kunden durch Behavioral Microtargeting. 
Verhaltenssteuerung durch Algorithmen aus der Sicht des Zivilrechts. In: MMR (7), S. 421&#8211;492. Online
verf&#252;gbar unter https://beck-
online.beck.de/?vpath=bibdata%2fzeits%2fMMR%2f2018%2fcont%2fMMR%2e2018%2e423%2e1%2 
ehtm, zuletzt abgerufen am 3. August 20220.
eco - Verband der Internetwirtschaft e. V; Arthur D. Little (2020): K&#252;nstliche Intelligenz &#8211; Potenzial und 
nachhaltige Ver&#228;nderung der Wirtschaft in Deutschland. Online verf&#252;gbar unter
https://www.eco.de/presse/neue-eco-studie-untersucht-wirtschaftspotenziale-von-kuenstlicher-
intelligenz-13-prozent-hoeheres-bip-bis-2025-moeglich/, zuletzt abgerufen am 18.08.2020.
ee-news.ch (2019): Verl&#228;ssliche Daten zum Ausbau Erneuerbarer: Kaiserwetter und SAP stellen KI-Ansatz zur
Risikominimierung von Investitionen vor. Online verf&#252;gbar unter ttps://www.ee-
news.ch/de/article/42278/verlassliche-daten-zum-ausbau-erneuerbarer-kaiserwetter-und-sap-stellen-
kiansatz-zur-risikominimierung-von-investitionen-vor, zuletzt abgerufen am 07.08.2020.
EGB Erich-Gutenberg-Berufskolleg K&#246;ln: Robotik. Digitalisierung und K&#252;nstliche Intelligenz ver&#228;ndern die
Arbeitswelt. In absehbarer Zeit k&#246;nnten Roboter ganze Berufe verschwinden lassen! Online verf&#252;gbar
unter https://www.egb-koeln.de/index.php/aktivitaeten-aktuelles/egb-digital/robotik, zuletzt abgerufen 
am 16.07.2020.
Egger, Andreas; Gerhard, Heinz (2019): Ergebnisse der ARD/ZDF-Massenkommunikation Trends und der
ARD/ZDF-Onlinestudie &#8211; Bewegtbildnutzung 2019. In: Media Perspektiven (9/2019), S. 389&#8211;405. 
Online verf&#252;gbar unter http://www.ard-zdf-onlinestudie.de/files/2019/0919_Egger_Gerhard.pdf, zuletzt
abgerufen am 16.07.2020.
EHI Retail Institute e. V. (2019): KI &#8211; wichtigster Zukunftstrend im Handel. Online verf&#252;gbar unter
https://www.ehi.org/de/pressemitteilungen/ki-wichtigster-zukunftstrend-im-handel, zuletzt abgerufen am
22.07.2020.
Ehinger, Patrick; Stiemerling, Oliver (2018): Die urheberrechtliche Schutzf&#228;higkeit von K&#252;nstlicher Intelligenz
am Beispiel von Neuronalen Netzen. In: Computer und Recht 34 (12), S. 761&#8211;770. 
Eilers, Silke; M&#246;ckel, Kathrin; Rump, Jutta; Schabel, Frank (2020): Lebenslanges Lernen. Eine empirische
Studie des Instituts f&#252;r Besch&#228;ftigung und Employability IBE und Hays. Hg. v. Hays und Institut f&#252;r
Besch&#228;ftigung und Employability IBE (Hr Report, 2020). Online verf&#252;gbar unter https://www.ibe-
ludwigshafen.de/wp-content/uploads/2020/01/Hays_Studie-HR-Report-2020.pdf, zuletzt abgerufen am
06.08.2020.
Einmahl, Matthias (2019): Einf&#252;hrung in die &#246;ffentliche Beschaffung. In: Matthias Einmahl und Adrian 
Ziomek (Hg.): Preview Einf&#252;hrung in die &#246;ffentliche Beschaffung. Online verf&#252;gbar unter
https://www.bundesanzeiger-
verlag.de/xaver/vergabeportal/start.xav?start=%2F%2F*%5B%40attr_id%3D%27vergabeportal_931850 
2027%27%5D, zuletzt abgerufen am 16.07.2020.
Ekelhof, Merel (2018): Autonomous weapons: Operationalizing meaningful human control. Hg. v. 
Humanitarian Law &amp; Policy. Internationales Komitee vom Roten Kreuz. Online verf&#252;gbar unter
https://blogs.icrc.org/law-and-policy/2018/08/15/autonomous-weapons-operationalizing-meaningful-
human-control/, zuletzt aktualisiert am 15.08.2018, zuletzt abgerufen am 20.07.2020.
Elsevier (2018): ArtificiaI Intelligence: How knowledge is created, transferred, and used. Trends in China, 
Europe, and the United States. Online verf&#252;gbar unter https://www.elsevier.com/research-
intelligence/resource-library/ai-report, zuletzt abgerufen am 04.08.2020.
elsevier.com (2018): Elsevier AI Ressource Center. Online verf&#252;gbar unter
https://www.elsevier.com/connect/resource-center/artificial-intelligence, zuletzt aktualisiert am
10.12.2019, zuletzt abgerufen am 07.08.2020.
Emporias Management Consulting (2017): Supply-Chain-Management in Industrieunternehmen 2017:
Zwischen Wunsch und Wirklichkeit.
Engelmann, Ines (2016): Gatekeeping. 1. Auflage. Baden-Baden: Nomos (Konzepte. Ans&#228;tze der Medien- und 
Kommunikationswissenschaft, 16). Online verf&#252;gbar unter
http://gbv.eblib.com/patron/FullRecord.aspx?p=4561596.
Erbst&#246;&#223;er, Anne-Caroline (2014): Smart City Berlin. Urbane Technologien f&#252;r Metropolen. Hg. v. TSB
Technologiestiftung Berlin. Online verf&#252;gbar unter https://www.smart-city-
berlin.de/fileadmin/user_upload/PDFs/TSB_Studie_SCB-compressed.pdf, zuletzt abgerufen am
20.07.2020.
Erlick, Eli (2018): How Instagram May Be Unwittingly Censoring the Queer Community. Hg. v. them.us. 
Online verf&#252;gbar unter https://www.them.us/story/instagram-may-be-unwittingly-censoring-the-queer-
community, zuletzt aktualisiert am 30.01.2018, zuletzt abgerufen am 03.08.2020.
Erling, Johnny (2019): So absurd ausgefeilt ist Chinas &#220;berwachungssystem. In: welt.de, 17. April 2019. 
Online verf&#252;gbar unter https://www.welt.de/wirtschaft/article192029849/Social-Scoring-So-absurd-
ausgefeilt-ist-Chinas-Ueberwachungssystem.html, zuletzt abgerufen am 04.09.2020.
Ernst &amp; Young (2019): Fast growth beyond borders: Tech start-ups reshaping the economy. Venture Capital 
and start-ups in Germany 2018. Online verf&#252;gbar unter https://start-up-initiative.ey.com/wp-
content/uploads/2019/03/ey-fast-growth-beyond-borders-tech-start-ups-reshaping-the-economy.pdf, 
zuletzt abgerufen am 22.07.2020.
Ernst &amp; Young (2019): Start-Up-Barometer Deutschland. Januar 2019. Online verf&#252;gbar unter https://start-up-
initiative.ey.com/wp-content/uploads/2019/01/EY-Start-up-Barometer-Deutschland-Januar-
2019_DE.pdf, zuletzt abgerufen am 21.07.2020.
Eschemann, Joachim; Knobloch, Tobias (2018): Transkript zum Hintergrundgespr&#228;ch &#8222;Predictive Policing in
Deutschland&#8220;. Hg. v. Stiftung Neue Verantwortung e. V. Berlin (Algorithmen f&#252;rs Gemeinwohl). Online
verf&#252;gbar unter https://www.stiftung-nv.de/de/publikation/transkript-zum-hintergrundgespraech-
predictive-policing-deutschland, zuletzt aktualisiert am 04.10.2018, zuletzt abgerufen am 17.07.2020.
ESF Europ&#228;ischer Sozialfonds f&#252;r Deutschland (2019): Das Qualifizierungschancengesetz. Online verf&#252;gbar
unter
https://www.esf.de/portal/SharedDocs/PDFs/DE/Veranstaltungen/2019/qualifizierungschancengesetz.pd 
f?__blob=publicationFile&amp;v=2, zuletzt abgerufen am 06.08.2020.
Esteva, Andre; Kuprel, Brett; Novoa, Roberto A.; Ko, Justin; Swetter, Susan M.; Blau, Helen M.; Thrun, 
Sebastian (2017): Dermatologist-level classification of skin cancer with deep neural networks. In:
Nature 542 (7639), S. 115&#8211;118.
E-Tailment &#8211; Das Digital Commerce Magazin von Der Handel (2018): Whitepaper &#8222;KI im Handel&#8220;. Online
verf&#252;gbar unter https://etailment.de/news/stories/Studien-Whitepaper-KI-im-Handel---so-nutzen-
Haendler-die-Macht-der-Algorithmen--21715, zuletzt abgerufen am 06.08.2020.
Etezadzadeh, Chirine (2015): Smart City &#8211; Stadt der Zukunft? Die Smart City 2.0 als lebenswerte Stadt und 
Zukunftsmarkt. Berlin: Springer.
Ethikbeirat HR-Tech (2020): Richtlinien f&#252;r den verantwortungsvollen Einsatz von K&#252;nstlicher Intelligenz und 
weiteren digitalen Technologien in der Personalarbeit. Online verf&#252;gbar unter https://www.ethikbeirat-
hrtech.de/wp-content/uploads/2020/03/Richtlinien_Download_deutsch_final.pdf, zuletzt abgerufen am
05.08.2020.
Ethik-Kommission (2017): Automatisiertes und Vernetztes Fahren. Bericht. Hg. v. Bundesministerium f&#252;r
Verkehr und digitale Infrastruktur. Online verf&#252;gbar unter
https://www.bmvi.de/SharedDocs/DE/Publikationen/DG/bericht-der-ethik-
kommission.pdf?__blob=publicationFile, zuletzt abgerufen am 28.07.2020.
EU Strategic Communications (2018): Autonomous weapons must remain under human control, Mogherini
says at European Parliament. Europ&#228;ischer Ausw&#228;rtiger Dienst. Online verf&#252;gbar unter
https://eeas.europa.eu/topics/economic-relations-connectivity-innovation/50465/autonomous-weapons-
must-remain-under-human-control-mogherini-says-european-parliament_en, zuletzt aktualisiert am
14.09.2018, zuletzt abgerufen am 20.07.2020.
Eubanks, Virginia (2018): Automating inequality. How high-tech tools profile, police, and punish the poor. 
First edition. New York: St. Martin's Press.
Eurofound (2019): Platform work: Maximising the potential while safeguarding standards? Unter Mitarbeit von
Irene Mandl. Luxembourg: Publications Office of the European Union (Digital age / Eurofound). Online
verf&#252;gbar unter
https://www.eurofound.europa.eu/sites/default/files/ef_publication/field_ef_document/ef19045en.pdf, 
zuletzt abgerufen am 17.07.2020.
Europ&#228;ische Kommission (2018): Code of Practice on Disinformation. Online verf&#252;gbar unter
https://ec.europa.eu/digital-single-market/en/news/code-practice-disinformation, zuletzt aktualisiert am
26.09.2018, zuletzt abgerufen am 04.08.2020.
Europ&#228;ische Kommission (2018): Bewertung der Richtlinie 85/374 / EWG des Rates vom 25. Juli 1985 &#252;ber
die Ann&#228;herung an die Gesetze, Verordnungen und Verwaltungsbestimmungen der Mitgliedstaaten 
betreffend Haftung f&#252;r fehlerhafte Produkte. Arbeitsdokument der Kommission. Online verf&#252;gbar unter
https://ec.europa.eu/transparency/regdoc/rep/10102/2018/EN/SWD-2018-157-F1-EN-MAIN-PART-
1.PDF, zuletzt abgerufen am 03.09.2020.
Europ&#228;ische Kommission (2019): Code of Practice on Disinformation one year on: online platforms submit
self-assessment reports. Online verf&#252;gbar unter
https://ec.europa.eu/commission/presscorner/detail/en/STATEMENT_19_6166, zuletzt aktualisiert am
29.10.2019, zuletzt abgerufen am 04.08.2020.
Europ&#228;ische Kommission (2019): Horizon 2020. Work Programme 2018-2020 Information and 
Communication Technologies. Online verf&#252;gbar unter
https://ec.europa.eu/programmes/horizon2020/sites/horizon2020/files/h2020-leit-ict-2018-2020-05-
27_draf_pre-publication.pdf, zuletzt abgerufen am 07.08.2020.
Europ&#228;ische Kommission (2019): Schaffung von Vertrauen in eine auf den Menschen ausgerichtete k&#252;nstliche
Intelligenz. Mitteilung der Kommission an das Europ&#228;ische Parlament, den Rat, den Europ&#228;ischen 
Wirtschafts- und Sozialausschuss und den Ausschuss der Regionen. COM(2019)168 final. Online
verf&#252;gbar unter https://data.consilium.europa.eu/doc/document/ST-8396-2019-INIT/de/pdf, zuletzt 
abgerufen am 13.07.2020.
Europ&#228;ische Kommission (2019): The Digital Competence Framework 2.0. Online verf&#252;gbar unter
https://ec.europa.eu/jrc/en/digcomp/digital-competence-framework, zuletzt aktualisiert am 09.01.2019, 
zuletzt abgerufen am 07.08.2020.
Europ&#228;ische Kommission (22.01.2019): Digitaler Binnenmarkt: EU-Verhandlungsf&#252;hrer einigen sich auf neue
Regeln f&#252;r die gemeinsame Nutzung der Daten des &#246;ffentlichen Sektors. Br&#252;ssel. 27.07.2020, zuletzt
abgerufen am https://ec.europa.eu/commission/presscorner/detail/de/IP_19_525.
Europ&#228;ische Kommission (08.04.2019): K&#252;nstliche Intelligenz: Kommission treibt Arbeit an Ethikleitlinien
weiter voran. Online verf&#252;gbar unter 19.08.2020, zuletzt abgerufen am
https://ec.europa.eu/commission/presscorner/detail/de/IP_19_1893.
Europ&#228;ische Kommission (2020): Bericht &#252;ber die Auswirkungen k&#252;nstlicher Intelligenz, des Internets der
Dinge und der Robotik in Hinblick auf Sicherheit und Haftung. Bericht der Kommission an das
Europ&#228;ische Parlament, den Rat und den Europ&#228;ischen Wirtschafts- und Sozialausschuss. COM (2020) 
64 final. Online verf&#252;gbar unter https://ec.europa.eu/transparency/regdoc/rep/1/2020/DE/COM-2020-64-
F1-DE-MAIN-PART-1.PDF, zuletzt abgerufen am 18.08.2020.
Europ&#228;ische Kommission (2020): Wei&#223;buch zur K&#252;nstlichen Intelligenz &#8211; ein europ&#228;isches Konzept f&#252;r
Exzellenz und Vertrauen. Online verf&#252;gbar unter https://ec.europa.eu/info/sites/info/files/commission-
white-paper-artificial-intelligence-feb2020_de.pdf, zuletzt abgerufen am 20.07.2020.
Europ&#228;ische Kommission (2020): Single European Sky. Online verf&#252;gbar unter
https://ec.europa.eu/transport/modes/air/ses_en, zuletzt aktualisiert am 03.08.2020, zuletzt abgerufen am
03.08.2020.
Europ&#228;ische Union: Open call: Towards a vibrant European network of AI excellence centres. Online verf&#252;gbar
unter https://www.clustercollaboration.eu/news/open-call-towards-vibrant-european-network-ai-
excellence-centres, zuletzt abgerufen am 07.08.2020.
Europ&#228;isches Patentamt (2017): Patents and the Fourth Industrial Revolution. The inventions behind digital
transformation. Online verf&#252;gbar unter
http://documents.epo.org/projects/babylon/eponet.nsf/0/17FDB5538E87B4B9C12581EF0045762F/$File 
/fourth_industrial_revolution_2017__en.pdf, zuletzt abgerufen am 27.07.2020.
European Chamber of Commerce in China (2017): China Manufacturing 2025 &#8211; Putting Industrial Policy
Ahead of Market Forces. Online verf&#252;gbar unter http://docs.dpaq.de/12007-european_chamber_cm2025-
en.pdf, zuletzt abgerufen am 21.07.2020.
European Data Portal (2019): Open education data on the European Data Portal. Discover open education data
and its applications on the European Data Portal. Online verf&#252;gbar unter
https://www.europeandataportal.eu/en/highlights/open-education-data-european-data-portal, zuletzt 
abgerufen am 06.08.2020.
European Data Protection Board (2019): Stellungnahme 3/2019 zu den Fragen und Antworten zum
Zusammenspiel der Verordnung &#252;ber klinische Pr&#252;fungen und der Datenschutz-Grundverordnung 
(DSGVO) (Artikel 70 Absatz 1 Buchstabe b). Online verf&#252;gbar unter
https://edpb.europa.eu/sites/edpb/files/files/file1/edpb_opinionctrq_a_final_de.pdf, zuletzt abgerufen am
10.07.2020.
European Information Technology Observatory (2018): AI in Europe &#8211; Ready for Take-off. Hg. v. Bitkom
Research GmbH. Online verf&#252;gbar unter https://www.bitkom-research.de/de/AI-in-Europe, zuletzt
abgerufen am 20.07.2020.
European Maritime Safety Agency (2016): Annual Overview of marine casualties and incidents 2016. Online
verf&#252;gbar unter http://www.emsa.europa.eu/news-a-press-centre/external-news/item/2903-annual-
overview-of-marine-casualties-and-incidents-2016.html, zuletzt abgerufen am 24.07.2020.
Evans, David S.; Schmalensee, Richard (2007): Catalyst code. The strategies behind the worlds most dynamic
companies. Boston, Mass.: Harvard Business School Press.
Evans, Richard; Gao, Jim (2016): DeepMind AI Reduces Google Data Centre Cooling Bill by 40%. Hg. v. 
Deepmind.com. Online verf&#252;gbar unter https://deepmind.com/blog/article/deepmind-ai-reduces-google-
data-centre-cooling-bill-40, zuletzt abgerufen am 23.07.2020.
Expertenkommission Forschung und Innovation (2018): Gutachten 2018. Online verf&#252;gbar unter
https://www.e-fi.de/fileadmin/Gutachten_2018/EFI_Gutachten_2018.pdf, zuletzt abgerufen am
27.07.2020.
Expertenkommission Forschung und Innovation (2018): Studie &#8222;Autonome Systeme&#8220; (Studien zum deutschen 
Innovationssystem, 13-2018). Online verf&#252;gbar unter https://www.e-
fi.de/fileadmin/Innovationsstudien_2018/StuDIS_13_2018.pdf, zuletzt abgerufen am 27.07.2020.
Facebook (2020): Facebook ver&#246;ffentlicht vierten NetzDG-Transparenzbericht. Online verf&#252;gbar unter
https://about.fb.com/de/news/2020/01/facebook-veroeffentlicht-vierten-netzdg-transparenzbericht/,
zuletzt aktualisiert am 31.01.2020, zuletzt abgerufen am 06.08.2020.
Facebook (2020): NetzDG Transparenzbericht. Online verf&#252;gbar unter https://about.fb.com/wp-
content/uploads/2020/01/facebook_netzdg_Januar_2020_German.pdf, zuletzt aktualisiert am Januar
2020, zuletzt abgerufen am 06.08.2020.
Fagerberg, Jan (2004): A guide to the literature. In: Jan Fagerberg, David C. Mowery und Richard R. Nelson 
(Hg.): The Oxford handbook of innovation. Oxford: Oxford Univ. Press, S. 1&#8211;26.
Faggella, Daniel (2020): 7 Applications of Machine Learning in Pharma and Medicine. Hg. v. emerj The AI
Research and Advisory Company. Online verf&#252;gbar unter https://emerj.com/ai-sector-
overviews/machine-learning-in-pharma-medicine/, zuletzt aktualisiert am 04.03.2020, zuletzt abgerufen 
am 16.07.2020.
Fahrradportal (2020): K&#252;nstliche Intelligenz hilft Verkehrsstr&#246;me in London besser zu verstehen. 
Sensortechnologie zur Radfahrererkennung. Hg. v. Deutsches Institut f&#252;r Urbanistik. Online verf&#252;gbar
unter https://nationaler-radverkehrsplan.de/de/aktuell/nachrichten/kuenstliche-intelligenz-hilft-
verkehrsstroeme, zuletzt aktualisiert am 16.01.2020, zuletzt abgerufen am 09.09.2020.
Fanta, Alexander (2018): EU-Projekt entwickelt smarten L&#252;gendetektor f&#252;r Grenzkontrollen. Hg. v. 
Netzpolitik.org. Online verf&#252;gbar unter https://netzpolitik.org/2018/eu-projekt-entwickelt-smarten-
luegendetektor-fuer-grenzkontrollen, zuletzt aktualisiert am 01.11.2018, zuletzt abgerufen am
17.07.2020.
Ferlemann, Enak: Gemeinsam auf dem Weg zum Schienenverkehr der Zukunft &#8211; erste Ergebnisse des 
Zukunftsb&#252;ndnis Schiene. Bericht des Vorsitzenden des Lenkungskreises &#252;ber die Arbeit des
Zukunftsb&#252;ndnis Schiene vom 09.10.2018 bis zum 30.04.2019. Unter Mitarbeit von Gesch&#228;ftsstelle des
Beauftragten der Bundesregierung. Hg. v. Bundesministerium f&#252;r Verkehr und digitale Infrastruktur. 
Online verf&#252;gbar unter https://www.bmvi.de/SharedDocs/DE/Anlage/E/schienengipfel-zwischenbericht-
psts-f.pdf?__blob=publicationFile, zuletzt abgerufen am 28.07.2020.
Finkenzeller, Karin (2019): K&#252;nstliche Intelligenz soll Versicherungsbetrug aufdecken. In:
Wirtschaftswoche.de, 2019. Online verf&#252;gbar unter
https://www.wiwo.de/unternehmen/versicherer/digitale-versicherungsfahnder-kuenstliche-intelligenz-
soll-versicherungsbetrug-aufdecken/24270964.html, zuletzt abgerufen am 23.07.2020.
FinTechRat (2019): Cloud for the financial industry. Positionspapier des FinTechRats. Online verf&#252;gbar unter
https://www.bundesfinanzministerium.de/Content/DE/Downloads/Finanzmarktpolitik/2019-03-21-
positionspaier-cloud-computing.pdf?__blob=publicationFile&amp;v=2, zuletzt abgerufen am 23.07.2020.
Fischer, Sarah; Petersen, Thomas (2018): Was Deutschland &#252;ber Algorithmen wei&#223; und denkt &#8211; Ergebnisse
einer repr&#228;sentativen Bev&#246;lkerungsumfrage. Hg. v. Bertelsmann Stiftung. Online verf&#252;gbar unter
https://www.bertelsmann-
stiftung.de/fileadmin/files/BSt/Publikationen/GrauePublikationen/Was_die_Deutschen_ueber_Algorith 
men_denken.pdf, zuletzt abgerufen am 20.07.2020.
Fischer, Tin (2019): Wenn die KI daneben liegt. In: Die Zeit, 07. November 2019 (46), S. 42. Online verf&#252;gbar
unter https://www.zeit.de/2019/46/kuenstliche-intelligenz-wissenschaft-computer-wissensluecken, 
zuletzt abgerufen am 07.08.2020.
Flamand, Eric; Rossi, Davide; Conti, Francesco; Loi, Igor; Pullini, Antonio; Rotenberg, Florent; Benini, Luca
(2018): GAP-8: A RISC-V SoC for AI at the Edge of the IoT. Hg. v. Institute of Electrical and 
Electronics Engineers. Online verf&#252;gbar unter https://ieeexplore.ieee.org/document/8445101, zuletzt
abgerufen am 23.07.2020.
Fleischer, J&#246;rg (2018): Entscheidung bleibt beim Menschen. Hg. v. Bundesministerium der Verteidigung. 
Online verf&#252;gbar unter https://www.bmvg.de/de/aktuelles/entscheidung-bleibt-beim-menschen-28946,
zuletzt aktualisiert am 12.11.2018, zuletzt abgerufen am 20.07.2020.
Fleischer, J&#246;rg (2018): &#8222;KI&#8220; ist Thema f&#252;r die ganze Bundeswehr. Interview. Hg. v. Bundesministerium der
Verteidigung. Online verf&#252;gbar unter https://www.bmvg.de/de/aktuelles/-ki-ist-thema-fuer-die-ganze-
bundeswehr-28938, zuletzt abgerufen am 20.07.2020.
Fletcher, Richard (2020): The truth behind filter bubbles: Bursting some myths. Hg. v. Reuters Institute for the
Study of Journalism. Online verf&#252;gbar unter https://reutersinstitute.politics.ox.ac.uk/risj-review/truth-
behind-filter-bubbles-bursting-some-myths, zuletzt abgerufen am 03.08.2020.
Floridi, Luciano (2015): Die 4. Revolution. Wie die Infosph&#228;re unser Leben ver&#228;ndert. Erste Auflage:
Suhrkamp.
FoBiD Forschungsinstitut Bildung Digital: Forschungsprojekt Assist. ASSIST &#8211; K&#252;nstliche Intelligenz, die
Lehrkr&#228;ften den Alltag erleichtert. Universit&#228;t des Saarlandes. Online verf&#252;gbar unter
https://fobid.org/projects/assist/, zuletzt abgerufen am 16.07.2020.
F&#246;rtsch, Michael (2018): Diese Videospiel-Stadt wurde von einer K&#252;nstlichen Intelligenz erschaffen.
Hg. v. gq-magazin.de. Online verf&#252;gbar unter https://www.gq-magazin.de/auto-technik/article/koennte-
die-grafik-in-videospielen-bald-von-einer-ki-berechnet-werden, zuletzt aktualisiert am 04.12.2018,
zuletzt abgerufen am 15.07.2020.
Frank, Morgan R.; Autor, David; Bessen, James E.; Brynjolfsson, Erik; Cebrian, Manuel; Deming, David J. et
al. (2019): Toward understanding the impact of artificial intelligence on labor. In: Proceedings of the
National Academy of Sciences of the United States of America 116 (14), S. 6531&#8211;6539. Franz&#246;sische
Regierung (2019): Creating a French framework to make social media platforms more accountable:
Acting in France with a European vision. Online verf&#252;gbar unter
https://minefi.hosting.augure.com/Augure_Minefi/r/ContenuEnLigne/Download?id=AE5B7ED5-2385-
4749-9CE8-
E4E1B36873E4&amp;filename=Mission%20Re%CC%81gulation%20des%20re%CC%81seaux%20sociaux 
%20-ENG.pdf, zuletzt abgerufen am 04.08.2020.
Fraunhofer IAO | Forschungsbereich | Cognitive Engineering and Production: &#187;APPsist&#171;: Wissens- und 
Assistenzsysteme in der smarten Produktion. Apps helfen bei der Interaktion mit Maschinen. Online
verf&#252;gbar unter https://www.engineering-produktion.iao.fraunhofer.de/de/forschung/appsist.html, zuletzt
abgerufen am 15.07.2020.
Fraunhofer-Allianz autoMOBILproduktion (2019): Mobilit&#228;t der Zukunft muss produziert werden. 
Positionspapier. Fraunhofer Institut f&#252;r Werkzeugmaschinen und Umformtechnik. Online verf&#252;gbar
unter https://www.automobil.fraunhofer.de/content/dam/automobil/de/documents/allianz-automobil-
positionspapier.pdf, zuletzt abgerufen am 28.07.2020.
Fraunhofer-Allianz Big Data (2017): Zukunftsmarkt K&#252;nstliche Intelligenz &#8211; Potenziale und Anwendungen. 
Online verf&#252;gbar unter
https://www.bigdata.fraunhofer.de/content/dam/bigdata/de/documents/Publikationen/KI-
Potenzialanalyse_2017.pdf, zuletzt abgerufen am 04.08.2020.
Fraunhofer-Gesellschaft zur F&#246;rderung der angewandten Forschung e. V. (2018): Maschinelles Lernen &#8211; Eine
Analyse zu Kompetenzen, Forschung und Anwendung. Online verf&#252;gbar unter
https://www.bigdata.fraunhofer.de/content/dam/bigdata/de/documents/Publikationen/Fraunhofer_Studie 
_ML_201809.pdf, zuletzt abgerufen am 22.07.2020.
Fraunhofer-Institut f&#252;r Materialfluss und Logistik: Drohnentechnik. Online verf&#252;gbar unter
https://www.iml.fraunhofer.de/de/abteilungen/b1/verpackungs_und_handelslogistik/autoid/DL_AutoID/ 
dl_aid_drohnentechnik.html, zuletzt abgerufen am 03.08.2020.
Fraunhofer-Institut f&#252;r Optronik, Systemtechnik und Bildauswertung: Intelligente Video&#252;berwachung f&#252;r mehr
Sicherheit und Datenschutz. Start f&#252;r Pilotprojekt in Mannheim. Unter Mitarbeit von Markus M&#252;ller. 
Online verf&#252;gbar unter https://www.iosb.fraunhofer.de/servlet/is/93474/, zuletzt abgerufen am
22.07.2020.
Fraunhofer-Institut f&#252;r Optronik, Systemtechnik und Bildauswertung (08.05.2018): Privatsph&#228;re und 
Datenschutz &#8211; dank intelligenter Video&#252;berwachung. Karlsruhe. Online verf&#252;gbar unter
https://www.iosb.fraunhofer.de/servlet/is/82548, zuletzt abgerufen am 17.07.2020.
Fraunhofer-Institut f&#252;r Optronik, Systemtechnik und Bildauswertung IOSB: Intelligent Tutoring Interface for
Technology Enhanced Learning. Online verf&#252;gbar unter
https://www.iosb.fraunhofer.de/servlet/is/33082/, zuletzt abgerufen am 16.07.2020.
Fraunhofer-Institut f&#252;r Optronik, Systemtechnik und Bildauswertung IOSB: Privacy by Design. Die 7 
Grundprinzipien. Online verf&#252;gbar unter https://www.iosb.fraunhofer.de/servlet/is/69348/, zuletzt
abgerufen am 16.07.2020.
Fraunhofer-Institut f&#252;r Produktionstechnik und Automatisierung IPA: Produktblatt &#8222;Care-O-bot&#174; 3&#8220;. 
Produktvision eines interaktiven Haushaltsassistenten. Online verf&#252;gbar unter
https://www.ipa.fraunhofer.de/content/dam/ipa/de/documents/Kompetenzen/Roboter--und-
Assistenzsysteme/Produktblatt_Care_O_bot.pdf, zuletzt abgerufen am 15.07.2020.
Fraunhofer-Institut f&#252;r Produktionstechnik und Automatisierung IPA: WiMi-Care: F&#246;rderung des
Wissenstransfers f&#252;r eine aktive Mitgestaltung des Pflegesektors durch Mikrosystemtechnik. Online
verf&#252;gbar unter https://www.ipa.fraunhofer.de/de/referenzprojekte/WiMi-Care.html, zuletzt abgerufen
am 15.07.2020.
Fraunhofer-Institut f&#252;r sichere Informationstechnologie (2019): SeDaFa. Selbstdatenschutz im vernetzten 
Fahrzeug. Online verf&#252;gbar unter
https://www.sit.fraunhofer.de/fileadmin/dokumente/Projektblaetter/web_SeDaFa-
FraunhoferSIT_de.pdf?_=1476171585, zuletzt abgerufen am 28.07.2020.
Freie Universit&#228;t Berlin (2019): K&#252;nstliche Intelligenz f&#252;r die Physik. Wissenschaftler der Freien Universit&#228;t 
Berlin entwickeln tiefes Lernverfahren zur L&#246;sung eines fundamentalen Problems der statistischen
Physik. Online verf&#252;gbar unter https://www.fu-berlin.de/presse/informationen/fup/2019/fup_19_255-ki-
physik/index.html, zuletzt abgerufen am 16.07.2020.
Frey, Carl Benedikt; Osborne, Michael A. (2013): The future of employment: How susceptible are jobs to 
computerisation? In: Technological Forecasting and Social Change 114, S. 254&#8211;280. 
Fridman, Lex; Brown, Daniel E.; Glazer, Michael; Angell, William; Dodd, Spencer; Jenik, Benedikt et al. 
(2019): MIT Advanced Vehicle Technology Study: Large-Scale Naturalistic Driving Study of Driver
Behavior and Interaction With Automation. In: IEEE Access 7, S. 102021&#8211;102038.
Friedrich Ebert Stiftung (2018): Smart City Singapur. &#8211; ein Vorbild f&#252;r unsere St&#228;dte? Online verf&#252;gbar unter
https://www.fes.de/stadtentwicklung-wie-sozial-ist-die-smart-city, zuletzt abgerufen am 22.07.2020.
Frohwitter, Tizia-Charlotte (2020): How Artificial Intelligence Is Supporting Humanity in the Battle Against 
Coronavirus. In: The Observer, 01. April 2020. Online verf&#252;gbar unter
https://fordhamobserver.com/45135/opinions/how-artificial-intelligence-is-supporting-humanity-in-th
ebattle-against-coronavirus/, zuletzt abgerufen am 18.09.2020.
Fr&#252;h, Michael; Gasser, Alina (2018): Erfahrungen aus dem Einsatz von Pflegerobotern f&#252;r Menschen im Alter. 
In: Oliver Bendel (Hg.): Pflegeroboter, Bd. 10. Wiesbaden: Springer Fachmedien Wiesbaden, S. 37&#8211;62. 
Online verf&#252;gbar unter https://link.springer.com/content/pdf/10.1007%2F978-3-658-22698-5.pdf, zuletzt
abgerufen am 10.07.2020.
Fujitsu Future Insights (2019): Global Digital Transformation Survey Report 2019. Online verf&#252;gbar unter
https://www.computerwoche.de/fileserver/idgwpcw/files/3214.pdf, zuletzt abgerufen am 27.07.2020.
Furman, Jason; Seamans, Robert (2019): AI and the Economy. In: Innovation Policy and the Economy 19 (1), 
S. 161&#8211;191.
fuse-ai.de (2019): K&#252;nstliche Intelligenz &#8211; Individualsiertes Netflix. Online verf&#252;gbar unter https://fuse-
ai.de/en/ki-blog/kunstliche-intelligenz-individualisiertes-netflix/, zuletzt aktualisiert am 31.07.2019,
zuletzt abgerufen am 28.07.2020.
Future of Life (2015): Autonomous Weapons: an Open Letter from AI &amp; Robotics Researchers. Offener Brief.
Online verf&#252;gbar unter https://www3.nd.edu/~dhoward1/FLI%20-
%20Future%20of%20Life%20Institute.pdf, zuletzt abgerufen am 20.07.2020.
FutureManagementGroupAG (2018): Smartes Handwerk: Zwischen Tradition und Technologie. 
Visionskandidaten und Zukunftsstrategien f&#252;r das Handwerk und seine Partner (Market Forsights, 
4/2018). Online verf&#252;gbar unter https://www.futuremanagementgroup.com/wp-
content/uploads/2018/11/MF_Zukunft-Handwerk-1.pdf, zuletzt abgerufen am 21.07.2020.
Gabler, Sibylle (2019): KI-Normung und -Standardisierung auf nationaler, europ&#228;ischer und internationaler
Ebene. Deutsches Institut f&#252;r Normung e. V., 2019. Online verf&#252;gbar unter
https://www.din.de/blob/340242/fcd3aec069317071ab31169cc888e3c4/ki-national-europaeisch-
international-data.pdf, zuletzt abgerufen am 27.07.2020.
Gallwitz, Florian (2019): Die M&#228;r von &#8222;Social Bots&#8220;. Standpunkt. In: Tagesspiegel Background, 03. Juni 2019. 
Online verf&#252;gbar unter https://background.tagesspiegel.de/digitalisierung/die-maer-von-social-bots, 
zuletzt abgerufen am 01.09.2020.
Garbade, Michael (2018): Top 8 open source AI technologies in machine learning. Hg. v. opensource.com. 
Online verf&#252;gbar unter https://opensource.com/article/18/5/top-8-open-source-ai-technologies-machine-
learning, zuletzt abgerufen am 23.07.2020.
Generalzolldirektion &#8211; Financial Intelligence Unit (FIU) (2019): Jahresbericht 2018 &#8211; Financial Intelligence
Unit. Online verf&#252;gbar unter https://www.zoll.de/SharedDocs/Downloads/DE/Links-fuer-
Inhaltseiten/Fachthemen/FIU/fiu_jahresbericht_2018.pdf?__blob=publicationFile&amp;v=3, zuletzt
abgerufen am 07.08.2020.
Gerstner, Dominik (2017): Predictive Policing als Instrument zur Pr&#228;vention von Wohnungseinbruchdiebstahl. 
Evaluationsergebnisse zum baden-w&#252;rttembergischen Pilotprojekt P4. 1. Auflage. Freiburg im Breisgau:
Max-Planck-Institut f&#252;r ausl&#228;ndisches und internationales Strafrecht (Research in brief, 50). Online
verf&#252;gbar unter https://pure.mpg.de/rest/items/item_2498917_3/component/file_3014304/content, 
zuletzt abgerufen am 17.07.2020.
Gesellschaft f&#252;r Informatik (2019): KI und Popkultur. Eine Repr&#228;sentativbefragung der deutschen Bev&#246;lkerung 
ab 16 Jahre. Institut f&#252;r Demoskopie Allensbach.
Gesellschaft f&#252;r Informatik (2019): T&#246;dliche autonome Waffensysteme (LAWS) m&#252;ssen v&#246;lkerrechtlich
ge&#228;chtet werden. Stellungnahme. Online verf&#252;gbar unter https://gi.de/fileadmin/GI/Allgemein/PDF/GI-
Stellungnahme_LAWS_2019-02.pdf, zuletzt abgerufen am 20.07.2020.
Gesellschaft f&#252;r Informatik e. V. (2018): Technische und rechtliche Betrachtungen algorithmischer
Entscheidungsverfahren. Studien und Gutachten im Auftrag des Sachverst&#228;ndigenrats f&#252;r
Verbraucherfragen. Hg. v. Sachverst&#228;ndigenrat f&#252;r Verbraucherfragen beim Bundesministerium der
Justiz und f&#252;r Verbraucherschutz. Berlin. Online verf&#252;gbar unter https://www.svr-
verbraucherfragen.de/wp-content/uploads/GI_Studie_Algorithmenregulierung.pdf, zuletzt abgerufen am
05.08.2020.
Gewerkschaft Erziehung und Wissenschaft (GEW) im DGB in Kooperation mit dem Verband f&#252;r Schulen f&#252;r
gemeinsames Lernen (GGG) und der Arbeitskammer des Saarlandes: Die Hattie-Studie. 
Forschungsbilanz und Handlungsperspektiven (Impulse Saarland). Online verf&#252;gbar unter
http://www.gew-saarland.de/images/pdf/Impulse_HattieStudie_Internet.pdf, zuletzt abgerufen am
06.08.2020.
Ghalati, Pejman F.; Samal, Satya S.; Bhat, Jayesh S.; Deisz, Robert; Marx, Gernot; Schuppert, Andreas (2019):
Critical Transitions in Intensive Care Units: A Sepsis Case Study. In: Scientific reports 9 (1), S. 12888. 
gie/dpa/aerzteblatt.de (2017): Brain-Computer-Interface: Vollst&#228;ndig gel&#228;hmte Patienten kommunizieren
wieder. Hg. v. &#196;rzteblatt.de. Online verf&#252;gbar unter
https://www.aerzteblatt.de/nachrichten/72806/Brain-Computer-Interface-Vollstaendig-gelaehmte-
Patienten-%20kommuni-zieren-wieder, zuletzt aktualisiert am 01.02.2017, zuletzt abgerufen am
10.07.2020.
Giles, Martin (2018): DARPA has an ambitious $1.5 billion plan to reinvent electronics. Hg. v.
technologyreview.com. Online verf&#252;gbar unter
https://www.technologyreview.com/2018/07/30/141258/darpa-has-an-ambitious-15-billion-plan-to-
reinvent-electronics/, zuletzt abgerufen am 23.07.2020.
Gillespie, Tarleton (2014): The Relevance of Algorithms. In: Tarleton Gillespie, Pablo J. Boczkowski und 
Kirsten A. Foot (Hg.): Media Technologies: The MIT Press, S. 167&#8211;194.
Gillmann, Barbara (2019): Die Bundesregierung st&#252;mpert bei der KI-F&#246;rderung. In: Handelsblatt.com, 
22. April 2019. Online verf&#252;gbar unter https://www.handelsblatt.com/meinung/kommentare/kommentar-
die-bundesregierung-stuempert-bei-der-ki-foerderung/24232748.html?ticket=ST-16667464-
kKfqkBd3OLnor6yFc4LC-ap5, zuletzt abgerufen am 30.07.2020.
Gimpel, Henner; Lanzl, Julia; Manner-Romberg, Tobias; N&#252;ske, Niklas (2018): Digitaler Stress in 
Deutschland. Eine Befragung von Erwerbst&#228;tigen zu Belastung und Beanspruchung durch Arbeit mit
digitalen Technologien. Hg. v. Hans B&#246;ckler Stiftung (Working Paper Forschungsf&#246;rderung, 101). 
Online verf&#252;gbar unter https://www.boeckler.de/de/faust-detail.htm?sync_id=HBS-07024, zuletzt
abgerufen am 30.07.2020.
Gitelman, Lisa (2013): &#8222;Raw data&#8220; is an oxymoron: The MIT Press (Infrastructures series). Online verf&#252;gbar
unter http://ieeexplore.ieee.org/servlet/opac?bknumber=6451327.
Gleich, Uli (2020): Nachrichtennutzung im Internet. In: Media Perspektiven (1/2020), S. 33&#8211;38. Online
verf&#252;gbar unter https://www.ard-werbung.de/fileadmin/user_upload/media-
perspektiven/pdf/2020/0120_ARD-Forschungsdienst.pdf, zuletzt abgerufen am 16.07.2020.
Goldsmith, Stephen; Crawford, Susan (2014): The responsive city. Engaging communities through data-smart
governance. First edition. San Francisco, CA: Jossey-Bass a Wiley brand (Safari Tech Books Online).
Online verf&#252;gbar unter http://proquest.safaribooksonline.com/9781118910931.
Goodfellow, Ian; Papernot, Nicolas (2017): Is attacking machine learning easier than defending it? Hg. v. 
cleverhans-blog. Online verf&#252;gbar unter http://www.cleverhans.io/security/privacy/ml/2017/02/15/why-
attacking-machine-learning-is-easier-than-defending-it, zuletzt abgerufen am 23.07.2020.
Google LLC (2020): Google Transparenzbericht. Entfernungen von Inhalten nach dem
Netzwerkdurchsetzungsgesetz &#8211; Berichtszeitraum Januar 2020 bis Juni 2020. Online verf&#252;gbar unter
https://transparencyreport.google.com/netzdg/youtube, zuletzt abgerufen am 06.08.2020.
Google LLC (2020): Google Transparenzbericht. YouTube-Community-Richtlinien und ihre Anwendung &#8211;
Berichtszeitraum Januar 2020 bis M&#228;rz 2020. Online verf&#252;gbar unter
https://transparencyreport.google.com/youtube-
policy/removals?hl=de&amp;lu=videos_by_views&amp;videos_by_views=detection_sources:AUTOMATED_O 
NLY, zuletzt abgerufen am 06.08.2020.
Google LLC (2020): Verwendung von Content ID. Online verf&#252;gbar unter
https://support.google.com/youtube/answer/3244015?hl=de, zuletzt abgerufen am 05.08.2020.
GoogleWachtBlog.de (2018): Milliarden-Investition in die Infrastruktur: Google baut neues Rechenzentrums in 
Singapur. Online verf&#252;gbar unter https://www.googlewatchblog.de/2018/08/milliarden-investition-
infrastruktur-google/, zuletzt abgerufen am 23.07.2020.
Goos, Maarten; Arntz, Melanie; Zierahn, Ulrich; Gregory, Terry; Gomez, Stephanie Carretero; Vazquez,
Ignacio Gonzalez; Jonkers, Koen (2019): The Impact of Technological Innovation on the Future of
Work. Seville (JRC Working Papers Series on Labour, Education and Technology, 2019/03). Online
verf&#252;gbar unter https://www.econstor.eu/bitstream/10419/202320/1/jrc-wplet201903.pdf, zuletzt
abgerufen am 15.07.2020.
Gordon, Robert J. (2016): The rise and fall of American growth. The U.S. standard of living since the Civil
War. Princeton, Oxford: Princeton University Press (The Princeton economic history of the Western 
world).
Gounalakis, Georgios; Sjurts, Insa; Althammer, Wilhelm; L&#252;bbert, Hans-Dieter; Mail&#228;nder, Peter; M&#252;ller-
Terpitz, Ralf et al. (2019): KEK Kommission zur Ermittlung der Konzentration im Medienbereich &#8211;
21. Jahresbericht 2018/2019. Berichtszeitraum 01.07.2018 bis 30.06.2019. Hg. v. die medienanstalten &#8211;
ALM GbR. Online verf&#252;gbar unter https://www.kek-
online.de/fileadmin/user_upload/KEK/Publikationen/Jahresberichte/21._Jahresbericht.pdf, zuletzt
abgerufen am 04.08.2020.
Government Digital Service; Office for Artificial Intelligence (2019): Natural language processing for Land
Registry documentation in Sweden. Learn how the Swedish Land Registry used natural language
processing to handle land registry requests more efficiently. Case study. Online verf&#252;gbar unter
https://www.gov.uk/government/case-studies/natural-language-processing-for-land-registry-
documentation-in-sweden, zuletzt abgerufen am 14.07.2020.
Gr&#228;fe, Daniel (2019): Stellen uns bald Roboter ein? Stimmanalysen, automatischer Lebenslauf-Check und 
Video-Interviews mit Software-Hilfe: Um geeignete Bewerber zu finden, nutzen auch Firmen aus der
Region k&#252;nstliche Intelligenz. In: Stuttgarter Zeitung 2019, 01. Februar 2019, S. 9.
Gr&#228;fe, Hans-Christian (2018): Webtracking und Microtargeting als Gefahr f&#252;r Demokratie und Medien. In:
PinG (1), S. 5&#8211;13. 
Grasel, Sara (2019): Dein altes Handy kann den Regenwald retten. Hg. v. techandnature.com. Online verf&#252;gbar
unter https://www.techandnature.com/rainforest-connection-wald-retten/, zuletzt abgerufen am
07.08.2020.
Gr&#228;vemeyer, Arne (2019): Simultan&#252;bersetzer und Dialogsysteme aus deutschen KI-Schmieden. Am
Karlsruher KIT werden Vorlesungen automatisiert mitgeschrieben und simultan &#252;bersetzt. Und am
S&#228;chsischen Landtag erzeugt ein Fraunhofer Spracherkenner Untertitel f&#252;r den Live-Mitschnitt. In: c't &#8211;
magazin f&#252;r computertechnik 2019, 23. Mai 2019 (11/2019). Online verf&#252;gbar unter
https://www.heise.de/ct/artikel/Simultanuebersetzer-und-Dialogsysteme-aus-deutschen-KI-Schmieden-
4416739.html, zuletzt abgerufen am 16.07.2020.
Great Britain. Department for Culture, Media and Sport (2019): Online harms white paper. London: Stationary
Office (CP, 57). Online verf&#252;gbar unter
https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/79336 
0/Online_Harms_White_Paper.pdf, zuletzt abgerufen am 12.08.2020.
Greef, Samuel; Schroeder, Wolfgang (2017): Plattform&#246;konomie und Crowdworking: Eine Analyse der
Strategien und Positionen zentraler Akteure. Unter Mitarbeit von Alexander Akel, Alex Berzel, Oliver
D'Antonio, Benedikt Schreiter, Hans Joachim Sperling und Universit&#228;t Kassel, Fachbereich 5 
Gesellschaftswissenschaften, Fachgebiet Politisches System der BRD &#8211; Staatlichkeit im Wandel.
Hg. v. Bundesministerium f&#252;r Arbeit und Soziales (BMAS) (Forschungsbericht 500). Online verf&#252;gbar
unter https://www.bmas.de/SharedDocs/Downloads/DE/PDF-Publikationen/Forschungsberichte/fb500-
plattformoekonomie-und-crowdworking.pdf?__blob=publicationFile&amp;v=1, zuletzt abgerufen am
17.07.2020.
Gregory, Terry; Salomons, Anna; Zierahn, Ulrich (2019 (aktualisiert 2019)): Racing With or Against the
Machine? Evidence from Europe. Hg. v. IZA &#8211; Institute of Labour Economics (IZA Discussion paper, 
No. 12063). Online verf&#252;gbar unter http://ftp.iza.org/dp12063.pdf, zuletzt abgerufen am 15.07.2020.
Greis, Friedhelm (2018): Fl&#228;chendeckende Gesichtserkennung r&#252;ckt n&#228;her. Pilotprojekt S&#252;dkreuz ausgewertet. 
Hg. v. Golem.de. Online verf&#252;gbar unter https://www.golem.de/news/pilotprojekt-suedkreuz-
ausgewertet-flaechendeckende-gesichtserkennung-rueckt-naeher-1810-137080.html, zuletzt abgerufen 
am 21.07.2020.
Gropp, Martin (2018): Singapur ist f&#252;hrende &#8222;Smart City&#8220;. Gr&#252;ner, besser, schneller. In: faz.net, 07. Juni 2018. 
Online verf&#252;gbar unter https://www.faz.net/aktuell/wirtschaft/diginomics/singapur-ist-fuehrende-smart-
city-15628406.html, zuletzt abgerufen am 16.07.2020.
Grzymek, Viktoria; Puntschuh, Michael (2019): Was Europa &#252;ber Algorithmen wei&#223; und denkt &#8211; Ergebnisse
einer repr&#228;sentativen Bev&#246;lkerungsumfrage. Hg. v. Bertelsmann Stiftung. Online verf&#252;gbar unter
https://www.bertelsmann-
stiftung.de/fileadmin/files/BSt/Publikationen/GrauePublikationen/WasEuropaUEberAlgorithmenWeissU 
ndDenkt.pdf, zuletzt abgerufen am 20.07.2020.
Guger, Christoph; Harkam, Werner; Hertnaes, Carin; Pfurtscheller, Gert (2001): Prosthetic Control by an EEG-
based BrainComputer Interface (BCI). Institute of Biomedical Engineering, Department of Medical
Informatics Ludwig-Boltzmann Institute for Medical Informatics and Neuroinformatics University of
Technology Graz. Online verf&#252;gbar unter
https://pdfs.semanticscholar.org/c864/6a15245732a8f91fb74294562b99d19628df.pdf?_ga=2.224692122 
.1226807780.1594302739-1331122190.1594302739, zuletzt abgerufen am 09.07.2020.
Haak, Steve (2020): Dieses KI-Startup arbeitet auch nur mit Google und Slack. In: gruenderszene.de, 
13. Januar 2020. Online verf&#252;gbar unter https://www.gruenderszene.de/technologie/tipps-und-tools-
ella?interstitial_click, zuletzt abgerufen am 03.08.2020.
Habel, Dominic (2019): Roboterjournalismus. 1. Auflage (Schriften zum Medien- und Informationsrecht).
Hachmeister, Lutz; Kenzler, Justine; Granzeuer, Fabian (2018): Ein Vakuum aus Kalk&#252;l &#8211; Zum Zustand der
deutschen und europ&#228;ischen Medienpolitik. In: Aus Politik und Zeitgeschichte 68 (40-41), S. 4&#8211;10. 
Online verf&#252;gbar unter https://www.bpb.de/apuz/276549/zum-zustand-der-deutschen-und-
europaeischen-medienpolitik, zuletzt abgerufen am 29.07.2020.
Hacker, Philipp (2020): Europ&#228;ische und nationale Regulierung von K&#252;nstlicher Intelligenz. In: NJW Neue 
Juristische Wochenschrift (30), S. 2142&#8211;2147.
HafenCity Universit&#228;t Hamburg: CityScienceLab, eine Kooperation mit dem MIT Media Lab. Online
verf&#252;gbar unter https://www.hcu-hamburg.de/research/csl/, zuletzt abgerufen am 16.07.2020.
Hagendorff, Thilo (2020): The Ethics of AI Ethics: An Evaluation of Guidelines. In: Minds &amp; Machines 30 (1), 
S. 99&#8211;120. 
Haim, Mario; Graefe, Andreas; Brosius, Hans-Bernd (2018): Burst of the Filter Bubble? In: Digital Journalism
6 (3), S. 330&#8211;343. 
Haller, Michael (2010): Ethik und Qualit&#228;t. In: Christian Schicha und Carsten Brosda (Hg.): Handbuch 
Medienethik, Bd. 40. Wiesbaden: VS Verlag f&#252;r Sozialwissenschaften, S. 348&#8211;361.
Hamich, Christopher (2019): UN-Bericht zu Hate Speech &#8211; Staaten sollten regulieren, nicht Unternehmen. 
Hg. v. Netzpolitik.org. Online verf&#252;gbar unter https://netzpolitik.org/2019/staaten-sollten-regulieren-
nicht-unternehmen/, zuletzt aktualisiert am 23.10.2019, zuletzt abgerufen am 06.08.2020.
Hampel, Svenja (2019): Smart City Index 2019: Wie digital sind Deutschlands St&#228;dte? Hg. v. Bitkom e. V. 
Online verf&#252;gbar unter https://www.bitkom.org/sites/default/files/2019-10/191021_smart-city-
index_gesamt.pdf.
Handelsverband Deutschland (2017): Handel 4.0 &#8211; Algorithmische Entscheidungen und K&#252;nstliche Intelligenz
im Handel. Online verf&#252;gbar unter https://einzelhandel.de/images/E-
Commerce/Publikationen/Handel_4.0/Two-Pager_Handel-4.0_Algorithmen--KI.pdf, zuletzt abgerufen 
am 22.07.2020.
Hannover Messe (27.03.2019): Hannover Messe boomt mit Industrie 4.0, K&#252;nstlicher Intelligenz und 5G. 
Online verf&#252;gbar unter https://www.hannovermesse.de/de/presse/pressemitteilungen/hannover-
messe/pressemitteilung-detailseite_1970, zuletzt abgerufen am 22.07.2020.
Hao, Karen (2019): The computing power needed to train AI is now rising seven times faster than ever before. 
In: MIT Technology Review. Online verf&#252;gbar unter The computing power needed to train AI is now
rising seven times faster than ever before, zuletzt abgerufen am 07.08.2020.
Haring, Robin (2019): Gesundheit digital. Perspektiven zur Digitalisierung im Gesundheitswesen. Berlin, 
Heidelberg: Springer Berlin Heidelberg.
Hartong, Sigrid (2019): Learning Analytics und Big Data in der Bildung. Zur notwendigen Entwicklung eines
datenpolitischen Alternativprogramms. Hg. v. Gewerkschaft Erziehung und Wissenschaft. Online
verf&#252;gbar unter
https://www.gew.de/index.php?eID=dumpFile&amp;t=f&amp;f=91791&amp;token=702ec8d5f9770206a4aa8a107975 
0ec9021b90bf&amp;sdownload=&amp;n=Learning-analytics-2019-web-IVZ.pdf, zuletzt abgerufen am
09.09.2020.
Hartong, Sigrid; F&#246;rschler, Annina (2019): Opening the black box of data-based school monitoring: Data
infrastructures, flows and practices in state education agencies. In: Big Data &amp; Society 6 (1), 
205395171985331.
Haskel, Jonathan; Westlake, Stian (2018): Capitalism without capital. The rise of the intangible economy : with 
a new preface by the authors. First paperback printing. Princeton: Princeton University Press.
Haskins, Carolina (2018): New App Lets You &#8222;Sue Anyone By Pressing a Button&#8220;. DoNotPay is a free app that
is designed to help normal people fight big corporations in small claims court. Hg. v. vice.com. Online
verf&#252;gbar unter https://www.vice.com/en_us/article/bj43y8/donotpay-app-lets-you-sue-anyone-by-
pressing-a-button, zuletzt abgerufen am 14.07.2020.
Hassan, Mahmoud; Daiber, Florian; Wiehr, Frederik; Kosmalla, Felix; Kr&#252;ger, Antonio (2017): FootStriker:
An EMS-based Foot Strike Assistant for Running. In: Proc. ACM Interact. Mob. Wearable Ubiquitous
Technol. 1 (1), S. 1&#8211;18. 
Heck, Max (2019): Wenn eine KI die wichtigen Charaktere im Computerspiel umbringt (Gr&#252;nstreifen). 
Deutschlandfunk Nova, 27. Mai 2019. Online verf&#252;gbar unter
https://www.deutschlandfunknova.de/beitrag/computerspiel-ueber-die-intelligenz-von-games, zuletzt
abgerufen am 15.07.2020.
Hecker, Dirk (2019): KI made in Germany. F&#252;r den Menschen, verl&#228;sslich im Einsatz, selbstbestimmt im
Umgang mit Daten. Fraunhofer Morgen-Radar. Fraunhofer-Gesellschaft, 24. Oktober 2019.
Hegelich, Simon; Serrano, Juan Carlos Medina (2019): Microtargeting in Deutschland bei der Europawahl
2019. Hg. v. Landesanstalt f&#252;r Medien NRW. Online verf&#252;gbar unter https://www.medienanstalt-
nrw.de/fileadmin/user_upload/
lfmnrw/Foerderung/Forschung/Dateien_Forschung/Studie_Microtargeting_DeutschlandEuropawahl2019_H 
egelich.pdf, zuletzt abgerufen am 03.08.2020.
Hegemann, Lisa (2020): Personalisierung ja, aber bitte nicht mit meinen Daten! In: Zeit.de 2020, 25. Februar
2020. Online verf&#252;gbar unter https://www.zeit.de/digital/datenschutz/2020-02/datenschutz-kuenstliche-
intelligenz-personalisierung-werbung, zuletzt abgerufen am 03.08.2020.
Heiniger, Bastian (2019): SBB, BLS und SOB bauen an der Bahn der Zukunft. Hg. v. HZ Das Wirtschaftportal
von Handelszeitung und BILANZ. Online verf&#252;gbar unter
https://www.handelszeitung.ch/unternehmen/sbb-bls-und-sob-bauen-der-bahn-der-zukunft, zuletzt
abgerufen am 24.07.2020.
heise.de (2019): Facebook l&#246;scht 1,7 Milliarden Fake-Accounts und erkennt Hassposts automatisch. Online
verf&#252;gbar unter https://www.heise.de/newsticker/meldung/Facebook-loescht-1-7-Milliarden-Fake-
Accounts-und-erkennt-Hassposts-automatisch-4585753.html, zuletzt aktualisiert am 14.11.2019, zuletzt
abgerufen am 06.08.2020.
Heitm&#252;ller, Ulrike (2019): Missing Link: Predictive Policing &#8211; die Kunst, Verbrechen vorherzusagen. Hg. v. 
heise.de. Online verf&#252;gbar unter https://www.heise.de/newsticker/meldung/Missing-Link-Predictive-
Policing-die-Kunst-Verbrechen-vorherzusagen-4425204.html, zuletzt aktualisiert am 19.05.2019, zuletzt 
abgerufen am 17.07.2020.
Helberger, Natali (2019): On the Democratic Role of News Recommenders. In: Digital Journalism 7 (8), 
S. 993&#8211;1012.
Heller, Piotr (2017): Interessante Technik &#8211; gro&#223;e Gefahr. Maschinelle Sprachimitation. Hg. v. 
Deutschlandfunk. Online verf&#252;gbar unter https://www.deutschlandfunk.de/maschinelle-sprachimitation-
interessante-technik-grosse.676.de.html?dram:article_id=393958, zuletzt aktualisiert am 21.08.2017,
zuletzt abgerufen am 17.07.2020.
Helmholtz: Das Programm &#8222;Future Information Technology (FIT) &#8211; Fundamentals, Novel Concepts, and 
Energy Efficiency&#8220;. Online verf&#252;gbar unter
https://www.helmholtz.de/forschung/schluesseltechnologien/future_information_technology/, zuletzt
abgerufen am 07.08.2020.
Hendry, Justin (2019): Second Aussie airport gets new contactless arrivals smartgates. Hg. v. itnews.com. 
Online verf&#252;gbar unter https://www.itnews.com.au/news/second-aussie-airport-gets-new-contactless-
arrivals-smartgates-518663, zuletzt aktualisiert am 12.02.2019, zuletzt abgerufen am 17.07.2020.
Henkel, Regina (2019): Adler Modem&#228;rkte: 40 neue Service-Roboter erfolgreich im Einsatz. Hg. v. 
FashionUnited. Online verf&#252;gbar unter https://fashionunited.de/nachrichten/business/adler-
modemaerkte-40-neue-service-roboter-erfolgreich-im-einsatz/2019092633179, zuletzt aktualisiert am
26.09.2019, zuletzt abgerufen am 15.07.2020.
Henley, Jon; Booth, Robert (2020): Welfare surveillance system violates human rights, Dutch court rules. 
Government told to halt use of AI to detect fraud in decision hailed by privacy campaigners. In:
theguardian.com, 05. Februar 2020. Online verf&#252;gbar unter
https://www.theguardian.com/technology/2020/feb/05/welfare-surveillance-system-violates-human-
rights-dutch-court-rules, zuletzt abgerufen am 06.08.2020.
Henn, Rupert; Holtmann, Berthold (2018): Autonomes Fahren in der Binnenschifffahrt. Machbarkeitsstudie f&#252;r
ein Testfeld im Ruhrgebiet. Hg. v. Industrie- und Handelskammern im Ruhrgebiet. Online verf&#252;gbar
unter https://www.dst-org.de/wp-content/uploads/2018/11/Machbarkeitsstudie-Autonomes-Fahren.pdf, 
zuletzt abgerufen am 03.08.2020.
Hensel, Martin; Litzel, Nico (2018): IDC-Studie identifiziert Nachholbedarf &#8211; Mangel an Fachkr&#228;ften bremst
KI-Projekte aus. Hg. v. BigData-Insider. Online verf&#252;gbar unter https://www.bigdata-insider.de/mangel-
an-fachkraeften-bremst-ki-projekte-aus-a-715306/, zuletzt abgerufen am 16.07.2020.
Herget, Steffen (2018): K&#252;nstliche Intelligenz im Kino: Die 10 spannendsten Filme mit KI. Hg. v. 
androidpit.de. Online verf&#252;gbar unter https://www.androidpit.de/kuenstliche-intelligenz-in-kino-filmen, 
zuletzt aktualisiert am 13.03.2018, zuletzt abgerufen am 14.07.2020.
Herold, Viktoria (2019): Algorithmisierung von Ermessensentscheidungen durch Machine Learning. In: InTeR:
Zeitschrift zum Innovations- und Technikrecht (01), S. 7&#8211;11.
Herpig, Sven (2019): IT-Sicherheit &amp; Maschinelles Lernen. TeleTrusT-Konferenz 2019 Berlin, 28. November
2019. Hg. v. Stiftung Neue Verantwortung e. V. Online verf&#252;gbar unter
https://www.teletrust.de/fileadmin/user_upload/02_TeleTrusT-
Konferenz_2019_Herpig_Stiftung_Neue_Verantwortung.pdf, zuletzt abgerufen am 20.07.2020.
Heumann, Stefan; Jentzsch, Nicola (2019): Wettbewerb um Daten &#8211; &#220;ber Datenpools zu Innovationen. 
Hg. v. Stiftung Neue Verantwortung e. V. Online verf&#252;gbar unter https://www.stiftung-
nv.de/sites/default/files/wettbewerb_um_daten.pdf, zuletzt abgerufen am 27.07.2020.
Heumann, Stefan; Zahn, Nicolas (2018): Erfolgsmessung von KI-Strategien. Mit Indikatoren und Benchmarks
die Umsetzung der Strategie erfolgreich steuern. Hg. v. Stiftung Neue Verantwortung e. V. Online
verf&#252;gbar unter https://www.stiftung-nv.de/sites/default/files/erfolgsmessung_von_ki-strategien.pdf, 
zuletzt abgerufen am 27.07.20202.
Highfield, Vaughn (2018): Sensors, Scandal And Sustainability: Inside The San Francisco Smart City Being
Built From Scratch On An Abandoned Naval Yard. Hg. v. alphr.com. Online verf&#252;gbar unter
https://www.alphr.com/the-future/1009514/inside-san-francisco-smart-city, zuletzt aktualisiert am
05.06.2018, zuletzt abgerufen am 16.07.2020.
High-Level Expert Group on Artificial Intelligence (2019): Eine Definition der KI: Wichtigste F&#228;higkeiten und 
Wissenschaftsgebiete. Hg. v. Europ&#228;ische Kommission. Online verf&#252;gbar unter
https://ec.europa.eu/newsroom/dae/document.cfm?doc_id=56341, zuletzt abgerufen am 04.08.2020.
High-Level Expert Group on Artificial Intelligence (2019): Ethik-Leitlinien f&#252;r eine vertrauensw&#252;rdige
KI. Hg. v. Europ&#228;ische Kommission. Online verf&#252;gbar unter https://ec.europa.eu/digital-single-
market/en/news/ethics-guidelines-trustworthy-ai, zuletzt abgerufen am 20.07.2020.
High-Level Expert Group on Artificial Intelligence (2019): Policy and investment recommendations for
trustworthy Artificial Intelligence. Hg. v. Europ&#228;ische Kommission. Online verf&#252;gbar unter
https://ec.europa.eu/digital-single-market/en/news/policy-and-investment-recommendations-trustworth
yartificial-intelligence, zuletzt abgerufen am 20.07.2020.
Hintemann, Ralph (2016): Rechenzentren &#8211; Energiefresser oder Effizienzwunder? In: informatik-aktuell.de, 
26. Juni 2016. Online verf&#252;gbar unter https://www.informatik-aktuell.de/betrieb/server/rechenzentren-
energiefresser-oder-effizienzwunder.html, zuletzt abgerufen am 23.07.2020.
Hirsch-Kreinsen, Hartmut (2018): Arbeit 4.0: Pfadabh&#228;ngigkeit statt Disruption. In: Soziologisches
Arbeitspapier (52). Online verf&#252;gbar unter
http://129.217.131.68:8080/bitstream/2003/36808/1/Pfadabh%C3%A4ngigkeit%20statt%20Disruption.p 
df, zuletzt abgerufen am 13.07.2020.
Hirsch-Kreinsen, Hartmut; Ittermann, Peter; Niehaus, Jonathan (2018): Digitalisierung industrieller Arbeit: 
Nomos Verlagsgesellschaft mbH &amp; Co. KG. Online verf&#252;gbar unter https://www.nomos-
elibrary.de/10.5771/9783845283340.pdf?download_full_pdf=1, zuletzt abgerufen am 17.07.2020.
Ho, Tram (2019): Estonia &#8222;The judge is not human&#8220;. Hg. v. itzone.com. Online verf&#252;gbar unter
https://itzone.com.vn/en/article/estonia-the-judge-is-not-human/, zuletzt aktualisiert am 14.04.2019,
zuletzt abgerufen am 14.07.2020.
Hodsden, Suzanne (2016): Artificial Intelligence Could Aid Earlier Diagnose of Alzheimer&#8217;s. Hg. v. Med 
Device Online. Online verf&#252;gbar unter https://www.meddeviceonline.com/doc/artificial-intelligence-
could-aid-earlier-diagnosis-of-alzheimer-s-0001, zuletzt aktualisiert am 11.07.2016, zuletzt abgerufen 
am 09.07.2020.
Hoffmann, Elisabeth; Henry-Huthmacher, Christine (2016): Ausbildungsreife &amp; Studierf&#228;higkeit. Konrad-
Adenauer-Stiftung. Sankt Augustin, Berlin: Konrad-Adenauer-Stiftung e.V (Eine Ver&#246;ffentlichung der
Konrad-Adenauer-Stiftung e.V). Online verf&#252;gbar unter
https://www.kas.de/documents/252038/253252/7_dokument_dok_pdf_44796_1.pdf/ec1762cf-4191-
596a-5163-3357c553d3ff?version=1.0&amp;t=1539650980320, zuletzt abgerufen am 06.08.2020.
Hofmann, Josephine; Wienken, Valerie (2018): Digital Leadership. F&#252;hrung in der digitalen Transformation. 
Hg. v. Fraunhofer-Institut f&#252;r Arbeitswirtschaft und Organisation IAO. Online verf&#252;gbar unter
https://www.dgfp.de/fileadmin/user_upload/DGFP_e.V/Medien/Publikationen/Studien/Studie_DGFP_Fr 
aunhofer_Digital_Leadership_2018.pdf, zuletzt abgerufen am 17.07.2020.
H&#246;lig, Sascha; Hasebrink, Uwe (2019): Reuters Institute Digital News Report 2019 &#8211; Ergebnisse f&#252;r 
Deutschland. Unter Mitarbeit von Julia Behre. Hg. v. Leibnitz-Institut f&#252;r Medienforschung Hans-
Bredow-Institut (Arbeitspapiere des HBI, 47). Online verf&#252;gbar unter https://www.hans-bredow-
institut.de/uploads/media/default/cms/media/os943xm_AP47_RDNR19_Deutschland.pdf, zuletzt
abgerufen am 16.07.2020.
Holler, Markus (2017): Verbreitung, Folgen und Gestaltungsaspekte der Digitalisierung in der Arbeitswelt. 
Auswertungsbericht auf Basis des DGB-Index Gute Arbeit 2016. Hg. v. Institut DGB-Index Gute Arbeit. 
Berlin. Online verf&#252;gbar unter https://index-gute-arbeit.dgb.de/++co++15db6694-b962-11e7-8463-
52540088cada, zuletzt abgerufen am 17.07.2020.
Holtel, Stefan; Hufenstuhl, Andreas; Klug, Andreas (2017): K&#252;nstliche Intelligenz verstehen als Automation 
des Entscheidens. Leitfaden. Hg. v. Bitkom e. V. Online verf&#252;gbar unter
https://www.bitkom.org/sites/default/files/file/import/Bitkom-Leitfaden-KI-verstehen-als-Automation-
des-Entscheidens-2-Mai-2017.pdf, zuletzt abgerufen am 16.07.2020.
hr info (2020): K&#252;nstliche Intelligenz in Hollywood &#8211; Wie man Filme auf Erfolg programmiert. Online
verf&#252;gbar unter https://www.hr-inforadio.de/programm/themen/kuenstliche-intelligenz-in-hollywood-
wie-man-filme-auf-erfolg-programmiert,kuenstliche-intelligenz-in-filmen-100.html, zuletzt aktualisiert 
am 07.02.2020, zuletzt abgerufen am 15.07.2020.
Hummel, Philipp (2017): Die T&#252;cken der Gesichtserkennung. &#220;berwachungstechnik. In: spektrum.de. Online
verf&#252;gbar unter https://www.spektrum.de/news/die-tuecken-der-gesichtserkennung/1521469, zuletzt
abgerufen am 17.07.2020.
Hunziker, Christian (2019): Wenn deine Stadt wei&#223;, wo du bist. In: welt.de, 11. Mai 2019. Online verf&#252;gbar
unter https://www.welt.de/finanzen/immobilien/article193108659/Kuenstliche-Intelligenz-Stadtplaner-
greifen-auf-Wohnungsdaten-zurueck.html, zuletzt abgerufen am 16.07.2020.
Hurtz, Simon (2019): Facebook darf keine L&#252;genschleuder f&#252;r Politiker sein. In: sueddeutsche.de 2019, 
31. Oktober 2019. Online verf&#252;gbar unter https://www.sueddeutsche.de/digital/twitter-facebook-
werbung-trump-1.4663590, zuletzt abgerufen am 15.07.2020.
Huss, Ralf (2019): K&#252;nstliche Intelligenz, Robotik und Big Data in der Medizin.
Hustedt, Carla (2019): Algorithmen-Transparenz. Was steckt hinter dem Buzzword? Hg. v. Bertelsmann 
Stiftung. Online verf&#252;gbar unter https://algorithmenethik.de/2019/05/06/algorithmen-transparenz-was-
steckt-hinter-dem-buzzword/, zuletzt aktualisiert am 06.05.2019, zuletzt abgerufen am 14.07.2020.
Hustedt, Carla; Knobloch, Tobias (2019): Der maschinelle Weg zum passenden Personal. Zur Rolle
algorithmischer Systeme in der Personalauswahl. Hg. v. Stiftung Neue Verantwortung &amp; Bertelsmann 
Stiftung. Online verf&#252;gbar unter https://www.stiftung-nv.de/sites/default/files/snv_robo_recruiting.pdf, 
zuletzt abgerufen am 05.08.2020.
Ians (2019): Google maps over 4.5 million animals in the wild. In: thehindu.com, 18. Dezember 2019. Online
verf&#252;gbar unter https://www.thehindu.com/sci-tech/technology/internet/google-maps-over-45-million-
animals-in-the-wild/article30337240.ece, zuletzt abgerufen am 07.08.2020.
ifm electronic gmbh (2019): Erwischt: O3X in Walmart. Online verf&#252;gbar unter
https://www.ifm.com/de/de/shared/news/o3x-in-walmart, zuletzt abgerufen am 15.07.2020.
IG Metall (2017): Arbeitszeit &#8211; sicher, gerecht und selbstbestimmt. Ergebnisse, Zahlen und Fakten zur
Arbeitszeit (Mein Leben &#8211; meine Zeit: Arbeit neu denken, Die Befragung 2017). Online verf&#252;gbar unter
https://www.igmetall.de/download/20170529_2017_05_29_befragung_ansicht_komp_489719b89f16dac 
a573614475c6ecfb706a78c9f.pdf, zuletzt abgerufen am 03.08.2020.
imsimity GmbH: imsimity. Online verf&#252;gbar unter http://imsimity.de/home.html, zuletzt abgerufen am
16.07.2020.
        
 
 
 
 
 
     
  
 
 
  
 
 
 
 
     
 
 
 
      
&#8201;
Info-communications Media Development Authority; Personal Data Protection Commission (2020): Artificial 
Intelligence Governance Framework. Second Edition. Model. Online verf&#252;gbar unter
https://www.pdpc.gov.sg/-/media/files/pdpc/pdf-files/resource-for-
organisation/ai/sgmodelaigovframework2.pdf, zuletzt abgerufen am 23.07.2020.
Informationsgemeinschaft zur Feststellung der Verbreitung von Werbetr&#228;gern e. V. (IVW) (2020):
Gesch&#228;ftsbericht der IVW 2019, 2020. Online verf&#252;gbar unter
https://www.ivw.de/sites/default/files/ivw-gb2019-2020.pdf, zuletzt abgerufen am 16.07.2020.
Ingsoft GmbH (2017): Hoher Qualit&#228;tsanspruch: gute Lebensmittel, gute Energieeffizienz. IngSoft InterWatt
im Einsatz bei tegut. Online verf&#252;gbar unter
https://www.ingsoft.de/fileadmin/user_upload/energiemanagement/referenzen/Anwenderberichte/anwen 
derbericht-tegut.pdf, zuletzt abgerufen am 23.07.2020.
Inhoffen, Lisa (2018): K&#252;nstliche Intelligenz: Deutsche sehen eher die Risiken als den Nutzen. Online
verf&#252;gbar unter https://yougov.de/news/2018/09/11/kunstliche-intelligenz-deutsche-sehen-eher-die-ris/,
zuletzt abgerufen am 20.07.2020.
Initiative D21 e. V.: D21 Digital Index 2018/2019. J&#228;hrliches Lagebild zur Digitalen Gesellschaft. Unter
Mitarbeit von Kantar TNS. Online verf&#252;gbar unter
https://initiatived21.de/app/uploads/2019/01/d21_index2018_2019.pdf, zuletzt abgerufen am
13.07.2020.
Initiative D21 e. V. (2020): Wie digital ist Deutschland? &#8211; D21 Digital Index 19/20 &#8211; J&#228;hrliches Lagebild zur
Digitalen Gesellschaft. Online verf&#252;gbar unter
https://initiatived21.de/app/uploads/2020/02/d21_index2019_2020.pdf, zuletzt abgerufen am
16.07.2020.
Institut DGB-Index Gute Arbeit (2016): DGB- Index Gute Arbeit &#8211; Der Report 2016. Wie die Besch&#228;ftigten die 
Arbeitsbedingungen in Deutschland beurteilen. Mit dem Themenschwerpunkt: Die Digitalisierung der
Arbeitswelt &#8211; Eine Zwischenbilanz aus der Sicht der Besch&#228;ftigten. Online verf&#252;gbar unter https://index-
gute-arbeit.dgb.de/++co++76276168-a0fb-11e6-8bb8-525400e5a74a, zuletzt abgerufen am 03.08.2020.
Institut DGB-Index Gute Arbeit (2018): DGB-Index Gute Arbeit &#8211; Der Report 2018. Wie die Besch&#228;ftigten die
Arbeitsbedingungen in Deutschland beurteilen. Mit dem Themenschwerpunkt: Arbeit mit Kundschaft, 
PatientInnen, Lernenden etc., Interaktionsarbeit. Online verf&#252;gbar unter https://index-gute-
arbeit.dgb.de/++co++2710716a-e72f-11e8-891f-52540088cada, zuletzt abgerufen am 30.07.2020.
Institut f&#252;r Medien- und Kommunikationspolitik gGmbH (2008): Ranking &#8211; Die 50 gr&#246;&#223;ten Medienkonzerne
2008. Online verf&#252;gbar unter https://www.mediadb.eu/forum/daten-fuer-archiv/intl-medienkonzerne-
2008.html, zuletzt aktualisiert am 30.05.2014, zuletzt abgerufen am 28.07.2020.
Institut f&#252;r Urheber- und Medienrecht e. V.: Leistungsschutzrecht f&#252;r Presseverleger. Online verf&#252;gbar unter
https://www.urheberrecht.org/topic/LSRPV/, zuletzt abgerufen am 28.07.2020.
International Data Corporation (2019): IDC Studie: Deutsche Unternehmen nutzen KI zur Prozessoptimierung, 
Innovation wird vernachl&#228;ssigt. Online verf&#252;gbar unter
https://www.idc.com/getdoc.jsp?containerId=prEUR145072519, zuletzt abgerufen am 30.07.2020.
International Data Corporation (04.09.2019): Worldwide Spending on Artificial Intelligence Systems Will Be
Nearly $98 Billion in 2023, According to New IDC Spending Guide. Online verf&#252;gbar unter
https://www.idc.com/getdoc.jsp?containerId=prUS45481219, zuletzt abgerufen am 20.08.2020.
Internationales Verkehrswesen (2019): Smart City: K&#252;nstliche Intelligenz f&#252;r die Mobilit&#228;t von morgen. Online
verf&#252;gbar unter https://www.internationales-verkehrswesen.de/smart-city-kuenstliche-intelligenz-fuer-
die-mobilitaet-von-morgen/, zuletzt abgerufen am 16.07.2020.
IOP Publishing (2015): A brain-computer interface for controlling an exoskeleton. Online verf&#252;gbar unter
https://ioppublishing.org/news/bci-exoskeleton/, zuletzt aktualisiert am 18.08.2015, zuletzt abgerufen am
10.07.2020.
IoTOne (2019): 2019 Top 500 Industrial IoT Companies. Online verf&#252;gbar unter
https://www.iotone.com/iotone500, zuletzt abgerufen am 22.07.2020.
iQL - Immersive Quantified Learning Lab: InCoRAP. Intentionsbasierte kooperative Roboterhandlungsplanung
und Werkerunterst&#252;tzung in Fabrikumgebungen. Online verf&#252;gbar unter http://www.iql-
lab.de/forschung/, zuletzt abgerufen am 16.07.2020.
iso.org: ISO 31000. Risk Management. Online verf&#252;gbar unter https://www.iso.org/iso-31000-risk-
management.html, zuletzt abgerufen am 04.08.2020.
JAAI Newsteam (2018): K&#252;nstliche Intelligenz im Fu&#223;ball &#8211; IBM Watson hilft bei Bundesliga Transfers.
Hg. v. JAAI. Online verf&#252;gbar unter https://jaai.de/kuenstliche-intelligenz-fussball-ibm-watson-hilft-bei-
bundesliga-transfers-1730/, zuletzt aktualisiert am 02.02.2018, zuletzt abgerufen am 10.07.2020.
Jackob, Nikolaus; Jakobs, Ilka; Quiring, Oliver; Schultz, Tanjev; Schemer, Christian; Ziegele, Marc (2019):
Medienskepsis und Medienzynismus. Funktionale und dysfunktionale Formen von Medienkritik. In:
ComSoc 52 (1), S. 19&#8211;35. 
Jackob, Nikolaus; Schultz, Tanjev; Jakobs, Ilka; Ziegele, Marc; Quiring, Oliver; Schemer, Christian (2019):
Mainzer Langzeitstudie Medienvertrauen 2018 &#8211; Medienvertrauen im Zeitalter der Polarisierung. In: 
Media Perspektiven 2019 (5), S. 210&#8211;220. Online verf&#252;gbar unter https://www.ard-
werbung.de/fileadmin/user_upload/
mediaperspektiven/pdf/2019/0519_Jackob_Schultz_Jakobs_Ziegele_Quiring_Schemer_2019-06-12.pdf, 
zuletzt abgerufen am 16.07.2020.
Jahn, Thomas (2018): Die Medienbranche steht nach dem AT&amp;T Urteil vor einer Fusionswelle. In:
Handelsblatt.com. Online verf&#252;gbar unter https://www.handelsblatt.com/unternehmen/it-medien/film-
und-fernsehgeschaeft-die-medienbranche-steht-nach-dem-atundt-urteil-vor-
einerfusionswelle/22680322.html, zuletzt abgerufen am 28.07.2020.
Jaki, Sylvia; Smedt, Tom de (2018): Right-wing German Hate Speech on Twitter: Analysis and Automatic 
Detection. Hg. v. Cornell University. Online verf&#252;gbar unter
https://arxiv.org/ftp/arxiv/papers/1910/1910.07518.pdf, zuletzt abgerufen am 06.08.2020.
J&#228;schke, Thomas; Rochow, Sina; Tewes, Hanjo; Vogel, Alexander; Mertes, Henning; Reiter, Julius; Methner, 
Olaf (2018): F&#252;r immer anonym: Wie kann De-Anonymisierung verhindert werden? Gutachten zur
Verhinderung der De-Anonymisierung. Hg. v. Projekt ABIDA &#8211; Assessing Big Data. Online verf&#252;gbar
unter
https://www.abida.de/sites/default/files/ABIDA%20Gutachten%20F%c3%9cR%20IMMER%20ANON 
YM.pdf, zuletzt abgerufen am 15.07.2020.
Jobin, Anna; Ienca, Marcello; Vayena, Effy (2019): The global landscape of AI ethics guidelines. In: Nat Mach 
Intell 1 (9), S. 389&#8211;399.
Johnson, Khari (2020): Google&#8217;s AI powers real-time orca tracking in Vancouver Bay. Hg. v. venturebeat.com. 
Online verf&#252;gbar unter https://venturebeat.com/2020/01/28/googles-ai-powers-real-time-orca-tracking-
in-vancouver-bay/, zuletzt abgerufen am 07.08.2020.
Kaas, Leo; Manger, Christian (2010): Ethnic Discrimination in Germany&#8217;s Labour Market: A Field 
Experiment. Hg. v. IZA &#8211; Institute of Labour Economics (IZA Discussion paper, No. 4741). Online
verf&#252;gbar unter http://ftp.iza.org/dp4741.pdf, zuletzt abgerufen am 05.08.2020.
Kaiser, Markus (2018): Roboterjournalismus. Online verf&#252;gbar unter
http://journalistikon.de/roboterjournalismus/, zuletzt aktualisiert am 01.03.2018, zuletzt abgerufen am
30.07.2020.
Kaiser, Ulrich (2018): Von einem, der auszog, das F&#252;rchten zu lernen &#8230; Hg. v. Wikimedia Deutschland &#8211;
Gesellschaft zur F&#246;rderung Freien Wissens e. V. Online verf&#252;gbar unter
https://blog.wikimedia.de/2018/08/06/von-einem-der-auszog-das-fuerchten-zu-lernen/, zuletzt 
aktualisiert am 06.08.2018, zuletzt abgerufen am 05.08.2020.
Kammerer, Florian; Sch&#228;fsto&#223;, Nicolas; R&#246;w, Martin (2020): Umweltpolitische Digitalagenda. 1. Aufl. 
Hg. v. Bundesministerium f&#252;r Umwelt, Naturschutz und nukleare Sicherheit. Online verf&#252;gbar unter 
https://www.bmu.de/fileadmin/Daten_BMU/Pools/Broschueren/broschuere_digitalagenda_bf.pdf, 
zuletzt abgerufen am 07.08.2020.
Kampa, Nele (2015): Mathematische Kompetenzen in Profiloberstufen in Schleswig-Holstein. In: IPN Bl&#228;tter
Informationen aus dem Leibniz-Institut f&#252;r die P&#228;dagogik der Naturwissenschaften und Mathematik 32,
2015 (2/2015). Online verf&#252;gbar unter https://www.ipn.uni-kiel.de/de/das-ipn/archiv/ipnbl152s13.pdf, 
zuletzt abgerufen am 07.08.2020.
Kanadische Regierung (2020): Canada's Digital Charter: Trust in a digital world. Online verf&#252;gbar unter
https://www.ic.gc.ca/eic/site/062.nsf/eng/h_00108.html, zuletzt abgerufen am 04.08.2020.
Kanning, Uwe Peter (2018): Fachbuch im Fokus. Stulle, Klaus P. (Hrsg.): Psychologische Diagnostik durch
Sprachanalyse. Validierung der Precire-Technologie f&#252;r die Personalarbeit. In: wirtschaftspsychologie-
aktuell.de, 25. April 2018. Online verf&#252;gbar unter https://www.wirtschaftspsychologie-
aktuell.de/fachbuch/20180425-klaus-stulle-psychologische-diagnostik-durch-sprachanalyse.html, zuletzt
abgerufen am 06.08.2020.
Kaufmann, Franz-Xaver (1992): Der Ruf nach Verantwortung. Risiko und Ethik in einer un&#252;berschaubaren 
Welt. Originalausg: Herder (Herder Spektrum).
Kehl, Christoph (2018): Robotik und assistive Neurotechnologien in der Pflege &#8211; gesellschaftliche
Herausforderungen. Hg. v. B&#252;ro f&#252;r Technikfolgen-Absch&#228;tzung beim Deutschen Bundestag 
(TAB-Arbeitsbericht Nr. 177). Online verf&#252;gbar unter https://www.tab-beim-
bundestag.de/de/pdf/publikationen/berichte/TAB-Arbeitsbericht-ab177.pdf, zuletzt abgerufen am
09.07.2020.
Keller, Paul (2020): Article 17 stakeholder dialogue: What we have learned so far &#8211; Part 1. Hg. v. Wolters
Kluwer. Online verf&#252;gbar unter http://copyrightblog.kluweriplaw.com/2020/01/13/article-17-
stakeholder-dialogue-what-we-have-learned-so-far-part-
1/?doing_wp_cron=1596631220.9840540885925292968750, zuletzt aktualisiert am 13.01.2020, zuletzt
abgerufen am 05.08.2020.
Kettemann, Matthias C.; Schulz, Wolfgang (2020): Setting Rules for 2.7 Billion. A (First) Look into 
Facebook&#8217;s Norm-Making System: Results of a Pilot Study. Hg. v. Hans-Bredow-Institut (Working 
Papers of the Hans-Bredow-Institut / Works in Progress # 1). Online verf&#252;gbar unter https://www.hans-
bredow-institut.de/uploads/media/default/cms/media/1soch5s_AP_WiP001InsideFacebook.pdf, zuletzt
abgerufen am 04.08.2020.
KI Bundesverband e. V. (2019): KI G&#252;tesiegel. Online verf&#252;gbar unter https://ki-verband.de/wp-
content/uploads/2019/04/KIBV_Guetesiegel_110409_o-1.pdf, zuletzt abgerufen am 27.07.2020.
KI macht Schule, ein Projekt von IT4Kids e. V.: KI macht Schule. Wir bringen K&#252;nstliche Intelligenz und 
Maschinelles Lernen an deutsche Schulen! Online verf&#252;gbar unter https://ki-macht-schule.de/, zuletzt
abgerufen am 16.07.2020.
Kind, Sonja; Bovenschulte, Marc; Ehrenberg-Silies, Simone; Jetzke, Tobias; Weide, Sebastian (2017): Social
Bots. Thesenpapier zum &#246;ffentlichen Fachgespr&#228;ch &#187;Social Bots &#8211; Diskussion und Validierung von 
Zwischenergebnissen&#171; am 26. Januar 2017 im Deutschen Bundestag. Hg. v. B&#252;ro f&#252;r Technikfolgen-
Absch&#228;tzung beim Deutschen Bundestag (TAB). Online verf&#252;gbar unter https://www.tab-beim-
bundestag.de/de/aktuelles/20161219/Social%20Bots_Thesenpapier.pdf, zuletzt abgerufen am
04.08.2020.
Kind, Sonja; Ferdinand, Jan-Peter; Priesack, Kai (2019): Legal Tech &#8211; Potenziale und Wirkungen. Hg. v. B&#252;ro 
f&#252;r Technikfolgen-Absch&#228;tzung beim Deutschen Bundestag (TAB-Arbeitsbericht Nr. 185). Online
verf&#252;gbar unter https://www.tab-beim-bundestag.de/de/pdf/publikationen/berichte/TAB-Arbeitsbericht-
ab185.pdf, zuletzt abgerufen am 15.07.2020.
King, David (2007): Latest content ID tool for YouTube. Hg. v. Google LLC. Online verf&#252;gbar unter
https://googleblog.blogspot.com/2007/10/latest-content-id-tool-for-youtube.html, zuletzt aktualisiert am
15.10.2007, zuletzt abgerufen am 05.08.2020.
Klaas, Arne (2019): Demokratieprinzip im Spannungsfeld mit k&#252;nstlicher Intelligenz : demokratische
Entscheidungsfindung durch und mithilfe von selbstlernenden Algorithmen. In: MultiMedia und Recht
22, S. 84&#8211;90, zuletzt abgerufen am 03.08.2020.
Klausa, Torben (2020): Gutachten: Neue Regeln f&#252;r Facebook &amp; Co. n&#246;tig. In: Tagesspiegel Background, 
29. Januar 2020. Online verf&#252;gbar unter https://background.tagesspiegel.de/digitalisierung/gutachten-
neue-regeln-fuer-facebook-co-noetig, zuletzt abgerufen am 04.08.2020.
Kleinberg, Jon; Mullainathan, Sendhil; Raghavan, Manish (2017): Inherent Trade-Offs in the Fair 
Determination of Risk Scores. Schloss Dagstuhl. Unter Mitarbeit von Marc Herbstritt. Innovations in 
Theoretical Computer Science. Wadern/Saarbruecken, Deutschland. Leibniz-Zentrum fuer Informatik 
GmbH (43). Online verf&#252;gbar unter https://drops.dagstuhl.de/opus/volltexte/2017/8156/pdf/LIPIcs-
ITCS-2017-43.pdf, zuletzt abgerufen am 04.08.2020.
Kluge, Friedrich; Seebold, Elmar (2011): Etymologisches W&#246;rterbuch der deutschen Sprache. EBookPlus. 25., 
aktualisierte und erw. Aufl. Berlin: DE GRUYTER. Online verf&#252;gbar unter
http://dx.doi.org/10.1515/9783110223651.
Knau&#223;, Ferdinand (2019): Mittelstandspr&#228;sident Ohoven &#8222;Viele Bewerber beherrschen nicht einmal die
Grundrechenarten&#8220;. Nachdem Tausende Abiturienten &#252;ber das angeblich zu schwierige Mathematik-
Abitur klagten, meldet sich jetzt die mittelst&#228;ndische Wirtschaft zu Wort. Die Mathekenntnisse der
Schulabg&#228;nger seien zu schwach. In: wiwo.de, 10. Mai 2019. Online verf&#252;gbar unter
https://www.wiwo.de/politik/deutschland/mittelstandspraesident-ohoven-viele-bewerber-beherrschen-
nicht-einmal-die-grundrechenarten/24326632.html, zuletzt abgerufen am 06.08.2019.
Knobloch, Tobias (2018): Vor die Lage kommen: Predictive Policing in Deutschland. Chancen und Gefahren 
datenanalytischer Prognosetechnik und Empfehlungen f&#252;r den Einsatz in der Polizeiarbeit. Hg. v. 
Stiftung Neue Verantwortung e. V. und Bertelsmann Stiftung. Berlin. Online verf&#252;gbar unter
https://www.bertelsmann-
stiftung.de/fileadmin/files/BSt/Publikationen/GrauePublikationen/predictive.policing.pdf, zuletzt 
abgerufen am 17.07.2020.
Kodiyan, Akhil Alfons (2019): An overview of ethical issues in using AI systems in hiring with a case study of
Amazon&#8217;s AI based hiring tool. Online verf&#252;gbar unter
https://www.researchgate.net/profile/Akhil_Kodiyan/publication/337331539_An_overview_of_ethical_i 
ssues_in_using_AI_systems_in_hiring_with_a_case_study_of_Amazon's_AI_based_hiring_tool/links/5 
dd2aa8d4585156b351d330a/An-overview-of-ethical-issues-in-using-AI-systems-in-hiring-with-a-case-
study-of-Amazons-AI-based-hiring-tool.pdf, zuletzt abgerufen am 04.08.2020.
Kohl, Ann-Kathrin; Pfretzschner, Frederik: Logistikmonitor 2018. Der Wirtschaftszweig in Zahlen. Ergebnisse
einer Expertenbefragung von Statista und der Bundesvereinigung Logistik (BVL) e. V. Hg. v. 
Bundesvereinigung Logistik e. V. und Statista. Online verf&#252;gbar unter
https://www.bvl.de/files/1951/1988/2128/Logistikmonitor_2018_-
_Der_Wirtschaftszweig_in_Zahlen.pdf, zuletzt abgerufen am 24.07.2020.
Kolleck, Alma; Orwat, Carsten (erscheint voraussichtlich Ende 2020): M&#246;gliche Diskriminierung durch 
algorithmische Entscheidungssysteme und maschinelles Lernen &#8211; ein &#220;berblick. Hg. v. B&#252;ro f&#252;r
Technikfolgen-Absch&#228;tzung beim Deutschen Bundestag (TAB-Hintergrundpapier, Nr. 24).
Kongsberg Maritime: Autonomous ship project, key facts about Yara Birkeland. The world&#180;s first zero
emission, autonomous container feeder. Online verf&#252;gbar unter
https://www.kongsberg.com/maritime/support/themes/autonomous-ship-project-key-facts-about-yara-
birkeland/, zuletzt abgerufen am 05.08.2020.
Konrad-Adenauer-Stiftung (2018): Vergleich nationaler Strategien zur F&#246;rderung von K&#252;nstlicher
Intelligenz &#8211; Teil 1. Online verf&#252;gbar unter
https://www.kas.de/documents/252038/3346186/Vergleich+nationaler+Strategien+zur+F%C3%B6rderu 
ng+von+K%C3%BCnstlicher+Intelligenz.pdf/46c08ac2-8a19-9029-6e6
ec5a43e751556?version=1.0&amp;t=1559905070357, zuletzt abgerufen am 13.07.2020.
Konrad-Adenauer-Stiftung (2019): Bewertung der deutschen KI-Strategie &#8211; Teil 3. Online verf&#252;gbar unter
https://www.kas.de/documents/252038/4521287/Bewertung+der+deutschen+KI-
Strategie+Teil+3.pdf/aa0ecb4e-3a71-de71-63ba-fb08bf72dd57?version=1.1&amp;t=1559810781469, zuletzt
abgerufen am 13.07.2020.
Konrad-Adenauer-Stiftung (2019): Vergleich nationaler Strategien zur F&#246;rderung von K&#252;nstlicher
Intelligenz &#8211; Teil 2. Online verf&#252;gbar unter
https://www.kas.de/documents/252038/4521287/K%C3%BCnstliche+Intelligenz+Internationaler+Vergl 
eich+Teil+2.pdf/16c82d12-898c-259b-c352-931a635fcfb3?version=1.1&amp;t=1560420028147, zuletzt
abgerufen am 13.07.2020.
Kornwachs, Klaus (2018): Arbeit 4.0 &#8211; People Analytics &#8211; F&#252;hrungsinformationssysteme. Soziologische, 
psychologische, wissenschaftsphilosophisch &#8211; ethische &#220;berlegungen zum Einsatz von Big Data in 
Personalmanagement und Personalf&#252;hrung. Gutachten im Rahmen des Projekts ABIDA &#8211; Assessing Big
Data. Online verf&#252;gbar unter https://www.abida.de/sites/default/files/Gutachten_Arbeit.pdf, zuletzt 
abgerufen am 05.08.2020.
Korte, Andrea (2020): Facial-Recognition Technology Cannot Read Emotions, Scientists Say. Hg. v. AAAS
American Association for the Advancement of Science. Online verf&#252;gbar unter
https://www.aaas.org/news/facial-recognition-technology-cannot-read-emotions-scientists-say, zuletzt 
abgerufen am 05.08.2020.
Kowalewsky, Reinhard (2018): K&#252;nstliche Intelligenz soll Suizide in NRW-Gef&#228;ngnissen stoppen. Justiz. 
In: rp-online.de, 04. Dezember 2018. Online verf&#252;gbar unter https://rp-
online.de/nrw/landespolitik/kuenstliche-intelligenz-soll-in-nrw-gefaengnisse-
selbstmordeverhindern_aid-34905457, zuletzt abgerufen am 17.07.2020.
Kozyreva, Anastasia; Herzog, Stefan; Lorenz-Spreen, Philipp; Hertwig, Ralph; Lewandowsky, Stephan (2020):
Artificial intelligence in online environments: Representative survey of public attitudes in Germany.
Krafft, Tobias D.; Gamer, Michael; Zweig, Katharina A.: What did you see? A study to measure
personalization in Google&#8217;s search engine (8). Online verf&#252;gbar unter
https://link.springer.com/content/pdf/10.1140/epjds/s13688-019-0217-5.pdf, zuletzt abgerufen am
05.08.2020.
Krafft, Tobias D.; Zweig, Katharina A. (2019): Transparenz und Nachvollziehbarkeit algorithmenbasierter
Entscheidungssysteme. Ein Regulierungsvorschlag aus sozioinformatischer Perspektive. 
Hg. v. Verbraucherzentrale Bundesverband e. V. Team Digitales und Medien. Berlin. Online verf&#252;gbar
unter https://www.vzbv.de/sites/default/files/downloads/2019/05/02/19-01-
22_zweig_krafft_transparenz_adm-neu.pdf, zuletzt abgerufen am 06.08.2020.
Kr&#228;hling, Christian (2014): Behandeln Sie die Amazon-Mitarbeiter/innen fair! Hg. v. ver.di. Online verf&#252;gbar
unter https://www.verdi.de/themen/geld-tarif/amazon/++co++217910b4-68ca-11e4-a52a-5254008a33df, 
zuletzt abgerufen am 15.07.2020.
Kr&#228;mer, Elmer (2017): Digitale Augen. Grenzen und Chancen der &#220;berwachungstechnik. Deutschlandfunk 
Kultur, 07. Dezember 2017. Online verf&#252;gbar unter https://www.deutschlandfunkkultur.de/grenzen-und-
chancen-der-ueberwachungstechnik-digitale-augen.976.de.html?dram:article_id=402603, zuletzt
abgerufen am 17.07.2020.
Kremp, Mathias (2018): Dieser Nachrichtensprecher kommt aus dem Computer. In: spiegel.de, 09. November
2018. Online verf&#252;gbar unter https://www.spiegel.de/netzwelt/gadgets/xinhua-dieser-
nachrichtensprecher-kommt-aus-dem-computer-a-1237685.html, zuletzt abgerufen am 13.07.2020.
Krempl, Stefan (2018): CCC: Bundespolizei hat Bericht zur Gesichtserkennung absichtlich gesch&#246;nt. 
Hg. v. heise.de. Online verf&#252;gbar unter https://www.heise.de/newsticker/meldung/CCC-Bundespolizei-
hat-Bericht-zur-Gesichtserkennung-absichtlich-geschoent-4191216.html, zuletzt aktualisiert am
15.10.2018, zuletzt abgerufen am 17.07.2020.
Krempl, Stefan (2019): Starcraft 2: Verbesserte DeepMind-KI schl&#228;gt 99,8 % der menschlichen Spieler.
Hg. v. heise.de. Online verf&#252;gbar unter https://www.heise.de/newsticker/meldung/Starcraft-2-
Verbesserte-DeepMind-KI-schlaegt-99-8-der-menschlichen-Spieler-4572734.html, zuletzt aktualisiert
am 30.10.2019, zuletzt abgerufen am 15.07.2020.
Krempl, Stefan (2019): Grenz&#252;berwachung: Roboterforscher warnt vor EU-Drohnenprojekt Roborder. 
Hg. v. heise.de. Online verf&#252;gbar unter https://www.heise.de/newsticker/meldung/Grenzueberwachung-
Roboterforscher-warnt-vor-EU-Drohnenprojekt-Roborder-4421224.html, zuletzt aktualisiert am
13.05.2019, zuletzt abgerufen am 17.07.2020.
Kretschmann, Lutz; Burmeister, Hans-Christoph; Jahn, Carlos (2017): Analyzing the economic benefit of
unmanned autonomous ships: An exploratory cost-comparison between an autonomous and a
conventional bulk carrier. In: Research in Transportation Business &amp; Management 25, S. 76&#8211;86. 
Kreutzer, Tobias (2014): Studie zu sozialen Medien &#8211; Auch im Netz regiert die Schweigespirale. In: faz.net, 
26. August 2014. Online verf&#252;gbar unter https://www.faz.net/aktuell/feuilleton/medien/studie-auch-im-
netz-regiert-die-schweigespirale-13118570.html?service=printPreview, zuletzt abgerufen am
29.07.2020.
Kr&#252;ger, Uwe (2019): Meinungsmacht. Der Einfluss von Eliten auf Leitmedien und Alpha-Journalisten &#8211; eine 
kritische Netzwerkanalyse. 2., &#252;berarbeitete und erweiterte Auflage (Reihe des Europ&#228;ischen Instituts f&#252;r
Journalismus- und Kommunikationsforschung (EIJK)).
Krumm Stephan; Dwertmann, Anne (2019): Perspektiven der KI in der Medizin. In: Volker Wittpahl (Hg.): 
K&#252;nstliche Intelligenz. Berlin, Heidelberg: Springer Berlin Heidelberg, S. 161&#8211;175.
K&#252;hl, Eike (2017): KI will rock you. In: Zeit.de, 26. Dezember 2017. Online verf&#252;gbar unter
https://www.zeit.de/digital/internet/2017-12/kuenstliche-intelligenz-musik-produktion-melodrive.
Kuhlmann, Martin; Splett, Barbara; Wiegrefe, Sascha (2018): Montagearbeit 4.0 ? Eine Fallstudie zu 
Arbeitswirkungen und Gestaltungsperspektiven digitaler Werkerf&#252;hrung. In: Wirtschafts- und 
Sozialwissenschaftliches Institut (WSI-Mitteilungen) 71 (3), S. 182&#8211;188. 
Kulp, Scott A.; Strauss, Benjamin H. (2019): New elevation data triple estimates of global vulnerability to
sealevel rise and coastal flooding. In: Nature communications 10 (1), S. 4844.
Kwong, Brian M.; McPherson, Sean M.; Shibata, Jonathan F. A.; Zee, Oliver T. (2012): Facebook: Data
Mining the World&#8217;s Largest Focus Group. In: Graziadio Business Review, 2012. Online verf&#252;gbar unter
https://gbr.pepperdine.edu/2012/11/facebook-data-mining-the-worlds-largest-focus-group/, zuletzt
abgerufen am 28.07.2020.
La Monica, Paul R. (2019): Uber and Lyft both hit all-time lows and continue to struggle since their IPOs. In:
edition.cnn.com, 05. September 2019. Online verf&#252;gbar unter
https://edition.cnn.com/2019/09/04/investing/uber-lyft-ipo-market/index.html, zuletzt abgerufen am
27.07.2020.
Lange, Steffen; Santarius, Tilman (2018): Smarte gr&#252;ne Welt? Digitalisierung zwischen &#220;berwachung, 
Konsum und Nachhaltigkeit. M&#252;nchen: oekom verlag.
Larson, Selena (2020): How a chatbot is helping homeless people find housing. A bot will optimize
applications. Hg. v. dailydot.com. Online verf&#252;gbar unter https://www.dailydot.com/debug/chat-bot-
housing-donotpay/, zuletzt aktualisiert am 29.02.2020, zuletzt abgerufen am 13.07.2020.
Lauber-R&#246;nsberg, Anne (2019): Autonome &#8222;Sch&#246;pfung&#8220; &#8211; Urheberschaft und Schutzf&#228;higkeit. In:
Gewerblicher Rechtschutz und Urheberrecht (3), S. 244&#8211;253.
Lecher, Colin (2019): How Amazon automatically tracks and fires warehouse workers for &#8216;productivity&#8217;. 
Documents show how the company tracks and terminates workers. Hg. v. The Verge. Online verf&#252;gbar
unter https://www.theverge.com/2019/4/25/18516004/amazon-warehouse-fulfillment-centers-
productivity-firing-terminations, zuletzt abgerufen am 15.07.2020.
Lee, Jane Lanhee (2019): U.S. vertical farms are racing against the sun. In: Reuters.com, 05. Juli 2019. Online
verf&#252;gbar unter https://www.reuters.com/article/us-vertical-farms-growth/u-s-vertical-farms-are-racing-
against-the-sun-idUSKCN1U010H, zuletzt abgerufen am 23.07.2020.
Lee, John D.; See, Katrina A. (2004): Trust in automation: designing for appropriate reliance. In: Human 
factors 46 (1), S. 50&#8211;80.
Leibniz-Institut f&#252;r Wirtschaftsforschung an der Universit&#228;t M&#252;nchen e. V. und Randstad Gruppe Deutschland 
(2019): Randstad-ifo Personalleiterbefragung. Ergebnisse: 1. Quartal 2019. Online verf&#252;gbar unter
https://www.randstad.de/s3fs-media/de/public/2020-06/randstad-ifo-berichtsband_q1-2019.pdf, zuletzt
abgerufen am 05.08.2020.
Lenzen, Manuela (2019): Open AI warnt vor GPT-2: Supertrolle am Start. In: faz.net, 19. Februar 2019. Online
verf&#252;gbar unter https://www.faz.net/aktuell/feuilleton/debatten/open-ai-warnt-vor-der-eigenen-
entwicklung-gpt-2-16047940.html#void, zuletzt abgerufen am 30.07.2020.
Lewis, Paul; McCormick, Erin (2018): How an ex-YouTube insider investigated its secret algorithm. In: The
Guardian, 02. Februar 2018. Online verf&#252;gbar unter
https://www.theguardian.com/technology/2018/feb/02/youtube-algorithm-election-clinton-trump-
guillaume-chaslot, zuletzt abgerufen am 31.07.2020.
Linke, David (2019): Urheberrechtlicher Schutz von &#8222;KI&#8220; als Computerprogramme &#8211; Squeezing today&#180;s
innovations into yesterday&#180;s system? In: Sven Hetmank und Constantin Rechenberg (Hg.):
Kommunikation, Kreation und Innovation &#8211; Recht im Umbruch?: Nomos Verlagsgesellschaft mbH &amp;
Co. KG, S. 29&#8211;48.
Linke, Norbert (2006): Presse- und Radiokodex. Hg. v. Bundeszentrale f&#252;r politische Bildung. Online
verf&#252;gbar unter https://www.bpb.de/74594/presse-und-radiokodex, zuletzt aktualisiert am 07.01.2006, 
zuletzt abgerufen am 29.07.2020.
Lischka, Konrad; Klingel, Anita; Bertelsmann Stiftung (2017): Wenn Maschinen Menschen bewerten. 
Internationale Fallbeispiele f&#252;r Prozesse algorithmischer Entscheidungsfindung. Arbeitspapier. Hg. v. 
Bertelsmann Stiftung. G&#252;tersloh (Impuls Algorithmenethik, #1). Online verf&#252;gbar unter
https://algorithmenethik.de/wp-content/uploads/sites/10/2018/02/ADM-Fallstudien-1.pdf, zuletzt
abgerufen am 06.08.2020.
Lischka, Konrad; St&#246;cker, Christian (2017): Digitale &#214;ffentlichkeit: Schauen wir den Algorithmen auf die
Finger. Hg. v. Bertelsmann Stiftung. Online verf&#252;gbar unter
https://algorithmenethik.de/2017/07/20/digitale-oeffentlichkeit/, zuletzt aktualisiert am 20.07.2017,
zuletzt abgerufen am 04.08.2020.
Litman, Todd (2017): Autonomous Vehicle Implementation Predictions. Implications for Transport Planning. 
Victoria Transport Policy Institute. Online verf&#252;gbar unter
https://orfe.princeton.edu/~alaink/SmartDrivingCars/PDFs/VIctoriaTransportAV_Predictionsavip.pdf, 
zuletzt abgerufen am 28.07.2020.
Littmann, J&#246;rg (2017): 31a SGB X. In: Karl Hauck, Wolfgang Noftz und Peter Becker: Hauck/Noftz Modul
SGB X: Verwaltungsverfahren, Schutz der Sozialdaten, Zusammenarbeit der Leistungstr&#228;ger und ihre
Beziehungen zu Dritten &#8211; Jahresabonnement. SGBdigital &#8211; Fachwissen Sozialrecht. Berlin: Schmidt,
Erich.
Liu, Jiahui; Dolan, Peter; Pedersen, Elin R&#248;nby (2010): Personalized news recommendation based on click 
behavior. In: Charles Rich, Qiang Yang, Marc Cavazza und Michelle Zhou (Hg.): Proceedings of the
15th international conference on Intelligent user interfaces &#8211; IUI '10. the 15th international conference. 
Hong Kong, China, 07.02.2010 &#8211; 10.02.2010. New York, New York, USA: ACM Press, S. 31.
Lobe, Adrian (2019): KI ist alles andere als gr&#252;n. Hg. v. spektrum.de. Online verf&#252;gbar unter
https://www.spektrum.de/news/kuenstliche-intelligenz-verbraucht-fuer-den-lernprozess-unvorstellbar-
viel-energie/1660246, zuletzt abgerufen am 07.08.2020.
Lobig, A.; Liedtke, G.; Lischke, A.; Wolfermann, A.; Kn&#246;rr, W. (2016): Verkehrsverlagerungspotenzial auf
den Schieneng&#252;terverkehr in Deutschland. Im Rahmen der Wissenschaftlichen Begleitung, 
Unterst&#252;tzung und Beratung des BMVI in den Bereichen Verkehr und Mobilit&#228;t mit besonderem Fokus
auf Kraftstoffen und Antriebstechnologien sowie Energie und Klima. Endbericht. Unter Mitarbeit von 
Institut f&#252;r Energie- und Umweltforschung Heidelberg GmbH, Ludwig-B&#246;lke-Systemtechnik GmbH und 
Deutsches Biomasseforschungszentrum gGmbH. Hg. v. Bundesministerium f&#252;r Verkehr und digitale
Infrastruktur. Deutsches Zentrum f&#252;r Luft- und Raumfahrt e. V. Online verf&#252;gbar unter
https://www.bmvi.de/SharedDocs/DE/Anlage/G/MKS/studie-verkehrsverlagerungspotenzial-
schienengueterverkehr.pdf?__blob=publicationFile, zuletzt abgerufen am 23.07.2020.
Lobo, Sascha (2016): Leben im Datenstrom. Bequemlichkeit schl&#228;gt Datensparsamkeit. In: spiegel.de, 
28. September 2016. Online verf&#252;gbar unter https://www.spiegel.de/netzwelt/web/zugriff-auf-daten-
bequemlichkeit-schlaegt-sicherheit-kolumne-a-1114091.html, zuletzt abgerufen am 10.07.2020.
Lockwood, Freya; Kent, Tim; Paul, Justin; Shenoi, Ajit; Westgarth, Richard; O&#180;Dell, Mark et al. (2017):
Global Marine Technology Trends 2030. Autonomous Maritime Systems. Hg. v. Lloyd&#8217;s Register Group 
Ltd, QinetiQ und University of Southampton. Online verf&#252;gbar unter
https://www.lr.org/en/insights/global-marine-trends-2030/technology-trends/, zuletzt abgerufen am
24.07.2020.
Lohr, Steve (2019): Google Antitrust Investigation Outlined by State Attorneys General. In: The New York 
Times, 09. September 2019. Online verf&#252;gbar unter
https://www.nytimes.com/2019/09/09/technology/google-antitrust-investigation.html, zuletzt abgerufen 
am 04.08.2020.
L&#246;hr, Julia; Wieduwilt, Hendrik (2019): FDP und CDU werben f&#252;r europ&#228;ische Cloud-L&#246;sungen. In: faz.net, 
20. Juli 2019. Online verf&#252;gbar unter https://www.faz.net/aktuell/wirtschaft/digitec/fdp-und-cdu-werben-
fuer-europaeische-cloud-loesungen-16293571.html, zuletzt abgerufen am 27.07.2020.
Loos, Alexander (2019): K&#252;nstliche Intelligenz unterst&#252;tzt den Artenschutz. Hg. v. wissenschaftsjahr.de. 
Online verf&#252;gbar unter https://www.wissenschaftsjahr.de/2019/neues-aus-der-wissenschaft/das-sagt-die-
wissenschaft/kuenstliche-intelligenz-unterstuetzt-den-artenschutz, zuletzt abgerufen am 07.08.2020.
Lossau, Norbert (2018): Wie K&#252;nstliche Intelligenz die Medien ver&#228;ndert. Hg. v. Konrad-Adenauer-
Stiftung e. V. Sankt Augustin/Berlin (Analysen und Argumente, 318). Online verf&#252;gbar unter
https://www.kas.de/documents/252038/3346186/Wie+k%C3%BCnstliche+Intelligenz+die+Medien+ver 
%C3%A4ndert.pdf/442f9873-a792-8e4d-cff3-3f2c5e59c9bb?version=1.0&amp;t=1543223168579, zuletzt
abgerufen am 29.07.2020.
Lossau, Norbert (2020): Deep Fake: Gefahren, Herausforderungen und L&#246;sungswege. Hg. v. Konrad-
Adenauer-Stiftung e. V. Berlin (Analysen &amp; Argumente, 382). Online verf&#252;gbar unter
https://www.kas.de/documents/252038/7995358/AA382+Deep+Fake.pdf/de479a86-ee42-2a9a-e038-
e18c208b93ac?version=1.0&amp;t=1581576967612, zuletzt abgerufen am 30.07.2020.
Lu, Yiting; Mamhoud, Marwa; Robinson, Peter (2017): Estimating Sheep Pain Level Using Facial Action Unit
Detection. Hg. v. Institute of Electrical and Electronics Engineers (2017 12th IEEE International
Conference on Automatic Face &amp; Gesture Recognition (FG 2017)). Online verf&#252;gbar unter
https://www.cl.cam.ac.uk/~pr10/publications/fg17.pdf, zuletzt abgerufen am 23.07.2020.
Lueken, Verena (2019): Kunstwerk ohne Rechte. In: faz.net 2019, 15. Juli 2019. Online verf&#252;gbar unter
https://www.faz.net/aktuell/feuilleton/kino/roboter-jan-bot-produziert-kunstwerke-ohne-rechte-
16284676.html, zuletzt abgerufen am 15.07.2020.
Lukowicz, Paul (2020): App-basierte Analyse und Kommunikation in Zeiten von Covid-19. Hg. v. Deutsches
Forschungszentrum f&#252;r K&#252;nstliche Intelligenz. Online verf&#252;gbar unter
https://www.dfki.de/web/news/detail/News/sis-app/, zuletzt abgerufen am 18.09.2020.
Lumb, David (2017): Immigration chat bot now helps you apply for a green card. The Facebook
Messengerbased AI, Visabot, will walk users through applying for the resident status. Hg. v. engadget.com. Online
verf&#252;gbar unter https://www.engadget.com/2017/07/11/immigration-chat-bot-now-helps-you-apply-for-
a-green-card/?guccounter=1, zuletzt abgerufen am 14.07.2020.
Luthe, Ernst-Wilhelm (2017): Der vollst&#228;ndig automatisierte Erlass eines Verwaltungsakts nach &#167; 31a SGB X. 
In: Die Sozialgerichtsbarkeit Zeitschrift f&#252;r das aktuelle Sozialrecht (05), S. 250&#8211;258.
Madiega, Tambiama (2019): EU-Leitlinien zur Ethik in der KI. Hg. v. Europ&#228;isches Parlament. Online
verf&#252;gbar unter
https://www.europarl.europa.eu/RegData/etudes/BRIE/2019/640163/EPRS_BRI(2019)640163_EN.pdf, 
zuletzt abgerufen am 04.08.2020.
Mainzer, Sebastian: Filmproduktion: Schritt f&#252;r Schritt in die Cloud. Online verf&#252;gbar unter
https://www.palmerhargreaves.de/blog/filmproduktion-schritt-fuer-schritt-in-die-cloud, zuletzt 
abgerufen am 15.07.2020.
Mangelsdorf, Axel (2019): Normen und Standards in der KI. In: Volker Wittpahl (Hg.): K&#252;nstliche Intelligenz. 
Technologie. Berlin, Heidelberg: Springer Berlin Heidelberg.
Marcus, Gary F.; Davis, Ernest (2019): Rebooting AI. Building artificial intelligence we can trust. New York: 
Pantheon Books.
Mar&#233;chal, Nathalie; Biddle, Ellery Roberts (2020): It's Not Just the Content, It's the Business Model:
Democracy&#8217;s Online Speech Challenge. Hg. v. New America. Online verf&#252;gbar unter
https://d1y8sb8igg2f8e.cloudfront.net/documents/REAL_FINAL-
Its_Not_Just_the_Content_Its_the_Business_Model.pdf, zuletzt abgerufen am 04.08.2020.
Marscheider-Weidemann, Frank; Langkau, Sabine; Hummen, Torsten; Erdmann, Lorenz; Tercero Espinoza, 
Luis Alberto; Angerer, Gerhard et al. (2016): Rohstoffe f&#252;r Zukunftstechnologien 2016. Auftragsstudie. 
Hannover: DERA (DERA Rohstoffinformationen, 28). Online verf&#252;gbar unter https://www.deutsche-
rohstoffagentur.de/DERA/DE/Downloads/Studie_Zukunftstechnologien-
2016.pdf?__blob=publicationFile&amp;v=5, zuletzt abgerufen am 04.08.2020.
Marshall, Andrew; Rojas, Raul; Stokes, Jay; Brinkman, Donald (2018): Securing the Future of Artificial
Intelligence and Machine Learning at Microsoft. Online verf&#252;gbar unter https://docs.microsoft.com/en-
us/security/engineering/securing-artificial-intelligence-machine-learning, zuletzt abgerufen am
23.07.2020.
Martini, Mario (2019): Blackbox Algorithmus &#8211; Grundfragen einer Regulierung K&#252;nstlicher Intelligenz. 1st ed. 
2019: Springer Berlin Heidelberg.
Martini, Mario; Botta, Jonas; Nink, David; Kolain, Michael; Bertelsmann Stiftung (2020): Automatisch 
erlaubt? F&#252;nf Anwendungsf&#228;lle algorithmischer Systeme auf dem juristischen Pr&#252;fstand. 
Hg. v. Bertelsmann Stiftung. Berlin (Impuls Algorithmenethik, #11). Online verf&#252;gbar unter
https://www.bertelsmann-
stiftung.de/fileadmin/files/BSt/Publikationen/GrauePublikationen/Automatisch_erlaubt_final.pdf, zuletzt 
abgerufen am 06.08.2020.
Martini, Mario; Nink, David (2017): Wenn Maschinen entscheiden &#8230; Pers&#246;nlichkeitsschutz in 
vollautomatisierten Verwaltungsverfahren. In: NVwZ (10), S. 681&#8211;682.
Mathur, Natasha (2018): Best game engines for Artificial Intelligence game development. Hg. v. 
hub.packthub.com. Online verf&#252;gbar unter https://hub.packtpub.com/best-game-engines-for-ai-game-
development/, zuletzt aktualisiert am 24.08.2018, zuletzt abgerufen am 15.07.2020.
Matsakis, Louise (2018): To Break a Hate-Speech Detection Algorithm, Try 'Love'. Companies like Facebook 
use artificial intelligence to try to detect hate speech, but new research proves it&#8217;s a daunting task.
Hg. v. Wired. Online verf&#252;gbar unter https://www.wired.com/story/break-hate-speech-algorithm-try-
love/, zuletzt aktualisiert am 26.09.2018, zuletzt abgerufen am 07.08.2018.
Matthes, Marie-Charlotte (2018): K&#252;nstliche Intelligenz in der Verwaltung. IFG-Beauftragte von Bund und 
L&#228;ndern fordern Transparenz. Hg. v. Netzpolitik.org. Online verf&#252;gbar unter
https://netzpolitik.org/2018/kuenstliche-intelligenz-in-der-verwaltung-ifg-beauftragte-von-bund-und-
laendern-fordern-transparenz/, zuletzt aktualisiert am 22.10.2018, zuletzt abgerufen am 20.07.2020.
Max-Planck-Institut f&#252;r Biogeochemie (2019): Mit k&#252;nstlicher Intelligenz das Erdsystem verstehen. Online
verf&#252;gbar unter https://www.bgc-
jena.mpg.de/www/index.php/PublicRelations/NewsSingle?userlang=de&amp;jahr=2019&amp;id=1550077032&amp;d 
isc=, zuletzt abgerufen am 07.08.2020.
Max-Planck-Institut f&#252;r Meteorologie (2019): K&#252;nstliche Intelligenz f&#252;r das Erdsystem. Online verf&#252;gbar unter
https://www.mpimet.mpg.de/kommunikation/aktuelles/single-news/news/kuenstliche-intelligenz-fuer-

daserdsystem/?tx_news_pi1%5Bcontroller%5D=News&amp;tx_news_pi1%5Baction%5D=detail&amp;cHash=bb13 
726de50f4130dad9a27104e747fe, zuletzt abgerufen am 07.08.2020.
Mayer, Roger C.; Davis, James H.; Schoorman, F. David (1995): An Integrative Model of Organizational
Trust. In: The Academy of Management Review 20 (3), S. 709&#8211;734.
Mayor of London (2020): Artificial intelligence to help fuel London&#8217;s cycling boom. Hg. v. Transport for
London. Online verf&#252;gbar unter https://tfl.gov.uk/info-for/media/press-releases/2020/january/artificial-
intelligence-to-help-fuel-london-s-cycling-boom, zuletzt abgerufen am 09.09.2020.
Maztat, Lorenz (2011): Datenjournalismus. Hg. v. Bundeszentrale f&#252;r politische Bildung. Online verf&#252;gbar
unter https://www.bpb.de/gesellschaft/digitales/opendata/64069/datenjournalismus, zuletzt aktualisiert
am 26.10.2011, zuletzt abgerufen am 30.07.2020.
Mazzucato, Mariana (2014): Das Kapital des Staates. Eine andere Geschichte von Innovation und Wachstum. 
M&#252;nchen: Verlag Antje Kunstmann.
Mazzucato, Mariana (2018): Mission-oriented research &amp; innovation in the European Union. A
problemsolving approach to fuel innovation-led growth. Luxembourg: Publications Office of the European 
Union (Missions).
McKinsey &amp; Company (2017): K&#252;nstliche Intelligenz im Handel &#8211; Appetit auf den Algorithmus. 
Hg. v. Handelsblatt.de. Online verf&#252;gbar unter https://www.handelsblatt.com/adv/smart-
mobility/kuenstliche-intelligenz-im-handel-appetit-auf-den-algorithmus/19955862-all.html, zuletzt 
abgerufen am 22.07.2020.
McKinsey &amp; Company (2017): Smartening up with Artificial Intelligence (AI) &#8211; What&#8217;s in it for Germany and
its Industrial Sector? Online verf&#252;gbar unter
https://www.mckinsey.com/~/media/McKinsey/Industries/Semiconductors/Our%20Insights/Smartening 
%20up%20with%20artificial%20intelligence/Smartening-up-with-artificial-intelligence.ashx, zuletzt 
abgerufen am 03.08.2020.
McKinsey Global Institute (2018): Notes from the AI frontier &#8211; Insights from hundreds of use cases. Online
verf&#252;gbar unter
https://www.mckinsey.com/~/media/McKinsey/Featured%20Insights/Artificial%20Intelligence/Notes% 
20from%20the%20AI%20frontier%20Applications%20and%20value%20of%20deep%20learning/Notes 
-from-the-AI-frontier-Insights-from-hundreds-of-use-cases-Discussion-paper.ashx, zuletzt abgerufen am
20.07.2020.
Medinside Das Portal f&#252;r die Gesundheitsbranche (2018): Patienten von Medgate sprechen wohl k&#252;nftig mit
einem Chatbot. Online verf&#252;gbar unter https://www.medinside.ch/de/post/medgate-patienten-
interagieren-bald-mit-einem-chatbot, zuletzt aktualisiert am 21.11.2018, zuletzt abgerufen am
10.07.2020.
Medizin und Technik (2017): August der Smarte hilft in der Altenpflege. Online verf&#252;gbar unter
https://medizin-und-technik.industrie.de/technik/forschung/august-der-smarte-hilft-in-der-altenpflege/,
zuletzt aktualisiert am 26.07.2017, zuletzt abgerufen am 10.07.2020.
Menzel, Christoph; Winkler, Christian (2018): Zur Diskussion der Effekte K&#252;nstlicher Intelligenz in der
wirtschaftswissenschaftlichen Literatur. Hg. v. Bundesministerium f&#252;r Wirtschaft und Energie
(Diskussionspapier, Nr. 8). Online verf&#252;gbar unter
https://www.bmwi.de/Redaktion/DE/Downloads/Diskussionspapiere/20190205-diskussionspapier-
effekte-kuenstlicher-intelligenz-in-der-wirtschaftswissenschaftlichen-
literatur.pdf?__blob=publicationFile&amp;v=6, zuletzt abgerufen am 05.08.2020.
Mertens, Jannik (2018): EU und Berlin planen mehr Gesichtserkennung in polizeilich genutzten Datenbanken.
Hg. v. Netzpolitik.org. Online verf&#252;gbar unter https://netzpolitik.org/2018/eu-und-berlin-planen-mehr-
gesichtserkennung-in-polizeilich-genutzten-datenbanken, zuletzt aktualisiert am 12.10.2018, zuletzt
abgerufen am 17.07.2020.
Metzinger, Thomas (2019): Nehmt der Industrie die Ethik weg! In: tagesspiegel.de, 08. April 2019. Online
verf&#252;gbar unter https://www.tagesspiegel.de/politik/eu-ethikrichtlinien-fuer-kuenstliche-intelligenz-
nehmt-der-industrie-die-ethik-weg/24195388.html, zuletzt abgerufen am 13.07.2020.
Microsoft; PricewaterhouseCoopers (2019): How AI can enable a Sustainable Future. Online verf&#252;gbar unter
https://www.pwc.co.uk/sustainability-climate-change/assets/pdf/how-ai-can-enable-a-sustainable-
future.pdf, zuletzt abgerufen am 27.07.2020.
Miller, R. A. (1994): Medical diagnostic decision support systems--past, present, and future: a threaded 
bibliography and brief commentary. In: Journal of the American Medical Informatics Association :
JAMIA 1 (1), S. 8&#8211;27. 
Mitchell, Tom; Brynjolfsson, Erik (2017): Track how technology is transforming work. In: Nature 544 (7650), 
S. 290&#8211;292.
Mitchell, Tom M.: The Need for Biases in Learning Generalizations. Online verf&#252;gbar unter
http://dml.cs.byu.edu/~cgc/docs/mldm_tools/Reading/Need%20for%20Bias.pdf, zuletzt abgerufen am
04.08.2020.
Mitchell, William J. (1995): City of bits. Space, place, and the infobahn. 7. print. Cambridge, Mass.: MIT
Press.
mm1 (2019): DAX 30 Startup- und Innovationsmonitor: Update 2019. Online verf&#252;gbar unter
https://mm1.com/ch/ueber-uns/aktuelle-publikationen/studie-dax-30-startup-und-innovationsmonitor-
update-2019/, zuletzt abgerufen am 22.07.2020.
MMC Ventures (2019): The State of AI: Divergence. Online verf&#252;gbar unter https://www.stateofai2019.com/, 
zuletzt abgerufen am 21.07.2020.
Mobile-Tech: Duolingo f&#252;r Schulen. Eine Schritt-f&#252;r-Schritt-Anleitung (Mobile-Tech Project, 2015-1-ES01-
KA202-015903). Online verf&#252;gbar unter http://www.mobile-tech.eu/wp-
content/uploads/2017/03/4.2.2_Duoling-Tutorial_GE.pdf, zuletzt abgerufen am 16.07.2020.
Mohr, Thorsten (2019): BMBF-F&#246;rderung: &#8222;Intelligenter&#8220; Stift soll Erlernen der Rechtschreibung unterst&#252;tzen. 
Hg. v. idw - Informationsdienst Wissenschaft Universit&#228;t des Saarlandes. Online verf&#252;gbar unter
https://idw-online.de/en/news?print=1&amp;id=723790, zuletzt abgerufen am 16.07.2020.
Monroy, Matthias (2018): &#8222;Gemeinsamer Identit&#228;tsspeicher&#8220;: Biometrische Daten landen in europ&#228;ischem
Datentopf. Hg. v. Netzpolitik.org. Online verf&#252;gbar unter https://netzpolitik.org/2018/gemeinsamer-
identitaetsspeicher-biometrische-daten-landen-in-europaeischem-datentopf, zuletzt aktualisiert am
26.06.2018, zuletzt abgerufen am 17.07.2020.
Montero, Anna (2018): IBM and Medgate creating chatbot to diagnose your aches and pains. Hg. v. 
CNNMoney Switzerland. Online verf&#252;gbar unter https://www.youtube.com/watch?v=P16d1ukZuXs, 
zuletzt abgerufen am 27.08.2020.
Moore, Samuel K. (2020): Huge chip smashes deep learning's speed barrier. In: IEEE Spectr. 57 (1), S. 24&#8211;27.
Moorstedt, Michael (2019): Algorithmen f&#252;r die Filmbranche &#8211; Chris Hemsworth + Scarlett Johansson +
Action = $$$. In: sueddeutsche.de 2019, 28. August 2019. Online verf&#252;gbar unter
https://www.sueddeutsche.de/digital/algorithmen-kinohits-filmbranche-studie-ki-1.4574935, zuletzt
abgerufen am 15.07.2020.
Morgeson, Frederick, P.; Campion, Michael A.; Dipboye, Robert L.; Hollenbeck, John R.; Murphy, Kevin;
Schmitt, Neal (2007): Reconsidering the Use of Personality Tests in Personnel Selection Contexts. In:
Personnel Psychology 60 (3), S. 683&#8211;729.
Morin, Antonia (2020): Wenn Computer komponieren. Hg. v. Bayerischer Rundfunk. Online verf&#252;gbar unter
https://www.br-klassik.de/aktuell/news-kritik/musik-kuenstliche-intelligenz-computer-100.html, zuletzt
aktualisiert am 05.03.2020, zuletzt abgerufen am 14.07.2020.
Moses, Lucia (2019): Immer weniger Interesse an Werbung: So will die Industrie mit KI k&#252;nftig 
Bannerblindheit bek&#228;mpfen. Hg. v. businessinsider.de. Online verf&#252;gbar unter
https://www.businessinsider.de/tech/ki-wie-unternehmen-mit-werbung-kuenftig-produkte-verkaufen-
wollen-2019-8/, zuletzt aktualisiert am 11.08.2019, zuletzt abgerufen am 29.07.2020.
moviepilot.de: Die besten Filme &#8211; K&#252;nstliche Intelligenz. Online verf&#252;gbar unter
https://www.moviepilot.de/filme/beste/handlung-kunstliche-intelligenz, zuletzt abgerufen am
14.07.2020.
Muir, Bonnie M. (1994): Trust in automation: Part I. Theoretical issues in the study of trust and human 
intervention in automated systems. In: Ergonomics 37 (11), S. 1905&#8211;1922.
M&#252;ller, Lena-Sophie; Andersen, Nicolai (2017): Denkimpuls Digitale Ethik. Warum wir uns mit Digitaler
Ethik besch&#228;ftigen sollten &#8211; Ein Denkmuster. Unter Mitarbeit von Julian Blohmke, Sebastian Heil und
Thomas Langkabel. Hg. v. Initiative D21. Online verf&#252;gbar unter
https://initiatived21.de/app/uploads/2017/08/01-2_denkimpulse_ag-ethik_digitale-ethik-ein-
denkmuster_final.pdf, zuletzt abgerufen am 20.08.2020.
M&#252;ller, Martin U. (2019): Plaudernd zum Job. Unternehmen w&#228;hlen Personal zunehmend mithilfe von 
Software aus. K&#252;nstliche Intelligenz soll anhand der Stimme &#252;ber die Bewerber entscheiden. Ist das
seri&#246;s? In: Der Spiegel, 12. Januar 2019 (3/2019), S. 66.
Mumtaz, Zain; Ullah, Saleem; Ilyas, Zeeshan; Aslam, Naila; Iqbal, Shahid; Liu, Shuo et al. (2018): An 
Automation System for Controlling Streetlights and Monitoring Objects Using Arduino. In: Sensors 18 
(10). 
Nahles, Andrea (2018): Die Tech-Riesen des Silicon Valleys gef&#228;hrden den fairen Wettbewerb. In:
Handelsblatt.com, 13. August 2018. Online verf&#252;gbar unter
https://www.handelsblatt.com/meinung/gastbeitraege/gastkommentar-die-tech-riesen-des-silicon-
valleys-gefaehrden-den-fairen-wettbewerb/22900656.html?ticket=ST-14380344-
2dCTTFda9NGxf3sVdKBg-ap5, zuletzt abgerufen am 27.07.2020.
Neckermann, Lukas (2018): smart cities, smart mobility. Transforming the way we live and work: Troubador
Publishing Ltd (Transport).
Nedelkoska, Ljubica; Quintini, Glenda (2018): Automation, skills use and training. Hg. v. OECD Publishing. 
Paris (OECD Social, Employment and Migration Working Papers, No. 202). Online verf&#252;gbar unter
https://www.oecd-ilibrary.org/docserver/2e2f4eea-
en.pdf?expires=1596716514&amp;id=id&amp;accname=guest&amp;checksum=DC3970B4E0BD6496B6B55FA451F 
12C08, zuletzt abgerufen am 06.08.2020.
Newcastle University (03.05.2017): Hand that sees offers new hope to amputees. Online verf&#252;gbar unter
https://www.ncl.ac.uk/press/articles/archive/2017/05/handthatsees/, zuletzt abgerufen am 09.07.2020.
Newman, Nic; Fletcher, Richard; Kalogeropoulos, Antonis (2019): Reuters Institute Digital News Report 2019. 
Hg. v. Reuters Institute for the Study of Journalism. Online verf&#252;gbar unter
https://reutersinstitute.politics.ox.ac.uk/sites/default/files/inline-files/DNR_2019_FINAL.pdf, zuletzt
abgerufen am 04.08.2020.
Nguyen, C. Thi (2020): Escape the echo chamber. Hg. v. Aeon Media Group Ltd. Online verf&#252;gbar unter
https://aeon.co/essays/why-its-as-hard-to-escape-an-echo-chamber-as-it-is-to-flee-a-cult, zuletzt 
aktualisiert am 09.04.2018, zuletzt abgerufen am 03.08.2020.
Nickel, Oliver (2019): Chinesische Lehrer &#252;berwachen Gehirnwellen ihrer Sch&#252;ler. Hg. v. Golem.de. Online
verf&#252;gbar unter https://www.golem.de/news/datenschutz-chinesische-lehrer-ueberwachen-gehirnwellen-
ihrer-schueler-1910-
144304.amp.html?t=&amp;__twitter_impression=true&amp;utm_source=D64+Ticker&amp;utm_campaign=07b142f8 
3c-EMAIL_CAMPAIGN_4_22_2018_COPY_01&amp;utm_medium=email&amp;utm_term=0_aa5ef144ff-
07b142f83c-64702577, zuletzt abgerufen am 06.08.2020.
Nida-R&#252;melin, Julian (2019): Medientage M&#252;nchen 2019 vom 23. bis 25. Oktober Zur Ethik der
Kommunikation in der digitalen Lebenswelt. &#8222;Wir brauchen ein &#246;ffentlich-rechtliches Google&#8220;. Hg. v. 
Medien.Bayern GmbH. Online verf&#252;gbar unter https://medientage.de/wp-
content/uploads/sites/9/2019/10/117_Keynote_Prof.-Dr.-Julian-Nida-R%C3%BCmelin.pdf, zuletzt
abgerufen am 03.08.2020.
Niiler, Eric (2019): Can AI be a fair judge in court? Estonia thinks so. Hg. v. arstechnica.com. Online verf&#252;gbar
unter https://arstechnica.com/tech-policy/2019/03/can-ai-be-a-fair-judge-in-court-estonia-thinks-
so/?comments=1, zuletzt aktualisiert am 30.03.2019, zuletzt abgerufen am 14.07.2020.
Niiler, Eric (2020): An AI Epidemiologist Sent the First Warnings of the Wuhan Virus. Hg. v. wired.com. 
Online verf&#252;gbar unter https://www.wired.com/story/ai-epidemiologist-wuhan-public-health-warnings/, 
zuletzt aktualisiert am 25.01.2020, zuletzt abgerufen am 18.09.2020.
Niklas, Jedrzej (2019): Polen: Regierung schafft umstrittenes Scoring-System f&#252;r Arbeitslose ab.
Hg. v. AlgorithmWatch. Online verf&#252;gbar unter https://algorithmwatch.org/story/polnische-regierung-
schafft-umstrittenes-scoring-system-fuer-arbeitslose-ab/, zuletzt abgerufen am 06.08.2020.
Ninnemann, Jan; Tesch, Torsten; Werner, Alena (2019): Digitalisierung in der Binnenschifffahrt. Perspektiven 
digitaler, datengetriebener Gesch&#228;ftsmodelle. Hg. v. Deutsches Zentrum f&#252;r innovative 
Binnenschifffahrt und MARIKO gemeinn&#252;tzige GmbH. Online verf&#252;gbar unter https://www.mariko-
leer.de/wp-content/uploads/2019/02/20190225-D-ZIB-Studie-Final.pdf, zuletzt abgerufen am
03.08.2020.
Nitsche, Nicole (2018): Alipay, WeChat &amp; UnionPay &#8211; Chinas Big Three. Hg. v. Payment &amp; Banking. Online
verf&#252;gbar unter https://paymentandbanking.com/alipay-wechat-unionpay-chinas-big-three, zuletzt
abgerufen am 23.07.2020.
Nobis, Claudia; Kuhnimhof, Tobias; Follmer, Robert; B&#228;umer, Marcus (2019): Mobilit&#228;t in Deutschland.
Zeitreihenbericht 2002 &#8211; 2008 &#8211; 2017. 1.1. Aufl. Hg. v. Bundesministerium f&#252;r Verkehr und digitale
Infrastruktur. infas Institut f&#252;r angewandte Sozialwissenschaft; Deutsches Zentrum f&#252;r Luft- und 
Raumfahrt e. V.; IVT Research GmbH; infas 360 GmbH. Online verf&#252;gbar unter
https://www.bmvi.de/SharedDocs/DE/Anlage/G/mid-zeitreihenbericht-2002-2008-
2017.pdf?__blob=publicationFile, zuletzt abgerufen am 23.07.2020.
Noble, Safiya Umoja (2018): Algorithms of oppression. How search engines reinforce racism. New York: New
York University Press. Online verf&#252;gbar unter
https://ebookcentral.proquest.com/lib/gbv/detail.action?docID=4834260.
Novak, Axel (2018): Smart City Moskau: Architektur der Vernetzung. Hg. v. Senkrechtstarter. Online
verf&#252;gbar unter https://senkrechtstarter-blog.de/2018/12/smart-city-moskau/, zuletzt aktualisiert am
10.12.2018, zuletzt abgerufen am 16.07.2020.
Nvidia (2018): Nvidia Tesla. One Platform. Unlimited Data Center Acceleration. Online verf&#252;gbar unter
https://images.nvidia.com/content/pdf/gpu-accelerated-server-platforms.pdf, zuletzt abgerufen am
07.08.2020.
Odell, Susannah (2016): Machine learning in the pharmaceutical industry. Hg. v. The Royal Society. Online
verf&#252;gbar unter https://blogs.royalsociety.org/in-verba/2016/10/05/machine-learning-in-the-
pharmaceutical-industry/, zuletzt abgerufen am 16.07.2020.
OECD (2001): Citizens as Partners. OECD Handbook on Information, Consultation and Public Participation in 
Policy-Making. Paris: Organisation for Economic Co-operation and Development. Online verf&#252;gbar
unter http://gbv.eblib.com/patron/FullRecord.aspx?p=533347.
OECD (2019): OECD-Grunds&#228;tze f&#252;r K&#252;nstliche Intelligenz. Online verf&#252;gbar unter
https://www.oecd.org/berlin/presse/Flyer_AIPrinciples_FINAL_GER.pdf, zuletzt abgerufen am
20.07.2020.
OECD Publishing (2015): Glossar. In: Frascati-Handbuch 2015: Leitlinien f&#252;r die Erhebung und Meldung von 
Daten &#252;ber Forschung und experimentelle Entwicklung, S. 433&#8211;455. Online verf&#252;gbar unter
https://read.oecd-ilibrary.org/science-and-technology/frascati-handbuch-2015/glossar_9789264291638-
17-de#page1, zuletzt abgerufen am 06.08.2020.
Oetker, Hartmut (2019): &#167; 249. Art und Umfang des Schadensersatzes. In: Franz J&#252;rgen S&#228;cker, Roland 
Rixecker, Hartmut Oetker, Bettina Limperg und Wolfgang Kr&#252;ger (Hg.): M&#252;nchener Kommentar zum
B&#252;rgerlichen Gesetzbuch, Bd. 2. Unter Mitarbeit von Gregor Bachmann, J&#252;rgen Basedow, Volker
Emmerich, Wolfgang Ernst, Thomas Finkenauer, Stefan Grundmann et al. 8. Auflage. M&#252;nchen:
C.H.Beck.
O'Neil, Cathy (2016): Angriff der Algorithmen. Wie sie Wahlen manipulieren, Berufschancen zerst&#246;ren und 
unsere Gesundheit gef&#228;hrden. M&#252;nchen: Carl Hanser Verlag.
Opiela, Nicole; Kar, Resa Mohabbat; Thapa, Basanta; Weber, Mike (2018): EXEKUTIVE KI 2030. Vier
Zukunftsszenarien f&#252;r K&#252;nstliche Intelligenz in der &#246;ffentlichen Verwaltung. 1. Aufl. Hg. v.
Kompetenzzentrum &#214;ffentliche IT, Fraunhofer-Institut f&#252;r Offene Kommunikation FOKUS. Berlin. 
Online verf&#252;gbar unter https://www.oeffentliche-it.de/documents/10181/14412/Exekutive+KI+2030+-
+Vier+Zukunftsszenarien+f%C3%BCr+K%C3%BCnstliche+Intelligenz+in+der+%C3%B6ffentlichen+ 
Verwaltung, zuletzt abgerufen am 14.07.2020.
Orwat, Carsten (2020): Diskriminierungsrisiken durch Verwendung von Algorithmen. Eine Studie erstellt mit
einer Zuwendung der Antidiskriminierungsstelle des Bundes. 1. Auflage. Online verf&#252;gbar unter
https://www.antidiskriminierungsstelle.de/SharedDocs/Downloads/DE/publikationen/Expertisen/Studie_ 
Diskriminierungsrisiken_durch_Verwendung_von_Algorithmen.pdf;jsessionid=61E51C3451954B062A 
8A2B348247C00F.2_cid341?__blob=publicationFile&amp;v=5, zuletzt abgerufen am 05.08.2020.
Oswald, Gerhard; Krcmar, Helmut (2018): Digitale Transformation. Wiesbaden: Springer Fachmedien 
Wiesbaden.
Ovens, Carsten (2017): Filterblasen &#8211; Ausgangspunkte einer neuen, fremdverschuldeten Unm&#252;ndigkeit? In:
kommunikation @ gesellschaft 18, S. 1&#8211;25. Online verf&#252;gbar unter
https://www.ssoar.info/ssoar/bitstream/handle/document/51482/ssoar-ketg-2017-Ovens-
Filterblasen.pdf?sequence=3&amp;isAllowed=y&amp;lnkname=ssoar-ketg-2017-Ovens-Filterblasen.pdf, zuletzt 
abgerufen am 11.08.2020.
Pagels, Max (2018): What is Online Machine Learning? Hg. v. The Hands-on Advisors. Online verf&#252;gbar unter
https://towardsdatascience.com/machine-learning-classifiers-a5cc4e1b0623, zuletzt aktualisiert am
27.09.2019, zuletzt abgerufen am 20.07.2020.
Pandit, Shrihari (2019): It&#180;s time for NYC to enhance its smart city status. Why Google and Amazon&#180;s latest
moves in New York City should unite the five boroughs to modernize its communications infrastructure.
Opinion. Hg. v. smartcitiesdive.com. Online verf&#252;gbar unter https://www.smartcitiesdive.com/news/its-
time-for-nyc-to-enhance-its-smart-city-status/546634/, zuletzt aktualisiert am 23.01.2019, zuletzt
abgerufen am 16.07.2020.
Papakyriakopoulos, Orestis; Hegelich, Simon; Shahrezaye, Morteza; Serrano, Juan Carlos Medina (2018):
Social media and microtargeting: Political data processing and the consequences for Germany. In: Big
Data &amp; Society 5 (2), 1-15. 
Papernot, Nicolas; McDaniel, Patrick; Goodfellow, Ian; Jha, Somesh; Celik, Z. Berkay; Swami, Ananthram
(2017): Practical Black-Box Attacks against Machine Learning. In: Ramesh Karri, Ozgur Sinanoglu, 
Ahmad-Reza Sadeghi und Xun Yi (Hg.): Proceedings of the 2017 ACM on Asia Conference on 
Computer and Communications Security. ASIA CCS '17: ACM Asia Conference on Computer and 
Communications Security. Abu Dhabi United Arab Emirates, 02 - 06 04 2017. New York, NY, USA:
ACM, S. 506&#8211;519.
Pariser, Eli (2011): The filter bubble. What the Internet is hiding from you. New York, NY: Penguin Press.
Pariser, Eli (2012): Filter Bubble. Wie wir im Internet entm&#252;ndigt werden. 1. Aufl. M&#252;nchen: Carl Hanser
Verlag. Online verf&#252;gbar unter http://www.hanser-
elibrary.com/action/showBook?doi=10.3139/9783446431164.
Pasternack, Alex (2019): Frustrated funders exit Facebook&#8217;s election transparency project. Hg. v. 
fastcompany.com. Online verf&#252;gbar unter https://www.fastcompany.com/90412518/facebooks-plan-for-
radical-transparency-was-too-radical, zuletzt aktualisiert am 28.10.2019, zuletzt abgerufen am
04.08.2020.
Patel, Jalpa Pragnesh (2019): Vertical Indoor Farming &#8212; AI revolution in Agriculture. Hg. v. medium.com. 
Online verf&#252;gbar unter https://medium.com/@jpp440/vertical-indoor-farming-ai-revolution-in-
agriculture-ef6d32ca256, zuletzt abgerufen am 23.07.2020.
Paton, Graeme (2018): UK&#8217;s first fully autonomous vessel the C-Worker 7 is launched. In: thetimes.co.uk, 
01. M&#228;rz 2018. Online verf&#252;gbar unter https://www.thetimes.co.uk/article/uk-s-first-fully-autonomous-
vessel-the-c-worker-7-is-launched-86jwnzmrm, zuletzt abgerufen am 24.07.2020.
Pelton, Joseph N.; Singh, Indu B. (2019): Smart Cities of Today and Tomorrow. Better Technology, 
Infrastructure and Security. Cham: Springer Copernicus Books is a brand of Springer.
Perrault, Raymond; Shoham, Yoav; Brynjolfsson, Erik; Clark, Jack; Etchemendy, John; Grosz, Barbara et al. 
(2019): The AI Index 2019 Annual Report. Hg. v. Stanford University. Online verf&#252;gbar unter
https://hai.stanford.edu/sites/default/files/ai_index_2019_report.pdf, zuletzt abgerufen am 07.08.2020.
Perry, Tekla S. (2020): John Deere's quest to solve agricultures deep-learning problems &#8211; [Spectral Lines].
In: IEEE Spectr. 57 (2), S. 4.
Petermann, Anke (2019): K&#252;nstliche Intelligenz im Klassenzimmer &#8211; Wenn das Schulbuch mitdenkt. 
Hg. v. Deutschlandfunk Kultur. Online verf&#252;gbar unter
https://www.deutschlandfunkkultur.de/kuenstliche-intelligenz-im-klassenzimmer-wenn-das-
schulbuch.1001.de.html?dram:article_id=437619, zuletzt abgerufen am 06.08.2020.
Petry, Thorsten (2019): Robot Recruiting: Roboter sucht Kollegen. In: Personalmagazin, 12. M&#228;rz 2019 
(Nr. 2/2019), S. 26&#8211;29. Online verf&#252;gbar unter https://www.haufe.de/personal/hr-management/robot-
recruiting-erwartungen-und-akzeptanz_80_484100.html, zuletzt abgerufen am 20.08.2020.
Pfundner, Hagen (2019): Digitalisierung in der Medizin: Im disruptiven Wandel wandelbar bleiben. In: Robin 
Haring (Hg.): Gesundheit digital. Perspektiven zur Digitalisierung im Gesundheitswesen. Berlin,
Heidelberg: Springer Berlin Heidelberg, S. 143&#8211;157.
Piantino et al. (2014): Selecting social networking system user information for display via a timeline interface.
Pielke, Roger (2012): Basic Research as a Political Symbol. In: Minerva 50 (3), S. 339&#8211;361. 
Pieper, Fritz-Ulli; Gehrmann, Mareike (2019): K&#252;nstliche Intelligenz &#8211; Wer haftet? Haftungsfragen beim
Einsatz von KI. In: LR, S. 123&#8211;128. Online verf&#252;gbar unter https://legal-
revolution.com/images//pdf/Knstliche_Intelligenz_-_Wer_haftet.pdf, zuletzt abgerufen am 03.09.2020.
Pietras, Jake (2019): Wie KI Werbung besser machen soll. Hg. v. t3n.de. Online verf&#252;gbar unter
https://t3n.de/news/ki-werbung-besser-1185002/, zuletzt aktualisiert am 07.08.2019, zuletzt abgerufen 
am 29.07.2020.
Plattform Industrie 4.0 (2019): Digitale Gesch&#228;ftsmodelle f&#252;r die Industrie 4.0. Hg. v. Bundesministerium f&#252;r
Wirtschaft und Energie. Online verf&#252;gbar unter https://www.plattform-
i40.de/PI40/Redaktion/DE/Downloads/Publikation/digitale-geschaeftsmodelle-fuer-industrie-
40.pdf?__blob=publicationFile&amp;v=7, zuletzt abgerufen am 22.07.2020.
Plattform Industrie 4.0 (2019): K&#252;nstliche Intelligenz (KI) in Sicherheitsaspekten der Industrie 4.0. 
Hg. v. Bundesministerium f&#252;r Wirtschaft und Energie. Online verf&#252;gbar unter https://www.plattform-
i40.de/PI40/Redaktion/DE/Downloads/Publikation/KI-in-
sicherheitsaspekten.pdf?__blob=publicationFile&amp;v=7, zuletzt abgerufen am 27.07.2020.
Plattform Industrie 4.0 (2019): K&#252;nstliche Intelligenz und Recht im Kontext von Industrie 4.0. 
Hg. v. Bundesministerium f&#252;r Wirtschaft und Energie. Online verf&#252;gbar unter https://www.plattform-
i40.de/PI40/Redaktion/DE/Downloads/Publikation/kuenstliche-intelligenz-und-
recht.pdf?__blob=publicationFile&amp;v=4, zuletzt abgerufen am 27.07.2020.
Plattform Industrie 4.0 (2019): Technologieszenario &#8222;K&#252;nstliche Intelligenz in der Industrie 4.0&#8220;. 
Hg. v. Bundesministerium f&#252;r Wirtschaft und Energie. Online verf&#252;gbar unter https://www.plattform-
i40.de/PI40/Redaktion/DE/Downloads/Publikation/KI-industrie-40.pdf?__blob=publicationFile&amp;v=10, 
zuletzt abgerufen am 27.07.2020.
Plattform Lernende Systeme (2019): Arbeit, Qualifizierung und Mensch-Maschine Interaktion. Ans&#228;tze zur
Gestaltung K&#252;nstlicher Intelligenz f&#252;r die Arbeitswelt. Whitepaper der Arbeitsgruppe
Arbeit/Qualifikation, Mensch-Maschine-Interaktion. M&#252;nchen. Online verf&#252;gbar unter
https://www.plattform-lernende-
systeme.de/files/Downloads/Publikationen/AG2_Whitepaper_210619.pdf, zuletzt abgerufen am
17.07.2020.
Plattform Lernende Systeme (2019): Auf dem Weg zu einem intelligenten Mobilit&#228;tsraum. Bericht der
Arbeitsgruppe Mobilit&#228;t und intelligente Verkehrssysteme. Online verf&#252;gbar unter
https://www.plattform-lernende-systeme.de/files/Downloads/Publikationen/AG5_Bericht_280619.pdf,
zuletzt abgerufen am 23.07.2020.
Plattform Lernende Systeme (2019): Lernende Systeme im Gesundheitswesen &#8211; Bericht der Arbeitsgruppe
Gesundheit, Medizintechnik Pflege. M&#252;nchen. Online verf&#252;gbar unter https://www.plattform-lernende-
systeme.de/publikationen-details/lernende-systeme-im-gesundheitswesen.html, zuletzt abgerufen am
09.07.2020.
Plattform Lernende Systeme (2019): Neue Gesch&#228;ftsmodelle mit K&#252;nstlicher Intelligenz, Bericht der
Arbeitsgruppe Gesch&#228;ftsmodellinnovationen. M&#252;nchen. Online verf&#252;gbar unter https://www.plattform-
lernende-systeme.de/files/Downloads/Publikationen/AG4_Bericht_231019.pdf, zuletzt abgerufen am
16.07.2020.
Plattform Lernende Systeme Arbeitsgruppe 7 &#8211; Lebensfeindliche Umgebungen: KI-
Anwendungsszenario &#8211; Schnelle Hilfe beim Rettungseinsatz. Ein Chemiewerk ist in Brand geraten. Um
das Feuer zu bek&#228;mpfen und m&#246;gliche Opfer zu retten, bringen Feuerwehrleute und weitere
Einsatzkr&#228;fte sich selbst in Gefahr. In Zukunft sollen sie deshalb von intelligenten Robotern unterst&#252;tzt
werden.|. Online verf&#252;gbar unter https://www.plattform-lernende-systeme.de/anwendungsszenario-
rettungseinsatz.html, zuletzt abgerufen am 15.07.2020.
Podbregar, Nadja (2019): KI meistert &#8222;StarCraft II&#8220;. Hg. v. wissenschaft.de. Online verf&#252;gbar unter
https://www.wissenschaft.de/technik-digitales/ki-meistert-starcraft-ii/, zuletzt aktualisiert am
30.10.2019, zuletzt abgerufen am 15.07.2020.
Polizeipr&#228;sidium Mannheim (2019): Auskunft auf Antrag nach dem Landesinformationsfreiheitsgesets Baden-
W&#252;rttemberg hier: ,,Daten und Ergebnisse zu der seit 03.12.201g in Betrieb befindtichen 
verhaltensbasierten video&#252;berwachung am Hauptbahnhof. Online verf&#252;gbar unter https://media.frag-
den-staat.de/files/foi/139008/po_ma_geschwaerzt.pdf, zuletzt abgerufen am 22.07.2020.
Pople, Harry E. (1985): Caduceus: a Computer-Based Diagnostic Consultant. University of Pittsburgh, 
Pittsburgh, PA, United States. Online verf&#252;gbar unter https://grantome.com/grant/NIH/R01-LM003710-
05S1, zuletzt abgerufen am 09.07.2020.
Portmann, Edy; Tabacchi, Marco E.; Seising, Rudolf; Habenstein, Astrid (2019): Designing Cognitive Cities. 
1st edition 2019: Springer International Publishing (Studies in Systems, Decision and Control, 176).
P&#246;ttker, Horst (2000): Kompensation von Komplexit&#228;t. In: Martin L&#246;ffelholz (Hg.): Theorien des
Journalismus. Wiesbaden: VS Verlag f&#252;r Sozialwissenschaften, S. 375&#8211;390.
Press Trust of India (2018): Delhi: Facial recognition system helps trace 3,000 missing children in 4 days. 
In: timesofindia.indiatimes.com, 22. April 2018. Online verf&#252;gbar unter
https://timesofindia.indiatimes.com/city/delhi/delhi-facial-recognition-system-helps-trace-3000-mis
singchildren-in-4-days/articleshow/63870129.cms, zuletzt abgerufen am 17.07.2020.
Presse- und Informationsamt der Bundesregierung (2018): Der n&#228;chste Schritt zur Erprobung von Flugtaxis in 
Deutschland. Online verf&#252;gbar unter https://www.bundesregierung.de/breg-de/aktuelles/der-naechste-
schritt-zur-erprobung-von-flugtaxis-in-deutschland-1146854, zuletzt abgerufen am 03.08.2020.
Presse- und Informationsamt der Bundesregierung (2020): Digitale Stadtentwicklung und F&#246;rderung von Smart
Cities. Federf&#252;hrendes Ressort: BMI. Online verf&#252;gbar unter https://www.bundesregierung.de/breg-
de/themen/digital-made-in-de/digitale-stadtentwicklung-und-foerderung-von-smart-cities-1546630, 
zuletzt aktualisiert am 24.06.2020, zuletzt abgerufen am 17.07.2020.
PricewaterhouseCoopers (2013): Interoperability: An essential component for scalable mHealth. Online
verf&#252;gbar unter https://www.pwc.com/gx/en/healthcare/mhealth/mhealth-insights/assets/pwc-mhealth-
insights-interoperability-an-essential-component-for-scalable-mhealth-pdf.pdf, zuletzt abgerufen am
10.07.2020.
PricewaterhouseCoopers (2017): Sherlock in Health. How artificial intelligence may improve quality and 
efficiency, whilst reducing healthcare costs in Europe. Online verf&#252;gbar unter
https://www.pwc.de/de/gesundheitswesen-und-pharma/studie-sherlock-in-health.pdf, zuletzt abgerufen 
am 09.07.2020.
PricewaterhouseCoopers (2018): Auswirkungen der Nutzung von k&#252;nstlicher Intelligenz in Deutschland. 
Online verf&#252;gbar unter https://www.pwc.de/de/business-analytics/sizing-the-price-final-juni-2018.pdf, 
zuletzt abgerufen am 23.07.2020.
PricewaterhouseCoopers (2018): Handel im Wandel. Online verf&#252;gbar unter https://www.pwc.de/de/digitale-
transformation/kuenstliche-intelligenz/pwc-bevoelkerungsumfrage-ki-handel-im-wandel.pdf, zuletzt 
abgerufen am 23.07.2020.
PricewaterhouseCoopers (2019): K&#252;nstliche Intelligenz in Unternehmen. Online verf&#252;gbar unter
https://www.pwc.de/de/digitale-transformation/kuenstliche-intelligenz/studie-kuenstliche-intelligenz-in-
unternehmen.pdf, zuletzt abgerufen am 21.07.2020.
PricewaterhouseCoopers (2019): Opportunities for the global semiconductor market. Online verf&#252;gbar unter
https://www.pwc.com/gx/en/industries/tmt/publications/assets/pwc-semiconductor-report-2019.pdf, 
zuletzt abgerufen am 23.07.2020.
PricewaterhouseCoopers Strategy&amp; (Germany) GmbH (2016): Weiterentwicklung der eHealthStrategie. Studie 
im Auftrag des Bundesministeriums f&#252;r Gesundheit. Online verf&#252;gbar unter
https://www.bundesgesundheitsministerium.de/fileadmin/Dateien/3_Downloads/E/eHealth/BMG-
Weiterentwicklung_der_eHealth-Strategie-Abschlussfassung.pdf, zuletzt abgerufen am 10.07.2020.
Purdy, Mark; Daugherty, Paul (2017): How AI boosts industry profits and innovation. Accenture. Online
verf&#252;gbar unter https://www.accenture.com/fr-fr/_acnmedia/36dc7f76eab444cab6a7f44017cc3997.pdf, 
zuletzt abgerufen am 22.07.2020.
Rahman, K. Sabeel; Teachout, Zephyr (2020): From Private Bads to Public Goods. Adapting Public Utility
Regulation for Informational Infrastructure. Hg. v. Knight First Amendment Institute. Online verf&#252;gbar
unter https://s3.amazonaws.com/kfai-documents/documents/50badb2d1d/Teachout-and-Rahman-
2.4.2020-FINAL.pdf, zuletzt abgerufen am 04.08.2020.
Rainforest Connection (2020): How our system helps preserve rainforests. Online verf&#252;gbar unter
https://rfcx.org, zuletzt abgerufen am 07.08.2020.
Raj, Manav; Seamans, Robert (op. 2019): Artificial Intelligence, Labor, Productivity, and the Need for Firm-
Level Data. In: Ajay Agrawal, Joshua Gans und Avi Goldfarb (Hg.): The economics of artificial
intelligence. An agenda. Chicago, London: The University of Chicago Press (National Bureau of
Economic Research conference report), S. 553&#8211;565.
Rajkomar, Alvin; Oren, Eyal; Chen, Kai; Dai, Andrew M.; Hajaj, Nissan; Hardt, Michaela et al. (2018):
Scalable and accurate deep learning with electronic health records. In: NPJ digital medicine 1, S. 18. 
Ranking Digital Rights (2019): Consultation Draft &#8211; Human Rights Risk Scenarios: Targeted Advertising. 
Online verf&#252;gbar unter https://rankingdigitalrights.org/wp-content/uploads/2019/02/Human-Rights-Risk-
Scenarios-targeted-advertising.pdf, zuletzt abgerufen am 11.08.2020.
Ranking Digital Rights (2019): Consultation Draft &#8211; Human rights risk scenarios: Algorithms, machine
learning and automated decision-making. Online verf&#252;gbar unter https://rankingdigitalrights.org/wp-
content/uploads/2019/07/Human-Rights-Risk-Scenarios_-algorithms-machine-learning-automated-
decision-making.pdf, zuletzt abgerufen am 11.08.2020.
Rau, Kristin (2018): Das sind Deutschlands geheime Weltmarktf&#252;hrer. In: wiwo.de, 25. Januar 2018. Online
verf&#252;gbar unter https://www.wiwo.de/unternehmen/mittelstand/hannovermesse/hidden-champions-das-
sind-deutschlands-geheime-weltmarktfuehrer/20883700.html, zuletzt abgerufen am 21.07.2020.
Raue, Benjamin (2019): Rechtssicherheit f&#252;r datengest&#252;tzte Forschung. Die Text-und-Data-Mining-Schranken 
in Art. 3 und 4 DSM-Richtlinie. In: Zeitschrift f&#252;r Urheber- und Medienrecht (8/9), S. 684&#8211;693.
Rayner, Tristan (2018): Dieser Roboter braucht im Kampf gegen Unkraut 20-mal weniger Herbizide.
Hg. v. reset.org. Online verf&#252;gbar unter https://reset.org/blog/dieser-roboter-braucht-im-kampf-unkraut-
20-mal-weniger-herbizide-09032018, zuletzt abgerufen am 30.07.2020.
Reetz, Fabian (2017): Welche Chancen ein digitales EnergieMarktdesign bietet. Erkenntnisse eines
ForesightProzesses. Hg. v. Stiftung Neue Verantwortung e. V. Online verf&#252;gbar unter
https://www.stiftung-nv.de/sites/default/files/chancen_eines_digitalen_marktdesigns.pdf, zuletzt
abgerufen am 07.08.2020.
Reetz, Fabian (2019): Blockchain &amp; das Klima. Warum die nationale BlockchainStrategie Innovations- und 
Klimapolitik zusammenbringen sollte. Hg. v. Stiftung Neue Verantwortung e. V. Online verf&#252;gbar unter
https://www.stiftung-nv.de/sites/default/files/blockchain_und_das_klima.pdf, zuletzt abgerufen am
07.08.2020.
Regierungskommission Deutscher Corporate Governance Kodex (2019): Deutscher Corporate Governance
Kodex. Online verf&#252;gbar unter
https://www.dcgk.de//files/dcgk/usercontent/de/download/kodex/191216_Deutscher_Corporate_Govern 
ance_Kodex.pdf, zuletzt abgerufen am 09.09.2020.
Reichelt, Patrick (2017): Einf&#252;hrung in den Roboterjournalismus. Bedrohung oder Chance? Baden-Baden:
Tectum.
Reichstein, Markus; Camps-Valls, Gustau; Stevens, Bjorn; Jung, Martin; Denzler, Joachim; Carvalhais, Nuno;
Prabhat (2019): Deep learning and process understanding for data-driven Earth system science.
In: Nature 566 (7743), S. 195&#8211;204.
Reidel, Michael (2019): Ohne Fahrer? Vorstellbar Autonome Autos: Die Akzeptanz w&#228;chst, das Marketing 
steht vor Herausforderungen &#8211; eine Studie der DHBW Ravensburg. In: Horizont, 09. Mai 2019, S. 18.
Reinbold, Peter (2018): Assistenz-Roboter f&#252;r Senioren Geriatronik soll Senioren im Alltag unterst&#252;tzen. 
Hg. v. OVB Online. Online verf&#252;gbar unter https://www.ovb-online.de/weltspiegel/bayern/assistenz-
roboter-senioren-geriatronik-soll-senioren-alltag-unterstuetzen-10304056.html, zuletzt aktualisiert am
06.10.2018, zuletzt abgerufen am 10.07.2020.
Rei&#223;mann, Ole (2019): Warum wir oft ein falsches Bild von k&#252;nstlicher Intelligenz haben. In: spiegel.de 2019, 
14. M&#228;rz 2019. Online verf&#252;gbar unter https://www.spiegel.de/netzwelt/web/kuenstliche-intelligenz-
filme-und-serien-machen-es-realer-ki-schwer-a-1257759.html, zuletzt abgerufen am 15.07.2020.
Resch, Bernd (2017): Nutzergenerierte Daten f&#252;r Entscheidungsunterst&#252;tzung in naher Echtzeit. In: Thomas H. 
Kolbe (Hg.): Geoinformationssysteme 2017. Beitr&#228;ge zur 4. M&#252;nchner GI-Runde: Wichmann, S. 90&#8211;98.
Research and Markets (2019): Worldwide Smart City Platforms Market Analysis, 2019-2023 &#8211; Government
Initiatives for Smart Cities Presents Lucrative Opportunities. Hg. v. prnewswire.com. Dublin. Online
verf&#252;gbar unter https://www.prnewswire.com/news-releases/worldwide-smart-city-platforms-market-
analysis-2019-2023---government-initiatives-for-smart-cities-presents-lucrative-opportunities-
300804917.html, zuletzt aktualisiert am 01.03.2019, zuletzt abgerufen am 16.07.2020.
Reuters (2018): MLB taps Amazon&#8217;s AI to power real-time game stats and graphics. Hg. v. VentureBeat. 
Online verf&#252;gbar unter https://venturebeat.com/2018/07/17/mlb-taps-amazons-ai-to-power-real-time-
game-stats-and-graphics/, zuletzt aktualisiert am 17.07.2018, zuletzt abgerufen am 10.07.2020.
Richter, Stephan; Kind, Sonja (2016): Predictive Policing. Hg. v. B&#252;ro f&#252;r Technikfolgen-Absch&#228;tzung beim
Deutschen Bundestag (Themenkurzprofil, 9). Online verf&#252;gbar unter https://www.tab-beim-
bundestag.de/de/pdf/publikationen/themenprofile/Themenkurzprofil-009.pdf, zuletzt abgerufen am
17.07.2020.
Rixecker, Kim (2016): Google senkt Stromverbrauch im Rechenzentrum &#8211; mittels k&#252;nstlicher Intelligenz.
Hg. v. t3n.de. Online verf&#252;gbar unter https://t3n.de/news/google-stromverbrauch-ki-deepmind-727798/, 
zuletzt abgerufen am 23.07.2020.
Robert Koch Institut (2020): DEMIS &#8722; Deutsches Elektronisches Melde- und Informationssystem f&#252;r den 
Infektionsschutz. Online verf&#252;gbar unter
https://www.rki.de/DE/Content/Infekt/IfSG/DEMIS/DEMIS_node.html, zuletzt aktualisiert am
16.09.2020, zuletzt abgerufen am 18.09.2020.
Rodi, Michael; Sch&#228;fer-Stradowsky, Simon; Doderer, Hannes; Burzlaff, Clara; Sterniczuk, Tim (2017):
Digitale Mobilit&#228;tsplattformen. Studie zur rechtlichen Weiterentwicklung des
Personenbef&#246;rderungsrechts unter besonderer Ber&#252;cksichtigung digitaler Mobilit&#228;tsplattformen. Hg. v.
Bundesministerium f&#252;r Verkehr und digitale Infrastruktur. Institut f&#252;r Klimaschutz, Energie und 
Mobilit&#228;t e. V. Online verf&#252;gbar unter https://www.bmvi.de/SharedDocs/DE/Publikationen/DG/studie-
digitale-mobilitaetsplattform-lang.pdf?__blob=publicationFile, zuletzt abgerufen am 27.07.2020.
Rodriguez, Ashley (2019): Wie Netflix euch beim Streaming zuschaut &#8211; und damit euer Sehverhalten massiv
beeinflusst. Hg. v. businessinsider.de. Online verf&#252;gbar unter
https://www.businessinsider.de/tech/netflix-amazon-prime-video-kuenstliche-intelligenz-ki-2019-8/, 
zuletzt aktualisiert am 10.08.2019, zuletzt abgerufen am 28.07.2020.
Roland Berger GmbH; Asgard Capital Verwaltung Gmbh (2018): Artificial Intelligence &#8211; A strategy for
European startups. Recommendations for policymakers.  Online verf&#252;gbar unter
https://www.rolandberger.com/de/Publications/AI-startups-as-innovation-drivers.html, zuletzt abgerufen 
am 21.07.2020.
Rondinella, Guiseppe (2017): Warum Deutschland ein Entwicklungsland ist. In: Horizont.net, 18. Oktober
2017. Online verf&#252;gbar unter https://www.horizont.net/tech/nachrichten/uebernahmen-von-Tech-Start-
ups-Warum-Deutschland-ein-Entwicklungsland-ist-161931, zuletzt abgerufen am 21.07.2020.
R&#246;per, Horst (2018): Zeitungsmarkt 2018: Pressekonzentration steigt rasant. Daten zur Konzentration der
Tagespresse in Deutschland im I. Quartal 2018. In: Media Perspektiven, 18. Dezember 2018 (5), S. 216&#8211; 
234. Online verf&#252;gbar unter https://www.ard-werbung.de/fileadmin/user_upload/media-
perspektiven/pdf/2018/0518_Roeper_2018-12-18.pdf, zuletzt abgerufen am 09.09.2020.
Roth, Ines (2017): Digitalisierung und Arbeitsqualit&#228;t Eine Sonderauswertung auf Basis des DGB-Index Gute
Arbeit 2016 f&#252;r den Dienstleistungssektor. Studie im Auftrag der ver.di Bundesverwaltung Ressort 13, 
Bereich Innovation und Gute Arbeit. Unter Mitarbeit von Nadine M&#252;ller. Hg. v. ver.di &#8211; Vereinte 
Dienstleistungsgewerkschaft Bereich Innovation und Gute Arbeit. Online verf&#252;gbar unter
https://innovation-gute-
arbeit.verdi.de/++file++592fd69d086c2653a7bb5b05/download/digitalverdi_web.cleaned.pdf, zuletzt
abgerufen am 15.07.2020.
Rott, Peter (2018): Rechtspolitischer Handlungsbedarf im Haftungsrecht, insbesondere f&#252;r digitale
Anwedungen. Hg. v. Verbraucherzentrale Bundesverband. Online verf&#252;gbar unter
https://www.vzbv.de/sites/default/files/document-wrapper-
files/2019/02/25/gutachten_handlungsbedarf_im_haftungsrecht.pdf, zuletzt abgerufen am 27.07.2020.
Rotter, Brian (2020): Warner Bros.: KI entscheidet, welche Filme produziert werden sollten. Hg. v. t3n. Online
verf&#252;gbar unter https://t3n.de/news/warner-bros-ki-entscheidet-1240312/, zuletzt aktualisiert am
09.01.2020, zuletzt abgerufen am 15.07.2020.
Rubin, Ben Fox (2018): Amazon's Alexa assistant now works with over 20K devices. Alexa's expansion is way
up from 4,000 devices in January. Hg. v. cnet. Online verf&#252;gbar unter
https://www.cnet.com/news/amazon-alexa-assistant-is-now-in-20k-devices/, zuletzt aktualisiert am
01.09.2018, zuletzt abgerufen am 15.07.2020.
Rudschies, Wolfgang; Kroher, Thomas (2019): Autonomes Fahren: Digital entspannt in die Zukunft. 
Hg. v. adac.de. Online verf&#252;gbar unter https://www.adac.de/rund-ums-fahrzeug/ausstattung-technik-
zubehoer/autonomes-fahren/technik-vernetzung/aktuelle-technik/, zuletzt aktualisiert am 11.12.2019, 
zuletzt abgerufen am 28.07.2020.
Rudzio, Kolja (2018): Wenn der Roboter die Fragen stellt. Ein Vorstellungsgespr&#228;ch bei einer Maschine?
Unser Autor hat es ausprobiert. In: Die Zeit 2018, 23. August 2018 (Nr. 35/2018). Online verf&#252;gbar
unter https://www.zeit.de/2018/35/kuenstliche-intelligenz-vorstellungsgespraech-interview-test, zuletzt 
abgerufen am 16.07.2020.
Ruhren, Stefan von der; Rindsf&#252;ser, Guido; Beckmann, Klaus J.; Kuhimhof, Tobias; Chlond, Bastian;
Zumkeller, Dirk (2005): Bestimmung multimodaler Personengruppen. Projekt FE 70.724 &#8211; Projektliste
2003. Schlussbericht. Hg. v. Institut f&#252;r Stadtbauwesen und Stadtverkehr RWTH Aachen und Institut f&#252;r
Verkehrswesen, Universit&#228;t Karlsruhe (Forschungsprogramm zur Verbesserung der
Verkehrsverh&#228;ltnisse in den Gemeinden). Online verf&#252;gbar unter
https://repository.difu.de/jspui/bitstream/difu/126985/1/DB1340.pdf, zuletzt abgerufen am 27.07.2020.
Ruppenhofer, Josef; Siegel, Melanie; Wiegand, Michael (2018): Proceedings of the GermEval 2018 Workshop.
14th Conference on Natural Language Processing &#8211; KONVENS 2018. Hg. v. Austrian Academy of
Sciences, Vienna. Wien. Online verf&#252;gbar unter
https://www.oeaw.ac.at/fileadmin/subsites/academiaecorpora/PDF/GermEval2018_Proceedings.pdf, 
zuletzt abgerufen am 06.08.2020.
Russell, Stuart J.; Norvig, Peter (2016): Artificial intelligence. A modern approach. Unter Mitarbeit von Ernest
Davis und Douglas Edwards. Third edition, Global edition. Boston, Columbus, Indianapolis: Pearson 
(Always learning).
Ru&#223;-Mohl, Stephan (1992): Am eigenen Schopfe&#8230; Qualit&#228;tssicherung im Journalismus &#8212; Grundfragen, 
Ans&#228;tze, N&#228;herungsversuche. In: Publizistik (1), S. 83&#8211;96.
RWI &#8211; Leibniz-Institut f&#252;r Wirtschaftsforschung (2017): Stand und Weiterentwicklung der
Investitionsf&#246;rderung im Krankenhausbereich. Online verf&#252;gbar unter
https://www.bundesgesundheitsministerium.de/fileadmin/Dateien/5_Publikationen/Ministerium/Berichte 
/Gutachten_Investitionsfoerderung_Krankenhausbereich.pdf, zuletzt abgerufen am 10.07.2020.
Sadik-Khan, Janette; Solomonow, Seth (2017): Streetfight. Handbook for an urban revolution. New York, New
York: Penguin Books.
San Francisco (2016): Smart City San Francisco. Online verf&#252;gbar unter http://smartcitysf.com/, zuletzt 
abgerufen am 16.07.2020.
Sanders, Jos; Grip, Andries de (2004): Training, task flexibility and the employability of low&#8208;skilled workers. 
In: Int J of Manpower 25 (1), S. 73&#8211;89. 
S&#228;ngerlaub, Alexander (2017): Deutschland vor der Bundestagswahl: &#220;berall Fake News?! Hg. v. Stiftung 
Neue Verantwortung. Online verf&#252;gbar unter https://www.stiftung-nv.de/sites/default/files/fakenews.pdf,
zuletzt aktualisiert am August 2017, zuletzt abgerufen am 15.07.2020.
Sauer, Frank (2018): K&#252;nstliche Intelligenz in den Streitkr&#228;ften. Zum Handlungsbedarf bei Autonomie in 
Waffensystemen. Hg. v. Bundesakademie f&#252;r Sicherheitspolitik (Arbeitspapier Sicherheitspolitik, 26). 
Online verf&#252;gbar unter
https://www.baks.bund.de/sites/baks010/files/arbeitspapier_sicherheitspolitik_2018_26.pdf, zuletzt
abgerufen am 20.07.2020.
Scanu, Simone (2018): Musik und KI: Wie Streaming-Dienste die k&#252;nstliche Intelligenz nutzen. Hg. v. 
nextpit.de. Online verf&#252;gbar unter https://www.androidpit.de/musik-streaming-und-kuenstliche-
intelligenz-plattformen, zuletzt aktualisiert am 09.12.2018, zuletzt abgerufen am 14.07.2020.
Schallbruch, Martin; Schweitzer, Heike; Wambach, Achim; Kirchhoff, Wolfgang; Langeheine, Bernd;
Schneider, Jens-Peter et al. (2019): Ein neuer Wettbewerbsrahmen f&#252;r die Digitalwirtschaft. Bericht der
Kommission Wettbewerbsrecht 4.0. Hg. v. Bundesministerium f&#252;r Wirtschaft und Energie. Online
verf&#252;gbar unter https://www.bmwi.de/Redaktion/DE/Publikationen/Wirtschaft/bericht-der-kommission-
wettbewerbsrecht-4-0.pdf?__blob=publicationFile&amp;v=12, zuletzt abgerufen am 28.07.2020.
Schatilow, Lars (2019): Human Friendly Automation Charta. Cross-company commitment: Implementing 
intelligent automation socially and responsibly // Invitation to join in. Online verf&#252;gbar unter
https://www.linkedin.com/pulse/human-friendly-automation-charta-dr-lars-schatilow, zuletzt abgerufen
am 05.08.2020.
Schayani, Isabel (2018): Moskau: Smart City (Weltspiegel). Das Erste, 19. M&#228;rz 2018. Online verf&#252;gbar unter
https://www.daserste.de/information/politik-weltgeschehen/weltspiegel/sendung/moskau-smart-city-
100.html, zuletzt abgerufen am 16.07.2020.
Scheuch, Laszlo (2018): Zocken auf schmalem Grat &#8211; Wie KI die Games-Branche erobert. In: General-
Anzeiger Bonn 2018, 16. November 2018. Online verf&#252;gbar unter https://ga.de/news/digitale-welt/wie-
ki-die-games-branche-erobert_aid-43952531, zuletzt abgerufen am 15.07.2020.
Schmal, Stanislaw; Werner, Fabian (2018): From Prototype to Operative Software with RapidMiner. Data 
Analytics at Lufthansa, 16. Oktober 2018. Online verf&#252;gbar unter https://rapidminer.com/resource/data-
analytics-lufthansa/, zuletzt abgerufen am 15.07.2020.
Schmelzle, Michael (2018): Nvidia Geforce RTX 2080 &amp; 2080 Ti im Test: Schnell, innovativ &amp; teuer. Hg. v. 
pcwelt.de. Online verf&#252;gbar unter https://www.pcwelt.de/a/nvidia-geforce-rtx-2080-ti-die-schnellste-
gaming-grafikkarte-der-welt,3450575, zuletzt abgerufen am 23.07.2020.
Schmidt, Axel; Reers, Juergen; Huber, Alexander; Tegtmeyer, Daniel; Kruse, Tobias (2019): Mobility
Services: the consumer perspective. Studie. Hg. v. Accenture. Online verf&#252;gbar unter
https://www.accenture.com/_acnmedia/PDF-109/Accenture-Mobility-Services.pdf#zoom=50, zuletzt
abgerufen am 27.07.2020.
Schmidt, Jan-Hinrik; Merten, Lisa; Hasebrink, Uwe (2017): Zur Relevanz von Online-Intermedi&#228;ren f&#252;r die 
Meinungsbildung. Hamburg: Hans-Bredow-Institut f&#252;r Medienforschung an der Universit&#228;t Hamburg 
(Arbeitspapiere des Hans-Bredow-Instituts, Nr. 40). Online verf&#252;gbar unter https://www.hans-bredow-
institut.de/uploads/media/default/cms/media/67256764e92e34539343a8c77a0215bd96b35823.pdf.
Schmiechen, Frank (2016): Dieser Film ist von einer k&#252;nstlichen Intelligenz geschrieben worden. Online
verf&#252;gbar unter https://www.gruenderszene.de/allgemein/film-kunstliche-
intelligenz?interstitial;%20https://www.palmerhargreaves.de/blog/kuenstlich-kreativ, zuletzt aktualisiert 
am 13.06.2016, zuletzt abgerufen am 15.07.2020.
Schmiedel, Stevie Meriel (2018): RTL hat uns mal kurz gekillt. Hg. v. Pinkstinks Germany e. V. Online
verf&#252;gbar unter https://pinkstinks.de/rtl-hat-uns-mal-kurz-gekillt/, zuletzt abgerufen am 05.08.2020.
Schmieder, J&#252;rgen (2019): Uber hat&#180;s versemmelt. B&#246;rsengang. In: s&#252;ddeutsche.de, 14. Mai 2019. Online
verf&#252;gbar unter https://www.sueddeutsche.de/wirtschaft/uber-boersengang-desaster-taxibranche-
1.4445812, zuletzt abgerufen am 27.07.2020.
Schneider, Jan; Yemane, Ruta; Weinmann, Martin (2014): Diskriminierung am Ausbildungsmarkt: Ausma&#223;, 
Ursachen und Handlungsperspektiven. Berlin: Sachverst&#228;ndigenrat deutscher Stiftungen f&#252;r Integration 
und Migration GmbH (SVR). Online verf&#252;gbar unter https://d-nb.info/1054103348/34, zuletzt abgerufen 
am 05.08.2020.
Schnell, Christian (2018): Start-ups Emil und Friday bieten Kfz-Tarife f&#252;r Wenigfahrer an. In:
Handelsblatt.com, 22. Oktober 2018. Online verf&#252;gbar unter
https://www.handelsblatt.com/finanzen/vorsorge/versicherung/versicherungen-start-ups-emil-und-frida
ybieten-kfz-tarife-fuer-wenigfahrer-an/23215030.html?ticket=ST-8342215-lErxNLsMoaRkvLZFY9
wxap3, zuletzt abgerufen am 22.07.2020.
Schreier, J&#252;rgen (2018): KI wandert von der Cloud an die Edge. Hg. v. industry-of-things.de. Online verf&#252;gbar
unter https://www.industry-of-things.de/ki-wandert-von-der-cloud-an-die-edge-a-741059/, zuletzt
abgerufen am 23.07.2020.
Schreier, J&#252;rgen (2020): Last Mile: Autonome Lieferroboter als Milliarden-Markt? Hg. v. next-mobility.news. 
Online verf&#252;gbar unter https://www.next-mobility.news/amp/last-mile-autonome-lieferroboter-als-
milliarden-markt-a-901427/, zuletzt abgerufen am 03.08.2020.
Schreiner, Maximilian (2020): Filme &#252;ber K&#252;nstliche Intelligenz: Sieben Meilensteine der KI-Filmgeschichte.
Online verf&#252;gbar unter https://mixed.de/beste-filme-kuenstliche-intelligenz/, zuletzt aktualisiert am
12.01.2020, zuletzt abgerufen am 14.07.2020.
Schr&#246;der, Lothar (2016): Die digitale Treppe. Wie die Digitalisierung unsere Arbeit ver&#228;ndert und wie wir
damit umgehen. Frankfurt am Main: Bund Verlag.
Schr&#246;der, Lothar (2019): Menschenbilder, Visionen, Normen. Orientierungen f&#252;r &#8222;Gute Arbeit mit KI&#8220;. In:
Stefan Selke, Helmut Fahrenbach, Annette Schlemm, Lothar Schr&#246;der, Ingo M&#252;ller, Bernd Stickelmann 
et al.: Latenz &#8211; Journal f&#252;r Philosophie und Gesellschaft, Arbeit und Technik, Kunst und Kultur. Der
K&#252;nstliche Mensch? Menschenbilder im 21. Jahrhundert. 1. Auflage. Hg. v. Irene Scherer und Welf
Schr&#246;ter. M&#246;ssingen: Talheimer (Latenz, 4).
Schroepfer, Mike (2019): Creating a data set and a challenge for deepfakes. Hg. v. Facebook. Online verf&#252;gbar
unter https://ai.facebook.com/blog/deepfake-detection-challenge, zuletzt aktualisiert am 05.09.2019,
zuletzt abgerufen am 30.07.2020.
Schubert, Franziska (2019): Bis zu 30 neue KI-Professuren. In: fr.de, 15. August 2019. Online verf&#252;gbar unter
https://www.fr.de/wissen/neue-ki-professuren-12916275.html, zuletzt abgerufen am 20.07.2020.
Schuck, J&#252;rgen (2018): Wie Shazam Songs erkennt. Hg. v. c`t magazin f&#252;r computer technik. Online verf&#252;gbar
unter https://www.heise.de/ct/artikel/Wie-Shazam-Songs-erkennt-4192471.html, zuletzt aktualisiert am
14.12.2018, zuletzt abgerufen am 14.07.2018.
Schuler, Marcus (2020): So macht KI Filme erfolgreich (SWR2 Impuls). S&#252;dwestrundfunk, 06. Februar 2020. 
Online verf&#252;gbar unter https://www.swr.de/swr2/wissen/so-macht-ki-filme-erfolgreich-100.html, zuletzt
abgerufen am 15.07.2020.
Schulz, Wolfgang; Dreyer, Stephan (2018): Stellungnahme zum Diskussionsentwurf eines
Medienstaatsvertrags der L&#228;nder. Hg. v. Hans-Bredow-Institut f&#252;r Medienforschung an der Universit&#228;t
Hamburg. Online verf&#252;gbar unter https://www.hans-bredow-
institut.de/uploads/media/Publikationen/cms/media/qiuektv_HBI_StellungnahmeMedienstaatsvertrag18 
0926.pdf, zuletzt abgerufen am 04.08.2020.
Schumpeter, Joseph A. (2006): Theorie der wirtschaftlichen Entwicklung. Nachdruck der 1. Auflage von 1912. 
Hg. v. Jochen R&#246;pke und Olaf Stiller. Berlin: Duncker &amp; Humblot. Online verf&#252;gbar unter
http://elibrary.duncker-humblot.de/9783428517466/U1.
Schwab, Katharine (2019): A hospital introduced a robot to help nurses. They didn&#8217;t expect it to be so popular. 
Moxi is a robot designed to make nurses&#8217; lives easier. But the friendly bot is turning out to be a welcome
presence for some patients, too. Hg. v. Fast Company. Online verf&#252;gbar unter
https://www.fastcompany.com/90372204/a-hospital-introduced-a-robot-to-help-nurses-they-didnt-
expect-it-to-be-so-popular, zuletzt aktualisiert am 08.07.2019, zuletzt abgerufen am 10.07.2020.
Schwan, Ben (2019): Wirbel um Reproduzierbarkeitskrise durch KI. Immer mehr Forschungsergebnisse lassen 
sich nicht verifizieren. Das k&#246;nnte auch am breiten Einsatz von maschinellem Lernen liegen, meint eine 
Forscherin. In: heise.de, 12. M&#228;rz 2019. Online verf&#252;gbar unter
https://www.heise.de/newsticker/meldung/Wirbel-um-Reproduzierbarkeitskrise-durch-KI-4326803.html, 
zuletzt abgerufen am 06.08.2020.
Schwartmann, Rolf; Hermann, Maximilian; M&#252;hlenbeck, Robin L. (2020): Transparenz bei
Medienintermedi&#228;ren. 1. Auflage. Leipzig: VISTAS Verlag.
Schwartz, Samuel I. (2015): Street smart. The rise of cities and the fall of cars. Unter Mitarbeit von William
Rosen. 1. Aufl. New York: PublicAffairs.
Schwarzenbach, Robin (2019): &#171;Blended Learning&#187;, &#171;Game-Based-Learning&#187; und andere Unbekannte: Je
digitaler der Unterricht, desto besser die Weiterbildung? Der technologische Wandel hat auch die
Anbieter berufsbegleitender Studieng&#228;nge fest im Griff &#8211; so fest gar, dass einige digitaler unterrichten
wollen, als es Kursteilnehmern lieb ist. In: nzz.ch, 28. November 2019. Online verf&#252;gbar unter
https://www.nzz.ch/schweiz/blended-learning-game-based-learning-und-andere-unbekannte-je-digitaler-
desto-besser-in-der-weiterbildung-ld.1524881, zuletzt abgerufen am 06.08.2020.
Schweiger, Wolfgang; Weber, Patrick; Prochazka, Fabian; Br&#252;ckner, Lara (2019): Algorithmisch 
personalisierte Nachrichtenkan&#228;le. Begriffe, Nutzung, Wirkung. 1. Auflage 2019. Wiesbaden: Springer
Fachmedien Wiesbaden GmbH. Online verf&#252;gbar unter http://www.springer.com/.
Schweitzer, Heike; Haucap, Justus; Kerber, Wolfgang; Welker, Robert (2018): Modernisierung der
Missbrauchsaufsicht f&#252;r marktm&#228;chtige Unternehmen. Endbericht. Hg. v. Dice Consult GmbH. Online
verf&#252;gbar unter https://www.bmwi.de/Redaktion/DE/Publikationen/Wirtschaft/modernisierung-der-
missbrauchsaufsicht-fuer-marktmaechtige-unternehmen.pdf?__blob=publicationFile&amp;v=15, zuletzt
abgerufen am 05.08.2020.
Schwemmle, Michael; Wedde, Peter (2018): Alles unter Kontrolle? Arbeitspolitik und Arbeitsrecht in digitalen
Zeiten &#8211; WISO Diskurs 2/2018. Hg. v. Friedrich-Ebert-Stiftung. Online verf&#252;gbar unter
https://library.fes.de/pdf-files/wiso/14087.pdf, zuletzt abgerufen am 20.07.2020.
scinexx das Wissensmagazin (2018): Bessere Sepsis dank KI? Selbstlernende Systeme k&#246;nnten bei der
Behandlung von Blutvergiftungen helfen. Online verf&#252;gbar unter
https://www.scinexx.de/news/technik/bessere-sepsis-therapie-dank-ki/, zuletzt aktualisiert am
23.10.2018, zuletzt abgerufen am 09.07.2020.
Semiconductor Industry Association; Semiconductor Research Corporation (2015): Rebooting the IT
Revolution: A call to action. Online verf&#252;gbar unter
https://eps.ieee.org/images/files/Roadmap/Rebooting-the-Revolution-SIA-SRC-09-2015.pdf, zuletzt
abgerufen am 23.07.2020.
Sennaar, Kumba (2020): How America&#8217;s 5 Top Hospitals are Using Machine Learning Today. Hg. v. emerj
The AI Research and Advisory Company. Online verf&#252;gbar unter https://emerj.com/ai-sector-
overviews/top-5-hospitals-using-machine-learning/, zuletzt aktualisiert am 24.03.2020, zuletzt abgerufen 
am 10.07.2020.
Shane, Janelle; Sands, Xe (2019): You look like a thing and I love you. How artificial intelligence works and 
why it's making the world a weirder place. 5 audio discs (5 hr., 30 min.). [New York]: Hachette Audio; 
Blackstone.
Shane, Scott (2017): These Are the Ads Russia Bought on Facebook in 2016. In: nytimes.com 2017,
01. November 2017. Online verf&#252;gbar unter https://www.nytimes.com/2017/11/01/us/politics/russia-
2016-election-facebook.html, zuletzt abgerufen am 15.07.2020.
Shaw, Greg (2019): The Future Computed &#8211; K&#252;nstliche Intelligenz in der Industrie. Hg. v. Microsoft. Online
verf&#252;gbar unter https://wuncontentservice.blob.core.windows.net/berlin-
cms/2019/06/Microsoft_TheFutureComputed_deutsch_Final.pdf, zuletzt abgerufen am 27.07.2020.
Shead, Sam (2019): DeepMind and Google Train AI To Predict Energy Output Of Wind Farms. In: forbes.com, 
27. Februar 2019. Online verf&#252;gbar unter https://www.forbes.com/sites/samshead/2019/02/27/deepmind-
and-google-train-ai-to-predict-energy-output-of-wind-farms/#4dd46bf95e9e, zuletzt abgerufen am
07.08.2020.
Shi, Ming (2018): Die KP liest immer mit. In: Zeit.de, 10. Mai 2018. Online verf&#252;gbar unter
https://www.zeit.de/wirtschaft/2018-04/china-digitalisierung-ueberwachung-online-shopping-konsum, 
zuletzt abgerufen am 23.07.2020.
Sicking, Joachim; Voss, Angi; Wirtz, Tim; Paul, Nathalie (2019): Maschinelles Lernen &#8222;On the Edge&#8220;. 
Hg. v Fraunhofer-Institut f&#252;r Intelligente Analyse- und Informationssysteme IAIS. Online verf&#252;gbar
unter
https://www.iais.fraunhofer.de/content/dam/iais/pr/pi/2019/WhitepaperMachineLearningontheedge/Whit 
epaper_Machine-Learning-on-the-edge_FraunhoferIAIS.pdf, zuletzt abgerufen am 22.07.2020.
Siebert, Maximilian (2019): Robotische Assistenz in der Pflege. Hg. v. RWTH Aachen. Institut f&#252;r
Angewandte Medizintechnik. Online verf&#252;gbar unter https://www.ame.rwth-
aachen.de/cms/AME/Forschung/RPE-Rehabilitations-und-
Praeventionst/Rehabilitation/~donpt/PfleKoRo/, zuletzt aktualisiert am 16.09.2019, zuletzt abgerufen am
18.09.2020.
Siegel, Tatjana (2020): Warner Bros. Signs Deal for AI-Driven Film Management System (Exclusive).
Hg. v The Hollywood Reporter. Online verf&#252;gbar unter
https://www.hollywoodreporter.com/news/warner-bros-signs-deal-ai-driven-film-management-system-
1268036, zuletzt aktualisiert am 08.01.2020, zuletzt abgerufen am 15.07.2020.
Simmel, Georg (1908): Soziologie: Untersuchungen &#252;ber die Formen der Vergesellschaftung. Leipzig: Duncker
&amp; Humblot.
Sindermann, Cornelia; Elhai, Jon D.; Moshagen, Morten; Montag, Christian (2020): Age, gender, personality, 
ideological attitudes and individual differences in a person's news spectrum: how many and who might
be prone to&#8220;filterbubbles&#8221;and&#8220;echo chambers&#8221;online? Hg. v. Elsevier Ltd. Online verf&#252;gbar unter
https://reader.elsevier.com/reader/sd/pii/S2405844020300591?token=F65B2D13C70F54464EE7A1AC2 
A5A5E2CA800DA315AA50D37DF0CEAB60A57040FA42975FA7712BC29554D413327AB581A, 
zuletzt abgerufen am 03.08.2020.
Singh, Julian (2017): Open data 101. The latest trends, challenges and research in government open data. First
edition (1.0). Erindale, Australian Capital Territory: Cooee Press.
Smart Cities New York (2018): Smart Cities New York. Online verf&#252;gbar unter https://smartcitiesny.com/,
zuletzt abgerufen am 16.07.2020.
Smart School by bitkom: Smart Schools in Deutschland. Online verf&#252;gbar unter https://smart-
school.de/de/bitkom/org/Smart-School/Smart-Schools-Deutschland, zuletzt abgerufen am 16.07.2020.
smart-city-berlin.de (2019): Berlin ist Vorreiter f&#252;r K&#252;nstliche Intelligenz in Deutschland. Online verf&#252;gbar
unter https://www.smart-city-berlin.de/news/newsdetail/berlin-ist-vorreiter-fuer-kuenstliche-intelligenz-
in-deutschland/, zuletzt aktualisiert am 18.04.2019, zuletzt abgerufen am 16.07.2020.
Smith, Aaron (2018): Public Attitudes Toward Computer Algorithms. Americans express broad concerns over
the fairness and effectiveness of computer programs making important decisions in people&#8217;s lives. Hg. v. 
Pew Research Center. Online verf&#252;gbar unter https://www.pewinternet.org/wp-
content/uploads/sites/9/2018/11/PI_2018.11.19_algorithms_FINAL.pdf, zuletzt abgerufen am
05.08.2020.
Smith, Rory (2020): The UK Election Showed Just How Unreliable Facebook&#8217;s Security System For Elections
Really Is. Hg. v. Inc. BuzzFeed. Online verf&#252;gbar unter
https://www.buzzfeednews.com/article/rorysmith/the-uk-election-showed-just-how-unreliable-
facebooks, zuletzt aktualisiert am 14.01.2020, zuletzt abgerufen am 03.08.2020.
S&#246;bbing, Thomas (2019): Fundamentale Rechtsfragen zur k&#252;nstlichen Intelligenz. In: Rethinking Law (1),
S. 33&#8211;39.
Soike, Roman; Libbe, Jens (2018): Smart Cities in Deutschland &#8211; eine Bestandsaufnahme. 1. Aufl.: Deutsches
Institut f&#252;r Urbanistik (Difu-Papers).
Spacenus GmbH: Spacenus. Online verf&#252;gbar unter https://spacenus.com/what-we-do, zuletzt abgerufen am
15.07.2020.
Spangenberg, Jochen (2015): Soziale Medien und journalistische Berichterstattung. In: Mike Friedrichsen und 
Roland Kohn (Hg.): Digitale Politikvermittlung. Chancen und Risiken interaktiver Medien, Bd. 8. 2., 
korrigierte Aufl. 2015. Wiesbaden: Springer VS, 110, zuletzt abgerufen am 29.07.2020.
Spath, Dieter (2013): Produktionsarbeit der Zukunft &#8211; Industrie 4.0. Studie. Fraunhofer-Institut f&#252;r 
Arbeitswirtschaft und Organisation. Stuttgart: Fraunhofer-Verl. Online verf&#252;gbar unter
http://web.archive.org/web/20140729000428/http://www.iao.fraunhofer.de/images/iao-
news/produktionsarbeit-der-zukunft.pdf, zuletzt abgerufen am 22.07.2020.
Spencer, Scott (2019): An update on our political ads policy. Hg. v. Google LLC. Online verf&#252;gbar unter
https://www.blog.google/technology/ads/update-our-political-ads-policy/, zuletzt aktualisiert am
20.11.2019, zuletzt abgerufen am 03.08.2020.
Spiecker genannt D&#246;hmann, Indra (2019): Digitale Mobilit&#228;t: Plattform Governance. IT-Sicherheits- und 
datenschutzrechtliche Implikationen. In: Gewerblicher Rechtschutz und Urheberrecht (4), S. 341&#8211;352.
spiegel.de (2020): Hohes Tempo Hauptgrund f&#252;r Verkehrstote. Unfallstatistik f&#252;r Autobahnen. In: spiegel.de, 
14. Januar 2020. Online verf&#252;gbar unter https://www.spiegel.de/auto/unfallstatistik-zu-hohes-tempo-
hauptgrund-fuer-unfalltote-auf-autobahnen-a-7da17506-309e-41f6-94d0-55691122e55c, zuletzt
abgerufen am 28.07.2020.
Spiekermann, Markus (2019): Chancen und Herausforderungen in der Daten&#246;konomie. In: Aus Politik und 
Zeitgeschichte 69 (24-26), S. 16&#8211;21, zuletzt abgerufen am 20.07.2020.
Springer Medizin (2019): Roboter in der Pflege &#8212; Ein Ausweg aus dem Personalnotstand? In: Geriatr Rep 14
(2), S. 6&#8211;7. 
Staab, Philipp (2016): Falsche Versprechen. Wachstum im digitalen Kapitalismus. Hamburg: Hamburger
Edition. Online verf&#252;gbar unter http://www.hamburger-edition.de.
Staab, Philipp; Geschke, Sascha-Christopher (2019): Ratings als arbeitspolitisches Konfliktfeld. Das Beispiel 
Zalando. D&#252;sseldorf: Hans-B&#246;ckler-Stiftung (Study / Hans-B&#246;ckler-Stiftung, Nr. 429). Online verf&#252;gbar
unter https://www.econstor.eu/bitstream/10419/203256/1/1676925716.pdf, zuletzt abgerufen am
17.07.2020.
Stadt N&#252;rnberg (2018): Echtes Pionierst&#252;ck: N&#252;rnbergs automatische U-Bahn. Online verf&#252;gbar unter
https://www.nuernberg.de/internet/digitales_nuernberg/automatische_ubahn_nuernberg.html, zuletzt
abgerufen am 24.07.2020.
Stanford University (25.01.2017): Deep learning algorithm does as well as dermatologists in identifying skin 
cancer. Stanford. Kubota, Taylor, tkubota@stanford.edu. Online verf&#252;gbar unter
https://news.stanford.edu/2017/01/25/artificial-intelligence-used-identify-skin-cancer/, zuletzt abgerufen
am 09.07.2020.
Stark, Birgit; Magin, Melanie; J&#252;rgens, Pascal (2017): Ganz meine Meinung? Informationsintermedi&#228;re und 
Meinungsbildung &#8211; eine Mehrmethodenstudie am Beispiel von Facebook. D&#252;sseldorf: Landesanstalt f&#252;r
Medien Nordrhein-Westfalen (LfM) (LfM-Dokumentation, Band 55). Online verf&#252;gbar unter
https://publikationen.medienanstalt-nrw.de/index.php?view=product_detail&amp;product_id=492.
Statista (2015): Prognose der L&#228;nder mit den h&#246;chsten Ums&#228;tzen der Medien- und Unterhaltungsbranche
weltweit im Jahr 2019 (in Milliarden US-Dollar). PWC. Online verf&#252;gbar unter
https://de.statista.com/statistik/daten/studie/232876/umfrage/prognose-zum-umsatz-in-den-groessten-
medienmaerkten-weltweit/, zuletzt aktualisiert am Juni 2015, zuletzt abgerufen am 17.07.2020.
Statista (2017): Semiconductor industry revenues forecast worldwide, from 2016 to 2024. Inkwood Research. 
Online verf&#252;gbar unter https://www.statista.com/statistics/809662/global-semiconductor-market-
revenue-forecast/, zuletzt abgerufen am 27.07.2020.
Statista (2018): Konkurrenz nimmt Amazon weiter Marktanteile ab. Gesch&#228;tzter Anteil am weltweiten Smart
Speaker-Absatz (in %). Strategy Analytics. Online verf&#252;gbar unter
https://de.statista.com/infografik/15159/geschaetzter-anteil-am-weltweiten-smart-speaker-absatz/, zuletzt 
abgerufen am 07.08.2020.
Statista (2018): Ranking der gr&#246;&#223;ten Medienkonzerne weltweit nach Umsatz 2018. Institut f&#252;r Medien- und 
Kommunikationspolitik gGmbH. Online verf&#252;gbar unter
https://de.statista.com/statistik/daten/studie/182990/umfrage/die-25-groessten-medienkonzerne-nach-
umsatz/, zuletzt abgerufen am 28.07.2020.
Statista (2018): Anteil von Stadt- und Landbewohnern in Deutschland von 1990 bis 2015 und Prognose bis
2050. United Nations Population Division Department of Economic and Social Affairs. Online verf&#252;gbar
unter https://de.statista.com/statistik/daten/studie/167166/umfrage/prognose-des-bewohneranteils-nach-
wohnstandort-seit-1990/, zuletzt abgerufen am 23.07.2020.
Statista (2018): Anzahl der Haushalte mit Bezug von Wohngeld in Deutschland von 1991 bis 2017. 
Statistisches Bundesamt. Online verf&#252;gbar unter
https://de.statista.com/statistik/daten/studie/72180/umfrage/wohngeld---empfaenger-in-deutschland-seit-
1996/, zuletzt abgerufen am 22.07.2020.
Statista (2019): Ausgaben f&#252;r Social-Media-Werbung in Deutschland in den Jahren 2017 und 2018 sowie eine
Prognose bis 2023. Statista; Statista Digital Market Outlook. Online verf&#252;gbar unter
https://de.statista.com/statistik/daten/studie/456177/umfrage/umsaetze-mit-social-media-werbung-in-
deutschland/, zuletzt abgerufen am 29.08.2020.
Statista (2019): Marktwert der gr&#246;&#223;ten Internetunternehmen weltweit im Juni 2019. S&amp;P Capital IQ; Bond. 
Online verf&#252;gbar unter https://de.statista.com/statistik/daten/studie/217485/umfrage/marktwert-der-
groessten-internet-firmen-weltweit/, zuletzt abgerufen am 28.07.2020.
Statista (2019): Prognose der weltweiten Ausgaben f&#252;r Suchmaschinenwerbung bis 2023. Statista; Statista
Digital Market Outlook. Online verf&#252;gbar unter
https://de.statista.com/statistik/daten/studie/457519/umfrage/weltweite-umsaetze-mit-
suchmaschinenwerbung/, zuletzt abgerufen am 29.07.2020.
Statista (2019): Ranking der gr&#246;&#223;ten Medienkonzerne in Europa nach ihrem Umsatz im Jahr 2018 (in
Milliarden Euro). Institut f&#252;r Medien- und Kommunikationspolitik. Online verf&#252;gbar unter
https://de.statista.com/statistik/daten/studie/699042/umfrage/die-groessten-medienkonzerne-in-europ
anach-umsatz/, zuletzt abgerufen am 10.08.2020.
Statista (2019): Umsatz von ausgew&#228;hlten Internet- und Tech-Unternehmen weltweit im Jahr 2019. Apple;
Amazon; Microsoft; Facebook; Alphabet. Online verf&#252;gbar unter
https://de.statista.com/statistik/daten/studie/187086/umfrage/internetunternehmen-nach-ihrem-umsatz-
weltweit/, zuletzt abgerufen am 28.07.2020.
Statista (2019): Weitester Nutzerkreis (Nutzung mindestens selten) ausgew&#228;hlter Medien in Deutschland in den 
Jahren 2014 bis 2019. SevenOne Media. Online verf&#252;gbar unter
https://de.statista.com/statistik/daten/studie/614237/umfrage/weitester-nutzerkreis-ausgewaehlter-
medien-in-deutschland/, zuletzt abgerufen am 07.08.2020.
Statista (2019): Ist an Ihrer Schule in allen Klassen- und Fachr&#228;umen ein Zugang zu schnellem Internet und 
WLAN verf&#252;gbar? Verband Bildung und Erziehung. Online verf&#252;gbar unter
https://de.statista.com/statistik/daten/studie/1004594/umfrage/umfrage-zur-verfuegbarkeit-von-
schnellem-internet-und-wlan-in-klassenzimmern/, zuletzt abgerufen am 06.08.2020.
Statista (2019): Welche Akzeptanzprobleme sehen Sie beim Autonomen Fahren? DHBW Ravensburg. Online
verf&#252;gbar unter https://de.statista.com/statistik/daten/studie/270612/umfrage/nachteile-von-autonomen-
fahrzeugen/, zuletzt abgerufen am 28.07.2020.
Statista (2019): Anzahl der mit BAf&#246;G gef&#246;rderten Studierenden und Sch&#252;ler von 1991 bis 2018. Statistisches
Bundesamt. Online verf&#252;gbar unter https://de.statista.com/statistik/daten/studie/75074/umfrage/anzahl-
der-schueler-und-studenten-die-bafoeg-beziehen-seit-1998/, zuletzt abgerufen am 23.07.2020.
Statista (2019): W&#252;rden Sie ein autonom fahrendes Auto nutzen? Aral. Online verf&#252;gbar unter
https://de.statista.com/statistik/daten/studie/270596/umfrage/interesse-an-autonomen-fahrzeugen/, 
zuletzt abgerufen am 28.07.2020.
Statista (2019): Entwicklung der verkauften Auflage der Tageszeitungen in Deutschland in ausgew&#228;hlten 
Jahren von 1991 bis 2019. BDZV Bundesverband Digitalpublisher und Zeitungsverleger e. V. Online
verf&#252;gbar unter https://de.statista.com/statistik/daten/studie/72084/umfrage/verkaufte-auflage-von-
tageszeitungen-in-deutschland/, zuletzt abgerufen am 03.09.2020.
Statista (2020): Amazon &#8211; Nummer 1 mit knappem Vorsprung. Gesch&#228;tzter weltweiter Smartspeaker-Absatz 
(in Mio.). Strategy Analytics. Online verf&#252;gbar unter
https://de.statista.com/infografik/20675/geschaetzter-weltweiter-smart-speaker-absatz/, zuletzt abgerufen
am 07.08.2020.
Statista (2020): Anteil der Verkehrstr&#228;ger an den weltweiten CO2-Emissionen aus der Verbrennung fossiler 
Brennstoffe im Jahr 2016. Bundesverband der Deutschen Luftverkehrswirtschaft. Online verf&#252;gbar unter
https://de.statista.com/statistik/daten/studie/317683/umfrage/verkehrsttraeger-anteil-co2-emissione
nfossile-brennstoffe/, zuletzt abgerufen am 23.07.2020.
Statista (2020): Entwicklung der durchschnittlichen t&#228;glichen Nutzungsdauer des Internets in Deutschland in 
den Jahren 2000 bis 2018 (in Minuten). ARD; ZDF. Online verf&#252;gbar unter
https://de.statista.com/statistik/daten/studie/1388/umfrage/taegliche-nutzung-des-internets-in-minuten/,
zuletzt abgerufen am 07.08.2020.
Statista (2020): Marktanteile der Suchmaschinen weltweit nach mobiler und station&#228;rer Nutzung im Juni 2020. 
NetMarketShare. Online verf&#252;gbar unter
https://de.statista.com/statistik/daten/studie/222849/umfrage/marktanteile-der-suchmaschinen-weltweit/,
zuletzt abgerufen am 28.07.2020.
Statista (2020): Marktanteile von Social-Media-Portalen in Deutschland von M&#228;rz 2019 bis Juni 2020. 
StatCounter. Online verf&#252;gbar unter
https://de.statista.com/statistik/daten/studie/559470/umfrage/marktanteile-von-social-media-seiten-
indeutschland/, zuletzt abgerufen am 28.07.2020.
Statista (2020): Mobile POS Payments &#8211; China. Online verf&#252;gbar unter
https://de.statista.com/outlook/331/117/mobile-pos-payments/china#market-marketDriver, zuletzt
abgerufen am 23.07.2020.
Statista (2020): Nettowerbeeinnahmen der Tageszeitungen in Deutschland in den Jahren 1995 bis 2019 (in 
Millionen Euro). Nettowerbeums&#228;tze der Tageszeitungen bis 2019. ZAW. Online verf&#252;gbar unter
https://de.statista.com/statistik/studie/id/45947/dokument/printwerbung/, zuletzt abgerufen am
10.08.2020.
Statista (2020): Reichweite der Top-15-Nachrichtenseiten in Deutschland im Juni 2020. agof. Online verf&#252;gbar
unter https://de.statista.com/statistik/daten/studie/165258/umfrage/reichweite-der-meistbesuchten-
nachrichtenwebsites/, zuletzt abgerufen am 27.07.2020.
Statista (2020): Revenues from the artificial intelligence (AI) software market worldwide from 2018 to 2025. 
Tractica. Online verf&#252;gbar unter https://www.statista.com/statistics/607716/worldwide-artificial-
intelligence-market-revenues/, zuletzt abgerufen am 23.07.2020.
Statista (2020): Social Networks mit den meisten Nutzern weltweit 2020. We Are Social; Hootsuite; 
DataReportal. Online verf&#252;gbar unter https://de.statista.com/statistik/daten/studie/181086/umfrage/die-
weltweit-groessten-social-networks-nach-anzahl-der-user/, zuletzt abgerufen am 28.07.2020.
Statista (2020): Statista-Dossier zu YouTube. Online verf&#252;gbar unter
https://de.statista.com/statistik/studie/id/12089/dokument/youtube-statista-dossier/, zuletzt abgerufen am
30.07.2020.
Statista (2020): Ums&#228;tze im Home-Video-Markt und im Kinomarkt in Deutschland in den Jahren 2000 bis
2019 (in Millionen Euro). FFA. Online verf&#252;gbar unter
https://de.statista.com/statistik/daten/studie/4154/umfrage/umsatzentwicklung-von-home-video-und-
kino-seit-1999/, zuletzt abgerufen am 10.08.2020.
Statista (2020): Werbeums&#228;tze von Facebook nach Regionen vom 1. Quartal 2013 bis zum 2. Quartal 2020(in 
Millionen US-Dollar). Facebook. Online verf&#252;gbar unter
https://de.statista.com/statistik/daten/studie/164678/umfrage/werbeumsaetze-von-facebook-nach-region/.
Statista (2020): Anzahl der Kinder in Kindertageseinrichtungen in Deutschland nach Bundesl&#228;ndern am
1. M&#228;rz 2019. Statistisches Bundesamt. Online verf&#252;gbar unter
https://de.statista.com/statistik/daten/studie/311750/umfrage/kinder-in-kindertageseinrichtungen-in-
deutschland-nach-bundeslaendern/, zuletzt abgerufen am 22.07.2020.
Statista (2020): Hartz IV: Anzahl der Leistungsempf&#228;nger von Arbeitslosengeld II und Sozialgeld im
Jahresdurchschnitt von 2010 bis 2020. Bundesagentur f&#252;r Arbeit. Online verf&#252;gbar unter
https://de.statista.com/statistik/daten/studie/242062/umfrage/leistungsempfaenger-von-arbeitsloseng
eldii-und-sozialgeld/, zuletzt abgerufen am 22.07.2020.
Statistisches Bundesamt (2018): Kosten der Krankenh&#228;user nach Bundesl&#228;ndern. Online verf&#252;gbar unter
https://www.destatis.de/DE/Themen/Gesellschaft-Umwelt/Gesundheit/Krankenhaeuser/Tabellen/kosten-
krankenhaeuser-bl.html;jsessionid=1D7DE9A9D18A9BA540AE774EA9EA1611.internet731, zuletzt
abgerufen am 10.07.2020.
Steck, Ralf (2017): Augmented Reality in der Logistik: Wegweiser in der Brille. Hg. v. INFORM GmbH. 
Online verf&#252;gbar unter https://www.inform-software.de/blog/post/augmented-reality-in-der-logistik-
wegweiser-in-der-brille, zuletzt abgerufen am 15.07.2020.
Stephani, Victor; Busse, Reinhard; Geissler, Alexander (2019): Benchmarking der Krankenhaus-IT:
Deutschland im internationalen Vergleich. In: J&#252;rgen Klauber, Max Geraedts, J&#246;rg Friedrich und J&#252;rgen 
Wasem (Hg.): Krankenhaus-Report 2019. Berlin, Heidelberg: Springer Berlin Heidelberg.
Steuer, Helmut (2020): Spotify &#252;bertrifft Erwartungen &#8211; verdient aber noch immer kein Geld. In:
Handelsblatt.com 2020, 29. April 2020. Online verf&#252;gbar unter https://www.handelsblatt.com/technik/it-
internet/musik-streaming-spotify-uebertrifft-erwartungen-verdient-aber-noch-immer-
keingeld/25787560.html?ticket=ST-13080916-BewumnCFBjiACxQnyjyN-ap6, zuletzt abgerufen am
27.07.2020.
Strubell, Emma; Ganesh, Ananya; McCallum, Andrew (2019): Energy and Policy Considerations for Deep
Learning in NLP. College of Information and Computer Sciences University of Massachusetts Amherst. 
Online verf&#252;gbar unter https://arxiv.org/pdf/1906.02243.pdf, zuletzt abgerufen am 07.08.2020.
Str&#252;ker, Jens; Albrecht, Simon; Schmid, Jan; Utz, Manuel; Mohr, Robin; Weber, Bernd et al. (2019): European 
Energy Lab 2030. Digitale Echtzeit-Energiewirtschaft &#8211; Bausteine f&#252;r ein marktwirtschaftliches
Zielmodell. Hg. v. Wirtschaftsrat der CDU e. V. Online verf&#252;gbar unter https://energylab2030.eu/wp-
content/uploads/2019/03/Leitstudie_EnergyLab2030.pdf, zuletzt abgerufen am 07.08.2020.
Stubbe, Julian; Mock, Johannes; Wischmann, Steffen (2019): Akzeptanz von Servicerobotern: Tools und 
Strategien f&#252;r den erfolgreichen betrieblichen Einsatz. Hg. v. Begleitforschung PAiCE. iit-Institut f&#252;r
Innovation und Technik in der VDI / VDE Innovation + Technik GmbH. Online verf&#252;gbar unter
https://www.digitale-
technologien.de/DT/Redaktion/DE/Downloads/Publikation/PAiCE_Servicerobotik_Studie.pdf?__blob=p 
ublicationFile&amp;v=6, zuletzt abgerufen am 09.07.2020.
St&#252;ber, J&#252;rgen (2018): Siemens zeigt in Potsdam erste fahrerlose Tram der Welt. In: welt.de, 06. September
2018. Online verf&#252;gbar unter https://www.welt.de/wirtschaft/webwelt/article181435642/Autonome-
Strassenbahn-Siemens-testet-erste-fahrerlose-Tram-in-Potsdam.html, zuletzt abgerufen am 03.08.2020.
St&#252;ber, J&#252;rgen (2018): Rolls-Royce schafft ein Forschungszentrum f&#252;r K&#252;nstliche Intelligenz. Hg. v. ngin-
mobility.com. Online verf&#252;gbar unter https://ngin-mobility.com/amp/rolls-royce-triebwerk-ki, zuletzt 
abgerufen am 03.08.2020.
Susskind, Richard E.; Susskind, Daniel (2017): The future of the professions. How technology will transform
the work of human experts. Oxford: Oxford University Press.
Synergy research group (2019): Chasing Pack Gain Market Share in Q1 but Amazon Maintains a Clear Lead.
Online verf&#252;gbar unter https://www.srgresearch.com/articles/chasing-pack-gain-market-share-q1-
amazon-maintains-clear-lead, zuletzt abgerufen am 21.07.2020.
tagesschau.de (2019): Medienstaatsvertrag &#8211; Grundregeln f&#252;r die digitale Welt. Online verf&#252;gbar unter
https://www.tagesschau.de/inland/medienstaatsvertrag-rundfunkstaatsvertrag-101.html, zuletzt
aktualisiert am 05.12.2019, zuletzt abgerufen am 29.07.2020.
Technische Universit&#228;t Kaiserslautern: Lerntypen. Online verf&#252;gbar unter https://service.zfl.uni-
kl.de/wp/glossar/lerntypen?print=print, zuletzt abgerufen am 06.08.2020.
Technische Universit&#228;t M&#252;nchen (19.06.2019): K&#252;nstliche Intelligenz enttarnt Fake-Videos. Software
FaceForensics erkennt Fake-Videos am zuverl&#228;ssigsten. Nie&#223;ner, Matthias, Lehrstuhl f&#252;r Visual
Computing. Online verf&#252;gbar unter https://www.tum.de/nc/die-
tum/aktuelles/pressemitteilungen/details/35501/, zuletzt abgerufen am 20.07.2020.
Telekom Deutschland GmbH (2018): Beginn einer neuen Medien&#228;ra: Mehr M&#246;glichkeiten Dank Cloud 
Computing. Online verf&#252;gbar unter https://open-telekom-
cloud.com/resource/blob/data/161412/72705cd017ea1bf384daded3a59075b3/cloud-computing-
whitepaper.pdf, zuletzt aktualisiert am Oktober 2018, zuletzt abgerufen am 15.07.2020.
Th&#228;nert, Sabine; Unger, Marina (2019): Linked Data in der iDAI.world. &#8211; am Beispiel des Projekts &#8222;Gelehrte,
Ausgr&#228;ber und Kunsth&#228;ndler: Die Korrespondenz des Insttuto di Corrispondenza Archeologica als
Wissensquelle und Netzwerkindikator&#8220; am Deutschen Arch&#228;ologischen Insttut. In: Informationspraxis.
The Shift Project (2019): Lean ICT: Towards digital sobriety. Online verf&#252;gbar unter
https://theshiftproject.org/wp-content/uploads/2019/03/Lean-ICT-Report_The-Shift-Project_2019.pdf, 
zuletzt abgerufen am 04.08.2020.
Thompson, Nicholas (2017): Our Minds Have Been Hijacked by Our Phones. Tristan Harris Wants to Rescue
Them. Hg. v. Wired. Online verf&#252;gbar unter https://www.wired.com/story/our-minds-have-been-
hijacked-by-our-phones-tristan-harris-wants-to-rescue-them/, zuletzt aktualisiert am 26.07.2017, zuletzt
abgerufen am 31.07.2020.
Tobias, Michael (2018): How New York is becoming a smart city. Hg. v. ny-engineers.com. Online verf&#252;gbar
unter https://www.ny-engineers.com/blog/how-new-york-is-becoming-a-smart-city, zuletzt aktualisiert 
am 06.09.2018, zuletzt abgerufen am 16.07.2020.
TomTom: Traffic Index. 2019. Online verf&#252;gbar unter https://www.tomtom.com/en_gb/traffic-index/ranking/, 
zuletzt abgerufen am 23.07.2020.
Toyota: Selbstfahrende Autos. Wie nah sind wir am autonomen Fahren? Online verf&#252;gbar unter
https://www.toyota.de/news/ratgeber/selbstfahrende-autos, zuletzt abgerufen am 24.07.2020.
Triola, Carmen (2016): Chatbots offers free legal aid to the homeless. Hg. v. mashable.com. Online verf&#252;gbar
unter https://mashable.com/2016/08/10/robot-lawyer-bot/?europe=true, zuletzt abgerufen am
14.07.2020.
Tufekci, Zeynep (2018): How social media took us from Tahrir Square to Donald Trump. Hg. v. MIT
Technology Review. Online verf&#252;gbar unter
https://www.technologyreview.com/2018/08/14/240325/how-social-media-took-us-from-tahrir-square-
to-donald-trump/, zuletzt aktualisiert am 14.08.2018, zuletzt abgerufen am 04.08.2020.
T&#220;V S&#220;D: T&#220;V S&#220;D testet neue Methode zur Inspektion von Rotorbl&#228;ttern. Online verf&#252;gbar unter
https://www.tuvsud.com/de-de/branchen/energie/erneuerbare-energien/windenergie/pruefung-
windkraftanlage-drohnen, zuletzt abgerufen am 03.08.2020.
Twitter Inc. (2020): Richtlinie zu hasssch&#252;rendem Verhalten. Online verf&#252;gbar unter
https://help.twitter.com/de/rules-and-policies/hateful-conduct-policy, zuletzt abgerufen am 06.08.2020.
Twitter Inc. (2020): Twitter Netzwerkdurchsetzungsgesetzbericht: Juli &#8211; Dezember 2019. Online verf&#252;gbar
unter https://cdn.cms-twdigitalassets.com/content/dam/transparency-twitter/data/download-netzdg-
report/netzdg-jul-dec-2019.pdf, zuletzt abgerufen am 06.08.2020.
UK Parliament (2019): Disinformation and &#8216;fake news&#8217;: Final Report published. Online verf&#252;gbar unter
https://www.parliament.uk/business/committees/committees-a-z/commons-select/digital-culture-media-
and-sport-committee/news/fake-news-report-published-17-19/, zuletzt abgerufen am 04.08.2020.
Umwelt Bundesamt (2020): Energiebedingte Emissionen. Online verf&#252;gbar unter
https://www.umweltbundesamt.de/daten/energie/energiebedingte-emissionen#energiebedingte-
treibhausgas-emissionen, zuletzt aktualisiert am 11.03.2020, zuletzt abgerufen am 23.07.2020.
Umweltbundesamt (2019): Berichterstattung unter der Klimarahmenkonvention der Vereinten Nationen und 
dem Kyoto-Protokoll 2019. Nationaler Inventarbericht zum Deutschen Treibhausgasinventar 1990 &#8211;
2017. Online verf&#252;gbar unter
https://www.umweltbundesamt.de/sites/default/files/medien/1410/publikationen/2019-05-28_cc_23-
2019_nir-2019_0.pdf, zuletzt abgerufen am 03.08.2020.
Unfallforschung der Versicherer (2017): Unf&#228;lle mit schweren Lkw enden oft t&#246;dlich. UDV: Technische
Ma&#223;nahmen schnell umsetzen. Hg. v. Gesamtverband der Deutschen Versicherungswirtschaft e. V. 
Online verf&#252;gbar unter https://udv.de/de/medien/mitteilungen/unfaelle-schweren-lkw-enden-oft-toedlich, 
zuletzt abgerufen am 09.09.2020.
United Nations Office for Disarmament Affairs (2018): Report of the 2018 session of the Group of
Governmental Experts on Emerging Technologies in the Area of Lethal Autonomous Weapons Systems. 
Adoption of the report. Geneva, 9-13 April 2018 and 27-31 August 2018. Online verf&#252;gbar unter
https://www.unog.ch/80256EDD006B8954/(httpAssets)/20092911F6495FA7C125830E003F9A5B/$file 
/CCW_GGE.1_2018_3_final.pdf, zuletzt abgerufen am 20.07.2020.
United Nations. Economic Commission for Europe, European Commission (2001): Terminologie des
kombinierten Verkehrs. Unter Mitarbeit von European Conference of Ministers of Transport. Ohio State
University.
Universit&#228;t der Bundeswehr: MUM-T. Manned-unmanned teaming. Online verf&#252;gbar unter
https://www.unibw.de/fmff/projekte/mum-t, zuletzt abgerufen am 28.07.2020.
Universit&#228;t Hamburg (2019): K&#252;nstliche Intelligenz (KI) erkennt Quantenphasen&#252;berg&#228;nge. Online verf&#252;gbar
unter https://www.uni-hamburg.de/newsroom/presse/2019/pm48.html, zuletzt abgerufen am 16.07.2020.
Universiteit van Amsterdam, Instituut voor Informatierecht (2019): Safeguarding User Freedoms in 
Implementing Article 17 of the Copyright in the Digital Single Market Directive: Recommendations
from European Academics. Online verf&#252;gbar unter https://www.ivir.nl/recommendationsarticle17/,
zuletzt abgerufen am 05.08.2020.
Urban Hub (2018): Smart City 3.0 &#8211; Fragen Sie Barcelona nach der n&#228;chsten Generation von Smart City
(Cities). Online verf&#252;gbar unter http://www.urban-hub.com/de/cities/barcelona-macht-seine-smart-city-
noch-smarter-2/, zuletzt aktualisiert am 13.02.2018, zuletzt abgerufen am 16.07.2020.
Vaish, Nitin (2018): Self-driving Cars and Power Consumption &#8212; New Chip Designs. Hg. v. medium.com. 
Online verf&#252;gbar unter https://medium.com/@nitinvaish/self-driving-cars-and-power-consumption-new-
chip-designs-4c723659f8cd, zuletzt abgerufen am 23.07.2020.
Vena, Danny (2018): Netflix bekommt ein Upgrade von der K&#252;nstlichen Intelligenz. Online verf&#252;gbar unter
https://www.fool.de/2018/03/21/netflix-bekommt-ein-upgrade-von-der-kuenstlichen-intelligenz/, zuletzt 
aktualisiert am 15.03.2018, zuletzt abgerufen am 28.07.2020.
Venkatesh, Viswanath; Morris, Michael G.; Davis, Gordon B.; Davis, Fred D. (2003): User Acceptance of
Information Technology: Toward a Unified View. In: MIS Quarterly 27 (3), S. 425&#8211;478. 
ver.di (2019): ver.di kritisiert System permanenter digitaler Leistungskontrollen und Ratings bei Zalando. 
Online verf&#252;gbar unter https://www.verdi.de/presse/pressemitteilungen/++co++8777f162-0b79-11ea-
a0a2-525400940f89, zuletzt abgerufen am 09.09.2020.
Verband der Elektrotechnik Elektronik Informationstechnik e. V. (2016): Die deutsche Normungsroadmap &#8211;
E-Energy / Smart Grid. Online verf&#252;gbar unter
https://www.dke.de/resource/blob/780292/3ae72fe24a471344af49c56d9ef36265/dke-normungsroadmap-
1-ger-data.pdf, zuletzt abgerufen am 27.07.2020.
Verband der T&#220;V e. V. (2020): Sicherheit und K&#252;nstliche Intelligenz. Erwartungen, Hoffnungen, Emotionen. 
Eine repr&#228;sentative Befragung der Bev&#246;lkerung in Deutschland. Online verf&#252;gbar unter
https://www.vdtuev.de/dok_view?oid=777991, zuletzt abgerufen am 06.08.2020.
Verband der T&#220;V e. V.: Vertrauen in KI-basierte Systeme schaffen (Positionspapier K&#252;nstliche Intelligenz). 
Online verf&#252;gbar unter https://www.vdtuev.de/dok_view?oid=755624, zuletzt abgerufen am 05.08.2020.
Verband Deutscher Verkehrsunternehmen (2019): Autonomer Fahrbetrieb bei Stra&#223;enbahnen. Positionspapier. 
Online verf&#252;gbar unter VDV Verband, Positionspapier &#8222;Autonomer Fahrbetrieb bei Stra&#223;enbahnen&#8220;, 
zuletzt abgerufen am 03.08.2020.
Verband Deutscher Verkehrsunternehmen (2019): 2018 &#8211; Statistik. Online verf&#252;gbar unter
https://www.vdv.de/statistik-jahresbericht.aspx, zuletzt abgerufen am 28.07.2020.
Verbraucherzentrale Brandenburg e. V. (2018): Dynamische Preisdifferenzierung im Online-Handel. Eine
Untersuchung der Verbraucherzentralen. Online verf&#252;gbar unter
https://www.verbraucherzentrale.de/sites/default/files/2019-09/marktwaechter-untersuchung-
dynamische-preisdifferenzierung.pdf, zuletzt abgerufen am 22.07.2020.
Verein Deutscher Ingenieure e. V. (2018): VDI-Statusreport K&#252;nstliche Intelligenz. Online verf&#252;gbar unter
https://www.vdi.de/ueber-uns/presse/publikationen/details/vdi-statusreport-kuenstliche-intelligenz,
zuletzt abgerufen am 27.07.2020.
Vereinigung der Bayerischen Wirtschaft (2020): Resilienz. Schlussfolgerungen aus der Corona-Pandemie.
Handlungsempfehlungen. Zukunftsrat der Bayerischen Wirtschaft. Online verf&#252;gbar unter
https://www.vbw-zukunftsrat.de/downloads/Zukunftsrat-Handlungsempfehlungen-Resilienz.pdf/, zuletzt 
abgerufen am 18.09.2020.
vfa. Die forschenden Pharma-Unternehmen: Personalisierte Medizin &#8211; das beste Medikament f&#252;r den Patienten
finden. Online verf&#252;gbar unter https://www.vfa.de/de/arzneimittel-forschung/personalisierte-
medizin/personalisierte-medizin-das-beste-medikament-fuer-den-patienten-finden.html, zuletzt
abgerufen am 09.07.2020.
Villani, C&#233;dric (2018): For a Meaningful Artificial Intelligence &#8211; Towards a French and European Strategy. 
Online verf&#252;gbar unter https://www.aiforhumanity.fr/pdfs/MissionVillani_Report_ENG-VF.pdf, zuletzt
abgerufen am 23.07.2020.
Vogel, Lukas; Richard, Philipp; Brey, Michael; Mamel, Sara; Sch&#228;tz, Konstatin (2019): K&#252;nstliche Intelligenz
f&#252;r die integrierte Energiewende. Einordnung des technologischen Status quo sowie Strukturierung von 
Anwendungsfeldern in der Energiewirtschaft. dena-ANALYSE. Hg. v. Deutsche Energie-Agentur
GmbH. Online verf&#252;gbar unter https://www.dena.de/fileadmin/dena/Publikationen/PDFs/2019/dena-
ANALYSE_Kuenstliche_Intelligenz_fuer_die_integrierte_Energiewende.pdf, zuletzt abgerufen am
07.08.2020.
Vogler-Ludwig, Kurt; Kriechel, Ben; D&#252;ll, Nicola (2016): Arbeitsmarkt 2030 &#8211; Wirtschaft und Arbeitsmarkt 
im digitalen Zeitalter. Prognose 2016. Bielefeld: W. Bertelsmann Verlag. Online verf&#252;gbar unter
https://library.oapen.org/viewer/web/viewer.html?file=/bitstream/handle/20.500.12657/30964/640936.pd 
f?sequence=1&amp;isAllowed=y, zuletzt abgerufen am 06.08.2020.
Volkswagen AG (2019): Digitale Neuronen &#8222;fahren&#8220; autonom. Online verf&#252;gbar unter
https://www.volkswagenag.com/de/news/stories/2019/06/volkswagen-neural-networks.html, zuletzt
abgerufen am 07.08.2020.
Voss, Oliver (2018): Roboter und Netflix-Konkurrenz aus der Bibliothek. Ob eigene Streamingdienste f&#252;r
Filme oder Lesestunden mit Robotern: Bei der Digitalisierung sind die Berliner B&#252;chereien bundesweite 
Pioniere. In: Der Tagesspiegel, 02. Dezember 2018. Online verf&#252;gbar unter
https://www.tagesspiegel.de/wirtschaft/digitalisierung-roboter-und-netflix-konkurrenz-aus-der-
bibliothek/23704280.html?utm_campaign=Background&amp;utm_medium=Email&amp;utm_source=Tagesspieg 
el_Newsletter, zuletzt abgerufen am 16.07.2020.
Voss, Oliver (2020): &#8222;Wir sind auf dem direkten Weg ins digitale Mittelalter&#8220;. Ehemaliger Google-Entwickler
warnt. In: tagesspiegel.de, 21. Februar 2020. Online verf&#252;gbar unter
https://www.tagesspiegel.de/wirtschaft/ehemaliger-google-entwickler-warnt-wir-sind-auf-dem-direkten-
weg-ins-digitale-mittelalter/25523798.html, zuletzt abgerufen am 09.09.2020.
Wagner, Gerhard (2019): Robot Liability. In: Lohsse, Sebastian; Schulze; Reiner und Staudenmayer, Dirk. 
(Hg.): Liability for artificial intelligence and the internet of things. M&#252;nster Colloquia on EU Law and 
the Digital Economy IV: Hart Publishing, S. 27&#8211;62.
Wagner, William P. (2017): Trends in expert system development: A longitudinal content analysis of over
thirty years of expert system case studies. In: Expert Systems with Applications 76, S. 85&#8211;96. DOI:
10.1016/j.eswa.2017.01.028.
Walker, Eva-Maria (2017): Subjektive Aneignungspraktiken digitaler Technologien und die zugrunde
liegenden Gerechtigkeitsanspr&#252;che der Besch&#228;ftigten. In: Arbeit Zeitschrift f&#252;r Arbeitsforschung,
Arbeitsgestaltung und Arbeitspolitik 26 (3-4), S. 315&#8211;342.
Wallenfels, Matthias (2017): Exoskelette f&#252;r einen leichteren Pflegealltag. Hg. v. &#196;rzte Zeitung. Online
verf&#252;gbar unter https://www.aerztezeitung.de/Wirtschaft/Exoskelette-fuer-einen-leichteren-Pflegealltag-
310658.html, zuletzt aktualisiert am 05.04.2017, zuletzt abgerufen am 10.07.2020.
Wangler, Leo; Botthof, Alfons (2019): E-Governance: Digitalisierung und KI in der &#246;ffentlichen Verwaltung. 
In: Volker Wittpahl (Hg.): K&#252;nstliche Intelligenz. Technologie. Berlin, Heidelberg: Springer Berlin 
Heidelberg, S. 122&#8211;141. Online verf&#252;gbar unter https://link.springer.com/content/pdf/10.1007%2F978-
3-662-58042-4.pdf, zuletzt abgerufen am 22.07.2020.
Warner, Benjamin R.; Neville-Shepard, Ryan (2011): The Polarizing Influence of Fragmented Media: Lessons
From Howard Dean. In: Atlantic Journal of Communication 19 (4), S. 201&#8211;215. 
Waschbusch, Lisa Marie (2019): Digitaler Zwilling: Ein Herzensprojekt. Hg. v. Industry of things. Online
verf&#252;gbar unter https://www.industry-of-things.de/digitaler-zwilling-ein-herzensprojekt-a-812001/, 
zuletzt aktualisiert am 20.03.2019, zuletzt abgerufen am 09.07.2020.
Webster, Graham; Creemers, Rogier; Triolo, Paul; Kania, Elsa: China&#8217;s Plan to &#8216;Lead&#8217; in AI: Purpose, 
Prospects, and Problems. New America. Online verf&#252;gbar unter
https://www.newamerica.org/cybersecurity-initiative/blog/chinas-plan-lead-ai-purpose-prospects-and-
problems/, zuletzt abgerufen am 21.07.2020.
Wedde, Peter (2020): Automatisierung im Personalmanagement &#8211; arbeitsrechtliche Aspekte und
Besch&#228;ftigtendatenschutz. Hg. v. AW AlgorithmWatch gGmbH. Berlin. Online verf&#252;gbar unter
https://algorithmwatch.org/wp-
content/uploads/2020/03/AlgorithmWatch_AutoHR_Gutachten_Arbeitsrecht_Datenschutz_Wedde_202 
0.pdf, zuletzt abgerufen am 06.08.2020.
Weidemann, Tobias (2017): Roboter als Verk&#228;ufer: Media Markt und Saturn gehen neue Wege. In: t3n.de, 09. 
M&#228;rz 2017. Online verf&#252;gbar unter https://t3n.de/news/roboter-verkaeufer-media-markt-saturn-803296/, 
zuletzt abgerufen am 15.07.2020.
Weimann, Thomas; Nagel, Daniel (2011): Unterzeichnung des Geodaten-Kodex &#8211; Mehr als reiner 
Aktionismus. In: lto.de (Legal Tribune Online), 04. M&#228;rz 2011. Online verf&#252;gbar unter
https://www.lto.de/recht/hintergruende/h/unterzeichnung-des-geodaten-kodex-mehr-als-reiner-
aktionismus/, zuletzt abgerufen am 27.07.2020.
Weischenberg, Siegfried; Rakers, Judith (2001): Nachrichten-Journalismus. Anleitungen und Qualit&#228;ts-
Standards f&#252;r die Medienpraxis. 1. Aufl. Wiesbaden: Westdt. Verl.
Weiss, Theresa (2018): Wie ein Algorithmus Studienabbrecher fr&#252;hzeitig erkennt. Fast 30 Prozent der
deutschen Studierenden beenden derzeit die Uni ohne Abschluss. Karlsruher Forscher versuchen nun, 
den Studienabbruch schon fr&#252;h vorherzusagen. Die Trefferquote ist hoch. In: faz.net, 19. Juni 2018. 
Online verf&#252;gbar unter https://www.faz.net/aktuell/karriere-hochschule/campus/wie-ein-algorithmus-
kuenftige-studienabbrecher-fruehzeitig-erkennt-15640650.html, zuletzt abgerufen am 06.08.2020.
Welchering, Peter (2019): Dual-Use-Problematikin der IT-Technik. Risiken der Forschung. Hg. v. 
Deutschlandfunk (Wissenschaft im Brennpunkt). Online verf&#252;gbar unter
https://www.deutschlandfunk.de/risiken-der-forschung-dual-use-problematik-in-der-it-
technik.740.de.html?dram:article_id=440556, zuletzt abgerufen am 20.07.2020.
welt.de (2015): Facebook mutiert zum Nachrichtenportal. In: welt.de, 06. Februar 2015. Online verf&#252;gbar unter
https://www.welt.de/wirtschaft/webwelt/article160309705/Facebook-mutiert-zum-
Nachrichtenportal.html, zuletzt abgerufen am 28.07.2020.
Weltbank (2018): Urban population (% of total population) &#8211; Germany. United Nations Population Division. 
World Urbanization Prospects: 2018 Revision. Online verf&#252;gbar unter
https://data.worldbank.org/indicator/SP.URB.TOTL.IN.ZS?locations=DE, zuletzt abgerufen am
23.07.2020.
Weltorganisation f&#252;r Geistiges Eigentum (2019): Artificial intelligence (WIPO technology trends, 2019). 
Online verf&#252;gbar unter https://www.wipo.int/edocs/pubdocs/en/wipo_pub_1055.pdf, zuletzt abgerufen 
am 21.07.2020.
Weltwirtschaftsforum (2018): Harnessing Artificial Intelligence for the Earth (Fourth Industrial Revolution for
the Earth Series). Online verf&#252;gbar unter
http://www3.weforum.org/docs/Harnessing_Artificial_Intelligence_for_the_Earth_report_2018.pdf, 
zuletzt abgerufen am 07.08.2020.
Welz, Michael (2018): Das Buhlen um den digitalen Nachwuchs. In: computerwoche.de, 26. M&#228;rz 2018. 
Online verf&#252;gbar unter https://www.computerwoche.de/a/das-buhlen-um-den-digitalen-
nachwuchs,3544428, zuletzt abgerufen am 03.08.2020.
Wendehorst, Christiane (2016): Die Digitalisierung und das BGB. In: NJW Neue Juristische Wochenschrift
(36), S. 2609&#8211;2613.
Wiegand, Silke (2019): KI f&#252;r Smart Cities. Technische Hochschule K&#246;ln. Online verf&#252;gbar unter
http://stories.online-redakteure.com/ki-smart-city/, zuletzt aktualisiert am 10.11.2019, zuletzt abgerufen 
am 16.07.2020.
Wien Holding GmbH: Smart City Wien. Online verf&#252;gbar unter https://smartcity.wien.gv.at/site/, zuletzt 
abgerufen am 16.07.2020.
Wietschel, Martin; Pl&#246;tz, Patrick; Pfluger, Benjamin; Klobasa, Marian; E&#223;er, Anke; Haendel, Michael et al.
(2018): Sektorkopplung. Definitionen, Chancen und Herausforderungen. Unter Mitarbeit von 
Technische Universit&#228;t Berlin, Universit&#228;t Kassel, VSE AG, Universit&#228;t Stuttgart, Institut f&#252;r
Energiewirtschaft und Rationelle Energieanwendung und Institut f&#252;r Klimaschutz, Energie und Mobilit&#228;t 
e. V. Hg. v. Fraunhofer-Institut f&#252;r System- und Innovationsforschung (Working Paper Sustainability
and Innovation, S 01/2018). Online verf&#252;gbar unter
https://www.isi.fraunhofer.de/content/dam/isi/dokumente/sustainability-innovation/2018/WP01-
2018_Sektorkopplung_Wietschel.pdf, zuletzt abgerufen am 23.07.2020.
Wijman, Tom (2019): Newzoo&#8217;s Games Trends to Watch in 2020. Online verf&#252;gbar unter
https://newzoo.com/insights/articles/newzoos-games-trends-to-watch-in-2020/, zuletzt aktualisiert am
12.12.2019, zuletzt abgerufen am 28.07.2020.
Wikipedia, Die freie Enzyklop&#228;die (2016): Internist-I. Online verf&#252;gbar unter
https://en.wikipedia.org/w/index.php?title=Internist-I&amp;oldid=757193465, zuletzt aktualisiert am
29.12.2016, zuletzt abgerufen am 09.07.2020.
Wikipedia, Die freie Enzyklop&#228;die (2019): CADUCEUS (expert system). Online verf&#252;gbar unter
https://en.wikipedia.org/w/index.php?title=CADUCEUS_(expert_system)&amp;oldid=887591200, zuletzt
aktualisiert am 13.03.2019, zuletzt abgerufen am 09.07.2020.
Wikipedia, Die freie Enzyklop&#228;die (2020): Movie production incentives in the United States. Online verf&#252;gbar
unter https://en.wikipedia.org/wiki/Movie_production_incentives_in_the_United_States, zuletzt
aktualisiert am 09.04.2020, zuletzt abgerufen am 29.07.2020.
Wikipedia, Die freie Enzyklop&#228;die (2020): Mycin (Expertensystem). Online verf&#252;gbar unter
https://de.wikipedia.org/w/index.php?title=Mycin_(Expertensystem)&amp;oldid=199520702, zuletzt
aktualisiert am 02.05.2020, zuletzt abgerufen am 09.07.2020.
Wikipedia, Die freie Enzyklop&#228;die (2020): Jeremy Howard (entrepreneur). Online verf&#252;gbar unter
https://en.wikipedia.org/w/index.php?title=Jeremy_Howard_(entrepreneur)&amp;oldid=961349882, zuletzt
aktualisiert am 07.06.2020, zuletzt abgerufen am 09.07.2020.
Wirth, R&#252;diger; Hipp, Jochen (2000): CRISP-DM: Towards a standard process model for data mining. In: Neil
Mackin (Hg.): Proceedings of the Fourth International Conference on the Practical Application of
Knowledge Discovery and Data Mining. 11th - 13th April 2000, Crowne Plaza Midland Hotel, 
Manchester, UK. Blackpool, Lancashire: Practical Application Company, S. 29&#8211;40.
Wissenschaftlicher Beirat der Bundesregierung Globale Umweltver&#228;nderungen (WBGU) (2019): Unsere
gemeinsame digitale Zukunft &#8211; Empfehlungen. Online verf&#252;gbar unter
https://www.wbgu.de/fileadmin/user_upload/wbgu/publikationen/hauptgutachten/hg2019/pdf/WBGU_H 
GD2019_Empfehlungen.pdf, zuletzt abgerufen am 23.07.2020. 
Wissenschaftlicher Beirat der Bundesregierung Globale Umweltver&#228;nderungen (WBGU) (2019): Unsere
gemeinsame digitale Zukunft &#8211; Hauptgutachten. Online verf&#252;gbar unter
https://www.wbgu.de/fileadmin/user_upload/wbgu/publikationen/hauptgutachten/hg2019/pdf/wbgu_hg2 
019.pdf, zuletzt abgerufen am 07.10.2020
Wissenschaftlicher Beirat der Bundesregierung Globale Umweltver&#228;nderungen (WBGU) (2019): Unsere
gemeinsame digitale Zukunft &#8211; Zusammenfassung. Online verf&#252;gbar unter
https://www.wbgu.de/fileadmin/user_upload/wbgu/publikationen/hauptgutachten/hg2019/pdf/WBGU_H 
GD2019_Z.pdf, zuletzt abgerufen am 07.10.2020
Wisskirchen, Gerlind; Biacabe, Blandine Thibault; Bormann, Ulrich; Muntz, Annemarie; Niehaus, Gunda;
Soler, Guillermo Jim&#233;nez; Brauchitsch, Beatrice von (2017): Artificial Intelligence and Robotics and 
Their Impact on the Workplace. Hg. v. International Bar Association Global Employment Institute (IBA
GEI). Online verf&#252;gbar unter https://www.ibanet.org/Article/NewDetail.aspx?ArticleUid=012a3473-
007f-4519-827c-7da56d7e3509, zuletzt abgerufen am 05.08.2020.
W&#246;hrmann, Anne Marit; Gerstenberg, Susanne; H&#252;nefeld, Lena; Pundt, Franziska; Reeske-Behrens, Anna;
Brenscheidt, Frank; Beermann, Beate (2016): Arbeitszeitreport Deutschland 2016. 1. Auflage. Hg. v. 
Bundesanstalt f&#252;r Arbeitsschutz und Arbeitsmedizin (BAuA). Dortmund. Online verf&#252;gbar unter
https://www.baua.de/DE/Angebote/Publikationen/Berichte/F2398.pdf?__blob=publicationFile, zuletzt
abgerufen am 03.08.2020.
Wojcicki, Susan (2017): Expanding our work against abuse of our platform. Hg. v. YouTube. Online verf&#252;gbar
unter https://youtube.googleblog.com/2017/12/expanding-our-work-against-abuse-of-our.html, zuletzt
aktualisiert am 04.12.2017, zuletzt abgerufen am 31.07.2020.
World Medical Association (2013): WMA Declaration of Helsinki &#8211; Ethical Principles for Medical Research
Involving Human Subjects. Online verf&#252;gbar unter https://www.wma.net/policies-post/wma-declaration-
of-helsinki-ethical-principles-for-medical-research-involving-human-subjects/, zuletzt abgerufen am
09.07.2020.
Wrobel, Stefan (2019): Wohin geht die Reise bei K&#252;nstlicher Intelligenz? Deep Learning and Beyond. 
Fraunhofer IAIS, 03. Juli 2019. Online verf&#252;gbar unter https://www.plattform-lernende-
systeme.de/jahreskonferenz.html, zuletzt abgerufen am 22.07.2020.
Wu, Katherine (2018): Google&#8217;s New AI Is a Master of Games, but How Does It Compare to the Human 
Mind? In: smithsonianmag.com, 10. Dezember 2018. Online verf&#252;gbar unter
https://www.smithsonianmag.com/innovation/google-ai-deepminds-alphazero-games-chess-and-go-
180970981/, zuletzt abgerufen am 23.07.2020.
Wu, Tim (2017): The attention merchants. The epic scramble to get inside our heads. First Vintage Books
edition.
Yang, Vivien; Schliesmeier, Niklas; Burger, Axel (2020): Die gefilterte Realit&#228;t &#8211; Welchen Anteil haben wir
selbst an der Entstehung von Echo-Kammern? Hg. v. Stichting In-Mind Foundation (4). Online
verf&#252;gbar unter https://de.in-mind.org/article/die-gefilterte-realitaet-welchen-anteil-haben-wir-selbst-an-
der-entstehung-von-
echokammern?page=2&amp;gclid=EAIaIQobChMImoDK39i96AIVV_lRCh24QQoTEAAYASAAEgIZp_D_Bw 
E, zuletzt abgerufen am 04.08.2020.
Yinug, Falan (2018): Semiconductors: A Strategic U.S. Advantage in the Global Artificial Intelligence
Technology Race. Hg. v. Semiconductor Industry Association, zuletzt aktualisiert am
https://www.semiconductors.org/wp-content/uploads/08.08.20181018_SIA_AI_white_paper_-
_FINAL_08092018_with_all_member_edits_with_logo3-1.pdf, zuletzt abgerufen am 23.07.2020.
Zalando SE (2018): Zalando testet Logistikroboter TORU in Erfurt. Im Logistikzentrum Erfurt k&#246;nnten 
zuk&#252;nftig zwei Roboter die Mitarbeiter bei schwierigen Stow- und Pick-Aufgaben unterst&#252;tzen. Online
verf&#252;gbar unter https://corporate.zalando.com/de/newsroom/de/storys/zalando-testet-logistikroboter-
toru-erfurt, zuletzt abgerufen am 15.07.2020.
Zander-Hayat, Helga; Domurath, Irina; Gro&#223;, Christian (2016): Personalisierte Preise. Hg. v.
Sachverst&#228;ndigenrat f&#252;r Verbraucherfragen (SVRV Working Paper, 2). Online verf&#252;gbar unter
https://www.svr-verbraucherfragen.de/wp-content/uploads/SVRV_WP02_Personalisierte-Preise.pdf, 
zuletzt abgerufen am 23.07.2020.
Zanker, Claus; Roth, Ines; Hoppe, Markus (2019): ver.di - Innovationsbarometer 2019 K&#252;nstliche Intelligenz. 
Studie im Auftrag der ver.di-Bundesverwaltung Ressort 13, Bereich Innovation und Gute Arbeit. Hg. v. 
ver.di &#8211; Vereinte Dienstleistungsgewerkschaft Bereich Innovation und Gute Arbeit. Online verf&#252;gbar
unter https://innovation-gute-
arbeit.verdi.de/++file++5dd3f17cd62276747746838b/download/innobaro_KI_RZweb3.pdf, zuletzt
abgerufen am 05.08.2020.
zdf.de (2020): Rechtsgrundlagen und Vorschriften. Online verf&#252;gbar unter
https://www.zdf.de/zdfunternehmen/zdf-rechtsgrundlagen-und-vorschriften-100.html, zuletzt aktualisiert 
am 15.07.2020, zuletzt abgerufen am 29.07.2020.
zdf.de (2020): Klimawandel: Energieschleuder Digitalisierung. Schulze legt Agenda vor. Online verf&#252;gbar 
unter https://www.zdf.de/nachrichten/politik/digitalagenda-umweltministerin-schulze-digitalisierung-
klimawandel-100.html, zuletzt abgerufen am 07.08.2020.
Zehrt, Wolfgang: Roboterjournalismus? Journalisten nutzen Robots! Online verf&#252;gbar unter
http://digitalkommunizieren.de/roboterjournalismus/, zuletzt abgerufen am 30.07.2020.
zeit.de(2019): San Francisco verbietet Gesichtserkennung durch Beh&#246;rden. &#220;berwachung. In: Zeit.de, 15. Mai
2019. Online verf&#252;gbar unter https://www.zeit.de/politik/ausland/2019-05/ueberwachung-
gesichtserkennung-san-francisco-usa-verbot, zuletzt abgerufen am 17.07.2020.
zeit.de (2019): Biometrische Daten von Millionen Nutzern offen im Netz. Hacker. In: Zeit.de, 14. August 2019. 
Online verf&#252;gbar unter https://www.zeit.de/digital/datenschutz/2019-08/hacker-israel-sicherheitsfirma-
suprema-datenschutz, zuletzt abgerufen am 17.07.2020.
zeit.de (2019): Facebook startet neues Nachrichtenangebot f&#252;r seine App. In: Zeit.de, 25. Oktober 2019. Online
verf&#252;gbar unter https://www.zeit.de/digital/2019-10/facebook-news-tab-app-zeitungen-verlage-soziales-
netzwerk?print, zuletzt abgerufen am 29.07.2020.
Zentralverband des deutschen Handwerks (2019): Positionspapier &#8211; Anforderungen des Handwerks an eine
faire Daten&#246;konomie. Online verf&#252;gbar unter
https://www.zdh.de/fileadmin/user_upload/themen/wirtschaft/daten/Positionspapier_Datenoekonomie_2 
0190627.pdf, zuletzt abgerufen am 21.07.2020.
Zika, Gerd; Helmrich, Robert; Maier, Tobias; Weber, Enzo; Wolterm Marc I. (2018): Arbeitsmarkteffekte der
Digitalisierung bis 2035 &#8211; Regionale Branchenstruktur spielt eine wichtige Rolle. Hg. v. IAB &#8211; Institut 
f&#252;r Arbeitsmarkt- und Berufsforschung (IAB Kurzbericht &#8211; Aktuelle Analysen aus dem Institut f&#252;r
Arbeitsmarkt- und Berufsforschung, 9/2018). Online verf&#252;gbar unter
http://doku.iab.de/kurzber/2018/kb0918.pdf, zuletzt abgerufen am 16.07.2020.
Zimmer, Anja (2019): Smart Regulation: Welche Antworten gibt der Medienstaatsvertrag auf die
Regulierungsherausforderungen des 21. Jahrhunderts? &#8211; Ein Blick aus der Regulierungspraxis. In: ZUM, 
S. 126&#8211;130. Online verf&#252;gbar unter https://beck-
online.beck.de/default.aspx?vpath=bibdata/zeits/ZUM/2019/cont/ZUM.2019.126.1.htm, zuletzt
abgerufen am 04.08.2020.
Zimmermann, Hendrik; Frank, David (2019): K&#252;nstliche Intelligenz f&#252;r die Energiewende: Chancen und 
Risiken. Hintergrundpapier. Unter Mitarbeit von Michelle Reuter und Sophie Jahns. Hg. v. 
Germanwatch e. V. Online verf&#252;gbar unter
https://www.germanwatch.org/sites/germanwatch.org/files/K%C3%BCnstliche%20Intelligenz%20f%C3 
%BCr%20die%20Energiewende%20-%20Chancen%20und%20Risiken.pdf, zuletzt abgerufen am
07.08.2020.
Zuboff, Shoshana (2018): Das Zeitalter des &#220;berwachungskapitalismus. Frankfurt, New York: Campus Verlag.
Online verf&#252;gbar unter https://www.content-
select.com/index.php?id=bib%5Fview&amp;ean=9783593439433.
Zuckerman, Ethan (2020): The Case for Digital Public Infrastructure. Hg. v. Knight First Amendment Institute. 
Online verf&#252;gbar unter https://s3.amazonaws.com/kfai-documents/documents/7f5fdaa8d0/Zuckerman-
1.17.19-FINAL-.pdf, zuletzt abgerufen am 04.08.2020.
Zuiderveen Borgesius, Frederik J.; M&#246;ller, Judith; Kruikemeier, Sanne; Fathaigh, Ronan &#211;.; Irion, Kristina;
Dobber, Tom et al. (2018): Online Political Microtargeting: Promises and Threats for Democracy. In:
Utrecht Law Review (14), S. 82&#8211;96. Online verf&#252;gbar unter
https://www.utrechtlawreview.org/articles/abstract/10.18352/ulr.420/, zuletzt abgerufen am 03.08.2020.
Zweig, Katharina A. (2018): Wo Maschinen irren k&#246;nnen. Fehlerquellen und Verantwortlichkeiten in 
Prozessen algorithmischer Entscheidungsfindung. Arbeitspapier. Unter Mitarbeit von Sarah Fischer und 
Konrad Lischka. Hg. v. Bertelsmann Stiftung. Online verf&#252;gbar unter https://www.bertelsmann-
stiftung.de/fileadmin/files/BSt/Publikationen/GrauePublikationen/WoMaschinenIrrenKoennen.pdf, 
zuletzt abgerufen am 22.07.2020.
Zweig, Katharina A. (2019): Algorithmische Entscheidungen: Transparenz und Kontrolle. Hg. v. Konrad-
Adenauer-Stiftung. Berlin (Analysen &amp; Argumente, 338). Online verf&#252;gbar unter
https://www.kas.de/documents/252038/4521287/AA338+Algorithmische+Entscheidungen.pdf/533ef913 
-e567-987d-54c3-1906395cdb81?version=1.0&amp;t=1548228380797, zuletzt abgerufen am 13.07.2020.
Zweig, Katharina A. (2019): Ein Algorithmus hat kein Taktgef&#252;hl. Wo k&#252;nstliche Intelligenz sich irrt, warum
uns das betrifft und was wir dagegen tun k&#246;nnen. Originalausgabe.
Einsetzungsbeschluss
Drucksache 19/23700 &#8211; 666 &#8211; Deutscher Bundestag &#8211; 19. Wahlperiode
Drucksache 19/23700 &#8211; 668 &#8211; Deutscher Bundestag &#8211; 19. Wahlperiode 
Organisation
2.2.1 Zusammensetzung der Enquete-Kommission
Fraktionen Ordentliche Mitglieder Stellvertretende Mitglieder Sachverst&#228;ndige
CDU/CSU Bernstiel, Christoph
(bis 26. September 2019)
Biadacz, Marc 
(ab 27. September 2019)
Durz, Hansj&#246;rg
Kemmer, Ronja
Metzler, Jan
Sauer, Stefan
(stellv. Vorsitzender)
Prof. Dr. Schmidtke, Claudia
Steier, Andreas
Bernstiel, Christoph
(ab 27. September 2019)
Knoerig, Axel
Lange, Ulrich
Schimke, Jana
Schipanski, Tankred
Sch&#246;n, Nadine
Sorge, Tino
Weinberg, Marcus
(bis 26. September 2019)
Dehmel, Susanne
Prof. Dr. Ecker, Wolfgang
Prof. Dr. Filipovi&#263;, Alexander
Dr. Kl&#252;wer, Tina
Prof. Dr. Kr&#252;ger, Antonio
Prof. Dr. M&#252;ller-Lietzkow, J&#246;rg
Dr. Wieczorek, Sebastian
SPD Esken, Saskia
(bis 16. Dezember 2019)
Korkmaz-Emre, Elvan
(ab 17. Dezember 2019)
Kolbe, Daniela (Vorsitzende)
Mohrs, Falko
R&#246;spel, Ren&#233;
Heidenblut, Dirk
Klare, Arno
Mindrup, Klaus
(ab 17. Dezember 2019)
M&#246;ller, Siemtje
Dr. Zimmermann, Jens
(bis 16. Dezember 2019)
Prof. Dr.-Ing. Haddadin, Sami
Rechtsanwalt Kuhlen, Jan
M&#252;ller, Lena-Sophie
Schr&#246;der, Lothar
AfD Dr. Jongen, Marc
Cotar, Joana
(ab 17. Januar 2019)
Kamann, Uwe 
(bis 31. Dezember 2018)
Cotar, Joana
(bis 16 Januar 2019)
Felser, Peter
(ab 17. Januar 2019)
Dr. Fr&#246;mming, G&#246;tz
(bis 25. November 2019)
Schneider, J&#246;rg 
(ab 26. November 2019)
Prof. Dr. Hollas, Boris
Prof. Dr. L&#246;schke, Knut
FDP Brandenburg, Mario
Kluckert, Daniela
Cronenberg, Carl-Julius 
H&#246;ferlin, Manuel
Dr. Burchardt, Aljoscha
Martin, Andrea
DIE LINKE. Dr. Sitte, Petra
Tatti, Jessica
Domscheit-Berg, Anke
Dr. Kessler, Achim (bis 
30. September 2019)
Ulrich, Alexander
(bis Februar 2019)
Wagner, Andreas
(ab 1. Oktober 2019)
Dr. Butollo, Florian
Prof. Dr. Zweig, Katharina
B&#220;NDNIS 90/
DIE GR&#220;NEN
Dr. Christmann, Anna
Janecek, Dieter
Dr. Bayaz, Danyal
R&#246;&#223;ner, Tabea
Prof. Dr. Bast, Hannah
Dr. Heumann, Stefan
2.2.2 Obleute
Kemmer, Ronja (CDU/CSU)
R&#246;spel, Ren&#233; (SPD)
Kamann, Uwe (AfD) (27. September 2018 &#8211; 31. Dezember 2019)
Cotar, Joana (AfD) (17. Januar 2019 &#8211; 14. November 2019)
Felser, Peter (AfD) (ab 15. November 2019)
Brandenburg, Mario (FDP)
Dr. Sitte, Petra (DIE LINKE)
Dr. Christmann, Anna (B&#220;NDNIS 90/DIE GR&#220;NEN) (27. September 2018 -16. Dezember 2019/ab 15.
April 2020)
Janecek, Dieter (B&#220;NDNIS 90/DIE GR&#220;NEN) (17. Dezember 2019 &#8211; 14. April 2020)
2.2.3 Zusammensetzung der Projektgruppen
Projektgruppe 1 &#8222;KI und Wirtschaft&#8220;
Projektgruppenmitglieder MdB Sachverst&#228;ndige
CDU/CSU Durz, Hansj&#246;rg
Kemmer, Ronja (Vorsitzende)
Metzler, Jan
Prof. Dr. Ecker, Wolfgang
Dr. Kl&#252;wer, Tina
SPD Klare, Arno
Mohrs, Falko
R&#246;spel, Ren&#233; (stellv. Mitglied)
Schr&#246;der, Lothar
AfD Cotar, Joana Prof. Dr. L&#246;schke, Knut
FDP Brandenburg, Mario (stellv. Mitglied) Dr. Burchardt, Aljoscha
DIE LINKE. Tatti, Jessica Dr. Butollo, Florian (stellv. Mitglied)
B&#220;NDNIS 90/DIE GR&#220;NEN Dr. Bayaz, Danyal
Janecek, Dieter (stellv. Mitglied)
Projektgruppe 2 &#8222;KI und Staat&#8220;
Projektgruppenmitglieder MdB Sachverst&#228;ndige
CDU/CSU Bernstiel, Christoph
Sauer, Stefan
Prof. Dr. Filipovi&#263;, Alexander
Prof. Dr. M&#252;ller-Lietzkow, J&#246;rg
Dr. Wieczorek, Sebastian
SPD Esken, Saskia
M&#246;ller, Siemtje (stellv. Mitglied)
RA Kuhlen, Jan
M&#252;ller, Lena-Sophie
AfD Felser, Peter
Dr. Jongen, Marc
FDP Cronenberg, Carl-Julius
H&#246;ferlin, Manuel (stellv. Mitglied)
DIE LINKE. Domscheit-Berg, Anke (Vorsitzende) Prof. Dr. Zweig, Katharina (stellv.
Mitglied)
B&#220;NDNIS 90/DIE GR&#220;NEN R&#246;&#223;ner, Tabea Dr. Heumann, Stefan (stellv. Mitglied)
Projektgruppe 3 &#8222;KI und Gesundheit&#8220;
Projektgruppenmitglieder MdB Sachverst&#228;ndige
CDU/CSU Prof. Dr. Schmidtke, Claudia
Sorge, Tino
Steier, Andreas
Dehmel, Susanne
Prof. Dr. Kr&#252;ger, Antonio
SPD Kolbe, Daniela
R&#246;spel, Ren&#233;
Dr. Zimmermann, Jens (stellv. Mitglied)
Prof. Dr.-Ing. Haddadin, Sami
AfD Dr. Fr&#246;mming, G&#246;tz Prof. Dr. Hollas, Boris
FDP Kluckert, Daniela (stellv. Mitglied) Martin, Andrea
DIE LINKE. Dr. Sitte, Petra
Dr. Kessler, Achim (stellv. Mitglied)
B&#220;NDNIS 90/DIE GR&#220;NEN Dr. Christmann, Anna (Vorsitzende) Prof. Dr. Bast, Hannah (stellv. Mitglied)
Projektgruppe 4 &#8222;KI und Arbeit, Bildung, Forschung&#8220;
Projektgruppenmitglieder MdB Sachverst&#228;ndige
CDU/CSU Biadacz, Marc (ab 1. Oktober 2019)
Schimke, Jana
Steier, Andreas
Prof. Dr. Schmidtke, Claudia
(stellv. Mitglied ab 1. Oktober 2019, 
vorher ordentl. Mitglied)
Dehmel, Susanne
Prof. Dr. Kr&#252;ger, Antonio
SPD R&#246;spel, Ren&#233; (Vorsitzender)
Kolbe, Daniela (stellv. Mitglied)
Prof. Dr.-Ing. Haddadin, Sami
Schr&#246;der, Lothar
AfD Dr. Fr&#246;mming, G&#246;tz
(bis 25. November 2019)
Schneider, J&#246;rg (ab 26. November 2019)
Prof. Dr. Hollas, Boris
FDP Cronenberg, Carl-Julius (stellv. Mitglied) Martin, Andrea
DIE LINKE. Tatti, Jessica Dr. Butollo, Florian (stellv. Mitglied)
B&#220;NDNIS 90/DIE GR&#220;NEN Dr. Christmann, Anna
Dr. Bayaz, Danyal (stellv. Mitglied)
(ab. 1. Oktober 2019)
Prof. Dr. Bast, Hannah (stellv. Mitglied)
(bis 31.September 2019)
Projektgruppe 5 &#8222;KI und Mobilit&#228;t&#8220;
Projektgruppenmitglieder MdB Sachverst&#228;ndige
CDU/CSU Bernstiel, Christoph
Metzler, Jan
Sauer, Stefan
Schreiner, Felix (ab 17. Dezember 2019)
Lange, Ulrich (stellv. Mitglied)
(bis 16. Dezember 2019)
Dr. Friedrich, Hans-Peter
(stellv. Mitglied) (ab 17. Dezember 2019)
Prof. Dr. Ecker, Wolfgang
Dr. Wieczorek, Sebastian
SPD Klare, Arno
Mindrup, Klaus (ab 17. Dezember 2019)
Mohrs, Falko
AfD Felser, Peter Prof. Dr. L&#246;schke, Knut
FDP Kluckert, Daniela (Vorsitzende)
H&#246;ferlin, Manuel (stellv. Mitglied)
DIE LINKE. Domscheit-Berg, Anke
Wagner, Andreas (stellv. Mitglied)
(ab 1. Oktober 2019)
B&#220;NDNIS 90/DIE GR&#220;NEN Janecek, Dieter Prof. Dr. Bast, Hannah (stellv. Mitglied)
(ab 26. November 2019)
Projektgruppe 6 &#8222;KI und Medien&#8220;
Projektgruppenmitglieder MdB Sachverst&#228;ndige
CDU/CSU Durz, Hansj&#246;rg
Kemmer, Ronja
Prof. Dr. Filipovi&#263;, Alexander
Dr. Kl&#252;wer, Tina
Prof. Dr. M&#252;ller-Lietzkow, J&#246;rg
SPD Esken, Saskia (bis 16. Dezember 2019)
Korkmaz-Emre, Elvan (ab
17. Dezember 2019)
Mohrs, Falko (stellv. Mitglied)
(ab 12. Juni 2020)
RA Kuhlen, Jan
M&#252;ller, Lena-Sophie
AfD Cotar, Joana (Vorsitzende)
Dr. Jongen, Marc
FDP Brandenburg, Mario (stellv. Mitglied) Dr. Burchardt, Aljoscha
DIE LINKE. Dr. Sitte, Petra Prof. Dr. Zweig, Katharina 
(stellv. Mitglied)
B&#220;NDNIS 90/DIE GR&#220;NEN R&#246;&#223;ner, Tabea Dr. Heumann, Stefan (stellv. Mitglied)
2.2.4 Fraktionsreferentinnen und -referenten
Fraktion CDU/CSU
ORR'in Dunker, Julia
Fraktion SPD
Bose, Sandra
Will, Matthias
Fraktion AfD
Dr. Hermanns, Andre
Kaufmann, Markus (2. Januar &#8211; 31. Mai 2019)
Peter, Christopher
Fraktion FDP
Rusche, Marianna (ab 1. Oktober 2019)
Shoar, Kya (bis 30. September 2019)
Fraktion DIE LINKE.
Dr. Christen, Christian
Galla, Nina
Reetz, Alexander
Roth, Anne
Schulze, Florian
Fraktion B&#220;NDNIS 90/DIE GR&#220;NEN
Bisanz, Sarkis (ab 2. April 2019)
Drenger, Markus
Piallat, Chris
Wratil, Patricia
2.2.5 Mitarbeiterinnen und Mitarbeiter der Mitglieder
Fraktion CDU/CSU
Bittner, Denise
Fraederich, Oliver
Haase, Ren&#233; 
Hohenreuther, Michael
Kuntze, Jan-Hendrik 
L&#228;mmermann, Ute 
Mackscheidt, Clemens
Scheffbuch, Johanna
Schmidt, Philipp 
Tjaden, Christian 
Wernke, Gerrit
Zarandi, Maik
Fraktion SPD
Kampherbeek, Henning
K&#246;bele-Ennaji, Valerie (bis 31. August 2019)
Nahrgang, Thorsten
Peter, Robert
Sparenberg, Anke
Taugner, Michael (ab 1. September 2019)
Thalheim, Ulrike
Fraktion AfD
Class, Dominik
Hummel, Michael
Karl, Nicolas
Schmidt, Stephan
Fraktion FDP
Herrmann, Maria
Schumacher, Philip
Shakirova, Aygul
Fraktion DIE LINKE.
Otto, Cornelia
Schillo, Moritz
Schindler, Mathias
Sieron, Sandra
Thumm, Manuel
Wei&#223;, Simon
Fraktion B&#220;NDNIS 90/DIE GR&#220;NEN
Eder, Linda
K&#246;nig, Alexander
Dr. Ralfs, Richard
Seyffarth, Miriam
Sachverst&#228;ndige:
Roberts, Cindy-Ricarda
2.2.6 &#220;bersicht &#252;ber die Mitarbeiterinnen und Mitarbeiter des Sekretariats der Enquete-
Kommission
MRn Claudia B&#252;lter
Leiterin des Sekretariats
RD Mark Krause (April 2019 bis Dezember 2019)
Referent/stellvertretender Leiter
ORRn Theresa Essers (ab Februar 2019)
Wissenschaftliche Mitarbeiterin
ab Januar 2020 stellvertretende Leiterin
RD Dr. Tarik Menzenbach (ab M&#228;rz 2020)
Referent
Volker Tripp
Wissenschaftlicher Mitarbeiter
Lisa Szugfil (ab M&#228;rz 2019)
Wissenschaftliche Mitarbeiterin
Christopher Speer
Wissenschaftlicher Mitarbeiter
ORR Felix Wehrmann (ab Januar 2020)
Wissenschaftlicher Mitarbeiter
Antje Herold (ab Dezember 2018)
B&#252;roleiterin
Tanja Raptis
Erste Ausschusssekret&#228;rin
Kerstin Stamm (September 2018 bis April 2019)
Zweite Ausschusssekret&#228;rin
Silvia Seifarth (ab Mai 2019)
Zweite Ausschusssekret&#228;rin
Annalena Franke (ab Juni 2019)
Rechtskandidatin
Jasmin Bechtold (Juni 2019 bis Dezember 2019)
Rechtskandidatin
Jennifer Liersch (ab April 2020)
Rechtskandidatin
Protokolle
2.3.1 Liste der Protokolle der Enquete-Kommission
Nr. Datum Art Gegenstand Seitenanzahl
Absendung
endg.
Protokoll
1 27.09.18 &#246;ffentlich Konstituierung 6 Seiten 17.10.2018
2 27.09.18 nicht &#246;ffentlich Beratungssitzung 6 Seiten 17.10.2018
3 I 15.10.18 &#246;ffentlich Klausurtagung 13 Seiten 26.11.2018
3 II 15.10.18 nicht &#246;ffentlich Klausurtagung 19 Seiten 26.11.2018
4 I 05.11.18 nicht &#246;ffentlich Anh&#246;rungssitzung 43 Seiten 05.02.2019
4 II 05.11.18 &#246;ffentlich Anh&#246;rungssitzung 20 Seiten 05.02.2019
5 I 10.12.18 &#246;ffentlich Anh&#246;rungssitzung 48 Seiten 01.03.2019
5 II 10.12.18 nicht &#246;ffentlich Anh&#246;rungssitzung 19 Seiten 01.03.2019
6 I 14.01.19 &#246;ffentlich Klausurtagung 39 Seiten 27.03.2020
6 II 14.01.19 nicht &#246;ffentlich Klausurtagung 20 Seiten 27.03.2020
7 I 11.02.19 &#246;ffentlich Anh&#246;rungssitzung 8 Seiten 27.03.2020
7 II 11.02.19 nicht &#246;ffentlich Anh&#246;rungssitzung 21 Seiten 27.03.2020
8 I 11.03.19 nicht &#246;ffentlich Anh&#246;rungssitzung 20 Seiten 31.03.2020
8 II 11.03.19 &#246;ffentlich Anh&#246;rungssitzung 17 Seiten 31.03.2020
9 I 01.04.19 nicht &#246;ffentlich Anh&#246;rungssitzung 29 Seiten 31.03.2020
9 II 01.04.19 &#246;ffentlich Anh&#246;rungssitzung 17 Seiten 31.03.2020
10 I 06.05.19 &#246;ffentlich Anh&#246;rungssitzung 18 Seiten 08.04.2020
10 II 06.05.19 nicht &#246;ffentlich Anh&#246;rungssitzung 24 Seiten 08.04.2020
11 I 03.06.19 &#246;ffentlich Anh&#246;rungssitzung 18 Seiten 17.04.2020
11 II 03.06.19 nicht &#246;ffentlich Anh&#246;rungssitzung 25 Seiten 17.04.2020
12 09.09.19 nicht &#246;ffentlich Beratungssitzung 28 Seiten 17.04.2020
13 14.10.19 nicht &#246;ffentlich Beratungssitzung 14 Seiten 17.04.2020
14 I 04.11.19 &#246;ffentlich Anh&#246;rungssitzung 11 Seiten 17.04.2020
14 II 04.11.19 nicht &#246;ffentlich Anh&#246;rungssitzung 22 Seiten 17.04.2020
15 I 29.11.19 nicht &#246;ffentlich Klausursitzung 28 Seiten 17.04.2020
15 II 30.11.19 nicht &#246;ffentlich Klausursitzung 18 Seiten 17.04.2020
16 I 09.12.19 &#246;ffentlich Anh&#246;rungssitzung 18 Seiten 21.10.2020
16 II 09.12.19 nicht &#246;ffentlich Anh&#246;rungssitzung 19 Seiten 21.10.2020
17 I 13.01.19 &#246;ffentlich Anh&#246;rungssitzung 15 Seiten 21.10.2020
17 II 13.01.19 nicht &#246;ffentlich Anh&#246;rungssitzung 22 Seiten 21.10.2020
18 I 10.02.20 &#246;ffentlich Anh&#246;rungssitzung 18 Seiten 21.10.2020
18 II 10.02.20 nicht &#246;ffentlich Anh&#246;rungssitzung 20 Seiten 21.10.2020
Nr. Datum Art Gegenstand Seitenanzahl
Absendung
endg.
Protokoll
19 I 02.03.20 &#246;ffentlich Anh&#246;rungssitzung 18 Seiten 21.10.2020
19 II 02.03.20 nicht &#246;ffentlich Anh&#246;rungssitzung 20 Seiten 21.10.2020
20 I 04.05.20 &#246;ffentlich Anh&#246;rungssitzung 15 Seiten 21.10.2020
20 II 04.05.20 nicht &#246;ffentlich Anh&#246;rungssitzung 19 Seiten 21.10.2020
21 15.06.20 nicht &#246;ffentlich Beratungssitzung 34 Seiten 21.10.2020
22 29.06.20 nicht &#246;ffentlich Beratungssitzung 21 Seiten 21.10.2020
23 07.09.20 nicht &#246;ffentlich Beratungssitzung 39 Seiten 21.10.2020
24 05.10.20 nicht &#246;ffentlich Beratungssitzung 25 Seiten 22.10.2020
25 26.10.20 nicht &#246;ffentlich Beratungssitzung/
Abschlusssitzung
8 Seiten 20.10.2020
2.3.2 Liste der Protokolle der Projektgruppe 1 &#8222;KI und Wirtschaft&#8220;
Nr. Datum Art Gegenstand Seitenanzahl
Absendung
endg.
Protokoll
1 11.02.2019 nicht &#246;ffentlich Konstituierende Sitzung 19 25.02.2019
2 11.03.2019 nicht &#246;ffentlich Anh&#246;rungssitzung 22 20.03.2019
3 01.04.2019 nicht &#246;ffentlich Anh&#246;rungssitzung 31 15.04.2019
4 08.04.2019 nicht &#246;ffentlich Klausurtagung 68 03.05.2019
5 06.05.2019 nicht &#246;ffentlich Anh&#246;rungssitzung 32 17.05.2019
6 03.06.2019 nicht &#246;ffentlich Beratungssitzung 29 11.06.2019
7 24.06.2019 nicht &#246;ffentlich Klausurtagung kein Protokoll
8 02.09.2019 nicht &#246;ffentlich Klausurtagung kein Protokoll
9 09.09.2019 nicht &#246;ffentlich Beratungssitzung kein Protokoll
10 14.10.2019 nicht &#246;ffentlich Beratungssitzung kein Protokoll
2.3.3 Liste der Protokolle der Projektgruppe 2 &#8222;KI und Staat&#8220;
Nr. Datum Art Gegenstand Seitenanzahl
Absendung
endg.
Protokoll
1 11.02.2019 nicht &#246;ffentlich Konstituierende Sitzung 14 15.02.2019
1.1 18.02.2019 nicht &#246;ffentlich Beratungssitzung der AG 1 15 25.02.2019
2 11.03.2019 nicht &#246;ffentlich Anh&#246;rungssitzung 11 12.06.2019
2.1 18.03.2019 nicht &#246;ffentlich Beratungssitzung der AG 1 16 12.06.2019
3 01.04.2019 nicht &#246;ffentlich Anh&#246;rungssitzung 15 12.06.2019
Nr. Datum Art Gegenstand Seitenanzahl
Absendung
endg.
Protokoll
4 06.05.2019 nicht &#246;ffentlich Anh&#246;rungssitzung 22 12.06.2019
5 13.05.2019 nicht &#246;ffentlich Beratungssitzung 20 19.07.2019
6 03.06.2019 nicht &#246;ffentlich Anh&#246;rungssitzung 18 18.07.2019
7 24.06.2019 nicht &#246;ffentlich Beratungssitzung 6 18.07.2019
8 02.09.2019 nicht &#246;ffentlich Klausurtagung kein Protokoll
9 09.09.2019 nicht &#246;ffentlich Beratungssitzung kein Protokoll
10 23.09.2019 nicht &#246;ffentlich Klausurtagung kein Protokoll
11 14.10.2019 nicht &#246;ffentlich Beratungssitzung kein Protokoll
2.3.4 Liste der Protokolle der Projektgruppe 3 &#8222;KI und Gesundheit&#8220;
Nr. Datum Art Gegenstand Seitenanzahl
Absendung
endg.
Protokoll
1 11.02.2019 nicht &#246;ffentlich Konstituierende Sitzung 11 19.02.2019
2 11.03.2019 nicht &#246;ffentlich Anh&#246;rungssitzung 14 05.10.2020
3 01.04.2019 nicht &#246;ffentlich Anh&#246;rungssitzung 21 05.10.2020
4 06.05.2019 nicht &#246;ffentlich Anh&#246;rungssitzung 22 05.10.2020
5 13.05.2019 nicht &#246;ffentlich Anh&#246;rungssitzung 34 05.10.2020
6 03.06.2019 nicht &#246;ffentlich Beratungssitzung 6 05.10.2020
7 24.06.2019 nicht &#246;ffentlich Beratungssitzung 5 02.07.2019
8 02.09.2019 nicht &#246;ffentlich Beratungssitzung 3 05.10.2020
9 09.09.2019 nicht &#246;ffentlich Beratungssitzung 3 05.10.2020
10 14.10.2019 nicht &#246;ffentlich Beratungssitzung 4 05.10.2020
2.3.5 Liste der Protokolle der Projektgruppe 4 &#8222;KI und Arbeit&#8220;
Nr. Datum Art Gegenstand Seitenanzahl
Absendung
endg.
Protokoll
1 14.10.2019 nicht &#246;ffentlich Konstituierende Sitzung 13 21.10.2019
2 04.11.2019 nicht &#246;ffentlich Beratungssitzung 29 22.11.2019
3 25.11.2019 nicht &#246;ffentlich Anh&#246;rungssitzung 43 17.02.2020
4 09.12.2020 nicht &#246;ffentlich Anh&#246;rungssitzung 37 23.04.2020
5 16.12.2020 nicht &#246;ffentlich Anh&#246;rungssitzung 62 23.04.2020
6 13.01.2020 nicht &#246;ffentlich Anh&#246;rungssitzung 30 23.04.2020
10.02.2020 nicht &#246;ffentlich Textarbeit Kein Protokoll
Nr. Datum Art Gegenstand Seitenanzahl
Absendung
endg.
Protokoll
7 02.03.2020 nicht &#246;ffentlich Anh&#246;rungssitzung 23 23.04.2020
8 09.03.2020 nicht &#246;ffentlich Anh&#246;rungssitzung 9 23.04.2020
9 11.05.2020 nicht &#246;ffentlich Textarbeit Kein Protokoll
10 18.05.2020 nicht &#246;ffentlich Textarbeit Kein Protokoll
11 25.05.2020 nicht &#246;ffentlich Textarbeit Kein Protokoll
12 08.06.2020 nicht &#246;ffentlich Textarbeit Kein Protokoll
13 15.06.2020 nicht &#246;ffentlich Textarbeit Kein Protokoll
14 22.06.2020 nicht &#246;ffentlich Textarbeit Kein Protokoll
15 06.07.2020 nicht &#246;ffentlich Textarbeit Kein Protokoll
2.3.6 Liste der Protokolle der Projektgruppe 5 &#8222;KI und Mobilit&#228;t&#8220;
Nr. Datum Art Gegenstand Seitenanzahl
Absendung
endg.
Protokoll
1 14.10.2019 nicht &#246;ffentlich Konstituierende Sitzung 2 08.11.2019
2 04.11.2019 nicht &#246;ffentlich Anh&#246;rungssitzung 24 17.01.2020
3 11.11.2019 nicht &#246;ffentlich Anh&#246;rungssitzung 16 02.03.2020
4 09.12.2019 nicht &#246;ffentlich Anh&#246;rungssitzung 15 25.02.2020
5 16.12.2019 nicht &#246;ffentlich Anh&#246;rungssitzung 20 11.03.2020
6 13.01.2020 nicht &#246;ffentlich Anh&#246;rungssitzung 19 31.08.2020
7 10.02.2020 nicht &#246;ffentlich Anh&#246;rungssitzung 20 24.09.2020
8 09.03.2020 nicht &#246;ffentlich Klausurtagung Kein Protokoll
9 25.05.2020 nicht &#246;ffentlich Textarbeit Kein Protokoll
10 03.06.2020 nicht &#246;ffentlich Textarbeit Kein Protokoll
11 22.06.2020 nicht &#246;ffentlich Textarbeit Kein Protokoll
2.3.7 Liste der Protokolle der Projektgruppe 6 &#8222;KI und Medien&#8220;
Nr. Datum Art Gegenstand Seitenanzahl
Absendung
endg.
Protokoll
1 14.10.2019 nicht &#246;ffentlich Konstituierende Sitzung 3 23.10.2019
2 04.11.2019 nicht &#246;ffentlich Beratungssitzung 30 10.01.2020
3 09.12.2019 nicht &#246;ffentlich Anh&#246;rungssitzung 34 05.03.2020
4 16.12.2019 nicht &#246;ffentlich Anh&#246;rungssitzung 25 05.03.2020
5 13.01.2020 nicht &#246;ffentlich Beratungssitzung 28 05.03.2020
Nr. Datum Art Gegenstand Seitenanzahl
Absendung
endg.
Protokoll
6 10.02.2020 nicht &#246;ffentlich Anh&#246;rungssitzung 24 05.03.2020
7 02.03.2020 nicht &#246;ffentlich Anh&#246;rungssitzung 16 18.03.2020
8 09.03.2020 nicht &#246;ffentlich Textarbeit Kein Protokoll
9 20.04.2020 nicht &#246;ffentlich Textarbeit Kein Protokoll
10 11.05.2020 nicht &#246;ffentlich Textarbeit Kein Protokoll
11 25.05.2020 nicht &#246;ffentlich Textarbeit Kein Protokoll
12 15.06.2020 nicht &#246;ffentlich Textarbeit Kein Protokoll
Verzeichnisse und &#220;bersichten
2.4.1 Liste der Drucksachen der Enquete-Kommission
Kommissionsdrucksache
19(27)&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
1 Pr&#228;sentation, 15.10.2018, Begriffskl&#228;rung KI, von 
Dr. Aljoscha Burchardt/Prof. Dr. Antonio Kr&#252;ger
02.11.2018
2 Pr&#228;sentation, 15.10.2018, Algorithmische
Entscheidungen, von Prof. Dr. Katharina Zweig
02.11.2018
3 Pr&#228;sentation, 05.11.2018, Nationale KI-Strategien EU
und USA, von Dr. Stefan Heumann
02.11.2018
4 Pr&#228;sentation, 05.11.2018, Der Drache und die KI, von 
Prof. Dr. M&#252;ller-Lietzkow
05.11.2018
5 Pr&#228;sentation, 15.10.2018, Maschinelles Lernen vs. 
Klassische Algorithmen, von Prof. Dr. Hannah Bast
15.10.2018/
06.11.2018
6 Pr&#228;sentation, 15.10.2018, Online-B&#252;rgerbeteiligung an 
der Parlamentsarbeit, von Britta Oertel, Carolin Kahlisch
und Dr. Steffen Albrecht
15.10.2018/
06.11.2018
7 Pr&#228;sentation, 05.11.2018, Overview EU AI High Level
Group, von Saskia Steinacker (Bayer)
28.11.2018
8 Definitionspapier, 09.11.2018, Begriffskl&#228;rung KI, 
CDU/CSU-Bundestagsfraktion
07.12.2018
9
(neu)
Pr&#228;sentation, 10.12.2018, K&#252;nstliche Intelligenz in der
Wirtschaft, von Dr. Sebastian Wieczorek
10.12.2018
10 Beschlussvorlage f&#252;r die Arbeitsstruktur und die
Einsetzung der Projektgruppen der Enquete-Kommission
K&#252;nstliche Intelligenz
11.01.2019
11 Beschlussvorlage f&#252;r Organisation und Vorsitz der
Projektgruppen, Enquete-Kommission K&#252;nstliche
Intelligenz
11.01.2019
12 Pr&#228;sentation, 14.01.2019, Ethik und KI &#8211;Grundlagen und
Grundwerte, von Prof. Dr. Alexander Filipovi&#263;
11.01.2019
Kommissionsdrucksache
19(27)&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
13 Pr&#228;sentation, 14.01.2019, Es fehlt eine gesellschaftliche
Vision, von Lothar Schr&#246;der
11.01.2019
14 Pr&#228;sentation, 14.01.2019, KI und Ethik &#8211; Umsetzung in 
industrielle Richtlinien und pragmatische Ans&#228;tze am
Beispiel IBM &#8211;, von Andrea Martin
15.01.2019
15 Pr&#228;sentation, 14.01.2019, Debatoo, von Henrik Tesch 15.01.2019
16 Handout f&#252;r den Vortrag, 14.01.2019, Black Box 
Analysen zur Kontrolle von ADM-Systemen, von Prof. 
Dr. Katharina Zweig
16.01.2019
17 Beschluss vom 14. Januar 2019 &#252;ber die Arbeitsstruktur
und die Einsetzung der Projektgruppen der Enquete-
Kommission K&#252;nstliche Intelligenz
18.01.2019
18 Beschluss vom 14. Januar 2019 &#252;ber Organisation und 
Vorsitz der Projektgruppen der Enquete-Kommission
18.01.2019
19 Strukturvorschlag Teilberichte, Enquete-Kommission
K&#252;nstliche Intelligenz
30.01.2019
20 Meta-Ebene Ethik &#8211; Themen und Verfahren, Prof. 
Dr. Alexander Filipovi&#263;
30.01.2019
21 Beschlussvorlage Besetzung der Projektgruppen der
Enquete-Kommission K&#252;nstliche Intelligenz
01.02.2019
22 Beschlussvorlage Rahmenbedingungen f&#252;r die Arbeit der
Projektgruppen der Enquete-Kommission K&#252;nstl. 
Intelligenz
01.02.2019
23 Beschlussvorlage Projektgruppen&#252;bergreifende
Leitfragen, Enquete-Kommission K&#252;nstliche Intelligenz
01.02.2019
24 Schriftl. Antwort des BMBF auf Fragen der Enquete-
Kommission zur &#8222;Strategie K&#252;nstliche Intelligenz (KI)&#8220;
der Bundesregierung, PStS Michael Meister
04.02.2019
25 Pr&#228;sentation, 11.02.2019, K&#252;nstl. Intelligenz. 
Gesellschftl. Wahrnehmung und Akzeptanz, von Susanne
Dehmel
08.02.2019
26 Pr&#228;sentation, 11.02.2019, KI und Ethik. Gesellschaftliche
Wahrnehmung und Akzeptanz, von Lena-Sophie M&#252;ller
08.02.2019
27 Beschluss Besetzung der Projektgruppen der Enquete-
Kommission K&#252;nstliche Intelligenz
18.02.2019
28 Beschluss Rahmenbedingungen f&#252;r die Arbeit der
Projektgruppen, Enquete-Kommission K&#252;nstliche
Intelligenz
18.02.2019
29 Beschluss Projektgruppen&#252;bergreifende Leitfragen, 
Enquete-Kommission K&#252;nstliche Intelligenz
18.02.2019
30 Beschlussvorlage der Struktur der Teilberichte der
Enquete-Kommission KI
05.02.2019 11.03.2019
Kommissionsdrucksache
19(27)&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
31 Impulsvortrag K&#252;nstliche Intelligenz &amp; Helmholtz von 
Prof. Dr.-Ing. Morris Riedel am 11.03.2019.
11.03.2019
32 Impulsvortrag von Prof. Dr. Emmanuel M&#252;ller
(Frauenhofer IAIS) zum Thema KI: Forschung &amp;
Entwicklung &#8211; Machine Learning, Algorithms, Data 
Science &#8211;
11.03.2019
33 Impulsvortrag von Prof. Dr. S&#246;ren Auer (TIB Leibniz
Gemeinschaft) zum Thema K&#252;nstliche Intelligenz am
11.03.2019.
11.03.2019
34 Impulsvortrag von Prof. Dr. Alexander Filipovi&#263; zum
Thema Ethik am 11.03.2019.
11.03.2019
35 Beschluss der Struktur der Teilberichte der Enquete-
Kommission KI
14.03.2019 11.03.2019
36
(neu)
Thesen und Vortragsunterlagen zum Thema &#8222;Die
Begriffe &#8222;Vertrauen&#8220; und &#8222;Gemeinwohl&#8220; in Bezug auf
&#8222;K&#252;nstliche Intelligenz(en)&#8220; von Herrn Prof. Dr. J. Fetzer
f&#252;r die 9. Sitzung der Enquetekommission K&#252;nstliche
Intelligenz am 01.04.2019.
28.03.2019 01.04.2019
37 Vortrag und Handout von Herrn Roy Uhlmann zum
Thema K&#252;nstliche Intelligenz am Beispiel autonomes
Fahren am 01.04.2019.
01.04.2019 01.04.2019
38 Thesenpapier von Frau Prof. Nadja Capus zur
Einsch&#228;tzung der Chancen und Risiken K&#252;nstlicher
Intelligenz im Bereich Strafrecht und Strafprozessrecht
sowie um Mitteilung allf&#228;lliger Handlungsempfehlungen
an den Gesetzgeber.
24.04.2019
39 Impulsvortrag von Prof. Dr. Axel Metzger (Humboldt-
Universit&#228;t zu Berlin) zum Thema &#8222;Rechtliche 
Herausforderung bei Entwicklung und Einsatz von KI am
06.05.2019.
40 Empfehlungen zu Rechtsfragen der &#8222;K&#252;nstlichen 
Intelligenz&#8220; von Herrn Prof. Dr. Axel Metzger
(Humboldt-Universit&#228;t zu Berlin).
02.05.2019 06.05.2019
41 Impulsvortrag von Herrn Michael Teigeler und 
Dr. Sebastian Hallensleben (VDE/DKE) zum Thema 
&#8222;Normen und Standards&#8220; am 06.05.2019
02.05.2019 06.05.2019
42 Kernthesen und Handlungsempfehlungen zum Thema
&#8222;Normung und Standards&#8220; von Herrn Michael Teigeler
und Dr. Sebastian Hallensleben (VDE/DKE).
02.05.2019 06.05.2019
43 Thesenpapier von Herrn Prof. Dr. Kai Cornelius zu 
Handlungsnotwenigkeit der Legislative im
Spannungsfeld &#8222;K&#252;nstliche Intelligenz&#8220; und dem
Strafbzw. Strafprozessrecht.
03.05.2019
44 Beschlussvorlage f&#252;r eine vorl&#228;ufige Grobgliederung des
Mantelberichts.
03.05.2019 06.05.2019
Kommissionsdrucksache
19(27)&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
45 Thesenpapier von Frau Carla Hustedt zur KI-Transparenz
aus Verantwortung.
03.05.2019 06.05.2019
46 Impulsvortrag von Frau Carla Hustedt zum Thema &#8222;KI-
Transparenz aus Verantwortung&#8220; am 06.05.2019
03.05.2019 06.05.2019
47
(neu)
Impulsvortrag von Herrn Rechtsanwalt Jan Kuhlen zum
Thema &#8222;Haftungsrechtliche Fragen K&#252;nstlicher
Intelligenz&#8220; am 06.05.2019
05.05.2019 06.05.2019
48 Beschlussvorlage zur Definition des Begriffs &#8222;K&#252;nstliche
Intelligenz&#8220; auf Vorschlag sachverst&#228;ndiger
Kommissionsmitglieder.
28.05.2019 03.06.2019
49 Impulsvortrag von Herrn Dr. Stefan Heumann
(sachverst&#228;ndiges Mitglied der Enquete-Kommission KI)
zum Thema &#8222;Europ&#228;isches Datenmodell f&#252;r KI&#8220; am
03.06.2019
28.05.2019 03.06.2019
50 Impulsvortrag von Frau Elisabeth Lindinger (Open 
Knowledge Foundation) zum Thema &#8222;&#214;ffentliche Daten
und KI&#8220; am 03.06.2019
28.05.2019 03.06.2019
51 Kernthesen und Handlungsempfehlungen von Frau 
Elisabeth Lindinger (Oben Knowledge Foundation) zu 
&#214;ffentliche Daten und KI.
28.05.2019 03.06.2019
52 Thesenpapier von Frau Prof. Dr. Judith Simon 
(Universit&#228;t Hamburg) zu Gerechtigkeit und 
Diskriminierung.
30.05.2019 03.06.2019
53 Impulsvortrag von Herrn Prof. Dr. Norbert Pohlmann 
(Westf&#228;lische Hochschule Gelsenkirchen) zum Thema 
&#8222;KI und Cyber-Sicherheit&#8220; am 03.06.2019.
30.05.2019 03.06.2019
54 Thesenpapier und Handlungsempfehlungen von Herrn 
Prof. Dr. Norbert Pohlmann (Westf&#228;lische Hochschule
Gelsenkirchen) zu Sicherheit und Vertrauensw&#252;rdigkeit
von KI-Systemen.
30.05.2019 03.06.2019
55 Handlungsempfehlungen von Herrn Prof. Dr.-Ing Boris
Otto (Fraunhofer).
31.05.2019 03.06.2019
56 Impulsvortrag von Herrn Prof. Dr.-Ing. Boris Otto 
(Fraunhofer) zum Thema &#8222;Datenmanagement und 
Datensouver&#228;nit&#228;t&#8220; am 03.06.2019.
31.05.2019 03.06.2019
57 Handlungsempfehlungen von Frau Saskia Steinacker
(Bayer).
13.06.2019
58 Thesen und Handlungsempfehlungen von Herrn Prof. 
Dr. S&#246;ren Auer (TIB) bezgl. der Enquete-Sitzung am
11.03.2019.
17.06.2019
59 Thesen und Handlungsempfehlungen von Herrn Prof. 
Dr. Emmanuel M&#252;ller (Fraunhofer-Gesellschaft) bezgl.
der Enquete-Sitzung am 11.03.2019.
19.06.2019
Kommissionsdrucksache
19(27)&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
60 Handlungsempfehlungen von Herrn Prof. Dr.-Ing. Morris 
Riedel (Forschungszentrum J&#252;lich GmbH) bezgl. der
Enquete-Sitzung am 11.03.2019.
21.06.2019
61 Thesen und Handlungsempfehlungen von Herrn Prof. 
Dr. Klaus-Robert M&#252;ller (Max-Planck-Gesellschaft) 
bezgl. der Enquete-Sitzung am 11.03.2019.
24.06.2019
62
(neu)
Besetzung der Projektgruppen 02.09.2019
63 Endbericht (noch in Bearbeitungsphase) der
Projektgruppe 1 &#8211; KI und Wirtschaft &#8211; der Enquete-
Kommission K&#252;nstliche Intelligenz
06.09.2019 09.09.2019
64 Endbericht (noch in Bearbeitungsphase) der
Projektgruppe 2 &#8211; KI und Staat &#8211; der Enquete-
Kommission K&#252;nstliche Intelligenz
06.09.2019 09.09.2019
65 Endbericht (noch in Bearbeitungsphase) der
Projektgruppe 3 &#8211; KI und Gesundheit &#8211; der Enquete-
Kommission K&#252;nstliche Intelligenz
06.09.2019 09.09.2019
66 Antrag auf &#214;ffentlichkeit der Sitzungen der Enquete-
Kommission &#8222;K&#252;nstliche Intelligenz &#8211; Gesellschaftliche 
Verantwortung und wirtschaftliche Potenziale&#8220; inklusive
der Projektgruppen-Sitzungen ab Oktober 2019 von Frau 
Dr. Petra Sitte, MdB.
24.09.2019 14.10.2019
67
(neuneu)
Aktualisierung der Besetzung der Projektgruppen 14.10.2019
68 Aktueller Bearbeitungsstand des Projektgruppenberichts
der Projektgruppe &#8222;KI und Gesundheit&#8220; (PG 3)
01.10.2019
69 Aktueller Bearbeitungsstand des Projektgruppenberichts
der Projektgruppe &#8222;KI und Wirtschaft&#8220; (PG 1)
01.10.2019
70 Beschlussvorlage &#252;ber die Vergabe eines Gutachtens zur
Haltung der &#214;ffentlichkeit zu den Thesen und 
Handlungsempfehlungen der Enquete-Kommission KI
10.10.2019 14.10.2019
71 Aktueller Bearbeitungsstand des Projektgruppenberichts
der Projektgruppe &#8222;KI und Staat&#8220; (PG 2)
18.10.2019 04.11.2019
72 Beschlussempfehlung der Projektgruppe 1 &#8211; KI und 
Wirtschaft &#8211; zu den eingereichten &#196;nderungsantr&#228;gen.
01.11.2019 04.11.2019
73 Beschlussempfehlung der Projektgruppe 3 &#8211; KI und 
Gesundheit &#8211; zu den eingereichten &#196;nderungsantr&#228;gen.
01.11.2019 04.11.2019
74 Impulsvortrag von Hansj&#246;rg Durz, MdB, und Falko 
Mohrs, MdB, zum Thema Wettbewerbsrecht 4.0 am
4. November 2019.
04.11.2019 04.11.2019
75 Handlungsempfehlungen von Hansj&#246;rg Durz, MdB, und 
Falko Mohrs, MdB, zum Thema Wettbewerbsrecht 4.0 
aus der Sitzung 4. November 2019.
04.11.2019 04.11.2019
Kommissionsdrucksache
19(27)&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
76 Beschluss: Annahme des Berichts der Projektgruppe KI
und Wirtschaft
05.11.2019 04.11.2019
77 Beschluss: Annahme des Berichts der Projektgruppe KI
und Gesundheit
05.11.2019 04.11.2019
78 Beschlussempfehlung der Projektgruppe 2 &#8211; KI und Staat
&#8211; zu den eingereichten &#196;nderungsantr&#228;gen.
13.11.2019 09.12.2019
79 Abschlussbericht der Projektgruppe KI und Wirtschaft 21.11.2019 04.11.2019
80 Abschlussbericht der Projektgruppe KI und Gesundheit 21.11.2019 04.11.2019
81 Aktualisierung der Besetzung der Projektgruppen 26.11.2019
82 Vorschlag zur Gliederung des Mantelberichts der
Enquete-Kommission KI
28.11.2019 29.11.2019
83 Vorschlag zur Zeitplanung 2020 der Enquete-
Kommission KI
28.11.2019 29.11.2019
84 Thesen und Handlungsempfehlungen von Prof. 
Dr. Thomas Metzinger (Johannes Gutenberg-Universit&#228;t 
Mainz) vom 3. Dezember 2019.
03.12.2019
85 Inputpapier von Herrn Fabian Reetz (Stiftung Neue
Verantwortung) zum Thema KI und Nachhaltigkeit &#8211;
Digitale Energiewende &#8211; f&#252;r die Sitzung der Enquete-
Kommission am 09.12-2109
06.12.2019 09.12.2019
86 Inputpapier von Herrn Dr. Sebastian Wieczorek,
sachverst&#228;ndiges Mitglied der Enquete-Kommission, zur
Analyse der KI-Definition.
06.12.2019
87 Inputpapier von Herrn Dr. Sebastian Wieczorek,
sachverst&#228;ndiges Mitglied der Enquete-Kommission, zu
Definitionen der K&#252;nstlichen Intelligenz.
06.12.2019
88 Impulsvortrag von Herrn Prof. Dr. Wolfgang Ecker, 
sachverst&#228;ndiges Mitglieder der Enquete-Kommission,
zum Thema Hardware am 9. Dezember 2019
08.12.2019 09.12.2019
89 Impulsvortrag von Herrn Dr. Florian Butollo, 
sachverst&#228;ndiges Mitglied der Enquete-Kommission,
zum Thema &#8222;KI: Wachstum, Produktivit&#228;t und 
Nachhaltigkeit&#8220;
06.12.2019 09.12.2019
90 Impulsvortrag von Herrn Prof. Dr.-Ing. Sami Haddadin, 
sachverst&#228;ndiges Mitglied der Enquete-Kommission,
zum Thema Ergebnisse der High-Level Expert Group on
Artificial Intelligence am 9. Dezember 2019.
09.12.2019 09.12.2019
91 Impulsvortrag von Herrn Fabian Reetz, Stiftung Neue
Verantwortung, zum Thema K&#252;nstliche Intelligenz in der
Energiewende
12.12.2019 09.12.2019
92 Zusammenfassung der vorl&#228;ufigen Ergebnisse der
Projektgruppe KI und Wirtschaft (PG 1).
18.12.2019 19.12.2019
Kommissionsdrucksache
19(27)&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
93 Zusammenfassung der vorl&#228;ufigen Ergebnisse der
Projektgruppe KI und Staat (PG 2).
18.12.2019 19.12.2019
94 Zusammenfassung der vorl&#228;ufigen Ergebnisse der
Projektgruppe KI und Gesundheit (PG 3).
18.12.2019 19.12.2019
95 Thesen und Handlungsempfehlungen von Herrn Ulrich 
Kelber (Der Bundesbeauftragte f&#252;r den Datenschutz und
die Informationsfreiheit) vom 08.01.2020.
08.01.2020 13.01.2020
96 Impulsvortrag von Herrn Tim Wybitul (RA Latham &amp;
Watkins zum Thema &#8222;KI und Datenschutz&#8220; am
13.01.2020
09.01.2020 13.01.2020
97 Handlungsempfehlungen von Rechtsanw&#228;ltin Eva
Gardyan-Eisenlohr, Group Data Privacy Officer, f&#252;r 
Datenschutzaspekte.
10.01.2020 13.01.2020
98 Handlungsempfehlungen von Oliver S&#252;me, eco-Verband, 
f&#252;r Datenschutzaspekte.
10.01.2020 13.01.2020
99 Beschlussvorlage zur Beauftragung optionaler
Leistungen gem. Angebot zur Erstellung eines
Gutachtens zur Haltung der &#214;ffentlichkeit zu den Thesen
und Handlungsempfehlungen der Enquete-Kommission
K&#252;nstliche Intelligenz
13.01.2020 13.01.2020
100 Impulsvortrag Rechtsanw&#228;ltin Eva Gardyan-Eisenlohr, 
Group Data Privacy Officer, zum Thema &#8222;KI und 
Datenschutz&#8220;
14.01.2020 13.01.2020
101 Aktualisierung der Projektgruppenbesetzungen 20.01.2020
102 Abschlussbericht der Projektgruppe KI und Staat 29.01.2020 09.12.2020
103 Impulsvortrag von Herrn Prof. Roberto V. Zicari
(Initiative Z-inspection) zum Thema &#8222;KI, Ethik, 
Vertrauen, Risiken, Audit&#8220; am 10.02.2020
05.02.2020 10.02.2020
104 Thesen und Handlungsempfehlungen von Herrn Prof. 
Roberto V. Zicari (Initiative Z-inspection) am
10.02.2020.
05.02.2020 10.02.2020
105 Thesen und Handlungsempfehlungen von Frau Lina
Ehrig (Verbraucherzentrale Bundesverband) am
10.02.2020.
06.02.2020 10.02.2020
106 Impulsvortrag von Frau Rebekka Weiss (Bitkom) zum
Thema &#8222;Rahmen und Recht &#8211; zwischen Verantwortung 
und Kontrolle&#8220;.
07.02.2020 10.02.2020
107 Thesen und Handlungsempfehlungen von Frau Rebekka
Weiss (Bitkom).
07.02.2020 10.02.2020
108 Impulsvortrag von Frau Prof. Dr. Katharina Zweig
(sachverst&#228;ndiges Mitglied der Enquete-Kommission)
zum Thema &#8222;Notwendigkeit der Regulierung von ADM-
Systemen)
07.02.2020 10.02.2020
Kommissionsdrucksache
19(27)&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
109 Impulsvortrag von Herrn Matthias Spielkamp 
(Algorithmwatch) zum Thema &#8222;KI und Bias, 
Algorithmenkontrolle, Klassifizierung, 
Risikoklassenmodelle&#8220;.
10.02.2020 10.02.2020
110 Redemanuskript von Frau Lina Ehrig 
(Verbraucherzentrale Bundesverband) zu ihrem
Impulsvortrag am 10.02.2020.
10.02.2020 10.02.2020
111 Impulsvortrag von Frau Andrea Martin (sachverst&#228;ndiges
Mitglied der Enquete-Kommission) zum Thema &#8222;KI und 
Frauen&#8220;.
28.02.2020 02.03.2020
112 Impulsvortrag von Frau Susanne Dehmel
(sachverst&#228;ndiges Mitglied der Enquete-Kommission)
zum Thema &#8222;KI und Frauen&#8220;.
28.02.2020 02.03.2020
113 Impulsvortrag von Frau Veronika Eckstein (Airbus) zum
Thema &#8222;Data Science &amp; K&#252;nstliche Intelligenz&#8220;.
28.02.2020 02.03.2020
114 Impulsvortrag von Frau Julia Kloiber (Superrr Lab) zum
Thema &#8222;KI und Frauen&#8220;.
01.03.2020 02.03.2020
115 Handlungsempfehlungen von Frau Julia Kloiber (Superrr
Lab) zum Thema &#8222;KI und Frauen&#8220;.
01.03.2020 02.03.2020
116 Impulsvortrag von Herrn Prof. Dr. Boris Hollas
(sachverst&#228;ndiges Mitglied der Enquete-Kommission)
zum Thema &#8222;Mathematische Bildung f&#252;r die K&#252;nstliche
Intelligenz&#8220;.
01.03.2020 02.03.2020
117 Handlungsempfehlungen der AW AlgorithmWatch 
gGmbH.
13.03.2020
118 Impulsvortrag von Frau Dr. Verena Weber (OECD) zum
Thema &#8222;OECD work on AI. From principles to 
practices&#8220;
04.05.2020
119 Thesen von Frau Dr. Verena Weber (OECD). 04.05.2020
120 Impulsvortrag von Frau Christiane Canenbley (EU-
Kommission)
04.05.2020
121 Vortrag zu den ersten Ergebnissen der Online-
Beteiligung der Enquete-Kommission K&#252;nstliche
Intelligenz von nexus und Liquid Democracy.
10.06.2020 15.06.2020
122 Aktualisierung der Projektgruppenbesetzungen 12.06.2020
123
(neu)
Mantelbericht der Enquete-Kommission &#8222;K&#252;nstliche
Intelligenz&#8220;
26.06.2020 29.06.2020
124
(neu)
Abschlussbericht der Projektgruppe KI und Arbeit 04.09.2020 07.09.2020
125
(neu)
Abschlussbericht der Projektgruppe KI und Mobilit&#228;t 04.09.2020 07.09.2020
Kommissionsdrucksache
19(27)&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
126
(neu)
Abschlussbericht der Projektgruppe KI und Medien 04.09.2020 07.09.2020
127 Zusammenfassung der vorl&#228;ufigen Ergebnisse der
Projektgruppe KI und Arbeit (PG 4).
25.09.2020
128 Zusammenfassung der vorl&#228;ufigen Ergebnisse der
Projektgruppe KI und Mobilit&#228;t (PG 5).
25.09.2020
129 Zusammenfassung der vorl&#228;ufigen Ergebnisse der
Projektgruppe KI und Medien (PG 6).
25.09.2020
130 Stellungnahmen der von der Enquete-Kommission
angefragten Experten zum Thema &#8222;KI und Corona&#8220;
06.10.2020
131 Sondervoten der CDU/CSU-Fraktion 13.10.2020
132 Sondervoten der SPD-Fraktion 13.10.2020
133 Sondervoten der AfD-Fraktion 13.10.2020
134 Sondervoten der FDP-Fraktion 13.10.2020
135 Sondervoten der Fraktion DIE LINKE. 13.10.2020
136 Sondervoten der Fraktion B&#220;NDNIS 90/DIE GR&#220;NEN 13.10.2020
137 Gesamtbericht der Enquete-Kommission K&#252;nstliche
Intelligenz &#8211; Vorversion
13.10.2020
138 Antwortschreiben von BMn Anja Karliczek auf Fragen
im Nachgang zum virtuellen Ministergespr&#228;ch am
8. September 2020
16.10.2020
139 Zu den Sondervoten eingereichte Repliken der
CDU/CSU-Fraktion, SPD-Fraktion und FDP-Fraktion.
20.10.2020
140 Dokumentation der Ergebnispr&#228;sentation der Enquete-
Kommission K&#252;nstliche Intelligenz des Deutschen 
Bundestages
20.10.2020
141 Verfahrensvorschlag zur Behandlung der Protokolle und 
Unterlagen
23.10.2020 26.10.2020
142
(neu)
Verfahrensvorschlag zur Feststellung des Berichts 23.10.2020 26.10.2020
143 Gesamtbericht der Enquete-Kommission K&#252;nstliche
Intelligenz
23.10.2020 26.10.2020
144 Antwortschreiben von BMn Anja Karliczek auf
erg&#228;nzende Fragen im Nachgang zum virtuellen
Ministergespr&#228;ch am 8. September 2020 
23.10.2020 26.10.2020
2.4.2 Liste der Drucksachen der Projektgruppe 1 &#8222;KI und Wirtschaft&#8220;
Projektgruppendrucksache
19(27)PG 1-
&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
1 Impulsvortrag von Herrn Prof. Dr. Emmanuel M&#252;ller
(Fraunhofer IAIS) zum Thema KI Forschung und
Innovationen f&#252;r die Deutsche Wirtschaft am 11.03.2019.
11.03.2019
2 Impulsvortrag von Frau Iris Pl&#246;ger (BDI) zum Thema KI
in der deutschen Wirtschaft am 11.03.2019.
11.03.2019
3 Impulsvortrag von Herrn J&#246;rg Bienert (Bundesverband
K&#252;nstliche Intelligenz e. V.) zum Thema Situation und 
Ma&#223;nahmenkatalog am 11.03.2019.
11.03.2019
4 Impulsvortrag von Herrn Alexander Waldmann 
(appliedAI-Initiative von UnternehmerTUM) zum Thema 
Vernetzung und Transformation im Kontext K&#252;nstlicher
Intelligenz am 01.04.2019.
01.04.2019
5 Impulsvortrag von Frau Dr. Tina Kl&#252;wer (CEO
parlamind, Bundesverband K.I. e. V. und 
sachverst&#228;ndiges Mitglied der Enquete-Kommission KI)
zum Thema SWOT Analyse Deutschland als Standort f&#252;r
K.I.-Startups am 01.04.2019.
01.04.2019
6 Impulsvortrag von Frau Alexandra Horn (BVMW) zum
Thema KI im Mittelstand am 01.04.2019.
01.04.2019
7 Impulsvortrag von Herrn Dr. Florian Butollo (WZB und 
sachverst&#228;ndiges Mitglied der Enquete-Kommission KI)
zum Thema Technologieeinsatz als inkrementeller
Wandel am 01.04.2019.
01.04.2019
8 Impulsvortrag von Herrn Prof. Dr. Philipp Staab
(Humboldt-Universit&#228;t zu Berlin und Einstein Center
Digital Future) zum Thema KI Wirtschaft, Wachstum,
Wertsch&#246;pfung am 01.04.2019.
01.04.2019
9 Impulsvortrag von Frau Dr. Katrin Leonhardt (KfW) zum
Thema Start-up- und Innovationsfinanzierung der KfW
am 08.04.2019
05.04.2019
10 Impulsvortrag von Herrn Fabian J. G. Westerheide
(Asgard Capital) zum Thema Schaffung eines
erfolgreichen Startup-&#214;kosystems in DEU/EU am
08.04.2019
05.04.2019
11 Impulsvortrag von Herrn Dr. Daniel Halmer (LexFox)
zum Thema Verbraucherschutz durch KI am 08.04.2019.
05.04.2019
12 Impulsvortrag von Herrn Prof. Dr. Heiner Lasi
(Ferdinand-Steinbeis-Institut) zum Thema Erkenntnisse
aus (Micro) Testbed Aktivit&#228;ten am 08.04.2019
05.04.2019
13 Impulsvortrag von Herrn Michael B&#252;ltmann (Here) zum
Thema We are HERE am 08.04.2019
05.04.2019
Projektgruppendrucksache
19(27)PG 1-
&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
14 Impulsvortrag von Herrn Dr. Mikio Braun (Zalando) zum
Thema Transformation durch KI in verschiedenen 
Branchen am 08.04.2019
05.04.2019
15 Impulsvortrag von Frau Lina Ehrig (Verbraucherzentrale 
Bundesverband) zum Thema KI im Verbraucheralltag &#8211;
fair und inklusiv? am 08.04.2019
05.04.2019
16 Faktenblatt der Verbraucherzentrale Bundesverband zum
Thema &#8222;KI: Vertrauen ist gut, Kontrolle ist besser&#8220;. 
&#220;bersandt von Frau Lina Ehrig (VZBV) am 05.04.2019.
05.04.2019
17 Impulsvortrag von Herrn Oliver Fu&#223;winkel und 
Dr. Thomas Deckers (BaFin) zum Thema Big Data trifft
auf KI. Implikationen f&#252;r den Finanzmarkt und die
Finanzdienstleistungsaufsicht am 08.04.2019.
05.04.2019
18 Stellungnahme und Empfehlungen zu Rechtsfragen der
&#8222;K&#252;nstlichen Intelligenz&#8220; (Immaterialg&#252;terrecht,
Haftung) von Herrn Prof. Dr. Axel Metzger.
02.05.2019 06.05.2019
19 Impulsvortrag von Herrn Prof. Dr. Axel Metzger zum
Thema &#8222;Rechtliche Herausforderung bei Entwicklung 
und Einsatz von KI&#8220; am 06.05.2019.
02.05.2019 06.05.2019
20 Impulsvortrag von Herrn Michael Teigeler und 
Dr. Sebastian Hallensleben (VDE/DKE) zum Thema 
&#8222;Normen und Standards&#8220; am 06.05.2019
02.05.2019 06.05.2019
21 Kernthesen und Handlungsempfehlungen zum Thema
&#8222;Normung und Standards&#8220; von Herrn Michael Teigeler
und Herrn Dr. Sebastian Hallensleben (VDE/DKE).
02.05.2019 06.05.2019
22 Impulsvortrag von Herrn Matthis Eicher (DIN) zum
Thema &#8222;Normungs- und Standardisierungsaktivit&#228;ten bei 
DIN&#8220; am 06.05.2019
03.05.2019 06.05.2019
23 Impulsvortrag von Herrn Dr. Ramin Assadollahi (ExB)
zum Thema KI &amp; Versicherungen am 08.04.2019
08.04.2019 08.04.2019
24 Impulsvortrag von Herrn Patrick Bunk (Ubermetrics 
Technologies GmbH) zum Thema &#8222;Schaffung eines
erfolgreichen Startup-&#214;kosystems in Deutschland &amp;
Europa&#8220; am 08.04.2019
08.04.2019 08.04.2019
25 Impulsvortrag von Herrn Christin Sch&#228;fer (acs plus) zum
Thema &#8222;Datenmanagement und Absicherung von 
Datenqualit&#228;t u. -verf&#252;gbarkeit bei KI-Einsatz&#8220; am
08.04.2019
08.04.2019 08.04.2019
26 Impulsvortrag von Herrn Dr. Reinhard Messerschmidt
(WBGU) zum Thema &#8222;Potenziale und Herausforderung 
von KI f&#252;r Nachhaltigkeit&#8220; am 08.04.2019
08.04.2019 08.04.2019
Projektgruppendrucksache
19(27)PG 1-
&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
27 Impulsvortrag von Herrn Prof. Dr. Volker Tresp
(Siemens) zum Thema &#8222;Mit einer verantwortlichen KI
ein zukunftsorientiertes Europa gestalten&#8220; am 08.04.2019
08.04.2019 08.04.2019
28 Impulsvortrag von Herrn David Kriesel (Procter &amp;
Gamble GmbH) zum Thema &#8222;DataScience (und KI)
anfassbar&#8220; am 08.04.2019
08.04.2019 08.04.2019
2.4.3 Liste der Drucksachen der Projektgruppe 2 &#8222;KI und Staat&#8220;
Projektgruppendrucksache
19(27)PG 2-
&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
1 Hypothesen zum Einsatz von ADM/KI-Systemen in
staatlichen Stellen
25.02.2019
2 Impulsvortrag zum Thema KI im Rechtsumfeld 
Automatisierung von Widerspruchs-, Antrags-, und 
Formularverfahren von Frau Anke Domscheit-Berg, 
MdB (ordentliches Mitglied der Enquete-Kommission
KI) am 11.03.2019.
11.03.2019
3 Impulsvortrag zum Partizipation und Teilhabe von Herrn 
Rechtsanwalt Jan Kuhlen (sachverst&#228;ndiges Mitglied der
Enquete-Kommission KI) am 18.03.2019.
18.03.2019
4 Impulsvortrag zum Thema K&#252;nstliche Intelligenz als
Impulsgeber f&#252;r Innovation von Herrn Dr. Sebastian
Wieczorek (sachverst&#228;ndiges Mitglied der Enquete-
Kommission KI) am 18.03.2019.
18.03.2019
5 Literaturliste zu K&#252;nstlicher Intelligenz uns &#8222;Automated 
Decision Making&#8220; (ADM) in der &#246;ffentlichen
Verwaltung.
27.03.2019
6 Papier zum Thema verwaltungsrechtliche Normen zum
Einsatz von KI-/ADM-Systemen von Rechtsanwalt Jan
Kuhlen (sachverst&#228;ndiges Mitglied der Enquete-
Kommission KI) am 01.04.2019.
03.04.2019
7 Impulsvortrag zum Thema Beh&#246;rden auf Autopilot?
Automatisierung und KI in der &#214;ffentlichen Verwaltung 
von Herrn Dr.-Ing. Matthias Fl&#252;gge (Fraunhofer Fokus)
am 11.03.2019.
15.03.2019
8 Fazit von Dr. J&#246;rg Dr&#228;ger (Mitglied des Vorstandes,
Bertelsmann Stiftung) zu seinem Impulsvortrag 
&#8222;K&#252;nstliche Intelligenz und Zivilgesellschaft&#8220; am
01.04.2019
25.04.2019
Projektgruppendrucksache
19(27)PG 2-
&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
9 Impulsvortrag von Herrn Prof. Dr. Hans-J&#246;rg Kreowski
(Forum InformatikerInnen f&#252;r Frieden und 
gesellschaftliche Verantwortung e. V.) zum Thema &#8222;KI,
Milit&#228;rtechnik und Frieden am 06.05.2019.
03.05.2019 06.05.2019
10 Fazit Impulsvortrag von R&#252;diger Bohn 24.05.2019
11 Fazit des Impulsvortrages von Andreas K&#246;nen 24.05.2019
12 Impulsvortrag von Frau Prof. Dr. Katharina Zweig
(sachverst&#228;ndiges Mitglied der Enquete-Kommission KI)
zum Thema &#8222;Wie kommt es zu Diskriminierung durch 
KI?&#8220; am 03.06.2019.
31.05.2019 03.06.2019
13 Beantwortung des von uns &#252;bersandten Fragebogens an
das BMJV, Herr Christian Lange, MdB
(Parlamentarischer Staatssekret&#228;r).
03.07.2019
14
(neu)
Beantwortung des von uns &#252;bersandten Fragebogens an
das BMU, Herr Dirk Meyer (Leiter der Abteilung Z).
11.07.2019
15 Beantwortung des von uns &#252;bersandten Fragebogens an
das BKA, Herr Prof. Dr. Helge Braun, MdB
(Bundesminister).
11.07.2019
16 Beantwortung des von uns &#252;bersandten Fragebogens an
das BMVg, Herr Dr. Peter Tauber (Parlamentarischer
Staatssekret&#228;r).
16.07.2019
17 Beantwortung des von uns &#252;bersandten Fragebogens an
das BMI, Herr Prof. Dr. G&#252;nter Krings, MdB
(Parlamentarischer Staatssekret&#228;r).
17.07.2019
18 Beantwortung des von uns &#252;bersandten Fragebogens an
das BMWi, Herr Christian Hirte, MdB
(Parlamentarischer Staatssekret&#228;r).
18.07.2019
19 Beantwortung des von uns &#252;bersandten Fragebogens an
das BMZ, Herr Dr. Gerd M&#252;ller, MdB (Bundesminister).
18.07.2019
20 Beantwortung des von uns &#252;bersandten Fragebogens an
das AA, Herr Dr. Christian Aulbach (Leiter des
Parlaments- und Kabinettsreferats).
16.07.2019
21 Beantwortung des von uns &#252;bersandten Fragebogens an
das BMFSFJ, Herr Stefan Zierke (Parlamentarischer
Staatssekret&#228;r).
24.07.2019
22 Beantwortung des von uns &#252;bersandten Fragebogens an
das BMG, Herr Dr. Thomas Gebhart (Parlamentarischer
Staatssekret&#228;r).
26.07.2019
23 Beantwortung des von uns &#252;bersandten Fragebogens an
das BMF, Herr Horst Fl&#228;tgen (UAL Z C).
30.07.2019
24 Beantwortung des von uns &#252;bersandten Fragebogens an
das BMBF, BMn Anja Karliczek
07.08.2019
Projektgruppendrucksache
19(27)PG 2-
&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
25 Fragestellungen zum Einkauf und Einsatz von ADM-/KI-
Systemen durch Bundesministerien und nachgeordnete
Beh&#246;rden
12.12.2019
2.4.4 Liste der Drucksachen der Projektgruppe 3 &#8222;KI und Gesundheit&#8220;
Projektgruppendrucksache
19(27)PG 3-
&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
1 Schriftliche Stellungnahme des Bundesministeriums f&#252;r
Gesundheit zum Stand der Planungen und Initiativen im
Themenbereich KI und Gesundheit
06.03.2019 11.03.2019
2 Schriftliche Unterrichtung des BMBF zu &#8222;KI und 
Gesundheit&#8220; f&#252;r die PG-Sitzung am 11. M&#228;rz 2019.
06.03.2019 11.03.2019
3 Fragenkatalog f&#252;r die PG 3 von Frau Susanne Dehmel 06.03.2019 11.03.2019
4 Papier von Andrea Martin, Prof. Dr. Antonio Kr&#252;ger und
Susanne Dehmel (sachverst&#228;ndige Mitglieder der
Enquete-Kommission KI) zu den gesammelten Use 
Cases zum Einsatz von KI im Bereich Gesundheit.
14.03.2019
5 Gliederungsvorschlag f&#252;r den Berichtssteil der
Projektgruppe von Susanne Dehmel (sachverst&#228;ndiges 
Mitglied der Enquete-Kommission KI).
14.03.2019
6 Fragenkatalog f&#252;r die PG-Sitzung am 01. April 2018 von 
Frau Anna Christmann, MdB (ordentliches Mitglieder
der Enquete-Kommission KI) und Herrn Prof. 
Dr. Antonio Kr&#252;ger (sachverst&#228;ndiges Mitglied der
Enquete-Kommission KI)
25.03.2019
7 Impulsvortrag von Herrn Prof. Dr. Philipp Berens
(Universit&#228;tsklinikum T&#252;bingen) zum Thema KI in der
Gesundheitsforschung am 01.04.2019.
04.04.2019
8 Impulsvortrag von Herrn Prof. Okan Ekinci (F. 
Hoffmann-La Roche Ltd) zum Thema KI in der
Gesundheitsforschung &#8211; Beitrag: Wirtschaft am
01.04.2019
05.04.2019
9 Impulsvortrag von Herrn Prof. Dr. Dr. h.c. mult. Martin 
Hrabe de Angelis (Helmholtz Zentrum M&#252;nchen) zum
Thema KI in der Gesundheitsforschung &#8211; Beitrag: 
Wirtschaft
05.04.2019
10 Impulsvortrag von Herrn Dipl.-Ing. Oliver P. Christ
(CEO &#8211; Prosystem GmbH) und Herrn Dr. Sebastian
Hallensleben (VDE/DKE) zum &#8222;Thema KI &amp; Gesundheit
&#8211; Was kann die Normung praktisch tun?&#8220; am 13.04.2019
10.05.2019 13.05.2019
Projektgruppendrucksache
19(27)PG 3-
&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
11 Kernthesen und Handlungsempfehlungen zum Thema
&#8222;KI &amp; Gesundheit &#8211; was kann die Normung praktisch 
tun?&#8220; von Herrn Dipl.-Ing. Oliver P. Christ (CEO &#8211;
Prosystem GmbH) und Dr. Sebastian Hallensleben
(VDE/DKE).
10.05.2019 13.05.2019
12 Impulsvortrag von Herrn Bernd Falk (Malteser
Hilfsdienst) zum Thema &#8222;Sicherheit&#8220; am 13.05.2019
10.05.2019 13.05.2019
13 Impulsvortrag von Herrn Dr. Alexander K&#246;nig (Reactive 
Robotics) zum Thema &#8222;Startups im Bereich Healthcare&#8220;
am 13.05.2019
13.05.2019 13.05.2019
14 Impulsvortrag von Herrn Prof. Dr. Arne Manzeschke 
(Ev. Hochschule N&#252;rnberg) zum Thema &#8222;Intelligente
Pflege&#8220; am 13.05.2019
13.05.2019 13.05.2019
15 Berichtsstrukturvorschlag f&#252;r die Projektgruppe 3 &#8211; KI
und Gesundheit
24.05.2019
16 Diskussionsgrundlage der Vorsitzenden Dr. Anna
Christmann zum TOP 2 der 6. Sitzung am 03.06.2019.
24.05.2019 03.06.2019
17 a Handlungsempfehlungen von Herrn Prof. Dr. Philipp
Berens, Universit&#228;t T&#252;bingen.
23.05.2019
17 b Impulsvortrag von Herrn Prof. Dr. Philipp Berens,
Universit&#228;t T&#252;bingen, zum Thema KI in der
Gesundheitsforschung am 01.04.2019.
23.05.2019
18 Textbeitrag von Herrn Prof. Dr. Antonio Kr&#252;ger mit dem
Titel &#8222;Definition f&#252;r K&#252;nstliche Intelligenz&#8220;
25.05.2019
19 Impulsvortrag von Herrn Dipl.-Ing. Oliver P. Christ
(CEO) und Herrn Dr. Sebastian Hallensleben (VDE) zum
Thema &#8222;KI &amp; Gesundheit &#8211; Was kann die Normung 
praktisch tun?&#8220; am 13.05.2019.
27.05.2019
20 Handlungsempfehlungen von Herrn Dipl.-Ing. Oliver P. 
Christ (CEO) und Herrn Dr. Sebastian Hallensleben
(VDE).
27.05.2019
21 Handlungsempfehlungen von Herrn Dr. Alexander K&#246;nig 
(Reactive Robotics).
27.05.2019
22 Handlungsempfehlungen von Herrn Prof. Siegfried 
Jedamzik (Bayerische TelemedAllianz).
27.05.2019
23 Handlungsempfehlung von Herrn Prof. Dr. Arne
Manzeschke (Ev. Hochschule N&#252;rnberg).
27.05.2019
24 Handlungsempfehlung von Bernd Falk (Malteser
Hilfsdienst).
27.05.2019
25 Impulsvortrag von Herrn Sebastian Hofstetter
(Medizinische Fakult&#228;t der Martin-Luther-
Universit&#228;t/Halle) am 13.05.2019.
27.05.2019
Projektgruppendrucksache
19(27)PG 3-
&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
26 Handlungsempfehlungen von Herrn Sebastian Hofstetter
(Medizinische Fakult&#228;t der Martin-Luther-
Universit&#228;t/Halle).
27.05.2019
27 Handlungsempfehlungen von Herrn Prof. Dr. Jarek
Krajewski.
27.05.2019
28 Handlungsempfehlungen der PG Gesundheit &#8211; KI und 
Gesundheitsforschung &#8211; erste Diskussionsgrundlage nach
Expertenanh&#246;rung.
27.05.2019
29 Handlungsempfehlungen von Frau Daniela Kolbe, MdB, 
und Andrea Martin (sachverst&#228;ndiges Mitglied der
Enquete-Kommission KI)
28.05.2019
30 Kurze Ausf&#252;hrungen zur Frage nach einem Modell der
freiwilligen &#8222;Gesundheitsdatenspende&#8220; von Frau Prof. 
Dr. Christiane Woopen (Datenethikkommission der
Bundesregierung, Universit&#228;t zu K&#246;ln).
28.05.2019
31 Stellungnahme des Deutschen Berufsverbandes f&#252;r
Flegeberufe (DBfK) vom 29.05.2019.
29.05.2019
32 Expertenstatement Siemens Healthineers 29.05.2019
33 Handlungsempfehlungen von Herrn Prof. J. Windeler
(IQWiG) vom 29.05.2019.
31.05.2019
34 Kurzzusammenfassung u. Handlungsempfehlungen von 
Frau Prof. Dr. Hannah Bast (sachverst&#228;ndiges Mitglied
der Enquete-Kommission KI) vom 31.05.2019.
31.05.2019
35 Handlungsempfehlungen der PG Gesundheit &#8211; KI und 
Gesundheitsforschung &#8211; erste Diskussionsgrundlage nach
Expertenanh&#246;rung &#8211; Anmerkungen Prof. Dr.-Ing. Sami
Haddadin (sachverst&#228;ndiges Mitglied der Enquete-
Kommission KI).
31.05.2019
36 Impulsvortrag von Herrn Prof. Dr. David Matusiewicz 
(FOM) zum Thema &#8222;KI und Gesundheit &#8211; Gesundheits-
und Krankenpflege am 13.05.2019
12.06.2019 13.05.2019
37 Statements von Herrn Prof. Dr. David Matusiewicz 
(FOM) zum Thema &#8222;KI in der Pflege&#8220;
12.06.2019
38 Berichtsteil von Herrn Prof. Dr. Boris Hollas
(sachverst&#228;ndiges Mitglied der Enquete-Kommission KI)
zum Thema KI in der Pr&#228;vention, Diagnose und
Therapie.
17.06.2019
39 Berichtsentwurf zum Punkt 4.1. 19.06.2019
40 Berichtsentwurf zum Punkt 4.4. 19.06.2019
41 Berichtsentwurf zum Punkt 4.6. 19.06.2019
Projektgruppendrucksache
19(27)PG 3-
&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
42 Stellungnahme des Gemeinsamen Bundesausschusses, 
Vorsitzender Prof. Josef Hecken, vom 12. August 2019
13.08.2019
43 Impulsvortrag von Herrn Dr. Thilo Weichert, Mitglied
des &#8222;Netzwerk Datenschutzexpertise&#8220;, Vorstandsmitglied 
der Deutschen Vereinigung f&#252;r Datenschutz e. V. (DVD)
zum Thema Anwendungen mit Gesundheitsdaten
06.09.2019 06.05.2019
44 Impulsvortrag von Herrn Prof. Dr. Peter Haas,
Fachhochschule Dortmund, zum Thema &#8222;KI im
Gesundheitswesen in D, Ausgangssituation und 
Empfehlungen. 
06.05.2019 06.05.2019
45 Impulsvortrag von Herrn Sebastian C. Semler, 
Gesch&#228;ftsf&#252;hrer von TMF &#8211; Technologie- und 
Methodenplattform f&#252;r die vernetzte medizinische
Forschung e. V., zum Thema KI und Gesundheitsdaten
06.05.2019 06.05.2019
46 Impulsvortrag von Herrn Dr. Philipp Storz-Pfennig,
GKV Spitzenverband, zum Thema KI: Versorgung, 
Forschung, Daten.
06.05.2019 06.05.2019
47 Handlungsempfehlungen von Herrn Dr. Philipp Storz-
Pfennig, GKV Spitzenverband.
06.09.2019 06.05.2019
48 Handlungsempfehlungen TMF &#8211; Technologie- und 
Methodenplattform f&#252;r die vernetzte medizinische
Forschung e. V.
12.09.2019
2.4.5 Liste der Drucksachen der Projektgruppe 4 &#8222;KI und Arbeit&#8220;
Projektgruppendrucksache
19(27)PG 4-
&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
1 Handlungsempfehlungen von Prof. Dr. Lisa Herzog,
Universit&#228;t Groningen, anl&#228;sslich der 3. Sitzung am
25.11.2019.
21.11.2019 25.11.2019
2 Stellungnahme von Prof. Dr. Jens S&#252;dekum, D&#252;sseldorf
Institute for Competition Economics.
21.11.2019 25.11.2019
3 Handlungsempfehlungen von Prof. Dr. Enzo Weber,
Institut f&#252;r Arbeitsmarkt und Berufsforschung, anl&#228;sslich 
der 3. Sitzung am 25.11.2019. Teil 1
22.11.2019 25.11.2019
4 Handlungsempfehlungen von Prof. Dr. Enzo Weber,
Institut f&#252;r Arbeitsmarkt und Berufsforschung, anl&#228;sslich 
der 3. Sitzung am 25.11.2019. Teil 2
22.11.2019 25.11.2019
Projektgruppendrucksache
19(27)PG 4-
&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
5 Handlungsempfehlungen von Prof. Dr. Enzo Weber,
Institut f&#252;r Arbeitsmarkt und Berufsforschung, anl&#228;sslich 
der 3. Sitzung am 25.11.2019. Teil 3
22.11.2019 25.11.2019
6 Handlungsempfehlungen von Thomas Langkabel, 
Microsoft Deutschland
06.12.2019 09.12.2019
7 Impulsvortrag von Herrn Dr. Florian Butollo, 
sachverst&#228;ndiges Mitglied der Enquete-Kommission,
zum Thema &#8222;KI und Arbeit &#8211; ausgew&#228;hlte 
Problemfelder&#8220; am 04.11.2019
12.12.2019 04.11.2019
8 Impulsvortrag von Herrn Lothar Schr&#246;der, 
sachverst&#228;ndiges Mitglied der Enquete-Kommission,
zum Thema &#8222;Gute Arbeit mit KI, eine Vision &#252;ber
Handlungsbedarfe f&#252;r Mitbestimmung und 
Pers&#246;nlichkeitsrechte&#8220; am 04.11.2019
04.11.2019 04.11.2019
9 Impulsvortrag von Herrn Prof. Dr. Antonio Kr&#252;ger, 
sachverst&#228;ndiges Mitglied der Enquete-Kommission,
zum Thema &#8222;KI-Assistenzsysteme am und f&#252;r den 
Arbeitsplatz&#8220; am 04.11.2019
04.11.2019 04.11.2019
10 Impulsvortrag von Frau Susanne Dehmel, 
sachverst&#228;ndiges Mitglied der Enquete-Kommission,
zum Thema &#8222;Welche Rolle spielt KI in der Arbeitswelt&#8220;
am 04.11.2019
04.11.2019 04.11.2019
11 Impulsvortrag von Frau Dr. Julia Borggr&#228;fe, 
Bundesministerium f&#252;r Arbeit und Soziales, zum Thema
&#8222;Digitalisierung der Arbeitswelt &#8211; Herausforderungen
und Chancen&#8220; am 25.11.2019
25.11.2019 25.11.2019
12 Impulsvortrag von Herrn Dr. Terry Gregory, IZA &#8211;
Institute of Labor Economics, zum Thema
&#8222;Arbeitsmarktforschung, Vorhersagequalit&#228;t von 
Entwicklungsprognosen, Substitution oder Schaffung von 
Arbeit&#8220; am 25.11.2019
25.11.2019 25.11.2019
13 Impulsvortrag von Herrn Oliver Suchy, DGB-
Bundesvorstand, zum Thema &#8222;K&#252;nstliche Intelligenz und 
die Arbeit der Zukunft&#8220; am 25.11.2019
25.11.2019 25.11.2019
14 Impulsvortrag von Herrn Prof. Dr. Enzo Weber, IAB &#8211;
Institute f&#252;r Arbeitsmarkt- und Berufsforschung, zum
Thema &#8222;KI und Arbeitsmarkt&#8220; am 25.11.2019
25.11.2019 25.11.2019
15 Impulsvortrag von Herrn Jens S&#252;dekum, Heinrich-Heine-
Universit&#228;t D&#252;sseldorf, zum Thema &#8222;KI und 
Arbeitsmarkt &#8211; Verteilungsfragen, Produktivit&#228;t, 
Wertsch&#246;pfung, Polarisierung&#8220; am 25.11.2019
25.11.2019 25.11.2019
16 Impulsvortrag von Frau Lisa Herzog, Universit&#228;t von
Groningen, zum Thema &#8222;Philosophische Perspektiven&#8220;
am 25.11.2019
25.11.2019 25.11.2019
Projektgruppendrucksache
19(27)PG 4-
&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
17 Handlungsempfehlungen von Dr. Terry Gregory, IZA &#8211;
Institute of Labor Economics)
25.11.2019 25.11.2019
18 Impulsvortrag von Frau Britta Matthes, IAB &#8211; Institut f&#252;r
Arbeitsmarkt- und Berufsforschung, zum Thema &#8222;Wie 
sich Strukturen und T&#228;tigkeiten durch den Einsatz von 
K&#252;nstlicher Intelligenz ver&#228;ndern k&#246;nnten&#8220; am
09.12.2019
09.12.2019 09.12.2019
19 Impulsvortrag von Frau Dr. Marie-Christine Fregin, 
WBZ Berlin, zum Thema &#8222;KI am Arbeitsplatz&#8220; am
09.12.2019
09.12.2019 09.12.2019
20 Handlungsempfehlungen von Herrn Dr. phil. Lars
Adolph, Bundesanstalt f&#252;r Arbeitsschutz und 
Arbeitsmedizin.
09.12.2019 09.12.2019
21 Handlungsempfehlungen von Frau Dr. Britta Matthes,
IAB &#8211; Institut f&#252;r Arbeitsmarkt- und Berufsforschung
09.12.2019 09.12.2019
22 Handlungsempfehlungen von Frau Dr. Marie-Christine
Fregin, WBZ Berlin.
09.12.2019 09.12.2019
23 Impulsvortrag von Herrn Dr. phil. Lars Adolph, 
Bundesanstalt f&#252;r Arbeitsschutz und Arbeitsmedizin, 
zum Thema &#8222;Die Bedeutung f&#252;r Sicherheit und 
Gesundheit bei der Arbeit, Menschen-Maschine-
Interaktion&#8220; am 09.12.2019
09.12.2019 09.12.2019
24 Impulsvortrag von Frau Dr. Gerlind Wisskirchen, CMS
Hasche Sigle, zum Thema &#8222;KI und Arbeit&#8220; am
09.12.2019
09.12.2019 09.12.2019
25 Handlungsempfehlungen von Frau Dr. Gerlind
Wisskirchen, CMS Hasche Sigle.
09.12.2019 09.12.2019
26 Handlungsempfehlungen von Herrn Detlef Steppuhn,
Erich Gutenberg Berufskolleg K&#246;ln.
13.12.2019 16.12.2019
27 Handlungsempfehlungen von Herrn Jan Renz, Hasso
Plattner Institut.
13.12.2019 16.12.2019
28 Impulsvortrag von Frau Dr. Constanze Kurz, Robert
Bosch AG, zum Thema &#8222;KI und Recruiting&#8220; am
16.12.2019
16.12.2019 16.12.2019
29 Impulsvortrag Herrn Detlef Steppuhn, Erich-Gutenberg-
Berufskolleg K&#246;ln zum Thema &#8222;KI und Schule&#8220; am
16.12.2019
16.12.2019 16.12.2019
30 Impulsvortrag Frau Eva-Maria Nyckel, Humboldt-
Universit&#228;t Berlin zum Thema &#8222;KI in der
Personalverwaltung, Besch&#228;ftigtendatenschutz und 
Mitbestimmung&#8220; am 16.12.2019
16.12.2019 16.12.2019
Projektgruppendrucksache
19(27)PG 4-
&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
31 Impulsvortrag Herrn Jan Renz, Hasso-Plattner-Institut 
zum Thema &#8222;KI und Schule&#8220; am 16.12.2019
16.12.2019 16.12.2019
32 Impulsvortrag Frau Martina Hofmann, Bundesagentur f&#252;r
Arbeit zum Thema &#8222;KI und Recruiting&#8220; am 16.12.2019
16.12.2019 16.12.2019
33 Impulsvortrag Herrn Matthias Spielkamp,
algorithmwatch zum Thema &#8222;KI in der Personalverwaltung, 
Besch&#228;ftigtendatenschutz und Mitbestimmung&#8220; am
16.12.2019
16.12.2019 16.12.2019
34 Impulsvortrag Frau Prof. Dr. Heidrun Allert, Christian-
Albrechts-Universit&#228;t zu Kiel zum Thema &#8222;KI und 
Schule&#8220; am 16.12.2019
16.12.2019 16.12.2019
35 Impulsvortrag Frau Prof. Dr. Ute Schmid, Universit&#228;t 
Bamberg zum Thema &#8222;KI und Lernen&#8220; am 16.12.2019.
16.12.2019 16.12.2019
36 Impulsvortrag Herrn Prof. Dr. Wolfgang J&#228;ger, Gr&#252;nder
der Jobb&#246;rse JobStairs zum Thema &#8222;KI und Recruiting&#8220;
am 16.12.2019
16.12.2019 16.12.2019
37 Impulsvortrag von Frau Susanne Dehmel,
sachverst&#228;ndiges Mitglied der Enquete-Kommission, zum Thema
&#8222;KI in der Personalverwaltung, Besch&#228;ftigtendatenschutz
und Mitbestimmung&#8220; am 16.12.2019
16.12.2019 16.12.2019
38 Impulsvortrag Herrn Thomas Belker, CEO Precire zum
Thema &#8222;KI in der Personalverwaltung, 
Besch&#228;ftigtendatenschutz und Mitbestimmung&#8220; am
16.12.2019
16.12.2019 16.12.2019
39 Impulsvortrag Herrn Prof. Dr. J&#252;rgen Handke, 
Universit&#228;t Marburg zum Thema &#8222;KI und Hochschule&#8220;
am 16.12.2019
16.12.2019 16.12.2019
40 Handlungsempfehlungen von Oliver Suchy, DGB-
Bundesvorstand.
25.11.2019 25.11.2019
41 Stellungnahme des DGB, Deutschen 
Gewerkschaftsbundes, zu den Eckpunkten der
Bundesregierung f&#252;r eine Strategie K&#252;nstliche Intelligenz
vom 18. Juli 2018
25.11.2019 25.11.2019
42 Stellungnahme des DGB, Deutschen 
Gewerkschaftsbundes, zur Strategie K&#252;nstliche 
Intelligenz der Bundesregierung vom
15. November 2018.
25.11.2019 25.11.2019
43 Handlungsempfehlungen von Herrn David Beitz,
Arbeitgeberverband Gesamtmetall e. V.
10.01.2020 13.01.2020
44 Handlungsempfehlungen von Herrn Prof. Dr. Ing. habil. 
Sascha Stowasser, ifaa &#8211; Institut f&#252;r angewandte
Arbeitswissenschaft.
10.01.2020 13.01.2020
Projektgruppendrucksache
19(27)PG 4-
&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
45 Impulsvortrag von Frau Susan Beudt, Educational
Technology Lab / DFKI Berlin, zum Thema &#8222;Lehren und 
Lernen &#252;ber, mit und trotz KI&#8220; am 16.12.2019
16.12.2019 16.12.2019
46 Handlungsempfehlungen von Frau Susan Beudt, 
Educational Technology Lab / DFKI Berlin, zum Thema
&#8222;Lehren und Lernen &#252;ber, mit und trotz KI&#8220; am
16.12.2019
16.12.2019 16.12.2019
47 Handlungsempfehlungen von Frau Ute Schmid, 
Universit&#228;t Bamberg.
16.12.2019 16.12.2019
48 Handlungsempfehlungen von Frau Sigrid Hartong, 
Helmut-Schmidt-Universit&#228;t Hamburg.
12.01.2020
49 Handlungsempfehlungen von Herrn Prof. Dr. Florian A. 
Schmidt, HTW Dresden.
12.01.2020
50 Impulsvortrag von Herrn Marco Grenz, IG Metall, zum
Thema &#8222;KI und Arbeit&#8220; am 13.01.2020
12.01.2020 13.01.2020
51 Impulsvortrag von Herrn Prof. Dr. Florian A. Schmidt, 
HTW Dresden, zum Thema &#8222;KI und Arbeit&#8220; am
13.01.2020.
12.02.2020 13.01.2020
52 Impulsvortrag von Herrn Prof. Dr.-Ing. habil. Sascha
Stowasser, ifaa, zum Thema &#8222;KI und ihre Auswirkungen 
auf Arbeitsprozesse&#8220; am 13.01.2020.
12.01.2020 13.01.2020
53 Impulsvortrag von Herrn Ralf Lemster, BD&#220;, zum
Thema &#8222;KI und als &#220;bersetzerin?&#8220; am 13.01.2020.
12.01.2020 13.01.2020
54 Handlungsempfehlungen von Frau Eva-Maria Nyckel,
Humboldt-Universit&#228;t zu Berlin.
13.01.2020 13.01.2020
55 Handlungsempfehlungen von Frau Dr. Katie Baldschun, 
Richterin am Sozialgericht, derzeit wissenschaftliche 
Mitarbeiterin an der Universit&#228;t Kassel
13.01.2020 13.01.2020
56 Handlungsempfehlungen von Frau Prof. Dr. Heidrun 
Allert, Christian-Albrechts-Universit&#228;t zu Kiel.
13.01.2020 13.01.2020
57 Handlungsempfehlungen von Herrn Marco Grenz, IG
Metall.
17.01.2020
58 Faktenblatt der IG Metall zu
Tranformationskurzarbeitergeld.
17.01.2020
59 Handlungsempfehlungen von Herrn Prof. Dr. Wolfgang 
J&#228;ger, Hochschule RheinMain.
17.01.2020
60 Handlungsempfehlungen von Frau Anka Grosch, 
Amazon Distribution GmbH Leipzig.
24.02.2020
61 Handlungsempfehlungen von Herr Prof. Dr. Philipp
Hennig, Universit&#228;t T&#252;bingen.
28.02.2020
Projektgruppendrucksache
19(27)PG 4-
&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
62 Impulsvortrag von Herrn Dr. Martin Kuhlmann 
(Soziologisches Forschungsinstitut an der Georg-August-
Universit&#228;t G&#246;ttingen) zum Thema &#8222;KI und Arbeit aus
arbeitssoziologischer Sicht&#8220;.
02.03.2020 02.03.2020
63 Impulsvortrag von Herrn Prof. Dr. Dr. Fabian Theis 
(Helmholtz Zentrum M&#252;nchen) zum Thema &#8222;Artificial 
intelligence with examples from biomedicine&#8220;.
02.03.2020 02.03.2020
64 Handlungsempfehlungen von Herrn Prof. Dr. Dr. Fabian
Theis (Helmholtz Zentrum M&#252;nchen).
02.03.2020 02.03.2020
65 Impulsvortrag von Herrn Prof. Dr. Philipp Hennig 
(Universit&#228;t T&#252;bingen) zum Thema &#8222;Zeitgen&#246;ssische KI
hei&#223;t Maschinelles Lernen&#8220;.
02.03.2020 02.03.2020
66 Impulsvortrag von Herrn Ulman Lindenberger (Max-
Planck-Institut f&#252;r Bildungsforschung) zum Thema &#8222;KI
&#252;ber die Lebensspanne&#8220;.
09.03.2020 09.03.2020
67 Handlungsempfehlungen der AW AlgorithmWatch 
gGmbH.
13.03.2020
2.4.6 Liste der Drucksachen der Projektgruppe 5 &#8222;KI und Mobilit&#228;t&#8220;
Projektgruppendrucksache
19(27)PG 5-
&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
1 &#220;bersicht der Schreibteams der Projektgruppe 5 (KI und 
Mobilit&#228;t), Stand: 31. Oktober 2019
08.11.2019
2 Liste der vorgeschlagenen Anh&#246;rpersonen der
Projektgruppe 5 (KI und Mobilit&#228;t), Stand: 31. Oktober 2019
08.11.2019
3 Impulsvortrag von Herrn Alexander Mankowsky
(Daimler AG) zum Thema &#8222;Zukunft der Mobilit&#228;t&#8220; am
04.11.2019.
01.11.2019 04.11.2019
4 Impulsvortrag von Herrn Prof. Dr. Stephan Rammler
(Institut f&#252;r Zukunftsstudien und
Technologiebewertung/IZT, Direktor) zum Thema &#8222;Digitalisierung der
Mobilit&#228;t&#8220; am 04.11.2019.
01.11.2019 04.11.2019
5 Impulsvortrag von Herrn Yves Sterbak (Thales
Deutschland GmbH) zum Thema &#8222;Thales und KI&#8220; am
11.11.2019.
08.11.2019 11.11.2019
6 Impulsvortrag von Herrn Dr.-Ing. Thomas Thiele
(Deutsche Bahn) zum Thema &#8222;Auf dem Weg zu KI bei
der Deutschen Bahn&#8220; am 11.11.2019.
08.11.2019 11.11.2019
Projektgruppendrucksache
19(27)PG 5-
&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
7 Handlungsempfehlungen von Herrn Dr.-Ing. Thomas
Thiele (Deutsche Bahn).
03.12.2019
8 Fragenkatalog zu Luft / Wasser von Herrn Christoph 
Bernstiel, MdB und Arno Klare, MdB.
04.12.2019
9 Antwort von Siemens Mobility (Wiebke Metzler) auf
Anfrage von Herrn Falko Mohrs, MdB, nach 
Handlungsempfehlungen.
05.12.2019
10 Antwort von Siemens Mobility (Wiebke Metzler) auf
Anfrage von Herrn Falko Mohrs, MdB, nach 
Handlungsempfehlungen.
05.12.2019
11 Antwort von Siemens Mobility (Wiebke Metzler) auf
Anfrage von Herrn Falko Mohrs, MdB, nach 
Handlungsempfehlungen.
05.12.2019
12 Impulsvortrag von Herrn Dr. Christian Seidel (Airbus
Helicopters Deutschland GmbH) zum Thema 
&#8222;K&#252;nstliche Intelligenz in der Luftfahrt &#8211; We make it
fly!&#8220; am 09.12.2019
06.12.2019 09.12.2019
13 Impulsvortrag von Herrn Prof. Dipl.-Ing. Thomas
Schlipk&#246;ther (Duisburger Hafen AG) zum Thema
&#8222;Digitization Strategy for Terminals of Combined
Traffic&#8220; am 09.12.2019
06.12.2019 09.12.2019
14 Fragenkatalog zur Stra&#223;e von Herrn Stefan Sauer, MdB, 
vom 11.12.2019
11.12.2019
15 Fragenkatalog zur Stra&#223;e von Peter Felser, MdB, und 
Prof. Dr. Knut L&#246;schke, sachverst&#228;ndiges Mitglied der
Enquete-Kommission KI
12.12.2019
16 Impulsvortrag von Frau Julia Miosga, 
DieDigitalLandschaftsG&#228;rtnerin, zum Thema &#8222;Chancen 
und Herausforderungen des Einsatzes KI-basierter
Technologien im Bereich &#8222;Stra&#223;e&#8220;&#8222; am
16. Dezember 2019.
13.12.2019 16.12.2019
17 Impulsvortrag von Herrn Andreas Karanas, Carrypicker 
GmbH, zum Thema &#8222;Transport Made Smart&#8220;.
18.12.2019 16.12.2019
18 Impulsvortrag von Herrn Prof. Dr.-Ing. Thomas Form
zum Thema &#8222;Herausforderungen Autonomes Fahren&#8220;
18.12.2019 16.12.2019
19 Impulsvortrag von Herrn Dr. Manuel G&#246;tz zum Thema 
AI in mobility
18.12.2019 16.12.2019
20 Handlungsempfehlungen Prof. Schlipk&#246;ther 09.12.2019 19.12.2019
21 Fragenkatalog-Intermodalit&#228;t &amp; Plattformen &#8211; CDUCSU 08.01.2020 13.01.2020
22 Fragenkatalog-Intermodalit&#228;t &amp; Plattformen &#8211; DIE
LINKE
08.01.2020 13.01.2020
Projektgruppendrucksache
19(27)PG 5-
&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
23 Impulsvortrag von Frau Dr. Sabine Seelenmeyer (SAP)
zum Thema &#8222;Multimodale Logistik &#8211; Anwendung von 
Optimierungsverfahren und zuk&#252;nftige Nutzung von KI&#8220;
am 13.01.2020.
09.01.2020 13.01.2020
24 Impulsvortrag von Herrn Dr. Tim Wiegels, FREE NOW,
zum Thema &#8222;Intermodalit&#228;t &amp; Plattformen&#8220; am
13.01.2020
13.01.2020 13.01.2020
25 Impulsvortrag von Herrn Christoph Weigler, Uber, zum
Thema &#8222;Intermodalit&#228;t &amp; Plattformen: Chancen KI-
basierter Technologien&#8220; am 13.01.2020
13.01.2020 13.01.2020
26 Stellungnahme von Herrn Dr. Uwe B&#246;hme (VCD) vom
21. Januar 2020
21.01.2020
27 Handlungsempfehlungen von Herrn Prof. Dr.-Ing. 
Thomas Form (Volkswagen AG)
21.01.2020
28 Fragenkatalog zu &#8222;&#220;bergreifende Themen&#8220; von 
Dr. Sebastian Wieczorek, sachverst&#228;ndiges Mitglied der
En-quete-Kommission KI, und Prof. Dr. Wolfgang 
Ecker, sachverst&#228;ndiges Mitglied der Enquete-
Kommission KI
21.01.2020 10.02.2020
29 Schriftliches Statement zu Intermodalit&#228;t und
Plattformen von Frau Christine Schmitt (Kommunikationschefin 
Evertracker GmbH).
24.01.2020
30 Berichtsteil &#8222;Stra&#223;e&#8220; von Herrn Stefan Sauer, MdB, Prof.
Dr. Wolfgang Ecker, sachverst&#228;ndiges Mitglied der
Enquete-Kommission KI, Peter Felser, MdB, Prof. 
Dr. Knut L&#246;schke, sachverst&#228;ndiges Mitglied der
Enquete-Kommission KI.
24.01.2020
31 Textbeitrag von Herrn Arno Klare, MdB, und Herrn 
Felix Schreiner, MdB, f&#252;r die Finalisierung des
Zwischen-berichts der Projektgruppe 5 &#8222;KI und 
Mobilit&#228;t&#8220; zum Thema &#8222;Luft/Wasser&#8220;.
28.01.2020
32 Textbeitrag von Herrn Stefan Sauer, MdB, Herrn Prof. 
Dr. Wolfgang Ecker, Herrn Peter Felser, MdB, und Herrn 
Prof. Dr. Knut L&#246;schke f&#252;r die Finalisierung des
Zwischenberichts der Projektgruppe 5 &#8222;KI und 
Mobilit&#228;t&#8220; zum Thema &#8222;Stra&#223;e&#8220;.
11.02.2020
33 Textbeitrag von Frau Domscheit-Berg, MdB, und Herrn 
Jan Metzler, MdB, f&#252;r die Finalisierung des
Zwischenberichts der Projektgruppe 5 &#8222;KI und Mobilit&#228;t&#8220; zum
Thema &#8222;Intermodalit&#228;t &amp; Plattformen&#8220;.
11.02.2020
34 Vortrag von Herrn Prof. Dr. Daniel Zimmer (Universit&#228;t 
Bonn) zum Thema &#8222;Herausforderungen des
Transformationsprozesses zu einer KI-gest&#252;tzten
Mobilit&#228;t im Hinblick auf &#214;konomie und Wettbewerb&#8220;.
11.02.2020 10.02.2020
Projektgruppendrucksache
19(27)PG 5-
&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
35 Vortrag von Herrn Univ.-Prof. Dr.-Ing. Klaus J. 
Beckmann (acatech) zum Thema &#8222;Mobilit&#228;t &#8211;
Stadtentwick-lung&#8220;
11.02.2020 10.02.2020
36 Vortrag von Herrn Dr. Dietmar C. Schl&#246;&#223;er (T&#220;V Nord
Group) zum Thema &#8222;Sicherheit bei KI-gest&#252;tzter
Mobilit&#228;t&#8220;.
11.02.2020
37 Stellungnahme von Herrn Dr. Ing. Rupert Henn (DST
Entwicklungszentrum f&#252;r Schiffstechnik und 
Transportsysteme e. V.
18.02.2020
38 Handlungsempfehlungen der T&#220;V NORD GROUP 26.02.2020
2.4.7 Liste der Drucksachen der Projektgruppe 6 &#8222;KI und Medien&#8220;
Projektgruppendrucksache
19(27)PG 6-
&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
1 Impulsvortrag von Dr. Aljoscha Burchardt
(sachverst&#228;ndiges Mitglied der Enquete-Kommission KI)
zum Thema &#8222;Crashkurs NLP&#8220; am 04.11.2019.
04.11.2019
2 Impulsvortrag von Prof. Dr. Alexander Filipovi&#263;
(sachverst&#228;ndiges Mitglied der Enquete-Kommission KI)
zum Thema &#8222;Wandel der Mediennutzung&#8220; am
04.11.2019.
04.11.2019
3 Impulsvortrag von Prof. Dr. J&#246;rg M&#252;ller-Lietzkow
(sachverst&#228;ndiges Mitglied der Enquete-Kommission KI)
zum Thema &#8222;KI und Medien&#8220; am 04.11.2019.
04.11.2019
4 Impulsvortrag von Prof. Dr. Katharina Zweig
(sachverst&#228;ndiges Mitglied der Enquete-Kommission KI)
zum Thema &#8222;Recommender Systeme&#8220; am 04.11.2019.
04.11.2019
5 Handlungsempfehlungen von Dr.-Ing. Christian Riess, 
Friedrich-Alexander Universit&#228;t Erlangen-N&#252;rnberg, 
vom 08.09.2019
09.12.2019 09.12.2019
6 Impulsvortrag von Dr.-Ing. Christian Riess, Friedrich-
Alexander Universit&#228;t Erlangen-N&#252;rnberg, zum Thema
&#8222;Medienforensik im journalistischen Kontext&#8220; am
09.12.2019
09.12.2019 09.12.2019
7 Impulsvortrag von Prof. Dr. Klaus Goldhammer, 
Goldmedia GmbH Strategy Consulting, zum Thema &#8222;KI 
und Medien&#8220; am 09.12.2019.
09.12.2019 09.12.2019
Projektgruppendrucksache
19(27)PG 6-
&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
8 Impulsvortrag von Clemens Boisser&#233;e, Rheinische Post, 
zum Thema &#8222;KI und Medien &#8211; Anwendungen bei der
Rheinischen Post&#8220; am 09.12.2019.
09.12.2019 09.12.2019
9 Impulsvortrag von Christian Daubner, Bayerischer
Rundfunk, zum Thema &#8222;KI und Medien&#8220; am 09.12.2019.
09.12.2019 09.12.2019
10 Handlungsempfehlungen von Christian Daubner, 
Bayerischer Rundfunk vom 09.12.2019.
09.12.2019 09.12.2019
11 Handlungsempfehlungen von Clemens Boisser&#233;e,
Rheinische Post, vom 09.12.2019.
09.12.2019 09.12.2019t
12 Handlungsempfehlungen von Prof. Dr. Klaus
Goldhammer, Goldmedia GmbH Strategy Consulting, 
vom 09.12.2019.
09.12.2019 09.12.2019
13 Impulsvortrag von Herrn Orestis Papakyriakopoulos, 
Hochschule f&#252;r Politik M&#252;nchen an der Technischen 
Universit&#228;t M&#252;nchen zum Thema &#8222;Die Algorithmische
Verzerrung der politischen Kommunikation auf Sozialen 
Medien&#8220; am 16.12.2019
13.12.2019 16.12.2019
14 Impulsvortrag von Dr. Aljoscha Burchardt
(sachverst&#228;ndiges Mitglied der Enquete-Kommission KI)
zum Thema &#8222;Hate Speech&#8220; am 16.12.2019.
13.12.2019 16.12.2019
15 Handlungsempfehlungen von Orestis Papakyriakopoulos, 
Hochschule f&#252;r Politik M&#252;nchen an der Technischen 
Universit&#228;t vom 16.12.2019
13.12.2019
16 Impulsvortrag von Frau Dr. Tina Kl&#252;wer
(sachverst&#228;ndiges Mitglieder der Enquete-Kommission
KI) zu den Themen Chatbots, Social Media-Monitoring, 
Sprachassistenzsysteme, Diskursplattformen und Hate
Speach am 16.12.2019
17 Impulsvortrag von Frau Prof. Dr. Christian St&#246;cker
(Hochschule f&#252;r Angewandte Wissenschaften Hamburg)
zu Thema &#8222;Automatisierte Sortierung von 
Medieninhalten&#8220;.
16.12.2019 16.12.2019
18 Handlungsempfehlungen von Herrn Christian Mihr
(Reporter ohne Grenzen).
07.02.2020 10.02.2020
19 Inputpapier von Herrn Dr. Ben Scott (Policy &amp; 
Advocacy).
07.02.2020 10.02.2020
20 Impulsvortrag von Herrn Prof. Dr. Rupprecht Podszun 
(Heinrich Heine Universit&#228;t D&#252;sseldorf) zum Thema 
&#8222;Wettbewerbsrecht&#8220;.
07.02.2020 10.02.2020
21 Handlungsempfehlungen von Herrn Prof. Dr. Rupprecht
Podszun (Heinrich Heine Universit&#228;t D&#252;sseldorf).
07.02.2020 10.02.2020
Projektgruppendrucksache
19(27)PG 6-
&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
22 Impulsvortrag von Frau Dr. Anja Zimmer (Medienanstalt
Berlin-Brandenburg) zum Thema &#8222;Regulierung von 
Medienintermedi&#228;ren&#8220;.
07.02.2020 10.02.2020
23 Handlungsempfehlungen von Frau Dr. Anja Zimmer
(Medienanstalt Berlin-Brandenburg)
07.02.2020 10.02.2020
24 Impulsvortrag von Herrn Dr. Stefan Heumann
(sachverst&#228;ndiges Mitglied der Enquete-Kommission
KI)) zum Thema &#8222;Internationalen
Regulierungsbestrebungen&#8220;.
11.02.2020 10.02.2020
25 Inputpapier von Herrn Prof. Dr. Rupprecht Podszun 
(Heinrich Heine Universit&#228;t D&#252;sseldorf) zum Thema
&#8222;Wettbewerbsrecht&#8220;.
11.02.2020 10.0.2020
26 Beantwortung des von uns &#252;bersandten Fragebogens zum
Thema Social Bots an Prof. Dr.-Ing. Florian Gallwitz
(Technische Hochschule N&#252;rnberg)
17.02.2020
27 Beantwortung des von uns &#252;bersandten Fragebogens zum
Thema Social Bots an Prof. Dr. Simon Hegelich 
(Technische Universit&#228;t M&#252;nchen)
17.02.2020
28 Beantwortung des von uns &#252;bersandten Fragebogens zum
Thema Social Bots an Frau Tabea Wilke (botswatch
Technologies GmbH)
17.02.2020
29 Beantwortung des von uns &#252;bersandten Fragebogens zum
Thema Social Bots an das BSI, Herrn Dr. Gerhard
Schabh&#252;ser (Vizepr&#228;sident des BSI)
17.02.2020
30 Beantwortung des von uns &#252;bersandten Fragebogens zum
Thema Social Bots an den Bundeswahlleiter Dr. Georg 
Thiel.
17.02.2020
31 Beantwortung des von uns &#252;bersandten Fragebogens zum
Thema Social Bots an das Bundeskriminalamt (BKA).
19.02.2020
32 Impulsvortrag von Herrn Prof. Dr. Jan Bernd Nordemann 
(Humboldt-Universit&#228;t zu Berlin) zum Thema 
&#8222;Urheberrecht&#8220;.
27.02.2020 02.03.2020
33 Impulsvortrag von Frau Prof. Dr. Anne Lauber-R&#246;nsberg 
LL.M. (Technische Universit&#228;t Dresden).
28.02.2020 02.03.2020
34 Handlungsempfehlungen von Frau Prof. Dr. Anne
Lauber-R&#246;nsberg LL.M. (Technische Universit&#228;t
Dresden).
28.02.2020 02.03.2020
2.4.8 Liste der Materialien der Enquete-Kommission
K-MAT-Nr. Inhalt Eingang Sekretariat Umfang
19(27)1 Ver&#246;ffentlichtes Papier der Stiftung Neue 
Verantwortung vom Januar 2018. &#220;bersandt von Herrn 
Dr. Stefan Heumann.
17.09.2018 40 Seiten
19(27)2 Ver&#246;ffentlichtes Eckpunktepapier einer nationalen 
Strategie f&#252;r K&#252;nstliche Intelligenz der Stiftung Neue
Verantwortung vom Mai 2018. &#220;bersandt von Herrn 
Dr. Stefan Heumann.
17.09.2018 32 Seiten
19(27)3 Ver&#246;ffentlichtes Papier der Bertelsmann Stiftung vom
Februar 2018. Empfohlen von Frau Prof. Dr. Katharina 
Zweig.
18.10.2018 40 Seiten
19(27)4 Ver&#246;ffentlichtes Papier des Kompetenzzentrums
&#214;ffentliche IT Fraunhofer-Institut f&#252;r Offene
Kommunikationssysteme FOKUS. Empfohlen von Frau 
Prof. Dr. Katharina Zweig.
18.10.2018 44 Seiten
19(27)5 Ver&#246;ffentlichtes Papier der Bayerischen Landeszentrale 
f&#252;r neue Medien von 2017. Empfohlen von Frau Prof. 
Dr. Katharina Zweig.
18.10.2018 36 Seiten
19(27)6 Ver&#246;ffentlichte Studie des Sachverst&#228;ndigenrat f&#252;r
Verbraucherfragen vom 31. Oktober 2018. Empfohlen 
von Frau Prof. Dr. Katharina Zweig.
14.11.2018 191 Seiten
19(27)7 Fraunhofer Umsicht Heft 2. &#220;bersandt von Herrn 
Dr. Thomas Marzi.
14.11.2018 114 Seiten
19(27)8 Papier der Konrad Adenauer Stiftung: Vergleich 
nationaler Strategien zur F&#246;rderung von K&#252;nstlicher
Intelligenz, Teil 1
19.11.2018 83 Seiten
19(27)9 Strategiepapier zur K&#252;nstlichen Intelligenz der
Bundesregierung
Stand: November 2018
22.11.2018 47 Seiten
19(27)10 Draft Ethics Guidelines for Trustworthy AI, The
European Commission&#8217;s High-Level Expert Group on 
Artificial Intelligence, Working Document for
Stakeholder&#8217;s Consultation, 18. Dezember 2018
15.01.2019 37 Seiten
19(27)11 Papier des Bundesministeriums f&#252;r Wirtschaft und 
Energie vom 19. Februar 2019 &#8222;A Franco-German
Manifesto for a European industrial policy fit for the
21st Century&#8220;. &#220;bersandt von Prof. Dr. Wolfgang Ecker.
20.02.2019 4 Seiten
19(27)12 Positionspapier der deutschen E-Commerce-Wirtschaft.
&#220;bersandt vom Bundesverband E-Commerce und 
Versandhandel Deutschland e. V. (bevh), Rechtsanwalt
Sebastian Schulz.
20.02.2019 7 Seiten
19(27)13 DGB-Impulspapier zum Thema K&#252;nstliche Intelligenz
und die Arbeit von morgen. &#220;bersandt von Lothar
Schr&#246;der.
21.02.2019 6 Seiten
K-MAT-Nr. Inhalt Eingang Sekretariat Umfang
19(27)14 Papier der Independet High-Level Expert Group on 
Artificial Intelligence. AI Definition. &#220;bersandt von 
Julia Dunker.
11.04.2019 9 Seiten
19(27)15 Papier der Independet High-Level Expert Group on 
Artificial Intelligence. AI Ethics Guidelines. &#220;bersandt
von Julia Dunker.
11.04.2019 41 Seiten
19(27)16 Papier der Stiftung Neue Verantwortung zum Thema
Wettbewerb von Daten von Dr. Stefan Heumann und 
Dr. Nicola Jentzsch.
24.04.2019 28 Seiten
19(27)17 Recommendation of the Council on OECD Legal
Instruments Artificial Intelligence. &#220;bersandt von 
Prof. Dr. Wolfgang Ecker
23.05.2019 12 Seiten
19(27)18 Policy an Investment Recommendations for Trustworthy
AI, High-Level Expert Group on Artificial Intelligence
vom 26.06.2019
27.06.2019 52 Seiten
19(27)19 Gutachten der Datenethikkommission 23.10.2019 240 Seiten
19(27)20 Bericht der Kommission Wettbewerbsrecht 4.0 23.10.2019 92 Seiten
19(27)21 Policy and Investment Recommendations for
Trustworthy AI, High-Level Expert Group on Artificial 
Intelligence.
02.12.2019 52 Seiten
19(27)22 Offensive Mittellstand: Umsetzungshilfen Arbeit 4.0 29.01.2020 476 Seiten
19(27)23 Brosch&#252;re des Bundesministerium f&#252;r Wirtschaft und 
Energie zum Thema &#8222;Einsatz von KI in der Deutschen 
Wirtschaft&#8220;
01.04.2020 43 Seiten
19(27)24 Positionspapier des Gesamtverbandes der Deutschen 
Versicherungswirtschaft e. V. zum Thema &#8222;Verwendung 
von Algorithmen in der Versicherungswirtschaft&#8220;
02.04.2020 7 Seiten
19(27)25 Positionspapier des Gesamtverbandes der Deutschen 
Versicherungswirtschaft zum Gutachten der
Datenethikkommission
02.04.2020 9 Seiten
19(27)26 Schreiben von ACM, das in den USA ver&#246;ffentlicht
wurde und sich auf die KI Software-basierte 
Ger&#228;tesicherheit f&#252;r die FDA. &#220;bersandt von Prof. 
Roberto V. Zicari.
19(27)27 Policy Brief des SVRV (Sachverst&#228;ndigenrat f&#252;r 
Verbraucherschutz) zur Corona-Warn-App vom Juni
2020.
10.06.2020 39 Seiten
19(27)28 Anschreiben des VDE (Verband der Elektrotechnik 
Elektronik Informationstechnik) zur &#220;bersendung des
Reports &#8222;Wie sich ethische Prinzipien f&#252;r K&#252;nstliche
Intelligenz in die Praxis &#252;bertragen lassen&#8220;.
12.06.2020 2 Seiten
19(27)29 AIEI Group: AI Ethics &#8211; From Principles to Practice
(Englische Originalfassung). &#220;bersandt von Markus B. 
Jaeger (VDE &#8211; Verband der Elektrotechnik Elektronik 
Informationstechnik)
12.06.2020 56 Seiten
K-MAT-Nr. Inhalt Eingang Sekretariat Umfang
19(27)30 AIEI Group: AI Ethics &#8211; From Principles to Practice
(Deutsche Kurzfassung). &#220;bersandt von Markus B. 
Jaeger (VDE &#8211; Verband der Elektrotechnik Elektronik 
Informationstechnik)
12.06.2020 13 Seiten
19(27)31 Stellungnahme &#8222;Grundlegung einer
verbrauchergerechten Regulierung
interaktionsmittelnder Plattformfunktionalit&#228;ten&#8220; vom
Sachverst&#228;ndigenrat f&#252;r Verbraucherfragen (SVRV)
17.06.2020 82 Seiten
19(27)32 Weltweite Datenschutzgesetze zur Verarbeitung
&#246;ffentlicher Bild- und Videodaten von brighter AI in 
Kooperation mit dem KI Bundesverband (eingereicht
von Frau Dr. Tina Kl&#252;wer)
20.08.2020 22 Seiten
19(27)33 Whitepaper &#8222;Ethik und K&#252;nstliche Intelligenz: Was
k&#246;nnen technische Normen und Standards leisten?&#8220; von 
DKE und DIN (eingereicht von Herrn Johannes Koch, 
VDE - Verband der Elektrotechnik Elektronik 
Informationstechnik e. V.).
05.10.2020 62 Seiten
19(27)34 Studie des Rathenau-Instituts: More grip on digitisation: 
An international comparison of parliamentary working 
methods&#8217;
09.10.2020 90 Seiten
2.4.9 Liste der Materialien der Projektgruppe 3 &#8222;KI und Gesundheit&#8220;
Projektgruppenmaterialie
19(27)PG 3-
&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
1 Studie zu Digital Health von Herrn Achim Berg, 
Bitkom-Pr&#228;sident, vom 08. Mai 2019. &#220;bersandt von 
Susanne Dehmel (Bitkom und sachverst&#228;ndiges
Mitglieder der Enquete-Kommission KI)
09.05.2019
2 Impulsvortrag von Frau Prof. (i. R.) Dr. M.-E. Karsten
zum Thema &#8222;Digitale Anforderungen an die
Ausbildungen in Sozial- u. Erziehungsberufen&#8220; in der
Sitzung am 01.04.2019 in der Enquete-Kommission
Berufliche Bildung in der digitalen Arbeitswelt.
23.05.2019
3 Impulsvortrag von Frau Michaela Evans zum Thema 
&#8222;Anforderungen an die Ausbildung im Betrieb&#8220; in der
Sitzung am 01.04.2019 in der Enquete-Kommission
Berufliche Bildung in der digitalen Arbeitswelt.
23.05.2019
4 Buch &#8222;Die Digitale Transformation der Pflege&#8220; von 
Herrn Arno Elmer und Prof. Dr. David Matusiewicz.
12.06.2019
2.4.10 Liste der Materialien der Projektgruppe 5 &#8222;KI und Mobilit&#228;t&#8220;
Projektgruppenmaterialie
19(27)PG 5-
&#8230;
Art, Datum, Inhalt Eingang/Verteilung am
Beschlossen/
Behandelt am
1 Bericht von duisport zum Thema &#8222;Digitalisierung und 
Teilautomatisation&#8220; im Dezember 2019
19.12.2019
2.4.11 Anh&#246;rungsg&#228;ste der Enquete-Kommission
Nr. Datum Art Gegenstand Dauer(Minuten)
Protkollumfang
(Seiten)
1 27.09.18 &#246;ffentlich Konstituierung 98 6
2 27.09.18 nicht&#246;ffentlich Beratungssitzung 21 6
3 15.10.18 teil&#246;ffentlich Klausurtagung/
Sachverst&#228;ndigenanh&#246;rung
Dr. Aljoscha Burchardt
Prof. Dr. Antonio Kr&#252;ger
Prof. Dr. Katharina Zweig
Prof. Dr. Hannah Bast
Prof. Dr.-Ing. Sami Haddadin
(sachverst&#228;ndige Mitglieder der
Enquete-Kommission KI)
Britta Oertel/Dr. Steffen Albrecht
(TAB)
423 32
4 05.11.18 teil&#246;ffentlich Sachverst&#228;ndigenanh&#246;rung
Dr. Carl-Christian Buhr
(stellvertretender Kabinettschef der EU-
Kommissarin Mariya Gabriel)
Saskia Steinacker
(Global Head Digital Transformation at
Bayer, New York)
Dr. Stefan Heumann
Prof. Dr. J&#246;rg M&#252;ller-Lietzkow
(sachverst&#228;ndige Mitglieder der
Enquete-Kommission KI)
243 63
5 10.12.18 teil&#246;ffentlich Sachverst&#228;ndigenanh&#246;rung
Oliver Wittke
(Parlamentarischer Staatssekret&#228;r beim
Bundesminister f&#252;r Wirtschaft und
Energie)
Dr. Michael Meister
(Parlamentarischer Staatssekret&#228;r bei der
Bundesministerin f&#252;r Bildung und 
Forschung)
Hubertus Heil
(Bundesminister f&#252;r Arbeit und
Soziales)
261 67
Nr. Datum Art Gegenstand Dauer(Minuten)
Protkollumfang
(Seiten)
Dr. Tina Kl&#252;wer
Dr. Sebastian Wieczorek
(sachverst&#228;ndige Mitglieder der
Enquete-Kommission KI)
6. 14.01.19 teil&#246;ffentlich Klausurtagung/
Sachverst&#228;ndigenanh&#246;rung
Prof. Dr. Knut L&#246;schke
Prof. Dr. Alexander Filipovi&#263;
Andrea Martin
Prof. Dr. Katharina Zweig
Prof. Dr. Hannah Bast
Lothar Schr&#246;der
(sachverst&#228;ndige Mitglieder der
Enquete-Kommission KI)
Henrik Tesch
(debatoo)
360 59
7. 11.02.19 teil&#246;ffentlich Sachverst&#228;ndigenanh&#246;rung
Susanne Dehmel
Lena-Sophie M&#252;ller
(sachverst&#228;ndige Mitglieder der
Enquete-Kommission KI)
124 29
8. 11.03.19 teil&#246;ffentlich Sachverst&#228;ndigenanh&#246;rung
Prof. Dr. Alexander Filipovi&#263;
(sachverst&#228;ndiges Mitglied der Enquete-
Kommission KI)
Prof. Dr. Emmanuel M&#252;ller
(Fraunhofer-Gesellschaft)
Prof. Dr. Morris Riedel
(Helmholtz Gemeinschaft)
Prof. Dr. S&#246;ren Auer
(Leibniz-Gemeinschaft)
Prof. Dr. Klaus-Robert M&#252;ller
(Max-Planck-Gesellschaft)
167 37
9. 01.04.19 teil&#246;ffentlich Sachverst&#228;ndigenanh&#246;rung
Prof. Dr. Joachim Fetzer
(Deutsche Netzwerk Wirtschaftsethik)
Dr. Tanja R&#252;ckert
(Bosch Building Technologies)
Hans-Christian Boos
(arago GmbH)
Roy Uhlmann
(Bundesverband Deutsche Startups)
Johannes M&#252;ller
(Netzwerk CorrelAid)
190 46
10. 06.05.19 teil&#246;ffentlich Sachverst&#228;ndigenanh&#246;rung
Carla Hustedt
(Bertelsmann Stiftung)
154 42
Nr. Datum Art Gegenstand Dauer(Minuten)
Protkollumfang
(Seiten)
Prof. Dr. Axel Metzger
(Humboldt-Universit&#228;t Berlin)
Michael Teigeler
(VDE)
Dr. Sebastian Hallensleben
(VDE)
11. 03.06.19 teil&#246;ffentlich Sachverst&#228;ndigenanh&#246;rung
Prof. Dr. Judith Simon
(Universit&#228;t Hamburg)
Dr. Stefan Heumann
(sachverst&#228;ndiges Mitglied der Enquete-
Kommission KI)
Prof. Dr. Boris Otto
(Fraunhofer-Institut f&#252;r Software- und 
Systemtechnik / International Data 
Space)
Prof. Dr. Norbert Pohlmann
(Westf&#228;lische Hochschule 
Gelsenkirchen)
Elisabeth Lindinger
(Open Knowledge Foundation)
156 43
12. 09.09.19 nicht&#246;ffentlich Beratungssitzung 131 28
13. 14.10.19 nicht&#246;ffentlich Beratungssitzung 54 14
14. 04.11.19 teil&#246;ffentlich Sachverst&#228;ndigenanh&#246;rung
Prof. Dr. med. Christiane Woopen
(Datenethikkommission der
Bundesregierung und
Universit&#228;tklinikum K&#246;ln)
Prof. Dr. Christiane Wendehorst
(Co-Sprecherin der
Datenethikkommission)
Hansj&#246;rg Durz, MdB
Falko Mohrs, MdB
(ordentliche Mitglieder der Enquete-
Kommission KI)
109 33
15 29./
30.11.19
nicht&#246;ffentlich Klausurtagung 542 46
16 09.12.19 teil&#246;ffentlich Sachverst&#228;ndigenanh&#246;rung
Fabian Reetz
(Stiftung Neue Verantwortung)
Prof. Dr.-Ing. Sami Haddadin
Prof. Dr. Wolfgang Ecker
Dr. Florian Butollo
(sachverst&#228;ndige Mitglieder der
Enquete-Kommission KI)
134 37
17 13.01.20 teil&#246;ffentlich Sachverst&#228;ndigenanh&#246;rung 135 34
Nr. Datum Art Gegenstand Dauer(Minuten)
Protkollumfang
(Seiten)
Ulrich Kelber
(Der Bundesbeauftragte f&#252;r den 
Datenschutz und die
Informationsfreiheit)
Eva Gardyan-Eisenlohr
(Bayer AG)
Tim Wybitul
(RA Latham &amp; Watkins)
Oliver S&#252;me
(eco-Verband)
18 10.02.20 teil&#246;ffentlich Sachverst&#228;ndigenanh&#246;rung
Prof. Dr. Katharina Zweig
(sachverst&#228;ndiges Mitglied der Enquete-
Kommission KI)
Prof. Roberto V. Zicari
(Initiative Z-inspection)
Rebakka Weiss
(Bitkom)
Mathias Spielkamp
(Algorithmwatch)
Lina Ehrig
(Verbraucherzentrale Bundesverband)
148 38
19 02.03.20 teil&#246;ffentlich Sachverst&#228;ndigenanh&#246;rung
Prof. Dr. Boris Hollas
Susanne Dehmel
(sachverst&#228;ndige Mitglieder der
Enquete-Kommission KI)
Veronika Eckstein 
(Airbus)
Dr. Janna Lipenkova
(Anacode / krankheitsbedingt abgesagt)
Julia Kloiber
(Superrr Lab)
144 38
20 04.05.20 nicht&#246;ffentlich
Web-Konferenz)
Sachverst&#228;ndigenanh&#246;rung
Christiane Canenbley
(Stellvertretende Kabinettchefin der
gesch&#228;ftsf&#252;hrenden Vizepr&#228;sidentin der
Europ&#228;ischen Kommission, Margarethe
Vestager)
Dr. Verena Weber
(Head of Communication Infrastructures
and Services Unit, Directorate for 
Science, Technology and Innovation,
OECD)
126 34
21 15.06.20 nicht&#246;ffentlich
(Web-Konferenz)
Beratungssitzung 159 34
22 29.06.20 nicht&#246;ffentlich
(Web-Konferenz)
Beratungssitzung 88 21
Nr. Datum Art Gegenstand Dauer(Minuten)
Protkollumfang
(Seiten)
23 07.09.20 nicht&#246;ffentlich
(Web-Konferenz)
Beratungssitzung 186 39
24 05.10.20 nicht&#246;ffentlich
(Web-Konferenz)
Beratungssitzung 123 25
25 26.10.20 nicht&#246;ffentlich
(Web-Konferenz)
Beratungssitzung/
Abschlusssitzung
2.4.12 Anh&#246;rungsg&#228;ste der Projektgruppen
2.4.12.1 Projektgruppe 1 &#8222; KI und Wirtschaft&#8220;
Nr. Datum Art Gegenstand
1 11.02.19 nicht&#246;ffentlich Konstituierende Sitzung
2 11.03.19 nicht&#246;ffentlich Anh&#246;rungssitzung
J&#246;rg Bienert
(aiso-lab, KI-Bundesverband)
Iris Pl&#246;ger
(BDI e. V.)
Prof. Dr. Emmanuel M&#252;ller
(Fraunhofer IAIS)
Prof. Dr. Svenja Falk
(Accenture GmbH, Plattform Lernende Systeme / acatech))
3 01.04.19 nicht&#246;ffentlich Anh&#246;rungssitzung
Dr. Tina Kl&#252;wer
(sachverst&#228;ndiges Mitglied der Enquete-Kommission KI)
Alexandra Horn
(BVMW)
Falko Mohrs, MdB
(ordentliches Mitglied der Enquete-Kommission KI)
Prof. Dr. Philipp Staab
(Humboldt-Universit&#228;t zu Berlin und Einstein Center Digital Future)
Prof. Dr. Wolfgang Ecker
(sachverst&#228;ndiges Mitglied der Enquete-Kommission KI)
Alexander Waldmann
(appliedAI-Initiative von UnternehmerTUM)
4 08.04.19 nicht&#246;ffentlich Klausurtagung
Prof. Dr. Patrick van der Smagt
(Volkswagen AG, Data Lab M&#252;nchen)
Prof. Dr. Volker Tresp
(Siemens AG)
Dr. Michael M&#252;ller-W&#252;nsch
(OTTO-Group)
Dr. Mikio Braun
(Zalando SE)
Dr. Ramin Assadollahi
(ExB Labs GmbH)
Nr. Datum Art Gegenstand
Michael Bruch und Dr. Henning Schult
(Allianz SE)
Nicolas Kipp
(RatePay GmbH)
Oliver Fu&#223;winkel und Dr. Thomas Decker
(BaFin)
Michael B&#252;ltmann
(Here Deutschland GmbH)
Patrick Bunk
(ubermetrics Technologies GmbH)
Prof. Dr. Heiner Lasi
(FSTI)
Fabian Westerheide
(Asgard Capital Verwaltung GmbH)
Dr. Kathrin Leonhardt
(KfW)
Christin Sch&#228;fer
(acs plus und Datenethikkommission)
David Kriesel
(Datenwissenschaftler)
Dr. Reinhard Messerschmidt
(WBGU)
Dr. Daniel Halmer
(LexFox GmbH)
Lina Ehrig
(vzbv)
5 06.05.19 nicht&#246;ffentlich Anh&#246;rungssitzung
Prof. Dr. Axel Metzger
(Humboldt-Universit&#228;t zu Berlin)
Michael Teigeler
(VDE)
Dr. Sebastian Hallensleben
(VDE)
Martin Schallbruch
(Digital Society Institut der ESMT Berlin unt Kommission
Wettbewerbsrecht 4.0 des BMWi)
Matthis Eicher und Sibylle Gabler
(DIN Arbeitsausschuss f&#252;r K&#252;nstliche Intelligenz)
6 03.06.19 nicht&#246;ffentlich Beratungssitzung
7 24.06.19 nicht&#246;ffentlich Klausurtagung
8 02.09.19 nicht&#246;ffentlich Klausurtagung
9 09.09.19 nicht&#246;ffentlich Beratungssitzung
10 14.10.19 nicht&#246;ffentlich Beratungssitzung
2.4.12.2 Projektgruppe 2 &#8222;KI und Staat&#8220;
Nr. Datum Art Gegenstand
1 11.02.19 nicht&#246;ffentlich Konstituierende Sitzung
2 18.02.19 nicht&#246;ffentlich Beratungssitzung der AG 1
3 11.03.19 nicht&#246;ffentlich Anh&#246;rungssitzung
Prof. Dr. Katharina Zweig
(sachverst&#228;ndiges Mitglied der Enquete-Kommission KI)
Matthias Fl&#252;gge
(Fraunhofer FOKUS)
Anke Domscheit-Berg, MdB
(ordentliches Mitglied der Enquete-Kommission KI)
4 18.03.19 nicht&#246;ffentlich Beratungssitzung der AG 1
5 01.04.19 nicht&#246;ffentlich Anh&#246;rungssitzung
Dr. J&#246;rg Dr&#228;ger
(Bertelsmann Stiftung)
Christiane Boschin-Heinz
(Stadt Paderborn)
Prof. Dr. J&#246;rg M&#252;ller-Lietzkow
(sachverst&#228;ndiges Mitglied der Enquete-Kommission KI)
Saskia Esken, MdB
(ordentliches Mitglied der Enquete-Kommission KI)
6 06.05.19 nicht&#246;ffentlich Anh&#246;rungssitzung
MDg Andreas K&#246;nen
(BMI)
Lorena Jaume-Palasi
(The Ethical Tech Society)
Prof. Dr. Hans-J&#246;rg Kreowski
(Forum InformatikerInnen f&#252;r Frieden und gesellschaftliche
Verantwortung e. V.)
R&#252;diger Bohn
(Ausw&#228;rtiges Amt)
7 13.05.19 nicht&#246;ffentlich Beratungssitzung
8 03.06.19 nicht&#246;ffentlich Anh&#246;rungssitzung
Dr. Sven Herpig
(Stiftung Neue Verantwortung)
9 24.06.19 nicht&#246;ffentlich Beratungssitzung
10 02.09.19 nicht&#246;ffentlich Klausurtagung
2.4.12.3 Projektgruppe 3 &#8222;KI und Gesundheit&#8220;
Nr. Datum Art Gegenstand
1 11.02.19 nicht&#246;ffentlich Konstituierende Sitzung
2 11.03.19 nicht&#246;ffentlich Anh&#246;rungssitzung
Lisa Witte-Stremmel
(BMG)
Nr. Datum Art Gegenstand
Prof. Dr. Veronika von Messling
(BMBF)
RDn Dr. Ute Petereit
(BMBF)
ORR Hanno Windler
(BMBF)
Susanne Dehmel
(sachverst&#228;ndiges Mitglied der Enquete-Kommission KI)
Prof. Dr.-Ing. Sami Haddadin
(sachverst&#228;ndiges Mitglied der Enquete-Kommission KI)
3 01.04.19 nicht&#246;ffentlich Anh&#246;rungssitzung
Prof. Dr. Peter Dabrock
(Vorsitzender des Deutschen Ethikrats und Friedrich-Alexander-Universit&#228;t 
Erlangen-N&#252;rnberg)
Prof. Dr. Martin Hrab&#233; de Angelis
(Helmholtz Zentrum M&#252;nchen und INFRAFRONTIER)
Prof. Dr. Philipp Berens
(Universit&#228;tsklinikum T&#252;bingen)
Prof. Dr. med. Sylvia Thun
(Berlin Institute of Health)
Prof. Dr. Okan Ekinci
(F. Hoffmann-La Roche Ltd)
4 06.05.19 nicht&#246;ffentlich Anh&#246;rungssitzung
Prof. Dr. Christiane Woopen
(Datenethikkommission und Universit&#228;tsklinikum K&#246;ln)
Dr. Thilo Weichert
(Netzwerk Datenschutzexpertise, DVD)
Prof. Dr. Peter Haas
(Fachhochschule Dortmund)
Sebastian Claudius Semler
(TMF)
Dr. Philipp Storz-Pfennig
(GKV-Spitzenverband)
5 13.05.19 nicht&#246;ffentlich Anh&#246;rungssitzung
Prof. Dr. Dr. Eric Hilgendorf
(Universit&#228;t W&#252;rzburg)
Dr. Alexander K&#246;nig
(Reactive Robotics)
Prof. Dr. med Siegfried Jedamzik
(Bayerische TelemedAllianz)
Dipl.-Ing. Oliver Christ
(NSF International)
Dr. Sebastian Hallensleben
(VDE)
Bernd Falk 
(Malteser Hilfsdienst)
Prof. Dr. theol. habil. Arne Manzeschke
(Ev. Hochschule N&#252;rnberg)
Prof. Dr. David Matusiewicz
(FOM)
Nr. Datum Art Gegenstand
Sebastian Hofstetter, M.A.
(Medizinische Fakult&#228;t der Martin-Luther-Universit&#228;t / Halle)
6 03.06.19 nicht&#246;ffentlich Beratungssitzung
7 24.06.19 nicht&#246;ffentlich Beratungssitzung
8 02.09.19 nicht&#246;ffentlich Beratungssitzung
9 09.09.19 nicht&#246;ffentlich Beratungssitzung
10 14.10.19 nicht&#246;ffentlich Beratungssitzung
2.4.12.4 Projektgruppe 4 &#8222;KI und Arbeit&#8220;
Nr. Datum Art Gegenstand
1 14.10.19 nicht&#246;ffentlich Konstituierende Sitzung
2 04.11.19 nicht&#246;ffentlich Beratungssitzung
3 25.11.19 nicht&#246;ffentlich Anh&#246;rungssitzung
Prof. Dr. Enzo Weber
(Institut f&#252;r Arbeitsmarkt und Berufsforschung)
Dr. Terry Gregory
(Institute of Labor Economics (IZA); Leibniz-Zentrum f&#252;r Europ&#228;ische
Wirtschaftsforschung (ZEW))
Dr. Julia Borggr&#228;fe
(Bundesministerium f&#252;r Arbeit und Soziales)
Prof. Dr. Lisa Herzog
(Universit&#228;t Groningen)
Prof. Dr. Jens S&#252;dekum
(D&#252;sseldorf Institute for Competition Economics)
Oliver Suchy
(Deutscher Gewerkschaftsbund)
4 09.12.20 nicht&#246;ffentlich Anh&#246;rungssitzung
Thomas Langkabel
(Microsoft Deutschland)
Dr. Britta Matthes
(Institut f&#252;r Arbeitsmarkt- und Berufsforschung)
Andrea Martin
(sachverst&#228;ndiges Mitglied der Enquete-Kommission KI)
Prof. Dr. Antonio Kr&#252;ger
(sachverst&#228;ndiges Mitglied der Enquete-Kommission KI)
Dr. Marie-Christine Fregin
(Wissenschaftszentrum Berlin und Input-Consulting)
Dr. Gerlind Wisskrichen
(Fachanw&#228;ltin f&#252;r Arbeitsrecht, CMS)
Prof. Dr. Lars Adolph
(Bundesanstalt f&#252;r Arbeitsschutz und Arbeitsmedizin)
5 16.12.20 nicht&#246;ffentlich Anh&#246;rungssitzung
Prof. Dr. Ute Schmid
(Universit&#228;t Bamberg)
Susan Beudt
(Educational Technology Lab, DFKI)
Nr. Datum Art Gegenstand
Jan Renz
(Hasso-Plattner-Institut)
Prof. Dr. J&#252;rgen Handke
(Universit&#228;t Marburg)
Eva-Maria Nyckel
(Humboldt-Universit&#228;t zu Berlin)
Matthias Spielkamp
(algorithmwatch)
Dr. Constanze Kurz
(Robert Bosch AG)
Martina Hofmann
(Bundesagentur f&#252;r Arbeit)
Thomas Belker
(Precire Technologies GmbH und Bundesverband der Personalmanager)
Florian Rampelt
(Stifterverband)
Detlef Steppuhn
(Erich-Gutenberg-Berufskolleg K&#246;ln)
Prof. Dr. Wolfgang J&#228;ger
(Hochschule RheinMain)
Prof. Dr. Heidrun Allert
(Christian-Albrechts-Universit&#228;t zu Kiel)
Susanne Dehmel
(sachverst&#228;ndiges Mitglied der Enquete-Kommission KI)
6 13.01.20 nicht&#246;ffentlich Anh&#246;rungssitzung
Prof. Dr.-Ing. habil. Sascha Stowasser
(Institut f&#252;r angewandte Arbeitswissenschaft)
Prof. Dr. Florian Schmidt
(Hochschule f&#252;r Technik und Wirtschaft Dresden)
Dr. Katie Baldschun
(Sozialgericht Dortmund, zum Zeitpunkt des Gespr&#228;ch an 
der Universit&#228;t Kassel)
Marco Grenz 
(IG Metall)
David Beitz
(Arbeitgeberverband Gesamtmetall e. V.)
Anka Grosch
(Betriebsrat Amazon Logistikzentrum Leipzig)
Ralf Lemster
(Bundesverband der Dolmetscher und &#220;bersetzer)
7 10.02.20 nicht&#246;ffentlich Textarbeit
8 02.03.20 nicht&#246;ffentlich Anh&#246;rungssitzung
Prof. Dr. Dr. Fabian Theis
(Helmholtz Zentrum M&#252;nchen)
Dr. Martin Kuhlmann
(Soziologisches Forschungsinstitut G&#246;ttingen)
Prof. Dr. Philipp Hennig
(Universit&#228;t T&#252;bingen und Max-Planck-Institut f&#252;r Intelligente Systeme)
Nr. Datum Art Gegenstand
9 09.03.20 nicht&#246;ffentlich Anh&#246;rungssitzung
Prof. Dr. Ulman Lindenberger
(Max-Planck-Institut f&#252;r Bildungsforschung)
10 11.05.20 nicht&#246;ffentlich Textarbeit
11 18.05.20 nicht&#246;ffentlich Textarbeit
12 25.05.20 nicht&#246;ffentlich Textarbeit
13 08.06.20 nicht&#246;ffentlich Textarbeit
14 15.06.20 nicht&#246;ffentlich Textarbeit
15 22.06.20 nicht&#246;ffentlich Textarbeit
16 06.07.20 nicht&#246;ffentlich Textarbeit
2.4.12.5 Projektgruppe 5 &#8222;KI und Mobilit&#228;t&#8220;
Nr. Datum Art Gegenstand
1 14.10.2019 nicht&#246;ffentlich Konstituierende Sitzung
2 04.11.2019 nicht&#246;ffentlich Anh&#246;rungssitzung
Alexander Mankowsky
(Daimler AG)
Prof. Dr. Stephan Rammler
(Institut f&#252;r Zukunftsstudien und Technologiebewertung/IZT)
3 11.11.2019 nicht&#246;ffentlich Anh&#246;rungssitzung
Dr. Ing. Thomas Thiele
(House of AI Deutsche Bahn AG)
Yves Sterbak
(Protostellar GmbH und Thales Deutschland GmbH)
4 09.12.2019 nicht&#246;ffentlich Anh&#246;rungssitzung
Dr. Christian Seidel
(Airbus Helicopters Deutschland GmbH)
Prof. Dipl.-Ing. Thomas Schlipk&#246;ther
(Duisburger Hafen AG)
5 16.12.2019 nicht&#246;ffentlich Anh&#246;rungssitzung
Dr. Manuel G&#246;tz
(ZF Friedrichshafen)
Andreas Karanas
(Carrypicker GmbH)
Demetrio Aiello
(Continental AG)
Julia Miosga
(DieDigitalLandschaftsG&#228;rtnerin)
Prof. Dr.-Ing. Thomas Form
(Volkswagen AG)
6. 13.01.2020 nicht&#246;ffentlich Anh&#246;rungssitzung
Dr. Tim Wiegels
(Free Now AG)
Nr. Datum Art Gegenstand
Christoph Weigler
(Uber Germany GmbH)
Sabine Seelenmeyer
(SAP SE)
7. 10.02.2020 nicht&#246;ffentlich Anh&#246;rungssitzung
Prof. Dr. Daniel Zimmer
(Universit&#228;t Bonn)
Prof. Dr. Klaus Beckmann
(acatech)
Dr. Dietmar Schl&#246;&#223;er
(T&#220;V Nord Group)
8. 09.03.2020 nicht&#246;ffentlich Klausurtagung
9. 25.05.2020 nicht&#246;ffentlich Textarbeit
10. 03.06.2020 nicht&#246;ffentlich Textarbeit
11. 22.06.2020 nicht&#246;ffentlich Textarbeit
2.4.12.6 Projektgruppe 6 &#8222;KI und Medien&#8220;
Nr. Datum Art Gegenstand
1 14.10.2019 nicht&#246;ffentlich Konstituierende Sitzung
2 04.11.2019 nicht&#246;ffentlich Beratungssitzung
3 09.12.2019 nicht&#246;ffentlich Anh&#246;rungssitzung
Clemens Boisser&#233;e
(Rheinische Post)
Prof. Dr. Klaus Goldhammer
(Freie Universit&#228;t Berlin)
Christian Daubner
(Bayerischer Rundfunk)
Dr.-Ing. Christian Riess
(Universit&#228;t Erlangen-N&#252;rnberg)
4 16.12.2019 nicht&#246;ffentlich Anh&#246;rungssitzung
Jens Redmer
(Google Inc.)
Orestis Papakyriakopoulos
(Hochschule f&#252;r Politik M&#252;nchen an der Technischen Universit&#228;t M&#252;nchen)
Prof. Dr. Christian St&#246;cker
(Hochschule f&#252;r Angewandte Wissenschaften Hamburg)
Dr. Tina Kl&#252;wer
(sachverst&#228;ndiges Mitglied der Enquete-Kommission KI)
Dr. Aljoscha Burchardt
(sachverst&#228;ndiges Mitglied der Enquete-Kommission KI)
5 13.01.2020 nicht&#246;ffentlich Beratungssitzung
6. 10.02.2020 nicht&#246;ffentlich Anh&#246;rungssitzung
Lennart Wetzel
(Microsoft Deutschland)
Dr. Stefan Heumann
(sachverst&#228;ndiges Mitglied der Enquete-Kommission KI)
Nr. Datum Art Gegenstand
Dr. Anja Zimmer
(Medienanstalt Berlin-Brandenburg)
Christian Mihr
(Reporter ohne Grenzen)
Prof. Dr. Rupprecht Podszun
(Universit&#228;t D&#252;sseldorf)
7. 02.03.2020 nicht&#246;ffentlich Anh&#246;rungssitzung
Prof. Dr. Anne Lauber-R&#246;nsberg
(Technische Universit&#228;t Dresden)
Prof. Dr. Jan Bernd Nordemann
(Humboldt-Universit&#228;t zu Berlin)
8. 09.03.2020 nicht&#246;ffentlich Textarbeit
9. 20.04.2020 nicht&#246;ffentlich Textarbeit
10. 11.05.2020 nicht&#246;ffentlich Textarbeit
11. 25.05.2020 nicht&#246;ffentlich Textarbeit
12. 15.06.2020 nicht&#246;ffentlich Textarbeit
G. Anlagen
Anlagen-Nr. Inhalt
1 Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des
Deutschen Bundestages
2 Dokumentation der Ergebnispr&#228;sentation der Enquete-Kommission K&#252;nstliche Intelligenz
des Deutschen Bundestages am 28. September 2020
Gutachten zur Online-Beteiligung der 
Enquete-Kommission K&#252;nstliche Intelligenz 
des Deutschen Bundestages
Auswertung der Online-Beteiligung  
&#169; drmakete lab/Unsplash
&#8211; 723 &#8211;
Anlage 1
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
i 
Impressum 
Liquid Democracy e.V.
Am Sudhaus 2
12053 Berlin 
nexus Institut f&#252;r Kooperationsmanagement  
und interdisziplin&#228;re Forschung GmbH
Willdenowstra&#223;e 38
12203 Berlin 
Autorinnen und Autoren:
Sabine Schr&#246;der, Franziska Detsch, Max Westbrock,&#8211; nexus Institut 
Marie-Kathrin Siemer Liquid Democracy
Auftraggeberin:  
Bundesrepublik Deutschland, vertreten durch den Pr&#228;sidenten des Deutschen Bundestages, 
dieser vertreten durch den Direktor beim Deutschen Bundestag 
Platz der Republik 1
11011 Berlin  
Berlin, August 2020
&#8211; 724 &#8211;
&#8211;
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
ii
Inhalt
Auswertung der Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz ........ 1
1 Einleitung ........................................................................................................................... 1
1.1 Ziele und Inhalte der Online-Beteiligung ...................................................................... 1
1.2 Ablauf der Online-Beteiligung und Output .................................................................... 2
2 Umsetzung der Online-Beteiligung ..................................................................................... 3
2.1 Inhaltlicher Aufbau ....................................................................................................... 3
2.2 Gestaltung der Online-Plattform................................................................................... 4
2.3 Zielgruppen und Teilnehmende.................................................................................... 5
2.4 Auswertungsmethodik .................................................................................................. 7
3 Ergebnisvorstellung entlang der Themenfelder und Diskussionsfragen.............................. 8
3.1 Themenfeld &#8222;Vertrauen und Transparenz&#8220; ................................................................... 8
Frage 1: &#8222;Welche Hoffnungen und Bef&#252;rchtungen verbinden Sie mit dem Einsatz von
KI?&#8220; ............................................................ 9 
Frage 2: &#8222;Inwieweit verlassen Sie sich auf Produkte oder Anwendungen, die mit KI 
arbeiten?&#8220; ....................................................... 14 
Frage 3: &#8222;Inwiefern w&#228;re es f&#252;r Sie hilfreich, wenn KI-Systeme auf m&#246;gliche Risiken hin 
eingesch&#228;tzt und klassifiziert werden?&#8220; .................................. 16 
Frage 4: &#8222;Wie beurteilen Sie die Einf&#252;hrung von Standards f&#252;r KI-Systeme, z. B. eines
anwendungsspezifischen G&#252;tesiegels?&#8220; ................................. 19 
3.2 Themenfeld &#8222;Beruf und Alltag&#8220; ....................................................................................21
Frage 5: &#8222;Welche Ver&#228;nderungen erwarten Sie durch den zunehmenden Einsatz von KI
in der Zukunft?&#8220;................................................... 21 
Frage 6: &#8222;In welchen pers&#246;nlichen Lebensbereichen w&#252;nschen Sie sich eine (st&#228;rkere)
Anwendung von KI?&#8220; ............................................... 25 
Frage 7: &#8222;Wie beurteilen Sie es, dass Informationen im Internet auf die nutzende Person
zugeschnitten werden?&#8220;............................................. 27 
Frage 8: &#8222;Welche Vor- &amp; Nachteile sehen Sie derzeit im Zusammenhang mit dem
Einsatz von KI im privaten und beruflichen Umfeld?&#8220; ........................ 30 
3.3 Themenfeld &#8222;Datennutzung und Datenschutz&#8220; ............................................................33
Frage 9 und 10: &#8222;Mit wem sind Sie bereit, Ihre Daten zu teilen, und warum (jetzt und in
Zukunft)?&#8220; und &#8222;F&#252;r welche KI-Anwendungsbereiche w&#228;ren Sie bereit, Ihre Daten zu 
teilen?&#8220; ......................................................... 33 
Frage 11: &#8222;Welchen Handlungsbedarf sehen Sie bei der bestehenden Regulierung von
Daten mit Blick auf KI?&#8220; ............................................. 37 
3.4 Themenfeld &#8222;Wissen und Forschung&#8220; .........................................................................38
&#8211; 725 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
iii
Frage 12: &#8222;Was verstehen Sie unter KI?&#8220;................................. 38 
Frage 13: &#8222;Wie und durch wen sollte Wissen &#252;ber KI verst&#228;rkt vermittelt werden?&#8220; .. 42 
Frage 14: &#8222;Welche Informationen ben&#246;tigen Sie, um Funktionen und Nutzen von KI zu
verstehen?&#8220;...................................................... 46 
Frage 15: &#8222;Zu welchen Bereichen von KI sollte in Deutschland mehr geforscht werden?&#8220;
 .............................................................. 48 
3.5 Themenfeld &#8222;Weitere Anregungen zu KI&#8220; ....................................................................51
Frage 16: &#8222;Welche Forderungen oder Anregungen haben Sie dar&#252;ber hinaus zum 
Einsatz von KI in Deutschland?&#8220; ....................................... 51 
4 Zusammenfassung............................................................................................................53
Anhang.................................................................................................................................. 1
Die Fragen der Online-Beteiligung im &#220;berblick .................................................................... 1
Themenfeld 1 &#8222;Vertrauen und Transparenz&#8220; ............................... 1 
Themenfeld 2 &#8222;Beruf und Alltag&#8220; ....................................... 2 
Themenfeld 3 &#8222;Datennutzung und Datenschutz&#8220; ............................ 2 
Themenfeld 4 &#8222;Wissen und Forschung&#8220;................................... 3 
Themenfeld 5 &#8222;Weitere Anregungen zu KI&#8220; ................................ 4
&#8211; 726 &#8211;
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
1 
1 EINLEITUNG
Die Enquete-Kommission &#8222;K&#252;nstliche Intelligenz Gesellschaftliche Verantwortung und
wirtschaftliche, soziale und &#246;kologische Potenziale&#8220; des Deutschen Bundestages soll den
zuk&#252;nftigen Einfluss der K&#252;nstlichen Intelligenz (KI) auf das gesellschaftliche (Zusammen-)Leben,
die deutsche Wirtschaft und die Arbeitswelt untersuchen. Es werden sowohl die Chancen als
auch die Herausforderungen der KI f&#252;r Gesellschaft, Staat und Wirtschaft sowie damit in
Zusammenhang stehende technische, rechtliche und ethische Fragen beleuchtet. Der Auftrag 
der Enquete-Kommission ist es, auf Basis ihrer Untersuchungsergebnisse den staatlichen
Handlungsbedarf auf nationaler, europ&#228;ischer und internationaler Ebene zu identifizieren und
zu beschreiben, um sowohl die Chancen der KI wirtschaftlich und gesellschaftlich nutzbar zu
machen als auch ihre Risiken zu minimieren.
1.1 Ziele und Inhalte der Online-Beteiligung 
Die Enquete-Kommission K&#252;nstliche Intelligenz hat vor diesem Hintergrund ein Gutachten in
Auftrag gegeben, um Meinungen und Perspektiven aus der Fach&#246;ffentlichkeit sowie von
B&#252;rgerinnen und B&#252;rgern zur Bedeutung und zur zuk&#252;nftigen Entwicklung von KI im Hinblick auf
soziale, &#246;kologische und &#246;konomische Chancen, Herausforderungen und Handlungsbedarfe
zu erheben. Ziel ist es, die Thesen und Handlungsempfehlungen der thematischen
Projektgruppen der Enquete-Kommission mit der Bev&#246;lkerung r&#252;ckzukoppeln. Die Ergebnisse der
Online-Beteiligung sollen im Rahmen des Abschlussberichts ber&#252;cksichtigt werden.
Die St&#228;rke des Formats der Online-Beteiligung liegt in der freien Zug&#228;nglichkeit f&#252;r alle
Interessierten, in der Transparenz des Erhebens von Meinungen und Ideen einer m&#246;glichst
heterogenen Gruppe von Menschen sowie in der Diskussion der Teilnehmenden und damit
gleichzeitigen M&#246;glichkeit zur gesellschaftlichen Meinungsbildung. Online-Beteiligungen k&#246;nnen
unabh&#228;ngig von Zeit und Ort aufgerufen werden und erm&#246;glichen so einen flexiblen Zugang. Die 
Online-Beteiligung erm&#246;glicht einen Eindruck der gesellschaftlichen Perspektiven auf KI und
deren Auswirkungen und zeigt argumentative Zusammenh&#228;nge auf, welche beispielsweise 
durch eine quantitative Umfrage nicht h&#228;tten erhoben werden k&#246;nnen. Quantitative Umfragen
zielen darauf ab, Wissensst&#228;nde und Meinungen repr&#228;sentativ abzufragen und in Zahlen
wiederzugeben. Die Online-Beteiligung diente hingegen nicht dem Zweck, repr&#228;sentative
Meinungsbilder der verschiedenen Zielgruppen zu erheben. Vielmehr stehen bei einer Online-
Beteiligung die Diskussion und der deliberative Austausch unter den Teilnehmenden und
zwischen Teilnehmenden sowie den Mitgliedern der Enquete-Kommission im Vordergrund.
Gew&#228;hrleistet wurde dies durch das Stellen offener Diskussionsfragen mit unterschiedlichem
Abstraktionsniveau in Anlehnung an die verschiedenen Interessenlagen und
Wissensbest&#228;nde zu KI bei den Zielgruppen sowie die Arbeitsauftr&#228;ge der Enquete-Kommission. Im
Aufdecken der Meinungsvielfalt, argumentativen &#220;bereinstimmungen und Tendenzen sowie
davon abweichenden Positionen liegt die St&#228;rke und die Relevanz dieser Beteiligungsmethode
f&#252;r politische Meinungsbildungsprozesse.
Die folgenden vier Themenfelder wurden von der Enquete-Kommission als besonders relevant
f&#252;r den gesellschaftlichen Input erachtet und f&#252;r die Online-Beteiligung aufbereitet: &#8222;Vertrauen
und Transparenz&#8220;, &#8222;KI in Beruf und Alltag&#8220;, &#8222;Datennutzung und Datenschutz&#8220; sowie &#8222;Wissen
&#8211; 727 &#8211; 
&#8211;
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
2 
und Forschung&#8220;. In einer f&#252;nften Kategorie &#8222;Weitere Anregungen zu KI&#8220; konnten dar&#252;ber
hinaus von den Teilnehmerinnen und Teilnehmern eigene Themen und Fragen zur Diskussion
gebracht werden.
1.2 Ablauf der Online-Beteiligung und Output
Verantwortlich f&#252;r die Umsetzung und Auswertung der Online-Beteiligung zeichnen Liquid
Democracy e.V. und nexus Institut f&#252;r Kooperationsmanagement und interdisziplin&#228;re
Forschung GmbH. Die Auftragnehmer verf&#252;gen &#252;ber jahrzehntelange, umfassende Expertise in
der Gestaltung, Durchf&#252;hrung und Analyse von Partizipationsprozessen und Online-
Beteiligungsformaten. Die konkrete Ausgestaltung der Online-Beteiligung verlief unter
fortw&#228;hrendem Austausch mit der Enquete-Kommission K&#252;nstliche Intelligenz. 
Vom 10. M&#228;rz bis zum 19. April 2020 waren die Fach&#246;ffentlichkeit sowie B&#252;rgerinnen und
B&#252;rger dazu eingeladen, sich auf der Online-Dialogplattform https://enquetebeteiligung.de/
einzubringen. Ein ansprechendes Webseiten-Layout, eine Software-Architektur aufbauend auf
der Beteiligungssoftware &#8222;Adhocracy&#8220;, offene Fragen in Anlehnung an die Diskussionsfelder
der Enquete-Kommission K&#252;nstliche Intelligenz sowie Hintergrundinformationen zum Thema
KI luden die Teilnehmerinnen und Teilnehmer dazu ein, ihre Perspektiven und ihr Wissen zu
teilen und sich auszutauschen.
In diesem Zeitraum wurden von 130 registrierten Teilnehmerinnen und Teilnehmern insgesamt
680 Beitr&#228;ge verfasst. Die hohe Qualit&#228;t und Spezifit&#228;t der Kommentare zeugt davon, dass KI
f&#252;r die &#252;berwiegende Anzahl der Teilnehmenden in ihrem beruflichen und/oder privaten
Umfeld eine Rolle spielt und sie sich mit der Thematik zum Teil bereits vertieft auseinandergesetzt
haben. Die Kommentare bilden vielf&#228;ltige Meinungen ab, und die Diskussionen zeigen teils 
sehr unterschiedliche Herangehensweisen an die Fragestellungen zu KI. Die Ergebnisse der
Online-Beteiligung spiegeln unterschiedliche gesellschaftliche Erwartungen an die zuk&#252;nftige
Entwicklung von KI sowie ihre Auswirkungen auf das soziale, &#246;konomische und &#246;kologische
Leben und Umfeld wider. Die Heterogenit&#228;t der Antworten macht diese Online-Beteiligung
interessant f&#252;r die politische Entwicklung einer nachhaltigen Handlungsstrategie zu KI.
&#8211; 728 &#8211;
&#8211;
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
3 
2 UMSETZUNG DER ONLINE-BETEILIGUNG
2.1 Inhaltlicher Aufbau 
Die Thesen und Handlungsempfehlungen eines Gremiums wie der Enquete-Kommission
K&#252;nstliche Intelligenz sind dem Thema und dem Ziel einer Enquete-Kommission
entsprechend teilweise von einem sehr spezifischen Fachwissen gepr&#228;gt, das sich die
Kommissionsmitglieder w&#228;hrend der Gremienarbeit und durch ihre T&#228;tigkeit als Expertinnen und
Experten angeeignet haben. Es stellt jedoch eine zentrale Bedingung der erfolgreichen Beteiligung
der &#214;ffentlichkeit (insbesondere bei der Einbeziehung verschiedener gesellschaftlicher
Gruppen mit ihrem spezifischen Vorwissen) dar, die Inhalte/Fragen eines Beteiligungsformates
m&#246;glichst verst&#228;ndlich und niedrigschwellig aufzubereiten. Nur so kann eine
zielgruppengerechte, motivierende Basis des Austauschs geschaffen werden.
Aus diesem Grund wurden die bis zum Zeitpunkt der Online-Beteiligung erarbeiteten Thesen
und Handlungsempfehlungen der Enquete-Kommission K&#252;nstliche Intelligenz in eine f&#252;r die
breite &#214;ffentlichkeit zug&#228;ngliche und auf das Format der Online-Beteiligung abgestimmte Form
gebracht. Es wurden hierf&#252;r in enger Abstimmung mit den Vertreterinnen und Vertretern der
Enquete-Kommission vier Themenfelder identifiziert, welche sich durch ihre zentrale
Bedeutung f&#252;r die zuk&#252;nftige Entwicklung von KI sowie ihren Lebensweltbezug auszeichnen, und f&#252;r
die Online-Beteiligung aufbereitet. Zus&#228;tzlich wurde das offene Themenfeld &#8222;Weitere
Anregungen zu KI&#8220; eingerichtet, um den Teilnehmerinnen und Teilnehmern die Diskussion weiterer
noch offenere Fragen oder Themen zu KI zu erm&#246;glichen.
Im Folgenden werden die Themenfelder eingehender beschrieben:
1) Das Themenfeld &#8222;Vertrauen und Transparenz&#8220; besch&#228;ftigt sich mit der grundlegenden 
Frage, wie KI gestaltet werden muss, damit sie gesellschaftlich akzeptiert wird.
Vertrauen in KI ist eine Bedingung daf&#252;r, dass KI genutzt wird. Deshalb sind Vertrauen
und Transparenz, welche zur gesellschaftlichen Vertrauensbildung beitr&#228;gt, wichtige
Aspekte im Diskurs zu KI.
2) KI findet bereits Anwendung in &#8222;Beruf und Alltag&#8220;. Wie sich KI in Zukunft auf Beruf und
Alltag von Nutzerinnen und Nutzern auswirken kann und wie die Teilnehmenden der
Online-Beteiligung dies bewerten, wird im zweiten Themenfeld diskutiert. Dieses
Themenfeld bietet die M&#246;glichkeit, eigene Erfahrungen jenseits von Expertenwissen
einzubringen.
3) Das dritte Themenfeld umfasst Fragen zu &#8222;Datennutzung und Datenschutz&#8220; in
Zusammenhang mit KI. Die Teilnehmenden sollen hier diskutieren, welche Daten f&#252;r welche
Zwecke sie mit welchen Akteuren gewillt w&#228;ren zu teilen. Au&#223;erdem diskutieren sie,
welche rechtlichen Rahmenbedingungen in Bezug auf KI gegebenenfalls. erweitert 
werden sollten.
4) Eine sich dynamisch entwickelnde Technologie wie KI wandelt sich kontinuierlich. 
&#8222;Wissen und Forschung&#8220; bilden die Grundlage daf&#252;r, dass sie verstanden werden kann.
In diesem Themenfeld geben die Teilnehmenden an, welche Bedarfe im Bereich der
Wissensvermittlung zu KI sie sehen und zu welchen KI-Themen ihrer Meinung nach
verst&#228;rkt geforscht werden sollte.
5) &#8222;Weitere Anregungen zu KI&#8220;, die nicht von den vier Themenfeldern bzw.
Diskussionsfragen abgedeckt wurden, konnten von den Teilnehmenden hier eingebracht werden. 
Die Fragen zu den Themenfeldern wurden offen formuliert, um die Teilnehmerinnen und
Teilnehmer zu er&#246;rternden Antworten und zu Diskussionen zu ermuntern. Weiterhin wurde den
Teilnehmenden die M&#246;glichkeit gegeben, gezielt auf Kommentare anderer Personen zu
antworten und somit eine Diskussion anzusto&#223;en. So konnten Argumente und Gegenargumente
&#8211; 729 &#8211; 
&#8211; 
&#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
4 
ausgetauscht und verschiedene Aspekte eines Sachverhalts beleuchtet werden. Durch die
&#252;bersichtliche Darstellung anhand eines ausklappbaren Diskussionsverlaufes kann dieser
leicht nachvollzogen werden. Ein solches diskursives Beteiligungsverfahren hat neben der
Wirkung der Ergebnisse in den politischen Raum auch eine Wirkung in die Lebenswelt der 
Beteiligten selbst, indem individuelle Ansichten und Meinungen der Teilnehmerinnen und
Teilnehmer ausgetauscht, erweitert und gegebenenfalls ge&#228;ndert werden.
2.2 Gestaltung der Online-Plattform  
Die Online-Beteiligung sollte die Teilnehmerinnen und Teilnehmer zu einer regen
Kommentierung und Diskussion der Fragestellungen anregen. Zu diesem Zweck wurde bei der
Einrichtung der Online-Plattform besonderer Wert auf &#220;bersichtlichkeit, eine visuell ansprechende
Gestaltung und die einfache Bedienbarkeit gelegt. Die technische Umsetzung der Online-
Konsultation erfolgte auf Basis der Beteiligungssoftware &#8222;Adhocracy&#8220; unter der freien Lizenz AG-
PLv3 (Open Source), die von Liquid Democracy entwickelt wird. 
Abbildung 1 Screenshot der Kacheln zu den Themenfeldern
Zu den ausgew&#228;hlten Themenfeldern wurden jeweils unter einem eigenen Reiter &#8222;Information&#8220;
leicht verst&#228;ndliche Hintergrundinformationen bereitgestellt, um auch Nutzerinnen und
Nutzern mit weniger Wissen zum Thema KI den Einstieg in die Diskussion zu erleichtern. Unter
dem zweiten Reiter &#8222;Beteiligung&#8220; fanden sich die jeweiligen themenspezifischen Fragen, zu
denen die Teilnehmenden diskutieren konnten. Unter dem dritten Reiter &#8222;Ergebnis&#8220; wurden die 
Teilnehmerinnen und Teilnehmer dar&#252;ber informiert, wie die Ergebnisse verwendet werden.
&#8211; 730 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
5 
Auf den untergeordneten Seiten mit den einzelnen Diskussionsfragen konnten sich die
Teilnehmerinnen und Teilnehmer nach einer Registrierung (Angabe von E-Mail-Adresse und
Username) an der Diskussion beteiligen. Die Usernamen konnten frei gew&#228;hlt werden. Sie
geben daher nur bedingt Aufschluss &#252;ber die Zielgruppenzugeh&#246;rigkeit. Unter der Maxime der
Datensparsamkeit wurden keine weiteren Daten &#252;ber die Nutzerinnen und Nutzer erhoben.
Ihre Beitr&#228;ge konnten die Nutzerinnen und Nutzer mit &#8222;Anmerkung&#8220;, &#8222;Vorschlag&#8220; und/oder 
&#8222;Frage&#8220; eigenst&#228;ndig kategorisieren. Weiterhin konnte auf Kommentare anderer Nutzerinnen 
und Nutzer geantwortet sowie deren Beitr&#228;ge mit einem Rating hinsichtlich &#8222;Zustimmung&#8220; oder
&#8222;Ablehnung&#8220; bewertet werden.
Die beschriebenen Funktionen trugen dazu bei, die Diskussion der Teilnehmenden auf
verschiedene Weise anzuregen und gleichzeitig eine m&#246;glichst gro&#223;e &#220;bersichtlichkeit der
Gespr&#228;chsverl&#228;ufe zu wahren. Dies unterst&#252;tzt einerseits den Einstieg von neuen Nutzerinnen
und Nutzern in die Diskussion, kommt aber auch der Nachvollziehbarkeit f&#252;r die Auswertung
der Online-Beteiligung zugute.
2.3 Zielgruppen und Teilnehmende 
Mit der Online-Beteiligung sollten Perspektiven und Empfehlungen von unterschiedlichen
Zielgruppen eingeholt werden, die f&#252;r die zuk&#252;nftige Gestaltung von KI von Bedeutung sind. Im
Vorfeld wurde dazu eine Stakeholder-Analyse vorgenommen. Die Zielgruppen der Online-
Beteiligung wurden dabei so ausgew&#228;hlt, dass sie die Vielfalt der f&#252;r das Themenfeld KI
relevanten Stakeholder, die sich fachlich mit dem Thema KI besch&#228;ftigen, sowie von Laien-
B&#252;rgerinnen und -B&#252;rgern spiegeln. Ziel der Stakeholder-Analyse war die Auswahl eines m&#246;glichst 
vielf&#228;ltigen Kreises relevanter Stakeholder und Multiplikatoren aus Wissenschaft, Wirtschaft, 
Politik und Zivilgesellschaft, um den Austausch von Personen mit unterschiedlichen
Fachsprachen, Priorit&#228;ten, Interessen und Positionen anzuregen.
Im Bereich Wirtschaft wurden Gro&#223;unternehmen, KMUs (kleine und mittlere Unternehmen)
und Start-ups recherchiert, um verschiedene Unternehmenstypen abzudecken. Zudem
wurden Gewerkschaften ausgew&#228;hlt. Im Feld der wissenschaftlichen Akteurinnen und Akteure
wurden informatik- und technikwissenschaftliche Wissenschaftlerinnen und Wissenschaftler
sowie geistes- und sozialwissenschaftlich Forschende, die sich mit dem Themenfeld KI und 
Digitalisierung befassen, recherchiert. Aus dem Bereich der organisierten Zivilgesellschaft
wurden verschiedene Organisationen mit netzpolitischer Ausrichtung adressiert, au&#223;erdem
ausgew&#228;hlte zivilgesellschaftliche Stakeholder wie Kirchen, Wohlfahrtsverb&#228;nde und
Organisationen, die Angebote zur Technikbildung f&#252;r Sch&#252;lerinnen und Sch&#252;ler bereitstellen.
Parteinahe Stiftungen wurden ebenfalls um Weiterleitung an ihre Kontakte gebeten. Der Online-
Dialog wurde au&#223;erdem &#252;ber die Kan&#228;le des Deutschen Bundestages und der Enquete-
Kommission K&#252;nstliche Intelligenz beworben. Um B&#252;rgerinnen und B&#252;rger anzusprechen, wurden
u.a. Technikmuseen angefragt, den Beteiligungsaufruf an ihre Besucherinnen und Besucher
weiterzutragen. Au&#223;erdem wurden Plakate und Flyer gedruckt und z. B. an Museen versendet. 
Auf Grund der Covid-19-Pandemie und der Schlie&#223;ung von Museen war jedoch die
M&#246;glichkeit, Laien-B&#252;rgerinnen und B&#252;rger f&#252;r den Online-Dialog zu erreichen, begrenzt. Geplant war
zudem, f&#252;r das Gutachten weniger digital-affine Zielgruppen in Fokusgruppen im Fr&#252;hjahr
2020 pers&#246;nlich zu befragen. Darauf hat die Enquete-Kommission aufgrund des m&#246;glichen
Ansteckungsrisikos durch Corona verzichtet. Die identifizierten Stakeholder wurden kontaktiert 
und gebeten, am Online-Dialog teilzunehmen sowie als Multiplikatorinnen und Multiplikatoren
&#8211; 731 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
6 
die Einladung zur Online-Beteiligung in ihre Netzwerke weiterzutragen und so weitere
interessierte Personen f&#252;r die Online-Beteiligung der Enquete-Kommission zu gewinnen.
Die Diskussionsfragen wurden so formuliert, dass sie f&#252;r Teilnehmende mit unterschiedlichen
Wissensst&#228;nden relevant waren: Es wurden sowohl alltagsnahe Fragen als auch st&#228;rker
fachlich orientierte (z. B. zu Risikoklassifizierungen und G&#252;tesiegeln) Fragen formuliert, ohne dabei
eine strukturelle Trennung vorzunehmen. Der Austausch heterogener Perspektiven und
Argumente konnte somit bef&#246;rdert und ein breites Spektrum an Wissen und individuellen Haltungen
zu KI eingefangen und abgebildet werden.
In der Gesamtlaufzeit von sechs Wochen wurden insgesamt 680 Kommentare geschrieben.
Diese wurden von 130 Nutzerinnen und Nutzern verfasst. Insgesamt registrierten sich 260
Personen, sodass sich die H&#228;lfte aktiv durch Kommentare eingebracht hat. Die Online-
Beteiligung verfolgt nicht den Anspruch der Repr&#228;sentativit&#228;t, sondern sie zeigt vielmehr einen
Ausschnitt gesellschaftlicher Meinungen und Perspektiven sowie Debattenverl&#228;ufe. Die
Usernamen und die unterschiedliche inhaltliche Tiefe der Kommentare lassen den Schluss zu, dass
die durch die Stakeholder-Analyse angesprochenen Zielgruppen auch erreicht wurden, also
Teilnehmerinnen und Teilnehmer aus Wirtschaft, Wissenschaft, (zivilgesellschaftlichen)
Verb&#228;nden und Teilnehmerinnen und Teilnehmer ohne erkennbaren institutionellen Hintergrund.
Die Qualit&#228;t und fachliche Tiefe der Kommentare l&#228;sst vermuten, dass mit dem Online-Dialog
prim&#228;r eine Fach&#246;ffentlichkeit erreicht wurde. Laien-B&#252;rgerinnen und B&#252;rger brachten sich
eher weniger ein, dies kann zum einen durch die f&#252;r ein Beteiligungsthema eher hohe
Komplexit&#228;t und Neuartigkeit des Themas begr&#252;ndet sein, aber auch damit zusammenh&#228;ngen, dass
durch die Covid-19-Pandemie und den damit einhergehenden Einschr&#228;nkungen Laien-
B&#252;rgerinnen und B&#252;rger z. B. &#252;ber Museen oder &#246;ffentliche Institutionen schwieriger erreicht werden
konnten.  
Ein wichtiges Kriterium f&#252;r die Bewertung von Online-Dialogen ist eine gute Diskussion.
Indikatoren f&#252;r eine gute Online-Diskussion sind insbesondere Rationalit&#228;t, Bezugnahme und
Respekt. Au&#223;erdem deuten auch Formen einer expressiven Kommunikation, das hei&#223;t des
Einbringens z. B. pers&#246;nlicher Erfahrungen und W&#252;nsche, sowie die Abwesenheit von
Inzivilit&#228;t auf eine hohe Qualitit&#228;t von deliberativer Diskussion hin. Im Falle der Online-Beteiligung
der Enquete-Kommission K&#252;nstliche Intelligenz war positiv festzustellen, dass es keine
Verst&#246;&#223;e gegen die Netiquette und damit inzivile Kommentare gab, die eine regulative Moderation 
gefordert h&#228;tten. Insgesamt haben sich fast 20 Prozent (121) der Kommentare auf vorherige
Beitr&#228;ge bezogen, was ein wichtiger Indikator daf&#252;r ist, dass in einen Austausch miteinander
treten wollten. Die Kommentare waren gepr&#228;gt von schl&#252;ssigen Argumentationslinien und
einer hohen sachlichen Qualit&#228;t. Es wurde zudem keine unsachliche Kritik an einzelnen
Akteuren oder Institutionen ge&#252;bt. In den Kommentaren finden sich nicht nur fachliche Beitr&#228;ge,
sondern auch pers&#246;nliche Einsch&#228;tzungen, Forderungen und W&#252;nsche, die darauf verweisen, 
dass die Online-Beteiligung Raum f&#252;r expressive Kommunikation bot. Die Online-Beteiligung
war angesichts des kurzen Zeitraums und der beginnenden Corona-Pandemie ein gro&#223;er
Erfolg f&#252;r die Einbeziehung von Stakeholdern zu einem spezifischen technischen Thema, das
eine gro&#223;e Komplexit&#228;t aufweist. Auch in Anbetracht des kurzen Beteiligungszeitraumes von
sechs Wochen ist die Online-Beteiligung als Erfolg zu bewerten. Als Vergleich hierzu lief die
Online-Beteiligung der Enquete-Kommission &#8222;Internet und digitale Gesellschaft&#8220; &#252;ber 26
Monate. Im Schnitt wurden dort 108 Beitr&#228;ge pro Monat gepostet. Die durchschnittliche Anzahl
von Beitr&#228;gen pro Monat in der Online-Beteiligung der Enquete-Kommission K&#252;nstliche
Intelligenz betr&#228;gt 453.
&#8211; 732 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
7 
Als Faustregel f&#252;r Online-Beteiligungen gilt zudem das Verh&#228;ltnis 90 9 1, das besagt, dass
90 Prozent der User lediglich Beitr&#228;ge lesen, 9 Prozent sich gering beteiligen und 1 Prozent
der Beitr&#228;ge von Power Usern verfasst werden. Im Falle dieser Online-Beteiligung haben sich
50 Prozent der registrierten User durch Kommentare oder Votes beteiligt. Unter diesen waren 
zehn besonders aktive User (sogenannte Power User), das hei&#223;t circa 8 Prozent und damit im
Vergleich mehr als &#252;blich. Diese verfassten 29 Prozent der Kommentare. Sie kommentierten
dabei viele Kommentare anderer Teilnehmender und st&#228;rkten so die Diskussion auf der
Plattform. Nimmt man die Power User aus, so verfassten die restlichen Nutzerinnen und Nutzer
durchschnittlich 4 Kommentare. Zwei Drittel haben mehr als einen Kommentar verfasst.  
2.4 Auswertungsmethodik 
F&#252;r die Auswertung der Online-Beteiligung wurde die Methode der strukturierenden
Inhaltsanalyse1 angewendet. Mit dieser Methode kann qualitatives Datenmaterial hinsichtlich
bestimmter Themen, Inhalte und Aspekte strukturiert werden, d.h. diese werden zuerst aus dem
Material extrahiert und bestimmten Kategorien zugeordnet. Anschlie&#223;end werden sie anhand ihrer
Bedeutungen neu zusammengefasst und weiterf&#252;hrend interpretiert. Das inhaltsanalytische
Vorgehen erm&#246;glicht es somit, aus den vielschichtigen Aussagen, einzelnen Vorschl&#228;gen,
diskursiven Kommentaren und Fragen der Teilnehmerinnen und Teilnehmer der Online-
Beteiligung die zentralen Inhalte und Erkenntnisse in komprimierter Form abzubilden.
Nach Abschluss der Online-Beteiligung erfolgte als Vorbereitung dazu im ersten Schritt ein
Export des Datenmaterials zu Excel. Die Excel-Tabelle wurde so aufbereitet, dass die Inhalte
problemlos in die Qualitative Datenanalyse-Software ATLAS.ti importiert werden konnten. Die 
inhaltsanalytische Auswertung erfolgte dann unter Verwendung von ATLAS.ti. Diese Software
stellt ein bew&#228;hrtes Instrument zur Verwaltung und Analyse qualitativer Daten dar und
erm&#246;glicht ein teambasiertes Arbeiten, was im Sinne der Forschertriangulation zu einem validen
Kategoriensystem betr&#228;gt. In dem erstellten ATLAS.ti-Projekt befinden sich die Daten der Online-
Beteiligung, das erstellte Kategoriensystem sowie die codierten Zitate. Die Vorgehensweise
der Kategorienbildung und Codierung von Textstellen ist dadurch transparent und jederzeit
nachvollziehbar.
Als Basiskategorien wurden die f&#252;nf Themenbereiche der Online-Befragung sowie die
untergeordneten Diskussionsfragen herangezogen. Alle Kommentare der Teilnehmerinnen und
Teilnehmer wurden jeweils als einzelner Fall in ATLAS.ti eingelesen. So konnte die Online-
Beteiligung pr&#228;zise nachgebildet werden und die Auswertung Schritt f&#252;r Schritt entlang der 
Diskussionsfragen und der jeweiligen Diskussionsverl&#228;ufe stattfinden.  
Im Vorfeld wurden zudem die folgenden normativen Kategorien festgelegt, die darlegen,
inwiefern ein Beitrag Teilaspekte von KI positiv oder negativ bewertet:
Gute Umsetzung und Chancen  
(z. B. positive Erfahrungen mit KI, Beispiele gelungener KI-Nutzung und -Gestaltung, 
m&#246;gliche positiv zu bewertende Wirkungen von KI, zuk&#252;nftig erwartbare
Verbesserungen und Potenziale von/mit KI)
Herausforderungen und Risiken  
1 Mayring, P. (2003). Qualitative Inhaltsanalyse. Grundlagen und Techniken. Weinheim: Beltz.
&#8211; 733 &#8211; 
 &#8211; &#8211;
-
-
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
8 
(z. B. negative Erfahrungen mit KI, Beispiele misslungener KI-Nutzung und -
Gestaltung, m&#246;gliche negativ zu bewertende Wirkungen von KI, zuk&#252;nftig erwartbare
Verschlechterungen und Probleme von/mit KI) 
Handlungsbedarfe und Rahmenbedingungen
(z. B. inhaltliche und strukturelle Handlungsanforderungen sowie von den
Teilnehmerinnen und Teilnehmern identifizierte Sachverhalte in Bezug auf KI, die eine Reaktion
erfordern)
Bei der Durchsicht des Datenmaterials wurden neben der Codierung von Textstellen mit den
normativen Kategorien (deduktives Vorgehen) auch neue Kategoriensysteme f&#252;r die
verschiedenen Diskussionsfragen gebildet (induktives Vorgehen). Hierbei wurde im ersten Schritt jeder
Kommentar einzeln betrachtet und inhaltliche Sinnzusammenh&#228;nge mit einer neuen Kategorie 
belegt. Dann wurden im zweiten Schritt die so entwickelten Kategorien gegebenenfalls
kommentar&#252;bergreifend (innerhalb einer Diskussionsfrage) zusammengelegt, wenn sie eine
inhaltlich gro&#223;e N&#228;he aufwiesen oder aber anhand von Subkategorien noch weiter ausdifferenziert. 
Je nach Art der Diskussionsfrage k&#246;nnen die Kategoriensysteme in ihrer Differenziertheit und
Ebenentiefe variieren.
Anschlie&#223;end erfolgte eine Auswertung entlang der Diskussionsfragen auf Basis der
Kategorien. Dabei werden auch Diskussionsschwerpunkte, -verl&#228;ufe und -ergebnisse, die
Gegen&#252;berstellung von Argumenten zu gleichen Themenaspekten, das Aufzeigen von
Widerspr&#252;chen sowie &#220;bereinstimmungen wiedergegeben. Weiterhin werden aussagekr&#228;ftige Zitate
angef&#252;hrt, um den Leserinnen und Lesern einen Einblick in das Datenmaterial zu geben und die
Teilnehmerinnen und Teilnehmer &#8222;f&#252;r sich selbst&#8220; sprechen zu lassen. Die Beitr&#228;ge wurden 
nicht quantitativ ausgewertet, wohl aber wurden gewisse Tendenzen und H&#228;ufungen
ber&#252;cksichtigt, wenn z. B. ein Argument mehrfach eingebracht wurde, um besonders wichtige
Argumente herauszufiltern. In diesem Falle wird von mehreren bzw. einigen Nennungen oder auch 
als weitere Steigerung - von vielen Nennungen gesprochen. Da zu den einzelnen
Fragenunterschiedlich viele Kommentare verfasst wurden, variiert auch die Einsch&#228;tzung, ab wie vielen 
Kommentaren ein Argument als z. B. &#8222;von einigen&#8220; oder &#8222;von vielen&#8220; genannt interpretiert
wurde. Z. B. kann eine Herausforderung, die bei einer Gesamtanzahl von 15 genannten
Herausforderungen f&#252;nfmal genannt wurde, als von einigen genannt eingestuft werden. Wird eine
Herausforderung mehr als einmal erw&#228;hnt, wird darauf verwiesen, dass sie von mehreren
Teilnehmenden genannt wurde. Einzelnennungen werden als solche benannt. Diese Angaben 
lassen sich dementsprechend nicht eindeutig quantifizieren, sondern geben nur Tendenzen
wieder.
3 ERGEBNISVORSTELLUNG ENTLANG DER THE-
MENFELDER UND DISKUSSIONSFRAGEN
3.1 Themenfeld &#8222;Vertrauen und Transparenz&#8220;
Vertrauen und Transparenz bilden die Grundlage f&#252;r K&#252;nstliche Intelligenz: Damit K&#252;nstliche
Intelligenz von B&#252;rgerinnen und B&#252;rgern tats&#228;chlich genutzt wird, muss Vertrauen in die
Technologie bestehen. Hoffnungen und Bef&#252;rchtungen in Bezug auf KI spiegeln, wie die
Teilnehmenden KI mit Blick auf die Zukunft einordnen und lassen darauf schlie&#223;en, welches Leben
&#8211; 734 &#8211; 
-
-
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
9 
mit KI sich die Teilnehmenden w&#252;nschen. Inwiefern Teilnehmende sich bereits auf KI-
Anwendungen verlassen, deutet auf bereits existentes Vertrauen in KI hin. Aus den Antworten l&#228;sst 
sich ableiten, wo KI auf Zustimmung st&#246;&#223;t und welche Aspekte und/oder Anwendungen eher
auf Ablehnung sto&#223;en. Die Antworten der Teilnehmenden erlauben Schl&#252;sse dar&#252;ber, wie KI 
gestaltet werden sollte, damit Nutzerinnen und Nutzer ihr vertrauen und sie nutzen. 
Transparenz ist dabei ein wichtiger Baustein: Sie kann das Vertrauen in eine Technologie
erh&#246;hen, indem Prozesse, die sonst im Hintergrund verlaufen w&#252;rden, offengelegt werden.
Risikoklassifizierungen und G&#252;tesiegel wiederum sind konkrete Vorschl&#228;ge der Enquete-
Kommission K&#252;nstliche Intelligenz, um die Transparenz von KI-Anwendungen zu steigern. Die Online-
Beteiligung sollte Aufschluss dar&#252;ber geben, wie die Teilnehmenden diese Ma&#223;nahmen
bewerten und wie Risikoklassifizierungen und G&#252;tesiegel gestaltet werden sollten. 
Frage 1: &#8222;Welche Hoffnungen und Bef&#252;rchtungen verbinden Sie mit dem
Einsatz von KI?&#8220; 
Diese Frage zielt auf die grundlegenden Einstellungen und allgemeinen normativen
Einsch&#228;tzungen zu KI. Insgesamt finden sich in den Kommentaren der Teilnehmenden der Online-
Beteiligung Hoffnungen und Bef&#252;rchtungen gleicherma&#223;en ohne eine deutliche Tendenz in die
eine oder andere Richtung. Die Teilnehmenden verbinden mit K&#252;nstlicher Intelligenz
insbesondere die Hoffnung, dass auf Basis neuer Erkenntnisse durch KI grundlegende positive
Errungenschaften insbesondere in den Bereichen Gesundheit, Mobilit&#228;t, Arbeit und
Produktion, aber auch f&#252;r den Umweltschutz erreicht werden k&#246;nnten. Als Bef&#252;rchtungen werden
vor allem eine Verst&#228;rkung von Diskriminierung, eine Verwendung der Technologie f&#252;r
Zwecke, die Gesellschaft und Menschen schaden und eine zunehmende Abh&#228;ngigkeit der
Menschen von KI bis hin zu ihrer Entm&#252;ndigung genannt. Neben den Hoffnungen und
Bef&#252;rchtungen sehen die Teilnehmenden dringende Handlungsbedarfe und Bedingungen f&#252;r die
Einf&#252;hrung von KI-Systemen, die sich insbesondere auf die Aspekte Transparenz, Regulierung
und Datensicherheit von KI beziehen. Weiterhin zeigt sich in der Diskussion, dass &#252;ber die
verwendeten Begriffe im Diskurs rund um KI, Maschinelles Lernen und algorithmenbasierte
Entscheidungssysteme noch keine Einigkeit besteht und hier ein breit angelegter
gesellschaftlicher Diskurs zur Definition verschiedener Auspr&#228;gungen und Bedeutungen von KI notwendig 
w&#228;re (siehe auch Frage 12). 
Hoffnungen und Chancen in Verbindung mit KI 
Insbesondere im Bereich Gesundheit erhoffen sich die Teilnehmenden positive
Auswirkungen durch den Einsatz von KI. Bei weitem die meisten genannten positiven Beispiele f&#252;r den
Einsatz von KI beziehen sich auf den Gesundheitsbereich. Mithilfe von KI k&#246;nne z. B. eine
ganze Reihe von Aufgaben in der Medizin besser gel&#246;st werden: So k&#246;nne z. B. durch neue 
Analyseverfahren die fr&#252;hzeitige Erkennung von Erkrankungen verbessert werden. Konkrete
Beispiele daf&#252;r umfassen das &#8222;Durchsuchen von R&#246;ntgenbildern nach Krebs-Hinweisen&#8220; 
(thom_zieg), andere &#8222;medizinische Bildanalysen&#8220; oder &#8222;Genomanalysen&#8220; (Benedikt B.) sowie
die Analyse von &#8222;Nebenbefunden, wo es zu kl&#228;ren gilt, ob es neben der prim&#228;ren klinische 
Fragestellung relevante Auff&#228;lligkeiten bei einem Untersuchungsergebnis gibt&#8220; (Katharina). 
Durch den Einsatz von KI in der Diagnostik k&#246;nnten zudem Fehler und Fehldiagnosen
verringert werden. Eine &#8222;datengetriebene Diagnostik, [trage dazu bei], dass es zu weniger
Fehldiagnosen durch &#252;berlastete und nicht perfekt informierte &#196;rzte kommt&#8220; (Christian). Auch vor
dem Hintergrund der Covid-19-Pandemie zeige sich, &#8222;wie &#8222;KI-Systeme durch Mustererken-
&#8211; 735 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
10 
nung eine rechtzeitige Fr&#252;hwarnung (Krankheiten, Epidemie) erkennen und verhindern
k&#246;nnten&#8220; (Conrad S.C.). Nicht nur in der Diagnostik, sondern auch in der Therapie k&#246;nnten KI-
Anwendungen zu Verbesserungen beitragen, indem durch den Einsatz von KI-Behandlungen
st&#228;rker individuell auf die Patientin oder den Patienten abgestimmt werden k&#246;nne. 
Weiterhin wurde von den Teilnehmenden eingebracht, dass Medizinerinnen und Mediziner
durch KI-basierte Entscheidungsunterst&#252;tzungssysteme, die ihnen Entscheidungen zwar nicht
abnehmen, wohl aber Vorschl&#228;ge auf Basis ihrer Analysen machen, bei ihrer Arbeit unterst&#252;tzt 
werden k&#246;nnten. Insgesamt k&#246;nne sich KI positiv auf die Gestaltung von Arbeits- und
Produktionsabl&#228;ufen auswirken:  
&#8222;Die Aufbereitung und Darstellung von Daten und Informationsquellen mittels KI kann 
unsere Arbeitsweise erheblich erleichtern. Stellt man sich z. B. eine
Suchmaschinen&#228;hnliche Informationsquelle vor, allerdings f&#252;r die eigenen Arbeitsinputs, dann 
k&#246;nnen viele Aufgaben deutlich effizienter gestaltet werden.&#8220; (Benedikt B.) 
Die Teilnehmenden sehen au&#223;erdem gro&#223;e Vorteile, wenn KI sich wiederholende und
monotone Routineaufgaben &#252;bern&#228;hme:
&#8222;Mit KI verbinde ich die Hoffnung, dass mir sowohl beruflich als auch privat l&#228;stige 
Routineaufgaben abgenommen werden.&#8220; (Fabian S.) 
Die eingesparte Zeit k&#246;nne dann f&#252;r als sinnvoller erachtete T&#228;tigkeiten genutzt werden.
Wieder in Bezug auf die medizinische Versorgung schreibt eine teilnehmende Person:  
&#8222;Algorithmische Systeme k&#246;nnen uns Routinet&#228;tigkeiten abnehmen und so mehr Zeit 
f&#252;rs Wesentliche (z. B. Zeit f&#252;r Patientenkontakte in der Medizin) schaffen.&#8220; 
(Projektteam Ethik der Algorithmen) 
Wichtig ist dabei, dass sich die Teilnehmenden eine &#220;bernahme von repetitiven T&#228;tigkeiten
durch KI erhoffen, gleichzeitig aber bef&#252;rchten, dass KI in Zukunft zu viele Aufgaben
&#252;bernehmen k&#246;nnte (siehe folgendes Unterkapitel).
Die Teilnehmenden erhoffen sich zudem, dass KI die flexible Planung und Organisation von
Arbeitsabl&#228;ufen und Produktionsprozessen im Allgemeinen positiv beeinflusst: Beschleunigte
und optimierte Prozesse k&#246;nnten nicht nur die Kosten z. B. in Krankenh&#228;usern und
medizinischen Einrichtungen senken, sondern auch in anderen Wirtschaftszweigen:
&#8222;So kann KI beispielweise in der Energiewirtschaft zu einem optimierten Netzbetrieb 
und einer h&#246;heren Netzauslastung beitragen, f&#252;r die intelligente Planung von
Wartungsarbeiten an Energie-Erzeugungsanlagen (Windkraftanlagen, etc.) eingesetzt oder 
zur Verbesserung von Prognosen fluktuierender erneuerbarer Energien genutzt
werden.&#8220; (Lisa K.) 
Einen wichtigen Aspekt optimierter Abl&#228;ufe stellt dabei die Personalisierung dar: Durch
passgenaue L&#246;sungen, die auf den Einzelfall abgestimmt sein sollen, k&#246;nne KI zur besseren
Prozessgestaltung beitragen. Individualisierte Behandlungen wurden bereits angef&#252;hrt, ein
weiteres konkretes Beispiel bezieht sich auf die individuelle Lernf&#246;rderung:
&#8222;[I]n der derzeitigen Situation von Schulschlie&#223;ungen wegen der Covid-19-Pandemie 
[k&#246;nnten] einfach personalisierte Lernpl&#228;ne von einer KI erstellt werden [&#8230;], so dass 
keine wertvolle Unterrichtszeit verloren geht&#8220; (SophieH.).
&#8211; 736 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
11 
Durch KI k&#246;nnten solche individualisierten Angebote kosteng&#252;nstiger werden, mehr Menschen 
zug&#228;nglich gemacht werden und damit die Teilhabe erh&#246;hen.
Weil KI insgesamt eine effizientere Materialnutzung und Ressourcenschonung erm&#246;gliche,
k&#246;nne sie auch ein wichtiges Mittel f&#252;r den Umweltschutz sein:
&#8222;Mittels KI basierter Objekt-Analyse k&#246;nnen bei der Produktfertigung Materialien 
effizienter eingesetzt werden, was der Umwelt hilft. Ebenso k&#246;nnen bei der 
Produktentsorgung Materialien effizienter recycelt werden.&#8220; (Pyromorphit) 
F&#252;r den Bereich Mobilit&#228;t erhoffen sich die Teilnehmenden optimierte Verkehrsfl&#252;sse,
Staureduktionen und autonomes Fahren. KI k&#246;nne zudem grundlegende Erkenntnisse &#252;ber die
&#8222;Wechselwirkungen zwischen Mensch und Umwelt [&#8230;] und Tipps zur Sicherung des
Gleichgewichts&#8220; (Republik U upis) liefern.
Die Hoffnungen und Chancen lassen sich &#252;bergreifend zusammenfassen. Die M&#246;glichkeiten, 
eine Vielzahl an Daten zu sammeln und mit neuartigen Analyseverfahren (z. B.
Mustererkennungen) auszuwerten, f&#252;hrten zu einem gro&#223;en Wissenszuwachs. Auf Grundlage neuer
Erkenntnisse k&#246;nnten fundiertere Entscheidungen getroffen werden:
&#8222;[KI] kann dazu beitragen die menschliche Entscheidungsfindung so zu verbessern, 
dass es die Welt integrativer macht und bahnbrechende Durchbr&#252;che bei 
schwierigen sozialen Herausforderungen wie dem Klimawandel und der 
Krebsforschung erm&#246;glicht.&#8220; (BSA  The Software Alliance) 
Prozesse aller Art k&#246;nnten analysiert und optimiert werden. So lie&#223;e sich die Effizienz steigern,
weil Zeit gewonnen werde. Auch die M&#246;glichkeit, individuelle und personalisierte L&#246;sungen zu 
entwickeln, sei ein Vorteil von KI. In den verschiedenen Anwendungsbereichen k&#246;nnten so
bessere L&#246;sungen f&#252;r den jeweiligen Anwendungsfall gefunden werden. 
Bef&#252;rchtungen und Herausforderungen in Verbindung mit dem Einsatz von KI
Die in den Kommentaren angesprochenen Herausforderungen beziehen sich gr&#246;&#223;tenteils auf 
die bef&#252;rchtete Abh&#228;ngigkeit des Menschen von KI, Negativauswirkungen auf Wirtschaft und
Arbeit, m&#246;gliche Diskriminierungen, begrenzte Spielr&#228;ume f&#252;r die Gestaltung von KI und
fehlgeleitete, negativ zu bewertende Anwendungen von KI.
Allgemeine Bef&#252;rchtungen in den Kommentaren der Teilnehmenden beziehen sich auf die
wachsende Abh&#228;ngigkeit des Menschen von KI durch mangelnde Nachvollziehbarkeit und
Verst&#228;ndnisprobleme. Einige Teilnehmende bef&#252;rchten, dass der Mensch infolgedessen
entm&#252;ndigt werde. Diese Bef&#252;rchtung kulminiert in der jedoch nur selten ge&#228;u&#223;erten Vorstellung 
einer entfesselten gro&#223;en KI, die den Untergang der Menschheit herbeif&#252;hre, weil sie nicht
mehr zu kontrollieren w&#228;re und die menschlichen F&#228;higkeiten weit &#252;bersteige. Hier zeigt sich
das Spannungsfeld zwischen Entlastung durch KI auf der einen Seite und Abh&#228;ngigkeit von 
KI auf der anderen Seite.
Bef&#252;rchtet wird zudem, dass KI missbr&#228;uchlich oder zu gesellschaftlich und moralisch nicht
vertretbaren Zwecken verwendet werden k&#246;nne. Als Technologie k&#246;nne KI Werkzeug zu
allerlei Zwecken sein, auch zu schlechten. So schreibt eine kommentierende Person: 
&#8222;KI ist wie ein Messer. Man kann es im Haushalt nutzen, man kann damit aber auch 
Menschen umbringen.&#8220; (C. F.) 
Dabei sei besonders problematisch, wenn &#252;ber die Zwecke keine Transparenz herrsche:
&#8211; 737 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
12 
&#8222;Bef&#252;rchtungen habe ich v.a. dahingehend, dass diese [Entscheidungen] aus 
gewinnmaximierenden oder Gr&#252;nden staatliche Geheimhaltung nicht offengelegt 
werden. Und nat&#252;rlich dass die Einsatzziele den Interessen der Gesellschaft, des 
Staates und der einzelnen B&#252;rger zuwiederlaufen.&#8220; (JeBau) 
Die Verwendung von KI f&#252;r milit&#228;rische (&#8222;autonome Kriegsroboter&#8220; (C. Fischer)) und
polizeiliche Zwecke (&#8222;Predictive Policing&#8220; (Hannes)) wird in diesem Kontext ebenfalls kritisiert. Auch
wenn KI lediglich die Interessen und Werte von Entwicklern und Eignern bediene, w&#252;rden die 
positiven Auswirkungen nicht allen Menschen zugutekommen und KI k&#246;nne dann bestehende
soziale Ungleichheiten verst&#228;rken:
&#8222;Der Betrieb einer KI kostet Geld, darum muss sie ihrem Eigent&#252;mer Vorteile 
verschaffen. Nun ist es h&#228;ufig so, dass die Vorteile einiger Weniger den Nachteilen 
von Vielen gegen&#252;ber stehen.&#8220; (Flake) 
Die Teilnehmenden bef&#252;rchten ebenfalls eine mangelnde Qualit&#228;t von Datens&#228;tzen und
deren Interpretation, weil dies zu verzerrenden und unangemessenen Entscheidungen f&#252;hren
k&#246;nne:
&#8222;Eventuelle Fehler im Konzept oder in den Datens&#228;tzen f&#252;hren zu systematischen 
Fehlern, nicht zu einmaligen menschlichen Fehlern mit begrenzter Dauer und 
&#252;berschaubarer Reichweite. Diese Fehler basieren auf falschen Regeln, die von 
Menschen oft nicht mal entdeckt werden k&#246;nnen.&#8220; (Georg W.) 
Besonders problematisch sei daran, dass sich die Fehler langfristig verstetigen k&#246;nnten. Daran 
anschlie&#223;end bef&#252;rchten die Teilnehmenden, dass verschiedene Formen der
Diskriminierung durch KI verst&#228;rkt werden k&#246;nnten: Preismanipulationen und Verweigerung von Krediten 
(aufgrund der Analyse von Nutzerprofilen), &#220;berwachung und Vorverurteilungen sowie die
Einschr&#228;nkung des Zugangs zu medizinischer Versorgung werden genannt. Diskriminierung
bildet hier die Kehrseite der zuweilen positiv gewerteten Personalisierung und kann Ungleichheit 
verst&#228;rken, wenn nicht entsprechenden Ma&#223;nahmen eingeleitet w&#252;rden:
&#8222;Andernfalls laufen wir Gefahr hinter bereits Erreichtes (Teilhabe, 
Chancengerechtigkeit, Vielfalt etc.) zur&#252;ckzufallen und bestehende 
Diskriminierungsmuster (z. B. in Rekrutierungsdaten) zu reproduzieren.&#8220; (Hanna V.) 
Weitere Herausforderungen und Bef&#252;rchtungen lassen sich unter der &#220;berschrift &#8222;negative
Auswirkungen auf Wirtschaft und Arbeit&#8220; b&#252;ndeln: Die zum Teil als positiv bewerteten
Prozessoptimierungen und die &#220;bernahme von Routineaufgaben k&#246;nnten, wie schon oben
erw&#228;hnt, auf der anderen Seite zu Arbeitsplatzverlusten f&#252;hren:
&#8222;Da KI wahrscheinlich zuerst bei repetitiven und vergleichsweise einfachen Arbeiten 
eingesetzt wird, steht der Arbeitsplatzverlust f&#252;r &#8218;nicht so hoch gebildete Menschen&#8216; zu 
bef&#252;rchten&#8220; (topas). 
Entsprechend sind sich die Teilnehmenden uneinig dar&#252;ber, ob KI mehr positive oder negative
Auswirkungen auf die Arbeitswelt haben wird. Au&#223;erdem werden Wettbewerbsverzerrungen
zugunsten von datenverarbeitenden Gro&#223;unternehmen von mehreren Teilnehmenden
bef&#252;rchtet, denn wer gro&#223;en Einfluss auf eine Schl&#252;sseltechnologie wie KI aus&#252;ben kann, der
verf&#252;ge auch &#252;ber eine Marktmacht:
&#8222;Gro&#223;e Datenunternehmen beeinflussen bereits weite Bereiche unseres Alltags. 
Daraus sollten wirtschaftlich keine Monopole erwachsen und die von solchen
&#8211; 738 &#8211;
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
13 
Unternehmen aufgestellten Regeln sollten demokratisch politisch legitimiert sein.&#8220; 
(Christian 7) 
Hinsichtlich des Kosten- und Ressourcenverbrauchs von KI wird auf &#8222;eine Beurteilung des 
tendenziell hohen Bedarfs an Rechenleistung und dem damit verbundenen erh&#246;hten
Stromverbrauch&#8220; (Lisa K.) verwiesen. So k&#246;nnten zwar Prozesse, wie oben erw&#228;hnt, auf der einen
Seite effizienter werden, aber bei der Bewertung der wirtschaftlichen Potenziale m&#252;ssten eben 
auch Kosten und Ressourcenverbrauch von KI-Anwendungen mit beachtet werden. 
Bef&#252;rchtet wird au&#223;erdem, dass die Entwicklung von KI als globale Technologie nur schwer
zu regulieren sei und Deutschland sowie Europa sich den unumg&#228;nglichen internationalen
Entwicklungen anpassen m&#252;ssten. So k&#246;nne man nicht darauf verzichten, auch gro&#223;e KIs zu
entwickeln, weil diese sonst von anderen Staaten entwickelt w&#252;rden und Deutschland
technologisch abgeh&#228;ngt w&#252;rde. Dies h&#228;tte schwerwiegende sicherheitspolitische Implikationen.
Die vorhandenen Gestaltungspielr&#228;ume f&#252;r die Regulierung von KI werden als eher klein
erachtet. Hier schwingt die Vorstellung mit, man sei dem technischen Wandel &#8222;hilflos&#8220;
ausgesetzt. Konventionen und Ethikr&#228;te werden, wenn auch nur in wenigen Kommentaren, als
wirkungslos kritisiert:  
&#8222;Aber selbst wenn wir das erstaunlicherweise in Deutschland schaffen w&#252;rden, wen 
w&#252;rde das in anderen L&#228;ndern interessieren? So ist es seit Jahrhunderten in allen 
Bereichen der Wissenschaft und Technik. Ethikr&#228;te versuchen weltweit zum Beispiel 
Regeln in der Biologie aufzustellen. Seit wieviel Jahrzehnten sind sie erfolglos?&#8220; 
(Michael G.) 
Die Kommentare deuten darauf hin, dass die verf&#252;gbaren Instrumente zur Regulierung von KI 
als nicht ausreichend wirkungsvoll erachtet werden. Die Teilnehmenden nennen daher
verschiedene Handlungsbedarfe und Rahmenbedingungen, die zu einer sozial vertr&#228;glichen
Gestaltung von KI beitragen k&#246;nnten.
Handlungsbedarfe und Rahmenbedingungen aus Sicht der Teilnehmenden 
Als grundlegende Bedingung sehen die Teilnehmenden insbesondere Transparenz und
Nachvollziehbarkeit von KI, um das Vertrauen in KI zu st&#228;rken. Konkrete Vorschl&#228;ge
umfassen die Offenlegung von Code, Risikobenennungen (z. B. durch Siegel, siehe auch die Fragen
1.3. und 1.4) und Verpflichtungen zur Dokumentation von Entscheidungen. Eine teilnehmende
Person betont, sie &#8222;m&#246;chte in der Lage sein, Entscheidungen dieser Systeme nachvollziehen 
zu k&#246;nnen und ein Recht darauf [haben], eine Entscheidung von einem Menschen nachpr&#252;fen 
zu lassen&#8220; (Christian). Mit dieser Forderung wird die Bef&#252;rchtung aufgegriffen, dass Menschen
von KI abh&#228;ngig werden k&#246;nnten, weil sie deren Entscheidungen nicht mehr nachvollziehen
und somit nicht hinterfragen k&#246;nnten.
Grundlegende Bedingung ist au&#223;erdem eine Zielsetzung von KI, die sich am Menschen 
ausrichtet und nicht anders herum: Eine teilnehmende Person schreibt, es sei ihr &#8222;wichtig, 
dass wir den Menschen im Mittelpunkt sehen und f&#252;r uns immer klar ist, dass die Technik dem 
Menschen zu dienen hat und nicht der Mensch der Technik&#8220; (Justus02). Auch um dies
sicherzustellen, m&#252;ssten die in KI-Anwendungen angelegten Normen und Werte demokratisch
legitimiert und kontrolliert werden:
&#8211; 739 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
14 
&#8222;Welche Werte Eingang finden, bedarf einer politischen und demokratischen Kontrolle, 
bevor automatisiere Entscheidungen ihrerseits Eingang in den Alltag finden.&#8220; (Christian 
07) 
Verschiedene Vorschl&#228;ge zur Regulierung und Gestaltung von politischen
Rahmenbedingungen werden gemacht, die z. B. die Transparenz des KI-Trainings sicherstellen,
sicherheitskritische Software kontrollieren oder KI im Arbeitskontext regulieren. Grundlegend sei
auch die Datensicherheit im Kontext von KI. Die Teilnehmenden schlagen diesbez&#252;glich 
standardisierte Pr&#252;fverfahren vor.
Die M&#246;glichkeit zur Kontrolle von KI-Entscheidungen durch eine menschliche Instanz wird als
besonders relevant erachtet:  
&#8222;Ich m&#246;chte nicht, dass z. B. KI dar&#252;ber entscheidet, ob &#8211; Beispiel autonomes Fahren 
&#8211; im Extremfall der alte Mann oder das Kind bei einem unvermeidlichen Unfall ums 
Leben kommen soll.&#8220; (cogoergosum) 
&#8222;&#220;berall wo &#252;ber Menschen entschieden wird, sind mir menschliche Entscheider lieber 
als eine KI, die nur angeblich vorurteilsfrei und sachlich entscheidet. Das m&#252;sste schon 
beweisbar vorurteilsfrei sein, nachvollziehbar warum so entschieden wurde und durch 
eine &#8218;h&#246;here&#8216; menschliche Instanz &#252;bersteuerbar.&#8220;(thom_z.) 
Regeln f&#252;r sicherheitskritische Software sollten deshalb besondere Beachtung finden. Auch
Haftungsfragen und Mindestanforderungen sollten in diesem Kontext gekl&#228;rt werden.
Zugleich wenden einige Teilnehmende jedoch ein, dass nicht &#252;berm&#228;&#223;ig von staatlicher Seite 
reguliert werden solle. Regulierende Eingriffe solle es nur dann geben, wenn Diskriminierung 
oder eine reale Gefahr zu bef&#252;rchten seien.
Frage 2: &#8222;Inwieweit verlassen Sie sich auf Produkte oder Anwendungen, die
mit KI arbeiten?&#8220; 
Die zweite Frage im Themenfeld &#8222;Vertrauen und Transparenz&#8220; zielte darauf ab, zu erfahren,
welchen KI-Anwendungen und Produkten die Teilnehmenden Vertrauen schenken. Die
Teilnehmenden an der Online-Beteiligung nennen in den Kommentaren zwar Bereiche und
Anwendungsf&#228;lle, in denen sie KI bef&#252;rworten und schon verwenden, h&#228;ufiger noch nennen sie
jedoch sensible Bereiche, in denen sie eine Verwendung ablehnen, keine Fehler tolerieren
w&#252;rden oder bei denen sie Bedingungen an den Einsatz von KI kn&#252;pfen. Ob und inwiefern
man sich auf KI verl&#228;sst, ist damit stark fallabh&#228;ngig.
Je sensibler die Daten und je h&#246;her das Risiko, desto kritischer die Sicht auf KI-
Anwendungen 
Als grundlegend erachten verschiedene Teilnehmende, dass je nach Anwendungsfall
entschieden wird, ob man sich auf KI verlassen kann. Damit gehe einher, dass die Sensibilit&#228;t der
Daten und das Gef&#228;hrdungspotential ber&#252;cksichtigt werden. Werden besonders sensible
Daten verwendet und bergen die Anwendungsszenarien gro&#223;e Risiken, so werden
Anwendungen, die mit KI arbeiten, eher abgelehnt.
&#8222;Bereiche in denen keine Fehlertoleranz herrscht, sollte man nicht alleinig der KI 
&#252;berlassen.&#8220; (Bomel)
&#8211; 740 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
15 
&#8222;Ein Chatbot an einer Hotline darf mal einen Fehler machen, hier entsteht kein 
nennenswerter Schaden, bei einem selbstfahrenden Auto ist die Lage sicher anders.&#8220; 
(der Markus) 
Eine Auswahl an abgelehnten Anwendungen umfasst daher KI in der Rechtsprechung, die
Vorsortierung von Bewerbungen (die in einem anderen Kommentar aber auch positiv bewertet
wurde), Risiko- und Bonit&#228;tspr&#252;fungen und die g&#228;nzliche &#220;bernahme von Aufgaben in der 
Pflege. In den Kommentaren finden sich jedoch nur wenige Pauschalaussagen, weil sich eine
Ablehnung immer aus dem spezifischen Risiko (und damit verbunden auch der jeweiligen
Fehlertoleranz) ergebe.
Akzeptierte Anwendungen 
Einige KI-Anwendungen werden von den Teilnehmenden bereits genutzt und akzeptiert wie
z. B. Suchfunktionen oder Bildoptimierungen.
&#8222;Bei Produkten oder Anwendungen &#8222;des t&#228;glichen Bedarfs&#8220; verlasse ich mich 
weitgehend auf KI, pr&#252;fe und verbessere ggf. aber sporadisch die Ergebnisse.&#8220; 
(Fabian S.) 
&#8222;Viele Dinge k&#246;nnte ich ohne semantisches Netz gar nicht mehr finden. Dateien, 
Datens&#228;tze, Fotos - das hat man in der Regel zu Tausenden auf dem Computer. 
Angenommen, ich w&#252;rde eine Notiz suchen, wo ich etwas zu einem Discounter 
geschrieben hatte. Zum Zeitpunkt der Suche w&#252;rde mir das Wort "Discounter" nicht 
in den Sinn kommen, wahrscheinlich w&#252;rde ich im Suchprogramm "Supermarkt" 
eingeben. Das Suchprogramm verwendet ein Semantisches Netz, das die Suche auf 
sinnverwandte W&#246;rter erweitert, z. B. "Einzelhandel", "Supermarktkette", und eben 
"Discounter".&#8220; (Joachim P.) 
Auch f&#252;r die Akzeptanz von Anwendungen nennen die Teilnehmenden Bedingungen.
Insbesondere d&#252;rfe die Fehlerquote nicht h&#246;her liegen, als bei der Ausf&#252;hrung durch den Menschen: 
&#8222;Wenn ein KI-System eine medizinische Diagnose stellt, dann ist die mit einer 
gewissen Wahrscheinlichkeit korrekt, aber eben nicht unfehlbar; Das muss man im 
Hinterkopf behalten. Die Fehler der KI sollten nur nicht h&#228;ufiger sein, als die des 
Menschen.&#8220; (Harald) 
Transparenz und Qualit&#228;t als Rahmenbedingungen
Auch in den Kommentaren zu dieser Frage werden Transparenz und Nachvollziehbarkeit als
wichtige Voraussetzungen f&#252;r die Anwendung von KI genannt und dass KI-Entscheidungen 
nachvollzogen werden k&#246;nnen, wird mehrfach gefordert. Regelm&#228;&#223;ige Kontrollen und die
M&#246;glichkeit, Entscheidungen zu &#252;berpr&#252;fen, werden empfohlen. Besonders in Bezug auf das
Training von KIs und die jeweilige Datenbasis werden Bedingungen formuliert: 
&#8222;Eine KI ist immer nur so gut wie ihre Trainingsdaten. Insofern sollte man jede KI 
genauso kritisch sehen wie jedes andere Produkt.&#8220; (versat) 
Dass in Bezug auf die Trainingsdaten keine Transparenz herrsche, kritisieren die
Teilnehmenden, weil so nicht &#252;berpr&#252;ft werden k&#246;nne, ob die KI erforderliche Qualit&#228;tsstandards einhalte.
&#8211; 741 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
16 
Herausforderungen und Handlungsbedarfe f&#252;r die Vertrauensbildung 
Eine Weiterentwicklung von KI sei aus Sicht der Teilnehmenden absehbar und damit
unvermeidlich, aber f&#252;r die Vertrauensbildung in Bezug auf KI nennen die Teilnehmenden
verschiedene Herausforderungen. Ob man sich auf KI verlasse, h&#228;nge weniger von der Technik an
sich ab, sondern davon, wie diese genutzt werde:
&#8222;Ich verlasse mich ja auch nicht sehr oder wenig auf einen Handwerker, der einen 
Schraubenschl&#252;ssel benutzt, sondern vertraue darauf (oder eben nicht), dass er 
wei&#223;, wie er ihn benutzen muss. Bei KI ist es nicht anders.&#8220; (TheresaW.) 
So vertraue man Menschen und ihrem Wissen zum korrekten Einsatz und nicht den KI-
Anwendungen an sich. Entsprechend schlagen die Teilnehmenden auch vor, dass
Letztentscheidungen von Menschen gef&#228;llt werden sollten. In diesem Kontext wird auch darauf
verwiesen, dass sowohl Menschen als auch KI Fehler unterliefen und &#220;berpr&#252;fungen deshalb in
beiden F&#228;llen sinnvoll seien. Dass Menschen bedenkenlos KI-Entscheidungen vertrauen
w&#252;rden, wird von einigen Teilnehmenden kritisiert. Entsprechend sollten Menschen KI-
Entscheidungen st&#228;rker hinterfragen bzw. dazu bef&#228;higt werden, dies zu tun. Doch genau diese
Hinterfragungsleistung wollten oder k&#246;nnten nicht alle User erbringen:
&#8222;Der Gro&#223;teil der User muss bzw. m&#246;chte sich gar nicht im Detail damit 
auseinandersetzten, wie die Software programmiert ist, sondern m&#246;chte sich auf den 
Hersteller verlassen k&#246;nnen, dass die Software qualit&#228;tiv hochwertig ist.&#8220; (LisaS). 
Es zeigen sich folglich Widerspr&#252;che in Bezug auf die Rolle des Menschen, der einerseits
durch KI entlastet werden soll, sich aber zugleich &#252;ber die Funktionsweise der KI informieren
soll. 
In Bezug auf die Vertrauensbildung wird betont, dass Positiverfahrungen das Vertrauen
st&#228;rken k&#246;nnen. F&#252;r Vertrauen k&#246;nnten hingegen klare Regeln f&#252;r Haftung und Transparenz
sorgen, die sicherstellen, dass Endnutzerinnen und Endnutzer sich auf die KI verlassen k&#246;nnen:
&#8222;Man kann sich nicht auf diese Systeme verlassen, solange deren Ergebnisse nicht 
&#252;berpr&#252;fbar und deren Betreiber nicht haftbar und deren Einsatz nicht 
unmi&#223;verst&#228;ndlich, un&#252;bersehbar kenntlich gemacht wird.&#8220; (Rainer) 
Untergraben w&#252;rde das Vertrauen hingegen durch Versuche der Verbrauchermanipulation,
get&#228;uschte neuronale Netze, aber auch besagte Intransparenzen in Bezug auf die
Trainingsdaten. 
Frage 3: &#8222;Inwiefern w&#228;re es f&#252;r Sie hilfreich, wenn KI-Systeme auf m&#246;gliche 
Risiken hin eingesch&#228;tzt und klassifiziert werden?&#8220;
Einsch&#228;tzung und Klassifizierung von Risiken k&#246;nnen Transparenz herstellen. Welche
Meinungen die Teilnehmenden in Bezug auf Sinnhaftigkeit und Umsetzung von
Risikoeinsch&#228;tzungen und -klassifizierungen vertreten, wurde mit der dritten Frage im Themenfeld &#8222;Vertrauen 
und Transparenz&#8220; erfragt.
Insgesamt bef&#252;rworten die Teilnehmenden der Online-Beteiligung die Einstufung von KI nach
Risikoklassen. In ihren Kommentaren nennen sie sowohl verschiedene Zwecke, bei denen
eine Risikoklassifizierung sinnvoll und notwendig w&#228;re, als auch wie die Risiken abgestuft und
&#8211; 742 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
17 
wie diese Abstufungen entwickelt werden sollten. Zahlreiche Kommentare befassen sich
zudem mit dem rechtlichen Rahmen und der Haftung, die ebenfalls genauer gekl&#228;rt werden
m&#252;ssten.  
Zwecke und Chancen von Risikoklassifizierungen
Ein wichtiger Vorteil von Risikoeinsch&#228;tzungen (und deren Durchsetzung durch
Regulierungen) bestehe darin, Vertrauen in KI-Anwendungen zu schaffen:
&#8222;Kontrolle wird die Akzeptanz der B&#252;rger erh&#246;hen, sich auf Ergebnisse der KI zu 
verlassen. Ferner kann so sichergestellt werden, dass ein Missbrauch 
ausgeschlossen wird. Wichtig w&#228;re aus meiner Sicht, dass die Regelungen 
transparent und verbindlich sind. Aktionen &#224; la &#8218;freiwillige Selbstverpflichtung&#8216; sollten 
im Feld der KI unterbleiben.&#8220; (Peter W.) 
Verbraucherinnen und Verbraucher k&#246;nnten sich durch Risikoeinsch&#228;tzungen besser
informieren und M&#228;ngel ausschlie&#223;en. B&#252;rgerinnen und B&#252;rger k&#246;nnten m&#252;ndig am Diskurs um
KI teilhaben und Menschen, die tendenziell von Diskriminierung betroffen sind, k&#246;nnten
etwaige negative Auswirkungen besser absch&#228;tzen. 
Vorschl&#228;ge f&#252;r die Entwicklung von Risikoeinsch&#228;tzungen
Die Teilnehmenden unterbreiten verschiedene Vorschl&#228;ge, wie Risikoeinsch&#228;tzungen und 
klassifizierungen vorgenommen werden k&#246;nnten. Eine kontinuierliche (Neu-)Bewertung
von Risiken und entsprechende Anpassung von Regulierungen sei sinnvoll, weil KI sich stetig 
weiterentwickle: 
&#8222;Diese Bewertung kann nie abschlie&#223;end sein und muss regelm&#228;&#223;ig wiederholt 
werden, so lange eine KI weiter lernt.&#8220; (kayrie) 
Risiken m&#252;ssten f&#252;r Software an sich eingesch&#228;tzt werden und nicht nur f&#252;r KI-Anwendungen, 
die Komponenten des Maschinellen Lernens enthalten. Algorithmische Systeme m&#252;ssten
au&#223;erdem im Kontext ihrer Entwicklung und Anwendung (z. B. Machtkonzentration Betreiber,
Auswirkung auf Teilhabe), betrachtet werden, weil sich nur so Risiken sinnvoll einsch&#228;tzen 
lie&#223;en.
Mehrfach wird vorgeschlagen, auf bestehende Qualit&#228;tskriterien und -klassifizierungen
aufzubauen: So k&#246;nnten &#8222;bereits bestehende Risikoklassifizierung im Rahmen der
Datenschutz-Folgenabsch&#228;tzung (Art. 35 DSGVO)&#8220; (Michael B. S. und David W.) erweitert werden
oder z. B. f&#252;r Medizinprodukte auf der &#8222;europ&#228;ische[n] Medizinprodukteverordnung&#8220;
(Katharina) aufgebaut werden.  
Rollenverteilung der Akteure in Entwicklung und Vergabe
Grundlegend wird eine breite Einbindung verschiedener Akteure in die Entwicklung von
Risikoklassifikationen gefordert sowie eine interdisziplin&#228;re Erarbeitung der Kriterien. Eine
demokratische Kontrolle der Risikoeinsch&#228;tzungen und -klassifizierungen erachten einige
Teilnehmenden ebenso als notwendig. Hierf&#252;r wird beispielweise vorgeschlagen, eine Einrichtung 
der Exekutive mit der Kontrolle der Risikoklassifizierung zu betrauen. Zum Beispiel k&#246;nnte dem
Bundesamt f&#252;r Sicherheit in der Informationstechnik eine zentrale Rolle zukommen, indem es
an der Erstellung von Vorgaben f&#252;r die Risikoeinsch&#228;tzung und -klassifizierung zust&#228;ndig 
w&#228;re. Die praktische Zuordnung von Risikoklassen und die Vergabe von G&#252;tesiegeln k&#246;nnte 
von anderen Organisationen &#252;bernommen werden, wie z. B. dem T&#220;V oder einer Stelle, die
&#8211; 743 &#8211; 
-
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
18 
akkreditiert sein sollte, um das Vertrauen in ihre Arbeit zu st&#228;rken. Selbsteinsch&#228;tzungen
werden kritisch betrachtet und wenn &#252;berhaupt, nur f&#252;r niedrige Risikoklassen empfohlen.
Schlie&#223;lich hingen die Ergebnisse von Risikozuweisungen davon ab, welche Organisation sie 
durchf&#252;hre. 
Abstufungen von Risiken
Die Teilnehmenden behandeln in ihren Kommentaren die verschiedenen Abstufungen und
jeweiligen Kriterien f&#252;r Risikoklassifizierungen. Besonders wichtig sei, dass
Risikoklassifizierungen die Datensensibilit&#228;t ber&#252;cksichtigen. Ein Kommentar stellt beispielhaft die Diversit&#228;t der
m&#246;glichen Anwendung und einhergehenden Risiken dar:
&#8222;Es macht einen Unterschied, ob ich &#246;ffentlich verf&#252;gbare Informationen zu 
Unterhaltungszwecken aufbereitet bekomme, ob Klimaentwicklung oder 
Verkehrsfl&#252;sse vorhergesagt, Prognosen f&#252;r st&#228;dtebauliche Ma&#223;nahmen erstellt 
werden, ob meine Bonit&#228;t gepr&#252;ft, ein Versicherungsrisiko bewertet, oder eine 
medizinische Diagnose gestellt wird.&#8220; (JeBau) 
Von einer starren &#8222;one size fits all&#8220;-Klassifizierung wird deshalb abgeraten, weil sie der Vielfalt
an Anwendungen und den unterschiedlich gro&#223;en Risiken nicht gerecht werden w&#252;rde. Hierf&#252;r
werden bereits konkrete Kriterien vorgeschlagen.
&#8222;Das Gesamtrisiko kann dabei anhand mehrerer Kriterien definiert werden, z. B. 
physische Sicherheit, Datenschutz, Diskriminierung etc. KI Anwendungen, die ein 
Risiko f&#252;r die Grundrechte darstellen, sollten einem Moratorium unterliegen, bis ein 
klarer ethischer und regulatorischer Rahmen existiert, der das Risiko beherrschbar 
macht  oder sie ganz verboten werden.&#8220; (Benedikt B.) 
Die Teilnehmenden schlagen konkret vor, dass die Klassifizierung auch die Qualit&#228;t der
Trainingsdaten einbeziehen und beachten sollte, welche Risiken von menschlichem Handeln und
KI-Entscheidungen ausgehen. Die Einsch&#228;tzung von Risiken wird dabei in der praktischen 
Umsetzung nicht als trivial angesehen: So sei eine Prognose der Auswirkung und potenzieller
Sch&#228;den in der praktischen Umsetzung eine Herausforderung, weil die Berechnung schwierig
sei.
Regulierung und Haftung
Flankierend zu den Risikoeinsch&#228;tzungen und -klassifizierungen werden ebenso klare
Haftungsregeln empfohlen, die wichtig seien, um das Vertrauen zu st&#228;rken. Ins Spiel gebracht 
werden auch ein Versicherungszwang gegen KI-Sch&#228;den und Sanktionen bei unterlassener
Risikokennzeichnung. F&#252;r juristische, polizeiliche und milit&#228;rische Einsatzzwecke m&#252;ssten
explizite Regeln festgelegt werden (z. B. eine Konvention zum Verbot autonomer Waffen, die auf
KI basieren).  
Au&#223;erdem gelte es, die Rechte von Nutzerinnen und Nutzern zu sichern. So wird das Recht
auf &#220;berpr&#252;fung von KI-Entscheidungen angef&#252;hrt, aber auch die M&#246;glichkeit, sich gegen die 
Verwendung einer KI zu entscheiden. 
Obwohl die Mehrzahl der Kommentare st&#228;rkere Regulierungen fordern, verweisen andere auf
die Gefahr einer &#220;berregulierung, die Innovationen hemme. Ein Vorschlag grenzt die
Regulierung deshalb auf die Systeme ein, &#8222;die eine mittelbare oder unmittelbare Auswirkung auf 
menschliche Teilhabem&#246;glichkeiten zeitigen k&#246;nnen&#8220; (Projektteam Ethik der Algorithmen).
&#8211; 744 &#8211; 
 -
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
19 
Frage 4: &#8222;Wie beurteilen Sie die Einf&#252;hrung von Standards f&#252;r KI-Systeme, 
z. B. eines anwendungsspezifischen G&#252;tesiegels?&#8220;
Standards und G&#252;tesiegel sollen auf einfache Art und Weise &#252;ber die Qualit&#228;t von KI
informieren. Die Teilnehmenden wurden gebeten ihre Perspektiven zu schildern und anzugeben, ob
ein G&#252;tesiegel ihr Vertrauen in KI st&#228;rken w&#252;rde, welche Informationen im Siegel enthalten 
sein sollten und wer mit der Vergabe betraut sein sollte.
In den Kommentaren finden sich zahlreiche Hinweise dazu, wie die Einf&#252;hrung von Standards
gestaltet werden k&#246;nnte, welche Bedingungen erf&#252;llt und welche Herausforderungen bedacht
werden m&#252;ssten. Die Beurteilungen geben Aufschluss dar&#252;ber, wie und unter welchen
Bedingungen Standards f&#252;r KI-Systeme begr&#252;&#223;t oder abgelehnt werden. Die konstruktiven
Kommentare zu den G&#252;tekriterien einer Kennzeichnung und zum Entwicklungs- und
Vergabeprozess zeugen davon, dass viele Teilnehmende G&#252;tesiegel und Standards f&#252;r sinnvoll
erachten und Chancen in der Etablierung eines Siegels sehen. Es gibt allerdings auch viele
Stimmen, die G&#252;tesiegel als wenig aussagekr&#228;ftig erachten, besonders weil KI-
Anwendungen sich dynamisch ver&#228;nderten und die stetige Anpassung der Siegel schwierig w&#228;re.
Abgesehen von G&#252;tesiegeln wird in einigen Kommentaren gefordert, dass Regulierungen und
rechtliche Mittel wichtig seien, weil ein auf Freiwilligkeit basierendes G&#252;tesiegel nicht
ausreiche. Diese k&#246;nnte z. B. Mindeststandards, Verbote sowie Strafen f&#252;r Verst&#246;&#223;e umfassen.  
&#8222;Ich finde, dass die Kriterien des G&#252;tesiegel eigentlich nicht in ein G&#252;tesiegel 
geh&#246;ren, sie sollten verpflichtend sein. In allen KI-Technologien sollten Bedingungen 
wie Datenschutz, Unvoreingenommenheit, Transparenz erf&#252;llt werden, die freiwillige 
Ber&#252;cksichtigung dieser reicht nicht aus.&#8220; (EllaM.) 
G&#252;tesiegel, die auf einer freiwilligen Pr&#252;fung basieren, sind in dieser Sichtweise nur eines der 
Mittel, mit denen sich die Qualit&#228;t von und damit auch das Vertrauen in KI st&#228;rken lie&#223;e.
G&#252;tekriterien
Verschiedene Kriterien werden genannt, die in G&#252;tesiegeln verankert werden sollten.
Insbesondere sollte ein G&#252;tesiegel &#252;ber die Verwendung von KI und verschiedene
Risikoklassen informieren:
&#8222;Voraussetzung f&#252;r die Einf&#252;hrung eines anwendungsspezifischen G&#252;tesiegels ist 
die systematische Beschreibung [&#8230;] und die Klassifizierung der KI-Systeme nach 
Kritikalit&#228;t.&#8220; (maschei) 
Die diskutierten Risikoklassen (siehe Frage 3) sollten dementsprechend im G&#252;tesiegel
aufgegriffen werden. Eine grundlegende Bedingung sei zudem, dass sich die G&#252;te an ethischen
Standards und der Einhaltung von Normen orientiere:
&#8222;Ein G&#252;tesiegel sollte unbedingt die Dimension der Antidiskriminierung umfassen. 
Das hei&#223;t, es muss &#252;berpr&#252;ft werden, inwieweit der Einsatz von KI nicht 
diskriminierend auf unterschiedliche Gruppen [&#8230;] wirkt, sondern im Gegenteil in der 
Zug&#228;nglichkeit und der Umsetzung inklusiv ist.&#8220; (Hanna V.) 
Mehrfach wird vorgeschlagen, den Prozess zu zertifizieren und nicht den tempor&#228;ren
Zustand eines KI-Systems, weil dieser sich stetig ver&#228;ndere.
&#8211; 745 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
20 
Anstelle eine G&#252;tesiegels k&#246;nnen auch Transparenz und Nachvollziehbarkeit die G&#252;te einer 
KI-Anwendung zeigen. So g&#228;be es die M&#246;glichkeit zu verstehen, wie Entscheidungen von der
KI-Anwendung gef&#228;llt werden:
&#8222;Das beste G&#252;tesiegel ist Transparenz. Wenn KI-Systeme Black-Boxen sind, zu 
denen nur wenige Zugang erhalten, kann kein Vertrauen entstehen: G&#252;tesiegel sind 
in diesem Fall kaum glaubw&#252;rdig und wiegen den Verbraucher in falscher Sicherheit.&#8220; 
(der Markus) 
Vorschl&#228;ge f&#252;r die Entwicklung und Vergabe eines G&#252;tesiegels
Die Teilnehmenden entwickelten auch praktische Vorschl&#228;ge, wie die Entwicklung, Vergabe
und Kontrolle von G&#252;tesiegeln organisiert werden k&#246;nnten. Bei der Entwicklung von Siegeln 
m&#252;ssten Akteure aus unterschiedlichen Bereichen wie Politik, Wirtschaft und Wissenschaft
(z. B. Fraunhofer-Institute) einbezogen werden, weil dies sicherstelle, dass unterschiedliche 
Interessen ber&#252;cksichtigt w&#252;rden: 
&#8222;G&#252;tesiegel sind sinnvoll. Sie m&#252;ssen aber von mehreren unabh&#228;ngigen Gruppen 
mitbestimmt werden, sodass das G&#252;tesiegel nicht nur das Interesse einer kleinen 
Minderheit widerspiegelt.&#8220; (ijon.tichy) 
Mehrfach wird gefordert, dass eine unabh&#228;ngige und kompetente Organisation mit der
Vergabe und Pr&#252;fung betraut wird. Dabei betonen die Teilnehmenden, dass eine staatliche 
und demokratische Kontrolle der vergebenden Institution sinnvoll sei. Eine
Selbstauszeichnung wird in diesem Kontext hingegen kritisiert. Daf&#252;r m&#252;ssten gegebenenfalls auch neue
Einrichtungen geschaffen werden. 
&#8222;Wichtig ist nat&#252;rlich, dass kompetente Organisationen f&#252;r diese Aufgabe zust&#228;ndig 
sind, auch wenn daf&#252;r m&#246;glicherweise neue Einrichtungen/Beh&#246;rden entstehen 
m&#252;ssten.&#8220; (caropt) 
Unabh&#228;ngige Stellen k&#246;nnten das Vertrauen in ein G&#252;tesiegel st&#228;rken. Eine Reihe weiterer 
konkreter Vorschl&#228;ge finden sich in den Kommentaren, z. B. schlagen die Teilnehmenden 
ein Pr&#252;fverfahren vor, bei dem eine KI durch eine daf&#252;r entwickelte KI-Anwendung gepr&#252;ft
werde. Denkbar sei auch, Kriterien f&#252;r KI in bereits bestehende G&#252;tesiegel zu integrieren. Die
Aufnahme von G&#252;tekriterien in &#246;ffentliche Beschaffungsstandards k&#246;nnte sich f&#252;r die
Durchsetzung der Kriterien zudem als hilfreich erweisen. 
Herausforderungen aus Sicht der Teilnehmenden
Die Teilnehmenden sehen in der Gestaltung des Kriterienkatalogs und der
Qualit&#228;tsbestimmung f&#252;r ein m&#246;gliches Siegel eine zentrale Herausforderung. Hinzu komme noch, dass 
G&#252;tesiegel einen bestimmten Zustand zertifizierten, KI aber per Definition ein sich wandelndes 
System sei:  
&#8222;G&#252;tesiegel k&#246;nnen immer nur den Stand an einem Tag x zertifizieren. Wie soll das 
bei kontinuierlicher Fortentwicklung von Software etc., geschweige denn KI, helfen?&#8220; 
(JeBi20) 
Auch wenn viele Teilnehmende G&#252;tesiegel bef&#252;rworten, wird von anderen bem&#228;ngelt,
G&#252;tesiegel hielten ihr Versprechen nicht, es g&#228;be ihrer bereits zu viele und sie seien aufw&#228;ndig
in Implementierung und Kontrolle. Die Identifizierung kompetenter Akteure f&#252;r Entwicklung,
&#8211; 746 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
21 
Vergabe und Kontrolle wird zudem in einigen Kommentaren als Herausforderung f&#252;r
G&#252;tesiegel benannt. So fragt eine kommentierende Person:
&#8222;Wer soll das G&#252;tesiegel erteilen, wer hat die Kompetenz entsprechende 
Einsch&#228;tzungen vorzunehmen?&#8220; (tomkre) 
3.2 Themenfeld &#8222;Beruf und Alltag&#8220;
Das Thema &#8222;Beruf und Alltag&#8220; wurde ausgew&#228;hlt, da KI bereits im Alltag und im beruflichen
Umfeld vieler Menschen (bewusst oder unbewusst) eine Rolle spielt und zuk&#252;nftig zunehmend
spielen wird. KI weist hier vielf&#228;ltigste Anwendungsbereiche auf und wird einerseits als
Unterst&#252;tzung wahrgenommen, andererseits aber auch kritisch betrachtet. Aufgrund der direkten
Betroffenheit vieler Menschen in diesen zwei Lebenswelten stellt dieses Themenfeld einen 
guten Raum f&#252;r Diskussionen auch ohne die Notwendigkeit vertiefter fachlicher Kenntnisse zu
KI dar.
Frage 5: &#8222;Welche Ver&#228;nderungen erwarten Sie durch den zunehmenden 
Einsatz von KI in der Zukunft?&#8220;
Die Teilnehmerinnen und Teilnehmer sollten hier diskutieren, welche Ver&#228;nderungen durch KI
sie in Zukunft erwarten und welche f&#252;r sie pers&#246;nlich die wichtigsten Verbesserungen und
welche die gr&#246;&#223;ten Risiken durch den zunehmenden Einsatz von KI darstellen w&#252;rden. Die 
Antworten der Teilnehmerinnen und Teilnehmer zeigen, dass sie &#252;berwiegend weitreichende
und verschiedenste Gesellschaftsbereiche durchdringende Ver&#228;nderungen mit dem
zunehmenden Einsatz von KI verbinden: 
&#8222;Unser Leben, unser Konsumverhalten und auch insbesondere Arbeit, Bildung und 
Wirtschaft werden sich sehr stark und radikal ver&#228;ndern. Darauf muss es Antworten 
geben und vor allem darf niemand &#252;berfordert werden. Die Verantwortung der Politik 
ist es nicht nur, die Rahmenbedingungen f&#252;r die umfassende Digitalisierung zu 
schaffen, sondern auch alle mitzunehmen und niemanden zu &#252;berfordern.&#8220; 
(Justus02) 
Insgesamt stehen die Teilnehmenden den Ver&#228;nderungen eher positiv als negativ gegen&#252;ber.  
Positive Ver&#228;nderungen und Chancen aus Sicht der Teilnehmenden
Eine besonders oft genannte Ver&#228;nderung, welche zugleich unterschiedliche Chancen f&#252;r die
Menschen mit sich bringen kann, ist die Effizienzsteigerung von Prozessen durch KI: 
&#8222;Die schnell wachsende Weltbev&#246;lkerung in Verbindung mit endlichen Ressourcen 
erfordert es, dass die Bau- und Fertigungsindustrie Wege findet, mehr Wohnungen 
zu bauen und mehr Konsumg&#252;ter auf effizientere und nachhaltigere Weise 
herzustellen. KI-f&#228;hige Technologien k&#246;nnen Architekten, Ingenieure, 
Bauunternehmen, Produktdesigner und Hersteller dabei unterst&#252;tzen, ihre Entw&#252;rfe 
und Prozesse zu optimieren, Designfehler zu begrenzen, Materialverschwendung zu 
minimieren und Projektzeit sowie -kosten zu reduzieren.&#8220; (Autodesk) 
Die Optimierung von Prozessen und Produkten, der Fokus auf die Kernt&#228;tigkeit und die
gleichzeitige Zeiteinsparung bieten aus Sicht einiger Teilnehmenden das Potenzial, das soziale
Miteinander wieder mehr in den Vordergrund zu r&#252;cken und beruflichen Stress zu reduzieren,
was sich wiederum positiv auf den Gesundheitszustand vieler Menschen auswirken k&#246;nne. KI
&#8211; 747 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
22 
k&#246;nne die Produktivit&#228;t erh&#246;hen und neben der Entlastung von bestimmten T&#228;tigkeiten den
Menschen mehr Freir&#228;ume und Wohlstand (u.a. m&#246;glich durch mehr Innovationen aufgrund 
der gewonnenen Zeit, Teilhabe an Zukunftstechnologien und wachsenden M&#228;rkten)
verschaffen (siehe auch Frage 1): 
&#8222;Ich erwarte, dass KI Aufgaben &#252;bernimmt, was zu einer Zeitersparnis bei einem 
Menschen f&#252;hrt, der diese Zeit dann in einen anderen Menschen investieren kann. 
Ich erwarte, dass KI Aufgaben &#252;bernimmt und wir so zu einer 4-Tage-Woche 
kommen.&#8220; (Pyromorphit) 
Als besonders zentral empfinden die Teilnehmerinnen und Teilnehmer die erwarteten
Ver&#228;nderungen im medizinischen Bereich: 
&#8222;KI unterst&#252;tzt und verbessert das Gesundheitswesen und die medizinische 
Versorgung ganzheitlich und hat Auswirkungen auf drei Ebenen, der technischen, 
klinischen und systemischen: [&#8230;] KI unterst&#252;tzt den Arzt bzw. das Fachpersonal bei 
der Bedienung der Medizinger&#228;te und IT-L&#246;sungen, um menschliche Fehler zu 
vermindern, alle relevanten Daten anzuzeigen oder Korrelationen zwischen 
Patientenkohorten herzustellen. [&#8230;] KI-unterst&#252;tzte Systeme k&#246;nnen genetische und 
molekularbiologische Merkmale eines Versicherten bzw. Patienten in die Diagnose 
und Therapie noch besser mit einbeziehen und unterst&#252;tzen so eine auf die 
individuellen Bed&#252;rfnisse ma&#223;geschneiderte Versorgung (Pr&#228;zisionsmedizin). Nur 
durch KI kann Pr&#228;zisionsmedizin in die Routine &#252;berf&#252;hrt werden. [&#8230;] KI erm&#246;glicht 
neue Durchbr&#252;che in der Versorgungsforschung (Population Health Management), 
wo Daten in gro&#223;en Mengen analysiert und medizinische Kohorten verglichen 
werden, mit dem Ziel, die Gesundheitsversorgung einer Bev&#246;lkerung insgesamt und 
den Gesundheitszustand des Einzelnen zu verbessern.&#8220; (Katharina) 
Die Teilnehmenden gehen davon aus, dass die Diagnostik in Zukunft durch den Zugriff auf
gro&#223;e Datenmengen stark verbessert werden kann und sogar bisher als unheilbar geltende
Krankheiten durch neue Erkenntnisse geheilt werden k&#246;nnten. Neben der medizinischen
Erforschung sehen die Teilnehmenden zuk&#252;nftig auch gro&#223;es Potenzial durch KI f&#252;r weitere
Wissenschaften; sie erwarten neue Erfindungen in der Pharmazeutik sowie generell bei
Materialien, Verbesserungen in der Klimaforschung und Physik-Grundlagenforschung. Im
Hinblick auf die Covid-19-Pandemie wird auch das Entwickeln verh&#228;ltnism&#228;&#223;iger Reaktionen auf
Ph&#228;nomene durch ein beschleunigtes Erkenntniswachstum dank KI erhofft.  
Neben pers&#246;nlichen KI-Assistenten z. B. f&#252;r die Informationsbeschaffung oder beim
Autofahren sowie insbesondere f&#252;r hilfebed&#252;rftige Zielgruppen wie &#228;ltere und kranke Menschen
erwarten die Teilnehmenden au&#223;erdem positive Ver&#228;nderungen im Service sowohl f&#252;r
Mitarbeiterinnen und Mitarbeiter (z. B. Chatbots f&#252;r Helpdesks) als auch f&#252;r Kundinnen und Kunden 
(z. B. in der Kundenbetreuung, bei der Kommunikation mit Versicherungen und Banken oder
in der Tourismusbranche). Im Hinblick auf die Arbeitsweise von Verwaltungen sehen die
Teilnehmenden Effizienzsteigerungspotenziale und die M&#246;glichkeit, die Komplexit&#228;t f&#252;r
B&#252;rgerinnen und B&#252;rger durch den Einsatz von KI hier zu verringern.
In den Bereichen Verkehr und Logistik werden positive Ver&#228;nderungen durch den Einsatz
von KI erwartet. So k&#246;nne der Verkehrsfluss optimiert werden, menschliche Fehler durch
Fahrassistenzsysteme reduziert und in kritischen Situationen im Stra&#223;enverkehr schneller bessere
&#8211; 748 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
23 
Entscheidungen getroffen werden. Das Vorantreiben des autonomen Fahrens (von
&#246;ffentlichen Verkehrsmitteln) wird auch im Hinblick auf die damit m&#246;gliche F&#246;rderung der Mobilit&#228;t 
(u.a. von Zielgruppen wie Seniorinnen und Senioren) in l&#228;ndlichen R&#228;umen begr&#252;&#223;t.
Positive Ver&#228;nderungen durch den zunehmenden Einsatz von KI erwarten sich die
Teilnehmenden auch in der Arbeitswelt und zwar branchen&#252;bergreifend. Sie hoffen, dass gef&#228;hrliche
und/oder monotone bzw. routinem&#228;&#223;ige Arbeiten technisiert werden, um bei den so
entlasteten Menschen neue Potenziale freizusetzen und wieder mehr Raum f&#252;r soziale T&#228;tigkeiten zu
schaffen. Diese Entwicklung m&#252;sse jedoch auf jeden Fall aktiv durch Qualifizierungs- und
Weiterbildungsprogramme begleitet werden:
&#8222;Durch KI  insbesondere durch die &#220;bernahme von Routinet&#228;tigkeiten werden 
sich viele Berufsbilder grundlegend ver&#228;ndern, viele Berufe werden wie bei allen 
vorherigen technischen Revolutionen &#8211; v&#246;llig verschwinden, daf&#252;r ganz neue 
entstehen. Diese Entwicklung ist positiv und unbedingt zu begr&#252;&#223;en, nicht zuletzt mit 
Blick auf den bereits beginnenden Fachkr&#228;ftemangel: KI erh&#246;ht nicht nur unsere 
Produktivit&#228;t und verschafft uns damit neue Freir&#228;ume und Wohlstand, sondern 
entlastet uns auch von monotonen &#8211; unter Umst&#228;nden sogar gef&#228;hrlichen &#8211; 
T&#228;tigkeiten. Allerdings d&#252;rfen wir den Wandel unserer Arbeitswelt nicht einfach so 
geschehen lassen, sondern m&#252;ssen ihn aktiv gestalten, z. B. durch umfangreiche 
Qualifizierungs- und Weiterbildungsprogramme.&#8220; (Fabian S.) 
Wenngleich die Ver&#228;nderungen in der Arbeitswelt durchaus positiv bewertet werden, haben 
einige der Teilnehmenden auch Bedenken in Bezug auf diese Entwicklung und bef&#252;rchten
eine steigende Arbeitslosenquote. 
Das Thema Nachhaltigkeit wird von den Teilnehmenden einerseits hinsichtlich der
Verbesserung f&#252;r unternehmerische Zwecke durch Predictive Maintenance (vorausschauende
Instandhaltung) adressiert sowie unter sozialen und Umweltaspekten, f&#252;r welche KI eine positive 
Ver&#228;nderung bewirken k&#246;nne. So werden z. B. die Reduktion des Energieverbrauches oder
die ressourcenschonende Stadt- und Umweltplanung genannt.
Weiterhin k&#246;nnten durch KI zuk&#252;nftig gerechtere Beurteilungssysteme eingesetzt werden
und diskriminierende soziale Strukturen eingeschr&#228;nkt werden: So k&#246;nne KI z. B. juristische 
Aufgaben &#252;bernehmen (Legal Tech) oder als Entscheidungs- und
Rechtfertigungswerkzeug f&#252;r politische und wirtschaftliche Entscheidungen fungieren.
Negative Ver&#228;nderungen und Herausforderungen aus Sicht der Teilnehmenden 
Mehrere Teilnehmerinnen und Teilnehmer sehen ein Risiko der Ver&#228;nderungen durch den
zunehmenden Einsatz von KI darin, dass es zu einer verst&#228;rkten Individualisierung von
Lebensbereichen und damit einer Entfremdung der Menschen untereinander kommen k&#246;nnte.
Auch die Gefahr einer wachsenden Schere zwischen den Menschen, die mit der technischen
Entwicklung Schritt halten k&#246;nnen, und denen, die u.a. aus finanziellen Gr&#252;nden abgeh&#228;ngt
werden, wird f&#252;r die Zukunft gesehen. Im Ergebnis k&#246;nne es zu einer zunehmenden Spaltung
der Gesellschaft kommen. Auch sich m&#246;glicherweise verst&#228;rkende
Diskriminierungsstrukturen werden kritisch betrachtet:
&#8222;Ein Risiko sehen wir darin, dass bestehende Ungleichheiten und Diskriminierungen 
sich in KI fortschreiben und damit noch uneinsehbarer und noch unbeeinflussbarer 
wirken.&#8220; (Hanna V.)
&#8211; 749 &#8211; 
 &#8211;  &#8211; 
&#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
24 
Neben dieser potenziellen Entsolidarisierung im Zuge eines zunehmenden Einsatzes von KI 
bewerten die Teilnehmenden auch die Entwicklung kritisch, dass Nutzerinnen und Nutzer zu
&#8222;gl&#228;sernen&#8220; Menschen (JeBau) werden w&#252;rden, denen ihr Konsumverhalten quasi
vorgeschrieben w&#252;rde. Unternehmen k&#246;nnten durch die Verfolgung und Auswertung der Daten ihr
Wissen &#252;ber die Nutzerinnen und Nutzer f&#252;r ausgew&#228;hlte Zwecke verwenden, ohne dass
diese davon w&#252;ssten bzw. sich dagegen zur Wehr setzen k&#246;nnten. Diskutiert wurde unter
diesem Aspekt, dass das produzierte Wissen &#252;ber Personen nur schwerlich wieder l&#246;schbar sei
und die Gefahr des Datenmissbrauchs z. B. in Form eines Sozialrankings bestehe:
&#8222;Werden allein von fr&#252;heren Verhalten (z. B. im Internet) oder dem Wohnort aufgrund 
von Wahrscheinlichkeiten Handyvertr&#228;ge verwehrt und Versicherungen teurer? 
Bekommt jeder Kunde im Supermarkt personalisierte, h&#246;here Preise, weil der 
Marktbetreiber bestimmte Interessen ausnutzt?&#8220; (Conrad S. C.) 
&#8222;Es wird KI-Systeme geben, die allen geh&#246;ren und solche, die einzelnen Firmen, 
Organisationen, St&#228;dten, Regierungen, einzelnen Personen geh&#246;ren. Das Wissen 
dieser KI-Systeme wird nicht in Form l&#246;schbarer einzelner Dateien vorliegen, 
sondern es wird verteilt, verschl&#252;sselt, mit Pr&#252;fsummen abgespeichert sein. Es wird 
extrem schwer sein, Unerw&#252;nschtes wieder loszuwerden, z. B. &#8218;Person X war im 
Gef&#228;ngnis&#8216;, &#8218;Stadtrat Y ist korrupt&#8216;, &#8218;Firma Z l&#228;&#223;t Kleidung durch Sklavenarbeit 
fertigen&#8216;. Man mu&#223; sich im klaren dar&#252;ber sein, da&#223; dieses Ph&#228;nomen kommen wird 
und technische Gegenma&#223;nahmen &#252;berlegen.&#8220; (Joachim P.) 
Weiterhin diskutieren die Teilnehmenden anhand verschiedener Beispiele das Risiko von
zunehmend formalisierten Entscheidungen aufgrund der fehlenden Emotionalit&#228;t durch KI
ohne die Ber&#252;cksichtigung sozialer Aspekte. So wird z. B. eine &#8222;unmenschliche &#8218;Fri&#223;-oder-
Stirb&#8216;-Formalisierung&#8220; (rdoch1) in &#196;mtern, Verwaltungen, Versicherungen, Banken bef&#252;rchtet. 
Es wird die Sorge zum Ausdruck gebracht, dass Entscheidungen in Zukunft zunehmend von
KI getroffen w&#252;rden und es immer weniger Entscheidungsspielr&#228;ume f&#252;r Mitarbeiterinnen und
Mitarbeiter und zugleich weniger Optionen f&#252;r Kundinnen und Kunden gebe. Das System
k&#246;nnte gegebenenfalls keine Alternativen und Ausnahmen zulassen, sondern w&#252;rde strikt
einzuhaltende Vorgaben machen. Zudem werde der Kundenservice immer st&#228;rker technisiert und
das menschliche Gegen&#252;ber fehle zunehmend. Als weiterer Beispielbereich wird die
medizinische Versorgung genannt: Hier k&#246;nne die Behandlung insbesondere von Menschen mit
weniger finanziellen Mitteln zunehmend durch KI bestimmt werden und das Pflegepersonal f&#252;hre
den Dienst nach den Vorgaben des Systems aus &#196;rztinnen und &#196;rzte st&#252;nden hingegen nur
noch finanziell besser gestellten Menschen zur Verf&#252;gung, so die Bef&#252;rchtung. Neben dem
Risiko der fehlenden sozialen und emotionalen Komponenten wird weiterhin angemerkt, dass 
ein &#252;berh&#246;htes Vertrauen in KI zu Fehleinsch&#228;tzungen und damit zu menschlichen
Fehlentscheidungen f&#252;hren k&#246;nne. 
Zutr&#228;glich zu einer solchen negativen Entwicklung wird auch die Gefahr gesehen, dass die KI-
Technologien eine Black Box f&#252;r den Staat sowie f&#252;r Verbraucherinnen und Verbraucher
darstellen k&#246;nnen. Die Teilnehmenden sehen hierbei als problematisch an, dass eine Reaktion
auf solche Technologien und ihre Wirkungsweisen (z. B., wenn sie Diskriminierungen
fortschreiben) von staatlichen und/oder gesellschaftlichen Akteuren aufgrund der
Undurchschaubarkeit kaum m&#246;glich w&#228;re. Es wird dar&#252;ber hinaus angemerkt, dass beispielsweise Smart
Security Systeme relativ leicht in &#220;berwachung umschlagen k&#246;nnten und daher viele Akteure
&#8211; 750 &#8211; 
&#8211;
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
25 
nach datenschutzkonformen L&#246;sungen zur KI-basierten smarten Video&#252;berwachung suchen
w&#252;rden.
Die M&#246;glichkeit der Manipulation von Nutzerinnen und Nutzern durch KI wird auch im Hinblick
auf die eingegrenzte, personalisierte Produktauswahl und eventuelle Preismanipulation
diskutiert. Die gezielte Beeinflussung von Wissen und Meinungen behindere die freie
Entscheidungsfindung und k&#246;nne so zum Beispiel auch zur gezielten Beeinflussung von Wahlen
f&#252;hren. Es gibt sowohl die Meinung, dass eine Manipulation von KI erst recht m&#246;glich sei, wenn 
Datens&#228;tze k&#252;nstlich beschr&#228;nkt w&#252;rden aber auch die Ansicht, dass eine k&#252;nstliche
Beschr&#228;nkung zur Risikominimierung beitragen k&#246;nne.
In Bezug auf den weiteren Verlauf der KI-Entwicklung wird diskutiert, dass Ver&#228;nderungen nur
dann von Unternehmen angestrebt werden w&#252;rden, wenn dadurch wirtschaftliche Gewinne
zu erwarten seien. Weiterhin sei auch die Frage der unklaren Haftung ein hemmender Faktor 
f&#252;r technische Innovationen, da Unternehmen kein gro&#223;es Risiko eingehen wollen w&#252;rden.
Frage 6: &#8222;In welchen pers&#246;nlichen Lebensbereichen w&#252;nschen Sie sich eine 
(st&#228;rkere) Anwendung von KI?&#8220;
Die zweite Frage zum Themenfeld &#8222;Beruf und Alltag&#8220; widmet sich den pers&#246;nlichen
Lebensbereichen, in denen sich die Teilnehmenden eine generelle oder st&#228;rkere Anwendung von KI 
w&#252;nschen. Sie wurden dazu angeregt, dar&#252;ber zu diskutieren, auf welchen Gebieten KI ihnen
helfen k&#246;nnte, ihr Leben zu verbessern und gegebenenfalls konkrete Beispiele und einen
Zeitpunkt der praktischen Umsetzbarkeit daf&#252;r zu nennen. Die Teilnehmerinnen und Teilnehmer
hatten zum &#252;berwiegenden Teil positive Assoziationen in Bezug auf die zuk&#252;nftige (verst&#228;rkte)
Anwendung von KI in den Bereichen ihres pers&#246;nlichen Lebens. Unter den Teilnehmenden
gab es nur sehr wenige kritische Stimmen bez&#252;glich der vermehrten Anwendung von KI in 
pers&#246;nlichen Lebensbereichen. Interessant ist hierbei, dass zwei teilnehmende Personen, die
selbst KI bereits in ihrem pers&#246;nlichen Umfeld nutzen bzw. beruflich damit zu tun haben, die
verst&#228;rkte Anwendung zum Teil kritischer als andere Personen betrachten und daran konkrete
Bedingungen kn&#252;pfen. 
Chancen aus Sicht der Teilnehmenden
Die Teilnehmerinnen und Teilnehmer k&#246;nnen sich vor allem eine st&#228;rkere Anwendung von KI
in Form von intelligenten pers&#246;nlichen Assistenten vorstellen. Hierbei werden
beispielsweise Selbstlernprogramme, die allt&#228;gliche Unterst&#252;tzung bei der Produktsuche sowie die
Unterst&#252;tzung durch Funktionen der Muster- und Spracherkennung genannt:  
&#8222;Mensch-Maschine-Interaktionen; Ich m&#246;chte z. B. mit meinem Computer ein 
Gespr&#228;ch f&#252;hren k&#246;nnen. Selbstlernprogrammen f&#252;r Wissens- und Sprachenerwerb, 
die einen menschlichen Lehrer simulieren.&#8220; (Susan) 
&#8222;Zun&#228;chst wird schwache KI bei Problemen der Mustererkennung zum Einsatz 
kommen. Ich freue mich schon auf den Tag, an der Mustererkennung meine 
Fotodatenbanken nach Ereignissen und Fragestellungen durchsucht.&#8220; (Achim W.) 
Weiterhin k&#246;nnen sich die Teilnehmenden eine st&#228;rkere Anwendung von KI z. B. in Form von 
Sprachbots und intelligenten Lautsprechern sowie zur Terminplanung und Ger&#228;tebedienung 
gut vorstellen.
&#8211; 751 &#8211; 
&#8211;
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
26 
Ein weiteres Feld, das von den Teilnehmenden mehrfach genannt wird, ist die smarte
Verkehrssteuerung und -planung sowie das autonome Fahren; hier k&#246;nne die verst&#228;rkte
Anwendung von KI zu Verbesserungen f&#252;hren, z. B. durch optimale Verkehrsflussregelungen an 
kritischen Bereichen, eine effizientere Routenplanung, intelligente Systeme f&#252;r den
Personentransport und mehr P&#252;nktlichkeit des &#214;PNV:
&#8222;Dar&#252;ber hinaus k&#246;nnte uns KI dabei unterst&#252;tzen, effiziente, menschen- und 
umweltfreundliche Verkehrskonzepte zu entwerfen. Hinterher werden wir sagen: Na 
logisch, warum sind wir nicht fr&#252;her darauf gekommen?!&#8220; (MicialMedia) 
In engem Zusammenhang hiermit steht die Erm&#246;glichung einer Effizienzsteigerung in der
Logistikbranche durch KI, u.a. durch neue Wege des G&#252;tertransports wie beispielsweise mit 
der Nutzung von Transportdrohnen sowie die Unterst&#252;tzung durch Roboter in Lagerzentren. 
Damit einhergehen m&#252;sse generell ein Wandel der Stadtplanung hin zu &#8222;Smart Cities&#8220;.
Hierdurch k&#246;nnten durch den Einsatz von KI z. B. Umwelt- und L&#228;rmschutz verbessert werden.
F&#252;r den medizinischen Bereich w&#252;nschen sich die Teilnehmenden vor allem verbesserte
Diagnosen und Therapien. So k&#246;nnte z. B. medizinisches Personal in der Diagnostik (u.a. Bild-
Analyse von R&#246;ntgen-/MRT-/Ultraschallaufnahmen, Analyse von akustischen Aufnahmen von 
Gelenkbewegungen, Stimmanalyse) unterst&#252;tzt werden. Auch ein KI-unterst&#252;tztes
Informationssystem f&#252;r die Gesundheitsvorsorge sowie eine beschleunigte Wirkstoffentdeckung durch 
KI werden als erstrebenswert erachtet:
&#8222;Dann in der pharmazeutischen Forschung bei der Potentialanalyse von nat&#252;rlichen 
und synthetischen Wirkstoffen zur Vorauswahl zu weiteren Tests, damit k&#246;nnten 
sicherlich auch Tierversuche vermieden werden. Auch das k&#246;nnte innerhalb von 5 
Jahren verf&#252;gbar sein. Weiter in der Steuerung von Prothesen durch Impulse von 
Nerven und Gehirnstr&#246;men, das k&#246;nnte in 10 Jahren verf&#252;gbar sein.&#8220; (JeBau) 
Au&#223;erdem w&#252;nschen sich die Teilnehmenden die Unterst&#252;tzung von Pflegekr&#228;ften (z. B. durch
Pflegeroboter) bei schweren Arbeiten. 
Ein weiterer Lebensbereich, der die Teilnehmenden pers&#246;nlich betrifft, ist der Umgang mit
Verwaltungen. Es wird mehrfach eine st&#228;rkere Anwendung von KI durch Beh&#246;rden
gew&#252;nscht, um z. B. das Stellen von Antr&#228;gen und das Ausf&#252;llen von Formularen sowie der
Steuererkl&#228;rung zu erleichtern. Es sollten sowohl generell Papierantr&#228;ge, als auch der
pers&#246;nliche Zeitaufwand reduziert werden:
&#8222;In Verwaltung und Politik sehe ich die Chance, neben effizienteren und schnelleren 
Abl&#228;ufen in den &#196;mtern (KI-basierte Vorpr&#252;fung von Antr&#228;gen; KI-basierte 
Vorformulierung von Bescheiden) zu besseren &#8211; ggf. vorausschauenden &#8211; 
Entscheidungen zu kommen, z. B. indem Entwicklungen fr&#252;hzeitig erkannt und ggf. 
antizipiert werden.&#8220; (Fabian S.) 
Weitere Chancen der st&#228;rkeren Anwendung von KI sehen die Teilnehmenden im Bereich
Finanzen und Vorsorge. Hier k&#246;nnten Banken, Versicherungen und Privathaushalte Kosten 
und Zeit durch den Einsatz von KI sparen. Private Wirtschaftsverh&#228;ltnisse k&#246;nnten einfacher
kalkuliert und aufbereitet werden. So k&#246;nne besser die &#220;bersicht behalten, gespart und Geld
angelegt werden. 
Weitere Chancen der st&#228;rkeren Anwendung von KI sehen die Teilnehmerinnen und
Teilnehmer in der Optimierung des Kundenservices (z. B. bei Reisebuchungen), im Haushalt (z. B.
&#8211; 752 &#8211;
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
27 
durch Ger&#228;testeuerung), bei assistiven Technologien f&#252;r Menschen mit Behinderung
(Erm&#246;glichung von mehr Teilhabe), bei der Mediennutzung (z. B. Auswahl relevanter
Informationen) sowie bei der Gefahrenabwehr (zum Schutz von Leib und Leben). Eine teilnehmende
Person konstatiert:
&#8222;Res&#252;mierend kann ich zu dieser Frage sagen, dass ich mir in quasi allen 
Lebensbereichen eine st&#228;rkere Durchdringung von KI w&#252;nsche, f&#252;r machbar und 
wahrscheinlich halte. Man k&#246;nnte alternativ fragen: In welchen Lebensbereichen 
w&#252;rde KI keine Rolle spielen oder sollte au&#223;en vorbleiben?&#8220; (MicialMedia) 
Herausforderungen aus Sicht der Teilnehmenden 
Die Teilnehmenden benennen mehrere Herausforderungen, die mit der verst&#228;rkten
Anwendung von KI in verschiedenen Lebensbereichen auftreten k&#246;nnen. Es wird beispielsweise im 
Widerspruch zu der bereits genannten Bef&#252;rchtung, dass KI ohne Emotionalit&#228;t agiere auch 
die Herausforderung gesehen, dass KI-Systeme zu menschlich (z. B. hinsichtlich der
Erzeugung von emotionaler Bindung an sie) werden k&#246;nnten. Damit einher gehe m&#246;glicherweise die 
&#8218;Kopierbarkeit&#8216; des Menschen und eventuell seine &#220;berfl&#252;ssigkeit.
Au&#223;erdem werden (datenschutz-)rechtliche Bedenken angef&#252;hrt, wenn es um die
Anwendung bestimmter pers&#246;nlicher KI-Assistenten geht: Es k&#246;nnten mehr Daten als erforderlich
von privatwirtschaftlichen Unternehmen f&#252;r kommerzielle Zwecke verarbeitet werden und zu
tiefe Einblicke in die Privatsph&#228;re der Nutzerinnen und Nutzer erfolgen. Eine besonders
kritische Stimme sagt:  
&#8222;Ich w&#252;nsche mir KI m&#246;glichst nirgendwo. Ich glaube nicht, dass sie in irgendwelchen 
Bereichen mein Leben verbessern wird &#8211; im Gegenteil. Da KI sich nicht verhindern 
l&#228;sst, hoffe ich, die Einf&#252;hrung verz&#246;gert sich noch so lange wie m&#246;glich.&#8220; (User1) 
Handlungsbedarfe und Rahmenbedingungen aus Sicht der Teilnehmenden
&#220;berwiegend bewerten die Teilnehmerinnen und Teilnehmer den verst&#228;rkten Einsatz von KI
in Bereichen des pers&#246;nlichen Lebens als erstrebenswert, kn&#252;pfen jedoch auch Bedingungen
daran: So sollten bei verst&#228;rkter Anwendung die Ziele immer ethischen und moralischen
Standards unterliegen sowie nicht-kommerzieller Natur sein: &#8222;All diese Ziele sind nicht-
kommerziell, sondern positiv, ethisch und vern&#252;nftig.&#8220; (Conrad S. C.) 
Weiterhin seien verbesserte Fehlerprognosen (Predictive Analytics, &#252;bersetzt die
Vorhersage zuk&#252;nftiger Ereignisse) notwendig, um den Betrieb z. B. von Robotern, die in Fabriken 
oder Lagerhallen unterst&#252;tzende Aufgaben ausf&#252;hren, zu optimieren. Um den
missbr&#228;uchlichen Umgang mit Daten von Nutzerinnen und Nutzern zu verhindern, seien zudem st&#228;rkere
Kontrolle und Regeln f&#252;r den Einsatz von KI durch privatwirtschaftliche Unternehmen n&#246;tig.
F&#252;r den medizinischen Bereich wird von den Teilnehmenden darauf hingewiesen, dass KI 
zwar unterst&#252;tzend als beratende Instanz eingesetzt werden k&#246;nne, jedoch nicht &#196;rztinnen 
und &#196;rzte ersetzen solle.
Frage 7: &#8222;Wie beurteilen Sie es, dass Informationen im Internet auf die 
nutzende Person zugeschnitten werden?&#8220; 
Die dritte Diskussionsfrage in diesem Themenfeld zielt auf den pers&#246;nlichen
Informationszuschnitt im Internet mittels KI-gest&#252;tzter Algorithmen. Die Teilnehmerinnen und Teilnehmer wur-
&#8211; 753 &#8211; 
&#8211;
&#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
28 
den dazu angeregt, &#252;ber die Vor- und Nachteile der Erstellung und Anpassung von
Informationen bei der Nutzung des Internets anhand pers&#246;nlicher Profile zu diskutieren. Insgesamt
zeigen die Kommentare, dass die Teilnehmerinnen und Teilnehmer eher Nach- als Vorteile
hinsichtlich des Zuschnitts von Informationen auf die Nutzerinnen und Nutzer im Internet
ausmachen, wie z. B. die Bildung von Filterblasen und Echokammern, welche bestimmte Meinungen 
verst&#228;rken und den gesellschaftlichen Diskurs behindern k&#246;nnten. Die zum Teil negative
Einstellung gegen&#252;ber dem Informationszuschnitt scheint bedingt durch das gef&#252;hlt derzeit zu 
wenig regulierte Umfeld: Sie w&#252;nschen sich u.a. mehr Datenschutz und Sicherheit, mehr
Transparenz sowie die M&#246;glichkeit, die Kriterien f&#252;r den Informationszuschnitt auf
Internetnutzerinnen und -nutzer selbst aktiv beeinflussen zu k&#246;nnen. Vorteile sehen die Teilnehmenden
vor allem in der gezielteren pers&#246;nlichen Information durch die Verwendung von Algorithmen.
Chancen und Herausforderungen aus Sicht der Teilnehmenden
Am st&#228;rksten positiv hinsichtlich des Informationszuschnitts im Internet bewerten die
Teilnehmerinnen und Teilnehmer, dass dieser zu einer gezielteren individuellen Information
beitr&#228;gt und damit ein f&#252;r das Individuum un&#252;berschaubarer und nicht bearbeitbarer
Informations&#252;berfluss verhindert wird:
&#8222;Zum einen ist es nat&#252;rlich bequem und angenehm, wenn eine Automatik &#8218;r&#228;t&#8216;, 
welche Musik mir gefallen k&#246;nnte, welche B&#252;cher ich lesenswert finde und welche 
Nachrichten mich interessieren.&#8220; (Harald) 
Auch die Erleichterung des individuellen Verstehens wird als positiver Faktor des
Informationszuschnitts genannt.
Gleichzeitig sehen die Teilnehmenden hierin auch den gr&#246;&#223;ten Nachteil, denn diese
automatische, f&#252;r das Individuum nicht nachvollziehbare Informationsauswahl schr&#228;nke den
pers&#246;nlichen Horizont ein und k&#246;nne die Entwicklung von Filterblasen und Echokammern
bef&#246;rdern. In diesen w&#252;rden nur homogene Informationen wiedergegeben werden und von der
eigenen Sichtweise abweichende Meinungen fast nicht vorkommen:
&#8222;Pers&#246;nlich zugeschnittene Informationen sind Fluch und Segen. Einerseits m&#246;chte 
ich meine pers&#246;nlichen Belange ber&#252;cksichtig wissen und nicht mit &#8218;Ballast&#8216; bel&#228;stigt 
werden, andererseits m&#246;chte ich mich nicht in eine Echokammer einsperren lassen.&#8220; 
(der Markus) 
Auch eine &#8218;Gleichmacherei&#8216; wurde in diesem Zusammenhang als Herausforderung benannt: 
Menschen w&#252;rden durch die Filteranwendung quasi zu Kategorien degradiert und ihnen w&#252;rde 
die Erweiterung des pers&#246;nlichen Horizonts z. B. durch die steigende Anwendung von
Apps f&#252;r allt&#228;gliche T&#228;tigkeiten (wie z. B. Routenplanung, Filmauswahl) somit zunehmend 
schwerfallen, da ihnen vieles im Sinne &#8218;ihrer Kategorie&#8216; vorgegeben werde.
Die Verst&#228;rkung der jeweiligen Weltbilder, die beg&#252;nstigte Verbreitung von Fake-News und
der dadurch immer schwieriger werdende (gesamt-)gesellschaftliche Diskurs durch die
Abgrenzung sozialer Gruppen voneinander werden von den Teilnehmenden als kritische
Entwicklungen benannt. In der Verzerrung von Nachrichten machen die Teilnehmenden auch
ein demokratiegef&#228;hrdendes Potenzial aus:
&#8222;Auch ohne KI haben wir schon das Problem der Filterblasen, was sich mit KI 
sicherlich vergr&#246;&#223;ert. Den Zuschnitt von Nachrichten halte ich daher f&#252;r besonders 
kritisch, dem m&#252;sste aktiv entgegengewirkt werden, ich halte das f&#252;r eine
&#8211; 754 &#8211;
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
29 
Gef&#228;hrdung unserer Demokratie und unserer offenen, pluralistischen Gesellschaft.&#8220; 
(JeBau) 
Eine teilnehmende Person &#228;u&#223;erte sich hingegen entgegengesetzt: Dadurch, dass nicht alle 
Nutzerinnen und Nutzer die gleichen Informationen angezeigt bekommen w&#252;rden, h&#228;tten die
g&#228;ngigen Suchmaschinen eine geringere Meinungsmacht. Als weitere positive Auswirkungen 
des personenabh&#228;ngigen Informationszuschnitts im Internet werden Zeitersparnis,
Praktikabilit&#228;t, die Optimierung personenbezogener Dienstleistungen sowie die M&#246;glichkeit 
z. B. Google f&#252;r berufliche Zwecke als pers&#246;nlichen KI-Assistenten zu nutzen, genannt.
Als weitere negative Auswirkungen des pers&#246;nlichen Informationszuschnitts werden ein
generelles Missfallen an personalisierten Inhalten (weil sie z. B. wenig n&#252;tzlich sind), die
eventuelle Beeinflussung des Konsumverhaltens der Nutzerinnen und Nutzer sowie die damit 
verbundene Profitmaximierung von Unternehmen als Zweck aufgez&#228;hlt. Ebenfalls kritisch wird 
gesehen, dass es nicht (einfach) m&#246;glich sei, sich gegen den Informationszuschnitt zu wehren,
da die pers&#246;nliche Identit&#228;t im Internet leicht (z. B. anhand der IP Adresse) verfolgt und genutzt
werden k&#246;nne. Besonders stark werden neben der Bildung von Filterblasen und
Echokammern die Themen der missbr&#228;uchlichen Datennutzung und des mangelnden
Datenschutzes kritisiert:
&#8222;Im Internet werden wir inzwischen von einer Tracking-Walze &#252;berrollt. Wer sich die 
M&#252;he macht und die Erl&#228;uterungen zu Cookies liest, ist ziemlich gepl&#228;ttet, wie viele 
Tracking- und Analyse-Firmen bei jeder neuen Seite bem&#252;ht sind, mir das optimale 
pers&#246;nlich zugeschnittene Internet-Erlebnis zu erm&#246;glichen. Die Spitze ist die 
&#8218;Datenschutzerkl&#228;rung&#8216; von Google. Und das ist nur das, was man an der Oberfl&#228;che 
sieht.&#8220; (Hajo W.) 
Es sei oft unklar, wie mit den erhobenen pers&#246;nlichen Daten umgegangen werde, wann diese 
gel&#246;scht und wie der datenschutzrechtlich korrekte Umgang mit Nutzer(innen)daten gepr&#252;ft 
werde. Der potenzielle Datenverkauf und -missbrauch wird von mehreren Teilnehmerinnen
und Teilnehmern als problematisch betrachtet:
&#8222;Die Vergangenheit hat mehr als deutlich gezeigt, dass Firmen keinerlei Interesse 
am Schutz der Privatsph&#228;re der Menschen und der von ihnen erhobenen Daten 
haben.&#8220; (topas) 
Handlungsbedarfe und Rahmenbedingungen aus Sicht der Teilnehmenden 
Als Bedingung f&#252;r die Anwendung von Filtern und dem damit verbundenen
personenabh&#228;ngigen Informationszuschnitt im Internet nennen die Teilnehmerinnen und Teilnehmer an erster
Stelle die Transparenz &#252;ber die Verwendung von Filtern und den zugrunde liegenden,
personenbasierten Kriterien. Dies sei auch eine Bedingung f&#252;r die Bearbeitbarkeit der Filter
durch Nutzerinnen und Nutzer sowie deren Abschaltbarkeit, die ebenfalls von den
Teilnehmenden gefordert wird:
&#8222;Ich m&#246;chte angezeigt bekommen, wenn Informationen gefiltert wurden und ich m&#246;chte 
sehen k&#246;nnen, auf welchem pers&#246;nlichen Profil die Filterung/Hervorhebung basiert und es 
ggf. korrigieren oder l&#246;schen k&#246;nnen.&#8220; (Moritz) 
Als Antwort auf den pers&#246;nlichen Informationszuschnitt wurde die Einrichtung einer
zuschaltbaren Funktion im Sinne eines &#8222;Advocatus Diaboli&#8220; als Gegenposition zur eigenen Filterblase 
und zur Erweiterung der filterbedingt eingeschr&#228;nkten Informationsquellen vorgeschlagen,
diskutiert und positiv von den Teilnehmenden bewertet.
&#8211; 755 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
30 
Weiterhin nennen die Teilnehmenden die Sicherstellung des Datenschutzes der
Nutzerinnen und Nutzer als Bedingung. Der Datenverkauf und -missbrauch sollte verhindert werden.
Die Datensicherheit und die Wahrung ethischer Standards d&#252;rften jedoch nicht die technische
Innovationsf&#228;higkeit unterbinden, so eine Forderung.
Au&#223;erdem wurden die freie Wahl des Internet-Dienstleisters sowie die Verf&#252;gbarkeit von
frei zug&#228;nglichen Tools zur &#8222;digitalen Selbstverteidigung&#8220; (z. B. zur Unterbindung des 
Informationszuschnitts) als Voraussetzung genannt. Auch ein automatischer Wechsel der
IP-Adressen durch die Provider wurde als L&#246;sungsansatz angesprochen: So k&#246;nne dem 
Problem entgegnet werden, dass zwar Cookies selbstst&#228;ndig gel&#246;scht werden k&#246;nnten,
jedoch ein Zuschnitt auch aufgrund der IP-Adresse erfolge, welche daher von den Providern
h&#228;ufiger gewechselt werden solle.
Die Teilnehmenden sprachen sich zudem f&#252;r die F&#246;rderung der Wissens- und
Kompetenzvermittlung aus, damit B&#252;rgerinnen und B&#252;rger die Funktionsweisen und Zwecke von
Algorithmen besser verstehen, sicherer im Umgang mit (Falsch-)Informationen werden und
Vertrauen in die KI-Technologie aufbauen k&#246;nnten. Zum Informationszuschnitt wurde hierbei
angemerkt:
&#8222;Ist die logische Konsequenz voranschreitender Digitalisierung. Dementsprechend 
sollte aber der Umgang mit Daten in Schulen und Universit&#228;ten st&#228;rker als bisher 
thematisiert werden und notfalls auch zum Schutz der Verbraucher reguliert werden.&#8220; 
(KWahl) 
Frage 8: &#8222;Welche Vor- &amp; Nachteile sehen Sie derzeit im Zusammenhang mit 
dem Einsatz von KI im privaten und beruflichen Umfeld?&#8220;
Im Rahmen dieser Frage sollten die Teilnehmenden diskutieren, wie sich ihrer Meinung nach
KI bereits heute in verschiedenen Bereichen ihres beruflichen oder privaten Lebens auswirkt 
und wie sie dies bewerten. Hier sehen die Teilnehmerinnen und Teilnehmer insgesamt mehr
Vorteile als Nachteile, wobei die Vorteile etwas st&#228;rker im beruflichen als im privaten
Umfeld gesehen werden, w&#228;hrend die Nachteile deutlich h&#228;ufiger im privaten als im
beruflichen Umfeld gesehen werden. Die Grenzen zwischen den Bereichen beruflich und privat sind 
jedoch nicht immer trennscharf: So werden z. B. Felder adressiert, in denen Personen in
beruflicher Hinsicht von dem Einsatz von KI betroffen sind und die gleichzeitig in das Private von 
z. B. Kundinnen und Kunden, Patientinnen und Patienten etc. hineinwirken.
Vorteile und Nachteile im beruflichen Umfeld aus Sicht der Teilnehmenden
Die Teilnehmerinnen und Teilnehmer sehen die Vorteile der aktuellen Nutzung von KI im
beruflichen Umfeld vor allem in der Optimierung der medizinischen Forschung und
Versorgung. KI k&#246;nne hier vor allem eine Unterst&#252;tzung bei der Diagnosestellung und der
Konzeption von Therapiemodellen leisten. In diesem Zusammenhang wird auch angef&#252;hrt, dass KI 
die Dokumentation &#252;bernehmen k&#246;nne, wodurch dem medizinischen Personal mehr Zeit f&#252;r
die Behandlung bleibe und dadurch eine Stressminimierung stattfinden k&#246;nne.
Insgesamt werden auch in anderen beruflichen Feldern durch den Einsatz von KI positive
Effekte gesehen, z. B. indem monotone und gef&#228;hrliche T&#228;tigkeiten von KI &#252;bernommen werden:
&#8222;Alle sich wiederholende T&#228;tigkeiten werden in den n&#228;chsten 5 bis 10 Jahren - auch 
durch KI  automatisiert werden. [&#8230;] der Kern meiner diesbez&#252;glichen Aussage ist
&#8211; 756 &#8211; 
-
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
31 
die, dass jeder Mensch diese sich wiederholende T&#228;tigkeiten in seinem Job, in 
Abstimmung mit seinem Vorgesetzten immer weniger aus&#252;bt und stattdessen immer 
mehr &#8218;menschliche&#8216;, auf Kreativit&#228;t und Empathie basierende T&#228;tigkeiten 
wahrnimmt.&#8220; (Peter S.) 
Vorteile werden auch durch gesteigerte Effizienz- und Effektivit&#228;t der Arbeit erwartet: KI
k&#246;nne Kosten und Zeit sparen, B&#252;rokratie abbauen und Sachverhalte generell vereinfachen
(z. B. durch die Erstellung von Modellen, die Nutzung gro&#223;er Datenbanken oder die
&#220;bernahme von Steuerungsfunktionen). Auch eine Qualit&#228;tssteigerung aufgrund des Einsatzes von 
KI sei m&#246;glich, wenn beispielsweise Dokumentationsaufgaben standardisiert werden. Die
Vorteile von KI seien jedoch nur nutzbar, wenn die Unternehmen bereit seien, ihre Strukturen zu
modernisieren. Damit einher gingen dann u.a. auch positive Effekte wie die Verschlankung 
von Prozessen und die Steigerung der Attraktivit&#228;t durch einen h&#246;heren Digitalisierungsgrad. 
Schlussendlich k&#246;nne die zuk&#252;nftige &#220;bernahme vieler Arbeiten durch KI die Verwirklichung
eines bedingungslosen Grundeinkommens erm&#246;glichen. 
Auf der anderen Seite wird aber auch angemerkt, dass der Einsatz von KI f&#252;r bestimmte
T&#228;tigkeiten auch zum Verlust von Arbeitspl&#228;tzen f&#252;hren k&#246;nne und somit negative Auswirkungen
habe, wenn dieser Arbeitsplatzverlust nicht begleitet und fr&#252;hzeitig f&#252;r berufliche
Alternativen gesorgt wird. 
Im Einsatz von KI im beruflichen Umfeld sehen die Teilnehmenden zum Teil auch die
M&#246;glichkeit f&#252;r eine chancengerechtere bzw. fairere Entscheidungsfindung. So k&#246;nnten
systematische oder auch unbewusste oder ungewollte Verzerrungen bei der Entscheidungsfindung
durch den Einsatz von KI unterbunden werden. Gleichzeitig m&#252;sse aber sichergestellt werden,
dass durch Design, Qualit&#228;t der Datens&#228;tze und Einsatzweise der automatisierten Anwendung
keine Formen struktureller Diskriminierung reproduziert w&#252;rden. Auf der anderen Seite gibt es
Teilnehmende, die sich kritisch gegen&#252;ber Auswahlverfahren von Bewerberinnen und
Bewerbern sowie in Gehaltsfestlegungen mithilfe des Einsatzes von KI &#228;u&#223;ern. Als
problematisch wird hierbei vor allem empfunden, wenn die KI zur Black Box werde und f&#252;r die
Bewerberin oder den Bewerber bzw. die Mitarbeitenden die Entscheidungsfindung &#252;ber
Einstellung/Absage oder Gehaltsbestimmung intransparent und nicht mehr nachvollziehbar sei: 
&#8222;Diese Frage ist heute schon kaum mehr zu beantworten, denn KI-Systeme sind 
wenig transparent. Welcher Arbeitgeber macht beispielsweise sein 
Auswahlverfahren f&#252;r potenzielle Mitarbeiter transparent? Welcher Kandidat wei&#223; 
&#252;berhaupt, dass er auf Grund einer KI-Entscheidung ausgew&#228;hlt oder abgelehnt 
wurde?&#8220; (der Markus) 
Weitere Vorteile im beruflichen Umfeld sehen die Teilnehmenden bei der Auswertung gro&#223;er
Datenmengen und der Steigerung der Datenqualit&#228;t durch die automatisierte Erkennung von
Anomalien. So k&#246;nnten z. B. Abl&#228;ufe im Kundenservice als auch in weiteren
Unternehmensbereichen u.a. durch verbesserte Spracherkennung qualitativ und zeitlich optimiert werden.
Weiterhin k&#246;nnte KI in der Landwirtschaft als auch in der Produktion (z. B. durch das
schnelle Identifizieren und Abstellen von Fehlern) positive Effekte erzielen. Als Risiko der
zunehmenden Nutzung von KI im beruflichen Umfeld wird angesehen, dass sich Personen/
Unternehmen/Gesellschaft zunehmend aus ihrer Verantwortung zur&#252;ckziehen k&#246;nnten,
insbesondere wenn Haftungsfragen juristisch nicht ausreichend gekl&#228;rt werden.
&#8211; 757 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
32 
Vorteile und Nachteile im privaten Umfeld aus Sicht der Teilnehmenden
Im privaten Umfeld sehen die Teilnehmerinnen und Teilnehmer vor allem die M&#246;glichkeiten, 
KI als pers&#246;nliche Assistenz bei T&#228;tigkeiten des Alltags zu nutzen, als Vorteil. KI k&#246;nne im 
Haushalt helfen und Sprach- und &#220;bersetzungsassistenten, Apps sowie die Vorsortierung von
Informationen und individualisierte Vorschl&#228;ge w&#252;rden das Leben erleichtern. KI k&#246;nne im
privaten Umfeld &#8222;Support f&#252;r den Menschen&#8220; (KWahl) leisten:
&#8222;Vorteile: [&#8230;] pers&#246;nlicher Assistent (Management von t&#228;glichen Aufgaben, 
Erleichterung des Alltags, Planung von Urlaubsreise, bessere Empfehlung/Beratung 
bei theoretisch allem)&#8220; (Trichomonas) 
Als sehr problematisch bewerten die Teilnehmenden jedoch die damit zusammenh&#228;ngende
und von ihnen z.T. als massiv empfundene Sammlung von Daten und den damit
einhergehenden mangelnden Schutz der Daten: 
&#8222;Google, Facebook und Co stellen Datenkraken dar. Wahrscheinlich wird das 
weltweit kaum so intensiv kritisiert wie im  mehr oder minder  datenbewussten 
Deutschland. Derartige Anbieter und Datenaggregatoren sind in der t&#228;glichen 
Anwendung in so vielen F&#228;llen hilfreich und oftmals heute kaum noch wegzudenken. 
Gleichwohl laufen im Hintergrund immer wieder Missbrauchsszenarien und m&#246;gliche 
Datenmissbr&#228;uche.&#8220; (MicialMedia) 
Als kritisch wird in diesem Zusammenhang au&#223;erdem betrachtet, dass Nutzerinnen und
Nutzer durch die zunehmende Auslagerung von T&#228;tigkeiten vermehrt hinsichtlich ihrer
Datensparsamkeit desensibilisiert w&#252;rden, dass Systeme nur unzureichend vor Hackerangriffen
gesch&#252;tzt seien und dass Unternehmen oft den wirtschaftlichen Nutzen &#252;ber die Bed&#252;rfnisse der 
Nutzenden stellten. Das zunehmende Verlassen auf die KI k&#246;nne neben dem Ausblenden 
bestimmter Dinge zudem auch zum Verlernen bestimmter F&#228;higkeiten f&#252;hren. Auch ein
Missbrauch der Daten, z. B. im Hinblick auf das Stehlen von Identit&#228;ten, oder gar die
Anwendung von KI als Waffe seien denkbar. F&#246;rderlich f&#252;r solche Missbr&#228;uche sei die derzeitige
Intransparenz von KI-Systemen.
In Bezug auf die Assistenzfunktionen von KI betonen die Teilnehmenden auch die positiven
Auswirkungen von KI-gest&#252;tzten assistiven Technologien auf die pers&#246;nlichen
Lebenssituationen von Menschen mit Behinderung. KI k&#246;nne diesen mehr Selbstst&#228;ndigkeit im Alltag 
erm&#246;glichen: 
&#8222;Die Vorteile von KI beim Einsatz von digitalen und assistiven Hilfsmitteln f&#252;r 
Menschen mit Behinderung k&#246;nnen sein, dass die Hilfsmittel sich besser individuell 
auf den Menschen einstellen k&#246;nnen. Das erleichtert die t&#228;gliche Handhabung und 
die Einrichtung. Durch digitale und assistive Hilfsmittel erlangen Menschen mit 
Behinderung mehr Selbst&#228;ndigkeit und Selbstwirksamkeit und k&#246;nnen insgesamt 
mehr Teilhabe erlangen.&#8220; (Caritas Behindertenhilfe und Psychiatrie e. V.) 
&#8222;KI hilft sehbehinderten Menschen, visuelle Inhalte, wie z. B. Fotos und ihre 
physische Umgebung, zu interpretieren und zu verstehen. Diese Technologie 
er&#246;ffnet ihnen neue M&#246;glichkeiten, sich in der Welt zurechtzufinden und gibt ihnen 
mehr Unabh&#228;ngigkeit und eine gr&#246;&#223;ere F&#228;higkeit, mit ihrem Umfeld in Kontakt zu 
treten.&#8220; (BSA The Software Alliance)
-  -
&#8211; 758 &#8211;
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
33 
Dar&#252;ber hinaus sehen die Teilnehmenden weitere pers&#246;nliche Vorteile von KI in der
Optimierung des Stra&#223;enverkehrs (z. B. durch dynamische Ampelsysteme und standortgenaue
Notfalldurchsagen) sowie beim autonomen Fahren, welches zu unabh&#228;ngiger Mobilit&#228;t z. B. im
h&#246;heren Alter f&#252;hren k&#246;nne. 
KI k&#246;nne au&#223;erdem zu mehr Sicherheit f&#252;r die Bev&#246;lkerung u.a. durch Verfahren der
Gesichtserkennung beitragen wenngleich hier ein Verlust an Privatsph&#228;re kritisiert wird. KI biete
zwar M&#246;glichkeiten der Verbesserung der pers&#246;nlichen Sicherheit, gleichwohl entstehe immer
auch ein Sicherheitsrisiko aufgrund technischer Fehler und Defekte, z. B. an Software oder 
Sensoren beim autonomen Fahren oder beim Agieren von Robotern in der medizinischen
Versorgung.
3.3 Themenfeld &#8222;Datennutzung und Datenschutz&#8220; 
KI basiert auf Daten, die analysiert werden und als Entscheidungsgrundlage dienen. Weil KI-
Anwendungen auf verf&#252;gbare Daten angewiesen sind, ist es von zentraler Bedeutung, wie
Daten geteilt und zugleich gesch&#252;tzt werden k&#246;nnen. Daten sind unterschiedlich sensibel, es
existieren diverse Anwendungsbereiche, die mit unterschiedlichen Risiken einhergehen und
verschiedene Akteure, die Daten verarbeiten bzw. in Zukunft verarbeiten k&#246;nnten.
Zustimmung oder Ablehnung der Datennutzung und spezifische Anforderungen an den Datenschutz
h&#228;ngen vom jeweiligen Anwendungsfall ab. Deshalb gibt es keine Einheitsl&#246;sung, nach der
sich Datennutzung und Datenschutz organisieren lie&#223;en. Aus diesem Grund wurden die
Teilnehmenden gefragt, f&#252;r welche Anwendungsbereiche und mit welchen Akteuren sie ihre Daten
teilen w&#252;rden sowie welche Handlungsbedarfe sie f&#252;r bestehende Regulierungen von Daten
f&#252;r KI sehen.
In den Antworten zu den drei Fragen in diesem Themenbereich fanden sich besonders viele 
&#220;berschneidungen, sodass die Ergebnisse zu Akteuren, Anwendungsbereichen und
Regulierungsbedarfen fragen&#252;bergreifend dargestellt werden. 
Frage 9 und 10: &#8222;Mit wem sind Sie bereit, Ihre Daten zu teilen, und warum 
(jetzt und in Zukunft)?&#8220; und &#8222;F&#252;r welche KI-Anwendungsbereiche w&#228;ren Sie 
bereit, Ihre Daten zu teilen?&#8220;
Akteure
Ob Daten mit einem Akteur geteilt werden, h&#228;ngt davon ab, welche Daten in welcher Form
geteilt werden sollen. So sollen beispielsweise mit Staat und Arbeitgebern Daten geteilt
werden, die notwendig sind f&#252;r Verwaltungs- und Abrechnungszwecke, dar&#252;ber hinausgehend ist
die Bereitschaft jedoch gering: 
&#8222;Meinem Arbeitgeber gebe ich nur die Daten, die ich ihm unbedingt geben muss.&#8220; 
(user1) 
Ein wichtiges Kriterium ist f&#252;r viele Teilnehmende die Tatsache, ob die Akteure die Daten zur
Generierung von Gewinnen oder f&#252;r gemeinn&#252;tzige Zwecke verwenden. Die Bereitschaft,
Daten zu teilen, ist vor allem bei solchen Akteuren vorhanden, die nachvollziehbare
gesamtgesellschaftliche Interessen verfolgen, wie z. B. gemeinn&#252;tzige Organisationen
(die z. B. freies Wissen bereitstellen) oder Akteure aus dem Gesundheitswesen, die nicht
nach Profitmaximierung streben. Auf wirtschaftliche Akteure bezogen &#228;u&#223;ern sich einige
Teilnehmende kritisch. Monet&#228;r motiviertes Datensammeln wird von einigen Teilnehmenden
&#8211; 759 &#8211; 
&#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
34 
abgelehnt. Ein Teilnehmender w&#252;rde seine Daten &#8222;[m]it Organisationen [teilen], die daf&#252;r 
sorgen, dass Daten keinen monet&#228;ren Wert erhalten, und dass das Wissen, das aus den 
Daten generiert wird, &#246;ffentliches Wissen bleibt und der Gesellschaft geh&#246;rt und nicht 
privatisiert und durch geistiges Eigentum gesch&#252;tzt wird&#8220; (Bart de W.). Es finden sich aber
auch Teilnehmende, die ihre Daten bereitwilliger teilen w&#252;rden, da sie ihre Daten z. B. schon
u.a. mit Facebook und Google teilten und der Verwendung der Daten f&#252;r monet&#228;re Zwecke
nicht kritisch gegen&#252;ber stehen.
Datentreuh&#228;nder als neutrale und vertrauensw&#252;rdige Institutionen k&#246;nnten das Teilen von 
Daten erleichtern: 
&#8222;Ein Datentreuh&#228;nder [&#8230;] sollte die Funktion haben, die ihm anvertrauten Daten in 
durchsichtiger und nachvollziehbarer Weise (Transparenz) uneigenn&#252;tzig einer 
gemeinwohlorientierten Nutzung (Neutralit&#228;t) zuzuf&#252;hren.&#8220; (Michael B. S. und David 
W.) 
Anwendungsbereiche
Die Teilnehmenden nennen verschiedene Anwendungsbereiche, f&#252;r die sie bereit w&#228;ren, 
Daten zu teilen, wie beispielsweise Forschung (hier insbesondere medizinische Forschung),
Verkehr und Mobilit&#228;t, Lern-Anwendungen, Kommunikation im Allgemeinen und Funktionalit&#228;t 
von Dienstleistungen, die auf Daten basieren.
Die Teilnehmenden teilen ihre Daten bereits zu verschiedenen Zwecken oder w&#228;ren bereit,
dies zu tun. Besonders f&#252;r medizinische Zwecke und Forschungszwecke w&#252;rden mehrere
Teilnehmende einer Nutzung ihrer Daten zustimmen und erhoffen sich davon eine bessere
medizinische Versorgung oder eine Unterst&#252;tzung bei der medizinischen Versorgung:
&#8222;F&#252;r die beste Gesundheit werden wir ein St&#252;ck unserer Privatsph&#228;re (im bisherigen 
Sinne) opfern m&#252;ssen.&#8220; (MicialMedia) 
&#8222;Ich w&#252;nsche mir beispielsweise eine elektronische Patientenakte, die mich 
automatisch an Termine, Medikamenteneinnahme und notwendige 
Vorsorgeuntersuchungen erinnert.&#8220; (KWahl) 
Im medizinischen Kontext wird auch darauf hingewiesen, dass pseudonymisierte (statt
anonymisierte) Daten f&#252;r Patientinnen und Patienten den Vorteil b&#246;ten, dass sie von
Forschungsergebnissen individuell profitieren k&#246;nnten, weil man sie kontaktieren k&#246;nne.
Insgesamt w&#228;ren viele Teilnehmenden au&#223;erdem bereit, ihre Daten f&#252;r gemeinn&#252;tzige
Zwecke zu teilen. Beispielsweise wird der &#8222;Aufbau von Knowhow-Datenbanken etc., aber immer 
anonymisiert und nicht auf Profit-Machen ausgelegt&#8220; (Susan) vorgeschlagen. Teilweise
werden diese gemeinn&#252;tzige Zwecke in Abgrenzung zu wirtschaftlichen Zwecken verstanden. Die
Bandbreite an gemeinn&#252;tzigen Zwecken umfasst (neben der angef&#252;hrten Forschung und der
medizinischen Verwendung) auch Verkehrsoptimierungen und Volksz&#228;hlungen.
An einigen Stellen nennen die Teilnehmenden der Online-Beteiligung auch Bereiche, f&#252;r die
sie die Anwendung von KI-Systemen eindeutig ablehnen w&#252;rden. Beispielsweise wird hier
von zwei Teilnehmenden die Gesichtserkennung genannt:
&#8222;Gesichtserkennung im &#246;ffentlichen Raum ohne Ausweichm&#246;glichkeiten f&#252;r 
B&#252;rger*innen ist vor allem ein eklatanter Eingriff in das Grundrecht der 
informationellen Selbstbestimmung, der nicht dem Grundsatz der
&#8211; 760 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
35 
Verh&#228;ltnism&#228;&#223;igkeit angesichts der niedrigen Gef&#228;hrdungslage entspricht.&#8220; (Digitale 
Freiheit) 
&#220;berwachung im Allgemeinen berge weitergehende Risiken f&#252;r die Gesellschaft. Sie k&#246;nnte
zum Gef&#252;hl st&#228;ndiger Beobachtung und einer vorwegnehmenden Selbstbeschr&#228;nkung
f&#252;hren, weil sich B&#252;rgerinnen und B&#252;rger den KI-Anwendungen anpassen w&#252;rden, um etwaige
negative Bewertungen durch KI-Anwendungen schon von Vornherein zu verhindern:
&#8222;Viel zu selten werden zudem die gesamtgesellschaftlichen Auswirkungen
nichtnachvollziehbarer Entscheidungsfindung in kritischen Bereichen betrachtet. Wer 
nicht wei&#223;, in welchem Umfang seine Daten gesammelt, gespeichert und aufbereitet 
werden, wird automatisch sein Verhalten &#228;ndern. Selbst wenn also s&#228;mtliche 
Fehlfunktionen der technischen Seite behoben wurden, wird es immer noch zur 
Einschr&#228;nkung von Freiheitsrechten und der individuellen Entfaltung kommen.&#8220; 
(Georg W.) 
Die Verwendung von Daten zu Werbezwecken oder die Verwendung von Mobilit&#228;tsdaten
werden ebenso als kritisch betrachtet, wobei sich hier ein heterogenes Bild zeigt, da das Teilen
von Daten im Bereich Mobilit&#228;t beispielsweise zur Optimierung des Verkehrsflusses von
anderen explizit positiv bewertet wird. 
Herausforderungen und Handlungsbedarfe f&#252;r das Teilen von Daten
Die Teilnehmenden nennen ebenfalls Gr&#252;nde daf&#252;r, das Teilen von Daten abzulehnen: 
Eine fehlende M&#246;glichkeit der Einwilligung/Ablehnung, mangelndes Vertrauen in die
datensammelnden Akteure und Datensicherheit. Es m&#252;ssten in der Praxis bereits pers&#246;nliche Daten
preisgegeben werden, ohne dass es daf&#252;r eine ausreichende Steuerungsm&#246;glichkeit g&#228;be.
So kritisiert eine teilnehmende Person: 
&#8222;Da man bereits unfreiwillig massenhaft pers&#246;nliche Daten preisgeben muss, werde 
ich freiwillig keine Daten dar&#252;ber hinaus preisgeben.&#8220; (Michael G.) 
Einige Teilnehmende sehen im potenziellen Missbrauch gesammelter Daten durch
Unternehmen und staatliche Stellen ein Risiko. Damit einhergehend warnen einige
Teilnehmende vor einer &#252;berm&#228;&#223;igen Privatisierung von Daten.
Eine Reihe an Teilnehmerinnen und Teilnehmern formulieren daher Bedingungen f&#252;r die
Bereitstellung von Daten. Insbesondere die Gew&#228;hrleistung von Datensicherheit sowie die
Kontrolle &#252;ber die Verwendung der eigenen Daten wurden als wichtige Punkte genannt,
damit die Teilnehmenden einer Verwendung ihrer Daten zustimmen w&#252;rden. Die derzeitige
Umsetzung des Datenschutzes wird von einigen Teilnehmenden kritisiert. Der Datenschutz
sei f&#252;r Endnutzer und Endnutzerinnen au&#223;erdem zu umst&#228;ndlich in der praktischen
Anwendung.
&#8222;Die Voraussetzung w&#228;re, dass die Daten sicher sind. Aber das ist theoretisch. Je 
mehr Daten an irgendeiner Stelle gesammelt sind, desto lukrativer wird der Einbruch 
und dann kommt es auch irgendwann zum Datenleck. Es vergeht kein Tag, an dem 
nicht jemandem Daten gestohlen werden, meistens gro&#223;e Datenmengen.&#8220; (User1) 
&#8222;Die sogenannten &#8218;Datenschutzerkl&#228;rungen&#8216; z. B. auf Webseiten sind eine 
Zumutung, wer liest sich schon bei jeder neuen Seite die elendig langen Texte durch 
bzw. hangelt sich durch die Men&#252;s, um Einstellungen vorzunehmen? Das muss 
&#252;bersichtlicher und einfacher werden. Zur Zeit habe ich nicht den Eindruck, wirklich
&#8211; 761 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
36 
Kontrolle dar&#252;ber zu haben, wer meine Daten bekommt und was damit genau 
geschieht.&#8220; (Susan) 
&#8222;Ich bin bereit, die meisten Daten zu teilen aber nur solange ich die Kontrolle dar&#252;ber 
habe.  Der bereits existierende Kontrollverlust ist jedoch etwas, was mich zu extremer 
Datensparsamkeit zwingt.&#8220; (Corwyn) 
&#8222;Ich m&#246;chte mitbestimmen k&#246;nnen, wer etwas &#252;ber mich als Person wei&#223;, da darauf 
aufbauend Annahmen &#252;ber mich getroffen werden.&#8220; (EllaM.) 
Ein konkreter Vorschlag empfiehlt eine App, die die Verwaltung von geteilten Daten erm&#246;glicht:
&#8222;Mit wem ich welche Daten teile, m&#246;chte ich gerne von Fall zu Fall festlegen k&#246;nnen. 
Ich stelle mir da irgendeine App vor, auf der ich Datenkategorien / 
&#220;berlassungsformat (anonymisiert / personenbezogen) / Preis usw. anklicken kann, 
die ich mit Interessierten teilen w&#252;rde, oder auf der mich auch Interessierte mit 
konkreten Anfragen anpingen k&#246;nnen.&#8220; (peters.) 
Eine freiwillige, widerrufbare Zustimmung zur Datenverwendung ist damit f&#252;r viele eine
notwendige Bedingung, unter der sie ihre Daten zur Verf&#252;gung stellen w&#252;rden. Dabei z&#228;hlt
nicht nur ein Rechtsanspruch, sondern auch die praktische Umsetzbarkeit im Alltag. 
Damit Daten sicher geteilt werden k&#246;nnen, regen die Teilnehmenden verschiedene
Ma&#223;nahmen an: F&#252;r das Teilen von Daten seien Anreize (u.a. Bezahlung), Standards aber auch
Schnittstellen notwendig, denn:
&#8222;ML basiert auf Daten, wenn es also keine Daten gibt, dann gibt es auch keine ML. 
Es m&#252;ssten hier schnellstm&#246;glich Datenlakes f&#252;r alle Bereiche mit anonymisierten 
Daten geschaffen werden.&#8220; (gkrause) 
In diesem Kontext wird h&#228;ufiger eine Gegenleistung f&#252;r das Teilen von Daten
vorgeschlagen. So schreibt ein Nutzer, er teile &#8222;mit der Wirtschaft &#252;berhaupt nicht, es sein denn, derjenige 
zahlt daf&#252;r (z. B. mit einer n&#252;tzlichen Suchmaschine)&#8220; (ChristianH).  
Personenbezogene Daten zu anonymisieren oder zu pseudonymisieren, wird in diesem
Kontext mehrfach als Bedingung f&#252;r das Teilen von Daten genannt, die Umsetzung dieser
Bedingung aber als problematisch gesehen.
&#8222;F&#252;r das Allgemeinwohl sollten alle Daten anonymisiert bereitgestellt werden. Dies 
ist auch hinreichend. Beispiel: Damit ML (machine learning) eine Krankheit mit einer 
bestimmten Wahrscheinlichkeit diagnostizieren kann, braucht es nur 
krankheitsbezogene Daten, aber nicht personalisierte Daten.&#8220; (gkrause) 
&#8222;Wenn anonymisiert/pseudonymisert und mit angemessener Strafbewehrung im 
Missbrauchsfall: Mit fast allen.&#8220; (JeBi20) 
&#8222;Anonymisieren h&#246;rt sich gut an, leider liest man oft von F&#228;llen, in denen 
anonymisierte Daten dann doch wieder zuordenbar wurden.&#8220; (RauAI) 
Auch im Hinblick auf eine langfristige Speicherung von Daten warnen einige Teilnehmende 
vor Risiken: Daten, die heute gesammelt werden, k&#246;nnten in Zukunft gegen Nutzer und
Nutzerinnen verwendet werden, &#8222;wenn sich die Zeiten mal &#228;ndern&#8220; (ChristianH).
&#8211; 762 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
37 
Frage 11: &#8222;Welchen Handlungsbedarf sehen Sie bei der bestehenden 
Regulierung von Daten mit Blick auf KI?&#8220;
Es bestehen bereits viele Regulierungen, die die Entwicklung und Verwendung von KI regeln. 
Eine neue, sich schnell wandelnde Technologie wirft jedoch Fragen auf, inwiefern der
Rechtsrahmen angepasst werden muss. Die Teilnehmenden wurden deshalb gefragt, welchen
zus&#228;tzlichen Regulierungsbedarf sie sehen und welche Regulierungen dazu beitragen k&#246;nnen,
die Akzeptanz f&#252;r KI zu erh&#246;hen.
Die bestehenden Regulierungen, dabei besonders die Datenschutz-Grundverordnung 
(DSGVO), bewerten viele Teilnehmerinnen und Teilnehmer als hilfreich und sinnvoll. Wohl
aber best&#252;nden L&#252;cken in Bezug auf Profilbildung und Scoring, als auch im Bereich
Anonymisierung und Pseudonymisierung. Handlungsbedarfe best&#252;nden weiterhin in der Festlegung
von Strafma&#223;en bei Datenlecks und der genaueren Ausgestaltung und Abstimmung von
Regulierungen im Allgemeinen. Auch die technische Gestaltung und die daraus resultierende
Praxistauglichkeit m&#252;sse ausgebaut werden.
Handlungsbedarfe
Bestehende Regulierungen wie die DSGVO halten die Teilnehmenden f&#252;r eine gute Basis f&#252;r
den Datenschutz, die im Allgemeinen nicht ver&#228;ndert werden m&#252;ssten. Die Durchsetzung der
Regulierungen m&#252;sste jedoch st&#228;rker kontrolliert werden 
Mehrere Teilnehmende sehen die Notwendigkeit, bestehende Regulierungen st&#228;rker
durchzusetzen und deren Verletzung durch die Etablierung effektiver Strafen st&#228;rker zu
ahnden.
&#8222;[&#8230;] abschreckende Strafen bei unerlaubter Nutzung von fremden Daten inklusive 
entsprechender Verfolgung [&#8230;] die DSGVO geht hier in die richtige Richtung&#8220; (RauAI). 
&#8222;Das (sinnlose) Horten von Daten bei den Unternehmen muss zu einem 
unternehmerischen Risiko werden, damit alle Beteiligten (ernsthafte) Versuche 
unternehmen, nur das zu speichern, was auch n&#246;tig ist. Es ist keinesfalls 
ausreichend, den Verbleib von Daten einfach vertraglich zu regeln. So frei nach dem 
Motto: wenn es verboten ist, wird es schon keiner machen.&#8220; (Doc Go) 
Entsprechend fordern Teilnehmende angemessen hohe Strafen f&#252;r Zuwiderhandlung sowie 
ein wirksames Recht auf die L&#246;schung von widerrechtlich erhobenen Daten, um die
Durchsetzung von bereits gesetzlich geregelten Rechten zu sichern.
Neben diesen &#252;bergreifenden Handlungsbedarfen gebe es zudem mehrere Teilbereiche, die
einer Anpassung bed&#252;rften. Besonderen Handlungsbedarf sehen die Teilnehmenden in Bezug 
auf Profilbildung und Scoring-Systeme. Es herrsche Unklarheit dar&#252;ber, ob die
Auskunftsregelungen der DSGVO auch f&#252;r zusammengef&#252;hrte Daten in Profilen gelten, und deshalb
m&#252;sse der Rechtsrahmen angepasst werden. Zudem k&#246;nnten Daten in Kombination mit
anderen Daten Aufschl&#252;sse erm&#246;glichen, die bei Einzelbetrachtung nicht ersichtlich seien. Auch
die datenanalytischen F&#228;higkeiten k&#246;nnten stark anwachsen, sodass heute gesammelte
Daten mit neuartigen Analysemethoden in Zukunft vielf&#228;ltige Aufschl&#252;sse bieten k&#246;nnten, die sich
aus heutiger Sicht noch nicht abzeichneten:
&#8222;Aus vermeintlich weniger sensiblen Daten kann die lernende KI unter Umst&#228;nden 
zuk&#252;nftig aber solche Informationen ableiten, die zu Gesundheitsdaten oder sonstigen 
sensiblen Daten f&#252;hren.&#8220; (Conrad S. C.)
&#8211; 763 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
38 
Auch k&#246;nnten Scoring-Systeme diskriminierende Effekte haben, weil die Annahmen
Stereotype reproduzierten. Um diesem Effekt entgegenzuwirken, m&#252;ssten Qualit&#228;tskriterien
definiert werden. Die Teilnehmenden formulieren verschiedene Bedingungen, z. B. dass sich
Betroffene einem Scoring entziehen k&#246;nnen m&#252;ssen und sie ein Anrecht darauf haben m&#252;ssen,
ihre Daten l&#246;schen zu lassen, auch wenn sie bereits in KI-Anwendungen verwendet wurden.
Ein generelles Verbot von Social Scoring wird ebenfalls genannt. 
Handlungsbedarfe sehen die Teilnehmenden au&#223;erdem besonders bei der Anonymisierung
und Pseudonymisierung von Daten: Besonders im medizinischen Anwendungsbereich 
seien anonymisierte Daten f&#252;r die Forschung erforderlich. Dazu k&#246;nne ein &#8222;nationales 
erkrankungsspezifisches Register&#8220; (Katharina), wenn es die datenschutzrechtlichen Auflagen
erf&#252;lle, beitragen. Klare Regeln seien jedoch zur Umsetzung notwendig, denn beispielsweise 
seien Anonymisierungen teilweise wieder aufhebbar und auch wenn die Pseudonymisierung 
z. B. f&#252;r Patientinnen und Patienten Vorteile haben kann, bed&#252;rfe es hierf&#252;r ebenfalls klarer
Vorgaben.
Mehrere Teilnehmende halten zudem eine globale Abstimmung von Standards,
Regulierungen und Haftungsmodellen f&#252;r notwendig. Dazu z&#228;hlt auch eine einheitliche Umsetzung der
DSGVO in den EU-Staaten.
F&#252;r staatliche Institutionen zeigen die Teilnehmenden verschiedene Handlungsbedarfe auf:
Aufsichts- und Sicherheitsbeh&#246;rden m&#252;ssten besser ausgestattet werden, staatlich legitimierte
Kontrollsysteme f&#252;r die Einhaltung von geltendem Recht geschaffen werden und in intelligente
Abwehrsysteme gegen Cyber-Angriffe investiert werden.
Eine zentrale Herausforderung sei nicht zuletzt, dass B&#252;rgerinnen und B&#252;rgern nicht bewusst 
sei, wie ihre Daten potenziell verwendet werden k&#246;nnten: &#8222;Datenkompetenz [ist] in Wirtschaft 
und Gesellschaft nur unzureichend vorhanden&#8220; (JeBi20). Es m&#252;ssten daher nicht nur
bestehende Regulierungen verbessert und erweitert werden, sondern damit einhergehend
Nutzerinnen und Nutzer auch st&#228;rker &#252;ber diese Regulierungen und die Implikationen der
Verwendung ihrer Daten aufgekl&#228;rt werden. Dar&#252;ber hinaus m&#252;sse auch die praktische Umsetzung
der bestehenden Regulierungen verbessert werden, um die Bereitschaft zur Verwendung 
von Daten zu erh&#246;hen. Durch Nachvollziehbarkeit und Privacy-by-Design k&#246;nne den
Nutzerinnen und Nutzern die &#220;berpr&#252;fung von KI-Entscheidungen erleichtert und der pers&#246;nliche 
Datenschutz durch eigene Voreinstellungen unterst&#252;tzt werden.
3.4 Themenfeld &#8222;Wissen und Forschung&#8220;
Wissen und Forschung zu KI bilden eine Grundlage f&#252;r die gesellschaftliche Akzeptanz von KI
sowie deren bedarfsorientierte Weiterentwicklung. Daher stellt dieses Themenfeld ein
zentrales Element der Online-Beteiligung dar. Anhand der Fragen wird die Breite der
gesellschaftlichen Bedarfe in diesem Feld angerissen: Von der grundlegenden Definition von KI &#252;ber die 
notwendige Bildung zu KI f&#252;r unterschiedliche Zielgruppen, die notwendigen Grundlagen f&#252;r
ein Verst&#228;ndnis von Funktionen und Nutzen bis hin zur Forschung zu KI. 
Frage 12: &#8222;Was verstehen Sie unter KI?&#8220;
Mit der ersten Frage zum Themenfeld &#8222;Wissen und Forschung&#8220; wurden die Teilnehmerinnen
und Teilnehmer dazu angeregt, &#252;ber ihr Verst&#228;ndnis von KI zu diskutieren. Sie wurden dazu 
aufgefordert, Schlagworte zu nennen, welche sie mit KI assoziieren und sich dar&#252;ber
auszutauschen, was sie mit KI im Allgemeinen verbinden. Aus den Antworten der Teilnehmerinnen
&#8211; 764 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
39 
und Teilnehmer geht hervor, dass es sich bei den Diskutierenden der Frage &#252;berwiegend um
Expertinnen und Experten handelt, die &#252;ber Wissen zu (Entstehungs-)Hintergr&#252;nden,
Funktionen und Zielen von KI sowie &#252;ber damit in Zusammenhang stehende Begrifflichkeiten und 
Begriffsdiskussionen verf&#252;gen. Der Austausch der Teilnehmenden dar&#252;ber, was sie unter KI
verstehen, verlief konstruktiv: Sie tauschten ihre Verst&#228;ndnisse dar&#252;ber aus, wie der Begriff KI
zu verwenden sei und wie aus ihrer Sicht optimalerweise nicht. Es wurden dar&#252;ber hinaus 
definitorische Ans&#228;tze dargelegt, welche zum Teil positiv, aber auch als weniger zielf&#252;hrend 
von anderen Teilnehmenden bewertet wurden. Einigkeit unter den Teilnehmerinnen und
Teilnehmern bestand gr&#246;&#223;tenteils dar&#252;ber, dass eine allgemeing&#252;ltige Begriffssch&#228;rfung f&#252;r KI
vorgenommen werden m&#252;sse. Denn derzeit werde der Begriff u.a. aus kommerziellen
Zwecken f&#252;r Technologien bzw. Anwendungen genutzt, welche keine KI im eigentlichen Sinne
darstellen w&#252;rden.
Im Rahmen der Online-Beteiligung wurde auf der Unterseite 'FAQ' eine kurze Begriffskl&#228;rung
zu KI vorgenommen. Es wurde darauf hingewiesen, dass es bislang keine allgemein
verbindliche Definition von KI gibt und dass sich die Enquete-Kommission auf die ausf&#252;hrliche
Definition der High-Level Expert Group on Artificial Intelligence der Europ&#228;ischen Kommission
bezieht und darauf verlinkt. Im Rahmen der Frage 'Was verstehen Sie unter KI?' wird von den
Teilnehmerinnen und Teilnehmern jedoch nicht auf die Definition der High-Level Expert Group 
on Artificial Intelligence referenziert. An anderen Stellen der Online-Beteiligung wird von
einigen Teilnehmenden zwar auf die zu beachtende Arbeit am Thema KI auf EU-Ebene und
insbesondere durch die Europ&#228;ische Kommission hingewiesen (z. B. 'Ethics guidelines for
trustworthy AI') jedoch findet sich auch hier im Rahmen der Kritik an einer mangelnden
Begriffsdefinition kein Bezug zur Definition der High-Level Expert Group.
Die Teilnehmerinnen und Teilnehmer n&#228;hern sich der Frage, was Sie unter KI verstehen, &#252;ber
unterschiedliche Herangehensweisen:
1. &#252;ber die Definition des Begriffs KI.
2. &#252;ber Kritik am derzeitigen Begriffsverst&#228;ndnis und an der Begriffsverwendung.
3. &#252;ber die Unterscheidung von schwacher (kleiner) KI und starker (gro&#223;er) KI, den
jeweiligen Umsetzungsstand sowie die generelle Machbarkeit. 
4. &#252;ber die F&#228;higkeiten und Ziele von KI.
Diese vier Zug&#228;nge werden nachfolgend erl&#228;utert.  
Zugang 1: Definition des Begriffs KI
Die Teilnehmenden empfinden bereits die fehlende Definition des Begriffs Intelligenz als
problematisch f&#252;r eine darauf aufbauende Definition von K&#252;nstlicher Intelligenz. Es besteht die
Meinung, dass die Definition menschlicher Intelligenz an Vernunft, Moral und Emotionen
gekn&#252;pft sei und daher grundlegend ungeeignet sei, um KI zu beschreiben. Deshalb brauche es
eine klare Abgrenzung zum Verst&#228;ndnis von menschlicher Intelligenz:
&#8222;Eine Definition f&#252;r K&#252;nstliche Intelligenz ist generell schwierig zu finden, da nicht klar 
ist, was biologische, &#8218;nat&#252;rliche&#8216; Intelligenz ausmacht. Mit heutiger k&#252;nstlicher 
Intelligenz assoziieren wir Systeme, spezifisch Algorithmen und Daten, welche 
Aufgaben l&#246;sen k&#246;nnen, die ansonsten von intelligenten Organismen gel&#246;st werden. 
Wichtig bei regulatorischen Ma&#223;nahmen ist eine klare rechtliche Definition, um KI-
Algorithmen von anderen Algorithmen klar abzugrenzen.&#8220; (Benedikt B.)
&#8211; 765 &#8211; 
-
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
40 
Es gibt aber auch einige Teilnehmende, die KI nicht als Form von Intelligenz (gemessen an 
menschlichen Ma&#223;st&#228;ben) ansehen und den Begriff in diesem Zusammenhang daher generell 
f&#252;r irref&#252;hrend halten. Wichtig sei in jedem Fall eine grundlegende und eindeutige
definitorische Unterscheidung zwischen k&#252;nstlicher und nat&#252;rlicher Intelligenz.
Weiterhin werden die Dimensionen einer (noch nicht existierenden) &#8218;absoluten Intelligenz&#8216;,
welche zur L&#246;sung unterschiedlichster, voneinander unabh&#228;ngiger Aufgaben und Probleme
geeignet sei, sowie einer &#8218;speziellen Intelligenz&#8216;, welche nur zur L&#246;sung konkreter Aufgaben
und Probleme geeignet ist (bereits existierende KI-Systeme), angef&#252;hrt. KI sei derzeit in
spezifischen Bereichen stark und erziele &#8218;&#252;bermenschliche Resultate&#8216;, jedoch sei bez&#252;glich der
Probleml&#246;sung in einer Vielzahl an mitunter auch neuen Situationen die menschliche
Intelligenz mit ihren verschiedenen Unterarten (z. B. emotionale Intelligenz) der KI (noch)
&#252;berlegen.
Die bislang erfolgten Ans&#228;tze der Wissenschaft f&#252;r die Entwicklung einer Definition von KI
werden von den Teilnehmenden nicht als ausreichend bewertet. Um dem entgegenzuwirken,
wird z. B. dieser Definitionsansatz dargelegt:
&#8222;Inspiriert von der Sicht auf kognitive Systeme von Albert Newen von der Ruhr-
Universit&#228;t Bochum, schlage ich folgende Definition vor: Eine K&#252;nstliche Intelligenz 
ist ein Prozess, der das emergente Resultat eines von Menschen hergestellten 
Gegenstandes ist und dazu in der Lage ist, wahrzunehmen, zu handeln, und dessen 
Handlungen derart sind, dass sie nicht durch starre Stimulus-Reaktions-Muster 
erkl&#228;rt werden k&#246;nnen, ohne eine gewisse Form von interner 
Informationsverarbeitung vorauszusetzen. [&#8230;] Diese m&#252;sste auf 
Ged&#228;chtnisstrukturen operieren, welche ein Modell der externen Welt darstellen. Das 
hei&#223;t: Eine K&#252;nstliche Intelligenz muss dazu in der Lage sein, mentale 
Repr&#228;sentationen der Au&#223;enwelt zu erinnern, und seine Handlungsentscheidungen 
unter Einbeziehung dieser mentalen Repr&#228;sentationen zu f&#228;llen.&#8220; (Daniel S.) 
Zugang 2: Kritik am Begriffsverst&#228;ndnis und der Begriffsverwendung
Die Teilnehmerinnen und Teilnehmer empfinden KI &#252;berwiegend als einen zu weit gefassten 
Begriff, welcher in seiner Bedeutung durch die Zusammenfassung verschiedenster
Technologien und technischer Verfahren abgeschw&#228;cht werde:
&#8222;Der Begriff &#8218;KI&#8216; ist so breit, dass er eigentlich nicht verwendet werden sollte. Es gibt 
Programme, die einfach nur &#8218;clever&#8216; programmiert sind. Und es gibt neuronale 
Mustererkenner, die etwas v&#246;llig anderes tun. Wenn man auf alles &#8218;KI&#8216; draufschreibt, 
vergr&#246;&#223;ert das nur die Verwirrung.&#8220; (Doc Go) 
Hinzu komme, dass KI zu Marketing- und Verkaufszwecken auch f&#252;r Produkte und
Anwendungen verwendet werde, die eigentlich keine KI seien:
&#8222;ALLES ist KI, wenn es Geld bringen k&#246;nnte. Der Begriff ist so ausgelutscht und so 
missbraucht, dass kein echter KI-Forscher sich noch als &#8218;KI&#8216; bezeichnet, wenn es 
geht! Heute versucht sich jeder als KI zu verkaufen, weil er glaubt dass er dann 
gef&#246;rdert wird. Und oft genug mit Erfolg, weil alle Angst vor dem &#8218;n&#228;chsten Google&#8216; 
haben, das sie platt macht. Aber mit KI hat das meistens nichts mehr zu tun.&#8220; (KI ist 
ein Buzzword und bedeutet NICHTS) 
Einige der Teilnehmenden pl&#228;dieren daf&#252;r, KI als Wissenschaft bzw. Forschungsgebiet zu
verstehen und nicht als eine spezifische Technologie oder Sammlung bestimmter Verfahren.
&#8211; 766 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
41 
Auch eine bislang noch fehlende Fachterminologie wird kritisiert: Aktuell herrsche eine
Vermenschlichung mathematischer Abl&#228;ufe durch Begriffe wie z. B. &#8218;wissen&#8216;, &#8218;erkennen&#8216; und &#8218;
lernen&#8216; vor. Diese Erkenntnis &#228;hnelt der Problematik der von den Teilnehmenden als mangelhaft
empfundenen Differenzierung zwischen nat&#252;rlicher und K&#252;nstlicher Intelligenz. Wenn KI als
wissenschaftlich-technische Forschungsdisziplin verstanden werden w&#252;rde, statt als einzelne
Technologie oder Anwendung, w&#252;rde dementsprechend der Begriff &#8218;KI-System&#8216; f&#252;r die
Maschine (bzw. die Anwendung) mit der F&#228;higkeit der (noch zu definierenden) &#8218;Maschinen-
Intelligenz&#8216; verwendet werden.
Zugang 3: Unterscheidung zwischen schwacher und starker KI
Die Teilnehmerinnen und Teilnehmer unterscheiden zwischen der schwachen (bzw. kleinen) 
KI und der starken (bzw. gro&#223;en) KI und beschreiben deren Unterschiede, nennen
Schlagworte, Ziele und diskutieren die technische Umsetzbarkeit.
Die schwache (bzw. kleine) KI werde auch mit dem Begriff &#8222;Narrow Artificial Intelligence&#8220;
bezeichnet und beschreibe 
&#8222;das Nachbilden/&#220;bertreffen von Verhalten eingeschr&#228;nkt auf spezielle 
Anwendungen, z. B. durch das Lernen/Trainieren auf gro&#223;en Datenmengen zur 
Erkennung von typischen Mustern in Eingabedaten.&#8220; (Benedikt B.) 
Ziel der schwachen KI sei es, Wissen zu akkumulieren und daraus Schlussfolgerungen zu
ziehen. Die Teilnehmenden nennen bez&#252;glich der schwachen KI verschiedene Schlagworte
wie u.a. &#8218;Algorithmus&#8216;, &#8218;Machine Learning&#8216;, &#8218;Deep Learning&#8216;, &#8218;k&#252;nstliche neuronale Netze&#8216;,
&#8218;Mustererkennung&#8216;, &#8218;Trainingsdaten&#8216; sowie &#8218;Expertensysteme&#8216;. Manche der Teilnehmenden
sehen schwache KI jedoch nicht als KI im eigentlichen Sinne, sondern lediglich als
Verkn&#252;pfung von Mustererkennung und hochleistungsf&#228;higer Rechentechnik. 
Die starke (bzw. gro&#223;e) KI werde auch mit dem Begriff &#8222;General Artificial Intelligence&#8220;
bezeichnet und stelle ein Teilgebiet von KI dar. Hinsichtlich der Entstehungsgeschichte schreibt 
ein Teilnehmer:  
&#8222;Als der Begriff KI vor 60 Jahren als &#220;berschrift der legend&#228;ren &#8218;KI-
Gr&#252;ndungskonferenz&#8216; gew&#228;hlt wurde, gingen die Vertreter dieser neuen 
wissenschaftlichen Fachrichtung tats&#228;chlich davon aus, dass mit Rechenmaschinen 
die menschliche Intelligenz umfassend nachgebildet werden k&#246;nnte im Sinne einer 
&#8218;starken KI&#8216;.&#8220; (Alexander B.) 
Die starke KI k&#246;nne vergleichbare F&#228;higkeiten wie der Mensch haben; Ziel sei hierbei die 
Nachbildung der menschlichen Intelligenz inklusive eines Bewusstseins, Intuition und der
F&#228;higkeit, &#8218;zwischen den Zeilen zu lesen&#8216;. Die reale Umsetzung der starken KI scheint den
Teilnehmerinnen und Teilnehmern jedoch in absehbarer Zeit nicht m&#246;glich zu sein. Einige
Teilnehmende empfinden dies sogar als vollkommen unm&#246;glich.
Zugang 4: F&#228;higkeiten und Ziele von KI
Die F&#228;higkeit des Lernens stellt f&#252;r einige der Teilnehmenden ein zentrales Merkmal von KI
dar; dies bedeute die &#196;nderung von Verhalten, die Optimierung von Probleml&#246;sungen und das
Erzielen eines Erkenntnisgewinns. Hierf&#252;r sei eine gro&#223;e Anzahl an vom Menschen
zugef&#252;hrten Trainingsdaten f&#252;r das entsprechende KI-System notwendig, damit es schlussendlich ein 
nicht-programmiertes Verhalten zeigen k&#246;nne. Es besteht aber daneben auch die Ansicht,
dass Lernen kein notwendiges Merkmal von KI-Systemen sei und daher zwischen lernenden
&#8211; 767 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
42 
und nicht-lernenden algorithmischen Entscheidungssystemen unterschieden werden
m&#252;sse. So gebe es auch KI-Systeme, die in der praktischen Anwendungsphase nicht
hinzulernen w&#252;rden.
Als Methoden des Maschinellen Lernens (Machine Learning) werden selbstverst&#228;rkendes,
&#252;berwachtes und un&#252;berwachtes Lernen genannt; selbstverst&#228;rkendes und &#252;berwachtes
Lernen seien als KI zu verstehen, wobei es um die Entstehung von Modellen durch einen
Lernprozess ginge, um damit die L&#246;sung konkreter Probleme zu erm&#246;glichen. F&#252;r manche
Teilnehmerinnen und Teilnehmer stellt dar&#252;ber hinaus die F&#228;higkeit, selbstst&#228;ndig
Entscheidungen auf Basis unvollst&#228;ndiger bzw. endlicher Informationen treffen zu k&#246;nnen, ein
zentrales Kriterium von KI dar. Nur ein stetiger Prozess des Lernens erm&#246;gliche es, optimale
Entscheidungen zu treffen und das Treffen von Entscheidungen und die Konsequenzen daraus
erm&#246;glichten wiederum einen Lernprozess: 
&#8222;Unter KI verstehe ich stark vereinfacht die F&#228;higkeit eines Algorithmus, Muster und 
Zusammenh&#228;nge in Daten zu erkennen, auf dieser Basis Vorhersagen abzuleiten, 
ggf. selbstst&#228;ndig Entscheidungen zu treffen und aus den gemachten Vorhersagen 
bzw. Entscheidungen zu lernen, d.h. sich immer weiter zu verbessern.&#8220; (Fabian S.) 
Ein zentrales Zielkriterium von KI wird von den Teilnehmenden benannt: KI solle im Dienste
der Menschen angewendet werden, d.h. KI-Systeme sollten Menschen unterst&#252;tzen und
ihnen bei der Bew&#228;ltigung einer immer komplexer werdenden Welt helfen.
Handlungsbedarfe und Rahmenbedingungen aus Sicht der Teilnehmenden 
Die Mehrheit der Teilnehmerinnen und Teilnehmer argumentiert, es m&#252;sse eine einheitliche
Definition von KI entwickelt werden, damit deutlich werde, welche Technologien und
Anwendungen als KI bezeichnet werden k&#246;nnen und d&#252;rfen und welche nicht. Au&#223;erdem solle die
Differenz zwischen schwacher und starker KI deutlicher herausgestellt bzw. die begriffliche
Vereinheitlichung unter &#8218;KI&#8216; solle aufgel&#246;st werden. Dadurch k&#246;nne ein Verst&#228;ndnis auch f&#252;r
B&#252;rgerinnen und B&#252;rger erleichtert werden. Die Differenzierung und das einheitliche
Verst&#228;ndnis seien wichtig, um &#252;ber Potenziale, Risiken und etwaige Regulierungen sprechen zu
k&#246;nnen. Als weiterer Handlungsbedarf wird identifiziert, dass m&#246;glichst fr&#252;hzeitig Visionen und
Strategien f&#252;r den Umgang mit KI-Systemen sowie bez&#252;glich ihres intendierten Nutzens
entwickelt werden. Nur so k&#246;nne sichergestellt werden, dass die gesellschaftliche nicht der
technischen Entwicklung hinterherlaufe.
Frage 13: &#8222;Wie und durch wen sollte Wissen &#252;ber KI verst&#228;rkt vermittelt
werden?&#8220; 
Die zweite Frage des Themenfeldes &#8222;Wissen und Forschung&#8220; zielt auf die Diskussion &#252;ber die
Art und Weise der Wissensvermittlung zu KI sowie auf die Akteure, welche f&#252;r die Vermittlung 
von Wissen zust&#228;ndig sein sollten. Spezifisch wurde gefragt, &#252;ber welche Medien und
Institutionen die Wissensvermittlung erfolgen sollte, ob und wie z. B. Wissen zu KI schon in der
Schule vermittelt werden sollte und welche M&#246;glichkeiten es f&#252;r die Weiterbildung am
Arbeitsplatz und in der Bev&#246;lkerung allgemein geben sollte.  
Die Analyse der Kommentare der Teilnehmerinnen und Teilnehmer zeigt unterschiedliche
Akteure der Bildungslandschaft auf, welche als relevant f&#252;r die Bildung zu KI angesehen werden.
Die H&#228;ufigkeit der Nennungen der jeweiligen Akteure kann eine ungef&#228;hre Einsch&#228;tzung
davon erm&#246;glichen, welche Akteure von den Teilnehmerinnen und Teilnehmern als besonders
&#8211; 768 &#8211; 
&#8211;
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
43 
relevant eingestuft werden: Schule, allgemeine Erwachsenenbildung/Weiterbildung sowie
Medien werden besonders h&#228;ufig genannt. Weiterhin haben die Teilnehmerinnen und Teilnehmer
erl&#228;utert, in welcher Weise Wissen zu KI verst&#228;rkt vermittelt werden soll. Sie gingen hierbei 
auf Bildungsziele, Zielgruppen, Bildungsinhalte, -formate und weitere Anforderungen an die 
Bildungsangebote ein. 
Es l&#228;sst sich zusammenfassen, dass sich die Teilnehmerinnen und Teilnehmer bis auf eine 
Person darin einig sind, dass es eine gezielte und verst&#228;rkte Wissensvermittlung zu KI geben
m&#252;sse. Gleichzeitig verbinden sie viele Herausforderungen mit einer umfassenden Bildung zu 
KI, welche es zuk&#252;nftig zu meistern gelte. Vorschl&#228;ge von Teilnehmerinnen und Teilnehmern
zur Wissensvermittlung durch kostenlose und frei zug&#228;ngliche Online-Kurse, durch
interdisziplin&#228;re Zusammenschl&#252;sse von Forschungseinrichtungen und Universit&#228;ten, durch Schulen
sowie durch ein EU-weites Projekt wurden von anderen Teilnehmenden positiv bewertet.
Akteure der Wissensvermittlung 
Die Teilnehmerinnen und Teilnehmer nennen h&#228;ufig die Schule als Bildungsinstitution mit
besonderer Bedeutung f&#252;r die Wissensvermittlung zu KI. Neben dem Themenfeld Digitalisierung
im Allgemeinen sollte hier eine grundlegende KI-Kompetenz vermittelt werden. Dabei sei es
wichtig, erlebnisorientiertes Lernen zu erm&#246;glichen: 
&#8222;Ausprobieren, anwenden, selbst (weiter-)entwickeln).&#8220; (Susan) 
Aber es wird auch die Meinung vertreten, es sei in der Schule zwar wichtig, z. B.
mathematische Grundf&#228;higkeiten zu vermitteln, jedoch k&#246;nne Wissen &#252;ber KI-Systeme erst in
weiterf&#252;hrenden Bildungseinrichtungen gelehrt werden. Die Mehrheit der Teilnehmenden sieht die
Schule dennoch bereits als Ort, an dem Wissen &#252;ber KI und angrenzende gesellschaftliche
Themenbereiche wie z. B. Ethik und Rechtstheorie, vermittelt werden sollte. So k&#246;nne ein
grundlegendes Verst&#228;ndnis f&#252;r eine zuk&#252;nftige &#8222;Kulturtechnik&#8220; schon fr&#252;hzeitig geschaffen
werden.
Als weiteren zentralen Bildungsakteur f&#252;r KI nennen die Teilnehmerinnen und Teilnehmer
Akteure der allgemeinen Erwachsenen- und Weiterbildung: 
&#8222;Da die Entwicklungen immer weiter gehen werden, m&#252;ssen hier Wege des 
lebenslangen Lernens geschaffen werden. Ich sehe dies als Voraussetzung f&#252;r ein 
selbstbestimmtes Leben.&#8220; (aberanek) 
Schwerpunktm&#228;&#223;ig wird hier angef&#252;hrt, dass Wissen zu KI in die breite Gesellschaft getragen 
werden m&#252;sse. Die M&#246;glichkeiten der Umsetzung variieren dabei und reichen von
Volkshochschulkursen, &#252;ber arbeitsplatzorientierte (private) Fortbildungen bis hin zur Einrichtung einer
Bundeszentrale f&#252;r algorithmische Kompetenz, welche Fortbildungsangebote f&#252;r
verschiedene Zielgruppen anbieten k&#246;nne. Wichtig bei berufsbegleitenden Angeboten sei es, dass
diese sich gut in den Arbeitsalltag integrieren lie&#223;en.
In Bezug auf die Bildung zu KI sehen die Teilnehmenden auch die Medien in der Pflicht, den
B&#252;rgerinnen und B&#252;rgern Bildungsangebote zu machen und eine &#246;ffentliche Diskussion
anzuregen:
&#8222;Mit Blick auf den aktuellen, von Vermutungen, Annahmen und Halbwissen 
gepr&#228;gten Debattenstand scheint mir den Medien jedoch eine besondere Rolle 
zuzukommen, um zu einem realistischen, faktenbasierten und aufgekl&#228;rten Diskurs 
zu kommen.&#8220; (Fabian S.)
&#8211; 769 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
44 
Neben Fernsehen im Allgemeinen k&#246;nne vor allem der &#246;ffentlich-rechtliche Rundfunk (der per
se einen Bildungsauftrag innehabe) einen wichtigen Beitrag leisten. Sendungen,
Dokumentarfilme und das Jugendangebot im Rundfunk mit Unterst&#252;tzung durch Social-Media-Kan&#228;le
werden hier in Bezug auf die M&#246;glichkeit der zielgruppengerechten Ansprache genannt.
Auch Universit&#228;ten und Hochschulen sehen mehrere Teilnehmerinnen und Teilnehmer als
zentral f&#252;r die Wissensvermittlung an. Ziel solle hier eine Entmystifizierung des Themas sein
sowie die Entwicklung von Informationspaketen, die an andere Bildungsinstitutionen
weitergereicht werden k&#246;nnten:
&#8222;Hier sollten die Informationspakete geschn&#252;rt werden, welche anschlie&#223;end durch 
Medien, Zentren f&#252;r politische Bildung, (Volks-)Hochschulen, Universit&#228;ten, und ggf. 
Schulen unter der Bev&#246;lkerung verbreitet werden. [&#8230;] Stattdessen sollten diese 
Informationspakete von interdisziplin&#228;ren Aussch&#252;ssen geschn&#252;rt werden, welche 
sich zusammensetzen aus Professoren und Doktoranden aus allen relevanten 
Gebieten.&#8220; (danielsabinasz) 
Zudem seien dies die Orte der Vermittlung von Expertenwissen und der Interdisziplinarit&#228;t. So 
sollten neben computerwissenschaftlichem, mathematischem und neuronalem Wissen auch
gesellschaftliche Aspekte vermittelt werden. Disziplinen wie z. B. die
Technikfolgenabsch&#228;tzung sollten zudem in der Lehre mehr Beachtung finden.
Hinsichtlich der Rolle von Arbeitgebern bei der F&#246;rderung der Wissensvermittlung zu KI
wiesen mehrere Teilnehmende darauf hin, dass unternehmenseigene, bedarfsgerechte
Weiterbildungsma&#223;nahmen effizienzsteigernd und sinnvoll seien. So k&#246;nne einem Fachkr&#228;ftemangel 
entgegengewirkt und das vorhandene Fachwissen der Mitarbeiterinnen und Mitarbeiter gezielt
genutzt und ausgebaut werden. 
Neben der Einrichtung einer Bundeszentrale f&#252;r algorithmische Kompetenz wurden im Feld
Politik und staatliche Akteuren noch die (deutsche) Bildungspolitik im Allgemeinen sowie
die Europ&#228;ische Kommission als Akteure genannt: Beide sollten vor allem f&#252;r
Chancengleichheit bez&#252;glich der Bildungsm&#246;glichkeiten zu KI sorgen und m&#246;glichst vielen B&#252;rgerinnen und
B&#252;rgern ein niedrigschwelliges Bildungsangebot erm&#246;glichen. Eine weitere Anmerkung galt
staatlichen Kontrollbeh&#246;rden sowie bestehenden zivilgesellschaftlichen W&#228;chter-
Organisationen, welche finanziell und personell gest&#228;rkt und im Kompetenzaufbau unterst&#252;tzt werden
sollten. Forschungseinrichtungen sollten z. B. durch digitale Open Educational Ressources
(OER) den Gro&#223;teil der Bildungsinhalte &#246;ffentlich und frei zur Verf&#252;gung stellen. Auch Zentren
f&#252;r Politische Bildung sowie die Berufsausbildung wurden als m&#246;gliche Akteure bzw. 
Felder der Wissensvermittlung identifiziert. 
Ziele, Formate und Inhalte der Wissensvermittlung
Als zentrales Bildungsziel wird der Aufbau eines Grundlagenwissens &#252;ber Funktionen,
Nutzen und Risiken von KI gesehen. So k&#246;nne laut den Teilnehmenden das Verst&#228;ndnis f&#252;r und
Vertrauen in KI gest&#228;rkt werden:  
&#8222;Um Vertrauen aufzubauen und eine differenzierte gesellschaftliche Debatte &#252;ber 
den Einsatz algorithmischer Systeme zu erm&#246;glichen, braucht es einen 
Kompetenzaufbau in der breiten Bev&#246;lkerung.&#8220; (Projektteam Ethik der Algorithmen) 
Auch gelte es, &#196;ngste abzubauen gerade bei &#228;lteren Menschen und weniger IT-affinen
Zielgruppen. Durch die Wissensvermittlung k&#246;nnten utopische und dystopische Vorstellungen, die
z. B. von Medien vermittelt w&#252;rden, relativiert werden. Ziel der schulischen Bildung sollte eine
&#8211; 770 &#8211; 
&#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
45 
langsame, aber geplante Heranf&#252;hrung an das Themenfeld KI inklusive des Einblickes in
angrenzende Themen und Disziplinen sein. Im Hinblick auf die Ausbildung und berufliche
Weiterbildung gelte es hingegen, gezielt Expertise auf- und auszubauen, um einem
Fachkr&#228;ftemangel entgegenzuwirken bzw. diesen zu verhindern.
Neben Sch&#252;lerinnen und Sch&#252;lern, jungen Menschen in Berufsausbildung oder Studium sowie 
Arbeitnehmerinnen und Arbeitnehmern werden auch explizit &#228;ltere Menschen, Laien und
generell nicht IT-affine Personen als Zielgruppen f&#252;r Bildungsangebote zu KI ausgemacht.
Weiterhin merken die Teilnehmenden an, dass es auch Bildungsangebote in Leichter Sprache, 
Geb&#228;rdensprache und f&#252;r die Unterst&#252;tzte Kommunikation geben solle, um eine m&#246;glichst
breite Streuung von Wissen zu erm&#246;glichen.
Als m&#246;gliche Bildungsformate werden z. B. genannt:
&#8222;Videos, Texte, (Online-)Kurse usw., die verschiedenen Anspr&#252;chen gen&#252;gen (also 
durchaus auch popul&#228;rwissenschaftlicher Art), aber dennoch soweit es geht korrekt 
sind. Deswegen sollten sie von entsprechend kompetenten Institutionen hergestellt 
werden (Netzwerk aus Universit&#228;ten zum Beispiel). Das Material sollte kostenlos und 
einfach zug&#228;nglich zur Verf&#252;gung stehen (staatlich gef&#246;rdert!?).&#8220; (versat) 
Weiterhin erw&#228;hnen die Teilnehmenden Dokumentarfilme, Tutorials, online verf&#252;gbare Skripte
und Cartoons als geeignete Formate. 
Bez&#252;glich der Bildungsinhalte finden einige der Teilnehmerinnen und Teilnehmer, dass
grunds&#228;tzlich ein breites Wissen &#252;ber Nutzen und Risiken sowie die M&#246;glichkeiten und
Grenzen von KI vermittelt werden sollte. Anhand praktischer Beispiele und der verst&#228;ndlichen
Darstellung und Analyse von KI-Beispielen k&#246;nne dies anschaulich erfolgen. Neben technischen
sollten auch ethische, rechtliche und sozialwissenschaftliche Inhalte gelehrt werden.
Als Anforderungen an Bildungsangebote werden u. a. Kostenfreiheit, freie Zug&#228;nglichkeit,
Barrierefreiheit und Fr&#252;hzeitigkeit genannt. Die Angebote sollten das gesamte Bildungssystem
(Schule, Ausbildung, Weiterbildung und Lebenslanges Lernen) umspannen und einen Praxis- 
und Anwendungsbezug aufweisen:  
&#8222;Mithilfe von &#246;ffentlichen Software-Bibliotheken k&#246;nnen Personen mit grundlegenden 
Programmierkenntnissen KI f&#252;r ihre ganz pers&#246;nlichen Projekte nutzbar machen. 
Daher sollte es neben Kursen f&#252;r (zuk&#252;nftige) Experten der KI-Entwicklung auch 
andere, frei zug&#228;ngliche Kurse geben, die sich an einen gr&#246;&#223;eren Teil der 
Bev&#246;lkerung richten und in denen vermittelt wird, wie man KI f&#252;r sich nutzbar macht, 
ohne ein Experte zu sein.&#8220; (wachsni) 
Eine st&#228;rkere &#246;ffentliche Thematisierung von Bildung zu KI sei wichtig, um m&#246;glichst vielen
B&#252;rgerinnen und B&#252;rgern Bedarfe zu verdeutlichen und Angebote aufzuzeigen und somit den
Zugang zu den Angeboten zu erleichtern.
Chancen und Herausforderungen aus Sicht der Teilnehmenden 
Bereits bestehende, kostenlose Online-Kurse wie z. B. &#8218;The Elements of AI&#8216; werden von den
Teilnehmerinnen und Teilnehmern als positive Beispiele f&#252;r eine niedrigschwellige Vermittlung
von Wissen zu KI, welche gleichzeitig eine gro&#223;e Anzahl an Menschen erreichen k&#246;nne,
angesehen. Als Chance f&#252;r die Zukunft wird betrachtet, dass der Einsatz von KI als Instrument
der Bildungspolitik eine M&#246;glichkeit f&#252;r mehr Chancengerechtigkeit im Bildungssystem sein
k&#246;nnte.
&#8211; 771 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
46 
Die Wissensvermittlung zu KI berge u.a. die Herausforderung der langsamen Anpassung von 
Lerninhalten an den technischen Entwicklungsstand in Schulen. Weiterhin wurde die
Verbreitung von Dystopien und Fehlinformationen als herausfordernder Faktor genannt, dem es durch 
Bildungsangebote etwas entgegenzusetzen gelte. Die rasante technologische Entwicklung 
eile der Anpassung der Gesellschaft voraus, was wiederum zu einer geringeren Akzeptanz
von KI f&#252;hre. Daher m&#252;sse daf&#252;r gesorgt werden, dass Bildung zu KI m&#246;glichst vielen
B&#252;rgerinnen und B&#252;rgern zug&#228;nglich sei und diese auch in Anspruch genommen werde. 
Handlungsbedarfe und Rahmenbedingungen aus Sicht der Teilnehmenden
Um mit und durch KI Zukunftsf&#228;higkeit und Chancengleichheit zu f&#246;rdern, m&#252;sse die
Bildungspolitik geeignete Rahmenbedingungen schaffen. Praktisch k&#246;nne dies umgesetzt werden,
indem z. B. Abitur- und Studieninhalte aufeinander abgestimmt werden und eine breitere
Ausrichtung des Unterrichtsstoffs u.a. hinsichtlich der Bereiche Recht, Wirtschaft und Ethik
stattfinde. Zudem m&#252;ssten kostenfreie, frei zug&#228;ngliche und zum Teil staatlich gef&#246;rderte Angebote
der Wissensvermittlung bereitgestellt und st&#228;rker beworben werden, um auch Erwachsene 
und vor allem auch Menschen der &#228;lteren Generation mit Bildung zu KI zu erreichen.
Niedrigschwellige Angebote f&#252;r die gesamte Gesellschaft bzw. f&#252;r verschiedene Zielgruppen
sollten daher entwickelt und bereitgestellt werden. Um Wissen in die breite Bev&#246;lkerung zu tragen
und die Akzeptanz von KI zu st&#228;rken, schlagen die Teilnehmenden u. a. eine &#8222;Bundeszentrale
f&#252;r algorithmische Kompetenz&#8220; sowie ein auf EU-Ebene initiiertes und gef&#246;rdertes
Bildungsangebot (einst&#252;ndiger Einf&#252;hrungskurs KI) vor.
Frage 14: &#8222;Welche Informationen ben&#246;tigen Sie, um Funktionen und Nutzen
von KI zu verstehen?&#8220; 
Die dritte Frage zum Themenfeld &#8222;Wissen und Forschung&#8220; zielte auf die
Hintergrundinformationen, die den Nutzerinnen und Nutzern zug&#228;nglich sein sollten, um die Funktionsweise und 
die Ziele einer KI zu verstehen. Es wurde in der Unterfrage gezielt danach gefragt, wo gut 
aufbereitete Informationen bislang fehlten. F&#252;r die Teilnehmerinnen und Teilnehmer stellt die
umfassende Transparenz einer KI eine zentrale Notwendigkeit dar. Abweichende Meinungen 
gibt es bez&#252;glich der Frage, wie umfassend die technische Funktion z. B. Verbraucherinnen
und Verbrauchern dargelegt werden m&#252;sse oder ob nicht das Verst&#228;ndnis des Nutzens der KI 
prim&#228;r sei (und die technische Funktionsweise dazu gar nicht bis ins Detail offengelegt und
verstanden werden m&#252;sse).
Informationen zum Verst&#228;ndnis von Funktion und Nutzen 
Neben einer Begriffskl&#228;rung und eindeutigen Definition von KI, die bereits auch anderer Stelle
formuliert wurde, ist den Teilnehmenden bei der Anwendung von KI vor allem wichtig, dass die 
KI in mehrerer Hinsicht transparent ist, um deren Funktion und/oder Nutzen nachvollziehen zu
k&#246;nnen. Es werden verschiedene Dimensionen von Transparenz hinsichtlich der Existenz, der
Funktionsweise, des Zwecks und der Entscheidungsfindung der KI aufgezeigt: 
&#8222;Kommt ein algorithmisches System zum Einsatz? (Vermummungsverbot bei 
Interaktion eines Systems mit Menschen)  Wie funktioniert das algorithmische 
System? (Systemtransparenz, u.a. zu Datenset, Entscheidungskriterien, 
Fehlerquoten)  Warum gibt es das algorithmische System? (Kontexttransparenz) 
Wie kommt die konkrete Entscheidung &#252;ber mich zustande? 
(Entscheidungstransparenz)&#8220; (Projektteam Ethik der Algorithmen)
&#8211; 772 &#8211;
-
- -
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
47 
Folgende Aspekte werden von den Teilnehmenden als notwendig f&#252;r das Verst&#228;ndnis von
Funktion und Nutzen einer KI erachtet:
a) Hinweis auf Verwendung von KI 
Kenntlichmachung z. B. durch Verwendung eines Labels wie &#8218;AI INSIDE&#8216; oder 
Soundlogo
b) Zweck des Einsatzes  
Was sind Ziele und Aufgaben der KI?
Welche Erkenntnisse sollen generiert werden? 
c) Welche Daten werden genutzt? 
Welche Datenarten und -typen werden verwendet? 
K&#246;nnen aus den Daten theoretisch sensible Informationen gewonnen werden? 
d) Wie werden die Daten genutzt?
Nach welchen Prinzipien und Parametern erfolgt die Analyse?
Welche Algorithmen werden verwendet? 
e) Wie werden Entscheidungen getroffen?  
Erkl&#228;rbare KI-Systeme: Sind der Prozess der Ergebnisfindung und die
Entscheidungen der KI nachvollziehbar/beschreibbar und interpretierbar?
f) Performance-Angaben
Wie schnell und genau arbeitet das System?
Trainingsdaten, Entwicklungsziel, Energieverbrauch 
Belege f&#252;r korrekte Funktionsf&#228;higkeit 
g) Zertifizierung 
Wann und durch wen wurde die KI zertifiziert?
h) Beschreibung der Risiken  
Unter welchen Umst&#228;nden und/oder Bedingungen ist eine Anwendung nicht
vorgesehen, analysiert oder erprobt?
Welche Schw&#228;chen hat das System?
i) Einspruchsm&#246;glichkeit gegen das KI-System
Kann man sich der Verwendung der KI bzw. konkreten Funktionen und
Datenzugriffen verweigern?
Die Teilnehmerinnen und Teilnehmer sind sich uneinig dar&#252;ber, in welcher Tiefe diese
Informationen insbesondere f&#252;r Verbraucherinnen und Verbraucher einsehbar sein m&#252;ssen. Es
erfolgen zwei unterschiedliche Herangehensweisen an die Frage:
1) Die Funktion eines KI-Systems zu verstehen, ist die Basis daf&#252;r, auch den Nutzen zu
verstehen.
2) Die Funktion eines KI-Systems muss nicht zwingend verstanden werden, um den
Nutzen zu verstehen.
&#8211; 773 &#8211; 
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
48 
Einige der Teilnehmenden vertreten die Meinung, dass Verbraucherinnen und Verbraucher
&#252;ber die allgemeinen technischen Funktionen einer KI aufgekl&#228;rt werden sollten, um auch
deren Nutzen verstehen zu k&#246;nnen. Dazu geh&#246;rten u.a. Informationen zu Datens&#228;tzen,
Entscheidungskriterien und Fehlerquoten. Da es unterschiedlichste KI-Methoden gebe, sollten die
Spezifika jeweils herausgestellt werden. Das folgende Zitat verdeutlicht beispielhaft, welche
Informationen von Unternehmen erhoben werden und dementsprechend auch den Nutzerinnen 
und Nutzern bei Bedarf zur Verf&#252;gung gestellt werden k&#246;nnten: 
&#8222;Die folgenden Informationen betrachten wir regelm&#228;&#223;ig bei der Entwicklung und 
Nutzung von KI Systemen: Welche Daten werden genutzt? (z. B. Metadaten zu den 
Datens&#228;tzen: Zeitbereich der Aufnahmen, Anzahl/Gr&#246;&#223;e der Daten, Datentypen, ggf. 
grobe Klassifizierung/Clustering der Daten) Beschreibung des Nutzens f&#252;r den 
Anwender, Beispiele f&#252;r Anwendungsf&#228;lle inkl. Vorbedingungen (Eingabewerte, 
Randbedingungen) und erwartetem Verhalten. Welche Risiken gibt es? (z. B. 
Beschreibung der Einschr&#228;nkungen: unter welchen Umst&#228;nden, Bedingungen ist 
eine Anwendung nicht vorgesehen/analysiert/erprobt) Welche Schw&#228;chen hat das 
System? Angaben zur Performance: Wie schnell und genau arbeitet das KI-System? 
Wie entscheidet das System (Erkl&#228;rbare KI)? Kann ich &#8222;Einspruch&#8220; gegen das 
System erheben?&#8220; (Benedikt B.) 
Die zweite Herangehensweise der Teilnehmenden legt hingegen nahe, dass es nicht
zwingend Informationen zur Funktionsweise einer KI brauche, um den Nutzen f&#252;r
Verbraucherinnen und Verbraucher verst&#228;ndlich zu machen. Vielmehr sehen viele Teilnehmende die
Notwendigkeit, positive praktische Erlebnisse mit KI zu erzeugen, um den Nutzen (und ggf. auch
die Funktion) erlebbar zu machen. Es wird auch der Vorschlag einer frei zug&#228;nglichen Online-
Plattform zum Testen von KI gemacht. Abstrakte Diskussionen w&#252;rden hingegen eher einer
gesellschaftlichen Aufkl&#228;rung entgegenwirken. Auch der Vergleich &#8222;Was kann ich mit KI, was 
ich ohne sie nicht k&#246;nnte bzw. was kann ich dank KI besser oder schneller als ohne sie?&#8220; 
(Fabian S.) k&#246;nne dabei unterst&#252;tzen, den Nutzen einer KI leicht verst&#228;ndlich zu machen. Um 
die Funktionsweise von KI zu verstehen, brauche es hingegen grundlegendes Wissen in
Statistik, Mathematik und Informatik auf Studiumsniveau, so eine Meinung. Sollte zuk&#252;nftig 
auch starke KI eingesetzt werden, stelle sich die Frage, ob Funktion und Nutzen &#252;berhaupt
noch verst&#228;ndlich dargelegt werden k&#246;nnten.
Frage 15: &#8222;Zu welchen Bereichen von KI sollte in Deutschland mehr geforscht 
werden?&#8220; 
Diese Frage besch&#228;ftigt sich konkret mit der Einstellung der Teilnehmerinnen und Teilnehmer
zur KI-Forschung in Deutschland. Es wurde danach gefragt, ob Forschungs- und
Entwicklungsergebnisse zu KI aus Deutschland bekannt seien bzw. welche Forschungs- und
Entwicklungsrichtungen gef&#246;rdert werden sollten. Es wurde angeregt, eine Einsch&#228;tzung des
Forschungs- und Entwicklungsstand zu KI in Deutschland im Vergleich zu anderen L&#228;ndern
abzugeben und sich dazu zu &#228;u&#223;ern, in welchen Bereichen mehr Forschung zu KI betrieben
werden sollte.
Die Teilnehmerinnen und Teilnehmer diskutieren schwerpunktm&#228;&#223;ig verschiedene
Forschungsfelder, zu denen ihrer Meinung nach in Deutschland verst&#228;rkt geforscht werden sollte.
Dabei zeigt sich ein Dissens bez&#252;glich des Stellenwertes von anwendungsorientierter (Indust-
&#8211; 774 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
49 
rie-)Forschung und Grundlagenforschung. Als besonders zentral identifizierte
Forschungsfelder werden Medizin und Gesundheit, Sicherheit und Datenschutz, Erkl&#228;rbare KI sowie 
Mensch-Maschine-Interaktionen genannt.
Forschungsbereiche
Den Teilnehmenden ist es wichtig, dass eine anwendungsorientierte Forschung zu KI
gef&#246;rdert wird. Insbesondere in Deutschland w&#252;rden im Bereich der Produkt- und
Produktionstechnologien Potenziale liegen, so die Meinung mehrerer Teilnehmender. Die regionale
Industrieforschung in Verbindung mit KI solle gef&#246;rdert werden, um nicht in internationale
Abh&#228;ngigkeiten zu geraten. Nur so k&#246;nne sich Deutschland weiterhin als Industriestandort und
wichtiger Exporteur von technischen Anlagen halten. Au&#223;erdem sollten die entwickelten KI-
L&#246;sungen auch f&#252;r mittelst&#228;ndische Unternehmen erschlie&#223;bar sein.  
Neben der Anwendungsorientierung sehen die Teilnehmenden auch Handlungsbedarf in der 
St&#228;rkung der Grundlagenforschung. Hier solle &#252;ber Machine-Learning-Systeme hinaus auch
an der starken KI, welche in Deutschland eher rudiment&#228;r beachtet werde, verst&#228;rkt geforscht 
werden. Es gibt jedoch unterschiedliche Meinungen hinsichtlich der Schwerpunktsetzung
zuk&#252;nftiger Forschungsvorhaben: Einige Teilnehmende empfinden es als zentral, den
technischen Fortschritt zu beschleunigen. Sie pl&#228;dieren z. B. f&#252;r die F&#246;rderung von
Quantencomputern und statistischer Ans&#228;tze. Andere Teilnehmende erachten es hingegen als notwendig,
u.a. zu Technikfolgenabsch&#228;tzung, Einteilung in Risikoklassen, Einsatz von KI im
Bildungssystem und Auswirkungen von KI auf die Arbeitswelt zu forschen. Hier stehen Investition in die
Erforschung und Optimierung des Zusammenspiels von Technik und Gesellschaft im Fokus.
Vor allem in den Feldern Gesundheit und Medizin sehen viele Teilnehmende noch
Forschungsbedarf. Im Gesundheitswesen solle KI f&#252;r das medizinische Personal unterst&#252;tzend 
bei Diagnose und Therapie eingesetzt werden, hier k&#246;nnen sich die Teilnehmenden z. B. die
vermehrte Forschung und den Einsatz von Expertensystemen (z. B. zum Katastrophenschutz
und Szenarienentwicklung bei Pandemien) vorstellen. Insbesondere im medizinischen Sektor
stelle sich jedoch auch die Frage nach der Verf&#252;gbarkeit entsprechender Daten, um die
Forschung vorantreiben zu k&#246;nnen:
&#8222;Die Forschung im medizinischen Sektor sollte mit hoher Priorit&#228;t weiter 
vorangetrieben und gef&#246;rdert werden. [&#8230;] Nicht nur die aktuellen Entwicklungen rund 
um das Coronavirus SARS-CoV-2 zeigen uns dabei, wie wichtig das Bereitstellen 
diagnostischer Daten, der internationale Austausch und Abgleich von Daten, sowie 
der Datenzugriff f&#252;r &#246;ffentliche und industrielle Forschung ist. Grundlagenforschung 
ist dabei ein wichtiger Bestandteil, aber alleine nicht ausreichend, um Angebote und 
L&#246;sungen zur medizinischen Versorgung der Gesellschaft zug&#228;nglich zu machen. 
Daher sollte der Industrie der Zugang zu Daten f&#252;r Forschung und Entwicklung 
digitaler Gesundheitsanwendungen und Versorgungsinnovationen erleichtert und 
gef&#246;rdert werden. Deutschland kann und sollte hierbei als Forschungs- und 
Industriestandort im medizinischen Sektor auch in internationalen Diskussionen, 
Forschungs- und Entwicklungsprojekten (auf EU-Ebene und &#252;ber die EU hinaus) die 
Entwicklung vorantreiben und mitbestimmen, in welche Richtung diese geht.&#8220; 
(Katharina)
&#8211; 775 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
50 
Weiterhin wird im Kontext Gesundheit auch die Forschung an assistiven Technologien f&#252;r
kranke oder &#228;ltere Menschen sowie f&#252;r Menschen mit Behinderung und psychischen
Erkrankungen gew&#252;nscht. Als Beispiel wird die Entwicklung von Service-Robotern f&#252;r die Pflege
genannt. Dar&#252;ber hinaus sei auch ein Einsatz in der Sozialen Arbeit denkbar.
Die Teilnehmerinnen und Teilnehmer diskutieren auch die Themen Sicherheit und
Transparenz im Kontext von Forschung. Da KI eine sicherheitspolitische Herausforderung darstelle,
solle dazu geforscht werden, wie KI sicherer gemacht werden kann. Es wird vorgeschlagen, 
dazu zu forschen, wie ein KI-T&#220;V gestaltet werden k&#246;nne, um KI-Systeme beherrschbar zu
halten. Auch algorithmenvermittelte Diskriminierung m&#252;sse erforscht werden: Es brauche
soziotechnische Methoden, um solche Diskriminierung aufzudecken, und Forschung, um
Gegenma&#223;nahmen wie z. B. die Erstellung &#8222;diskriminierungsfreier&#8220; Datens&#228;tze zu entwickeln. 
Auch das Thema Datenschutz wird in diesem Zusammenhang angesprochen. Es bestehe
Forschungsbedarf hinsichtlich der Bereitstellung m&#246;glichst gro&#223;er Datenmengen auf der einen
und der gleichzeitigen Wahrung der Vertraulichkeit dieser Daten auf der anderen Seite. Das
f&#246;derierte Lernen (dezentrales Machine Learning), bei dem echte Nutzungsdaten
verschl&#252;sselt zum Training verwendet werden, k&#246;nne hier eine L&#246;sung darstellen. Auch die Forschung
zu synthetischen Daten m&#252;sse gef&#246;rdert werden. So k&#246;nnten datenschutzfreundlich
algorithmische Systeme mit aus originalen Datens&#228;tzen generierten synthetischen Daten trainiert
werden. 
Die Teilnehmerinnen und Teilnehmer sehen au&#223;erdem Forschungsbedarf bei Explainable AI
(Erkl&#228;rbare KI). KI-Systeme m&#252;ssten erkl&#228;rbar und jederzeit nachvollziehbar sein. Dazu
m&#252;sse die Forschung noch intensiviert werden.
Auch die interdisziplin&#228;re Forschung zur Mensch-Maschine-Interaktion solle vorangetrieben 
werden, insbesondere die Forschung zum Umgang mit teilautomatisierten 
Entscheidungsprozessen (algorithmische Entscheidungsunterst&#252;tzungssysteme), wo aktuell
noch rechtliche L&#252;cken best&#252;nden und Fragen zur Wahrung von menschlicher Autonomie
noch unbeantwortet seien. Die Forschung k&#246;nne sich hierbei au&#223;erdem spezifischen Themen
wie z. B. KI Mediatoren, die als Vermittler zwischen Menschen (z. B. als Friedensstifter)
auftreten k&#246;nnen, widmen. 
Weiterhin w&#252;nschen sich die Teilnehmenden mehr Forschung zum autonomen Fahren, zur
F&#246;rderung des Umweltschutzes sowie zum besseren Verst&#228;ndnis von Tieren und Pflanzen
mithilfe von KI. 
Handlungsbedarfe und Rahmenbedingungen aus Sicht der Teilnehmenden 
Als Rahmenbedingungen f&#252;r die Intensivierung der Forschung und Entwicklung zu KI nennen
die Teilnehmenden die Notwendigkeit von weniger energieintensiven KI-Systemen. Im
Hinblick auf die Energiewende seien derzeitige Systeme nicht tragbar. Die Entwicklung eigener 
Hardware stelle zudem eine zentrale Stellschraube dar, um die Forschung und Entwicklung
nicht von internationalen Abh&#228;ngigkeiten einschr&#228;nken zu lassen und konkurrenzf&#228;hig zu
bleiben. Andernfalls m&#252;sse auf veraltete Hardware anderer Unternehmen zur&#252;ckgegriffen werden,
wodurch wiederum Fortschritte in der Entwicklung von Algorithmen nur begrenzt m&#246;glich 
seien. 
&#8222;Die Hardware der n&#228;chsten Generation (Stichwort Tensor Cores) wird derzeit von 
den Laboren von Google und NVIDIA entwickelt. Diese Firmen haben damit eigene 
Rechenzentren aufgebaut und haben dementsprechend einen substantiellen Vorteil
&#8211; 776 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
51 
gegen&#252;ber Forschungseinrichtungen in Deutschland, die Rechenkapazit&#228;t einkaufen 
m&#252;ssen oder in eigenen Rechenzentren Hardware &#8218;von der Stange&#8216; verwenden. Mit 
veralteter Hardware k&#246;nnen deutsche Forschungseinrichtungen aber den Anschluss 
nicht halten. Diese ist zu teuer, zu langsam, verbraucht zu viel Strom, und ist damit 
auch vom umweltpolitischen Aspekt nicht vertretbar.&#8220; (EricP.) 
Bei der Entwicklung und Forschung zu KI solle au&#223;erdem m&#246;glichst auf einen
gesellschaftlichen Konsens geachtet werden, statt durch wenige Akteure Fakten zu schaffen. So sollten
zum Beispiel, wie auch im Wei&#223;buch zur K&#252;nstlichen Intelligenz der Europ&#228;ischen
Kommission empfohlen, zivilgesellschaftliche Organisationen in die Forschung zu KI einbezogen
werden: 
&#8222;Gemeinwohlorientierte und nachhaltige/zukunftsf&#228;hige KI-Anwendungen unter 
Beteiligung von Organisationen der Zivilgesellschaft, sowohl was die 
Themensetzung als auch den Projektfortschritt anbelangt [, f&#246;rdern].&#8220; (maschei) 
Die Schaffung eines rechtlichen Rahmens sei laut der Teilnehmenden wichtig, wenn die
Forschung und Entwicklung von KI weiter vorangetrieben werden solle. Es sei unbedingt
notwendig, die derzeitige Rechtslage anzupassen, denn momentan seien Entwicklungen im Bereich
KI nicht rechtlich gesch&#252;tzt. Dies hemme Unternehmen, in KI zu investieren. Neben der
Entwicklung rechtlicher Standards seien auch ethische Standards eine notwendige Bedingung 
f&#252;r eine vermehrte KI-Forschung. So solle KI beispielsweise immer nachweislich beherrschbar
bleiben.
3.5 Themenfeld &#8222;Weitere Anregungen zu KI&#8220;
Frage 16: &#8222;Welche Forderungen oder Anregungen haben Sie dar&#252;ber hinaus 
zum Einsatz von KI in Deutschland?&#8220;
Als Erg&#228;nzung zu den vorgegebenen Diskussionsfragen wurde den Teilnehmerinnen und
Teilnehmern die M&#246;glichkeit gegeben, weitere Forderungen, Anregungen und Fragen zu nennen,
die durch die anderen Themen noch nicht abgedeckt wurden, aber ihrer Meinung nach noch
genannt bzw. diskutiert werden sollten. 
Es kristallisierten sich mehrere Schwerpunkte in den Diskussionen zu dieser Frage heraus,
welche bereits in den anderen Themenfeldern genannt wurden. Die erneute Nennung der
Aspekte betont deren Wichtigkeit f&#252;r die Teilnehmerinnen und Teilnehmer, weshalb sie hier in
Kurzform noch einmal (entlang der H&#228;ufigkeit der Nennungen) zusammengefasst sind:
Bei der Entwicklung von KI sollen nicht politische, milit&#228;rische oder
marktwirtschaftliche Interessen die treibenden Kr&#228;fte sein, sind sich die meisten Teilnehmenden
einig. Stattdessen solle das menschliche Leben und dessen Unversehrtheit
stets die h&#246;chste Priorit&#228;t haben.
Auf nationaler Ebene solle die Entwicklung von KI st&#228;rker gef&#246;rdert werden,
dabei solle sich an der internationalen Entwicklung orientiert werden. Die
Zusammenarbeit auf EU-Ebene m&#252;sse gest&#228;rkt werden, um international anschlussf&#228;hig zu
bleiben bzw. eine Vorreiterrolle bei Entwicklung und Vertrieb von KI einnehmen zu
k&#246;nnen.
 Klare Grenzen f&#252;r die Entwicklung und den Einsatz von KI seien wichtig, aber
die Regulierungen d&#252;rften auch nicht zu stark sein, damit Innovationen nicht
unterbunden werden. Hier stehen sich ganz deutlich Teilnehmerinnen und Teilnehmer
beider Standpunkte in der Diskussion gegen&#252;ber.
&#8211; 777 &#8211; 
-
-
-
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
52 
Datenschutz und -sicherheit seien essentiell, und es gelte, strenge
Anforderungen an Transparenz und Anonymisierung zu erf&#252;llen.
 Die Bestimmung von Rechten und Pflichten (u.a. hinsichtlich
Verantwortlichkeiten, Auskunftspflicht, Haftung, Schadenersatzpflicht) m&#252;sse vorangetrieben und 
bestehende L&#252;cken hierbei geschlossen werden.
 Eine St&#228;rkung der gesellschaftlichen Akzeptanz von KI m&#252;sse stattfinden, u.a.
denkbar durch den Einsatz Erkl&#228;rbarer KI, die Nutzung von KI in Beh&#246;rden
(St&#228;rkung der Vorreiterrolle des Staates), mehr Bildung sowie Diskurse mit
verschiedensten gesellschaftlichen Zielgruppen.
 Eine St&#228;rkung der Grundlagen- und anwendungsorientierte Forschung zu KI
(z. B. Chip-Technologie, starke KI, Medizin und Gesundheit, Mobilit&#228;t) sowie der
bislang wenig beachteten Schnittstelle von Kunst und KI m&#252;sse erfolgen.
&#8211; 778 &#8211; 
-
-
-
-
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
53 
4 ZUSAMMENFASSUNG
Insgesamt registrierten sich 260 Personen f&#252;r die Online-Beteiligung der Enquete-Kommission
K&#252;nstliche Intelligenz. Vom 10. M&#228;rz bis zum 19. April 2020 nahmen 130 Personen aktiv an
der Online-Beteiligung teil und verfassten insgesamt 680 Kommentare zu verschiedenen
Fragestellungen aus den Bereichen Vertrauen und Transparenz, KI in Beruf und Alltag,
Datennutzung und Datenschutz sowie Wissen und Forschung. Die offenen Fragen luden die
Teilnehmenden dazu ein, eigene Perspektiven auszuf&#252;hren. Enthalten sind Meinungen,
Empfehlungen, W&#252;nsche und kritische Anmerkungen in Bezug auf KI. Der offene Aufbau der Online-
Beteiligung bewirkte, dass sich die Ergebnisse nicht (wie z. B. bei einer quantitativen Umfrage)
statistisch quantitativ auswerten lassen. Die Aussagen sind sehr reichhaltig und lassen sich 
nur bedingt zu Oberthemen zusammenfassen, ohne die Spezifizit&#228;t des Beitrags
auszublenden. Wohl aber k&#246;nnen Argumentationsmuster, thematische Schwerpunkte und
Meinungstendenzen in der Diskussion ausgemacht werden. 
Die Teilnehmerinnen und Teilnehmer der Online-Beteiligung der Enquete-Kommission
K&#252;nstliche Intelligenz zeigen generell eine konstruktive Einstellung gegen&#252;ber der Anwendung und 
(Weiter-)Entwicklung von KI. Sie stehen KI im Allgemeinen st&#228;rker positiv als negativ
gegen&#252;ber und machen viele Chancen der Technologie aus. Gleichzeitig gelte es, m&#246;gliche Risiken
bereits im Vorfeld zu erkennen und fr&#252;hzeitig einzud&#228;mmen sowie sich entstehenden
Herausforderungen aktiv zu stellen. Die positive Haltung gegen&#252;ber KI ist also stets an
Rahmenbedingungen gekn&#252;pft, die es von politischer, wissenschaftlicher und wirtschaftlicher Seite
aufzustellen und einzuhalten gelte, um keine unerw&#252;nschten Wirkungen von KI auf die
Gesellschaft zu provozieren.
KI &#8211; ein Begriff, viele Verst&#228;ndnisse
Immer wieder zeigt sich in der Online-Beteiligung, dass unter KI verschiedene Verfahren
verstanden werden: Es wird zwischen gro&#223;er und kleiner KI unterschieden, und nicht alle
Teilnehmenden sind der Meinung, dass die schwache KI eine KI im intendierten oder eigentlichen
Sinne darstelle, weil eine schwache KI nur vorher festgelegte Aufgaben l&#246;sen, neue Probleme
aber nicht bearbeiten k&#246;nne. Au&#223;erdem w&#252;rden algorithmenbasierte Anwendungen, die
teilweise nur einfachere statistische Auswertungsverfahren nutzen, f&#228;lschlicherweise bzw. zu
Verkaufszwecken unter dem Begriff KI subsummiert. 
Es bedarf eines gesamtgesellschaftlichen Diskurses und mehr Bildung 
zu KI 
Aufgrund der bestehenden Vieldeutigkeit ist laut den Teilnehmerinnen und Teilnehmern der
Online-Beteiligung eine Sch&#228;rfung des Begriffs und des Verst&#228;ndnisses von KI
beziehungsweise unterschiedlichen Arten von KI notwendig, um unterschiedliche Ph&#228;nomene (z. B. 
starke oder schwache KI), Anwendungsbereiche und Szenarien differenzierter betrachten und
bewerten zu k&#246;nnen: Es lie&#223;e sich anschlie&#223;end zielf&#252;hrender diskutieren, welche
Hoffnungen, Bef&#252;rchtungen und Handlungsbedarfe sich ausmachen lassen. Hierf&#252;r bed&#252;rfe es eines
breiten gesamtgesellschaftlichen Diskurses.
Die verschiedenen Definitionsans&#228;tze, Anwendungsbereiche und Funktionsweisen von KI
machen deutlich, wie komplex die Prozesse der Verst&#228;ndnisbildung und des Lernens von
Umgangsweisen mit KI sind. Vermehrte Bildung f&#252;r verschiedene Zielgruppen stellt f&#252;r die
Teilnehmenden der Online-Beteiligung daher ein zentrales Kriterium dar, um neben Expertinnen
&#8211; 779 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
54 
und Experten auch B&#252;rgerinnen und B&#252;rgern einen m&#252;ndigen Umgang mit KI zu erm&#246;glichen
und ihr Vertrauen in die Technologie zu st&#228;rken. Neben schulischer und universit&#228;rer Bildung
zu KI solle auch die berufliche Weiterbildung und Erwachsenenbildung im Allgemeinen
gest&#228;rkt werden. Hier sollen niedrigschwellige, kostenlose und nicht zugangsbeschr&#228;nkte
Bildungsangebote verschiedene Zielgruppen in ihren jeweiligen Lebenssituationen abholen.
Auch der Einsatz f&#252;r ein EU-weites Bildungsangebot zu KI solle forciert werden. Neben
klassischen Bildungstr&#228;gern sollen auch die Medien vermehrt dazu beitragen, dass eine sachliche
und gesamtgesellschaftliche Debatte gef&#252;hrt werden k&#246;nne, so die Meinung der
Teilnehmenden.
KI kann Meinungsbildung beeinflussen und Diskriminierung verst&#228;rken
KI selbst wird in Bezug auf die gesellschaftliche Meinungsbildung eine zweischneidige Rolle 
zugeschrieben: Einerseits k&#246;nne sie dazu beitragen, dass Informationen dem Individuum
beispielsweise durch Filterung aufgrund bestimmter Kriterien einfacher zug&#228;nglich werden.
Andererseits berge diese individualisierte Bereitstellung von Informationen die Problematik des
Entstehens von Filterblasen und Echokammern: Das Verst&#228;rken pers&#246;nlicher Sichtweisen
ohne den Austausch mit anderen Perspektiven und Meinungen kann Dystopien befeuern und 
langfristig einen gesamtgesellschaftlichen Diskurs unm&#246;glich machen, so die Bedenken der
Teilnehmenden. Au&#223;erdem k&#246;nnte, so eine h&#228;ufig vertretene Bef&#252;rchtung, KI dazu beitragen,
dass Diskriminierungen verst&#228;rkt werden, weil die Algorithmen stereotype Annahmen zur
Grundlage n&#228;hmen. Die von KI getroffenen Entscheidungen spiegelten diese Stereotype,
verfestigten und reproduzierten sie vielfach, besonders wenn die Entscheidungen nicht hinterfragt
w&#252;rden. M&#246;gliche Potentiale von KI, Diskriminierungen zu verringern, werden in der Online-
Beteiligung dagegen weniger thematisiert. 
Entlastung durch versus Abh&#228;ngigkeit von KI
Einen zentralen Aspekt der Diskussionen der Online-Beteiligung stellt der Wandel der Rolle
des Menschen durch den vermehrten Einsatz von KI dar: KI f&#252;hre langfristig zu tiefgreifenden
Ver&#228;nderung der Arbeitswelt und bringe k&#246;rperliche und zeitliche Entlastung f&#252;r
Arbeitnehmerinnen und Arbeitnehmer mit sich. Gleichzeitig w&#252;rden Arbeitspl&#228;tze durch die Technologie
obsolet werden und es m&#252;ssen Alternativen zu derzeitigen Berufsfeldern, Arbeitszeitmodellen
und sozialen Sicherungssystemen entwickelt werden.
Dem Vorteil der Entlastung des Menschen im beruflichen sowie privaten Umfeld stehe immer 
auch das Risiko des Verlustes von Kontroll- und Entscheidungsm&#246;glichkeiten gegen&#252;ber: Die
Teilnehmenden benennen hier die Herausforderung, KI nicht zu einer undurchschaubaren
&#8222;Black Box&#8220;-Technologie werden zu lassen, deren Entscheidungen nicht mehr von Menschen 
nachvollzogen werden k&#246;nnen. Ein zentrales Argument der Teilnehmenden ist, dass KI-
Entscheidungen niemals zuungunsten des Menschen getroffen werden d&#252;rfen. Daher bed&#252;rfe es
Standards und Sicherungssysteme, um sich auf durch die KI gef&#228;llte Entscheidungen
verlassen zu k&#246;nnen und beispielweise Diskriminierungen durch KI-Systeme vorzubeugen bzw.
diese feststellen zu k&#246;nnen.
Insbesondere im Bereich Medizin und Gesundheit wird ein hohes
Potential durch die Anwendung von KI gesehen
Die meisten Vorteile von KI sehen die Teilnehmenden in den Bereichen Medizin und
Gesundheit. Insbesondere die medizinische Forschung k&#246;nnte von KI profitieren und zur Entwicklung
neuer diagnostischer sowie therapeutischer Verfahren beitragen. Eine KI-gest&#252;tzte Medizin
&#8211; 780 &#8211;
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
55 
k&#246;nne in viel gr&#246;&#223;erem Ma&#223;e Daten automatisiert vergleichen und so Muster erkennen, die
mit herk&#246;mmlichen Methoden nicht aufgedeckt w&#252;rden. Auch eine Medizin, die auf die
Patientin oder den Patienten abgestimmt ist, lie&#223;e sich mit KI leichter implementieren. Neue assistive 
Systeme k&#246;nnten zudem Menschen mit Pflegebedarf zugutekommen. So k&#246;nne auch das
Pflegepersonal entlastet werden. Damit KI die Vorteile in Medizin und Gesundheit entfalten
k&#246;nne, m&#252;ssten Anonymisierungen und Pseudonymisierungen einfacher umsetzbar werden,
denn so k&#246;nne das Teilen von sensiblen personenbezogenen Daten erleichtert werden. Als 
herausfordernd sehen die Teilnehmenden der Online-Beteiligung den potenziellen Umstand,
dass &#196;rztinnen und &#196;rzte in ihrer Kompetenz durch KI abgel&#246;st werden k&#246;nnten und
Entscheidungen zu wenig am einzelnen Menschen orientiert, sondern nur noch technologiebasiert
getroffen k&#246;nnten. 
Arbeit und Produktion 
Allgemein biete KI gute M&#246;glichkeiten, Arbeitsprozesse aller Art zu optimieren. Besonders f&#252;r
systematische Arbeitsabl&#228;ufe sowie verschiedenste Produktionsprozesse werden die
Potenziale von KI in der Online-Beteiligung als vielversprechend bewertet. Monotone und
zeitaufwendige T&#228;tigkeiten k&#246;nnten durch KI-Anwendungen &#252;bernommen werden, sodass den
Arbeitnehmerinnen und Arbeitnehmern mehr Zeit zum Verrichten kreativer und sozialer
Aufgaben bliebe. Auch materielle Ressourcen k&#246;nnten eingespart werden. KI k&#246;nne dabei auch als
Partner in Arbeitsabl&#228;ufe integriert werden und z. B. als Assistenzsystem
Entscheidungsoptionen anbieten, aber sollte in Abh&#228;ngigkeit zu Branche und Aufgabenziel nicht unbedingt
eigenst&#228;ndig Entscheidungen treffen. Dennoch bilden wegfallende Arbeitspl&#228;tze, unabh&#228;ngig
vom Qualifizierungsgrad, die bef&#252;rchtete Kehrseite der Prozessoptimierungen. Dieser
Herausforderung gelte es sich fr&#252;hzeitig zu stellen und den Wandel zu gestalten, um negative
Auswirkungen zu minimieren.
KI in Alltag und Freizeit
Die Teilnehmenden der Online-Beteiligung benennen f&#252;r die Bereiche Alltag und Freizeit viele
Vorteile durch die Unterst&#252;tzung von KI-Systemen als pers&#246;nliche Assistenten (z. B.
Sprachassistenz, Bildbearbeitung, Reisebuchung, Haushaltsf&#252;hrung). Sie empfinden den Einsatz von 
KI insbesondere in Bereichen wie Finanzplanung, Umgang mit &#196;mtern und Arbeitgebern als 
Komfortzuwachs. Hier k&#246;nne zuk&#252;nftig viel an Formularen und stetigen Aktualisierungen von 
Daten sowie &#8218;Papierkram&#8216; eingespart werden und gleichzeitig z. B. zeitaufwendige Prozesse
der Antragsstellung durch KI vereinfacht oder gar &#252;bernommen werden. Die Teilnehmenden
sehen aber auch die Herausforderung, dass sich Nutzerinnen und Nutzer immer mehr
Informationen und Handlungsempfehlungen von der KI vorgeben lassen und gewisserma&#223;en das
kritische Denken, das Entdecken neuer Interessen und Orte sowie den Wunsch nach sozialen
Interaktionen aufgrund einer KI, die immer mehr F&#228;higkeiten hat und menschlicher anmutet,
aufgeben.  
Mobilit&#228;t und Umwelt 
Weitere zentrale Bereiche des Einsatzes von KI stellen f&#252;r die Teilnehmenden der Online-
Befragung Mobilit&#228;t und Umwelt dar. So spiele KI eine tragende Rolle bei der Entwicklung 
nachhaltiger Energieversorgungskonzepte. Eine Herausforderung stellt gleichzeitig dar, dass
KI selbst h&#246;chst energieintensiv ist. Es brauche daher Investitionen in die Entwicklung weniger 
energieverbrauchender KI-Systeme. Als positiv wird hervorgehoben, dass KI zur intelligenten
Steuerung von Verkehrsstr&#246;men insbesondere in St&#228;dten beitragen k&#246;nne und dass KI-
basierte Fahrassistenzsysteme die Vermeidung von Fehlern im Stra&#223;enverkehr bef&#246;rderten.
&#8211; 781 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
56 
Auch eine Verbesserung der Navigation beim Autofahren und bei der Nutzung der &#246;ffentlichen
Verkehrsmittel wird sich von den Teilnehmenden erhofft. Das autonome Fahren stelle
zuk&#252;nftig zudem eine Chance f&#252;r die Bef&#246;rderung von bislang weniger mobilen Personen aber auch
von G&#252;tern dar. Das Ziel der &#8218;Smart Cities&#8216; im Sinne von technisch, wirtschaftlich und sozial
nachhaltigen St&#228;dten, k&#246;nne durch den Einsatz von KI erreicht werden.  
St&#228;rkere Regulierung von KI und deren effiziente Durchsetzung sind
notwendig 
Die Online-Beteiligung spiegelt, dass eine neue, sich dynamisch ver&#228;ndernde Technologie,
die aller Voraussicht nach in verschiedenste Lebensbereiche Einzug halten wird, eines
angemessenen Rechtsrahmens bedarf. Datensicherheit sei eine grundlegende Bedingung f&#252;r die
Verwendung insbesondere personenbezogener Daten und m&#252;sse auch ohne Ausnahmen
umgesetzt werden. F&#252;r viele Teilnehmende ist es wichtig, dass KI sich am Gemeinwohl orientiere
und nicht an gewinnorientierten Zwecken. Es gelte, Diskriminierungen durch KI, z. B. bedingt
durch unausgewogene Trainingsdaten, zu verhindern. Die DSGVO sei eine gute Grundlage, 
doch m&#252;sse sie auch verantwortungsvoll von den betreffenden Unternehmen umgesetzt und
dies in geeignetem Rahmen &#252;berpr&#252;ft werden k&#246;nnen. In diesem Zusammenhang wird auch
eine effizientere Durchsetzung bestehender und zuk&#252;nftiger Regulierungen inklusive
entsprechender Sanktionen gefordert. Die Klassifizierung von Risiken sei f&#252;r die Regulierungen
ebenfalls sinnvoll, weil durch sie abgesch&#228;tzt werden k&#246;nne, welche Sch&#228;den mit welcher
Wahrscheinlichkeit eintreten k&#246;nnten.
Mehr Transparenz f&#252;r die Vertrauensbildung in KI &#8211; z. B. durch
Risikoeinsch&#228;tzungen und G&#252;tesiegel
Das Thema Transparenz kam in der Online-Beteiligung immer wieder auf, weil durch sie 
grundlegende Herausforderungen des Einsatzes von und des Umgangs mit KI gel&#246;st werden
k&#246;nnten. So soll Transparenz hinsichtlich der Funktionsweise und der Zwecke einer KI dazu
f&#252;hren, dass Entscheidungen auch durch die Nutzerinnen und Nutzer nachvollzogen werden
k&#246;nnen und im Zweifel auch Einspruch gegen die Art und Weise der Erhebung und
Verarbeitung der Daten m&#246;glich ist. Dazu geh&#246;re auch, dass z. B. die Datenschutzabfragen auf
Webseiten nutzerfreundlich im Sinne von leicht verst&#228;ndlich und weniger zeitintensiv gestaltet
werden. G&#252;tesiegel k&#246;nnen zus&#228;tzlich dazu beitragen, dass Verbraucherinnen und Verbraucher
schnell erkennen, welche Qualit&#228;t die jeweilige KI-Anwendung hat und welche Risiken
gegebenenfalls von ihr ausgehen. 
Die Einsch&#228;tzungen von Risiken und G&#252;te von KI-Anwendungen hielten die Teilnehmenden
gr&#246;&#223;tenteils f&#252;r sinnvoll, auch wenn sie auf Schwierigkeiten, wie z. B. die Bewertung der G&#252;te
zu einem bestimmten Zeitpunkt bei sich stetig weiter entwickelnden KI-Anwendungen,
hinwiesen. Diese Dynamik im technischen Wandel allgemein und in kontinuierlich lernenden
Systemen k&#246;nne die Aussagekraft von G&#252;tesiegeln beeintr&#228;chtigen. Auch reiche ein G&#252;tesiegel
allein nicht aus, vielmehr br&#228;uchte es daneben Mindeststandards sowie Verbote und
Sanktionen.
Als Kriterien f&#252;r ein G&#252;tesiegel sollte zum Beispiel die Risikoklasse angegeben werden, und 
auch ethische Standards (z. B. hinsichtlich Diskriminierung) sollten explizit im G&#252;tesiegel
aufgegriffen werden. Ebenso kann Transparenz selbst ein G&#252;tekriterium bilden, weil sie
gew&#228;hrleistet, dass potenzielle Auswirkungen &#252;berpr&#252;ft werden k&#246;nnen und so f&#252;r Nutzerinnen und
Nutzer offenlegt, wie die jeweilige KI-Anwendung funktioniert.
&#8211; 782 &#8211;
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
57 
In die Entwicklung von Risikoklassifizierungen und G&#252;tesiegeln sollten Akteure aus
unterschiedlichen Bereichen einbezogen werden, um sicherzustellen, dass vielf&#228;ltige Perspektiven
bei der Auswahl der Kriterien mitbetrachtet werden. Au&#223;erdem sollte die Einsch&#228;tzung der
Risiken einer demokratischen Kontrolle unterliegen.
Datensicherheit und Datenkontrolle wichtig f&#252;r das Teilen von Daten
Hinsichtlich des Teilens der pers&#246;nlichen Daten &#228;u&#223;ern die Teilnehmenden eher Bereitschaft,
ihre Daten zu teilen, wenn diese entweder dringend notwendig z. B. f&#252;r Verwaltungsvorg&#228;nge
sind oder aber gemeinn&#252;tzigen oder Forschungszwecken (insbesondere medizinische
Forschung) dienen, weniger, wenn diese von Akteuren der Wirtschaft abgefragt werden. Bei
einigen hat sich durch die bereits bestehende Praxis des Sammelns von pers&#246;nlichen Daten (z. B.
durch Google oder Facebook) schon eine h&#246;here Toleranz f&#252;r das Teilen von Daten
eingestellt. Wichtige Voraussetzungen f&#252;r die Bereitschaft, pers&#246;nliche Daten zu teilen, seien die
sichere Speicherung der Daten sowie die Kontrolle und &#220;bersicht &#252;ber die geteilten Daten.
Dies beinhalte die explizite Zustimmung und das Recht auf Widerruf inklusive einer
nutzerfreundlicheren Umsetzung dieser Optionen, aber auch M&#246;glichkeiten einer besseren &#220;bersicht
dar&#252;ber, welche Daten man bereits mit wem geteilt hat.
Deutschland muss bei der Forschung zu KI Vorreiterrolle &#252;bernehmen 
und Abh&#228;ngigkeit von anderen L&#228;ndern verhindern 
Im Zeitalter von Globalisierung und vernetzten Gesellschaften sei technischer Wandel
ebenfalls als ein globales Ph&#228;nomen zu betrachten. Die Forschung zu und Entwicklung von KI seien 
eingebettet in die weltweit stattfindenden Entwicklungen, w&#252;rden jedoch h&#228;ufig nur auf
nationaler Ebene betrachtet, so die Meinung der Teilnehmenden der Online-Beteiligung. Global
agierende Konzerne w&#252;rden zentrale Rollen bei der Weiterentwicklung der KI-Technologie
einnehmen, w&#228;hrend Staaten wie Deutschland mit der rasanten Entwicklung vor allem im
Bereich der Hardware-Entwicklung f&#252;r KI nicht so recht Schritt halten und dadurch in
innovationshemmende Abh&#228;ngigkeiten geraten w&#252;rden. In der Online-Beteiligung wird immer wieder
darauf hingewiesen, dass Deutschland in Zusammenarbeit mit den EU-Staaten eine
internationale Vorreiterrolle in Forschung und Entwicklung anstreben sollte m&#246;glicherweise mit dem
Alleinstellungsmerkmal von qualit&#228;tsgepr&#252;ften und ethisch vertretbaren KI-Anwendungen.
Neben dem Ausbau der Grundlagenforschung solle vermehrt auch die anwendungsbezogene
Forschung und insbesondere die Industrieforschung gef&#246;rdert werden. Hier habe Deutschland
gro&#223;es Potenzial, das Know-How auszubauen und wichtiger Technologie-Exporteur zu
werden.
&#8211; 783 &#8211; 
&#8211;
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
1 
ANHANG
Die Fragen der Online-Beteiligung im &#220;berblick 
Themenfeld 1
&#8222;Vertrauen und 
Transparenz&#8220; 
Wie muss KI
gestaltet werden,
damit sie
gesellschaftlich
akzeptiert wird? 
Vertrauen Sie KI? 
Wie soll der
Einsatz von KI
sichtbar gemacht
werden? 
1) Welche Hoffnungen und Bef&#252;rchtungen verbinden Sie mit
dem Einsatz von KI?
Auf welchen Gebieten k&#246;nnte KI helfen, unser Zusammenleben zu 
verbessern?
Welche dringenden Probleme der Menschheit k&#246;nnten Ihrer
Meinung nach mit KI gel&#246;st werden? 
Auf welchen Gebieten sollte der Staat Ihrer Meinung nach
regulierend eingreifen?
2) Inwieweit verlassen Sie sich auf Produkte oder
Anwendungen, die mit KI arbeiten?
In vielen Lebensbereichen kann KI menschliche Arbeit unterst&#252;tzen 
oder ersetzen. Vertrauen Sie eher den Ergebnissen von Menschen 
oder von KI-Systemen?
Wie tolerant sind Sie gegen&#252;ber Fehlern von KI-Systemen?  
In welchen Bereichen w&#252;rden Sie einem KI-System eher Fehler
zugestehen, in welchen nicht?
3) Inwiefern w&#228;re es f&#252;r Sie hilfreich, wenn KI-Systeme auf
m&#246;gliche Risiken hin eingesch&#228;tzt und klassifiziert werden?
Wenn ja, wer sollte diese Pr&#252;fung &#252;bernehmen?
Wie sollte eine solche Klassifizierung gestaltet sein? 
Inwiefern w&#228;re eine entsprechende Kennzeichnung sinnvoll? 
Inwiefern sollte der Einsatz von KI f&#252;r bestimmte Anwendungen
ausgeschlossen werden? 
4) Wie beurteilen Sie die Einf&#252;hrung von Standards f&#252;r KI-
Systeme, z. B. eines anwendungsspezifischen G&#252;tesiegels?
Standards oder G&#252;tesiegel zeichnen Anwendungen und Produkte
aus, die festgelegten Qualit&#228;tskriterien entsprechen. W&#252;rde ein
G&#252;tesiegel Ihr Vertrauen in KI erh&#246;hen?
Welche Informationen erwarten Sie von einem G&#252;tesiegel?
&#8211; 784 &#8211;
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
2 
Durch wen sollte ein solches G&#252;tesiegel vergeben werden? 
Themenfeld 2
&#8222;Beruf und 
Alltag&#8220; 
Wo begegnet uns 
KI im Alltag und 
wie wollen wir 
diese nutzen?  
Welche Rolle soll 
der Einsatz von KI 
z. B. im Internet 
spielen? 
5) Welche Ver&#228;nderungen erwarten Sie durch den
zunehmenden Einsatz von KI in der Zukunft?
Was w&#228;ren f&#252;r Sie pers&#246;nlich die wichtigsten Verbesserungen, was 
die gr&#246;&#223;ten Risiken durch den KI-Einsatz?
6) In welchen pers&#246;nlichen Lebensbereichen w&#252;nschen Sie sich
eine (st&#228;rkere) Anwendung von KI?
Auf welchen Gebieten k&#246;nnte KI helfen, Ihr Leben zu verbessern 
(pers&#246;nlicher Nutzen)? 
K&#246;nnen Sie konkrete Beispiele nennen?  
Wann denken Sie, wird diese Verbesserung verf&#252;gbar sein?  
7) Wie beurteilen Sie es, dass Informationen im Internet auf die 
nutzende Person zugeschnitten werden?
Informationsinhalte (z. B. Suchmaschinenergebnisse, Vorschl&#228;ge zu
Inhalten und Nachrichten) k&#246;nnen mittels KI-gest&#252;tzter Algorithmen
pers&#246;nlichen Profilen entsprechend angepasst werden. Nutzerinnen 
und Nutzern erhalten nicht dieselben Informationen, sondern werden 
individuell informiert. Welche Vorteile und welche Nachteile sehen 
Sie darin? 
8) Welche Vor- und Nachteile sehen Sie derzeit im
Zusammenhang mit dem Einsatz von KI im privaten und beruflichen
Umfeld?
In vielen Bereichen unterst&#252;tzt oder ersetzt KI bereits menschliche 
Arbeit, z. B. bei der Diagnose von Krankheiten, autonom fahrenden 
Bussen oder Autos oder bei der Bewerberauswahl. Wie wirkt sich 
das bereits auf ihr Leben aus?
Themenfeld 3
&#8222;Datennutzung 
und 
Datenschutz&#8220;
Wof&#252;r d&#252;rfen
welche Daten von KI 
verwendet
werden?  
9) Mit wem sind Sie bereit, Ihre Daten zu teilen, und warum (jetzt
und in Zukunft)?
Dies betrifft personenbezogene und nicht-personenbezogene Daten
f&#252;r z. B. durch staatliche Stellen, private und &#246;ffentliche
Unternehmen (Arbeitgeber, Kliniken, Verkehrsbetriebe) oder auch
gemeinn&#252;tzige Organisationen, aber auch die Bildung von Datenpools
(zwischen Unternehmen, Forschungseinrichtungen etc.).
10) F&#252;r welche KI-Anwendungsbereiche w&#228;ren Sie bereit, Ihre 
Daten zu teilen?
&#8211; 785 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
3 
W&#252;rden Sie ihre 
pers&#246;nlichen Daten 
f&#252;r z. B. f&#252;r eine 
bessere
medizinische Versorgung 
oder optimierte 
Mobilit&#228;tsangebote 
teilen? 
Welche Voraussetzungen m&#252;ssten erf&#252;llt sein? 
Welche Verbesserungen f&#252;r das Teilen von Daten w&#252;rden Sie sich 
w&#252;nschen? 
Wo sehen Sie Grenzen?  
Gehen Sie auf konkrete Beispiele aus Bereichen wie z. B.
Gesundheit, Mobilit&#228;t, Nachhaltigkeit oder Arbeit ein.
11) Welchen Handlungsbedarf sehen Sie bei der bestehenden 
Regulierung von Daten mit Blick auf KI?
M&#252;ssen bestehende Datenschutzregelungen ver&#228;ndert werden, um
KI besser einsetzen zu k&#246;nnen? 
Welche Faktoren/Regelungen im Datenbereich k&#246;nnten dazu
beitragen, dass die Entwicklung, der Einsatz oder die Akzeptanz von KI in
Deutschland erleichtert werden? 
Themenfeld 4
&#8222;Wissen und 
Forschung&#8220; 
Was wissen Sie 
&#252;ber KI und wo gibt 
es noch
Forschungs- und
Informationsbedarf? 
12) Was verstehen Sie unter KI?
Mit welchen Schlagworten assoziieren Sie KI?
Was verbinden Sie mit KI?
13) Wie und durch wen sollte Wissen &#252;ber KI verst&#228;rkt vermittelt 
werden?
Z. B. durch Medien (Fernsehen, Rundfunk, Internet), Zentrum f&#252;r
politische Bildung, (Volks)-Hochschule, Universit&#228;t
Sollten Kinder in Schulen lernen, KI-Systeme zu verstehen, und,
wenn ja, wie?
Welche M&#246;glichkeiten sehen Sie f&#252;r die spezifische Weiterbildung 
am Arbeitsplatz oder der Bev&#246;lkerung im Allgemeinen? 
14) Welche Informationen ben&#246;tigen Sie, um Funktion und
Nutzen von KI zu verstehen?
Zu welchen Teilaspekten von KI m&#246;chten Sie mehr erfahren? 
Zu welchen Themen fehlen gut aufbereitete Informationen?
15) Zu welchen Bereichen von KI sollte in Deutschland mehr
geforscht werden?
Kennen Sie Forschungs- und Entwicklungsergebnisse zu KI aus
Deutschland und wenn ja, welche finden Sie gut welche nicht,
welche sollten forciert werden?
&#8211; 786 &#8211; 
Gutachten zur Online-Beteiligung der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages
4 
Wie sch&#228;tzen Sie den Forschungs- und Entwicklungsstand zu KI in
Deutschland im Vergleich zu anderen L&#228;ndern ein?  
Themenfeld 5
&#8222;Weitere 
Anregungen zu 
KI&#8220;
Welche
Kernforderungen haben Sie 
zum Einsatz von 
KI? 
16) Welche Forderungen oder Anregungen haben Sie dar&#252;ber
hinaus zum Einsatz von KI in Deutschland?
Bitte beschr&#228;nken Sie sich auf bis zu drei Anregungen.
&#8211; 787 &#8211; 

Dokumentation der 
Ergebnispr&#228;sentation der Enquete-
Kommission K&#252;nstliche Intelligenz des 
Deutschen Bundestages
am 28. September 2020 im Paul-L&#246;be-Haus und online
&#8211; 789 &#8211;
Anlage 2
Dokumentation der Ergebnispr&#228;sentation
der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages am 28. September 2020
i 
Impressum
Liquid Democracy e.V.
Am Sudhaus 2
12053 Berlin 
nexus Institut f&#252;r Kooperationsmanagement
und interdisziplin&#228;re Forschung GmbH
Willdenowstra&#223;e 38
12203 Berlin 
Autorinnen und Autoren:
Sabine Schr&#246;der, Franziska Detsch, Max Westbrock  nexus Institut 
Marie-Kathrin Siemer Liquid Democracy
Auftraggeberin:  
Bundesrepublik Deutschland, vertreten durch den Pr&#228;sidenten des Deutschen Bundestages,
dieser vertreten durch den Direktor beim Deutschen Bundestag 
Platz der Republik 1
11011 Berlin  
Berlin, Oktober 2020
&#8211; 790 &#8211;
 &#8211;
&#8211;
Dokumentation der Ergebnispr&#228;sentation
der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages am 28. September 2020
ii
Inhalt
1 Ziele ............................................................................................................................... 1
2 Ablauf ............................................................................................................................. 1
3 Panel 1: Gesellschaft, Staat und Medien Was machen wir mit KI und was macht KI mit
uns? ............................................................................................................................... 3
4 Panel 2: KI in Gesundheit und Mobilit&#228;t &#8211; Chance auf ein ges&#252;nderes und nachhaltigeres
Leben? ........................................................................................................................... 7
5 Panel 3: Wirtschaft und Arbeit &#8211; KI als Heilsbringer und Schreckgespenst....................10
&#8211; 791 &#8211; 
&#8211; 
Dokumentation der Ergebnispr&#228;sentation
der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages am 28. September 2020
1 
1 Ziele 
Bei der am 28. September 2020 stattfindenden Veranstaltung &#8222;Mit K&#252;nstlicher Intelligenz jetzt
Zukunft gemeinsam gestalten!&#8220; der Enquete-Kommission &#8222;K&#252;nstliche Intelligenz
Gesellschaftliche Verantwortung und wirtschaftliche, soziale und &#246;kologische Potenziale&#8220; des
Deutschen Bundestages diskutierten die Mitglieder der Enquete-Kommission die Ergebnisse ihrer
Arbeit. Den Rahmen gaben relevante Themen und Ergebnisse aus der Online-Beteiligung, die
die &#214;ffentlichkeit vom 10. M&#228;rz bis zum 19. April 2020 einlud, ihre Perspektiven auf K&#252;nstliche 
Intelligenz einzubringen. Sachverst&#228;ndige Mitglieder debattierten entlang zentraler Thesen
und Empfehlungen der Online-Beteiligung und lie&#223;en dabei das gemeinsam in der Enquete-
Kommission erarbeitete Wissen einflie&#223;en.1
Das Ziel der Beteiligung der (Fach-)&#214;ffentlichkeit durch eine Online-Beteiligung war es,
Perspektiven, Meinungen und Ideen zu sammeln. Daf&#252;r registrierten sich auf der Online-
Dialogplattform www.enquetebeteiligung.de 260 Personen und verfassten insgesamt 680
Diskussionsbeitr&#228;ge. Die vier gro&#223;en Themenfelder der Online-Beteiligung &#8222;Vertrauen und
Transparenz&#8220;, &#8222;Beruf und Alltag&#8220;, &#8222;Datennutzung und Datenschutz&#8220; sowie &#8222;Wissen und Forschung&#8220;
orientierten sich an den Projektgruppen der Enquete-Kommission. Unter &#8222;Weitere Anregungen
zu KI&#8220; konnten sich die Teilnehmenden der Online-Beteiligung dar&#252;ber hinaus zu weiteren 
Themenfeldern und Fragestellungen einbringen.
Die Ergebnisse der Online-Beteiligung spiegeln unterschiedliche gesellschaftliche
Erwartungen an die zuk&#252;nftige Entwicklung von KI sowie ihre Auswirkungen auf das soziale,
&#246;konomische und &#246;kologische Leben und Umfeld. Die teils unterschiedlichen Perspektiven und
Argumente wurden bei der Ergebnispr&#228;sentation der Enquete-Kommission vorgestellt und den 
Sachverst&#228;ndigen mit der Bitte um deren Stellungnahmen eingespielt. Die
Ergebnispr&#228;sentation verfolgte damit insbesondere das Ziel einer &#246;ffentlichen Auseinandersetzung der
Mitglieder der Enquete-Kommission mit den Ergebnissen der Online-Beteiligung der &#214;ffentlichkeit. 
2 Ablauf2
Die Veranstaltung wurde durch die Vorsitzende der Enquete-Kommission, Daniela Kolbe
(MdB) er&#246;ffnet, die die Arbeit der Enquete-Kommission vorstellte. Im Anschluss diskutierten
sachverst&#228;ndige Mitglieder der Enquete-Kommission in drei Panels zu verschiedenen
thematischen Schwerpunkten die Ergebnisse der Enquete-Kommission.
Das erste Panel mit dem Thema &#8222;Gesellschaft, Staat und Medien was machen wir mit
KI und was macht KI mit uns?&#8220; widmete sich den Fragen, was KI eigentlich ist und was sie
kann, welche gesellschaftlichen Fragen ihr Einsatz aufwirft und wie ihr Einsatz, zum Beispiel
in den Medien, die Meinungsbildung beeinflusst.  
Anschlie&#223;end diskutierten die sachverst&#228;ndigen Mitglieder im zweiten Panel zum Thema &#8222;KI
in Gesundheit und Mobilit&#228;t &#8211; Chance auf ein ges&#252;nderes und nachhaltigeres Leben?&#8220;, 
1 Diese Thesen sind in der Dokumentation als &#8222;Statements aus der Online-Beteiligung&#8220; in
Anf&#252;hrungszeichen gekennzeichnet und farbig hervorgehoben.
2 Die tabellarische Darstellung des Ablaufplans findet sich im Anhang.
&#8211; 792 &#8211; 
&#8211; 
&#8211;
Dokumentation der Ergebnispr&#228;sentation
der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages am 28. September 2020
2 
in welchen F&#228;llen KI dort bereits angewendet wird, welche Bedeutung dies f&#252;r die Mobilit&#228;t,
die medizinische Versorgung und Diagnose hat, wie man dem wachsenden Energieverbrauch
von KI begegnen kann und wie das Vertrauen in KI erh&#246;ht werden kann.  
Im dritten Panel zum Thema &#8222;Wirtschaft und Arbeit &#8211; KI als Heilsbringer und
Schreckgespenst&#8220; er&#246;rterten die sachverst&#228;ndigen Mitglieder, welche Chancen und Herausforderung KI
f&#252;r Unternehmen und Arbeitnehmerinnen und -nehmer birgt und wie die Forschung zu KI
ausgerichtet sein sollte.
Diskussionsimpulse setzten zentrale Ergebnisse aus der Online-Beteiligung und griffen damit
Empfehlungen und Fragen aus der &#214;ffentlichkeit auf.3
Aufgrund der Beschr&#228;nkungen im Zusammenhang mit der Corona-Pandemie nahmen nur die 
Mitglieder der Enquete-Kommission sowie Anh&#246;rpersonen der Kommission vor Ort an der
Veranstaltung teil. F&#252;r die Einbeziehung der &#214;ffentlichkeit wurde die Veranstaltung im
Bundestagsfernsehen per Livestream &#252;bertragen. Insgesamt gab es w&#228;hrend der Veranstaltung 7 356
Abrufe des Livestreams von 945 unterschiedlichen Nutzerinnen und Nutzern (unique users).
Die Veranstaltung und ihre &#220;bertragung wurden im Vorhinein, unter anderem auch unter den
Teilnehmenden der Online-Beteiligung, beworben. Die Aufzeichnung ist in der Mediathek des
Deutschen Bundestages abrufbar.
Zus&#228;tzlich konnten die Zuschauerinnen und Zuschauer &#252;ber ein Online-Tool auf der Webseite
www.enquetebeteiligung.de Fragen an die diskutierenden Sachverst&#228;ndigen einreichen und 
sich so in die Diskussion einbringen. &#220;ber das Online-Tool konnten sowohl Fragen gestellt
werden, als auch bereits gestellte Fragen positiv bewertet werden. Dadurch r&#252;ckten Fragen,
die f&#252;r mehrere Personen relevant waren, in den Vordergrund. Ausgew&#228;hlte Fragen wurden 
durch die Vorsitzende Daniela Kolbe an die Podiumsg&#228;ste gerichtet und von diesen diskutiert.
Von den 41 Fragen wurden neun w&#228;hrend der Veranstaltung an die Podiumsg&#228;ste gestellt und
von diesen beantwortet. Hierbei wurden insbesondere die Fragen ausgew&#228;hlt, die von
mehreren anderen positiv bzw. als relevant bewertet wurden (&#8222;Votes&#8220;). 
Insgesamt wurden &#252;ber das Online-Tool 41 Fragen aus der &#214;ffentlichkeit gestellt, wobei einige 
Beitr&#228;ge mehrere Fragen enthielten. Die Fragen waren alle sachbezogen und verstie&#223;en nicht 
gegen die Netiquette. Einer der Beitr&#228;ge enthielt Fragen, die von einer KI generiert worden
waren. Die Mehrheit der Fragen kamen von B&#252;rgerinnen und B&#252;rgern (55 Prozent), etwa ein
Drittel aus der Wirtschaft (27 Prozent) und jeweils 9 Prozent aus Wissenschaft und
Zivilgesellschaft.4
Zum Abschluss der Veranstaltung zogen die Obleute der sechs Fraktionen ihr Res&#252;mee zur
Arbeit der Enquete-Kommission.
3 Die Statements aus der Online-Beteiligung sind in der Dokumentation farbig hervorgehoben.
4 Die Zugeh&#246;rigkeit zu einer dieser Gruppen konnte jeweils beim Stellen der Frage angegeben werden.
&#8211; 793 &#8211; 
Dokumentation der Ergebnispr&#228;sentation
der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages am 28. September 2020
3 
3 Panel 1: Gesellschaft, Staat und Medien &#8211; Was machen
wir mit KI und was macht KI mit uns?
Podiumsg&#228;ste
&#8226; Lena-Sophie M&#252;ller, Initiative D21 e.V.
&#8226; Prof. Dr. J&#246;rg M&#252;ller-Lietzkow, HafenCity Universit&#228;t Hamburg, Lehrstuhl &#214;konomie
und Digitalisierung 
&#8226; Dr. Aljoscha Burchardt, Language Technology Lab des Deutschen
Forschungszentrums f&#252;r K&#252;nstliche Intelligenz (DFKI)
Podiumsdiskussion
Statement aus der Online-Beteiligung 
&#8222;Der Begriff KI und das Verst&#228;ndnis unterschiedlicher Arten von KI muss gesch&#228;rft
werden.&#8220; 
KI sei ein Sammelbegriff, und es existierten immer mehr Anwendungen davon. Eine
einheitliche Definition existiere allerdings nicht. Die Enquete-Kommission habe die Definition der High-
Level Expert Group on Artificial Intelligence der EU aufgegriffen. Diese definiere KI als
Systeme, die ihre Umgebung wahrnehmen, eine Anwendung auf Basis der Wahrnehmung
ausf&#252;hren und so eine Ver&#228;nderung herbeif&#252;hren. Die Enquete-Kommission habe f&#252;r ihre Arbeit
den Begriff zudem auf Anwendungen des Maschinellen Lernens eingegrenzt. Bei einem so 
komplexen und diversen Themenfeld unterschieden sich die Fragestellungen je nach
Anwendungsfeld. Entsprechend h&#228;tten sich die Projektgruppen mit konkreten Gegenstandsbereichen
befasst und f&#252;r diese Handlungsempfehlungen formuliert.
Statement aus der Online-Beteiligung 
&#8222;Vermehrte Bildung in allen Bereichen und Altersstufen ist notwendig, um B&#252;rgerinnen und 
B&#252;rger einen m&#252;ndigen Umgang mit KI zu erm&#246;glichen und ihr Vertrauen in die Technologie 
zu st&#228;rken.&#8220; 
Gesellschaftliche Aspekte seien f&#252;r die Gestaltung von KI in unterschiedlichen
Anwendungsbereichen relevant. KI k&#246;nne perspektivisch viele Aufgaben &#252;bernehmen, die bis dato nur
Menschen verrichten k&#246;nnten. Enorme Chancen, aber auch Herausforderungen er&#246;ffneten
sich dadurch. Damit sich die B&#252;rgerinnen und B&#252;rger diese Chancen auch erschlie&#223;en
k&#246;nnen, br&#228;uchten sie dabei Unterst&#252;tzung. Gesellschaft sei divers: Einige Gruppen seien
digitalaffin, andere weniger. F&#252;r viele Menschen sei nicht erkennbar, ob KI eingesetzt wird oder nicht.
Ein kompetenter Umgang mit KI sei f&#252;r diese Nutzenden mit grundlegenden Digital- und
Medienkompetenzen verbunden. Weil die Wissensbest&#228;nde unterschiedlich seien, sei
zielgruppenspezifische Aufkl&#228;rung notwendig. Au&#223;erdem sollten zu vermittelnde Kompetenzen nach
Anwendungsbereichen aufgeschl&#252;sselt werden (z. B. Medizin, Arbeitswelt, Medien).
Statement aus der Online-Beteiligung 
&#8222;KI kann dazu beitragen, dass Informationen dem Individuum einfacher zug&#228;nglich
werden.
&#8211; 794 &#8211;
Dokumentation der Ergebnispr&#228;sentation
der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages am 28. September 2020
4 
Aber: individualisierte Informationen k&#246;nnen pers&#246;nliche Sichtweisen einseitig verst&#228;rken und 
der fehlende Austausch mit anderen Perspektiven langfristig einen
gesamtgesellschaftlichen Diskurs unm&#246;glich machen.&#8220; 
Der Einfluss von KI auf die politische Meinungsbildung in den sozialen Medien sei in der
Enquete-Kommission intensiv diskutiert worden. Viele Menschen sorgten sich vor
Manipulationen durch KI-Anwendungen, wenn Medien KI einsetzen, um meinungsbildende Inhalte zu
bef&#246;rdern, oder Inhalte durch Algorithmen vorselektiert werden. Die Bildung von Filterblasen sei 
ein Beispiel, das viele Menschen in ihrem Alltag beobachten k&#246;nnten. Die gro&#223;e
gesellschaftliche Herausforderung bestehe darin, einen Umgang damit zu finden und sich nicht lenken zu
lassen. Auch Social Bots, also Programme, die mediale Inhalte selbst produzieren k&#246;nnen und
ggf. nicht von Menschen als Programme erkannt werden, seien intensiv in der Enquete-
Kommission diskutiert worden. Bisher gebe es keine eindeutigen Antworten auf die Frage, wie
Social Bots Meinungsbildung beeinflussten.
Die Produktion von Medieninhalten k&#246;nne k&#252;nftig durch sogenanntes &#8222;Automatic Writing&#8220; von
KI &#252;bernommen werden. Diskurse w&#252;rden dann durch Algorithmen mitbestimmt mit
weitreichenden Implikationen f&#252;r Medien und &#246;ffentliche Debatten. Die Enquete-Kommission sei sich
darin einig, dass KI-Anwendungen keine Unwahrheiten fortschreiben sollten. KI k&#246;nne die
journalistische Arbeit in der Recherche jedoch auch unterst&#252;tzen. Obsolet werde traditioneller
Journalismus aller Voraussicht nach nicht, denn kritische Perspektiven w&#252;rden weiterhin
ben&#246;tigt. Die Frage sei hier, ob Menschen noch bereit sein werden, daf&#252;r zu zahlen. Es m&#252;sse
daher geschaut werden, wie daf&#252;r Gesch&#228;ftsmodelle im Medienbereich entwickelt w&#252;rden.
Statement aus der Online-Beteiligung 
&#8222;KI kann Diskriminierungen verst&#228;rken, z. B. durch unausgewogene Trainingsdaten und
stereotype Annahmen, die durch die KI-Anwendung vielfach reproduziert werden.&#8220;
Was passiert, wenn zugrundeliegende Daten einer KI-Anwendung fehlerhaft sind oder
Verzerrungen aufweisen? Bias sei etwas ganz Normales, das den komplexen Alltag erleichtere und 
auch bei analogen Prozessen vorkomme  zum Beispiel, wenn man sich bei der Auswahl von
Bewerberinnen und Bewerbern nach den Noten richte. Schwierig werde es, wenn es dabei zu 
strukturellen Diskriminierungen komme, das KI-System hiervon lerne und so die
Diskriminierung repliziere. Dies gelte es zu verhindern. KI k&#246;nne aber auch dabei helfen, Probleme zu 
bew&#228;ltigen. Die Verzerrungen, die in heutigen Auswahlverfahren schon best&#252;nden, k&#246;nnten
mithilfe von KI erst einmal aufgedeckt werden, z. B. indem eine KI vorher definierte Fairness-
Ma&#223;e auf die Daten eines Auswahlverfahrens anwendet. Sollte KI tats&#228;chlich Bewerberinnen 
oder Bewerber ausw&#228;hlen, k&#246;nne nach dem Vier-Augen-Prinzip gepr&#252;ft werden, sodass
immer ein Mensch etwaige Verzerrungen und Fehler kontrolliere. Als Unterst&#252;tzung k&#246;nnten
spezialisierte KI-Systeme nur in der Vorauswahl von bestimmten Bewerberinnen und Bewerbern
eingesetzt werden, die von Menschen final ausgew&#228;hlt w&#252;rden. Auch lie&#223;e sich mithilfe von 
synthetischen Daten eine ideale Bewerberauswahl simulieren. Aber daf&#252;r m&#252;ssten in einer 
gesellschaftlichen Debatte zun&#228;chst Kriterien f&#252;r die Auswahl beziehungsweise ein Soll-
Zustand formuliert werden. Hierf&#252;r brauche es diverse interdisziplin&#228;re Teams, um diesen Soll-
Zustand zu definieren.
&#8211; 795 &#8211; 
&#8211; 
&#8211;
Dokumentation der Ergebnispr&#228;sentation
der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages am 28. September 2020
5 
Statement aus der Online-Beteiligung 
&#8222;KI kann Menschen als pers&#246;nlicher Assistent dienen und zeitaufw&#228;ndige und
b&#252;rokratische Prozesse beschleunigen oder gar &#252;bernehmen.&#8220; 
Weil der Staat hoheitliche Aufgaben ausf&#252;hre und in die Rechte von B&#252;rgerinnen und B&#252;rgern
eingreifen k&#246;nne, m&#252;sse die Verwendung von KI hier besonders sorgf&#228;ltig &#252;berpr&#252;ft werden.
Diskriminierung durch staatliche Akteure k&#246;nne verst&#228;rkt werden, wenn Bias in KI-Systemen
nicht reflektiert werde z. B. beim Predictive Policing, das in der Enquete-Kommission intensiv
diskutiert worden sei. Dabei k&#246;nnten Stereotype dazu f&#252;hren, dass Warnsysteme in
bestimmten Bereichen zu fr&#252;h ausschlagen und bestimmte Gruppen diskriminierten. Hier k&#246;nne man 
von den Fehlern anderer L&#228;nder wie China oder den USA lernen und es besser machen.
F&#252;r den Staat und die Verwaltung gebe es aber auch viele Potenziale f&#252;r die Nutzung von KI, 
bestimmte Prozesse zu beschleunigen. In bestimmten Phasen von Entscheidungsprozessen 
in der Verwaltung gebe es durchaus unkritische Anwendungsm&#246;glichkeiten von KI (z. B. bei
der Posteingangssortierung). Auf diese neuen Prozesse gelte es, die Ausbildung und
Fortbildung von Mitarbeitenden abzustimmen und strategisch nach sinnvollen Einsatzm&#246;glichkeiten
zu suchen. 
Statement aus der Online-Beteiligung 
&#8222;Die Einsch&#228;tzungen von Risiken und G&#252;tekriterien von KI sind sinnvoll &#8211; aber wie k&#246;nnen 
diese bei einer sich stetig weiterentwickelnden KI festgelegt werden?&#8220; 
Um die Qualit&#228;t von KI-Anwendungen zu bestimmen, machten die Sachverst&#228;ndigen
verschiedene Vorschl&#228;ge. KI lasse sich nach technischen Kriterien &#252;berpr&#252;fen, z. B. im Hinblick darauf,
ob sie Bias beinhalte. Die inhaltliche Qualit&#228;t von KI lasse sich nur schwer durch
Kritikalit&#228;tsmodelle objektiv abbilden, weil diese auf subjektiven Bewertungen basiere. Daraus resultierten
schwierige Aushandlungsprozesse, die eine Einsch&#228;tzung der G&#252;te erschwerten. Die starke
Forschung in Deutschland k&#246;nne dazu beitragen, gemeinsam mit europ&#228;ischen Partnern
Parameter f&#252;r KI zu entwickeln, die gemeinsamen demokratischen Grundvorstellungen
entspr&#228;chen. Ein herkunftsbezogenes G&#252;tesiegel &#8222;AI Made in Germany&#8220; sei nur bedingt hilfreich, auch
weil nicht die Systeme an sich, sondern ihre kontextspezifische Anwendung relevant seien.
Bevor Technologien reguliert oder G&#252;tesiegel vergeben w&#252;rden, sollten M&#246;glichkeiten
geschaffen werden, sie im praktischen Einsatz zu erforschen (z. B. durch offene Schnittstellen 
zu Social Media f&#252;r Forschende).
Fragen aus der &#214;ffentlichkeit an die Podiumsg&#228;ste 
Wie k&#246;nnte eine nationale Umsetzung des AI Whitepapers aussehen? Wie stehen Sie 
zum dort angesprochenen Zertifizierungsverfahren und der einfachen High/Low Risk 
Klassifizierung? (10 Votes) 
Eine dichotome Klassifizierung nach hohem und niedrigem Risiko sei schwierig und w&#252;rde
nicht funktionieren. Stattdessen pr&#228;feriere die Enquete-Kommission ein Mehrstufenmodell.
Die Konsequenzen dieser Modelle seien aber offen, hier gebe es noch Diskussionen. Wichtig 
sei hier au&#223;erdem, nicht in erster Linie die Technologie zu bewerten, sondern deren
Anwendungsfelder. Eine Klassifizierung f&#252;hre bei den Menschen, die die Technologie nutzen, zu
einer besseren Einsch&#228;tzbarkeit der Technologie und mache au&#223;erdem einen gesellschaftlichen
Diskurs &#252;ber Folgen, Nutzen und potenzielle Sch&#228;den notwendig, der an sich sehr wichtig sei.
&#8211; 796 &#8211;
&#8211; 
Dokumentation der Ergebnispr&#228;sentation
der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages am 28. September 2020
6 
Wer ist schuld, wenn eine KI einen Fehler macht? (16 Votes)
In Bezug auf diese Frage m&#252;sse man sich vor Augen f&#252;hren, dass es momentan in der
Diskussion vor allem um schwache KI gehe. Hierf&#252;r sei man rechtlich derzeit gut aufgestellt. Ob
es daf&#252;r neue Haftungsregime brauche, sei noch nicht zu Ende diskutiert.
In zentralen Bereichen unserer Gesellschaft (wie Gesundheit, Recht, Integration, &#8230;) 
muss das Primat beim Menschen liegen, nicht bei Algorithmen. Wie k&#246;nnen wir das 
sicherstellen? (6 Votes) 
Das Primat beim Menschen sei als Utopie gut, aber es gebe Bereiche, wo die Technik dem
Menschen &#252;berlegen sei (z. B. Internetsuche). Wenn man menschliche Souver&#228;nit&#228;t behalten
wolle, m&#252;sse man sehr genau spezifizieren, was die Systeme tun d&#252;rfen und was sie nicht tun
d&#252;rfen und wie man dies testen k&#246;nne. Daf&#252;r brauche man Qualit&#228;ts-Kriterien mit denen
man dann auch analoge Prozesse testen k&#246;nne. In diesem Zusammenhang sei die Frage,
was die Technologie verhaltenspsychologisch mit uns mache und wie sie sich auf unser
Handeln auswirke, noch zu wenig erforscht.
KI spielt sicherlich in der Erzeugung, Verbreitung und Rezeption von Medieninhalten 
eine wichtige Rolle. Dazu bedarf es auf jeden Fall viel Forschung. Aber wie sieht es mit 
der Meinungsbildung zu KI und KI-Anwendungen aus? Was wissen wir bislang dar&#252;ber, 
wie sich die &#246;ffentliche Meinung zu KI entwickelt, wodurch sie gepr&#228;gt wird? Rezipiert 
man Medienberichte, so bleibt der Eindruck h&#228;ngen, es gibt zu hohe Erwartungen und 
zu gro&#223;e &#196;ngste inwiefern stimmt das aber tats&#228;chlich? (6 Votes) 
In Zusammenhang mit dem Aufkommen neuer Technologien zeigten sich auch in der
Vergangenheit h&#228;ufig gro&#223;e Bef&#252;rchtungen (z. B. Debatten zu Telearbeit und deren
Auswirkungen auf die Arbeit oder zu den Auswirkungen des Internets). KI reihe sich mit der Mystifizierung
des Begriffs einerseits in diese Diskussion ein, auf der anderen Seite habe die Enquete-
Kommission, aber auch die Datenethikkommission und die High-Level Expert Group on Artificial
Intelligence dazu beigetragen, dass fundierter und besonnener diskutiert werde, wozu die 
Technologie genutzt werden k&#246;nne. Eine aktuelle Bitkom-Studie zeige ein positives
Meinungsbild zu KI in der Bev&#246;lkerung, das sich auch verbessert habe. Mehr Forschung und kluge,
verst&#228;ndliche Wissenschaftskommunikation seien notwendig, um eine gute Wahrnehmung in
der Bev&#246;lkerung zu erhalten.
&#8211; 797 &#8211; 
&#8211;
-
&#8211;
&#8211;
Dokumentation der Ergebnispr&#228;sentation
der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages am 28. September 2020
7 
4 Panel 2: KI in Gesundheit und Mobilit&#228;t &#8211; Chance auf ein 
ges&#252;nderes und nachhaltigeres Leben?
Podiumsg&#228;ste
&#8226; Andrea Martin, Leiterin IBM Watson IoT Center M&#252;nchen
&#8226; Prof. Dr. Wolfgang Ecker, Infineon Technologies AG
&#8226; Prof. Dr. Sami Haddadin, Munich School of Robotics, Technische Universit&#228;t
M&#252;nchen 
Podiumsdiskussion
Statement aus der Online-Beteiligung 
&#8222;KI tr&#228;gt zur intelligenten Steuerung von Verkehrsstr&#246;men in St&#228;dten bei und vermeidet 
Fehler im Stra&#223;enverkehr. Autonomes Fahren bietet Chancen f&#252;r bislang weniger
mobile Personen.&#8220; 
Zu Beginn wurden existierende Anwendungsfelder von KI in der Mobilit&#228;t vorgestellt. Schon
heute werde KI z. B. bei der Berechnung von optimalen Routen in Navigationssystemen
genutzt, bei der Verkehrszeichenerkennung oder bei autonom fahrenden Traktoren auf Feldern
oder Fabrikh&#246;fen, also privatem Land. Auch fliegende Avatare w&#252;rden derzeit schon in
Laboren getestet. Allerdings fehlten daf&#252;r noch die entsprechend leistungsf&#228;higen Batteriesysteme. 
Daneben fehle es derzeit insgesamt an entsprechender Infrastruktur f&#252;r KI in der Mobilit&#228;t. Die
Infrastruktur sei jedoch elementar f&#252;r die Weiterentwicklung von KI.  
Mobilit&#228;t betreffe jedoch nicht nur den Personenverkehr, sondern auch den G&#252;ter- und
Luftverkehr. Diese verschiedenen Mobilit&#228;tsbereiche m&#252;sse man zusammendenken. Im Bereich
G&#252;terverkehr k&#246;nnten z. B. durch die Nutzung intelligenter Systeme bei der Abstimmung der
Fahrten die Anzahl an Leerfahrten reduziert werden. Gerade im l&#228;ndlichen Raum k&#246;nne der
G&#252;terverkehr au&#223;erdem st&#228;rker mit dem Personenverkehr zusammengedacht werden, z. B. 
durch Transport von Waren in &#246;ffentlichen Verkehrsmitteln. Intelligente Systeme k&#246;nnten diese
Verzahnung unterst&#252;tzen. Auch autonome, also KI-gest&#252;tzte Drohnen k&#246;nnten im l&#228;ndlichen 
Raum Bringdienste &#252;bernehmen. Daneben k&#246;nnten autonome Drohnen z. B. auch
Kartierungen vornehmen.
KI in der Mobilit&#228;t solle aber auch mit anderen Bereichen zusammen gedacht werden, etwa in
der Schifffahrt: Hier k&#246;nnten autonom fahrende Schiffe wertvolle Daten sammeln, die f&#252;r die
Meeresforschung verwendet werden k&#246;nnten.
Statement aus der Online-Beteiligung 
&#8222;KI kann eine tragende Rolle bei der Entwicklung nachhaltiger Energieversorgungskonzepte 
spielen. KI selbst ist aber h&#246;chst energieintensiv. Es braucht daher Investitionen in die
Entwicklung weniger energieverbrauchender KI-Systeme.&#8220; 
Die Energieversorgung sei ein wichtiges Thema bei KI. In der Mobilit&#228;t gebe es noch viele 
Einsparungspotenziale durch KI, zum Beispiel, indem Motoren durch den Einsatz von KI ener-
&#8211; 798 &#8211;
Dokumentation der Ergebnispr&#228;sentation
der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages am 28. September 2020
8 
giesparender und effizienter w&#252;rden und dadurch auch erst zu einem sp&#228;teren Zeitpunkt
ersetzt werden m&#252;ssten. Bei Segelschiffen k&#246;nnten die Segel durch KI intelligent gesteuert
werden und die Schiffe so effizienter werden. KI k&#246;nne auch bei der Wartung von Fahrzeugen
eingesetzt werden, sodass notwendige Reparaturen bei Fahrzeugen oder Maschinen
fr&#252;hzeitig erkannt und durchgef&#252;hrt werden k&#246;nnten und die Lebensdauer erh&#246;ht werde (Predictive
Maintenance).
Statements aus der Online-Beteiligung 
&#8222;Insbesondere im Bereich Medizin und Gesundheit wird ein hohes Potential durch die
Anwendung von KI gesehen.&#8220; 
&#8222;Die medizinische Behandlung kann durch KI besser auf die Patientinnen und Patienten 
abgestimmt werden.&#8220; 
Im Bereich Gesundheit werde KI heute bereits vor allem bei bildgebenden Verfahren genutzt. 
Hier habe die KI enorme Fortschritte gemacht, z. B. bei der Krebsdiagnose. Mithilfe von KI 
k&#246;nnten CT-Bilder analysiert und Krebs fr&#252;hzeitig erkannt werden. Der Vorteil von KI sei, dass
sie immer konzentriert sei und auch bei der Sichtung von gro&#223;en Datenmengen nicht erm&#252;de.
Ein weiteres Anwendungsfeld sei beispielsweise Spracherkennung bei Demenzerkrankungen. 
Hier k&#246;nnten mithilfe von KI fr&#252;hzeitige kleinste sprachliche Ver&#228;nderungen erkannt werden 
und so eine fr&#252;hzeitige Diagnose gestellt werden. Auch in der Schl&#252;sselloch-Chirurgie werde 
bereits heute ein Avatar-Systeme eingesetzt, bei dem die Chirurgin oder der Chirurg mit einem
kleinen Roboter im K&#246;rper verbunden sei, der dort &#252;ber die Kommunikation mit der Chirurgin
oder dem Chirurg operiere. KI unterst&#252;tze au&#223;erdem bei der &#220;berwachung von
Vitalparametern. Im Rahmen der Corona-Pandemie k&#246;nnten so z. B. Muster in Blutwerten erkannt werden
und fr&#252;hzeitig Anzeichen f&#252;r eine Blutvergiftung, die ein h&#228;ufig t&#246;dliches Symptom der
Corona-Erkrankung sei, erkannt werden. Es brauche hier aber auch eine Sensibilit&#228;t daf&#252;r, ob
Patientinnen und Patienten m&#246;chten, dass ihre Diagnose durch KI unterst&#252;tzt wird. Einerseits 
solle es ein Anrecht auf den Einsatz von KI bei der Diagnose geben, andererseits wollten
manche Menschen gar keine Fr&#252;herkennung von Krankheiten und dementsprechend
eventuell auch keinen Einsatz von KI; auch darauf m&#252;sse R&#252;cksicht genommen werden. 
Eine weitere wichtige Anwendung von KI-Technologien sei die Behandlung durch die
sogenannte &#8222;verk&#246;rperte KI&#8220;. Das hei&#223;t, die medizinische Versorgung k&#246;nne gerade bei
Risikosituationen aus der sicheren Entfernung an die Patientin oder den Patienten gebracht werden.
Auch die Bereiche Pflege und Reha k&#246;nnten durch KI revolutioniert werden, z. B. durch
individualisierte Rehabilitationsm&#246;glichkeiten, bei denen die Patientinnen und Patienten
entsprechend ihrer individuellen Fortschritte durch eine durch Pflegekr&#228;fte angelernte KI-Technologie
behandelt w&#252;rden (assist as needed), sodass damit bei wenigen vorhandenen Reha-Kr&#228;ften
auch die Verf&#252;gbarkeit von Therapien erh&#246;ht werden k&#246;nne. 
Weiterhin w&#252;rden im Bereich Pflege in Deutschland derzeit Themen vorangetrieben wie: Wie 
k&#246;nnen wir intelligente Roboterassistenten z. B. f&#252;r einfache Arbeiten wie Hol- und
Bringdienste einsetzen oder wie k&#246;nnen intelligente Roboterassistenten beim Aufstehen helfen?
&#8211; 799 &#8211; 
&#8211; &#8211;
Dokumentation der Ergebnispr&#228;sentation
der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages am 28. September 2020
9 
Statement aus der Online-Beteiligung 
&#8222;&#196;rzte und &#196;rztinnen k&#246;nnten in ihrer Kompetenz durch KI abgel&#246;st werden.
Entscheidungen w&#252;rden in der Folge zu wenig am einzelnen Menschen orientiert und w&#252;rden nur noch 
technologiebasiert getroffen.&#8220; 
Die KI solle im medizinischen Bereich nicht als Ersatztechnologie gesehen werden, sondern
als Unterst&#252;tzung f&#252;r &#196;rztinnen und &#196;rzte, als Erg&#228;nzung bei Diagnose, Therapie und Pflege. 
Durch den Einsatz von KI solle die Qualit&#228;t der Behandlung erh&#246;ht werden, aber der Mensch 
nicht ersetzt werden, das hei&#223;t, das Prinzip ist &#8222;Maschine und Mensch&#8220; und nicht &#8222;Maschine
statt Mensch&#8220;. Die Technologie solle immer ein Werkzeug f&#252;r den Menschen sein, im
Vordergrund st&#252;nden der Mensch und das Ergebnis. Wichtig sei in diesem Zusammenhang dennoch
die Frage, was die zunehmende Unterst&#252;tzung durch KI mit der Entscheidungskompetenz der
Menschen mache: Lassen wir uns irgendwann doch Entscheidungen von Maschinen
abnehmen? Verlernen wir, eigene Entscheidungen zu treffen oder hinterfragen wir KI-
Entscheidungen weniger? Diese Effekte seien bisher noch nicht hinreichend erforscht. 
In bestimmten Bereichen, z. B. bei einfachen Diagnosen, k&#246;nne KI auch weitreichendere,
autonome Funktionen &#252;bernehmen. In Deutschland sei die medizinische Versorgung gut, in
L&#228;ndern mit schlechteren Voraussetzungen k&#246;nne durch den Einsatz von KI die medizinische 
Versorgung deutlich verbessert werden. F&#252;r mehr Akzeptanz und Vertrauen in KI m&#252;ssten die
Betroffenen st&#228;rker mitgenommen und z. B. auch in die Weiterentwicklung der Technologie
einbezogen werden. Hierf&#252;r brauche es mehr anschauliche Beispiele und Erfahrungsberichte:
Wo steckt KI drin? Was kann sie uns bringen? Hier solle den teilweise verbreiteten Science-
Fiction-Bildern von KI etwas entgegengesetzt werden und KI transparent und
nachvollziehbarer gemacht werden. Au&#223;erdem m&#252;ssten &#196;rzte, Pflegekr&#228;fte und die Bev&#246;lkerung lernen, mit 
der KI-Technologie umzugehen. Das k&#246;nne &#196;ngste nehmen, von der Technologie &#252;berrannt
zu werden.
Fragen aus der &#214;ffentlichkeit an die Podiumsg&#228;ste 
Welche M&#246;glichkeiten bietet K&#252;nstliche Intelligenz angesichts ihres
Energieverbrauchs den Klimawandel aufzuhalten? (17 Votes) 
KI sei eine Software, die eine Hardware brauche, um abgearbeitet zu werden. Es gebe aber
unterschiedliche Anwendungen von KI, das hei&#223;t, unterschiedlich m&#228;chtige KI, die
dementsprechend unterschiedlich m&#228;chtige und energieintensive Hardware ben&#246;tige. Hier sei es
wichtig, die Komplexit&#228;t der eingesetzten Hardware besser auf die Anwendung abzustimmen, 
um den Energieverbrauch niedrig zu halten. In dem Bereich gebe es noch sehr viel Potenzial
f&#252;r mehr Effizienz.
Inwieweit kann und sollte KI in der Altenpflege eingesetzt werden? (10 Votes) 
Auch f&#252;r die Pflege wurde betont, dass die KI-Technologie keinen Ersatz der Pflegekr&#228;fte
darstellen solle, sondern diese erleichtern und damit auch den Pflegeberuf aufwerten k&#246;nne.
Ergebnisse einer Bitkom-Studie zu KI zeigten bereits hohe Erwartungen an KI im Bereich Pflege. 
Drei Viertel der Befragten w&#252;nschten sich den Einsatz von KI in der Pflege. Hierbei sei es
wichtig, eine Akzeptanz bei &#228;lteren Menschen und Pflegekr&#228;ften zu schaffen.
&#8211; 800 &#8211; 
Dokumentation der Ergebnispr&#228;sentation
der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages am 28. September 2020
10 
5 Panel 3: Wirtschaft und Arbeit &#8211; KI als Heilsbringer und
Schreckgespenst
Podiumsg&#228;ste
&#8226; Dr. Florian Butollo, Weizenbaum Institut f&#252;r die vernetzte Gesellschaft 
&#8226; Susanne Dehmel, Bitkom e. V.
&#8226; Dr. Sebastian Wieczorek, SAP Data Intelligence
Podiumsdiskussion
Statement aus der Online-Beteiligung 
&#8222;Entwicklung von KI im globalen Wettbewerb: &#8222;Deutschland sollte in Zusammenarbeit mit den 
EU-Staaten eine internationale Vorreiterrolle in Forschung und Entwicklung anstreben, 
um im globalen Wettbewerb nicht abgeh&#228;ngt zu werden und unabh&#228;ngig zu bleiben.&#8220; 
Neue Produkte und Dienstleistungen im Bereich KI b&#246;ten enorme wirtschaftliche Potenziale, 
gleichzeitig st&#252;nden sektorale Umbr&#252;che bevor. Insofern stelle sich die Frage, wie die
Wettbewerbsf&#228;higkeit gesteigert werden k&#246;nne. Hier sei die Zusammenarbeit mit anderen EU-
Staaten ein zentraler Faktor, um im internationalen Vergleich (insbesondere mit China und den
USA) nicht abgeh&#228;ngt zu werden bzw. gar eine Vorreiterrolle f&#252;r KI einnehmen zu k&#246;nnen.
Wichtig seien dabei vor allem auch die Bereitstellung und der Ausbau technischer
Infrastrukturen sowie die M&#246;glichkeit, ausreichend gro&#223;e Mengen an Daten zu teilen. Die Schaffung von
&#214;kosystemen f&#252;r den Transfer von Wissen und Forschung sei notwendig, um
wettbewerbsf&#228;hig zu sein.
Statement aus der Online-Beteiligung 
&#8222;KI soll sich am Gemeinwohl orientieren und nicht an gewinnorientierten Zwecken.&#8220; 
Hinsichtlich gesellschaftlicher Effekte der Weiterentwicklung von KI gebe es bislang oft
einseitige Prognosen. Es stellten sich Fragen, wie Politik mit solchen wissenschaftlichen,
wirtschaftlichen und gesellschaftlichen Umbr&#252;chen umgehen k&#246;nne, wie Gewinne m&#246;glichst
gleichm&#228;&#223;ig verteilt werden k&#246;nnten und wie wegweisende Innovationen auf den Weg gebracht werden
k&#246;nnten. Wichtig seien hier Moon-Shot-Projekte: Es bed&#252;rfe einer staatlichen
Innovationsf&#246;rderung, um solche wegweisenden Projekte zu identifizieren und umzusetzen und die
Potenziale von KI bestm&#246;glich ausnutzen zu k&#246;nnen. Politische Unterst&#252;tzungsleistungen k&#246;nnten
Unternehmen in die Lage versetzen, KI einzusetzen. 
KI sei erst einmal eine Technologie ohne konkrete Ziele; die meisten Anwendungen von KI 
seien v&#246;llig unproblematisch in der Umsetzung. Es m&#252;sse aber Einigkeit hergestellt werden,
wo und wie die Technologie zuk&#252;nftig angewendet werden solle. Hier k&#246;nne Deutschland
anstreben, in der Breite eine Technologief&#252;hrerschaft in eher unkritischen Bereichen wie der
Gesundheit, der &#246;ffentlichen Verwaltung und des Maschinenbaus zu erlangen. Die Frage danach,
wie der f&#252;r Innovationen notwendige Datenzugang f&#252;r Unternehmen und
Forschungseinrichtungen optimal erm&#246;glicht werden k&#246;nne, sei jedoch noch offen. Die KI-Entwicklung werde
sehr wahrscheinlich viele Unternehmen in Zukunft unter Druck setzen, und wenn Deutschland
&#8211; 801 &#8211; 
Dokumentation der Ergebnispr&#228;sentation
der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages am 28. September 2020
11 
sich als Hochtechnologiestandort behaupten wolle, m&#252;ssten Innovationen in Produkte
gebracht werden.
Statement aus der Online-Beteiligung 
&#8222;Monotone und zeitaufwendige T&#228;tigkeiten werden durch KI &#252;bernommen.
Arbeitnehmerinnen und Arbeitnehmern bleibt mehr Zeit f&#252;r kreative und soziale Aufgaben. Materielle 
Ressourcen k&#246;nnen eingespart werden.&#8220; 
Erst sechs Prozent der Unternehmen in Deutschland setzten KI ein. Es gebe in Deutschland
also noch viel Bedarf an einer Transformationsf&#246;rderung und gleichzeitig Unsicherheiten und
teils auch Skepsis im Hinblick darauf, wie der Einsatz von KI die Arbeit generell, den
Arbeitsmarkt und spezifische Arbeitspl&#228;tze ver&#228;ndern werde. Auch stellten sich Arbeitnehmerinnen 
und Arbeitnehmer die Frage, ob es ihren Arbeitsplatz mit fortschreitendem Einsatz von KI in
einigen Jahren &#252;berhaupt noch geben werde. Bislang l&#228;gen dazu keine KI-spezifischen
Prognosen vor, sondern nur Daten im Hinblick auf die Wirkung der Digitalisierung auf die Arbeit.
Ein Blick in die Geschichte der technologischen Entwicklung zeige jedoch, dass
Technologiespr&#252;nge bislang immer zu insgesamt mehr statt weniger Arbeitspl&#228;tzen gef&#252;hrt h&#228;tten.
Diese w&#252;rden sich jedoch in anderen bzw. neuen Wirtschaftsbereichen ansiedeln und
bed&#252;rfen daher auch neuer Kompetenzen der Arbeitenden.
Derzeit stelle sich die Frage, wie KI in der Arbeitswelt konkret eingesetzt werden k&#246;nne: Dem
Einsatz von KI am eigenen Arbeitsplatz st&#252;nden viele Arbeitnehmerinnen und Arbeitnehmer 
trotz einer generell positiven Einsch&#228;tzung der KI-Effekte bislang noch eher skeptisch
gegen&#252;ber. Ein Beispiel sei die Angst vor st&#228;rkerer Kontrolle durch eine KI. Hier sei noch mehr
praktische Erfahrung beim Einsatz von KI notwendig, um der Skepsis von Arbeitnehmerinnen und
Arbeitnehmern zu begegnen. Auch stelle sich die Frage, wie betriebliche Akteure, z. B.
Betriebsr&#228;te, aktiv in den Prozess der Implementierung von KI in Unternehmen mitgenommen
werden k&#246;nnten.
Statement aus der Online-Beteiligung 
&#8222;Wegfallende Arbeitspl&#228;tze, unabh&#228;ngig vom Qualifizierungsgrad, bilden die Kehrseite der 
Prozessoptimierung.&#8220; 
Der technische Fortschritt k&#246;nne nicht aufgehalten werden, aber man k&#246;nne Zukunft aktiv
gestalten: Da Prozesse des technischen Wandels immer auch Anpassungen der Arbeit mit sich
br&#228;chten, gelte es f&#252;r die verschiedenen Branchen, sich selbst neu zu erfinden. Denn um gute 
Arbeitspl&#228;tze zu schaffen, m&#252;sse sich die Wirtschaft anpassen und bei internationalen
Entwicklungen mithalten. Wichtig sei es, die Chancen statt nur die Risiken des technologischen
Fortschritts zu sehen. Deutschland sei in einer guten Position, z. B. durch die renommierte
Forschungslandschaft, die Entwicklung nutzen zu k&#246;nnen.
Grundlegend sei der Gedanke, dass es nicht darum gehe, alle bestehenden Arbeitspl&#228;tze in
ihrer derzeitigen Form zu erhalten, sondern vielmehr neue zu schaffen und ein gutes
gesamtwirtschaftliches System zu errichten. Menschen seien flexibel und passten sich seit jeher an
Transformationsprozesse an. Die zentrale gesellschaftliche Aufgabe sei es hierbei, m&#246;glichst 
viele Menschen mitzunehmen, denn KI sei bereits globale Realit&#228;t und man k&#246;nne sich dieser
Entwicklung zuk&#252;nftig nicht verschlie&#223;en. Es solle daher eruiert werden, wo und wie Menschen
arbeiten m&#246;chten und wo die KI guten Gewissens ihren Platz einnehmen k&#246;nne (z. B. stark
&#8211; 802 &#8211; 
Dokumentation der Ergebnispr&#228;sentation
der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages am 28. September 2020
12 
repetitive T&#228;tigkeiten). Ein verst&#228;rkter Transfer von Wissen und Forschung in die Wirtschaft
unterst&#252;tze diese Zielsetzungen.
Zielf&#252;hrend f&#252;r eine gelingende und breite Integration von KI in den (Arbeits-)Alltag seien auch
Br&#252;ckenschl&#228;ge zwischen Anwendungsbereichen sowie die F&#246;rderung von
bereichs&#252;bergreifenden Kompetenzen. Im Fokus solle dabei die qualitative Transformation der Arbeitswelt
stehen, denn KI-Systeme k&#246;nnten entweder dazu beitragen, Arbeitnehmerinnen und
Arbeitnehmer zu entm&#252;ndigen bzw. fremdzusteuern oder sie zu unterst&#252;tzen. Das Gestaltungsfeld sei
daher ein zentrales f&#252;r die betriebliche Mitbestimmung, bestenfalls solle die technologische
Weiterentwicklung mit den Mitarbeiterinnen und Mitarbeitern im Dialog implementiert werden.
Zudem solle der Betriebsrat in seiner Rolle f&#252;r die Meinungsbildung im Unternehmen beachtet
werden und u. a. dazu bef&#228;higt werden, die Ver&#228;nderungen (ggf. auch durch ein geeignetes
Monitoring) zu begleiten. Die Mitarbeiterinnen und Mitarbeiter n&#228;hmen dann auch schnell die 
Vorteile und Chancen von KI f&#252;r ihre Arbeit wahr.
Fragen aus der &#214;ffentlichkeit an die Podiumsg&#228;ste 
Wie steht die Enquete-Kommission zu einem "AI-Made-in-Europe"-Label, das durch 
Standardisierung gest&#252;tzt wird? (13 Votes) 
Zu der online gestellten Frage, wie die Enquete-Kommission zu einem Label &#8222;AI Made in
Europe&#8220; stehe, wurde konstatiert, dass es eine zentrale Grundlage sei, dass ein
gesellschaftliches Vertrauen in KI bestehe, wenn diese vermehrt eingesetzt werde. Dazu m&#252;sse eine
ethischere KI etabliert werden, als sie beispielsweise im Silicon Valley umgesetzt werde. Es stelle 
sich zunehmend die Frage, ob eine andere Form des wirtschaftlichen Wachstums m&#246;glich sei,
einhergehend mit einer sozial-&#246;kologischen Transformation: Der Klimawandel und eine
zunehmende Monopolisierung stellten Herausforderungen dar, welche zudem den Gegensatz
zwischen Arm und Reich noch verst&#228;rkten. KI k&#246;nne ein Instrument zur Vermehrung des
gesamtgesellschaftlichen Wohlstandes bei gleichzeitiger Beachtung von Klimaschutzzielen sein.  
Das EU-Wei&#223;buch zu KI strebt hoch performative, vertrauensw&#252;rdige KI-Systeme an. 
Durch vertrauensbildende Algorithmen (Sicherheit, Erkl&#228;rbarkeit, Nachvollziehbarkeit) 
wird jedoch die Komplexit&#228;t des Systems erh&#246;ht und somit die Performance im
Vergleich zu Systemen, die keine vertrauensbildenden Algorithmen anwenden, gemindert. 
Ist der Wunsch nach vertrauensw&#252;rdigen KI-Systemen, die performativ mit Systemen 
aus autokratischen Staaten mithalten k&#246;nnen, also eine Utopie? (3 Votes) 
Die Anforderungen an KI in Deutschland seien zum Teil sehr hoch. Es sei schwierig, wenn
man eine hoch performative, nachhaltige und datenschutzrechtlich sichere Technologie
zugleich haben m&#246;chte. In der Diskussion werde deutlich, dass KI nicht in allen Bereichen sofort 
optimal unter ethischen, sozialen und wirtschaftlichen Gesichtspunkten eingesetzt werden
k&#246;nne. Stattdessen m&#252;ssten vorhandene St&#228;rken identifiziert und ausgebaut werden. KI-
Systeme, die zwar ethisch einwandfrei seien, jedoch nicht gut funktionierten, seien nicht
zielf&#252;hrend. Daher sei eine Differenzierung je nach Anwendungsbereich n&#246;tig, um Abstufungen in
den Anforderungen f&#252;r unterschiedliche KI-Systeme vornehmen zu k&#246;nnen.
&#8211; 803 &#8211; 
Dokumentation der Ergebnispr&#228;sentation
der Enquete-Kommission K&#252;nstliche Intelligenz des Deutschen Bundestages am 28. September 2020
13 
Sind wir im internationalen Vergleich zu langsam? (3 Votes) 
Es sei wichtig, f&#252;r die Nutzung von Innovationspotenzialen fr&#252;hzeitig und in der Breite den 
Zugang und das Interagieren mit KI zu erm&#246;glichen. Es w&#252;rden Menschen ben&#246;tigt, die Ideen
daf&#252;r h&#228;tten, wie KI genutzt werden k&#246;nne. Daher m&#252;ssten bereits in der Schule, u. a. in den
Naturwissenschaften, der Zugang und der kritische Umgang mit Technik gelehrt und gelernt
werden. Weiterhin m&#252;ssten Arbeitnehmerinnen und Arbeitnehmer die M&#246;glichkeit zur
regelm&#228;&#223;igen Weiterbildung erhalten und Fachkr&#228;fte zus&#228;tzlich Wissen dar&#252;ber erhalten, wie sie
KI gewinnbringend f&#252;r ihren Beruf nutzen und ihre pers&#246;nlichen Kompetenzen ausbauen
k&#246;nnten.
&#8211; 804 &#8211; 
13.00 - 13.15 Uhr Er&#246;ffnung durch die Moderatorin, Nadine Kreutzer, und die 
Vorsitzende der Enquete-Kommission, Daniela Kolbe, MdB 
13.15 - 13.45 Uhr Gesellschaft, Staat und Medien Was machen wir mit KI und was 
macht KI mit uns? 
Podium: Dr. Aljoscha Burchardt, Lena-Sophie M&#252;ller und 
Prof. Dr. J&#246;rg M&#252;ller-Lietzkow 
13.45 - 14.15 Uhr KI in Gesundheit und Mobilit&#228;t Chance auf ein ges&#252;nderes und 
nachhaltigeres Leben? 
Podium: Prof. Dr. Wolfgang Ecker, Prof. Dr.-Ing. Sami Haddadin und 
Andrea Martin 
14.15 - 14.45 Uhr Wirtschaft und Arbeit  KI als Heilsbringer und Schreckgespenst 
Podium: Dr. Florian Butollo, Susanne Dehmel und  
Dr. Sebastian Wieczorek 
14.45 - 15.00 Uhr Res&#252;mee der Fraktionen CDU/CSU, FDP und DIE LINKE. 
Podium: Ronja Kemmer, MdB, Mario Brandenburg, MdB, und 
Dr. Petra Sitte, MdB 
15.00 - 15.15 Uhr Res&#252;mee der Fraktionen SPD, AfD und B&#220;NDNIS 90/DIE GR&#220;NEN 
Podium: Ren&#233; R&#246;spel, MdB, Peter Felser, MdB, und 
Dr. Anna Christmann, MdB 
15.15 - 15.30 Uhr Abschlussmoderation durch die Moderatorin, Nadine Kreutzer 
15.30 Uhr Ende der Live&#252;bertragung auf www.bundestag.de 
15.30 - 16.30 Uhr Gelegenheit zum informellen Austausch mit den G&#228;sten und den 
anwesenden Pressevertreterinnen und -vertretern 
Mit K&#252;nstlicher Intelligenz jetzt Zukunft gemeinsam gestalten! 
Programm am 28. September 2020 ab 13 Uhr 
Live&#252;bertragung auf www.bundestag.de 
Enquete-Kommission 
K&#252;nstliche Intelligenz 
Ihre Fragen k&#246;nnen Sie live &#252;ber www.enquetebeteiligung.de 
in die Diskussion einbringen!
&#8211; 805 &#8211; 
 &#8211; 
&#8211; 
&#8211;
Gesamtherstellung: H. Heenemann GmbH &amp; Co. KG, Buch- und Offsetdruckerei, Bessemerstra&#223;e 83&#8211;91, 12103 Berlin, www.heenemann-druck.de
Vertrieb: Bundesanzeiger Verlag GmbH, Postfach 10 05 34, 50445 K&#246;ln, Telefon (02 21) 97 66 83 40, Fax (02 21) 97 66 83 44, www.betrifft-gesetze.de
ISSN 0722-8333]</text>
    <titel>Bericht der Enquete-Kommission K&#252;nstliche Intelligenz - Gesellschaftliche Verantwortung und wirtschaftliche, soziale und &#246;kologische Potenziale</titel>
    <datum>2020-10-28</datum>
  </document>
  