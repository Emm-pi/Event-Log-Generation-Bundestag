<document>
    <id>236276</id>
    <drucksachetyp>Kleine Anfrage</drucksachetyp>
    <dokumentart>Drucksache</dokumentart>
    <autoren_anzahl>38</autoren_anzahl>
    <typ>Dokument</typ>
    <vorgangsbezug_anzahl>1</vorgangsbezug_anzahl>
    <dokumentnummer>19/15210</dokumentnummer>
    <wahlperiode>19</wahlperiode>
    <herausgeber>BT</herausgeber>
    <pdf_hash>28afcc88627b6117098348002ad9096b</pdf_hash>
    <aktualisiert>2022-07-26T19:57:15+02:00</aktualisiert>
    <vorgangsbezug>
      <id>255463</id>
      <titel>Besch&#228;ftigung der Bundesregierung mit Deepfakes</titel>
      <vorgangstyp>Kleine Anfrage</vorgangstyp>
    </vorgangsbezug>
    <urheber>
      <einbringer>false</einbringer>
      <bezeichnung>FDP</bezeichnung>
      <titel>Fraktion der FDP</titel>
    </urheber>
    <fundstelle>
      <pdf_url>https://dserver.bundestag.de/btd/19/152/1915210.pdf</pdf_url>
      <id>236276</id>
      <dokumentnummer>19/15210</dokumentnummer>
      <datum>2019-11-14</datum>
      <dokumentart>Drucksache</dokumentart>
      <drucksachetyp>Kleine Anfrage</drucksachetyp>
      <herausgeber>BT</herausgeber>
      <urheber>Fraktion der FDP</urheber>
    </fundstelle>
    <autoren_anzeige>
      <id>1062</id>
      <titel>Manuel H&#246;ferlin, MdB, FDP</titel>
      <autor_titel>Manuel H&#246;ferlin</autor_titel>
    </autoren_anzeige>
    <autoren_anzeige>
      <id>2136</id>
      <titel>Frank Sitta, MdB, FDP</titel>
      <autor_titel>Frank Sitta</autor_titel>
    </autoren_anzeige>
    <text>[Kleine Anfrage
der Abgeordneten Manuel H&#246;ferlin, Frank Sitta, Grigorios Aggelidis, Renata Alt, 
Nicole Bauer, Jens Beeck, Dr. Jens Brandenburg (Rhein-Neckar), Dr. Marco 
Buschmann, Britta Katharina Dassler, Hartmut Ebbing, Dr. Marcus Faber, Daniel 
F&#246;st, Thomas Hacker, Katrin Helling-Plahr, Markus Herbrand, Torsten Herbst, 
Reinhard Houben, Olaf in der Beek, Gyde Jensen, Dr. Marcel Klinge, Daniela 
Kluckert, Konstantin Kuhle, Alexander Graf Lambsdorff, Ulrich Lechte, Michael 
Georg Link, Roman M&#252;ller-B&#246;hm, Hagen Reinhold, Bernd Reuther, Dr. Wieland 
Schinnenburg, Bettina Stark-Watzinger, Dr. Marie-Agnes Strack-Zimmermann, 
Katja Suding, Linda Teuteberg, Michael Theurer, Stephan Thomae, Dr. Florian 
Toncar, Gerald Ullrich, Nicole Westig und der Fraktion der FDP
Besch&#228;ftigung der Bundesregierung mit Deepfakes
Der Begriff &#8222;Deepfake&#8220; bezeichnet t&#228;uschend echt wirkende Bild-, Audio- oder 
auch Videomanipulationen, die zumeist mit Hilfe k&#252;nstlicher Intelligenz
hergestellt wurden. Hierf&#252;r werden neuronale Netzwerke entsprechend programmiert 
und trainiert, sodass die Bilder bzw. Videos weitgehend autonom erzeugt
werden k&#246;nnen. So wurde beispielsweise bereits das Gesicht Dr. Angela Merkels 
durch das von Donald Trump ersetzt (www.tagesschau.de/faktenfinder/hinter
grund/deep-fakes-101.html) oder ein Video erstellt, in dem Mark Zuckerberg 
von der Macht schw&#228;rmt, die ihm die gestohlenen Daten von Milliarden von 
Menschen verleihen (www.welt.de/wirtschaft/webwelt/video195189665/Deep
fake-Video-Mark-Zuckerberg-schwaermt-von-Weltherrschaft-verblueffend-
echt.html). Auch wenn sich zu Beginn viele F&#228;lschungen noch bei genauerem 
Hinsehen mit blo&#223;em Auge erkennen lie&#223;en, werden die Manipulationen
zunehmend besser und sind vor allem beim schnellen Erfassen beispielsweise 
&#252;ber Social Media auf dem Handybildschirm kaum als F&#228;lschung zu erkennen.
&#8222;Im Oktober 2019 hat der US-Bundesstaat Kalifornien das Verbreiten von
&#8222;materially deceptive audio or visual media&#8220; in Bezug auf politische Kandidaten 
f&#252;r den Zeitraum von 60 Tagen vor einer Wahl verboten (Assembly Bill 
No. 730 &#8222;Elections: deceptive audio or visual media.&#8220;). Das Gesetz nimmt f&#252;r 
&#8222;materially deceptive audio or visual media&#8220; in SEC. 4 subdivision (e) eine
Definition vor. (Quelle: https://leginfo.legislature.ca.gov/faces/billTextCli
ent.xhtml?bill_id=201920200AB730)&#8220;
Die missbr&#228;uchliche Nutzung von Deepfakes ist aus Sicht der Fragesteller
zurzeit haupts&#228;chlich in drei Feldern zu beobachten bzw. zu bef&#252;rchten. Zum einen 
bieten Deepfakes neue und bessere M&#246;glichkeiten f&#252;r Desinformation. So
k&#246;nnen beispielsweise falsche Statements bzw. Fotos oder Videos von Personen 
oder Ungl&#252;cksf&#228;llen nach Ansicht der Fragesteller im schlimmsten Fall
Einfluss auf politische Prozesse nehmen. Ein weiterer Bereich ist die Nutzung von 
Deepfakes f&#252;r pornographische Inhalte. Publik wurde dieses Thema k&#252;rzlich 
Deutscher Bundestag Drucksache 19/15210
19. Wahlperiode 14.11.2019
durch den Erfolg der App &#8222;DeepNude&#8220;, die aus Fotos einer bekleideten Person 
ein Nackt-Foto ebenjener Person generierte. Das Programm wurde binnen
k&#252;rzester Zeit 100.000fach heruntergeladen, sodass schlie&#223;lich die Entwickler selbst 
die App vom Markt nahmen. Sie begr&#252;ndeten dies damit, dass bei einer solchen 
Masse an Nutzern trotz der getroffenen Sicherheitsvorkehrungen (wie z. B. 
Wasserzeichen auf den Bildern) ein Missbrauch der Anwendung nicht
auszuschlie&#223;en sei und sie auf diesem Wege kein Geld verdienen wollen (https://twit
ter.com/deepnudeapp/status/1144307316231200768). Anzumerken ist jedoch, 
dass dies lediglich mit weiblichen K&#246;rpern funktionierte (www.heise.de/tr/arti
kel/Deepfakes-Die-nackte-Gefahr-4458332.html). Dar&#252;ber hinaus werden 
immer bessere Videos pornographischen Inhalts erstellt, in denen die Gesichter 
der Akteure mit Hilfe k&#252;nstlicher Intelligenz ausgetauscht werden. Zurzeit sind 
hiervon haupts&#228;chlich prominente K&#252;nstlerinnen betroffen, jedoch sind
vermehrt auch Privatpersonen das Ziel der Manipulationen. Bereits jetzt gibt es die 
M&#246;glichkeit, gegen Bitcoins einen Deepfake-Porno mit einer beliebigen Person 
zu erwerben (www.wired.com/story/most-deepfakes-porn-multiplying-fast/). 
Voraussetzung ist lediglich gen&#252;gend Bildmaterial, was zum Teil bereits durch 
die Links zu Social-Media-Profilen gegeben ist. Solche Videoclips k&#246;nnen nach 
Ansicht der Fragesteller als Grundlage f&#252;r beispielsweise Erpressungen,
Verleumdungen oder weiteres strafrechtlich relevantes Verhalten dienen. Bisher ist 
zu beobachten, dass von dieser Problematik haupts&#228;chlich Frauen betroffen 
sind. Eine weitere Gefahr von Deepfakes ist der Bereich der Identifizierung 
bzw. Authentifizierung. Biometrische Merkmale wie die Stimme, die Iris oder 
das Gesicht lassen sich mit immer weniger Aufwand bei zeitgleich immer
besserer Qualit&#228;t unter Zuhilfenahme k&#252;nstlicher Intelligenz f&#228;lschen. Vor allem 
im Hinblick auf das Video-Ident-Verfahren er&#246;ffnet sich hier die Gefahr eines 
weitreichenden Identit&#228;tsdiebstahls (vgl. www.computerwoche.de/a/so-manipu
lieren-hacker-audio-und-videodaten,3545745).
Zusammenfassend l&#228;sst sich sagen, dass Deepfakes nach Ansicht der
Fragesteller das Potential haben, die Sicherheit momentan angewendeter Methoden zur 
Authentifizierung im Rechtsverkehr zu untergraben, das Vertrauen der
Bev&#246;lkerung in den &#246;ffentlichen Diskurs zu besch&#228;digen sowie gerade bei
pornographischen Inhalten nicht nur massiv die Pers&#246;nlichkeitsrechte Betroffener zu 
verletzen, sondern auch tiefgreifende pers&#246;nliche Sch&#228;den zu verursachen.
Jedoch gibt es auch aktive Bestrebungen und Forschungen zur Erkennung von 
manipulierten Bild-, Ton- oder Videoaufnahmen. So hat Facebook zusammen 
mit einigen Partnern wie Microsoft oder Amazon die &#8222;Deepfake Detection 
Challenge&#8220;, kurz: DFDC (https://deepfakedetectionchallenge.ai/), ins Leben 
gerufen, welche im Dezember 2019 starten wird und die Forschung im Bereich 
der automatisierten Erkennung von Deepfakes vorantreiben soll.
Es kann jedoch auch durchaus positive Einsatzm&#246;glichkeiten von Deepfakes 
geben. Im kulturellen Bereich hat beispielsweise die Zeitung &#8222;The Times&#8220;
zusammen mit Rothco einen ersten Schritt mit dem Projekt &#8222;JFK Unsilenced&#8220;
gemacht, indem sie die Rede, die John F. Kennedy am Tag seiner Ermordung in 
Dallas h&#228;tte halten sollen, mit Hilfe von k&#252;nstlicher Intelligenz und einem 
Deepfake in seiner Stimme vertont hat (https://rothco.ie/work/jfk-unsilenced/). 
Ebenso ist ein Einsatz im medizinischen Bereich denkbar. Deepfakes k&#246;nnen 
zum Beispiel Menschen helfen, die aufgrund von Behinderungen oder
chronischen Erkrankungen ihre Stimme verlieren, eine authentische Stimme zur 
Kommunikation zu erhalten oder sogar ihre eigene Stimme gewisserma&#223;en zu 
behalten (www.projectrevoice.org/).
Wir fragen die Bundesregierung:
&#8199;1. In welchen Zusammenh&#228;ngen besch&#228;ftigt sich die Bundesregierung mit 
dem Thema Deepfakes?
Welche Ressorts und dort jeweils welche Abteilungen, Referate oder
Stabsstellen besch&#228;ftigen sich konkret mit dem Thema?
&#8199;2. Welche Definition von Deepfakes legt die Bundesregierung ihrer
Besch&#228;ftigung mit diesem Thema zugrunde?
&#8199;3. Unterscheidet die Bundesregierung in ihrer Besch&#228;ftigung mit dem Thema 
Deepfakes zwischen legitimen oder harmlosen (bzw. rechtm&#228;&#223;igen) und
illegitimen oder gef&#228;hrlichen (bzw. rechtswidrigen) Zwecken zur Erstellung 
oder Verwendung von Deepfakes?
In welche Kategorie fallen f&#252;r die Bundesregierung Manipulationen von 
Medien (Audio, Foto, Video) zu Zwecken der Satire, der (kulturellen)
Bildung oder der pornographischen Darstellung?
&#8199;4. In welchen Bereichen sieht die Bundesregierung konkreten Nutzen, der 
von Deepfakes ausgeht?
Wie sch&#228;tzt die Bundesregierung den Nutzen von Deepfakes beispielsweise 
zum Zweck der Satire, der (kulturellen) Bildung oder der pornographischen 
Darstellung ein?
&#8199;5. In welchen Bereichen sieht die Bundesregierung konkrete Gefahren, die 
von Deepfakes ausgehen?
Wie sch&#228;tzt die Bundesregierung die Gefahren von Deepfakes
beispielsweise zum Zweck der Satire, der (kulturellen) Bildung oder der
pornographischen Darstellung ein?
&#8199;6. Hat die Bundesregierung zur Erforschung von Nutzen und Gefahren von 
Deepfakes bereits Studien in Auftrag gegeben?
Wenn ja, welche?
Welche bereits existierenden Studien zum Nutzen und zu den Gefahren von 
Deepfakes sind der Bundesregierung bekannt?
&#8199;7. Welche rechtlichen Regelungen existieren nach Ansicht der
Bundesregierung bereits, die konkret auf Deepfakes anwendbar sind?
Welchen Regelungsbedarf in Bezug auf Deepfakes sieht die
Bundesregierung dar&#252;ber hinaus &#8211; m&#246;glicherweise auch nur in Bezug auf einzelne
Anwendungsbereiche von Deepfakes?
&#8199;8. Hat die Bundesregierung zur rechtlichen Einordnung und zum rechtlichen 
Regelungsbedarf in Bezug auf Deepfakes bereits Studien in Auftrag
gegeben?
Wenn ja, welche?
Welche bereits existierenden Studien zur rechtlichen Einordnung und zum 
rechtlichen Regelungsbedarf in Bezug auf Deepfakes sind der
Bundesregierung bekannt?
&#8199;9. Wie viele gerichtliche Auseinandersetzungen oder Strafverfahren, in denen 
es um Deepfakes und ihre Auswirkungen ging, gab es nach Kenntnis der 
Bundesregierung seit dem Jahr 2015 (bitte nach Jahren aufschl&#252;sseln)?
10. Wie sch&#228;tzt die Bundesregierung die M&#246;glichkeit der Ausl&#246;sung oder
Vertiefung diplomatischer Spannungsf&#228;lle durch Deepfakes ein?
Wie bereitet sich die Bundesregierung auf m&#246;gliche diplomatische
Spannungsf&#228;lle vor, die durch Deepfakes ausgel&#246;st oder vertieft werden?
Welche konkreten Ma&#223;nahmen hat die Bundesregierung bisher dazu
ergriffen oder sind in Planung (wie z. B. die Entwicklung von Strategien oder 
Leitf&#228;den zur Krisenkommunikation, Szenarienworkshops, Media
Forensik, Aufbau von Expertise im Ausw&#228;rtigen Amt)?
11. Welche Ma&#223;nahmen plant die Bundesregierung, um die gesellschaftliche 
Resilienz und Medienkompetenz der Bev&#246;lkerung zu st&#228;rken und die
B&#252;rgerinnen und B&#252;rger dazu zu bef&#228;higen, Deepfakes und ihre Auswirkungen 
besser zu erkennen?
12. Welche Hilfem&#246;glichkeiten existieren nach Kenntnis der Bundesregierung 
f&#252;r Betroffene von Deepfakes?
Welche Beratungs- und Hilfestellen existieren nach Kenntnis der
Bundesregierung, die insbesondere Betroffene von Deepfakes adressieren?
13. Welchen gesamtgesellschaftlichen Einfluss k&#246;nnten Deepfakes nach
Ansicht der Bundesregierung entfalten?
Wie sch&#228;tzt die Bundesregierung etwa das Potential von Deepfakes zur 
Verunsicherung der Bev&#246;lkerung in Bezug auf das Vertrauen in wahre und 
unwahre Informationen ein?
14. Was plant die Bundesregierung, um Deepfakes insbesondere im
Zusammenhang mit Wahlen zu bek&#228;mpfen?
Plant die Bundesregierung in diesem Bereich Ma&#223;nahmen in Bezug auf 
Social-Media-Plattformen?
Wenn ja, welche?
15. Welche Bem&#252;hungen und Ma&#223;nahmen oder Vorschl&#228;ge f&#252;r Ma&#223;nahmen in 
Bezug auf Deepfakes sind der Bundesregierung auf EU-Ebene und auf 
Ebene der anderen EU-Mitgliedstaaten bekannt?
16. Wird die Bundesregierung den Umgang mit Deepfakes &#8211; im
Zusammenhang mit, aber auch au&#223;erhalb von Wahlen &#8211; als ein Thema der deutschen 
EU-Ratspr&#228;sidentschaft 2021 festlegen?
17. Wurde das Thema Deepfakes nach Kenntnis der Bundesregierung in den 
Verhandlungen zum Medienstaatsvertrag behandelt?
Wenn ja, in welcher Form?
Wenn nein, warum nicht?
18. Welche technischen M&#246;glichkeiten zur Erkennung von Deepfakes sind der 
Bundesregierung bekannt?
Welche Forschungsvorhaben gibt es nach Kenntnis der Bundesregierung 
hierzu in Deutschland und weltweit?
Berlin, den 6. November 2019
Christian Lindner und Fraktion
Gesamtherstellung: H. Heenemann GmbH &amp; Co. KG, Buch- und Offsetdruckerei, Bessemerstra&#223;e 83&#8211;91, 12103 Berlin, www.heenemann-druck.de
Vertrieb: Bundesanzeiger Verlag GmbH, Postfach 10 05 34, 50445 K&#246;ln, Telefon (02 21) 97 66 83 40, Fax (02 21) 97 66 83 44, www.betrifft-gesetze.de
ISSN 0722-8333]</text>
    <titel>Besch&#228;ftigung der Bundesregierung mit Deepfakes</titel>
    <datum>2019-11-14</datum>
  </document>
  