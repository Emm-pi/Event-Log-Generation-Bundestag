<document>
    <id>255901</id>
    <drucksachetyp>Beschlussempfehlung und Bericht</drucksachetyp>
    <dokumentart>Drucksache</dokumentart>
    <autoren_anzahl>6</autoren_anzahl>
    <typ>Dokument</typ>
    <vorgangsbezug_anzahl>1</vorgangsbezug_anzahl>
    <dokumentnummer>19/31026</dokumentnummer>
    <wahlperiode>19</wahlperiode>
    <herausgeber>BT</herausgeber>
    <pdf_hash>6e7c608a26601a417fda444522fff155</pdf_hash>
    <aktualisiert>2022-07-26T19:57:15+02:00</aktualisiert>
    <vorgangsbezug>
      <id>275622</id>
      <titel>F&#246;rderung der automatischen Erkennung KI-manipulierter Fotos und Videos</titel>
      <vorgangstyp>Antrag</vorgangstyp>
    </vorgangsbezug>
    <urheber>
      <einbringer>false</einbringer>
      <bezeichnung>AfBFT</bezeichnung>
      <titel>Ausschuss f&#252;r Bildung, Forschung und Technikfolgenabsch&#228;tzung</titel>
    </urheber>
    <fundstelle>
      <pdf_url>https://dserver.bundestag.de/btd/19/310/1931026.pdf</pdf_url>
      <id>255901</id>
      <dokumentnummer>19/31026</dokumentnummer>
      <datum>2021-06-23</datum>
      <verteildatum>2021-06-23</verteildatum>
      <dokumentart>Drucksache</dokumentart>
      <drucksachetyp>Beschlussempfehlung und Bericht</drucksachetyp>
      <herausgeber>BT</herausgeber>
      <urheber>Ausschuss f&#252;r Bildung, Forschung und Technikfolgenabsch&#228;tzung</urheber>
    </fundstelle>
    <autoren_anzeige>
      <id>7596</id>
      <titel>Mario Brandenburg (S&#252;dpfalz), MdB, FDP</titel>
      <autor_titel>Mario Brandenburg (S&#252;dpfalz), Berichterstattung</autor_titel>
    </autoren_anzeige>
    <autoren_anzeige>
      <id>2102</id>
      <titel>Dr. Anna Christmann, MdB, B&#220;NDNIS 90/DIE GR&#220;NEN</titel>
      <autor_titel>Anna Christmann, Berichterstattung</autor_titel>
    </autoren_anzeige>
    <autoren_anzeige>
      <id>2142</id>
      <titel>Dr. Michael Espendiller, MdB, AfD</titel>
      <autor_titel>Michael Espendiller, Berichterstattung</autor_titel>
    </autoren_anzeige>
    <autoren_anzeige>
      <id>197</id>
      <titel>Ren&#233; R&#246;spel, MdB, SPD</titel>
      <autor_titel>Ren&#233; R&#246;spel, Berichterstattung</autor_titel>
    </autoren_anzeige>
    <text>[Deutscher Bundestag Drucksache 19/31026
19. Wahlperiode 23.06.2021
Beschlussempfehlung und Bericht
des Ausschusses f&#252;r Bildung, Forschung und Technikfolgenabsch&#228;tzung 
(18. Ausschuss)
zu dem Antrag der Abgeordneten Joana Cotar, Dr. Michael Espendiller, Uwe
Schulz, weiterer Abgeordneter und der Fraktion der AfD
&#8211; Drucksache 19/27848 &#8211;
F&#246;rderung der automatischen Erkennung KI-manipulierter Fotos und Videos
A. Problem
Sogenannte Deep Fakes, also manipulierte Videodateien, deren Bearbeitung mit 
blo&#223;em Auge nicht zu erkennen ist, k&#246;nnen durch den Einsatz von k&#252;nstlicher
Intelligenz pr&#228;zise und mit zeitlich wie wirtschaftlich sinkendem Aufwand
produziert werden. Die nachtr&#228;gliche Bearbeitung von Bildern und Videos geschieht
durch Software, die keine Spuren mehr hinterl&#228;sst. Eingesetzt wird diese
grunds&#228;tzlich legale Technik jedoch nicht nur in der Kunst und Kultur, sondern auch zu
gesellschaftlichen und politischen Zwecken, zum Beispiel um Wahlen zu
beeinflussen oder das Ansehen demokratischer Institutionen zu untergraben. Deep
Fakes haben das Potential, das Vertrauen in den Journalismus, in Social Media
und in die gesellschaftliche Debatte zu untergraben. Demokratie und die
&#246;ffentliche Sicherheit k&#246;nnen darunter leiden. 
B. L&#246;sung
Echte von computergenerierten Bildern und Videos zu unterscheiden, ist f&#252;r die
Medienforensik eine permanente Herausforderung. Daf&#252;r brauch es eine
technologische Weiterentwicklung der Software. Eine unabh&#228;ngige Forschung daf&#252;r
jenseits kommerzieller Interessen ist notwendig, um den jeweils aktuellen Stand
der Deep-Fakes-Fabrikationen abbilden zu k&#246;nnen. Anders als die USA f&#246;rdert
die Bundesregierung trotz des gro&#223;en Missbrauchspotentials von Deep Fakes zum
Schaden der Demokratie die &#246;ffentliche Forschung nicht.
Ablehnung des Antrags mit den Stimmen der Fraktionen CDU/CSU, SPD,
FDP, DIE LINKE. und B&#220;NDNIS 90/DIE GR&#220;NEN gegen die Stimmen der
Fraktion der AfD.
C. Alternativen
Annahme des Antrags.
D. Kosten
Wurden nicht er&#246;rtert.
Beschlussempfehlung
Der Bundestag wolle beschlie&#223;en,
den Antrag auf Drucksache 19/27848 abzulehnen.
Berlin, den 9. Juni 2021
Der Ausschuss f&#252;r Bildung, Forschung und Technikfolgenabsch&#228;tzung
Dr. Ernst Dieter Rossmann
Vorsitzender
Andreas Steier Ren&#233; R&#246;spel Dr. Michael Espendiller
Berichterstatter Berichterstatter Berichterstatter
Mario Brandenburg (S&#252;dpfalz) Dr. Petra Sitte Dr. Anna Christmann
Berichterstatter Berichterstatterin Berichterstatterin
Bericht der Abgeordneten Andreas Steier, Ren&#233; R&#246;spel, Dr. Michael Espendiller,
Mario Brandenburg (S&#252;dpfalz), Dr. Petra Sitte und Dr. Anna Christmann
I. &#220;berweisung
Der Deutsche Bundestag hat den Antrag auf Drucksache 19/27848 in seiner 218. Sitzung am 25. M&#228;rz  2021
beraten und an den Ausschuss f&#252;r Bildung, Forschung und Technikfolgenabsch&#228;tzung zur federf&#252;hrenden
Beratung sowie an den Ausschuss f&#252;r Inneres und Heimat, den Ausschuss f&#252;r Kultur und Medien, den Ausschuss
Digitale Agenda und den Ausschuss f&#252;r Recht und Verbraucherschutz zur Mitberatung &#252;berwiesen.
II. Wesentlicher Inhalt der Vorlage
Schon seit den 1990er-Jahren werde Software verwendet, die Bilder aus &#228;sthetischen, kommerziellen oder
politischen Gr&#252;nden nachtr&#228;glich bearbeitet und keine sichtbaren Spuren mehr hinterl&#228;sst. In neuerer Zeit werden auch
Videodateien mit sogenannten Deep Fakes bearbeitet, die mit blo&#223;em Auge nicht mehr zu erkennen sind. Durch
den Einsatz von k&#252;nstlicher Intelligenz wachse die Pr&#228;zision und die Wirtschaftlichkeit der Manipulation. 
Wesentliche Bereiche zur Einsetzung von Deep Fakes auf der Basis des maschinellen Lernens seien das
Filmgesch&#228;ft, die Gamingbranche aber auch die Pornoindustrie. Oftmals w&#252;rden im letzteren Bereich Prominente in
rufsch&#228;digender oder erpresserischer Absicht in ein Video hineinkopiert. Doch k&#246;nne Deep Fake im schlimmsten
Falle auch Teil einer Kampagne sein, um Wahlen zu beeinflussen und das Ansehen demokratischer Institutionen 
zu untergraben. Personen des &#246;ffentlichen Lebens seien in Gefahr, Opfer dieser Technik zu werden. Daher habe
die Defence Advanced Research Projects Agency (DARPA) im Vorfeld der j&#252;ngsten US-Pr&#228;sidentschaftswahlen
Forschungsmittel bereitgestellt, um eine Abwehrstrategie gegen Deep Fakes zu entwickeln. Dabei gehe es
insbesondere darum, F&#228;lschungen automatisch erkennen zu k&#246;nnen. Da Deep Fakes das Potential h&#228;tten, das Vertrauen
in Journalismus, Social Media und in die gesellschaftliche Debatte zu verletzen, stelle diese Technik eine gro&#223;e
Gefahr f&#252;r die Demokratie und die &#246;ffentliche Sicherheit dar. Daher sei es notwendig, Forschung zu betreiben, 
und um Deep Fakes sicher, rasch und kosteng&#252;nstig als solche identifizieren zu k&#246;nnen.  
Die bisherigen Verfahren der Medienforensik m&#252;ssten hierzu technologisch weiterentwickelt werden, um
sicherzustellen, dass demokratiegef&#228;hrdende Deep-Fake-Produktionen als solche auch erkannt werden k&#246;nnen. Die
Forschung in diesem Bereich sei unabweisbar, was private Anbieter bereits erkannt h&#228;tten. Diese riefen regelm&#228;&#223;ig
zu Wettbewerben zur Detektion und Identifikation von Deep Fakes auf. Aufgrund der Gefahren von Deep Fakes
f&#252;r die Demokratie und die freiheitliche Gesellschaft erscheine es notwendig, dass auch unabh&#228;ngige Forschung
jenseits kommerzieller Interessen den jeweils aktuellen Stand der Deep-Fakes-Fabrikation abbilden k&#246;nne. Dies
sei eine Aufgabe der Bundesregierung. 
Die Fraktion der AfD fordert die Bundesregierung unter anderem auf,
&#8211; das Wissen &#252;ber die dynamische Erstellung und die Detektion von Deep Fakes in Deutschland deutlich
auszubauen, um der signifikanten Verbreitung von Deep Fakes auf der Basis von KI angemessen begegnen zu
k&#246;nnen;
&#8211; medienforensische F&#228;higkeiten entlang der oben genannte Desiderate in Beh&#246;rden, Unternehmen und
Hochschulen wie auch au&#223;eruniversit&#228;rer Forschungseinrichtungen (stellvertretend das Fraunhofer Institut f&#252;r
Digitale Medientechnologie IDMT) auszubauen, um auch in diesem Bereich eine digitale Souver&#228;nit&#228;t
Deutschlands zu gew&#228;hrleisten;
&#8211; das Wissen &#252;ber Fertigung, Wirkung, Verbreitung und Identifizierung von Deep Fakes f&#252;r eine systematische
Aufkl&#228;rung der Bev&#246;lkerung &#252;ber das technisch Praktikable zu nutzen;
&#8211; Kooperationen unterschiedlichster Institutionen rechtlich, organisatorisch, finanziell und technisch zu
unterst&#252;tzen, um die bestehenden Kompetenzen zur Verifizierung/Falsifizierung von Medien zu b&#252;ndeln und so
die Pr&#252;fpraxis erheblich schlagkr&#228;ftiger und schneller machen und die Glaubw&#252;rdigkeit der Pr&#252;fergebnisse
zu erh&#246;hen;
&#8211; den entsprechenden Wissenstransfer mit hinreichenden Mitteln auszustatten, um mit der technologischen
Entwicklung Schritt halten zu k&#246;nnen.
III. Stellungnahmen der mitberatenden Aussch&#252;sse
Der Ausschuss f&#252;r Inneres und Heimat hat den Antrag auf Drucksache 19/27848 in seiner 138. Sitzung am
5. Mai 2021 beraten und empfiehlt mit den Stimmen der Fraktionen CDU/CSU, SPD, FDP, DIE LINKE. und
B&#220;NDNIS 90/DIE GR&#220;NEN gegen die Stimmen der Fraktion der AfD die Ablehnung.
Der Ausschuss f&#252;r Recht und Verbraucherschutz hat den Antrag auf Drucksache 19/27848 in seiner 158.
Sitzung am 9. Juni 2021 beraten und empfiehlt mit den Stimmen der Fraktionen CDU/CSU, SPD, FDP, DIE LINKE.
und B&#220;NDNIS 90/DIE GR&#220;NEN gegen die Stimmen der Fraktion der AfD die Ablehnung.
Der Ausschuss f&#252;r Kultur und Medien hat den Antrag auf Drucksache 19/27848 in seiner 76. Sitzung am
9. Juni 2021 beraten und empfiehlt mit den Stimmen der Fraktionen CDU/CSU, SPD, FDP, DIE LINKE. und 
B&#220;NDNIS 90/DIE GR&#220;NEN gegen die Stimmen der Fraktion der AfD die Ablehnung.
Der Ausschuss Digitale Agenda hat den Antrag auf Drucksache 19/27848 in seiner 82. Sitzung am 9. Juni 2021
beraten und empfiehlt mit den Stimmen der Fraktionen CDU/CSU, SPD, FDP, DIE LINKE. und B&#220;NDNIS
90/DIE GR&#220;NEN gegen die Stimmen der Fraktion der AfD die Ablehnung.
IV. Beratungsverlauf und Beratungsergebnisse im federf&#252;hrenden Ausschuss
Der Ausschuss f&#252;r Bildung, Forschung und Technikfolgenabsch&#228;tzung hat den Antrag auf Drucksache 
19/27848 in seiner 76. Sitzung am 9. Juni 2021 beraten und empfiehlt mit den Stimmen der Fraktionen CDU/CSU,
SPD, FDP, DIE LINKE. und B&#220;NDNIS 90/DIE GR&#220;NEN gegen die Stimmen der Fraktion der AfD die
Ablehnung.
Berlin, den 9. Juni 2021
Andreas Steier Ren&#233; R&#246;spel Dr. Michael Espendiller
Berichterstatter Berichterstatter Berichterstatter
Mario Brandenburg (S&#252;dpfalz) Dr. Petra Sitte Dr. Anna Christmann
Berichterstatter Berichterstatterin Berichterstatterin


Gesamtherstellung: H. Heenemann GmbH &amp; Co. KG, Buch- und Offsetdruckerei, Bessemerstra&#223;e 83&#8211;91, 12103 Berlin, www.heenemann-druck.de
Vertrieb: Bundesanzeiger Verlag GmbH, Postfach 10 05 34, 50445 K&#246;ln, Telefon (02 21) 97 66 83 40, Fax (02 21) 97 66 83 44, www.betrifft-gesetze.de
ISSN 0722-8333]</text>
    <titel>zu dem Antrag der Abgeordneten Joana Cotar, Dr. Michael Espendiller, Uwe Schulz, weiterer Abgeordneter und der Fraktion der AfD
- Drucksache 19/27848 -
F&#246;rderung der automatischen Erkennung KI-manipulierter Fotos und Videos</titel>
    <datum>2021-06-23</datum>
  </document>
  